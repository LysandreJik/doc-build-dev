import{S as Fe,i as Re,s as Ge,e as a,k as m,w as A,t as s,M as Je,c as n,d as r,m as c,a as o,x as z,h as l,b as d,G as t,g as _,y as L,L as Ke,q,o as j,B as M,v as Qe}from"../chunks/vendor-hf-doc-builder.js";import{D as K}from"../chunks/Docstring-hf-doc-builder.js";import{C as Xe}from"../chunks/CodeBlock-hf-doc-builder.js";import{I as Ye}from"../chunks/IconCopyLink-hf-doc-builder.js";function Ze(Ae){let f,Q,g,v,B,I,me,H,ce,X,y,pe,V,de,ue,Y,u,he,U,fe,ge,k,W,_e,ve,Z,E,ee,i,N,ye,b,x,be,F,$e,Te,$,D,we,R,Ie,ke,T,C,Ee,P,Ne,G,xe,De,Ce,w,O,Pe,J,Oe,te;return I=new Ye({}),E=new Xe({props:{code:`-from transformers import Trainer
+from optimum.intel.neural_compressor import IncTrainer

-trainer = Trainer(
+trainer = IncTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
    data_collator=data_collator,
)`,highlighted:`<span class="hljs-deletion">-from transformers import Trainer</span>
<span class="hljs-addition">+from optimum.intel.neural_compressor import IncTrainer</span>

<span class="hljs-deletion">-trainer = Trainer(</span>
<span class="hljs-addition">+trainer = IncTrainer(</span>
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
    data_collator=data_collator,
)`}}),N=new K({props:{name:"class optimum.intel.IncTrainer",anchor:"optimum.intel.IncTrainer",parameters:[{name:"model",val:": Module = None"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"model_init",val:": Callable = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": Tuple = (None, None)"},{name:"preprocess_logits_for_metrics",val:": Callable = None"}],source:"https://github.com/huggingface/optimum.intel/blob/vr_28/src/optimum/intel/neural_compressor/trainer.py#L66"}}),x=new K({props:{name:"compute_distillation_loss",anchor:"optimum.intel.IncTrainer.compute_distillation_loss",parameters:[{name:"student_outputs",val:""},{name:"teacher_outputs",val:""}],source:"https://github.com/huggingface/optimum.intel/blob/vr_28/src/optimum/intel/neural_compressor/trainer.py#L589"}}),D=new K({props:{name:"compute_loss",anchor:"optimum.intel.IncTrainer.compute_loss",parameters:[{name:"model",val:""},{name:"inputs",val:""},{name:"return_outputs",val:" = False"}],source:"https://github.com/huggingface/optimum.intel/blob/vr_28/src/optimum/intel/neural_compressor/trainer.py#L531"}}),C=new K({props:{name:"save_model",anchor:"optimum.intel.IncTrainer.save_model",parameters:[{name:"output_dir",val:": typing.Optional[str] = None"},{name:"_internal_call",val:": bool = False"}],source:"https://github.com/huggingface/optimum.intel/blob/vr_28/src/optimum/intel/neural_compressor/trainer.py#L481"}}),O=new K({props:{name:"train",anchor:"optimum.intel.IncTrainer.train",parameters:[{name:"agent",val:": typing.Optional[neural_compressor.experimental.component.Component] = None"},{name:"resume_from_checkpoint",val:": typing.Union[bool, str, NoneType] = None"},{name:"trial",val:": typing.Union[_ForwardRef('optuna.Trial'), typing.Dict[str, typing.Any]] = None"},{name:"ignore_keys_for_eval",val:": typing.Optional[typing.List[str]] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"optimum.intel.IncTrainer.train.agent",description:`<strong>agent</strong> (<code>Component</code>, <em>optional</em>) &#x2014;
Component object containing the compression objects to apply during the training process.`,name:"agent"},{anchor:"optimum.intel.IncTrainer.train.resume_from_checkpoint",description:`<strong>resume_from_checkpoint</strong> (<em>str</em> or <em>bool</em>, <em>optional</em>) &#x2014;
If a <em>str</em>, local path to a saved checkpoint as saved by a previous instance of
<a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer" rel="nofollow">Trainer</a>. If a <em>bool</em> and equals <em>True</em>, load the last checkpoint in
<em>args.output_dir</em> as saved by a previous instance of <a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer" rel="nofollow">Trainer</a>. If present,
training will resume from the model/optimizer/scheduler states loaded here.`,name:"resume_from_checkpoint"},{anchor:"optimum.intel.IncTrainer.train.trial",description:`<strong>trial</strong> (<em>optuna.Trial</em> or <em>Dict[str, Any]</em>, <em>optional</em>) &#x2014;
The trial run or the hyperparameter dictionary for hyperparameter search.`,name:"trial"},{anchor:"optimum.intel.IncTrainer.train.ignore_keys_for_eval",description:`<strong>ignore_keys_for_eval</strong> (<em>List[str]</em>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions for evaluation during the training.
kwargs &#x2014;
Additional keyword arguments used to hide deprecated arguments`,name:"ignore_keys_for_eval"}],source:"https://github.com/huggingface/optimum.intel/blob/vr_28/src/optimum/intel/neural_compressor/trainer.py#L67"}}),{c(){f=a("meta"),Q=m(),g=a("h1"),v=a("a"),B=a("span"),A(I.$$.fragment),me=m(),H=a("span"),ce=s("IncTrainer"),X=m(),y=a("p"),pe=s("The "),V=a("code"),de=s("IncTrainer"),ue=s(" class provides an API to apply compression techniques such as knowledge distillation, pruning and quantization while training the model."),Y=m(),u=a("p"),he=s("Those compression techniques can be combined easily with our "),U=a("code"),fe=s("IncTrainer"),ge=s(" which possess a similar behavior than the "),k=a("a"),W=a("code"),_e=s("Trainer"),ve=s(" of Transformers:"),Z=m(),A(E.$$.fragment),ee=m(),i=a("div"),A(N.$$.fragment),ye=m(),b=a("div"),A(x.$$.fragment),be=m(),F=a("p"),$e=s("How the distillation loss is computed given the student and teacher outputs."),Te=m(),$=a("div"),A(D.$$.fragment),we=m(),R=a("p"),Ie=s("How the loss is computed by Trainer. By default, all models return the loss in the first element."),ke=m(),T=a("div"),A(C.$$.fragment),Ee=m(),P=a("p"),Ne=s("Will save the model, so you can reload it using "),G=a("code"),xe=s("from_pretrained()"),De=s(`.
Will only save from the main process.`),Ce=m(),w=a("div"),A(O.$$.fragment),Pe=m(),J=a("p"),Oe=s("Main training entry point."),this.h()},l(e){const p=Je('[data-svelte="svelte-1phssyn"]',document.head);f=n(p,"META",{name:!0,content:!0}),p.forEach(r),Q=c(e),g=n(e,"H1",{class:!0});var re=o(g);v=n(re,"A",{id:!0,class:!0,href:!0});var ze=o(v);B=n(ze,"SPAN",{});var Le=o(B);z(I.$$.fragment,Le),Le.forEach(r),ze.forEach(r),me=c(re),H=n(re,"SPAN",{});var qe=o(H);ce=l(qe,"IncTrainer"),qe.forEach(r),re.forEach(r),X=c(e),y=n(e,"P",{});var ae=o(y);pe=l(ae,"The "),V=n(ae,"CODE",{});var je=o(V);de=l(je,"IncTrainer"),je.forEach(r),ue=l(ae," class provides an API to apply compression techniques such as knowledge distillation, pruning and quantization while training the model."),ae.forEach(r),Y=c(e),u=n(e,"P",{});var S=o(u);he=l(S,"Those compression techniques can be combined easily with our "),U=n(S,"CODE",{});var Me=o(U);fe=l(Me,"IncTrainer"),Me.forEach(r),ge=l(S," which possess a similar behavior than the "),k=n(S,"A",{href:!0,rel:!0});var Se=o(k);W=n(Se,"CODE",{});var Be=o(W);_e=l(Be,"Trainer"),Be.forEach(r),Se.forEach(r),ve=l(S," of Transformers:"),S.forEach(r),Z=c(e),z(E.$$.fragment,e),ee=c(e),i=n(e,"DIV",{class:!0});var h=o(i);z(N.$$.fragment,h),ye=c(h),b=n(h,"DIV",{class:!0});var ne=o(b);z(x.$$.fragment,ne),be=c(ne),F=n(ne,"P",{});var He=o(F);$e=l(He,"How the distillation loss is computed given the student and teacher outputs."),He.forEach(r),ne.forEach(r),Te=c(h),$=n(h,"DIV",{class:!0});var oe=o($);z(D.$$.fragment,oe),we=c(oe),R=n(oe,"P",{});var Ve=o(R);Ie=l(Ve,"How the loss is computed by Trainer. By default, all models return the loss in the first element."),Ve.forEach(r),oe.forEach(r),ke=c(h),T=n(h,"DIV",{class:!0});var ie=o(T);z(C.$$.fragment,ie),Ee=c(ie),P=n(ie,"P",{});var se=o(P);Ne=l(se,"Will save the model, so you can reload it using "),G=n(se,"CODE",{});var Ue=o(G);xe=l(Ue,"from_pretrained()"),Ue.forEach(r),De=l(se,`.
Will only save from the main process.`),se.forEach(r),ie.forEach(r),Ce=c(h),w=n(h,"DIV",{class:!0});var le=o(w);z(O.$$.fragment,le),Pe=c(le),J=n(le,"P",{});var We=o(J);Oe=l(We,"Main training entry point."),We.forEach(r),le.forEach(r),h.forEach(r),this.h()},h(){d(f,"name","hf:doc:metadata"),d(f,"content",JSON.stringify(et)),d(v,"id","optimum.intel.IncTrainer"),d(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(v,"href","#optimum.intel.IncTrainer"),d(g,"class","relative group"),d(k,"href","https://huggingface.co/docs/transformers/main/en/main_classes/trainer#trainer"),d(k,"rel","nofollow"),d(b,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),d(i,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,p){t(document.head,f),_(e,Q,p),_(e,g,p),t(g,v),t(v,B),L(I,B,null),t(g,me),t(g,H),t(H,ce),_(e,X,p),_(e,y,p),t(y,pe),t(y,V),t(V,de),t(y,ue),_(e,Y,p),_(e,u,p),t(u,he),t(u,U),t(U,fe),t(u,ge),t(u,k),t(k,W),t(W,_e),t(u,ve),_(e,Z,p),L(E,e,p),_(e,ee,p),_(e,i,p),L(N,i,null),t(i,ye),t(i,b),L(x,b,null),t(b,be),t(b,F),t(F,$e),t(i,Te),t(i,$),L(D,$,null),t($,we),t($,R),t(R,Ie),t(i,ke),t(i,T),L(C,T,null),t(T,Ee),t(T,P),t(P,Ne),t(P,G),t(G,xe),t(P,De),t(i,Ce),t(i,w),L(O,w,null),t(w,Pe),t(w,J),t(J,Oe),te=!0},p:Ke,i(e){te||(q(I.$$.fragment,e),q(E.$$.fragment,e),q(N.$$.fragment,e),q(x.$$.fragment,e),q(D.$$.fragment,e),q(C.$$.fragment,e),q(O.$$.fragment,e),te=!0)},o(e){j(I.$$.fragment,e),j(E.$$.fragment,e),j(N.$$.fragment,e),j(x.$$.fragment,e),j(D.$$.fragment,e),j(C.$$.fragment,e),j(O.$$.fragment,e),te=!1},d(e){r(f),e&&r(Q),e&&r(g),M(I),e&&r(X),e&&r(y),e&&r(Y),e&&r(u),e&&r(Z),M(E,e),e&&r(ee),e&&r(i),M(N),M(x),M(D),M(C),M(O)}}}const et={local:"optimum.intel.IncTrainer",title:"IncTrainer"};function tt(Ae){return Qe(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class it extends Fe{constructor(f){super();Re(this,f,tt,Ze,Ge,{})}}export{it as default,et as metadata};
