import{S as Wa,i as Za,s as nc,e as h,k as g,w as v,t as m,M as tc,c as p,d as a,m as d,x as j,a as u,h as f,b as q,G as c,g as r,y,o as b,p as dn,q as k,B as w,v as sc,n as _n}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ya}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Ja}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Kt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as E}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Qa}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as ec}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function ac($){let e,l;return e=new Qa({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section5_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section5_tf.ipynb"}]}}),{c(){v(e.$$.fragment)},l(t){j(e.$$.fragment,t)},m(t,o){y(e,t,o),l=!0},i(t){l||(k(e.$$.fragment,t),l=!0)},o(t){b(e.$$.fragment,t),l=!1},d(t){w(e,t)}}}function cc($){let e,l;return e=new Qa({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section5_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section5_pt.ipynb"}]}}),{c(){v(e.$$.fragment)},l(t){j(e.$$.fragment,t)},m(t,o){y(e,t,o),l=!0},i(t){l||(k(e.$$.fragment,t),l=!0)},o(t){b(e.$$.fragment,t),l=!1},d(t){w(e,t)}}}function ic($){let e,l;return e=new Ja({props:{id:"ROxrFOEbsQE"}}),{c(){v(e.$$.fragment)},l(t){j(e.$$.fragment,t)},m(t,o){y(e,t,o),l=!0},i(t){l||(k(e.$$.fragment,t),l=!0)},o(t){b(e.$$.fragment,t),l=!1},d(t){w(e,t)}}}function lc($){let e,l;return e=new Ja({props:{id:"M6adb1j2jPI"}}),{c(){v(e.$$.fragment)},l(t){j(e.$$.fragment,t)},m(t,o){y(e,t,o),l=!0},i(t){l||(k(e.$$.fragment,t),l=!0)},o(t){b(e.$$.fragment,t),l=!1},d(t){w(e,t)}}}function rc($){let e,l,t,o;return e=new E({props:{code:`import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = tf.constant(ids)
# This line will fail.
model(input_ids)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = tf.constant(ids)
<span class="hljs-comment"># This line will fail.</span>
model(input_ids)`}}),t=new E({props:{code:"InvalidArgumentError: Input to reshape is a tensor with 14 values, but the requested shape has 196 [Op:Reshape]",highlighted:'InvalidArgumentError: Input to reshape <span class="hljs-keyword">is</span> a tensor <span class="hljs-keyword">with</span> <span class="hljs-number">14</span> values, but the requested shape has <span class="hljs-number">196</span> [Op:Reshape]'}}),{c(){v(e.$$.fragment),l=g(),v(t.$$.fragment)},l(s){j(e.$$.fragment,s),l=d(s),j(t.$$.fragment,s)},m(s,_){y(e,s,_),r(s,l,_),y(t,s,_),o=!0},i(s){o||(k(e.$$.fragment,s),k(t.$$.fragment,s),o=!0)},o(s){b(e.$$.fragment,s),b(t.$$.fragment,s),o=!1},d(s){w(e,s),s&&a(l),w(t,s)}}}function oc($){let e,l,t,o;return e=new E({props:{code:`import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = torch.tensor(ids)
# This line will fail.
model(input_ids)`,highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
input_ids = torch.tensor(ids)
<span class="hljs-comment"># This line will fail.</span>
model(input_ids)`}}),t=new E({props:{code:"IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)",highlighted:'IndexError: Dimension out of <span class="hljs-built_in">range</span> (expected to be <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span> of [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], but got <span class="hljs-number">1</span>)'}}),{c(){v(e.$$.fragment),l=g(),v(t.$$.fragment)},l(s){j(e.$$.fragment,s),l=d(s),j(t.$$.fragment,s)},m(s,_){y(e,s,_),r(s,l,_),y(t,s,_),o=!0},i(s){o||(k(e.$$.fragment,s),k(t.$$.fragment,s),o=!0)},o(s){b(e.$$.fragment,s),b(t.$$.fragment,s),o=!1},d(s){w(e,s),s&&a(l),w(t,s)}}}function hc($){let e,l,t,o;return e=new E({props:{code:`tokenized_inputs = tokenizer(sequence, return_tensors="tf")
print(tokenized_inputs["input_ids"])`,highlighted:`tokenized_inputs = tokenizer(sequence, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-built_in">print</span>(tokenized_inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])`}}),t=new E({props:{code:`<tf.Tensor: shape=(1, 16), dtype=int32, numpy=
array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,
        12172,  2607,  2026,  2878,  2166,  1012,   102]], dtype=int32)>`,highlighted:`&lt;tf.Tensor: shape=(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>), dtype=int32, numpy=
array([[  <span class="hljs-number">101</span>,  <span class="hljs-number">1045</span>,  <span class="hljs-number">1005</span>,  <span class="hljs-number">2310</span>,  <span class="hljs-number">2042</span>,  <span class="hljs-number">3403</span>,  <span class="hljs-number">2005</span>,  <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>,
        <span class="hljs-number">12172</span>,  <span class="hljs-number">2607</span>,  <span class="hljs-number">2026</span>,  <span class="hljs-number">2878</span>,  <span class="hljs-number">2166</span>,  <span class="hljs-number">1012</span>,   <span class="hljs-number">102</span>]], dtype=int32)&gt;`}}),{c(){v(e.$$.fragment),l=g(),v(t.$$.fragment)},l(s){j(e.$$.fragment,s),l=d(s),j(t.$$.fragment,s)},m(s,_){y(e,s,_),r(s,l,_),y(t,s,_),o=!0},i(s){o||(k(e.$$.fragment,s),k(t.$$.fragment,s),o=!0)},o(s){b(e.$$.fragment,s),b(t.$$.fragment,s),o=!1},d(s){w(e,s),s&&a(l),w(t,s)}}}function pc($){let e,l,t,o;return e=new E({props:{code:`tokenized_inputs = tokenizer(sequence, return_tensors="pt")
print(tokenized_inputs["input_ids"])`,highlighted:`tokenized_inputs = tokenizer(sequence, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-built_in">print</span>(tokenized_inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])`}}),t=new E({props:{code:`tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,
          2607,  2026,  2878,  2166,  1012,   102]])`,highlighted:`tensor([[  <span class="hljs-number">101</span>,  <span class="hljs-number">1045</span>,  <span class="hljs-number">1005</span>,  <span class="hljs-number">2310</span>,  <span class="hljs-number">2042</span>,  <span class="hljs-number">3403</span>,  <span class="hljs-number">2005</span>,  <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>, <span class="hljs-number">12172</span>,
          <span class="hljs-number">2607</span>,  <span class="hljs-number">2026</span>,  <span class="hljs-number">2878</span>,  <span class="hljs-number">2166</span>,  <span class="hljs-number">1012</span>,   <span class="hljs-number">102</span>]])`}}),{c(){v(e.$$.fragment),l=g(),v(t.$$.fragment)},l(s){j(e.$$.fragment,s),l=d(s),j(t.$$.fragment,s)},m(s,_){y(e,s,_),r(s,l,_),y(t,s,_),o=!0},i(s){o||(k(e.$$.fragment,s),k(t.$$.fragment,s),o=!0)},o(s){b(e.$$.fragment,s),b(t.$$.fragment,s),o=!1},d(s){w(e,s),s&&a(l),w(t,s)}}}function uc($){let e,l;return e=new E({props:{code:`import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = tf.constant([ids])
print("Input IDs:", input_ids)

output = model(input_ids)
print("Logits:", output.logits)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = tf.constant([ids])
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Input IDs:&quot;</span>, input_ids)

output = model(input_ids)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Logits:&quot;</span>, output.logits)`}}),{c(){v(e.$$.fragment)},l(t){j(e.$$.fragment,t)},m(t,o){y(e,t,o),l=!0},i(t){l||(k(e.$$.fragment,t),l=!0)},o(t){b(e.$$.fragment,t),l=!1},d(t){w(e,t)}}}function mc($){let e,l;return e=new E({props:{code:`import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = torch.tensor([ids])
print("Input IDs:", input_ids)

output = model(input_ids)
print("Logits:", output.logits)`,highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

input_ids = torch.tensor([ids])
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Input IDs:&quot;</span>, input_ids)

output = model(input_ids)
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Logits:&quot;</span>, output.logits)`}}),{c(){v(e.$$.fragment)},l(t){j(e.$$.fragment,t)},m(t,o){y(e,t,o),l=!0},i(t){l||(k(e.$$.fragment,t),l=!0)},o(t){b(e.$$.fragment,t),l=!1},d(t){w(e,t)}}}function fc($){let e,l;return e=new E({props:{code:`Input IDs: tf.Tensor(
[[ 1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026  2878
   2166  1012]], shape=(1, 14), dtype=int32)
Logits: tf.Tensor([[-2.7276208  2.8789377]], shape=(1, 2), dtype=float32)`,highlighted:`Input IDs: tf.Tensor(
[[ <span class="hljs-number">1045</span>  <span class="hljs-number">1005</span>  <span class="hljs-number">2310</span>  <span class="hljs-number">2042</span>  <span class="hljs-number">3403</span>  <span class="hljs-number">2005</span>  <span class="hljs-number">1037</span> <span class="hljs-number">17662</span> <span class="hljs-number">12172</span>  <span class="hljs-number">2607</span>  <span class="hljs-number">2026</span>  <span class="hljs-number">2878</span>
   <span class="hljs-number">2166</span>  <span class="hljs-number">1012</span>]], shape=(<span class="hljs-number">1</span>, <span class="hljs-number">14</span>), dtype=int32)
Logits: tf.Tensor([[-<span class="hljs-number">2.7276208</span>  <span class="hljs-number">2.8789377</span>]], shape=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), dtype=float32)`}}),{c(){v(e.$$.fragment)},l(t){j(e.$$.fragment,t)},m(t,o){y(e,t,o),l=!0},i(t){l||(k(e.$$.fragment,t),l=!0)},o(t){b(e.$$.fragment,t),l=!1},d(t){w(e,t)}}}function gc($){let e,l;return e=new E({props:{code:`Input IDs: [[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607, 2026,  2878,  2166,  1012]]
Logits: [[-2.7276,  2.8789]]`,highlighted:`Input IDs: [[ <span class="hljs-number">1045</span>,  <span class="hljs-number">1005</span>,  <span class="hljs-number">2310</span>,  <span class="hljs-number">2042</span>,  <span class="hljs-number">3403</span>,  <span class="hljs-number">2005</span>,  <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>, <span class="hljs-number">12172</span>,  <span class="hljs-number">2607</span>, <span class="hljs-number">2026</span>,  <span class="hljs-number">2878</span>,  <span class="hljs-number">2166</span>,  <span class="hljs-number">1012</span>]]
Logits: [[-<span class="hljs-number">2.7276</span>,  <span class="hljs-number">2.8789</span>]]`}}),{c(){v(e.$$.fragment)},l(t){j(e.$$.fragment,t)},m(t,o){y(e,t,o),l=!0},i(t){l||(k(e.$$.fragment,t),l=!0)},o(t){b(e.$$.fragment,t),l=!1},d(t){w(e,t)}}}function dc($){let e,l,t,o,s,_,z,T;return{c(){e=h("p"),l=m("\u270F\uFE0F "),t=h("strong"),o=m("Th\u1EED nghi\u1EC7m th\xF4i!"),s=m(" Chuy\u1EC3n \u0111\u1ED5i danh s\xE1ch "),_=h("code"),z=m("batch_ids"),T=m(" n\xE0y th\xE0nh m\u1ED9t tensor v\xE0 chuy\u1EC3n n\xF3 qua m\xF4 h\xECnh c\u1EE7a b\u1EA1n. Ki\u1EC3m tra \u0111\u1EC3 \u0111\u1EA3m b\u1EA3o r\u1EB1ng b\u1EA1n c\xF3 \u0111\u01B0\u1EE3c logit gi\u1ED1ng nh\u01B0 tr\u01B0\u1EDBc \u0111\xE2y (nh\u01B0ng hai l\u1EA7n)!")},l(J){e=p(J,"P",{});var A=u(e);l=f(A,"\u270F\uFE0F "),t=p(A,"STRONG",{});var Bn=u(t);o=f(Bn,"Th\u1EED nghi\u1EC7m th\xF4i!"),Bn.forEach(a),s=f(A," Chuy\u1EC3n \u0111\u1ED5i danh s\xE1ch "),_=p(A,"CODE",{});var bn=u(_);z=f(bn,"batch_ids"),bn.forEach(a),T=f(A," n\xE0y th\xE0nh m\u1ED9t tensor v\xE0 chuy\u1EC3n n\xF3 qua m\xF4 h\xECnh c\u1EE7a b\u1EA1n. Ki\u1EC3m tra \u0111\u1EC3 \u0111\u1EA3m b\u1EA3o r\u1EB1ng b\u1EA1n c\xF3 \u0111\u01B0\u1EE3c logit gi\u1ED1ng nh\u01B0 tr\u01B0\u1EDBc \u0111\xE2y (nh\u01B0ng hai l\u1EA7n)!"),A.forEach(a)},m(J,A){r(J,e,A),c(e,l),c(e,t),c(t,o),c(e,s),c(e,_),c(_,z),c(e,T)},d(J){J&&a(e)}}}function _c($){let e,l,t,o;return e=new E({props:{code:`model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[200, 200, 200]]
sequence2_ids = [[200, 200]]
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

print(model(tf.constant(sequence1_ids)).logits)
print(model(tf.constant(sequence2_ids)).logits)
print(model(tf.constant(batched_ids)).logits)`,highlighted:`model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>]]
sequence2_ids = [[<span class="hljs-number">200</span>, <span class="hljs-number">200</span>]]
batched_ids = [
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>],
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, tokenizer.pad_token_id],
]

<span class="hljs-built_in">print</span>(model(tf.constant(sequence1_ids)).logits)
<span class="hljs-built_in">print</span>(model(tf.constant(sequence2_ids)).logits)
<span class="hljs-built_in">print</span>(model(tf.constant(batched_ids)).logits)`}}),t=new E({props:{code:`tf.Tensor([[ 1.5693678 -1.3894581]], shape=(1, 2), dtype=float32)
tf.Tensor([[ 0.5803005  -0.41252428]], shape=(1, 2), dtype=float32)
tf.Tensor(
[[ 1.5693681 -1.3894582]
 [ 1.3373486 -1.2163193]], shape=(2, 2), dtype=float32)`,highlighted:`tf.Tensor([[ <span class="hljs-number">1.5693678</span> -<span class="hljs-number">1.3894581</span>]], shape=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), dtype=float32)
tf.Tensor([[ <span class="hljs-number">0.5803005</span>  -<span class="hljs-number">0.41252428</span>]], shape=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), dtype=float32)
tf.Tensor(
[[ <span class="hljs-number">1.5693681</span> -<span class="hljs-number">1.3894582</span>]
 [ <span class="hljs-number">1.3373486</span> -<span class="hljs-number">1.2163193</span>]], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=float32)`}}),{c(){v(e.$$.fragment),l=g(),v(t.$$.fragment)},l(s){j(e.$$.fragment,s),l=d(s),j(t.$$.fragment,s)},m(s,_){y(e,s,_),r(s,l,_),y(t,s,_),o=!0},i(s){o||(k(e.$$.fragment,s),k(t.$$.fragment,s),o=!0)},o(s){b(e.$$.fragment,s),b(t.$$.fragment,s),o=!1},d(s){w(e,s),s&&a(l),w(t,s)}}}function bc($){let e,l,t,o;return e=new E({props:{code:`model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[200, 200, 200]]
sequence2_ids = [[200, 200]]
batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

print(model(torch.tensor(sequence1_ids)).logits)
print(model(torch.tensor(sequence2_ids)).logits)
print(model(torch.tensor(batched_ids)).logits)`,highlighted:`model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequence1_ids = [[<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>]]
sequence2_ids = [[<span class="hljs-number">200</span>, <span class="hljs-number">200</span>]]
batched_ids = [
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>],
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, tokenizer.pad_token_id],
]

<span class="hljs-built_in">print</span>(model(torch.tensor(sequence1_ids)).logits)
<span class="hljs-built_in">print</span>(model(torch.tensor(sequence2_ids)).logits)
<span class="hljs-built_in">print</span>(model(torch.tensor(batched_ids)).logits)`}}),t=new E({props:{code:`tensor([[ 1.5694, -1.3895]], grad_fn=<AddmmBackward>)
tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)
tensor([[ 1.5694, -1.3895],
        [ 1.3373, -1.2163]], grad_fn=<AddmmBackward>)`,highlighted:`tensor([[ <span class="hljs-number">1.5694</span>, -<span class="hljs-number">1.3895</span>]], grad_fn=&lt;AddmmBackward&gt;)
tensor([[ <span class="hljs-number">0.5803</span>, -<span class="hljs-number">0.4125</span>]], grad_fn=&lt;AddmmBackward&gt;)
tensor([[ <span class="hljs-number">1.5694</span>, -<span class="hljs-number">1.3895</span>],
        [ <span class="hljs-number">1.3373</span>, -<span class="hljs-number">1.2163</span>]], grad_fn=&lt;AddmmBackward&gt;)`}}),{c(){v(e.$$.fragment),l=g(),v(t.$$.fragment)},l(s){j(e.$$.fragment,s),l=d(s),j(t.$$.fragment,s)},m(s,_){y(e,s,_),r(s,l,_),y(t,s,_),o=!0},i(s){o||(k(e.$$.fragment,s),k(t.$$.fragment,s),o=!0)},o(s){b(e.$$.fragment,s),b(t.$$.fragment,s),o=!1},d(s){w(e,s),s&&a(l),w(t,s)}}}function kc($){let e,l,t,o;return e=new E({props:{code:`batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

attention_mask = [
    [1, 1, 1],
    [1, 1, 0],
]

outputs = model(tf.constant(batched_ids), attention_mask=tf.constant(attention_mask))
print(outputs.logits)`,highlighted:`batched_ids = [
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>],
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, tokenizer.pad_token_id],
]

attention_mask = [
    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],
]

outputs = model(tf.constant(batched_ids), attention_mask=tf.constant(attention_mask))
<span class="hljs-built_in">print</span>(outputs.logits)`}}),t=new E({props:{code:`tf.Tensor(
[[ 1.5693681  -1.3894582 ]
 [ 0.5803021  -0.41252586]], shape=(2, 2), dtype=float32)`,highlighted:`tf.Tensor(
[[ <span class="hljs-number">1.5693681</span>  -<span class="hljs-number">1.3894582</span> ]
 [ <span class="hljs-number">0.5803021</span>  -<span class="hljs-number">0.41252586</span>]], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=float32)`}}),{c(){v(e.$$.fragment),l=g(),v(t.$$.fragment)},l(s){j(e.$$.fragment,s),l=d(s),j(t.$$.fragment,s)},m(s,_){y(e,s,_),r(s,l,_),y(t,s,_),o=!0},i(s){o||(k(e.$$.fragment,s),k(t.$$.fragment,s),o=!0)},o(s){b(e.$$.fragment,s),b(t.$$.fragment,s),o=!1},d(s){w(e,s),s&&a(l),w(t,s)}}}function $c($){let e,l,t,o;return e=new E({props:{code:`batched_ids = [
    [200, 200, 200],
    [200, 200, tokenizer.pad_token_id],
]

attention_mask = [
    [1, 1, 1],
    [1, 1, 0],
]

outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))
print(outputs.logits)`,highlighted:`batched_ids = [
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>],
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, tokenizer.pad_token_id],
]

attention_mask = [
    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],
]

outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))
<span class="hljs-built_in">print</span>(outputs.logits)`}}),t=new E({props:{code:`tensor([[ 1.5694, -1.3895],
        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward>)`,highlighted:`tensor([[ <span class="hljs-number">1.5694</span>, -<span class="hljs-number">1.3895</span>],
        [ <span class="hljs-number">0.5803</span>, -<span class="hljs-number">0.4125</span>]], grad_fn=&lt;AddmmBackward&gt;)`}}),{c(){v(e.$$.fragment),l=g(),v(t.$$.fragment)},l(s){j(e.$$.fragment,s),l=d(s),j(t.$$.fragment,s)},m(s,_){y(e,s,_),r(s,l,_),y(t,s,_),o=!0},i(s){o||(k(e.$$.fragment,s),k(t.$$.fragment,s),o=!0)},o(s){b(e.$$.fragment,s),b(t.$$.fragment,s),o=!1},d(s){w(e,s),s&&a(l),w(t,s)}}}function vc($){let e,l,t,o,s;return{c(){e=h("p"),l=m("\u270F\uFE0F "),t=h("strong"),o=m("Th\u1EED nghi\u1EC7m th\xF4i!"),s=m(" \xC1p d\u1EE5ng th\u1EE7 c\xF4ng tokenize cho hai c\xE2u \u0111\u01B0\u1EE3c s\u1EED d\u1EE5ng trong ph\u1EA7n 2 (\u201CI\u2019ve been waiting for a HuggingFace course my whole life.\u201D v\xE0 \u201CI hate this so much!\u201D). \u0110\u01B0a ch\xFAng v\xE0o m\xF4 h\xECnh v\xE0 ki\u1EC3m tra xem b\u1EA1n c\xF3 nh\u1EADn \u0111\u01B0\u1EE3c c\xE1c logit gi\u1ED1ng nh\u01B0 trong ph\u1EA7n 2 kh\xF4ng. B\xE2y gi\u1EDD, g\u1ED9p ch\xFAng l\u1EA1i v\u1EDBi nhau b\u1EB1ng c\xE1ch s\u1EED d\u1EE5ng token \u0111\u1EC7m, sau \u0111\xF3 t\u1EA1o attention mask th\xEDch h\u1EE3p. Ki\u1EC3m tra xem b\u1EA1n c\xF3 \u0111\u1EA1t \u0111\u01B0\u1EE3c k\u1EBFt qu\u1EA3 t\u01B0\u01A1ng t\u1EF1 khi \u0111\u01B0a qua m\xF4 h\xECnh kh\xF4ng!")},l(_){e=p(_,"P",{});var z=u(e);l=f(z,"\u270F\uFE0F "),t=p(z,"STRONG",{});var T=u(t);o=f(T,"Th\u1EED nghi\u1EC7m th\xF4i!"),T.forEach(a),s=f(z," \xC1p d\u1EE5ng th\u1EE7 c\xF4ng tokenize cho hai c\xE2u \u0111\u01B0\u1EE3c s\u1EED d\u1EE5ng trong ph\u1EA7n 2 (\u201CI\u2019ve been waiting for a HuggingFace course my whole life.\u201D v\xE0 \u201CI hate this so much!\u201D). \u0110\u01B0a ch\xFAng v\xE0o m\xF4 h\xECnh v\xE0 ki\u1EC3m tra xem b\u1EA1n c\xF3 nh\u1EADn \u0111\u01B0\u1EE3c c\xE1c logit gi\u1ED1ng nh\u01B0 trong ph\u1EA7n 2 kh\xF4ng. B\xE2y gi\u1EDD, g\u1ED9p ch\xFAng l\u1EA1i v\u1EDBi nhau b\u1EB1ng c\xE1ch s\u1EED d\u1EE5ng token \u0111\u1EC7m, sau \u0111\xF3 t\u1EA1o attention mask th\xEDch h\u1EE3p. Ki\u1EC3m tra xem b\u1EA1n c\xF3 \u0111\u1EA1t \u0111\u01B0\u1EE3c k\u1EBFt qu\u1EA3 t\u01B0\u01A1ng t\u1EF1 khi \u0111\u01B0a qua m\xF4 h\xECnh kh\xF4ng!"),z.forEach(a)},m(_,z){r(_,e,z),c(e,l),c(e,t),c(t,o),c(e,s)},d(_){_&&a(e)}}}function jc($){let e,l,t,o,s,_,z,T,J,A,Bn,bn,F,S,On,P,N,Vn,Kn,Ps,Rt,I,_t,Ns,Ms,kn,Ds,bt,Ls,Hs,Bs,kt,Os,Vs,$t,Ks,Gt,Rn,Rs,Ut,Q,sn,vt,$n,Gs,jt,Us,Xt,Gn,Xs,Yt,M,D,Un,Xn,Ys,Jt,en,Js,yt,Qs,Ws,Qt,L,H,Yn,Jn,Zs,Wt,B,O,Qn,Wn,ne,Zt,V,K,Zn,W,wt,te,se,qt,ee,ae,ns,vn,ts,nt,ce,ss,an,es,cn,ie,Et,le,re,as,Z,ln,zt,jn,oe,Tt,he,cs,tt,pe,is,yn,ls,x,ue,At,me,fe,It,ge,de,xt,_e,be,rs,wn,os,rn,ke,Ct,$e,ve,hs,R,G,st,et,je,ps,on,ye,Ft,we,qe,us,nn,hn,St,qn,Ee,Pt,ze,ms,En,Nt,Te,Ae,fs,at,Ie,gs,U,X,ct,it,xe,ds,lt,Ce,_s,pn,bs,tn,un,Mt,zn,Fe,Dt,Se,ks,rt,Pe,$s,mn,Lt,Ne,Me,Ht,De,vs,Y,Le,Tn,He,Be,An,Oe,Ve,js,fn,Ke,Bt,Re,Ge,ys,In,ws;t=new ec({props:{fw:$[0]}}),T=new Kt({});const Xe=[cc,ac],xn=[];function Ye(n,i){return n[0]==="pt"?0:1}F=Ye($),S=xn[F]=Xe[F]($);const Je=[lc,ic],Cn=[];function Qe(n,i){return n[0]==="pt"?0:1}P=Qe($),N=Cn[P]=Je[P]($),$n=new Kt({});const We=[oc,rc],Fn=[];function Ze(n,i){return n[0]==="pt"?0:1}M=Ze($),D=Fn[M]=We[M]($);const na=[pc,hc],Sn=[];function ta(n,i){return n[0]==="pt"?0:1}L=ta($),H=Sn[L]=na[L]($);const sa=[mc,uc],Pn=[];function ea(n,i){return n[0]==="pt"?0:1}B=ea($),O=Pn[B]=sa[B]($);const aa=[gc,fc],Nn=[];function ca(n,i){return n[0]==="pt"?0:1}V=ca($),K=Nn[V]=aa[V]($),vn=new E({props:{code:"batched_ids = [ids, ids]",highlighted:'<span class="hljs-attr">batched_ids</span> = [ids, ids]'}}),an=new Ya({props:{$$slots:{default:[dc]},$$scope:{ctx:$}}}),jn=new Kt({}),yn=new E({props:{code:`batched_ids = [
    [200, 200, 200],
    [200, 200]
]`,highlighted:`batched_ids = [
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>],
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>]
]`}}),wn=new E({props:{code:`padding_id = 100

batched_ids = [
    [200, 200, 200],
    [200, 200, padding_id],
]`,highlighted:`padding_id = <span class="hljs-number">100</span>

batched_ids = [
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, <span class="hljs-number">200</span>],
    [<span class="hljs-number">200</span>, <span class="hljs-number">200</span>, padding_id],
]`}});const ia=[bc,_c],Mn=[];function la(n,i){return n[0]==="pt"?0:1}R=la($),G=Mn[R]=ia[R]($),qn=new Kt({});const ra=[$c,kc],Dn=[];function oa(n,i){return n[0]==="pt"?0:1}return U=oa($),X=Dn[U]=ra[U]($),pn=new Ya({props:{$$slots:{default:[vc]},$$scope:{ctx:$}}}),zn=new Kt({}),In=new E({props:{code:"sequence = sequence[:max_sequence_length]",highlighted:"sequence = sequence[:max_sequence_length]"}}),{c(){e=h("meta"),l=g(),v(t.$$.fragment),o=g(),s=h("h1"),_=h("a"),z=h("span"),v(T.$$.fragment),J=g(),A=h("span"),Bn=m("X\u1EED l\xFD \u0111a chu\u1ED7i"),bn=g(),S.c(),On=g(),N.c(),Vn=g(),Kn=h("p"),Ps=m("Trong ph\u1EA7n tr\u01B0\u1EDBc, ch\xFAng ta \u0111\xE3 kh\xE1m ph\xE1 c\xE1c tr\u01B0\u1EDDng h\u1EE3p s\u1EED d\u1EE5ng \u0111\u01A1n gi\u1EA3n nh\u1EA5t: th\u1EF1c hi\u1EC7n lu\u1EADn suy tr\xEAn m\u1ED9t d\xE3y \u0111\u01A1n c\xF3 \u0111\u1ED9 d\xE0i nh\u1ECF. Tuy nhi\xEAn, m\u1ED9t s\u1ED1 c\xE2u h\u1ECFi \u0111\u01B0\u1EE3c \u0111\u1EC1 c\u1EADp nh\u01B0:"),Rt=g(),I=h("ul"),_t=h("li"),Ns=m("L\xE0m th\u1EBF n\xE0o \u0111\u1EC3 ch\xFAng ta x\u1EED l\xFD nhi\u1EC1u chu\u1ED7i?"),Ms=g(),kn=h("li"),Ds=m("L\xE0m th\u1EBF n\xE0o \u0111\u1EC3 ch\xFAng ta x\u1EED l\xFD nhi\u1EC1u chu\u1ED7i "),bt=h("em"),Ls=m("c\xF3 \u0111\u1ED9 d\xE0i kh\xE1c nhau"),Hs=m("?"),Bs=g(),kt=h("li"),Os=m("C\xE1c ch\u1EC9 s\u1ED1 t\u1EEB v\u1EF1ng c\xF3 ph\u1EA3i l\xE0 \u0111\u1EA7u v\xE0o duy nh\u1EA5t cho ph\xE9p m\u1ED9t m\xF4 h\xECnh ho\u1EA1t \u0111\u1ED9ng t\u1ED1t kh\xF4ng?"),Vs=g(),$t=h("li"),Ks=m("N\u1EBFu nh\u01B0 m\u1ED9t chu\u1ED7i qu\xE1 d\xE0i th\xEC sao?"),Gt=g(),Rn=h("p"),Rs=m("H\xE3y xem nh\u1EEFng c\xE2u h\u1ECFi n\xE0y \u0111\u1EB7t ra nh\u1EEFng lo\u1EA1i v\u1EA5n \u0111\u1EC1 n\xE0o v\xE0 c\xE1ch ch\xFAng t\xF4i c\xF3 th\u1EC3 gi\u1EA3i quy\u1EBFt ch\xFAng b\u1EB1ng c\xE1ch s\u1EED d\u1EE5ng API \u{1F917} Transformers."),Ut=g(),Q=h("h2"),sn=h("a"),vt=h("span"),v($n.$$.fragment),Gs=g(),jt=h("span"),Us=m("M\xF4 h\xECnh k\xEC v\u1ECDng m\u1ED9t l\xF4 c\xE1c \u0111\u1EA7u v\xE0o"),Xt=g(),Gn=h("p"),Xs=m("Trong b\xE0i t\u1EADp tr\u01B0\u1EDBc, b\u1EA1n \u0111\xE3 th\u1EA5y c\xE1ch c\xE1c chu\u1ED7i \u0111\u01B0\u1EE3c chuy\u1EC3n th\xE0nh danh s\xE1ch c\xE1c s\u1ED1. H\xE3y chuy\u1EC3n \u0111\u1ED5i danh s\xE1ch c\xE1c s\u1ED1 n\xE0y th\xE0nh m\u1ED9t tensor v\xE0 g\u1EEDi n\xF3 \u0111\u1EBFn m\xF4 h\xECnh:"),Yt=g(),D.c(),Un=g(),Xn=h("p"),Ys=m("\xD4i kh\xF4ng! T\u1EA1i sao \u0111o\u1EA1n m\xE3 l\u1EA1i kh\xF4ng th\xE0nh c\xF4ng? Ch\xFAng ta \u0111\xE3 l\xE0m theo c\xE1c b\u01B0\u1EDBc t\u1EEB pipeline trong ph\u1EA7n 2."),Jt=g(),en=h("p"),Js=m("V\u1EA5n \u0111\u1EC1 \u1EDF \u0111\xE2y \u0111\xF3 l\xE0 ch\xFAng ta \u0111\xE3 g\u1EEDi m\u1ED9t chu\u1ED7i \u0111\u01A1n cho m\xF4 h\xECnh, trong khi m\xF4 h\xECnh \u{1F917} Transformers mong \u0111\u1EE3i nhi\u1EC1u c\xE2u theo m\u1EB7c \u0111\u1ECBnh. \u1EDE \u0111\xE2y, ch\xFAng ta \u0111\xE3 c\u1ED1 g\u1EAFng th\u1EF1c hi\u1EC7n m\u1ECDi th\u1EE9 m\xE0 tokenizer \u0111\xE3 l\xE0m \u1EDF ph\xEDa sau khi \xE1p d\u1EE5ng n\xF3 v\xE0o m\u1ED9t "),yt=h("code"),Qs=m("chu\u1ED7i"),Ws=m(", nh\u01B0ng n\u1EBFu b\u1EA1n nh\xECn k\u1EF9, b\u1EA1n s\u1EBD th\u1EA5y r\u1EB1ng n\xF3 kh\xF4ng ch\u1EC9 chuy\u1EC3n \u0111\u1ED5i danh s\xE1ch ID \u0111\u1EA7u v\xE0o th\xE0nh m\u1ED9t tensor, n\xF3  c\xF2n th\xEAm m\u1ED9t chi\u1EC1u l\xEAn tr\xEAn:"),Qt=g(),H.c(),Yn=g(),Jn=h("p"),Zs=m("H\xE3y c\u0169ng th\u1EED l\u1EA1i v\xE0 th\xEAm m\u1ED9t chi\u1EC1u m\u1EDBi:"),Wt=g(),O.c(),Qn=g(),Wn=h("p"),ne=m("Ta in ra c\xE1c ID \u0111\u1EA7u v\xE0o c\u0169ng nh\u01B0 k\u1EBFt qu\u1EA3 logit nh\u01B0 sau:"),Zt=g(),K.c(),Zn=g(),W=h("p"),wt=h("em"),te=m("Batching"),se=m(" hay "),qt=h("em"),ee=m("L\xF4"),ae=m(" l\xE0 h\xE0nh \u0111\u1ED9ng g\u1EEDi nhi\u1EC1u c\xE2u qua m\xF4 h\xECnh, t\u1EA5t c\u1EA3 c\xF9ng m\u1ED9t l\xFAc. N\u1EBFu b\u1EA1n ch\u1EC9 c\xF3 m\u1ED9t c\xE2u, b\u1EA1n ch\u1EC9 c\xF3 th\u1EC3 x\xE2y d\u1EF1ng m\u1ED9t l\xF4 v\u1EDBi m\u1ED9t chu\u1ED7i duy nh\u1EA5t:"),ns=g(),v(vn.$$.fragment),ts=g(),nt=h("p"),ce=m("\u0110\xE2y l\xE0 m\u1ED9t l\xF4 ch\u1EE9a hai chu\u1ED7i gi\u1ED1ng nhau!"),ss=g(),v(an.$$.fragment),es=g(),cn=h("p"),ie=m("Vi\u1EC7c ph\xE2n ph\u1ED1i l\xF4 cho ph\xE9p m\xF4 h\xECnh ho\u1EA1t \u0111\u1ED9ng khi b\u1EA1n \u0111\u01B0a v\xE0o nhi\u1EC1u c\xE2u. Vi\u1EC7c s\u1EED d\u1EE5ng nhi\u1EC1u chu\u1ED7i c\u0169ng \u0111\u01A1n gi\u1EA3n nh\u01B0 x\xE2y d\u1EF1ng m\u1ED9t l\xF4 v\u1EDBi m\u1ED9t chu\u1ED7i duy nh\u1EA5t. Tuy nhi\xEAn, c\xF3 m\u1ED9t v\u1EA5n \u0111\u1EC1 th\u1EE9 hai. Khi b\u1EA1n c\u1ED1 g\u1EAFng gh\xE9p hai (ho\u1EB7c nhi\u1EC1u) c\xE2u l\u1EA1i v\u1EDBi nhau, ch\xFAng c\xF3 th\u1EC3 c\xF3 \u0111\u1ED9 d\xE0i kh\xE1c nhau. N\u1EBFu b\u1EA1n \u0111\xE3 t\u1EEBng l\xE0m vi\u1EC7c v\u1EDBi tensor tr\u01B0\u1EDBc \u0111\xE2y, b\u1EA1n bi\u1EBFt r\u1EB1ng ch\xFAng c\u1EA7n c\xF3 d\u1EA1ng h\xECnh ch\u1EEF nh\u1EADt, v\xEC v\u1EADy b\u1EA1n s\u1EBD kh\xF4ng th\u1EC3 chuy\u1EC3n \u0111\u1ED5i tr\u1EF1c ti\u1EBFp danh s\xE1ch ID \u0111\u1EA7u v\xE0o th\xE0nh tensor. \u0110\u1EC3 gi\u1EA3i quy\u1EBFt v\u1EA5n \u0111\u1EC1 n\xE0y, ch\xFAng t\xF4i th\u01B0\u1EDDng "),Et=h("em"),le=m("\u0111\u1EC7m"),re=m(" c\xE1c \u0111\u1EA7u v\xE0o."),as=g(),Z=h("h2"),ln=h("a"),zt=h("span"),v(jn.$$.fragment),oe=g(),Tt=h("span"),he=m("\u0110\xEAm th\xEAm v\xE0o \u0111\u1EA7u v\xE0o"),cs=g(),tt=h("p"),pe=m("Danh s\xE1ch c\xE1c danh s\xE1ch d\u01B0\u1EDBi \u0111\xE2y kh\xF4ng th\u1EC3 chuy\u1EC3n \u0111\u1ED5i th\xE0nh m\u1ED9t tensor:"),is=g(),v(yn.$$.fragment),ls=g(),x=h("p"),ue=m("\u0110\u1EC3 gi\u1EA3i quy\u1EBFt v\u1EA5n \u0111\u1EC1 n\xE0y, ch\xFAng ta s\u1EBD s\u1EED d\u1EE5ng "),At=h("em"),me=m("\u0111\u1EC7m"),fe=m(" \u0111\u1EC3 l\xE0m cho c\xE1c tensor c\u1EE7a ch\xFAng ta c\xF3 h\xECnh ch\u1EEF nh\u1EADt. \u0110\u1EC7m \u0111\u1EA3m b\u1EA3o t\u1EA5t c\u1EA3 c\xE1c c\xE2u c\u1EE7a ch\xFAng ta c\xF3 c\xF9ng \u0111\u1ED9 d\xE0i b\u1EB1ng c\xE1ch th\xEAm m\u1ED9t t\u1EEB \u0111\u1EB7c bi\u1EC7t \u0111\u01B0\u1EE3c g\u1ECDi l\xE0 "),It=h("em"),ge=m("padding token"),de=m(" hay "),xt=h("em"),_e=m("token \u0111\u01B0\u1EE3c \u0111\u1EC7m th\xEAm"),be=m(" v\xE0o c\xE1c c\xE2u c\xF3 \xEDt gi\xE1 tr\u1ECB h\u01A1n. V\xED d\u1EE5: n\u1EBFu b\u1EA1n c\xF3 10 c\xE2u 10 t\u1EEB v\xE0 1 c\xE2u 20 t\u1EEB, ph\u1EA7n \u0111\u1EC7m s\u1EBD \u0111\u1EA3m b\u1EA3o t\u1EA5t c\u1EA3 c\xE1c c\xE2u c\xF3 20 t\u1EEB. Trong v\xED d\u1EE5 c\u1EE7a ch\xFAng t\xF4i, tensor k\u1EBFt qu\u1EA3 tr\xF4ng gi\u1ED1ng nh\u01B0 sau:"),rs=g(),v(wn.$$.fragment),os=g(),rn=h("p"),ke=m("ID c\u1EE7a token \u0111\u1EC7m c\xF3 th\u1EC3 t\xECm th\u1EA5y \u1EDF "),Ct=h("code"),$e=m("tokenizer.pad_token_id"),ve=m(". H\xE3y s\u1EED d\u1EE5ng n\xF3 v\xE0 g\u1EEDi hai c\xE2u c\u1EE7a ch\xFAng ta th\xF4ng qua m\xF4 h\xECnh ri\xEAng l\u1EBB v\xE0 theo l\xF4 v\u1EDBi nhau:"),hs=g(),G.c(),st=g(),et=h("p"),je=m("C\xF3 \u0111i\u1EC1u g\xEC \u0111\xF3 kh\xF4ng \u1ED5n v\u1EDBi c\xE1c logit trong c\xE1c d\u1EF1 \u0111o\xE1n theo l\xF4 c\u1EE7a ch\xFAng ta: h\xE0ng th\u1EE9 hai ph\u1EA3i gi\u1ED1ng v\u1EDBi logit cho c\xE2u th\u1EE9 hai, nh\u01B0ng ch\xFAng ta c\xF3 c\xE1c gi\xE1 tr\u1ECB ho\xE0n to\xE0n kh\xE1c nhau!"),ps=g(),on=h("p"),ye=m("\u0110i\u1EC1u n\xE0y l\xE0 do t\xEDnh n\u0103ng ch\xEDnh c\u1EE7a c\xE1c m\xF4 h\xECnh Transformer l\xE0 c\xE1c l\u1EDBp attention \u0111\xE3 "),Ft=h("em"),we=m("ng\u1EEF c\u1EA3nh h\xF3a"),qe=m(" m\u1ED7i token. Ch\xFAng s\u1EBD t\xEDnh \u0111\u1EBFn c\xE1c padding token v\xEC ch\xFAng tham gia v\xE0o t\u1EA5t c\u1EA3 c\xE1c token c\u1EE7a m\u1ED9t chu\u1ED7i. \u0110\u1EC3 c\xF3 \u0111\u01B0\u1EE3c k\u1EBFt qu\u1EA3 t\u01B0\u01A1ng t\u1EF1 khi chuy\u1EC3n c\xE1c c\xE2u ri\xEAng l\u1EBB c\xF3 \u0111\u1ED9 d\xE0i kh\xE1c nhau qua m\xF4 h\xECnh ho\u1EB7c khi chuy\u1EC3n m\u1ED9t l\xF4 v\u1EDBi c\xE1c c\xE2u v\xE0 ph\u1EA7n \u0111\u1EC7m gi\u1ED1ng nhau \u0111\u01B0\u1EE3c \xE1p d\u1EE5ng, ch\xFAng ta c\u1EA7n y\xEAu c\u1EA7u c\xE1c l\u1EDBp attention \u0111\xF3 b\u1ECF qua c\xE1c th\u1EBB \u0111\u1EC7m. \u0110i\u1EC1u n\xE0y \u0111\u01B0\u1EE3c th\u1EF1c hi\u1EC7n b\u1EB1ng c\xE1ch s\u1EED d\u1EE5ng attention mask."),us=g(),nn=h("h2"),hn=h("a"),St=h("span"),v(qn.$$.fragment),Ee=g(),Pt=h("span"),ze=m("Attention masks"),ms=g(),En=h("p"),Nt=h("em"),Te=m("Attention masks"),Ae=m(" l\xE0 c\xE1c tensor c\xF3 h\xECnh d\u1EA1ng ch\xEDnh x\xE1c nh\u01B0 tensor ID \u0111\u1EA7u v\xE0o, \u0111\u01B0\u1EE3c l\u1EA5p \u0111\u1EA7y b\u1EDFi 0 v\xE0 1: 1 cho bi\u1EBFt c\xE1c tokenn t\u01B0\u01A1ng \u1EE9ng n\xEAn \u0111\u01B0\u1EE3c tham gia v\xE0 c\xE1c s\u1ED1 0 cho bi\u1EBFt c\xE1c token t\u01B0\u01A1ng \u1EE9ng kh\xF4ng \u0111\u01B0\u1EE3c tham gia (t\u1EE9c l\xE0 ch\xFAng ph\u1EA3i b\u1ECB b\u1ECF qua b\u1EDFi c\xE1c l\u1EDBp attention c\u1EE7a m\xF4 h\xECnh)."),fs=g(),at=h("p"),Ie=m("H\xE3y ho\xE0n th\xE0nh v\xED d\u1EE5 tr\u01B0\u1EDBc v\u1EDBi m\u1ED9t attention mask:"),gs=g(),X.c(),ct=g(),it=h("p"),xe=m("B\xE2y gi\u1EDD ch\xFAng ta nh\u1EADn \u0111\u01B0\u1EE3c c\xE1c logit t\u01B0\u01A1ng t\u1EF1 cho c\xE2u th\u1EE9 hai trong l\xF4."),ds=g(),lt=h("p"),Ce=m("L\u01B0u \xFD c\xE1ch gi\xE1 tr\u1ECB cu\u1ED1i c\xF9ng c\u1EE7a chu\u1ED7i th\u1EE9 hai l\xE0 ID \u0111\u1EC7m, l\xE0 gi\xE1 tr\u1ECB 0 trong attention mask."),_s=g(),v(pn.$$.fragment),bs=g(),tn=h("h2"),un=h("a"),Mt=h("span"),v(zn.$$.fragment),Fe=g(),Dt=h("span"),Se=m("Nh\u1EEFng chu\u1ED7i d\xE0i h\u01A1n"),ks=g(),rt=h("p"),Pe=m("V\u1EDBi c\xE1c m\xF4 h\xECnh Transformer, c\xF3 m\u1ED9t gi\u1EDBi h\u1EA1n v\u1EC1 \u0111\u1ED9 d\xE0i c\u1EE7a c\xE1c chu\u1ED7i m\xE0 ch\xFAng t\xF4i c\xF3 th\u1EC3 v\u01B0\u1EE3t qua c\xE1c m\xF4 h\xECnh. H\u1EA7u h\u1EBFt c\xE1c m\xF4 h\xECnh x\u1EED l\xFD chu\u1ED7i l\xEAn \u0111\u1EBFn 512 ho\u1EB7c 1024 token v\xE0 s\u1EBD b\u1ECB l\u1ED7i khi \u0111\u01B0\u1EE3c y\xEAu c\u1EA7u x\u1EED l\xFD chu\u1ED7i d\xE0i h\u01A1n. C\xF3 hai gi\u1EA3i ph\xE1p cho v\u1EA5n \u0111\u1EC1 n\xE0y:"),$s=g(),mn=h("ul"),Lt=h("li"),Ne=m("S\u1EED d\u1EE5ng m\xF4 h\xECnh c\xF3 \u0111\u1ED9 d\xE0i chu\u1ED7i \u0111\u01B0\u1EE3c h\u1ED7 tr\u1EE3 d\xE0i h\u01A1n."),Me=g(),Ht=h("li"),De=m("C\u1EAFt ng\u1EAFn chu\u1ED7i c\u1EE7a b\u1EA1n."),vs=g(),Y=h("p"),Le=m("C\xE1c m\xF4 h\xECnh c\xF3 \u0111\u1ED9 d\xE0i chu\u1ED7i \u0111\u01B0\u1EE3c h\u1ED7 tr\u1EE3 kh\xE1c nhau v\xE0 m\u1ED9t s\u1ED1 m\xF4 h\xECnh chuy\xEAn x\u1EED l\xFD c\xE1c tr\xECnh t\u1EF1 r\u1EA5t d\xE0i. "),Tn=h("a"),He=m("Longformer"),Be=m(" l\xE0 m\u1ED9t v\xED d\u1EE5 v\xE0 m\u1ED9t v\xED d\u1EE5 kh\xE1c l\xE0 "),An=h("a"),Oe=m("LED"),Ve=m(". N\u1EBFu b\u1EA1n \u0111ang th\u1EF1c hi\u1EC7n m\u1ED9t c\xF4ng vi\u1EC7c \u0111\xF2i h\u1ECFi tr\xECnh t\u1EF1 r\u1EA5t d\xE0i, ch\xFAng t\xF4i khuy\xEAn b\u1EA1n n\xEAn xem c\xE1c m\xF4 h\xECnh \u0111\xF3."),js=g(),fn=h("p"),Ke=m("N\u1EBFu kh\xF4ng, ch\xFAng t\xF4i khuy\xEAn b\u1EA1n n\xEAn c\u1EAFt b\u1EDBt c\xE1c chu\u1ED7i c\u1EE7a m\xECnh b\u1EB1ng c\xE1ch ch\u1EC9 \u0111\u1ECBnh tham s\u1ED1 "),Bt=h("code"),Re=m("max_sequence_length"),Ge=m(":"),ys=g(),v(In.$$.fragment),this.h()},l(n){const i=tc('[data-svelte="svelte-1phssyn"]',document.head);e=p(i,"META",{name:!0,content:!0}),i.forEach(a),l=d(n),j(t.$$.fragment,n),o=d(n),s=p(n,"H1",{class:!0});var Ln=u(s);_=p(Ln,"A",{id:!0,class:!0,href:!0});var ot=u(_);z=p(ot,"SPAN",{});var ht=u(z);j(T.$$.fragment,ht),ht.forEach(a),ot.forEach(a),J=d(Ln),A=p(Ln,"SPAN",{});var pt=u(A);Bn=f(pt,"X\u1EED l\xFD \u0111a chu\u1ED7i"),pt.forEach(a),Ln.forEach(a),bn=d(n),S.l(n),On=d(n),N.l(n),Vn=d(n),Kn=p(n,"P",{});var ut=u(Kn);Ps=f(ut,"Trong ph\u1EA7n tr\u01B0\u1EDBc, ch\xFAng ta \u0111\xE3 kh\xE1m ph\xE1 c\xE1c tr\u01B0\u1EDDng h\u1EE3p s\u1EED d\u1EE5ng \u0111\u01A1n gi\u1EA3n nh\u1EA5t: th\u1EF1c hi\u1EC7n lu\u1EADn suy tr\xEAn m\u1ED9t d\xE3y \u0111\u01A1n c\xF3 \u0111\u1ED9 d\xE0i nh\u1ECF. Tuy nhi\xEAn, m\u1ED9t s\u1ED1 c\xE2u h\u1ECFi \u0111\u01B0\u1EE3c \u0111\u1EC1 c\u1EADp nh\u01B0:"),ut.forEach(a),Rt=d(n),I=p(n,"UL",{});var C=u(I);_t=p(C,"LI",{});var mt=u(_t);Ns=f(mt,"L\xE0m th\u1EBF n\xE0o \u0111\u1EC3 ch\xFAng ta x\u1EED l\xFD nhi\u1EC1u chu\u1ED7i?"),mt.forEach(a),Ms=d(C),kn=p(C,"LI",{});var Hn=u(kn);Ds=f(Hn,"L\xE0m th\u1EBF n\xE0o \u0111\u1EC3 ch\xFAng ta x\u1EED l\xFD nhi\u1EC1u chu\u1ED7i "),bt=p(Hn,"EM",{});var ft=u(bt);Ls=f(ft,"c\xF3 \u0111\u1ED9 d\xE0i kh\xE1c nhau"),ft.forEach(a),Hs=f(Hn,"?"),Hn.forEach(a),Bs=d(C),kt=p(C,"LI",{});var gt=u(kt);Os=f(gt,"C\xE1c ch\u1EC9 s\u1ED1 t\u1EEB v\u1EF1ng c\xF3 ph\u1EA3i l\xE0 \u0111\u1EA7u v\xE0o duy nh\u1EA5t cho ph\xE9p m\u1ED9t m\xF4 h\xECnh ho\u1EA1t \u0111\u1ED9ng t\u1ED1t kh\xF4ng?"),gt.forEach(a),Vs=d(C),$t=p(C,"LI",{});var Ot=u($t);Ks=f(Ot,"N\u1EBFu nh\u01B0 m\u1ED9t chu\u1ED7i qu\xE1 d\xE0i th\xEC sao?"),Ot.forEach(a),C.forEach(a),Gt=d(n),Rn=p(n,"P",{});var ha=u(Rn);Rs=f(ha,"H\xE3y xem nh\u1EEFng c\xE2u h\u1ECFi n\xE0y \u0111\u1EB7t ra nh\u1EEFng lo\u1EA1i v\u1EA5n \u0111\u1EC1 n\xE0o v\xE0 c\xE1ch ch\xFAng t\xF4i c\xF3 th\u1EC3 gi\u1EA3i quy\u1EBFt ch\xFAng b\u1EB1ng c\xE1ch s\u1EED d\u1EE5ng API \u{1F917} Transformers."),ha.forEach(a),Ut=d(n),Q=p(n,"H2",{class:!0});var qs=u(Q);sn=p(qs,"A",{id:!0,class:!0,href:!0});var pa=u(sn);vt=p(pa,"SPAN",{});var ua=u(vt);j($n.$$.fragment,ua),ua.forEach(a),pa.forEach(a),Gs=d(qs),jt=p(qs,"SPAN",{});var ma=u(jt);Us=f(ma,"M\xF4 h\xECnh k\xEC v\u1ECDng m\u1ED9t l\xF4 c\xE1c \u0111\u1EA7u v\xE0o"),ma.forEach(a),qs.forEach(a),Xt=d(n),Gn=p(n,"P",{});var fa=u(Gn);Xs=f(fa,"Trong b\xE0i t\u1EADp tr\u01B0\u1EDBc, b\u1EA1n \u0111\xE3 th\u1EA5y c\xE1ch c\xE1c chu\u1ED7i \u0111\u01B0\u1EE3c chuy\u1EC3n th\xE0nh danh s\xE1ch c\xE1c s\u1ED1. H\xE3y chuy\u1EC3n \u0111\u1ED5i danh s\xE1ch c\xE1c s\u1ED1 n\xE0y th\xE0nh m\u1ED9t tensor v\xE0 g\u1EEDi n\xF3 \u0111\u1EBFn m\xF4 h\xECnh:"),fa.forEach(a),Yt=d(n),D.l(n),Un=d(n),Xn=p(n,"P",{});var ga=u(Xn);Ys=f(ga,"\xD4i kh\xF4ng! T\u1EA1i sao \u0111o\u1EA1n m\xE3 l\u1EA1i kh\xF4ng th\xE0nh c\xF4ng? Ch\xFAng ta \u0111\xE3 l\xE0m theo c\xE1c b\u01B0\u1EDBc t\u1EEB pipeline trong ph\u1EA7n 2."),ga.forEach(a),Jt=d(n),en=p(n,"P",{});var Es=u(en);Js=f(Es,"V\u1EA5n \u0111\u1EC1 \u1EDF \u0111\xE2y \u0111\xF3 l\xE0 ch\xFAng ta \u0111\xE3 g\u1EEDi m\u1ED9t chu\u1ED7i \u0111\u01A1n cho m\xF4 h\xECnh, trong khi m\xF4 h\xECnh \u{1F917} Transformers mong \u0111\u1EE3i nhi\u1EC1u c\xE2u theo m\u1EB7c \u0111\u1ECBnh. \u1EDE \u0111\xE2y, ch\xFAng ta \u0111\xE3 c\u1ED1 g\u1EAFng th\u1EF1c hi\u1EC7n m\u1ECDi th\u1EE9 m\xE0 tokenizer \u0111\xE3 l\xE0m \u1EDF ph\xEDa sau khi \xE1p d\u1EE5ng n\xF3 v\xE0o m\u1ED9t "),yt=p(Es,"CODE",{});var da=u(yt);Qs=f(da,"chu\u1ED7i"),da.forEach(a),Ws=f(Es,", nh\u01B0ng n\u1EBFu b\u1EA1n nh\xECn k\u1EF9, b\u1EA1n s\u1EBD th\u1EA5y r\u1EB1ng n\xF3 kh\xF4ng ch\u1EC9 chuy\u1EC3n \u0111\u1ED5i danh s\xE1ch ID \u0111\u1EA7u v\xE0o th\xE0nh m\u1ED9t tensor, n\xF3  c\xF2n th\xEAm m\u1ED9t chi\u1EC1u l\xEAn tr\xEAn:"),Es.forEach(a),Qt=d(n),H.l(n),Yn=d(n),Jn=p(n,"P",{});var _a=u(Jn);Zs=f(_a,"H\xE3y c\u0169ng th\u1EED l\u1EA1i v\xE0 th\xEAm m\u1ED9t chi\u1EC1u m\u1EDBi:"),_a.forEach(a),Wt=d(n),O.l(n),Qn=d(n),Wn=p(n,"P",{});var ba=u(Wn);ne=f(ba,"Ta in ra c\xE1c ID \u0111\u1EA7u v\xE0o c\u0169ng nh\u01B0 k\u1EBFt qu\u1EA3 logit nh\u01B0 sau:"),ba.forEach(a),Zt=d(n),K.l(n),Zn=d(n),W=p(n,"P",{});var Vt=u(W);wt=p(Vt,"EM",{});var ka=u(wt);te=f(ka,"Batching"),ka.forEach(a),se=f(Vt," hay "),qt=p(Vt,"EM",{});var $a=u(qt);ee=f($a,"L\xF4"),$a.forEach(a),ae=f(Vt," l\xE0 h\xE0nh \u0111\u1ED9ng g\u1EEDi nhi\u1EC1u c\xE2u qua m\xF4 h\xECnh, t\u1EA5t c\u1EA3 c\xF9ng m\u1ED9t l\xFAc. N\u1EBFu b\u1EA1n ch\u1EC9 c\xF3 m\u1ED9t c\xE2u, b\u1EA1n ch\u1EC9 c\xF3 th\u1EC3 x\xE2y d\u1EF1ng m\u1ED9t l\xF4 v\u1EDBi m\u1ED9t chu\u1ED7i duy nh\u1EA5t:"),Vt.forEach(a),ns=d(n),j(vn.$$.fragment,n),ts=d(n),nt=p(n,"P",{});var va=u(nt);ce=f(va,"\u0110\xE2y l\xE0 m\u1ED9t l\xF4 ch\u1EE9a hai chu\u1ED7i gi\u1ED1ng nhau!"),va.forEach(a),ss=d(n),j(an.$$.fragment,n),es=d(n),cn=p(n,"P",{});var zs=u(cn);ie=f(zs,"Vi\u1EC7c ph\xE2n ph\u1ED1i l\xF4 cho ph\xE9p m\xF4 h\xECnh ho\u1EA1t \u0111\u1ED9ng khi b\u1EA1n \u0111\u01B0a v\xE0o nhi\u1EC1u c\xE2u. Vi\u1EC7c s\u1EED d\u1EE5ng nhi\u1EC1u chu\u1ED7i c\u0169ng \u0111\u01A1n gi\u1EA3n nh\u01B0 x\xE2y d\u1EF1ng m\u1ED9t l\xF4 v\u1EDBi m\u1ED9t chu\u1ED7i duy nh\u1EA5t. Tuy nhi\xEAn, c\xF3 m\u1ED9t v\u1EA5n \u0111\u1EC1 th\u1EE9 hai. Khi b\u1EA1n c\u1ED1 g\u1EAFng gh\xE9p hai (ho\u1EB7c nhi\u1EC1u) c\xE2u l\u1EA1i v\u1EDBi nhau, ch\xFAng c\xF3 th\u1EC3 c\xF3 \u0111\u1ED9 d\xE0i kh\xE1c nhau. N\u1EBFu b\u1EA1n \u0111\xE3 t\u1EEBng l\xE0m vi\u1EC7c v\u1EDBi tensor tr\u01B0\u1EDBc \u0111\xE2y, b\u1EA1n bi\u1EBFt r\u1EB1ng ch\xFAng c\u1EA7n c\xF3 d\u1EA1ng h\xECnh ch\u1EEF nh\u1EADt, v\xEC v\u1EADy b\u1EA1n s\u1EBD kh\xF4ng th\u1EC3 chuy\u1EC3n \u0111\u1ED5i tr\u1EF1c ti\u1EBFp danh s\xE1ch ID \u0111\u1EA7u v\xE0o th\xE0nh tensor. \u0110\u1EC3 gi\u1EA3i quy\u1EBFt v\u1EA5n \u0111\u1EC1 n\xE0y, ch\xFAng t\xF4i th\u01B0\u1EDDng "),Et=p(zs,"EM",{});var ja=u(Et);le=f(ja,"\u0111\u1EC7m"),ja.forEach(a),re=f(zs," c\xE1c \u0111\u1EA7u v\xE0o."),zs.forEach(a),as=d(n),Z=p(n,"H2",{class:!0});var Ts=u(Z);ln=p(Ts,"A",{id:!0,class:!0,href:!0});var ya=u(ln);zt=p(ya,"SPAN",{});var wa=u(zt);j(jn.$$.fragment,wa),wa.forEach(a),ya.forEach(a),oe=d(Ts),Tt=p(Ts,"SPAN",{});var qa=u(Tt);he=f(qa,"\u0110\xEAm th\xEAm v\xE0o \u0111\u1EA7u v\xE0o"),qa.forEach(a),Ts.forEach(a),cs=d(n),tt=p(n,"P",{});var Ea=u(tt);pe=f(Ea,"Danh s\xE1ch c\xE1c danh s\xE1ch d\u01B0\u1EDBi \u0111\xE2y kh\xF4ng th\u1EC3 chuy\u1EC3n \u0111\u1ED5i th\xE0nh m\u1ED9t tensor:"),Ea.forEach(a),is=d(n),j(yn.$$.fragment,n),ls=d(n),x=p(n,"P",{});var gn=u(x);ue=f(gn,"\u0110\u1EC3 gi\u1EA3i quy\u1EBFt v\u1EA5n \u0111\u1EC1 n\xE0y, ch\xFAng ta s\u1EBD s\u1EED d\u1EE5ng "),At=p(gn,"EM",{});var za=u(At);me=f(za,"\u0111\u1EC7m"),za.forEach(a),fe=f(gn," \u0111\u1EC3 l\xE0m cho c\xE1c tensor c\u1EE7a ch\xFAng ta c\xF3 h\xECnh ch\u1EEF nh\u1EADt. \u0110\u1EC7m \u0111\u1EA3m b\u1EA3o t\u1EA5t c\u1EA3 c\xE1c c\xE2u c\u1EE7a ch\xFAng ta c\xF3 c\xF9ng \u0111\u1ED9 d\xE0i b\u1EB1ng c\xE1ch th\xEAm m\u1ED9t t\u1EEB \u0111\u1EB7c bi\u1EC7t \u0111\u01B0\u1EE3c g\u1ECDi l\xE0 "),It=p(gn,"EM",{});var Ta=u(It);ge=f(Ta,"padding token"),Ta.forEach(a),de=f(gn," hay "),xt=p(gn,"EM",{});var Aa=u(xt);_e=f(Aa,"token \u0111\u01B0\u1EE3c \u0111\u1EC7m th\xEAm"),Aa.forEach(a),be=f(gn," v\xE0o c\xE1c c\xE2u c\xF3 \xEDt gi\xE1 tr\u1ECB h\u01A1n. V\xED d\u1EE5: n\u1EBFu b\u1EA1n c\xF3 10 c\xE2u 10 t\u1EEB v\xE0 1 c\xE2u 20 t\u1EEB, ph\u1EA7n \u0111\u1EC7m s\u1EBD \u0111\u1EA3m b\u1EA3o t\u1EA5t c\u1EA3 c\xE1c c\xE2u c\xF3 20 t\u1EEB. Trong v\xED d\u1EE5 c\u1EE7a ch\xFAng t\xF4i, tensor k\u1EBFt qu\u1EA3 tr\xF4ng gi\u1ED1ng nh\u01B0 sau:"),gn.forEach(a),rs=d(n),j(wn.$$.fragment,n),os=d(n),rn=p(n,"P",{});var As=u(rn);ke=f(As,"ID c\u1EE7a token \u0111\u1EC7m c\xF3 th\u1EC3 t\xECm th\u1EA5y \u1EDF "),Ct=p(As,"CODE",{});var Ia=u(Ct);$e=f(Ia,"tokenizer.pad_token_id"),Ia.forEach(a),ve=f(As,". H\xE3y s\u1EED d\u1EE5ng n\xF3 v\xE0 g\u1EEDi hai c\xE2u c\u1EE7a ch\xFAng ta th\xF4ng qua m\xF4 h\xECnh ri\xEAng l\u1EBB v\xE0 theo l\xF4 v\u1EDBi nhau:"),As.forEach(a),hs=d(n),G.l(n),st=d(n),et=p(n,"P",{});var xa=u(et);je=f(xa,"C\xF3 \u0111i\u1EC1u g\xEC \u0111\xF3 kh\xF4ng \u1ED5n v\u1EDBi c\xE1c logit trong c\xE1c d\u1EF1 \u0111o\xE1n theo l\xF4 c\u1EE7a ch\xFAng ta: h\xE0ng th\u1EE9 hai ph\u1EA3i gi\u1ED1ng v\u1EDBi logit cho c\xE2u th\u1EE9 hai, nh\u01B0ng ch\xFAng ta c\xF3 c\xE1c gi\xE1 tr\u1ECB ho\xE0n to\xE0n kh\xE1c nhau!"),xa.forEach(a),ps=d(n),on=p(n,"P",{});var Is=u(on);ye=f(Is,"\u0110i\u1EC1u n\xE0y l\xE0 do t\xEDnh n\u0103ng ch\xEDnh c\u1EE7a c\xE1c m\xF4 h\xECnh Transformer l\xE0 c\xE1c l\u1EDBp attention \u0111\xE3 "),Ft=p(Is,"EM",{});var Ca=u(Ft);we=f(Ca,"ng\u1EEF c\u1EA3nh h\xF3a"),Ca.forEach(a),qe=f(Is," m\u1ED7i token. Ch\xFAng s\u1EBD t\xEDnh \u0111\u1EBFn c\xE1c padding token v\xEC ch\xFAng tham gia v\xE0o t\u1EA5t c\u1EA3 c\xE1c token c\u1EE7a m\u1ED9t chu\u1ED7i. \u0110\u1EC3 c\xF3 \u0111\u01B0\u1EE3c k\u1EBFt qu\u1EA3 t\u01B0\u01A1ng t\u1EF1 khi chuy\u1EC3n c\xE1c c\xE2u ri\xEAng l\u1EBB c\xF3 \u0111\u1ED9 d\xE0i kh\xE1c nhau qua m\xF4 h\xECnh ho\u1EB7c khi chuy\u1EC3n m\u1ED9t l\xF4 v\u1EDBi c\xE1c c\xE2u v\xE0 ph\u1EA7n \u0111\u1EC7m gi\u1ED1ng nhau \u0111\u01B0\u1EE3c \xE1p d\u1EE5ng, ch\xFAng ta c\u1EA7n y\xEAu c\u1EA7u c\xE1c l\u1EDBp attention \u0111\xF3 b\u1ECF qua c\xE1c th\u1EBB \u0111\u1EC7m. \u0110i\u1EC1u n\xE0y \u0111\u01B0\u1EE3c th\u1EF1c hi\u1EC7n b\u1EB1ng c\xE1ch s\u1EED d\u1EE5ng attention mask."),Is.forEach(a),us=d(n),nn=p(n,"H2",{class:!0});var xs=u(nn);hn=p(xs,"A",{id:!0,class:!0,href:!0});var Fa=u(hn);St=p(Fa,"SPAN",{});var Sa=u(St);j(qn.$$.fragment,Sa),Sa.forEach(a),Fa.forEach(a),Ee=d(xs),Pt=p(xs,"SPAN",{});var Pa=u(Pt);ze=f(Pa,"Attention masks"),Pa.forEach(a),xs.forEach(a),ms=d(n),En=p(n,"P",{});var Ue=u(En);Nt=p(Ue,"EM",{});var Na=u(Nt);Te=f(Na,"Attention masks"),Na.forEach(a),Ae=f(Ue," l\xE0 c\xE1c tensor c\xF3 h\xECnh d\u1EA1ng ch\xEDnh x\xE1c nh\u01B0 tensor ID \u0111\u1EA7u v\xE0o, \u0111\u01B0\u1EE3c l\u1EA5p \u0111\u1EA7y b\u1EDFi 0 v\xE0 1: 1 cho bi\u1EBFt c\xE1c tokenn t\u01B0\u01A1ng \u1EE9ng n\xEAn \u0111\u01B0\u1EE3c tham gia v\xE0 c\xE1c s\u1ED1 0 cho bi\u1EBFt c\xE1c token t\u01B0\u01A1ng \u1EE9ng kh\xF4ng \u0111\u01B0\u1EE3c tham gia (t\u1EE9c l\xE0 ch\xFAng ph\u1EA3i b\u1ECB b\u1ECF qua b\u1EDFi c\xE1c l\u1EDBp attention c\u1EE7a m\xF4 h\xECnh)."),Ue.forEach(a),fs=d(n),at=p(n,"P",{});var Ma=u(at);Ie=f(Ma,"H\xE3y ho\xE0n th\xE0nh v\xED d\u1EE5 tr\u01B0\u1EDBc v\u1EDBi m\u1ED9t attention mask:"),Ma.forEach(a),gs=d(n),X.l(n),ct=d(n),it=p(n,"P",{});var Da=u(it);xe=f(Da,"B\xE2y gi\u1EDD ch\xFAng ta nh\u1EADn \u0111\u01B0\u1EE3c c\xE1c logit t\u01B0\u01A1ng t\u1EF1 cho c\xE2u th\u1EE9 hai trong l\xF4."),Da.forEach(a),ds=d(n),lt=p(n,"P",{});var La=u(lt);Ce=f(La,"L\u01B0u \xFD c\xE1ch gi\xE1 tr\u1ECB cu\u1ED1i c\xF9ng c\u1EE7a chu\u1ED7i th\u1EE9 hai l\xE0 ID \u0111\u1EC7m, l\xE0 gi\xE1 tr\u1ECB 0 trong attention mask."),La.forEach(a),_s=d(n),j(pn.$$.fragment,n),bs=d(n),tn=p(n,"H2",{class:!0});var Cs=u(tn);un=p(Cs,"A",{id:!0,class:!0,href:!0});var Ha=u(un);Mt=p(Ha,"SPAN",{});var Ba=u(Mt);j(zn.$$.fragment,Ba),Ba.forEach(a),Ha.forEach(a),Fe=d(Cs),Dt=p(Cs,"SPAN",{});var Oa=u(Dt);Se=f(Oa,"Nh\u1EEFng chu\u1ED7i d\xE0i h\u01A1n"),Oa.forEach(a),Cs.forEach(a),ks=d(n),rt=p(n,"P",{});var Va=u(rt);Pe=f(Va,"V\u1EDBi c\xE1c m\xF4 h\xECnh Transformer, c\xF3 m\u1ED9t gi\u1EDBi h\u1EA1n v\u1EC1 \u0111\u1ED9 d\xE0i c\u1EE7a c\xE1c chu\u1ED7i m\xE0 ch\xFAng t\xF4i c\xF3 th\u1EC3 v\u01B0\u1EE3t qua c\xE1c m\xF4 h\xECnh. H\u1EA7u h\u1EBFt c\xE1c m\xF4 h\xECnh x\u1EED l\xFD chu\u1ED7i l\xEAn \u0111\u1EBFn 512 ho\u1EB7c 1024 token v\xE0 s\u1EBD b\u1ECB l\u1ED7i khi \u0111\u01B0\u1EE3c y\xEAu c\u1EA7u x\u1EED l\xFD chu\u1ED7i d\xE0i h\u01A1n. C\xF3 hai gi\u1EA3i ph\xE1p cho v\u1EA5n \u0111\u1EC1 n\xE0y:"),Va.forEach(a),$s=d(n),mn=p(n,"UL",{});var Fs=u(mn);Lt=p(Fs,"LI",{});var Ka=u(Lt);Ne=f(Ka,"S\u1EED d\u1EE5ng m\xF4 h\xECnh c\xF3 \u0111\u1ED9 d\xE0i chu\u1ED7i \u0111\u01B0\u1EE3c h\u1ED7 tr\u1EE3 d\xE0i h\u01A1n."),Ka.forEach(a),Me=d(Fs),Ht=p(Fs,"LI",{});var Ra=u(Ht);De=f(Ra,"C\u1EAFt ng\u1EAFn chu\u1ED7i c\u1EE7a b\u1EA1n."),Ra.forEach(a),Fs.forEach(a),vs=d(n),Y=p(n,"P",{});var dt=u(Y);Le=f(dt,"C\xE1c m\xF4 h\xECnh c\xF3 \u0111\u1ED9 d\xE0i chu\u1ED7i \u0111\u01B0\u1EE3c h\u1ED7 tr\u1EE3 kh\xE1c nhau v\xE0 m\u1ED9t s\u1ED1 m\xF4 h\xECnh chuy\xEAn x\u1EED l\xFD c\xE1c tr\xECnh t\u1EF1 r\u1EA5t d\xE0i. "),Tn=p(dt,"A",{href:!0,rel:!0});var Ga=u(Tn);He=f(Ga,"Longformer"),Ga.forEach(a),Be=f(dt," l\xE0 m\u1ED9t v\xED d\u1EE5 v\xE0 m\u1ED9t v\xED d\u1EE5 kh\xE1c l\xE0 "),An=p(dt,"A",{href:!0,rel:!0});var Ua=u(An);Oe=f(Ua,"LED"),Ua.forEach(a),Ve=f(dt,". N\u1EBFu b\u1EA1n \u0111ang th\u1EF1c hi\u1EC7n m\u1ED9t c\xF4ng vi\u1EC7c \u0111\xF2i h\u1ECFi tr\xECnh t\u1EF1 r\u1EA5t d\xE0i, ch\xFAng t\xF4i khuy\xEAn b\u1EA1n n\xEAn xem c\xE1c m\xF4 h\xECnh \u0111\xF3."),dt.forEach(a),js=d(n),fn=p(n,"P",{});var Ss=u(fn);Ke=f(Ss,"N\u1EBFu kh\xF4ng, ch\xFAng t\xF4i khuy\xEAn b\u1EA1n n\xEAn c\u1EAFt b\u1EDBt c\xE1c chu\u1ED7i c\u1EE7a m\xECnh b\u1EB1ng c\xE1ch ch\u1EC9 \u0111\u1ECBnh tham s\u1ED1 "),Bt=p(Ss,"CODE",{});var Xa=u(Bt);Re=f(Xa,"max_sequence_length"),Xa.forEach(a),Ge=f(Ss,":"),Ss.forEach(a),ys=d(n),j(In.$$.fragment,n),this.h()},h(){q(e,"name","hf:doc:metadata"),q(e,"content",JSON.stringify(yc)),q(_,"id","x-l-a-chui"),q(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(_,"href","#x-l-a-chui"),q(s,"class","relative group"),q(sn,"id","m-hnh-k-vng-mt-l-cc-u-vo"),q(sn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(sn,"href","#m-hnh-k-vng-mt-l-cc-u-vo"),q(Q,"class","relative group"),q(ln,"id","m-thm-vo-u-vo"),q(ln,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(ln,"href","#m-thm-vo-u-vo"),q(Z,"class","relative group"),q(hn,"id","attention-masks"),q(hn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(hn,"href","#attention-masks"),q(nn,"class","relative group"),q(un,"id","nhng-chui-di-hn"),q(un,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),q(un,"href","#nhng-chui-di-hn"),q(tn,"class","relative group"),q(Tn,"href","https://huggingface.co/transformers/model_doc/longformer.html"),q(Tn,"rel","nofollow"),q(An,"href","https://huggingface.co/transformers/model_doc/led.html"),q(An,"rel","nofollow")},m(n,i){c(document.head,e),r(n,l,i),y(t,n,i),r(n,o,i),r(n,s,i),c(s,_),c(_,z),y(T,z,null),c(s,J),c(s,A),c(A,Bn),r(n,bn,i),xn[F].m(n,i),r(n,On,i),Cn[P].m(n,i),r(n,Vn,i),r(n,Kn,i),c(Kn,Ps),r(n,Rt,i),r(n,I,i),c(I,_t),c(_t,Ns),c(I,Ms),c(I,kn),c(kn,Ds),c(kn,bt),c(bt,Ls),c(kn,Hs),c(I,Bs),c(I,kt),c(kt,Os),c(I,Vs),c(I,$t),c($t,Ks),r(n,Gt,i),r(n,Rn,i),c(Rn,Rs),r(n,Ut,i),r(n,Q,i),c(Q,sn),c(sn,vt),y($n,vt,null),c(Q,Gs),c(Q,jt),c(jt,Us),r(n,Xt,i),r(n,Gn,i),c(Gn,Xs),r(n,Yt,i),Fn[M].m(n,i),r(n,Un,i),r(n,Xn,i),c(Xn,Ys),r(n,Jt,i),r(n,en,i),c(en,Js),c(en,yt),c(yt,Qs),c(en,Ws),r(n,Qt,i),Sn[L].m(n,i),r(n,Yn,i),r(n,Jn,i),c(Jn,Zs),r(n,Wt,i),Pn[B].m(n,i),r(n,Qn,i),r(n,Wn,i),c(Wn,ne),r(n,Zt,i),Nn[V].m(n,i),r(n,Zn,i),r(n,W,i),c(W,wt),c(wt,te),c(W,se),c(W,qt),c(qt,ee),c(W,ae),r(n,ns,i),y(vn,n,i),r(n,ts,i),r(n,nt,i),c(nt,ce),r(n,ss,i),y(an,n,i),r(n,es,i),r(n,cn,i),c(cn,ie),c(cn,Et),c(Et,le),c(cn,re),r(n,as,i),r(n,Z,i),c(Z,ln),c(ln,zt),y(jn,zt,null),c(Z,oe),c(Z,Tt),c(Tt,he),r(n,cs,i),r(n,tt,i),c(tt,pe),r(n,is,i),y(yn,n,i),r(n,ls,i),r(n,x,i),c(x,ue),c(x,At),c(At,me),c(x,fe),c(x,It),c(It,ge),c(x,de),c(x,xt),c(xt,_e),c(x,be),r(n,rs,i),y(wn,n,i),r(n,os,i),r(n,rn,i),c(rn,ke),c(rn,Ct),c(Ct,$e),c(rn,ve),r(n,hs,i),Mn[R].m(n,i),r(n,st,i),r(n,et,i),c(et,je),r(n,ps,i),r(n,on,i),c(on,ye),c(on,Ft),c(Ft,we),c(on,qe),r(n,us,i),r(n,nn,i),c(nn,hn),c(hn,St),y(qn,St,null),c(nn,Ee),c(nn,Pt),c(Pt,ze),r(n,ms,i),r(n,En,i),c(En,Nt),c(Nt,Te),c(En,Ae),r(n,fs,i),r(n,at,i),c(at,Ie),r(n,gs,i),Dn[U].m(n,i),r(n,ct,i),r(n,it,i),c(it,xe),r(n,ds,i),r(n,lt,i),c(lt,Ce),r(n,_s,i),y(pn,n,i),r(n,bs,i),r(n,tn,i),c(tn,un),c(un,Mt),y(zn,Mt,null),c(tn,Fe),c(tn,Dt),c(Dt,Se),r(n,ks,i),r(n,rt,i),c(rt,Pe),r(n,$s,i),r(n,mn,i),c(mn,Lt),c(Lt,Ne),c(mn,Me),c(mn,Ht),c(Ht,De),r(n,vs,i),r(n,Y,i),c(Y,Le),c(Y,Tn),c(Tn,He),c(Y,Be),c(Y,An),c(An,Oe),c(Y,Ve),r(n,js,i),r(n,fn,i),c(fn,Ke),c(fn,Bt),c(Bt,Re),c(fn,Ge),r(n,ys,i),y(In,n,i),ws=!0},p(n,[i]){const Ln={};i&1&&(Ln.fw=n[0]),t.$set(Ln);let ot=F;F=Ye(n),F!==ot&&(_n(),b(xn[ot],1,1,()=>{xn[ot]=null}),dn(),S=xn[F],S||(S=xn[F]=Xe[F](n),S.c()),k(S,1),S.m(On.parentNode,On));let ht=P;P=Qe(n),P!==ht&&(_n(),b(Cn[ht],1,1,()=>{Cn[ht]=null}),dn(),N=Cn[P],N||(N=Cn[P]=Je[P](n),N.c()),k(N,1),N.m(Vn.parentNode,Vn));let pt=M;M=Ze(n),M!==pt&&(_n(),b(Fn[pt],1,1,()=>{Fn[pt]=null}),dn(),D=Fn[M],D||(D=Fn[M]=We[M](n),D.c()),k(D,1),D.m(Un.parentNode,Un));let ut=L;L=ta(n),L!==ut&&(_n(),b(Sn[ut],1,1,()=>{Sn[ut]=null}),dn(),H=Sn[L],H||(H=Sn[L]=na[L](n),H.c()),k(H,1),H.m(Yn.parentNode,Yn));let C=B;B=ea(n),B!==C&&(_n(),b(Pn[C],1,1,()=>{Pn[C]=null}),dn(),O=Pn[B],O||(O=Pn[B]=sa[B](n),O.c()),k(O,1),O.m(Qn.parentNode,Qn));let mt=V;V=ca(n),V!==mt&&(_n(),b(Nn[mt],1,1,()=>{Nn[mt]=null}),dn(),K=Nn[V],K||(K=Nn[V]=aa[V](n),K.c()),k(K,1),K.m(Zn.parentNode,Zn));const Hn={};i&2&&(Hn.$$scope={dirty:i,ctx:n}),an.$set(Hn);let ft=R;R=la(n),R!==ft&&(_n(),b(Mn[ft],1,1,()=>{Mn[ft]=null}),dn(),G=Mn[R],G||(G=Mn[R]=ia[R](n),G.c()),k(G,1),G.m(st.parentNode,st));let gt=U;U=oa(n),U!==gt&&(_n(),b(Dn[gt],1,1,()=>{Dn[gt]=null}),dn(),X=Dn[U],X||(X=Dn[U]=ra[U](n),X.c()),k(X,1),X.m(ct.parentNode,ct));const Ot={};i&2&&(Ot.$$scope={dirty:i,ctx:n}),pn.$set(Ot)},i(n){ws||(k(t.$$.fragment,n),k(T.$$.fragment,n),k(S),k(N),k($n.$$.fragment,n),k(D),k(H),k(O),k(K),k(vn.$$.fragment,n),k(an.$$.fragment,n),k(jn.$$.fragment,n),k(yn.$$.fragment,n),k(wn.$$.fragment,n),k(G),k(qn.$$.fragment,n),k(X),k(pn.$$.fragment,n),k(zn.$$.fragment,n),k(In.$$.fragment,n),ws=!0)},o(n){b(t.$$.fragment,n),b(T.$$.fragment,n),b(S),b(N),b($n.$$.fragment,n),b(D),b(H),b(O),b(K),b(vn.$$.fragment,n),b(an.$$.fragment,n),b(jn.$$.fragment,n),b(yn.$$.fragment,n),b(wn.$$.fragment,n),b(G),b(qn.$$.fragment,n),b(X),b(pn.$$.fragment,n),b(zn.$$.fragment,n),b(In.$$.fragment,n),ws=!1},d(n){a(e),n&&a(l),w(t,n),n&&a(o),n&&a(s),w(T),n&&a(bn),xn[F].d(n),n&&a(On),Cn[P].d(n),n&&a(Vn),n&&a(Kn),n&&a(Rt),n&&a(I),n&&a(Gt),n&&a(Rn),n&&a(Ut),n&&a(Q),w($n),n&&a(Xt),n&&a(Gn),n&&a(Yt),Fn[M].d(n),n&&a(Un),n&&a(Xn),n&&a(Jt),n&&a(en),n&&a(Qt),Sn[L].d(n),n&&a(Yn),n&&a(Jn),n&&a(Wt),Pn[B].d(n),n&&a(Qn),n&&a(Wn),n&&a(Zt),Nn[V].d(n),n&&a(Zn),n&&a(W),n&&a(ns),w(vn,n),n&&a(ts),n&&a(nt),n&&a(ss),w(an,n),n&&a(es),n&&a(cn),n&&a(as),n&&a(Z),w(jn),n&&a(cs),n&&a(tt),n&&a(is),w(yn,n),n&&a(ls),n&&a(x),n&&a(rs),w(wn,n),n&&a(os),n&&a(rn),n&&a(hs),Mn[R].d(n),n&&a(st),n&&a(et),n&&a(ps),n&&a(on),n&&a(us),n&&a(nn),w(qn),n&&a(ms),n&&a(En),n&&a(fs),n&&a(at),n&&a(gs),Dn[U].d(n),n&&a(ct),n&&a(it),n&&a(ds),n&&a(lt),n&&a(_s),w(pn,n),n&&a(bs),n&&a(tn),w(zn),n&&a(ks),n&&a(rt),n&&a($s),n&&a(mn),n&&a(vs),n&&a(Y),n&&a(js),n&&a(fn),n&&a(ys),w(In,n)}}}const yc={local:"x-l-a-chui",sections:[{local:"m-hnh-k-vng-mt-l-cc-u-vo",title:"M\xF4 h\xECnh k\xEC v\u1ECDng m\u1ED9t l\xF4 c\xE1c \u0111\u1EA7u v\xE0o"},{local:"m-thm-vo-u-vo",title:"\u0110\xEAm th\xEAm v\xE0o \u0111\u1EA7u v\xE0o"},{local:"attention-masks",title:"Attention masks"},{local:"nhng-chui-di-hn",title:"Nh\u1EEFng chu\u1ED7i d\xE0i h\u01A1n"}],title:"X\u1EED l\xFD \u0111a chu\u1ED7i"};function wc($,e,l){let t="pt";return sc(()=>{const o=new URLSearchParams(window.location.search);l(0,t=o.get("fw")||"pt")}),[t]}class Cc extends Wa{constructor(e){super();Za(this,e,wc,jc,nc,{})}}export{Cc as default,yc as metadata};
