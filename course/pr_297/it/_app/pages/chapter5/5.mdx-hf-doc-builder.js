import{S as Xc,i as Wc,s as Yc,e as r,k as p,w as f,t,M as ed,c as o,d as a,m as c,a as n,x as _,h as i,b as m,N as Ga,G as s,g as u,y as b,q as v,o as x,B as $,v as sd}from"../../chunks/vendor-hf-doc-builder.js";import{T as na}from"../../chunks/Tip-hf-doc-builder.js";import{Y as ad}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Ra}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as td}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function id(S){let d,z,h,y,w;return{c(){d=r("p"),z=t("\u270F\uFE0F "),h=r("strong"),y=t("Prova tu!"),w=t(" Clicca su alcuni degli URL nel payload JSON per farti un\u2019idea del tipo di informazione a cui \xE8 collegato ogni issue GitHub.")},l(g){d=o(g,"P",{});var q=n(d);z=i(q,"\u270F\uFE0F "),h=o(q,"STRONG",{});var P=n(h);y=i(P,"Prova tu!"),P.forEach(a),w=i(q," Clicca su alcuni degli URL nel payload JSON per farti un\u2019idea del tipo di informazione a cui \xE8 collegato ogni issue GitHub."),q.forEach(a)},m(g,q){u(g,d,q),s(d,z),s(d,h),s(h,y),s(d,w)},d(g){g&&a(d)}}}function ld(S){let d,z,h,y,w,g,q,P,j,E,H,D,O;return{c(){d=r("p"),z=t("\u26A0\uFE0F Fai attenzione a non condividere un notebook con il tuo "),h=r("code"),y=t("GITHUB_TOKEN"),w=t(" al suo interno. Ti consigliamo di cancellare l\u2019ultima cella una volta che l\u2019hai eseguita per evitare di far trapelare quest\u2019informazione accidentalmente. Meglio ancora, salva il tuo token in un file "),g=r("em"),q=t(".env"),P=t(" e usa la "),j=r("a"),E=t("libreria "),H=r("code"),D=t("python-dotenv"),O=t(" per caricarlo automaticamente come una variabile d\u2019ambiente."),this.h()},l(A){d=o(A,"P",{});var k=n(d);z=i(k,"\u26A0\uFE0F Fai attenzione a non condividere un notebook con il tuo "),h=o(k,"CODE",{});var T=n(h);y=i(T,"GITHUB_TOKEN"),T.forEach(a),w=i(k," al suo interno. Ti consigliamo di cancellare l\u2019ultima cella una volta che l\u2019hai eseguita per evitare di far trapelare quest\u2019informazione accidentalmente. Meglio ancora, salva il tuo token in un file "),g=o(k,"EM",{});var B=n(g);q=i(B,".env"),B.forEach(a),P=i(k," e usa la "),j=o(k,"A",{href:!0,rel:!0});var R=n(j);E=i(R,"libreria "),H=o(R,"CODE",{});var N=n(H);D=i(N,"python-dotenv"),N.forEach(a),R.forEach(a),O=i(k," per caricarlo automaticamente come una variabile d\u2019ambiente."),k.forEach(a),this.h()},h(){m(j,"href","https://github.com/theskumar/python-dotenv"),m(j,"rel","nofollow")},m(A,k){u(A,d,k),s(d,z),s(d,h),s(h,y),s(d,w),s(d,g),s(g,q),s(d,P),s(d,j),s(j,E),s(j,H),s(H,D),s(d,O)},d(A){A&&a(d)}}}function rd(S){let d,z,h,y,w,g,q,P,j,E,H,D,O,A,k,T,B,R,N,Q;return{c(){d=r("p"),z=t("\u270F\uFE0F "),h=r("strong"),y=t("Prova tu!"),w=t(" Calcola il tempo medio che ci vuole a chiudere un issue su \u{1F917} Datasets. Potrebbe essere utile usare la funzione "),g=r("code"),q=t("Dataset.filter()"),P=t(" per eliminare le richieste di pull e gli issue aperti, e puoi usare la funzione "),j=r("code"),E=t("Dataset.set_format()"),H=t(" per convertire il dataset in un "),D=r("code"),O=t("DataFrame"),A=t(" cos\xEC che puoi facilmente manipolare i timestamp "),k=r("code"),T=t("created_at"),B=t(" e "),R=r("code"),N=t("closed_at"),Q=t(". Per dei punti bonus, calcola il tempo medio che ci vuole a chiudere le richieste di pull.")},l(pe){d=o(pe,"P",{});var I=n(d);z=i(I,"\u270F\uFE0F "),h=o(I,"STRONG",{});var X=n(h);y=i(X,"Prova tu!"),X.forEach(a),w=i(I," Calcola il tempo medio che ci vuole a chiudere un issue su \u{1F917} Datasets. Potrebbe essere utile usare la funzione "),g=o(I,"CODE",{});var ua=n(g);q=i(ua,"Dataset.filter()"),ua.forEach(a),P=i(I," per eliminare le richieste di pull e gli issue aperti, e puoi usare la funzione "),j=o(I,"CODE",{});var ve=n(j);E=i(ve,"Dataset.set_format()"),ve.forEach(a),H=i(I," per convertire il dataset in un "),D=o(I,"CODE",{});var pa=n(D);O=i(pa,"DataFrame"),pa.forEach(a),A=i(I," cos\xEC che puoi facilmente manipolare i timestamp "),k=o(I,"CODE",{});var ca=n(k);T=i(ca,"created_at"),ca.forEach(a),B=i(I," e "),R=o(I,"CODE",{});var da=n(R);N=i(da,"closed_at"),da.forEach(a),Q=i(I,". Per dei punti bonus, calcola il tempo medio che ci vuole a chiudere le richieste di pull."),I.forEach(a)},m(pe,I){u(pe,d,I),s(d,z),s(d,h),s(h,y),s(d,w),s(d,g),s(g,q),s(d,P),s(d,j),s(j,E),s(d,H),s(d,D),s(D,O),s(d,A),s(d,k),s(k,T),s(d,B),s(d,R),s(R,N),s(d,Q)},d(pe){pe&&a(d)}}}function od(S){let d,z,h,y,w,g,q,P,j,E,H;return{c(){d=r("p"),z=t("\u270F\uFE0F "),h=r("strong"),y=t("Prova tu!"),w=t(" Usa le tue credenziali dell\u2019Hub Hugging Face per ottenere un token e creare una repository vuota chiamata "),g=r("code"),q=t("github-issues"),P=t(". Ricordati di "),j=r("strong"),E=t("non salvere mai le tue credenziali"),H=t(" su Colab o qualunque altra repository, perch\xE9 potrebbero essere recuperate da malintenzionati.")},l(D){d=o(D,"P",{});var O=n(d);z=i(O,"\u270F\uFE0F "),h=o(O,"STRONG",{});var A=n(h);y=i(A,"Prova tu!"),A.forEach(a),w=i(O," Usa le tue credenziali dell\u2019Hub Hugging Face per ottenere un token e creare una repository vuota chiamata "),g=o(O,"CODE",{});var k=n(g);q=i(k,"github-issues"),k.forEach(a),P=i(O,". Ricordati di "),j=o(O,"STRONG",{});var T=n(j);E=i(T,"non salvere mai le tue credenziali"),T.forEach(a),H=i(O," su Colab o qualunque altra repository, perch\xE9 potrebbero essere recuperate da malintenzionati."),O.forEach(a)},m(D,O){u(D,d,O),s(d,z),s(d,h),s(h,y),s(d,w),s(d,g),s(g,q),s(d,P),s(d,j),s(j,E),s(d,H)},d(D){D&&a(d)}}}function nd(S){let d,z,h,y,w,g,q,P;return{c(){d=r("p"),z=t("\u{1F4A1} Puoi caricare un dataset nell\u2019Hub di Hugging Face anche direttamente dal terminale usando "),h=r("code"),y=t("huggingface-cli"),w=t(" e un po\u2019 di magia Git. La "),g=r("a"),q=t("guida a \u{1F917} Datasets"),P=t(" spiega come farlo."),this.h()},l(j){d=o(j,"P",{});var E=n(d);z=i(E,"\u{1F4A1} Puoi caricare un dataset nell\u2019Hub di Hugging Face anche direttamente dal terminale usando "),h=o(E,"CODE",{});var H=n(h);y=i(H,"huggingface-cli"),H.forEach(a),w=i(E," e un po\u2019 di magia Git. La "),g=o(E,"A",{href:!0,rel:!0});var D=n(g);q=i(D,"guida a \u{1F917} Datasets"),D.forEach(a),P=i(E," spiega come farlo."),E.forEach(a),this.h()},h(){m(g,"href","https://huggingface.co/docs/datasets/share.html#add-a-community-dataset"),m(g,"rel","nofollow")},m(j,E){u(j,d,E),s(d,z),s(d,h),s(h,y),s(d,w),s(d,g),s(g,q),s(d,P)},d(j){j&&a(d)}}}function ud(S){let d,z,h,y,w,g,q,P,j,E,H,D,O,A;return{c(){d=r("p"),z=t("\u270F\uFE0F "),h=r("strong"),y=t("Prova tu!"),w=t(" Usa l\u2019applicazione "),g=r("code"),q=t("dataset-tagging"),P=t(" e la "),j=r("a"),E=t("guida \u{1F917} Datasets"),H=t(" per completare il file "),D=r("em"),O=t("README.md"),A=t(" per il tuo dataset di issue di GitHub."),this.h()},l(k){d=o(k,"P",{});var T=n(d);z=i(T,"\u270F\uFE0F "),h=o(T,"STRONG",{});var B=n(h);y=i(B,"Prova tu!"),B.forEach(a),w=i(T," Usa l\u2019applicazione "),g=o(T,"CODE",{});var R=n(g);q=i(R,"dataset-tagging"),R.forEach(a),P=i(T," e la "),j=o(T,"A",{href:!0,rel:!0});var N=n(j);E=i(N,"guida \u{1F917} Datasets"),N.forEach(a),H=i(T," per completare il file "),D=o(T,"EM",{});var Q=n(D);O=i(Q,"README.md"),Q.forEach(a),A=i(T," per il tuo dataset di issue di GitHub."),T.forEach(a),this.h()},h(){m(j,"href","https://github.com/huggingface/datasets/blob/master/templates/README_guide.md"),m(j,"rel","nofollow")},m(k,T){u(k,d,T),s(d,z),s(d,h),s(h,y),s(d,w),s(d,g),s(g,q),s(d,P),s(d,j),s(j,E),s(d,H),s(d,D),s(D,O),s(d,A)},d(k){k&&a(d)}}}function pd(S){let d,z,h,y,w,g,q,P;return{c(){d=r("p"),z=t("\u270F\uFE0F "),h=r("strong"),y=t("Prova tu!"),w=t(" Segui i passi che abbiamo eseguito in questa sezione per creare un dataset di issue GitHub per la tua libreria open source preferita (ovviamente scegli qualcosa di diverso da \u{1F917} Datasets!). Per punti bonus, esegui il fine-tuning di un classificatore multiclasse per predirre i tag presenti nel campo "),g=r("code"),q=t("labels"),P=t(".")},l(j){d=o(j,"P",{});var E=n(d);z=i(E,"\u270F\uFE0F "),h=o(E,"STRONG",{});var H=n(h);y=i(H,"Prova tu!"),H.forEach(a),w=i(E," Segui i passi che abbiamo eseguito in questa sezione per creare un dataset di issue GitHub per la tua libreria open source preferita (ovviamente scegli qualcosa di diverso da \u{1F917} Datasets!). Per punti bonus, esegui il fine-tuning di un classificatore multiclasse per predirre i tag presenti nel campo "),g=o(E,"CODE",{});var D=n(g);q=i(D,"labels"),D.forEach(a),P=i(E,"."),E.forEach(a)},m(j,E){u(j,d,E),s(d,z),s(d,h),s(h,y),s(d,w),s(d,g),s(g,q),s(d,P)},d(j){j&&a(d)}}}function cd(S){let d,z,h,y,w,g,q,P,j,E,H,D,O,A,k,T,B,R,N,Q,pe,I,X,ua,ve,pa,ca,da,Sa,dr,ti,ma,mr,ii,ce,xe,Ua,es,hr,La,gr,li,$e,fr,ss,_r,br,ri,as,ts,Zu,oi,ha,vr,ni,is,ls,Ku,ui,W,xr,rs,$r,jr,je,Er,Ma,yr,qr,pi,Ee,wr,Fa,kr,zr,ci,os,di,Y,Pr,Ba,Dr,Hr,Qa,Or,Cr,mi,ns,hi,ye,Tr,Ja,Ar,Nr,gi,us,fi,ps,_i,J,Ir,Va,Gr,Rr,cs,Sr,Ur,Za,Lr,Mr,bi,ds,vi,ms,xi,V,Fr,Ka,Br,Qr,Xa,Jr,Vr,Wa,Zr,Kr,$i,qe,ji,U,Xr,hs,Wr,Yr,Ya,eo,so,gs,ao,to,et,io,lo,Ei,fs,yi,we,qi,ga,ro,wi,_s,ki,ee,oo,st,no,uo,at,po,co,zi,bs,Pi,ke,mo,fa,ho,go,Di,vs,Hi,xs,Oi,se,fo,$s,_o,bo,js,vo,xo,Ci,_a,de,$o,tt,jo,Eo,it,yo,qo,Ti,ze,wo,K,ko,lt,zo,Po,rt,Do,Ho,ot,Oo,Co,To,Ai,ba,Ao,Ni,me,Pe,nt,Es,No,ut,Io,Ii,G,Go,pt,Ro,So,va,Uo,Lo,ct,Mo,Fo,dt,Bo,Qo,mt,Jo,Vo,ht,Zo,Ko,Gi,ys,Ri,qs,Si,L,Xo,gt,Wo,Yo,ft,en,sn,_t,an,tn,bt,ln,rn,Ui,ws,Li,De,Mi,xa,on,Fi,$a,nn,Bi,he,He,vt,ks,un,xt,pn,Qi,ja,cn,Ji,zs,Ps,Xu,Vi,Oe,dn,Ce,mn,$t,hn,gn,Zi,Ds,Ki,Hs,Xi,Z,fn,jt,_n,bn,Et,vn,xn,yt,$n,jn,Wi,Os,Yi,Cs,el,ae,En,qt,yn,qn,wt,wn,kn,sl,Ts,al,Ea,zn,tl,As,il,ge,Te,kt,Ns,Pn,zt,Dn,ll,Is,rl,te,Hn,Gs,On,Cn,Pt,Tn,An,ol,Rs,nl,Ss,ul,Ae,Nn,Dt,In,Gn,pl,Ne,Rn,Ht,Sn,Un,cl,Us,dl,Ie,Ln,Ot,Mn,Fn,ml,Ls,hl,Ge,Bn,Ct,Qn,Jn,gl,Ms,fl,Fs,_l,ie,Vn,Tt,Zn,Kn,At,Xn,Wn,bl,Re,vl,Se,Yn,Nt,eu,su,xl,Bs,$l,M,au,It,tu,iu,Gt,lu,ru,Rt,ou,nu,St,uu,pu,jl,Qs,El,Ue,cu,Ut,du,mu,yl,Js,ql,Le,hu,Lt,gu,fu,wl,Vs,Zs,Wu,kl,le,_u,Mt,bu,vu,Ft,xu,$u,zl,Ks,Pl,Xs,Dl,Me,ju,Bt,Eu,yu,Hl,Fe,Ol,fe,Be,Qt,Ws,qu,Jt,wu,Cl,ya,ku,Tl,Qe,zu,Vt,Pu,Du,Al,qa,_e,Hu,Je,Ou,Zt,Cu,Tu,Kt,Au,Nu,Nl,Ys,ea,Yu,Il,sa,aa,Iu,ta,Gu,Ru,Gl,re,Su,Xt,Uu,Lu,Wt,Mu,Fu,Rl,ia,la,ep,Sl,Ve,Ul,wa,Bu,Ll,Ze,Ml;return g=new Ra({}),H=new td({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section5.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section5.ipynb"}]}}),es=new Ra({}),os=new C({props:{code:"!pip install requests",highlighted:"!pip install requests"}}),ns=new C({props:{code:`import requests

url = "https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1"
response = requests.get(url)`,highlighted:`<span class="hljs-keyword">import</span> requests

url = <span class="hljs-string">&quot;https://api.github.com/repos/huggingface/datasets/issues?page=1&amp;per_page=1&quot;</span>
response = requests.get(url)`}}),us=new C({props:{code:"response.status_code",highlighted:"response.status_code"}}),ps=new C({props:{code:"200",highlighted:'<span class="hljs-number">200</span>'}}),ds=new C({props:{code:"response.json()",highlighted:"response.json()"}}),ms=new C({props:{code:`[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'repository_url': 'https://api.github.com/repos/huggingface/datasets',
  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/labels{/name}',
  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/comments',
  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792/events',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792',
  'id': 968650274,
  'node_id': 'MDExOlB1bGxSZXF1ZXN0NzEwNzUyMjc0',
  'number': 2792,
  'title': 'Update GooAQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2021-08-12T11:40:18Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'pull_request': {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/2792',
   'html_url': 'https://github.com/huggingface/datasets/pull/2792',
   'diff_url': 'https://github.com/huggingface/datasets/pull/2792.diff',
   'patch_url': 'https://github.com/huggingface/datasets/pull/2792.patch'},
  'body': '[GooAQ](https://github.com/allenai/gooaq) dataset was recently updated after splits were added for the same. This PR contains new updated GooAQ with train/val/test splits and updated README as well.',
  'performed_via_github_app': None}]`,highlighted:`[{<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792&#x27;</span>,
  <span class="hljs-string">&#x27;repository_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets&#x27;</span>,
  <span class="hljs-string">&#x27;labels_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792/labels{/name}&#x27;</span>,
  <span class="hljs-string">&#x27;comments_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792/comments&#x27;</span>,
  <span class="hljs-string">&#x27;events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792/events&#x27;</span>,
  <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792&#x27;</span>,
  <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">968650274</span>,
  <span class="hljs-string">&#x27;node_id&#x27;</span>: <span class="hljs-string">&#x27;MDExOlB1bGxSZXF1ZXN0NzEwNzUyMjc0&#x27;</span>,
  <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">2792</span>,
  <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Update GooAQ&#x27;</span>,
  <span class="hljs-string">&#x27;user&#x27;</span>: {<span class="hljs-string">&#x27;login&#x27;</span>: <span class="hljs-string">&#x27;bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">19718818</span>,
   <span class="hljs-string">&#x27;node_id&#x27;</span>: <span class="hljs-string">&#x27;MDQ6VXNlcjE5NzE4ODE4&#x27;</span>,
   <span class="hljs-string">&#x27;avatar_url&#x27;</span>: <span class="hljs-string">&#x27;https://avatars.githubusercontent.com/u/19718818?v=4&#x27;</span>,
   <span class="hljs-string">&#x27;gravatar_id&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
   <span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;followers_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/followers&#x27;</span>,
   <span class="hljs-string">&#x27;following_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/following{/other_user}&#x27;</span>,
   <span class="hljs-string">&#x27;gists_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/gists{/gist_id}&#x27;</span>,
   <span class="hljs-string">&#x27;starred_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}&#x27;</span>,
   <span class="hljs-string">&#x27;subscriptions_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/subscriptions&#x27;</span>,
   <span class="hljs-string">&#x27;organizations_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/orgs&#x27;</span>,
   <span class="hljs-string">&#x27;repos_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/repos&#x27;</span>,
   <span class="hljs-string">&#x27;events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/events{/privacy}&#x27;</span>,
   <span class="hljs-string">&#x27;received_events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/received_events&#x27;</span>,
   <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;User&#x27;</span>,
   <span class="hljs-string">&#x27;site_admin&#x27;</span>: <span class="hljs-literal">False</span>},
  <span class="hljs-string">&#x27;labels&#x27;</span>: [],
  <span class="hljs-string">&#x27;state&#x27;</span>: <span class="hljs-string">&#x27;open&#x27;</span>,
  <span class="hljs-string">&#x27;locked&#x27;</span>: <span class="hljs-literal">False</span>,
  <span class="hljs-string">&#x27;assignee&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;assignees&#x27;</span>: [],
  <span class="hljs-string">&#x27;milestone&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;comments&#x27;</span>: <span class="hljs-number">1</span>,
  <span class="hljs-string">&#x27;created_at&#x27;</span>: <span class="hljs-string">&#x27;2021-08-12T11:40:18Z&#x27;</span>,
  <span class="hljs-string">&#x27;updated_at&#x27;</span>: <span class="hljs-string">&#x27;2021-08-12T12:31:17Z&#x27;</span>,
  <span class="hljs-string">&#x27;closed_at&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;author_association&#x27;</span>: <span class="hljs-string">&#x27;CONTRIBUTOR&#x27;</span>,
  <span class="hljs-string">&#x27;active_lock_reason&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;pull_request&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/pulls/2792&#x27;</span>,
   <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792&#x27;</span>,
   <span class="hljs-string">&#x27;diff_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792.diff&#x27;</span>,
   <span class="hljs-string">&#x27;patch_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792.patch&#x27;</span>},
  <span class="hljs-string">&#x27;body&#x27;</span>: <span class="hljs-string">&#x27;[GooAQ](https://github.com/allenai/gooaq) dataset was recently updated after splits were added for the same. This PR contains new updated GooAQ with train/val/test splits and updated README as well.&#x27;</span>,
  <span class="hljs-string">&#x27;performed_via_github_app&#x27;</span>: <span class="hljs-literal">None</span>}]`}}),qe=new na({props:{$$slots:{default:[id]},$$scope:{ctx:S}}}),fs=new C({props:{code:`GITHUB_TOKEN = xxx  # inserisci qui il tuo token GitHub
headers = {"Authorization": f"token {GITHUB_TOKEN}"}`,highlighted:`GITHUB_TOKEN = xxx  <span class="hljs-comment"># inserisci qui il tuo token GitHub</span>
headers = {<span class="hljs-string">&quot;Authorization&quot;</span>: <span class="hljs-string">f&quot;token <span class="hljs-subst">{GITHUB_TOKEN}</span>&quot;</span>}`}}),we=new na({props:{warning:!0,$$slots:{default:[ld]},$$scope:{ctx:S}}}),_s=new C({props:{code:`import time
import math
from pathlib import Path
import pandas as pd
from tqdm.notebook import tqdm


def fetch_issues(
    owner="huggingface",
    repo="datasets",
    num_issues=10_000,
    rate_limit=5_000,
    issues_path=Path("."),
):
    if not issues_path.is_dir():
        issues_path.mkdir(exist_ok=True)

    batch = []
    all_issues = []
    per_page = 100  # Numero di issue da restituire per pagina
    num_pages = math.ceil(num_issues / per_page)
    base_url = "https://api.github.com/repos"

    for page in tqdm(range(num_pages)):
        # La query ha state=all per ottenere sia gli issue aperti che quelli chiusi
        query = f"issues?page={page}&per_page={per_page}&state=all"
        issues = requests.get(f"{base_url}/{owner}/{repo}/{query}", headers=headers)
        batch.extend(issues.json())

        if len(batch) > rate_limit and len(all_issues) < num_issues:
            all_issues.extend(batch)
            batch = []  # puliamo la batch per il termine successivo
            print(f"Reached GitHub rate limit. Sleeping for one hour ...")
            time.sleep(60 * 60 + 1)

    all_issues.extend(batch)
    df = pd.DataFrame.from_records(all_issues)
    df.to_json(f"{issues_path}/{repo}-issues.jsonl", orient="records", lines=True)
    print(
        f"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl"
    )`,highlighted:`<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> math
<span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> tqdm.notebook <span class="hljs-keyword">import</span> tqdm


<span class="hljs-keyword">def</span> <span class="hljs-title function_">fetch_issues</span>(<span class="hljs-params">
    owner=<span class="hljs-string">&quot;huggingface&quot;</span>,
    repo=<span class="hljs-string">&quot;datasets&quot;</span>,
    num_issues=<span class="hljs-number">10_000</span>,
    rate_limit=<span class="hljs-number">5_000</span>,
    issues_path=Path(<span class="hljs-params"><span class="hljs-string">&quot;.&quot;</span></span>),
</span>):
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> issues_path.is_dir():
        issues_path.mkdir(exist_ok=<span class="hljs-literal">True</span>)

    batch = []
    all_issues = []
    per_page = <span class="hljs-number">100</span>  <span class="hljs-comment"># Numero di issue da restituire per pagina</span>
    num_pages = math.ceil(num_issues / per_page)
    base_url = <span class="hljs-string">&quot;https://api.github.com/repos&quot;</span>

    <span class="hljs-keyword">for</span> page <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(num_pages)):
        <span class="hljs-comment"># La query ha state=all per ottenere sia gli issue aperti che quelli chiusi</span>
        query = <span class="hljs-string">f&quot;issues?page=<span class="hljs-subst">{page}</span>&amp;per_page=<span class="hljs-subst">{per_page}</span>&amp;state=all&quot;</span>
        issues = requests.get(<span class="hljs-string">f&quot;<span class="hljs-subst">{base_url}</span>/<span class="hljs-subst">{owner}</span>/<span class="hljs-subst">{repo}</span>/<span class="hljs-subst">{query}</span>&quot;</span>, headers=headers)
        batch.extend(issues.json())

        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(batch) &gt; rate_limit <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(all_issues) &lt; num_issues:
            all_issues.extend(batch)
            batch = []  <span class="hljs-comment"># puliamo la batch per il termine successivo</span>
            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Reached GitHub rate limit. Sleeping for one hour ...&quot;</span>)
            time.sleep(<span class="hljs-number">60</span> * <span class="hljs-number">60</span> + <span class="hljs-number">1</span>)

    all_issues.extend(batch)
    df = pd.DataFrame.from_records(all_issues)
    df.to_json(<span class="hljs-string">f&quot;<span class="hljs-subst">{issues_path}</span>/<span class="hljs-subst">{repo}</span>-issues.jsonl&quot;</span>, orient=<span class="hljs-string">&quot;records&quot;</span>, lines=<span class="hljs-literal">True</span>)
    <span class="hljs-built_in">print</span>(
        <span class="hljs-string">f&quot;Downloaded all the issues for <span class="hljs-subst">{repo}</span>! Dataset stored at <span class="hljs-subst">{issues_path}</span>/<span class="hljs-subst">{repo}</span>-issues.jsonl&quot;</span>
    )`}}),bs=new C({props:{code:`# A seconda della tua connessione internet, ci potrebbe volere qualche secondo...
fetch_issues()`,highlighted:`<span class="hljs-comment"># A seconda della tua connessione internet, ci potrebbe volere qualche secondo...</span>
fetch_issues()`}}),vs=new C({props:{code:`issues_dataset = load_dataset("json", data_files="datasets-issues.jsonl", split="train")
issues_dataset`,highlighted:`issues_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=<span class="hljs-string">&quot;datasets-issues.jsonl&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
issues_dataset`}}),xs=new C({props:{code:`Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app'],
    num_rows: 3019
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;url&#x27;</span>, <span class="hljs-string">&#x27;repository_url&#x27;</span>, <span class="hljs-string">&#x27;labels_url&#x27;</span>, <span class="hljs-string">&#x27;comments_url&#x27;</span>, <span class="hljs-string">&#x27;events_url&#x27;</span>, <span class="hljs-string">&#x27;html_url&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;node_id&#x27;</span>, <span class="hljs-string">&#x27;number&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;state&#x27;</span>, <span class="hljs-string">&#x27;locked&#x27;</span>, <span class="hljs-string">&#x27;assignee&#x27;</span>, <span class="hljs-string">&#x27;assignees&#x27;</span>, <span class="hljs-string">&#x27;milestone&#x27;</span>, <span class="hljs-string">&#x27;comments&#x27;</span>, <span class="hljs-string">&#x27;created_at&#x27;</span>, <span class="hljs-string">&#x27;updated_at&#x27;</span>, <span class="hljs-string">&#x27;closed_at&#x27;</span>, <span class="hljs-string">&#x27;author_association&#x27;</span>, <span class="hljs-string">&#x27;active_lock_reason&#x27;</span>, <span class="hljs-string">&#x27;pull_request&#x27;</span>, <span class="hljs-string">&#x27;body&#x27;</span>, <span class="hljs-string">&#x27;timeline_url&#x27;</span>, <span class="hljs-string">&#x27;performed_via_github_app&#x27;</span>],
    num_rows: <span class="hljs-number">3019</span>
})`}}),Es=new Ra({}),ys=new C({props:{code:`sample = issues_dataset.shuffle(seed=666).select(range(3))

# Stampiamo le entrate \`URL\` e \`pull_request\`
for url, pr in zip(sample["html_url"], sample["pull_request"]):
    print(f">> URL: {url}")
    print(f">> Pull request: {pr}\\n")`,highlighted:`sample = issues_dataset.shuffle(seed=<span class="hljs-number">666</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>))

<span class="hljs-comment"># Stampiamo le entrate \`URL\` e \`pull_request\`</span>
<span class="hljs-keyword">for</span> url, pr <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(sample[<span class="hljs-string">&quot;html_url&quot;</span>], sample[<span class="hljs-string">&quot;pull_request&quot;</span>]):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;&gt;&gt; URL: <span class="hljs-subst">{url}</span>&quot;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;&gt;&gt; Pull request: <span class="hljs-subst">{pr}</span>\\n&quot;</span>)`}}),qs=new C({props:{code:`>> URL: https://github.com/huggingface/datasets/pull/850
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/850', 'html_url': 'https://github.com/huggingface/datasets/pull/850', 'diff_url': 'https://github.com/huggingface/datasets/pull/850.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/850.patch'}

>> URL: https://github.com/huggingface/datasets/issues/2773
>> Pull request: None

>> URL: https://github.com/huggingface/datasets/pull/783
>> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/783', 'html_url': 'https://github.com/huggingface/datasets/pull/783', 'diff_url': 'https://github.com/huggingface/datasets/pull/783.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/783.patch'}`,highlighted:`&gt;&gt; URL: https://github.com/huggingface/datasets/pull/<span class="hljs-number">850</span>
&gt;&gt; Pull request: {<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/pulls/850&#x27;</span>, <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/850&#x27;</span>, <span class="hljs-string">&#x27;diff_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/850.diff&#x27;</span>, <span class="hljs-string">&#x27;patch_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/850.patch&#x27;</span>}

&gt;&gt; URL: https://github.com/huggingface/datasets/issues/<span class="hljs-number">2773</span>
&gt;&gt; Pull request: <span class="hljs-literal">None</span>

&gt;&gt; URL: https://github.com/huggingface/datasets/pull/<span class="hljs-number">783</span>
&gt;&gt; Pull request: {<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/pulls/783&#x27;</span>, <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/783&#x27;</span>, <span class="hljs-string">&#x27;diff_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/783.diff&#x27;</span>, <span class="hljs-string">&#x27;patch_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/783.patch&#x27;</span>}`}}),ws=new C({props:{code:`issues_dataset = issues_dataset.map(
    lambda x: {"is_pull_request": False if x["pull_request"] is None else True}
)`,highlighted:`issues_dataset = issues_dataset.<span class="hljs-built_in">map</span>(
    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;is_pull_request&quot;</span>: <span class="hljs-literal">False</span> <span class="hljs-keyword">if</span> x[<span class="hljs-string">&quot;pull_request&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">True</span>}
)`}}),De=new na({props:{$$slots:{default:[rd]},$$scope:{ctx:S}}}),ks=new Ra({}),Ds=new C({props:{code:`issue_number = 2792
url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
response = requests.get(url, headers=headers)
response.json()`,highlighted:`issue_number = <span class="hljs-number">2792</span>
url = <span class="hljs-string">f&quot;https://api.github.com/repos/huggingface/datasets/issues/<span class="hljs-subst">{issue_number}</span>/comments&quot;</span>
response = requests.get(url, headers=headers)
response.json()`}}),Hs=new C({props:{code:`[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',
  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',
  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',
  'id': 897594128,
  'node_id': 'IC_kwDODunzps41gDMQ',
  'user': {'login': 'bhavitvyamalik',
   'id': 19718818,
   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',
   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',
   'gravatar_id': '',
   'url': 'https://api.github.com/users/bhavitvyamalik',
   'html_url': 'https://github.com/bhavitvyamalik',
   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',
   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',
   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',
   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',
   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',
   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',
   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',
   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',
   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',
   'type': 'User',
   'site_admin': False},
  'created_at': '2021-08-12T12:21:52Z',
  'updated_at': '2021-08-12T12:31:17Z',
  'author_association': 'CONTRIBUTOR',
  'body': "@albertvillanova my tests are failing here:\\r\\n\`\`\`\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n\`\`\`\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?",
  'performed_via_github_app': None}]`,highlighted:`[{<span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/comments/897594128&#x27;</span>,
  <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128&#x27;</span>,
  <span class="hljs-string">&#x27;issue_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/repos/huggingface/datasets/issues/2792&#x27;</span>,
  <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">897594128</span>,
  <span class="hljs-string">&#x27;node_id&#x27;</span>: <span class="hljs-string">&#x27;IC_kwDODunzps41gDMQ&#x27;</span>,
  <span class="hljs-string">&#x27;user&#x27;</span>: {<span class="hljs-string">&#x27;login&#x27;</span>: <span class="hljs-string">&#x27;bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-number">19718818</span>,
   <span class="hljs-string">&#x27;node_id&#x27;</span>: <span class="hljs-string">&#x27;MDQ6VXNlcjE5NzE4ODE4&#x27;</span>,
   <span class="hljs-string">&#x27;avatar_url&#x27;</span>: <span class="hljs-string">&#x27;https://avatars.githubusercontent.com/u/19718818?v=4&#x27;</span>,
   <span class="hljs-string">&#x27;gravatar_id&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
   <span class="hljs-string">&#x27;url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;html_url&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/bhavitvyamalik&#x27;</span>,
   <span class="hljs-string">&#x27;followers_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/followers&#x27;</span>,
   <span class="hljs-string">&#x27;following_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/following{/other_user}&#x27;</span>,
   <span class="hljs-string">&#x27;gists_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/gists{/gist_id}&#x27;</span>,
   <span class="hljs-string">&#x27;starred_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}&#x27;</span>,
   <span class="hljs-string">&#x27;subscriptions_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/subscriptions&#x27;</span>,
   <span class="hljs-string">&#x27;organizations_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/orgs&#x27;</span>,
   <span class="hljs-string">&#x27;repos_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/repos&#x27;</span>,
   <span class="hljs-string">&#x27;events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/events{/privacy}&#x27;</span>,
   <span class="hljs-string">&#x27;received_events_url&#x27;</span>: <span class="hljs-string">&#x27;https://api.github.com/users/bhavitvyamalik/received_events&#x27;</span>,
   <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;User&#x27;</span>,
   <span class="hljs-string">&#x27;site_admin&#x27;</span>: <span class="hljs-literal">False</span>},
  <span class="hljs-string">&#x27;created_at&#x27;</span>: <span class="hljs-string">&#x27;2021-08-12T12:21:52Z&#x27;</span>,
  <span class="hljs-string">&#x27;updated_at&#x27;</span>: <span class="hljs-string">&#x27;2021-08-12T12:31:17Z&#x27;</span>,
  <span class="hljs-string">&#x27;author_association&#x27;</span>: <span class="hljs-string">&#x27;CONTRIBUTOR&#x27;</span>,
  <span class="hljs-string">&#x27;body&#x27;</span>: <span class="hljs-string">&quot;@albertvillanova my tests are failing here:\\r\\n\`\`\`\\r\\ndataset_name = &#x27;gooaq&#x27;\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n&gt;       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) &gt; 0)\\r\\nE   AssertionError: False is not true\\r\\n\`\`\`\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?&quot;</span>,
  <span class="hljs-string">&#x27;performed_via_github_app&#x27;</span>: <span class="hljs-literal">None</span>}]`}}),Os=new C({props:{code:`def get_comments(issue_number):
    url = f"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments"
    response = requests.get(url, headers=headers)
    return [r["body"] for r in response.json()]


# Testiamo la nostra funzione
get_comments(2792)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_comments</span>(<span class="hljs-params">issue_number</span>):
    url = <span class="hljs-string">f&quot;https://api.github.com/repos/huggingface/datasets/issues/<span class="hljs-subst">{issue_number}</span>/comments&quot;</span>
    response = requests.get(url, headers=headers)
    <span class="hljs-keyword">return</span> [r[<span class="hljs-string">&quot;body&quot;</span>] <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> response.json()]


<span class="hljs-comment"># Testiamo la nostra funzione</span>
get_comments(<span class="hljs-number">2792</span>)`}}),Cs=new C({props:{code:"[\"@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?\"]",highlighted:'[<span class="hljs-string">&quot;@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = &#x27;gooaq&#x27;\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n&gt;       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) &gt; 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?&quot;</span>]'}}),Ts=new C({props:{code:`# A seconda della tua connessione, potrebbe volerci qualche secondo...
issues_with_comments_dataset = issues_dataset.map(
    lambda x: {"comments": get_comments(x["number"])}
)`,highlighted:`<span class="hljs-comment"># A seconda della tua connessione, potrebbe volerci qualche secondo...</span>
issues_with_comments_dataset = issues_dataset.<span class="hljs-built_in">map</span>(
    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;comments&quot;</span>: get_comments(x[<span class="hljs-string">&quot;number&quot;</span>])}
)`}}),As=new C({props:{code:'issues_with_comments_dataset.to_json("issues-datasets-with-hf-doc-builder.jsonl")',highlighted:'issues_with_comments_dataset.to_json(<span class="hljs-string">&quot;issues-datasets-with-hf-doc-builder.jsonl&quot;</span>)'}}),Ns=new Ra({}),Is=new ad({props:{id:"HaN6qCr_Afc"}}),Rs=new C({props:{code:`from huggingface_hub import list_datasets

all_datasets = list_datasets()
print(f"Number of datasets on Hub: {len(all_datasets)}")
print(all_datasets[0])`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> list_datasets

all_datasets = list_datasets()
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Number of datasets on Hub: <span class="hljs-subst">{<span class="hljs-built_in">len</span>(all_datasets)}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(all_datasets[<span class="hljs-number">0</span>])`}}),Ss=new C({props:{code:`Number of datasets on Hub: 1487
Dataset Name: acronym_identification, Tags: ['annotations_creators:expert-generated', 'language_creators:found', 'languages:en', 'licenses:mit', 'multilinguality:monolingual', 'size_categories:10K<n<100K', 'source_datasets:original', 'task_categories:structure-prediction', 'task_ids:structure-prediction-other-acronym-identification']`,highlighted:`Number of datasets on Hub: <span class="hljs-number">1487</span>
Dataset Name: acronym_identification, Tags: [<span class="hljs-string">&#x27;annotations_creators:expert-generated&#x27;</span>, <span class="hljs-string">&#x27;language_creators:found&#x27;</span>, <span class="hljs-string">&#x27;languages:en&#x27;</span>, <span class="hljs-string">&#x27;licenses:mit&#x27;</span>, <span class="hljs-string">&#x27;multilinguality:monolingual&#x27;</span>, <span class="hljs-string">&#x27;size_categories:10K&lt;n&lt;100K&#x27;</span>, <span class="hljs-string">&#x27;source_datasets:original&#x27;</span>, <span class="hljs-string">&#x27;task_categories:structure-prediction&#x27;</span>, <span class="hljs-string">&#x27;task_ids:structure-prediction-other-acronym-identification&#x27;</span>]`}}),Us=new C({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Ls=new C({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),Ms=new C({props:{code:`from huggingface_hub import create_repo

repo_url = create_repo(name="github-issues", repo_type="dataset")
repo_url`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> create_repo

repo_url = create_repo(name=<span class="hljs-string">&quot;github-issues&quot;</span>, repo_type=<span class="hljs-string">&quot;dataset&quot;</span>)
repo_url`}}),Fs=new C({props:{code:"'https://huggingface.co/datasets/lewtun/github-issues'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/datasets/lewtun/github-issues&#x27;</span>'}}),Re=new na({props:{$$slots:{default:[od]},$$scope:{ctx:S}}}),Bs=new C({props:{code:`from huggingface_hub import Repository

repo = Repository(local_dir="github-issues", clone_from=repo_url)
!cp issues-datasets-with-hf-doc-builder.jsonl github-issues/`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository

repo = Repository(local_dir=<span class="hljs-string">&quot;github-issues&quot;</span>, clone_from=repo_url)
!cp issues-datasets-<span class="hljs-keyword">with</span>-hf-doc-builder.jsonl github-issues/`}}),Qs=new C({props:{code:'repo.lfs_track("*.jsonl")',highlighted:'repo.lfs_track(<span class="hljs-string">&quot;*.jsonl&quot;</span>)'}}),Js=new C({props:{code:"repo.push_to_hub()",highlighted:"repo.push_to_hub()"}}),Ks=new C({props:{code:`remote_dataset = load_dataset("lewtun/github-issues", split="train")
remote_dataset`,highlighted:`remote_dataset = load_dataset(<span class="hljs-string">&quot;lewtun/github-issues&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
remote_dataset`}}),Xs=new C({props:{code:`Dataset({
    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'performed_via_github_app', 'is_pull_request'],
    num_rows: 2855
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;url&#x27;</span>, <span class="hljs-string">&#x27;repository_url&#x27;</span>, <span class="hljs-string">&#x27;labels_url&#x27;</span>, <span class="hljs-string">&#x27;comments_url&#x27;</span>, <span class="hljs-string">&#x27;events_url&#x27;</span>, <span class="hljs-string">&#x27;html_url&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;node_id&#x27;</span>, <span class="hljs-string">&#x27;number&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;state&#x27;</span>, <span class="hljs-string">&#x27;locked&#x27;</span>, <span class="hljs-string">&#x27;assignee&#x27;</span>, <span class="hljs-string">&#x27;assignees&#x27;</span>, <span class="hljs-string">&#x27;milestone&#x27;</span>, <span class="hljs-string">&#x27;comments&#x27;</span>, <span class="hljs-string">&#x27;created_at&#x27;</span>, <span class="hljs-string">&#x27;updated_at&#x27;</span>, <span class="hljs-string">&#x27;closed_at&#x27;</span>, <span class="hljs-string">&#x27;author_association&#x27;</span>, <span class="hljs-string">&#x27;active_lock_reason&#x27;</span>, <span class="hljs-string">&#x27;pull_request&#x27;</span>, <span class="hljs-string">&#x27;body&#x27;</span>, <span class="hljs-string">&#x27;performed_via_github_app&#x27;</span>, <span class="hljs-string">&#x27;is_pull_request&#x27;</span>],
    num_rows: <span class="hljs-number">2855</span>
})`}}),Fe=new na({props:{$$slots:{default:[nd]},$$scope:{ctx:S}}}),Ws=new Ra({}),Ve=new na({props:{$$slots:{default:[ud]},$$scope:{ctx:S}}}),Ze=new na({props:{$$slots:{default:[pd]},$$scope:{ctx:S}}}),{c(){d=r("meta"),z=p(),h=r("h1"),y=r("a"),w=r("span"),f(g.$$.fragment),q=p(),P=r("span"),j=t("Creare il proprio dataset"),E=p(),f(H.$$.fragment),D=p(),O=r("p"),A=t("A volte il dataset che ti serve per la tua applicazione NLP non esiste, per cui dovrai crearlo da te. In questa sezione ti mostreremo come creare un corpus di "),k=r("a"),T=t("issue da GitHub"),B=t(", usate solitamente per tenere traccia dei bug e delle feature nelle repository su GitHub. Questo corpus pu\xF2 essere usato in diversi modi, ad esempio:"),R=p(),N=r("ul"),Q=r("li"),pe=t("Esplorare il tempo impiegato per chiudere un issue, o per effettuare dei pull"),I=p(),X=r("li"),ua=t("Addestrare un "),ve=r("em"),pa=t("classificatore multiclasse"),ca=t(" che assegna a ogni issue dei metadati sulla base della descrizione dell\u2019issue (ad esempio, \u201Cbug\u201D, \u201Cenhancement\u201D, \u201Cquestion\u201D)"),da=p(),Sa=r("li"),dr=t("Creare un motore di ricerca semantico per trovare quale issue corrisponde a una richiesta dell\u2019utente"),ti=p(),ma=r("p"),mr=t("Ci focalizzeremo sulla creazione del corpus, e nella prossima sezione affronteremo la creazione di un motore di ricerca semantico. Useremo gli issue GitHub associate a un progetto open source molto popolare: \u{1F917} Datasets! Diamo un\u2019occhiata a come recuperare i dati e come esplorare le informazioni contenute negli issue."),ii=p(),ce=r("h2"),xe=r("a"),Ua=r("span"),f(es.$$.fragment),hr=p(),La=r("span"),gr=t("Recuperare i dati"),li=p(),$e=r("p"),fr=t("Puoi trovare tutte gli issue in \u{1F917} Datasets navigando nella "),ss=r("a"),_r=t("sezione Issues della repository"),br=t(". Come si vede dallo screenshot, al momento della scrittura c\u2019erano 331 issue aperti e 668 issue chiusi."),ri=p(),as=r("div"),ts=r("img"),oi=p(),ha=r("p"),vr=t("Se clicchi su una di questi issue vedrai che contiene un titolo, una descrizione, e un set di etichette che caratterizzano l\u2019issue. Un esempio \xE8 mostrato nello screenshot successivo."),ni=p(),is=r("div"),ls=r("img"),ui=p(),W=r("p"),xr=t("Per scaricare gli issue della repository, useremo la "),rs=r("a"),$r=t("REST API di GitHub"),jr=t(" per interrogare l\u2019"),je=r("a"),Er=t("endpoint "),Ma=r("code"),yr=t("Issues"),qr=t(". Questo endpoint restituisce una lista di oggetti JSON, e ogni oggetto contiene un gran numero di campi, tra cui il titolo e la descrizione, cos\xEC come dei metadati circo lo status dell\u2019issue e altro ancora."),pi=p(),Ee=r("p"),wr=t("Una maniera conveniente di scaricare gli issue \xE8 attraverso la libreria "),Fa=r("code"),kr=t("requests"),zr=t(", che rappresenta il metodo standard di fare richieste HTTP su Python. Puoi installa la libreria attraverso il codice:"),ci=p(),f(os.$$.fragment),di=p(),Y=r("p"),Pr=t("Una volta che la libreria \xE8 stata installata, puoi effettuare una richiesta GET all\u2019endpoint "),Ba=r("code"),Dr=t("Issues"),Hr=t(" utilizzando la funzione "),Qa=r("code"),Or=t("requests.get()"),Cr=t(". Ad esempio, puoi eseguire il comando mostrato di seguito per recuperare il primo issue nella prima pagina:"),mi=p(),f(ns.$$.fragment),hi=p(),ye=r("p"),Tr=t("L\u2019oggetto "),Ja=r("code"),Ar=t("response"),Nr=t(" contiene un sacco di informazioni utili sulla richiesta, compreso il codice di stato HTTP:"),gi=p(),f(us.$$.fragment),fi=p(),f(ps.$$.fragment),_i=p(),J=r("p"),Ir=t("Lo status "),Va=r("code"),Gr=t("200"),Rr=t(" indica che la richiesta ha avuto buon fine (puoi trovare una lista di codici di stato HTTTP "),cs=r("a"),Sr=t("qui"),Ur=t("). Ma ci\xF2 che ci interessa davvero \xE8 il "),Za=r("em"),Lr=t("payload"),Mr=t(", a cui \xE8 possibile accedere utilizzando diversi formati come byte, stringh, o JSON. Visto che sappiamo che i nostri issue sono in formato JSON, diamo un\u2019occhiata al payload come segue:"),bi=p(),f(ds.$$.fragment),vi=p(),f(ms.$$.fragment),xi=p(),V=r("p"),Fr=t("Wow, quante informazioni! Possiamo vedere alcuni campi utili come "),Ka=r("code"),Br=t("title"),Qr=t(", "),Xa=r("code"),Jr=t("body"),Vr=t(" e "),Wa=r("code"),Zr=t("number"),Kr=t(" che descrivono l\u2019issue, cos\xEC come informazioni sull\u2019utente che l\u2019ha aperto."),$i=p(),f(qe.$$.fragment),ji=p(),U=r("p"),Xr=t("Come descritto nella "),hs=r("a"),Wr=t("documentazione di GitHub"),Yr=t(", le richieste senza autenticazione sono limitate a 60 ogni ora. Bench\xE9 possiamo aumentare il parametro della query "),Ya=r("code"),eo=t("per_page"),so=t(" per ridurre il numero di richieste, raggiungerai comunque il limite su qualunque repository che ha qualche migliaio di issue. Quindi, dovresti seguire le "),gs=r("a"),ao=t("istruzioni"),to=t(" su come creare un "),et=r("em"),io=t("token di accesso personale"),lo=t(" cos\xEC che puoi aumentare il limite a 5.000 richieste ogni ora. Una volta che hai ottenuto il tuo token, puoi includerlo come parte dell\u2019header della richiesta:"),Ei=p(),f(fs.$$.fragment),yi=p(),f(we.$$.fragment),qi=p(),ga=r("p"),ro=t("Ora che abbiamo il nostro token di accesso, creiamo una funzione che scarichi tutti gli issue da una repository GitHub:"),wi=p(),f(_s.$$.fragment),ki=p(),ee=r("p"),oo=t("Ora quando eseguiremo "),st=r("code"),no=t("fetch_issues()"),uo=t(", scaricher\xE0 tutti gli issue in batch per evitare di superare il limite di GitHub del numero di richieste per ora; il risultato sar\xE0 conservato in un file "),at=r("em"),po=t("repository_name-issues.jsonl"),co=t(", in cui ogni linea \xE8 un oggetto JSON che rappresenta un issue. Usiamo questa funzione per recuperare tutti gli issue da \u{1F917} Datasets:"),zi=p(),f(bs.$$.fragment),Pi=p(),ke=r("p"),mo=t("Una volta che gli issue sono stati scaricati, possiamo caricarli in locale usando le nuove abilit\xE0 imparate nella "),fa=r("a"),ho=t("sezione 2"),go=t(":"),Di=p(),f(vs.$$.fragment),Hi=p(),f(xs.$$.fragment),Oi=p(),se=r("p"),fo=t("Benissimo, abbiamo creato il nostro primo dataset da zero! Ma perch\xE9 ci sono migliaia di issue quando la "),$s=r("a"),_o=t("sezione Issues"),bo=t(" della repository \u{1F917} Datasets mostra circa 1,000 issue in totale \u{1F914}? Come indicato nella "),js=r("a"),vo=t("documentazione di GitHub"),xo=t(", \xE8 perch\xE9 abbiamo scaricato anche le richieste di pull:"),Ci=p(),_a=r("blockquote"),de=r("p"),$o=t("GitHub\u2019s REST API v3 considers every pull request an issue, but not every issue is a pull request. For this reason, \u201CIssues\u201D endpoints may return both issues and pull requests in the response. You can identify pull requests by the "),tt=r("code"),jo=t("pull_request"),Eo=t(" key. Be aware that the "),it=r("code"),yo=t("id"),qo=t(" of a pull request returned from \u201CIssues\u201D endpoints will be an issue id."),Ti=p(),ze=r("p"),wo=t("("),K=r("em"),ko=t("La REST API v3 di GitHub considera ogni richiesta di pull un issue, ma non ogni issue \xE8 una richiesta di pull. Per questa ragione, gli endpoint \u201CIssues\u201D potrebbe tornare sia gli issue che le richieste di pull. \xC8 possibile identificare le richieste di pull utilizzando la chiave "),lt=r("code"),zo=t("pull_request"),Po=t(". Tieni presente che l\u2019"),rt=r("code"),Do=t("id"),Ho=t(" di una richiesta di pull resituita dagli endpoint "),ot=r("code"),Oo=t("Issues"),Co=t(" sar\xE0 un id di un issue."),To=t(")"),Ai=p(),ba=r("p"),Ao=t("Poich\xE8 i contenuti degli issue e delle richieste di pull sono molto diversi, facciamo un po\u2019 di preprocessing per permetterci di distinguere tra i due."),Ni=p(),me=r("h2"),Pe=r("a"),nt=r("span"),f(Es.$$.fragment),No=p(),ut=r("span"),Io=t("Pulire i dati"),Ii=p(),G=r("p"),Go=t("Il frammento precedente della documentazione di GitHub ci dice che la colonna "),pt=r("code"),Ro=t("pull_request"),So=t(" pu\xF2 essere utilizzata per distinguere gli issue e le richieste di pull. Diamo uno sguardo a un esempio casuale per vedere qual \xE8 la differenza. Come abbiamo fatto nella "),va=r("a"),Uo=t("sezione 3"),Lo=t(", concateneremo "),ct=r("code"),Mo=t("Dataset.shuffle()"),Fo=t(" e "),dt=r("code"),Bo=t("Dataset.select()"),Qo=t(" per creare un campione random, e poi zipperemo le colonne "),mt=r("code"),Jo=t("html_url"),Vo=t(" e "),ht=r("code"),Zo=t("pull_request"),Ko=t(" cos\xEC da poter paragonare i diversi URL:"),Gi=p(),f(ys.$$.fragment),Ri=p(),f(qs.$$.fragment),Si=p(),L=r("p"),Xo=t("Possiamo vedere che ogni richiesta di pull \xE8 associata a diversi URL, mentre i comuni issue hanno un\u2019entrata "),gt=r("code"),Wo=t("None"),Yo=t(". Possiamo usare questa distinzione per crare una nuova colonna "),ft=r("code"),en=t("is_pull_request"),sn=t(" che controlla se il campo "),_t=r("code"),an=t("pull_request"),tn=t(" sia "),bt=r("code"),ln=t("None"),rn=t(" o meno:"),Ui=p(),f(ws.$$.fragment),Li=p(),f(De.$$.fragment),Mi=p(),xa=r("p"),on=t("Bench\xE9 potremmo procedere e pulire ulteriormente il dataset eliminando o rinominando alcune colonne, \xE8 solitamente buona prassi lasciare il dataset quando pi\xF9 intatto \xE8 possibile in questo stadio, cos\xEC che pu\xF2 essere utilizzato facilmente in pi\xF9 applicazioni."),Fi=p(),$a=r("p"),nn=t("Prima di caricare il nostro dataset sull\u2019Hub Hugging Face, dobbiamo occuparci di una cosa che manca: i commenti associati a ogni issue e richiesta di pull. Hai indovinato, li aggiungeremo utilizzando la REST API di GitHub!"),Bi=p(),he=r("h2"),He=r("a"),vt=r("span"),f(ks.$$.fragment),un=p(),xt=r("span"),pn=t("Estendere il dataset"),Qi=p(),ja=r("p"),cn=t("Come mostrato negli screenshot di seguito, i commenti associati a un issue o una richiesta di pull offrono una fonte molto ricca di informazioni, soprattutto se siamo interessati a costruire un motore di ricerca per rispondere alle richieste degli utenti sulla libreria."),Ji=p(),zs=r("div"),Ps=r("img"),Vi=p(),Oe=r("p"),dn=t("La REST API di GitHub offre un "),Ce=r("a"),mn=t("endpoint "),$t=r("code"),hn=t("Comments"),gn=t(" che restituisce tutti i commenti associati con un numero di issue. Testiamo quest\u2019endpoint per vedere cosa restituisce:"),Zi=p(),f(Ds.$$.fragment),Ki=p(),f(Hs.$$.fragment),Xi=p(),Z=r("p"),fn=t("Possiamo vedere che il commento \xE8 archiviato nel campo "),jt=r("code"),_n=t("body"),bn=t(", quindi possiamo scvrivere una semplice funzione che restituisce tutti i commenti associati con un issue estraendo i contenuti di "),Et=r("code"),vn=t("body"),xn=t(" per ogni elemento in "),yt=r("code"),$n=t("response.json()"),jn=t(":"),Wi=p(),f(Os.$$.fragment),Yi=p(),f(Cs.$$.fragment),el=p(),ae=r("p"),En=t("Sembra andar bene, quindi possiamo usare "),qt=r("code"),yn=t("Dataset.map()"),qn=t(" per aggiungere una nuova colonna "),wt=r("code"),wn=t("comments"),kn=t(" a ogni usse nel nostro dataset:"),sl=p(),f(Ts.$$.fragment),al=p(),Ea=r("p"),zn=t("Come passaggio finale, salviamo il dataset esteso assieme ai nostri dati non processati, cos\xEC da poter caricare entrambi sull\u2019Hub:"),tl=p(),f(As.$$.fragment),il=p(),ge=r("h2"),Te=r("a"),kt=r("span"),f(Ns.$$.fragment),Pn=p(),zt=r("span"),Dn=t("Caricare il dataset sull'Hub Hugging Face"),ll=p(),f(Is.$$.fragment),rl=p(),te=r("p"),Hn=t("Ora che abbiamo il nostro dataset esteso, \xE8 arrivato il momento di caricarlo sull\u2019Hub, cos\xEC da poterlo condividere con la community! Per caricare il dataset useremo la "),Gs=r("a"),On=t("libreria \u{1F917} Hub"),Cn=t(", che ci permette di interagire con l\u2019Hub di Hugging Face attraverso un\u2019API di Python. \u{1F917} Hub \xE8 preinstallato con \u{1F917} Transformers, cos\xEC possiamo usarlo da subito. Ad esempio, possiamo usare la funzione "),Pt=r("code"),Tn=t("list_datastes()"),An=t(" per avere informazioni su tutti i dataset pubblici attualmente presenti sull\u2019Hub:"),ol=p(),f(Rs.$$.fragment),nl=p(),f(Ss.$$.fragment),ul=p(),Ae=r("p"),Nn=t("Possiamo vedere che al momento ci sono circa 1.500 dataset sull\u2019Hub, e la funzione "),Dt=r("code"),In=t("list_datasets()"),Gn=t(" inoltre permette di avere alcuni metadati su ciascuna repository."),pl=p(),Ne=r("p"),Rn=t("Per ci\xF2 che ci riguarda, la prima cosa che dobbiamo fare \xE8 crare una nuova repository nell\u2019Hub. Per far ci\xF2 abbiamo bisogno di un token di autentificazione, che pou\xF2 essere ottenuto effettuando l\u2019accesso nell\u2019Hub Hugging Face con la funzione "),Ht=r("code"),Sn=t("notebook_login()"),Un=t(":"),cl=p(),f(Us.$$.fragment),dl=p(),Ie=r("p"),Ln=t("Questo creer\xE0 un widget in cui puoi inserire il tuo username e la tua password, e un token API verr\xE0 salvato in "),Ot=r("em"),Mn=t("~/.huggingface/token"),Fn=t(". Se stai eseguendo il codice in un terminale, puoi effettuare l\u2019accesso attraverso il comando:"),ml=p(),f(Ls.$$.fragment),hl=p(),Ge=r("p"),Bn=t("Una volta fatto questo, possiamo crare una nuova repository con la funzione "),Ct=r("code"),Qn=t("create_repo()"),Jn=t(":"),gl=p(),f(Ms.$$.fragment),fl=p(),f(Fs.$$.fragment),_l=p(),ie=r("p"),Vn=t("In quest\u2019esempio, abbiamo creato una repository vuota chiamata "),Tt=r("code"),Zn=t("github-issues"),Kn=t(" con l\u2019username "),At=r("code"),Xn=t("lewtun"),Wn=t(" (l\u2019username dovrebbe essere quello del tuo account Hub quando esegui questo codice!)."),bl=p(),f(Re.$$.fragment),vl=p(),Se=r("p"),Yn=t("Ora, cloniamo la repository dall\u2019Hub alla nostra macchina e copiamo al suo interno i file del nostro dataset. \u{1F917} Hub contiene una classe "),Nt=r("code"),eu=t("Repository"),su=t(" che ha al suo interno molti dei comandi pi\xF9 comuni di Git, per cui per clonare la repository in remoto dobbiamo semplicemente fornire l\u2019URL e il percorso locale in cui desideriamo clonare:"),xl=p(),f(Bs.$$.fragment),$l=p(),M=r("p"),au=t("Di default, diverse estensioni file (ad esempio "),It=r("em"),tu=t(".bin"),iu=t(", "),Gt=r("em"),lu=t(".gz"),ru=t(" e "),Rt=r("em"),ou=t(".zip"),nu=t(") sono registrate da Git LFS, cos\xEC che i file di grandi dimensioni possono essere gestiti all\u2019interno dello stesso workflow. Puoi trovare una lista delle estensioni di file monitorati nel file "),St=r("em"),uu=t(".gitattributes"),pu=t(" della repository. Per includere il formato JSON Lines a questa lista, possiamo utilizzare il comando:"),jl=p(),f(Qs.$$.fragment),El=p(),Ue=r("p"),cu=t("Ora possiamo usare "),Ut=r("code"),du=t("Repository.push_to_hub()"),mu=t(" per caricare il dataset sull\u2019Hub:"),yl=p(),f(Js.$$.fragment),ql=p(),Le=r("p"),hu=t("Se navighiamo fino all\u2019URL contenuto in "),Lt=r("code"),gu=t("repo_url"),fu=t(", vedremo che il file del nostro dataset \xE8 stato caricato."),wl=p(),Vs=r("div"),Zs=r("img"),kl=p(),le=r("p"),_u=t("Da qui, chiunque pu\xF2 scaricare il dataset semplicemente inserendo l\u2019ID della repository come argomento "),Mt=r("code"),bu=t("path"),vu=t(" di "),Ft=r("code"),xu=t("load_dataset()"),$u=t(":"),zl=p(),f(Ks.$$.fragment),Pl=p(),f(Xs.$$.fragment),Dl=p(),Me=r("p"),ju=t("Bene, abbiamo caricato il nostro dataset sull\u2019Hub, e pu\xF2 essere utilizzato da tutti! C\u2019\xE8 un\u2019altra cosa importante che dobbiamo fare: aggiungere una "),Bt=r("em"),Eu=t("dataset card"),yu=t(" che spiega come \xE8 stato creato il corpus, e offre altre informazioni utili per la community."),Hl=p(),f(Fe.$$.fragment),Ol=p(),fe=r("h2"),Be=r("a"),Qt=r("span"),f(Ws.$$.fragment),qu=p(),Jt=r("span"),wu=t("Creare una dataset card"),Cl=p(),ya=r("p"),ku=t("I dataset ben-documentati sono pi\xF9 utili agli altri utenti (compreso il futuro te!), poich\xE9 spiegano il contesto per permettere agli utenti di decidere se un dataset pu\xF2 essere utile, e valutare gli eventuali bias o rischi associati nell\u2019utilizzo del dataset."),Tl=p(),Qe=r("p"),zu=t("Sull\u2019Hug di Hugging Face, queste informazioni si trovano nel file "),Vt=r("em"),Pu=t("README.md"),Du=t(" della repository. Ci sono due passaggi principali che dovresti seguire prima di creare questo file:"),Al=p(),qa=r("ol"),_e=r("li"),Hu=t("Usa l\u2019"),Je=r("a"),Ou=t("applicatione "),Zt=r("code"),Cu=t("datasets-tagging"),Tu=t(" per creare tag di metadati in formato YAML. Questi tag sono usato per una serie di funzioni di ricerca sull\u2019Hub di Hugging Face, e assicurano che il tuo dataset possa essere facilmente trovato dai membri della community. Poich\xE8 abbiamo creato un nostro dataset, dovrai clonare la repository "),Kt=r("code"),Au=t("datasets-tagging"),Nu=t(", ed eseguire l\u2019applicazione in locale. Ecco com\u2019\xE8 l\u2019interfaccia:"),Nl=p(),Ys=r("div"),ea=r("img"),Il=p(),sa=r("ol"),aa=r("li"),Iu=t("Leggi la "),ta=r("a"),Gu=t("guida \u{1F917} Datasets"),Ru=t(" sulla creazione di dataset card informative, e usala come template."),Gl=p(),re=r("p"),Su=t("Puoi creare il file "),Xt=r("em"),Uu=t("README.md"),Lu=t(" direttamente sull\u2019Hub, e puoi trovare un modello per una dataset card nella repository "),Wt=r("code"),Mu=t("lewtun/github-issues"),Fu=t(". Di seguito \xE8 mostrato uno screenshot di una dataset card gi\xE0 compilata."),Rl=p(),ia=r("div"),la=r("img"),Sl=p(),f(Ve.$$.fragment),Ul=p(),wa=r("p"),Bu=t("\xC8 tutto! Abbiamo visto in questa sezione che creare un buon dataset pu\xF2 essere un\u2019impresa, ma per fortuna caricarlo e condividerlo con la community \xE8 molto pi\xF9 semplice. Nella prossima sezione useremo il nostro nuovo dataset per creare un motore di ricerca semantico con \u{1F917} Datasets, che abbina alle domande gli issue e i commenti pi\xF9 rilevanti."),Ll=p(),f(Ze.$$.fragment),this.h()},l(e){const l=ed('[data-svelte="svelte-1phssyn"]',document.head);d=o(l,"META",{name:!0,content:!0}),l.forEach(a),z=c(e),h=o(e,"H1",{class:!0});var ra=n(h);y=o(ra,"A",{id:!0,class:!0,href:!0});var Yt=n(y);w=o(Yt,"SPAN",{});var ei=n(w);_(g.$$.fragment,ei),ei.forEach(a),Yt.forEach(a),q=c(ra),P=o(ra,"SPAN",{});var si=n(P);j=i(si,"Creare il proprio dataset"),si.forEach(a),ra.forEach(a),E=c(e),_(H.$$.fragment,e),D=c(e),O=o(e,"P",{});var oa=n(O);A=i(oa,"A volte il dataset che ti serve per la tua applicazione NLP non esiste, per cui dovrai crearlo da te. In questa sezione ti mostreremo come creare un corpus di "),k=o(oa,"A",{href:!0,rel:!0});var ai=n(k);T=i(ai,"issue da GitHub"),ai.forEach(a),B=i(oa,", usate solitamente per tenere traccia dei bug e delle feature nelle repository su GitHub. Questo corpus pu\xF2 essere usato in diversi modi, ad esempio:"),oa.forEach(a),R=c(e),N=o(e,"UL",{});var be=n(N);Q=o(be,"LI",{});var sp=n(Q);pe=i(sp,"Esplorare il tempo impiegato per chiudere un issue, o per effettuare dei pull"),sp.forEach(a),I=c(be),X=o(be,"LI",{});var Fl=n(X);ua=i(Fl,"Addestrare un "),ve=o(Fl,"EM",{});var ap=n(ve);pa=i(ap,"classificatore multiclasse"),ap.forEach(a),ca=i(Fl," che assegna a ogni issue dei metadati sulla base della descrizione dell\u2019issue (ad esempio, \u201Cbug\u201D, \u201Cenhancement\u201D, \u201Cquestion\u201D)"),Fl.forEach(a),da=c(be),Sa=o(be,"LI",{});var tp=n(Sa);dr=i(tp,"Creare un motore di ricerca semantico per trovare quale issue corrisponde a una richiesta dell\u2019utente"),tp.forEach(a),be.forEach(a),ti=c(e),ma=o(e,"P",{});var ip=n(ma);mr=i(ip,"Ci focalizzeremo sulla creazione del corpus, e nella prossima sezione affronteremo la creazione di un motore di ricerca semantico. Useremo gli issue GitHub associate a un progetto open source molto popolare: \u{1F917} Datasets! Diamo un\u2019occhiata a come recuperare i dati e come esplorare le informazioni contenute negli issue."),ip.forEach(a),ii=c(e),ce=o(e,"H2",{class:!0});var Bl=n(ce);xe=o(Bl,"A",{id:!0,class:!0,href:!0});var lp=n(xe);Ua=o(lp,"SPAN",{});var rp=n(Ua);_(es.$$.fragment,rp),rp.forEach(a),lp.forEach(a),hr=c(Bl),La=o(Bl,"SPAN",{});var op=n(La);gr=i(op,"Recuperare i dati"),op.forEach(a),Bl.forEach(a),li=c(e),$e=o(e,"P",{});var Ql=n($e);fr=i(Ql,"Puoi trovare tutte gli issue in \u{1F917} Datasets navigando nella "),ss=o(Ql,"A",{href:!0,rel:!0});var np=n(ss);_r=i(np,"sezione Issues della repository"),np.forEach(a),br=i(Ql,". Come si vede dallo screenshot, al momento della scrittura c\u2019erano 331 issue aperti e 668 issue chiusi."),Ql.forEach(a),ri=c(e),as=o(e,"DIV",{class:!0});var up=n(as);ts=o(up,"IMG",{src:!0,alt:!0,width:!0}),up.forEach(a),oi=c(e),ha=o(e,"P",{});var pp=n(ha);vr=i(pp,"Se clicchi su una di questi issue vedrai che contiene un titolo, una descrizione, e un set di etichette che caratterizzano l\u2019issue. Un esempio \xE8 mostrato nello screenshot successivo."),pp.forEach(a),ni=c(e),is=o(e,"DIV",{class:!0});var cp=n(is);ls=o(cp,"IMG",{src:!0,alt:!0,width:!0}),cp.forEach(a),ui=c(e),W=o(e,"P",{});var ka=n(W);xr=i(ka,"Per scaricare gli issue della repository, useremo la "),rs=o(ka,"A",{href:!0,rel:!0});var dp=n(rs);$r=i(dp,"REST API di GitHub"),dp.forEach(a),jr=i(ka," per interrogare l\u2019"),je=o(ka,"A",{href:!0,rel:!0});var Qu=n(je);Er=i(Qu,"endpoint "),Ma=o(Qu,"CODE",{});var mp=n(Ma);yr=i(mp,"Issues"),mp.forEach(a),Qu.forEach(a),qr=i(ka,". Questo endpoint restituisce una lista di oggetti JSON, e ogni oggetto contiene un gran numero di campi, tra cui il titolo e la descrizione, cos\xEC come dei metadati circo lo status dell\u2019issue e altro ancora."),ka.forEach(a),pi=c(e),Ee=o(e,"P",{});var Jl=n(Ee);wr=i(Jl,"Una maniera conveniente di scaricare gli issue \xE8 attraverso la libreria "),Fa=o(Jl,"CODE",{});var hp=n(Fa);kr=i(hp,"requests"),hp.forEach(a),zr=i(Jl,", che rappresenta il metodo standard di fare richieste HTTP su Python. Puoi installa la libreria attraverso il codice:"),Jl.forEach(a),ci=c(e),_(os.$$.fragment,e),di=c(e),Y=o(e,"P",{});var za=n(Y);Pr=i(za,"Una volta che la libreria \xE8 stata installata, puoi effettuare una richiesta GET all\u2019endpoint "),Ba=o(za,"CODE",{});var gp=n(Ba);Dr=i(gp,"Issues"),gp.forEach(a),Hr=i(za," utilizzando la funzione "),Qa=o(za,"CODE",{});var fp=n(Qa);Or=i(fp,"requests.get()"),fp.forEach(a),Cr=i(za,". Ad esempio, puoi eseguire il comando mostrato di seguito per recuperare il primo issue nella prima pagina:"),za.forEach(a),mi=c(e),_(ns.$$.fragment,e),hi=c(e),ye=o(e,"P",{});var Vl=n(ye);Tr=i(Vl,"L\u2019oggetto "),Ja=o(Vl,"CODE",{});var _p=n(Ja);Ar=i(_p,"response"),_p.forEach(a),Nr=i(Vl," contiene un sacco di informazioni utili sulla richiesta, compreso il codice di stato HTTP:"),Vl.forEach(a),gi=c(e),_(us.$$.fragment,e),fi=c(e),_(ps.$$.fragment,e),_i=c(e),J=o(e,"P",{});var Ke=n(J);Ir=i(Ke,"Lo status "),Va=o(Ke,"CODE",{});var bp=n(Va);Gr=i(bp,"200"),bp.forEach(a),Rr=i(Ke," indica che la richiesta ha avuto buon fine (puoi trovare una lista di codici di stato HTTTP "),cs=o(Ke,"A",{href:!0,rel:!0});var vp=n(cs);Sr=i(vp,"qui"),vp.forEach(a),Ur=i(Ke,"). Ma ci\xF2 che ci interessa davvero \xE8 il "),Za=o(Ke,"EM",{});var xp=n(Za);Lr=i(xp,"payload"),xp.forEach(a),Mr=i(Ke,", a cui \xE8 possibile accedere utilizzando diversi formati come byte, stringh, o JSON. Visto che sappiamo che i nostri issue sono in formato JSON, diamo un\u2019occhiata al payload come segue:"),Ke.forEach(a),bi=c(e),_(ds.$$.fragment,e),vi=c(e),_(ms.$$.fragment,e),xi=c(e),V=o(e,"P",{});var Xe=n(V);Fr=i(Xe,"Wow, quante informazioni! Possiamo vedere alcuni campi utili come "),Ka=o(Xe,"CODE",{});var $p=n(Ka);Br=i($p,"title"),$p.forEach(a),Qr=i(Xe,", "),Xa=o(Xe,"CODE",{});var jp=n(Xa);Jr=i(jp,"body"),jp.forEach(a),Vr=i(Xe," e "),Wa=o(Xe,"CODE",{});var Ep=n(Wa);Zr=i(Ep,"number"),Ep.forEach(a),Kr=i(Xe," che descrivono l\u2019issue, cos\xEC come informazioni sull\u2019utente che l\u2019ha aperto."),Xe.forEach(a),$i=c(e),_(qe.$$.fragment,e),ji=c(e),U=o(e,"P",{});var oe=n(U);Xr=i(oe,"Come descritto nella "),hs=o(oe,"A",{href:!0,rel:!0});var yp=n(hs);Wr=i(yp,"documentazione di GitHub"),yp.forEach(a),Yr=i(oe,", le richieste senza autenticazione sono limitate a 60 ogni ora. Bench\xE9 possiamo aumentare il parametro della query "),Ya=o(oe,"CODE",{});var qp=n(Ya);eo=i(qp,"per_page"),qp.forEach(a),so=i(oe," per ridurre il numero di richieste, raggiungerai comunque il limite su qualunque repository che ha qualche migliaio di issue. Quindi, dovresti seguire le "),gs=o(oe,"A",{href:!0,rel:!0});var wp=n(gs);ao=i(wp,"istruzioni"),wp.forEach(a),to=i(oe," su come creare un "),et=o(oe,"EM",{});var kp=n(et);io=i(kp,"token di accesso personale"),kp.forEach(a),lo=i(oe," cos\xEC che puoi aumentare il limite a 5.000 richieste ogni ora. Una volta che hai ottenuto il tuo token, puoi includerlo come parte dell\u2019header della richiesta:"),oe.forEach(a),Ei=c(e),_(fs.$$.fragment,e),yi=c(e),_(we.$$.fragment,e),qi=c(e),ga=o(e,"P",{});var zp=n(ga);ro=i(zp,"Ora che abbiamo il nostro token di accesso, creiamo una funzione che scarichi tutti gli issue da una repository GitHub:"),zp.forEach(a),wi=c(e),_(_s.$$.fragment,e),ki=c(e),ee=o(e,"P",{});var Pa=n(ee);oo=i(Pa,"Ora quando eseguiremo "),st=o(Pa,"CODE",{});var Pp=n(st);no=i(Pp,"fetch_issues()"),Pp.forEach(a),uo=i(Pa,", scaricher\xE0 tutti gli issue in batch per evitare di superare il limite di GitHub del numero di richieste per ora; il risultato sar\xE0 conservato in un file "),at=o(Pa,"EM",{});var Dp=n(at);po=i(Dp,"repository_name-issues.jsonl"),Dp.forEach(a),co=i(Pa,", in cui ogni linea \xE8 un oggetto JSON che rappresenta un issue. Usiamo questa funzione per recuperare tutti gli issue da \u{1F917} Datasets:"),Pa.forEach(a),zi=c(e),_(bs.$$.fragment,e),Pi=c(e),ke=o(e,"P",{});var Zl=n(ke);mo=i(Zl,"Una volta che gli issue sono stati scaricati, possiamo caricarli in locale usando le nuove abilit\xE0 imparate nella "),fa=o(Zl,"A",{href:!0});var Hp=n(fa);ho=i(Hp,"sezione 2"),Hp.forEach(a),go=i(Zl,":"),Zl.forEach(a),Di=c(e),_(vs.$$.fragment,e),Hi=c(e),_(xs.$$.fragment,e),Oi=c(e),se=o(e,"P",{});var Da=n(se);fo=i(Da,"Benissimo, abbiamo creato il nostro primo dataset da zero! Ma perch\xE9 ci sono migliaia di issue quando la "),$s=o(Da,"A",{href:!0,rel:!0});var Op=n($s);_o=i(Op,"sezione Issues"),Op.forEach(a),bo=i(Da," della repository \u{1F917} Datasets mostra circa 1,000 issue in totale \u{1F914}? Come indicato nella "),js=o(Da,"A",{href:!0,rel:!0});var Cp=n(js);vo=i(Cp,"documentazione di GitHub"),Cp.forEach(a),xo=i(Da,", \xE8 perch\xE9 abbiamo scaricato anche le richieste di pull:"),Da.forEach(a),Ci=c(e),_a=o(e,"BLOCKQUOTE",{});var Tp=n(_a);de=o(Tp,"P",{});var Ha=n(de);$o=i(Ha,"GitHub\u2019s REST API v3 considers every pull request an issue, but not every issue is a pull request. For this reason, \u201CIssues\u201D endpoints may return both issues and pull requests in the response. You can identify pull requests by the "),tt=o(Ha,"CODE",{});var Ap=n(tt);jo=i(Ap,"pull_request"),Ap.forEach(a),Eo=i(Ha," key. Be aware that the "),it=o(Ha,"CODE",{});var Np=n(it);yo=i(Np,"id"),Np.forEach(a),qo=i(Ha," of a pull request returned from \u201CIssues\u201D endpoints will be an issue id."),Ha.forEach(a),Tp.forEach(a),Ti=c(e),ze=o(e,"P",{});var Kl=n(ze);wo=i(Kl,"("),K=o(Kl,"EM",{});var We=n(K);ko=i(We,"La REST API v3 di GitHub considera ogni richiesta di pull un issue, ma non ogni issue \xE8 una richiesta di pull. Per questa ragione, gli endpoint \u201CIssues\u201D potrebbe tornare sia gli issue che le richieste di pull. \xC8 possibile identificare le richieste di pull utilizzando la chiave "),lt=o(We,"CODE",{});var Ip=n(lt);zo=i(Ip,"pull_request"),Ip.forEach(a),Po=i(We,". Tieni presente che l\u2019"),rt=o(We,"CODE",{});var Gp=n(rt);Do=i(Gp,"id"),Gp.forEach(a),Ho=i(We," di una richiesta di pull resituita dagli endpoint "),ot=o(We,"CODE",{});var Rp=n(ot);Oo=i(Rp,"Issues"),Rp.forEach(a),Co=i(We," sar\xE0 un id di un issue."),We.forEach(a),To=i(Kl,")"),Kl.forEach(a),Ai=c(e),ba=o(e,"P",{});var Sp=n(ba);Ao=i(Sp,"Poich\xE8 i contenuti degli issue e delle richieste di pull sono molto diversi, facciamo un po\u2019 di preprocessing per permetterci di distinguere tra i due."),Sp.forEach(a),Ni=c(e),me=o(e,"H2",{class:!0});var Xl=n(me);Pe=o(Xl,"A",{id:!0,class:!0,href:!0});var Up=n(Pe);nt=o(Up,"SPAN",{});var Lp=n(nt);_(Es.$$.fragment,Lp),Lp.forEach(a),Up.forEach(a),No=c(Xl),ut=o(Xl,"SPAN",{});var Mp=n(ut);Io=i(Mp,"Pulire i dati"),Mp.forEach(a),Xl.forEach(a),Ii=c(e),G=o(e,"P",{});var F=n(G);Go=i(F,"Il frammento precedente della documentazione di GitHub ci dice che la colonna "),pt=o(F,"CODE",{});var Fp=n(pt);Ro=i(Fp,"pull_request"),Fp.forEach(a),So=i(F," pu\xF2 essere utilizzata per distinguere gli issue e le richieste di pull. Diamo uno sguardo a un esempio casuale per vedere qual \xE8 la differenza. Come abbiamo fatto nella "),va=o(F,"A",{href:!0});var Bp=n(va);Uo=i(Bp,"sezione 3"),Bp.forEach(a),Lo=i(F,", concateneremo "),ct=o(F,"CODE",{});var Qp=n(ct);Mo=i(Qp,"Dataset.shuffle()"),Qp.forEach(a),Fo=i(F," e "),dt=o(F,"CODE",{});var Jp=n(dt);Bo=i(Jp,"Dataset.select()"),Jp.forEach(a),Qo=i(F," per creare un campione random, e poi zipperemo le colonne "),mt=o(F,"CODE",{});var Vp=n(mt);Jo=i(Vp,"html_url"),Vp.forEach(a),Vo=i(F," e "),ht=o(F,"CODE",{});var Zp=n(ht);Zo=i(Zp,"pull_request"),Zp.forEach(a),Ko=i(F," cos\xEC da poter paragonare i diversi URL:"),F.forEach(a),Gi=c(e),_(ys.$$.fragment,e),Ri=c(e),_(qs.$$.fragment,e),Si=c(e),L=o(e,"P",{});var ne=n(L);Xo=i(ne,"Possiamo vedere che ogni richiesta di pull \xE8 associata a diversi URL, mentre i comuni issue hanno un\u2019entrata "),gt=o(ne,"CODE",{});var Kp=n(gt);Wo=i(Kp,"None"),Kp.forEach(a),Yo=i(ne,". Possiamo usare questa distinzione per crare una nuova colonna "),ft=o(ne,"CODE",{});var Xp=n(ft);en=i(Xp,"is_pull_request"),Xp.forEach(a),sn=i(ne," che controlla se il campo "),_t=o(ne,"CODE",{});var Wp=n(_t);an=i(Wp,"pull_request"),Wp.forEach(a),tn=i(ne," sia "),bt=o(ne,"CODE",{});var Yp=n(bt);ln=i(Yp,"None"),Yp.forEach(a),rn=i(ne," o meno:"),ne.forEach(a),Ui=c(e),_(ws.$$.fragment,e),Li=c(e),_(De.$$.fragment,e),Mi=c(e),xa=o(e,"P",{});var ec=n(xa);on=i(ec,"Bench\xE9 potremmo procedere e pulire ulteriormente il dataset eliminando o rinominando alcune colonne, \xE8 solitamente buona prassi lasciare il dataset quando pi\xF9 intatto \xE8 possibile in questo stadio, cos\xEC che pu\xF2 essere utilizzato facilmente in pi\xF9 applicazioni."),ec.forEach(a),Fi=c(e),$a=o(e,"P",{});var sc=n($a);nn=i(sc,"Prima di caricare il nostro dataset sull\u2019Hub Hugging Face, dobbiamo occuparci di una cosa che manca: i commenti associati a ogni issue e richiesta di pull. Hai indovinato, li aggiungeremo utilizzando la REST API di GitHub!"),sc.forEach(a),Bi=c(e),he=o(e,"H2",{class:!0});var Wl=n(he);He=o(Wl,"A",{id:!0,class:!0,href:!0});var ac=n(He);vt=o(ac,"SPAN",{});var tc=n(vt);_(ks.$$.fragment,tc),tc.forEach(a),ac.forEach(a),un=c(Wl),xt=o(Wl,"SPAN",{});var ic=n(xt);pn=i(ic,"Estendere il dataset"),ic.forEach(a),Wl.forEach(a),Qi=c(e),ja=o(e,"P",{});var lc=n(ja);cn=i(lc,"Come mostrato negli screenshot di seguito, i commenti associati a un issue o una richiesta di pull offrono una fonte molto ricca di informazioni, soprattutto se siamo interessati a costruire un motore di ricerca per rispondere alle richieste degli utenti sulla libreria."),lc.forEach(a),Ji=c(e),zs=o(e,"DIV",{class:!0});var rc=n(zs);Ps=o(rc,"IMG",{src:!0,alt:!0,width:!0}),rc.forEach(a),Vi=c(e),Oe=o(e,"P",{});var Yl=n(Oe);dn=i(Yl,"La REST API di GitHub offre un "),Ce=o(Yl,"A",{href:!0,rel:!0});var Ju=n(Ce);mn=i(Ju,"endpoint "),$t=o(Ju,"CODE",{});var oc=n($t);hn=i(oc,"Comments"),oc.forEach(a),Ju.forEach(a),gn=i(Yl," che restituisce tutti i commenti associati con un numero di issue. Testiamo quest\u2019endpoint per vedere cosa restituisce:"),Yl.forEach(a),Zi=c(e),_(Ds.$$.fragment,e),Ki=c(e),_(Hs.$$.fragment,e),Xi=c(e),Z=o(e,"P",{});var Ye=n(Z);fn=i(Ye,"Possiamo vedere che il commento \xE8 archiviato nel campo "),jt=o(Ye,"CODE",{});var nc=n(jt);_n=i(nc,"body"),nc.forEach(a),bn=i(Ye,", quindi possiamo scvrivere una semplice funzione che restituisce tutti i commenti associati con un issue estraendo i contenuti di "),Et=o(Ye,"CODE",{});var uc=n(Et);vn=i(uc,"body"),uc.forEach(a),xn=i(Ye," per ogni elemento in "),yt=o(Ye,"CODE",{});var pc=n(yt);$n=i(pc,"response.json()"),pc.forEach(a),jn=i(Ye,":"),Ye.forEach(a),Wi=c(e),_(Os.$$.fragment,e),Yi=c(e),_(Cs.$$.fragment,e),el=c(e),ae=o(e,"P",{});var Oa=n(ae);En=i(Oa,"Sembra andar bene, quindi possiamo usare "),qt=o(Oa,"CODE",{});var cc=n(qt);yn=i(cc,"Dataset.map()"),cc.forEach(a),qn=i(Oa," per aggiungere una nuova colonna "),wt=o(Oa,"CODE",{});var dc=n(wt);wn=i(dc,"comments"),dc.forEach(a),kn=i(Oa," a ogni usse nel nostro dataset:"),Oa.forEach(a),sl=c(e),_(Ts.$$.fragment,e),al=c(e),Ea=o(e,"P",{});var mc=n(Ea);zn=i(mc,"Come passaggio finale, salviamo il dataset esteso assieme ai nostri dati non processati, cos\xEC da poter caricare entrambi sull\u2019Hub:"),mc.forEach(a),tl=c(e),_(As.$$.fragment,e),il=c(e),ge=o(e,"H2",{class:!0});var er=n(ge);Te=o(er,"A",{id:!0,class:!0,href:!0});var hc=n(Te);kt=o(hc,"SPAN",{});var gc=n(kt);_(Ns.$$.fragment,gc),gc.forEach(a),hc.forEach(a),Pn=c(er),zt=o(er,"SPAN",{});var fc=n(zt);Dn=i(fc,"Caricare il dataset sull'Hub Hugging Face"),fc.forEach(a),er.forEach(a),ll=c(e),_(Is.$$.fragment,e),rl=c(e),te=o(e,"P",{});var Ca=n(te);Hn=i(Ca,"Ora che abbiamo il nostro dataset esteso, \xE8 arrivato il momento di caricarlo sull\u2019Hub, cos\xEC da poterlo condividere con la community! Per caricare il dataset useremo la "),Gs=o(Ca,"A",{href:!0,rel:!0});var _c=n(Gs);On=i(_c,"libreria \u{1F917} Hub"),_c.forEach(a),Cn=i(Ca,", che ci permette di interagire con l\u2019Hub di Hugging Face attraverso un\u2019API di Python. \u{1F917} Hub \xE8 preinstallato con \u{1F917} Transformers, cos\xEC possiamo usarlo da subito. Ad esempio, possiamo usare la funzione "),Pt=o(Ca,"CODE",{});var bc=n(Pt);Tn=i(bc,"list_datastes()"),bc.forEach(a),An=i(Ca," per avere informazioni su tutti i dataset pubblici attualmente presenti sull\u2019Hub:"),Ca.forEach(a),ol=c(e),_(Rs.$$.fragment,e),nl=c(e),_(Ss.$$.fragment,e),ul=c(e),Ae=o(e,"P",{});var sr=n(Ae);Nn=i(sr,"Possiamo vedere che al momento ci sono circa 1.500 dataset sull\u2019Hub, e la funzione "),Dt=o(sr,"CODE",{});var vc=n(Dt);In=i(vc,"list_datasets()"),vc.forEach(a),Gn=i(sr," inoltre permette di avere alcuni metadati su ciascuna repository."),sr.forEach(a),pl=c(e),Ne=o(e,"P",{});var ar=n(Ne);Rn=i(ar,"Per ci\xF2 che ci riguarda, la prima cosa che dobbiamo fare \xE8 crare una nuova repository nell\u2019Hub. Per far ci\xF2 abbiamo bisogno di un token di autentificazione, che pou\xF2 essere ottenuto effettuando l\u2019accesso nell\u2019Hub Hugging Face con la funzione "),Ht=o(ar,"CODE",{});var xc=n(Ht);Sn=i(xc,"notebook_login()"),xc.forEach(a),Un=i(ar,":"),ar.forEach(a),cl=c(e),_(Us.$$.fragment,e),dl=c(e),Ie=o(e,"P",{});var tr=n(Ie);Ln=i(tr,"Questo creer\xE0 un widget in cui puoi inserire il tuo username e la tua password, e un token API verr\xE0 salvato in "),Ot=o(tr,"EM",{});var $c=n(Ot);Mn=i($c,"~/.huggingface/token"),$c.forEach(a),Fn=i(tr,". Se stai eseguendo il codice in un terminale, puoi effettuare l\u2019accesso attraverso il comando:"),tr.forEach(a),ml=c(e),_(Ls.$$.fragment,e),hl=c(e),Ge=o(e,"P",{});var ir=n(Ge);Bn=i(ir,"Una volta fatto questo, possiamo crare una nuova repository con la funzione "),Ct=o(ir,"CODE",{});var jc=n(Ct);Qn=i(jc,"create_repo()"),jc.forEach(a),Jn=i(ir,":"),ir.forEach(a),gl=c(e),_(Ms.$$.fragment,e),fl=c(e),_(Fs.$$.fragment,e),_l=c(e),ie=o(e,"P",{});var Ta=n(ie);Vn=i(Ta,"In quest\u2019esempio, abbiamo creato una repository vuota chiamata "),Tt=o(Ta,"CODE",{});var Ec=n(Tt);Zn=i(Ec,"github-issues"),Ec.forEach(a),Kn=i(Ta," con l\u2019username "),At=o(Ta,"CODE",{});var yc=n(At);Xn=i(yc,"lewtun"),yc.forEach(a),Wn=i(Ta," (l\u2019username dovrebbe essere quello del tuo account Hub quando esegui questo codice!)."),Ta.forEach(a),bl=c(e),_(Re.$$.fragment,e),vl=c(e),Se=o(e,"P",{});var lr=n(Se);Yn=i(lr,"Ora, cloniamo la repository dall\u2019Hub alla nostra macchina e copiamo al suo interno i file del nostro dataset. \u{1F917} Hub contiene una classe "),Nt=o(lr,"CODE",{});var qc=n(Nt);eu=i(qc,"Repository"),qc.forEach(a),su=i(lr," che ha al suo interno molti dei comandi pi\xF9 comuni di Git, per cui per clonare la repository in remoto dobbiamo semplicemente fornire l\u2019URL e il percorso locale in cui desideriamo clonare:"),lr.forEach(a),xl=c(e),_(Bs.$$.fragment,e),$l=c(e),M=o(e,"P",{});var ue=n(M);au=i(ue,"Di default, diverse estensioni file (ad esempio "),It=o(ue,"EM",{});var wc=n(It);tu=i(wc,".bin"),wc.forEach(a),iu=i(ue,", "),Gt=o(ue,"EM",{});var kc=n(Gt);lu=i(kc,".gz"),kc.forEach(a),ru=i(ue," e "),Rt=o(ue,"EM",{});var zc=n(Rt);ou=i(zc,".zip"),zc.forEach(a),nu=i(ue,") sono registrate da Git LFS, cos\xEC che i file di grandi dimensioni possono essere gestiti all\u2019interno dello stesso workflow. Puoi trovare una lista delle estensioni di file monitorati nel file "),St=o(ue,"EM",{});var Pc=n(St);uu=i(Pc,".gitattributes"),Pc.forEach(a),pu=i(ue," della repository. Per includere il formato JSON Lines a questa lista, possiamo utilizzare il comando:"),ue.forEach(a),jl=c(e),_(Qs.$$.fragment,e),El=c(e),Ue=o(e,"P",{});var rr=n(Ue);cu=i(rr,"Ora possiamo usare "),Ut=o(rr,"CODE",{});var Dc=n(Ut);du=i(Dc,"Repository.push_to_hub()"),Dc.forEach(a),mu=i(rr," per caricare il dataset sull\u2019Hub:"),rr.forEach(a),yl=c(e),_(Js.$$.fragment,e),ql=c(e),Le=o(e,"P",{});var or=n(Le);hu=i(or,"Se navighiamo fino all\u2019URL contenuto in "),Lt=o(or,"CODE",{});var Hc=n(Lt);gu=i(Hc,"repo_url"),Hc.forEach(a),fu=i(or,", vedremo che il file del nostro dataset \xE8 stato caricato."),or.forEach(a),wl=c(e),Vs=o(e,"DIV",{class:!0});var Oc=n(Vs);Zs=o(Oc,"IMG",{src:!0,alt:!0,width:!0}),Oc.forEach(a),kl=c(e),le=o(e,"P",{});var Aa=n(le);_u=i(Aa,"Da qui, chiunque pu\xF2 scaricare il dataset semplicemente inserendo l\u2019ID della repository come argomento "),Mt=o(Aa,"CODE",{});var Cc=n(Mt);bu=i(Cc,"path"),Cc.forEach(a),vu=i(Aa," di "),Ft=o(Aa,"CODE",{});var Tc=n(Ft);xu=i(Tc,"load_dataset()"),Tc.forEach(a),$u=i(Aa,":"),Aa.forEach(a),zl=c(e),_(Ks.$$.fragment,e),Pl=c(e),_(Xs.$$.fragment,e),Dl=c(e),Me=o(e,"P",{});var nr=n(Me);ju=i(nr,"Bene, abbiamo caricato il nostro dataset sull\u2019Hub, e pu\xF2 essere utilizzato da tutti! C\u2019\xE8 un\u2019altra cosa importante che dobbiamo fare: aggiungere una "),Bt=o(nr,"EM",{});var Ac=n(Bt);Eu=i(Ac,"dataset card"),Ac.forEach(a),yu=i(nr," che spiega come \xE8 stato creato il corpus, e offre altre informazioni utili per la community."),nr.forEach(a),Hl=c(e),_(Fe.$$.fragment,e),Ol=c(e),fe=o(e,"H2",{class:!0});var ur=n(fe);Be=o(ur,"A",{id:!0,class:!0,href:!0});var Nc=n(Be);Qt=o(Nc,"SPAN",{});var Ic=n(Qt);_(Ws.$$.fragment,Ic),Ic.forEach(a),Nc.forEach(a),qu=c(ur),Jt=o(ur,"SPAN",{});var Gc=n(Jt);wu=i(Gc,"Creare una dataset card"),Gc.forEach(a),ur.forEach(a),Cl=c(e),ya=o(e,"P",{});var Rc=n(ya);ku=i(Rc,"I dataset ben-documentati sono pi\xF9 utili agli altri utenti (compreso il futuro te!), poich\xE9 spiegano il contesto per permettere agli utenti di decidere se un dataset pu\xF2 essere utile, e valutare gli eventuali bias o rischi associati nell\u2019utilizzo del dataset."),Rc.forEach(a),Tl=c(e),Qe=o(e,"P",{});var pr=n(Qe);zu=i(pr,"Sull\u2019Hug di Hugging Face, queste informazioni si trovano nel file "),Vt=o(pr,"EM",{});var Sc=n(Vt);Pu=i(Sc,"README.md"),Sc.forEach(a),Du=i(pr," della repository. Ci sono due passaggi principali che dovresti seguire prima di creare questo file:"),pr.forEach(a),Al=c(e),qa=o(e,"OL",{});var Uc=n(qa);_e=o(Uc,"LI",{});var Na=n(_e);Hu=i(Na,"Usa l\u2019"),Je=o(Na,"A",{href:!0,rel:!0});var Vu=n(Je);Ou=i(Vu,"applicatione "),Zt=o(Vu,"CODE",{});var Lc=n(Zt);Cu=i(Lc,"datasets-tagging"),Lc.forEach(a),Vu.forEach(a),Tu=i(Na," per creare tag di metadati in formato YAML. Questi tag sono usato per una serie di funzioni di ricerca sull\u2019Hub di Hugging Face, e assicurano che il tuo dataset possa essere facilmente trovato dai membri della community. Poich\xE8 abbiamo creato un nostro dataset, dovrai clonare la repository "),Kt=o(Na,"CODE",{});var Mc=n(Kt);Au=i(Mc,"datasets-tagging"),Mc.forEach(a),Nu=i(Na,", ed eseguire l\u2019applicazione in locale. Ecco com\u2019\xE8 l\u2019interfaccia:"),Na.forEach(a),Uc.forEach(a),Nl=c(e),Ys=o(e,"DIV",{class:!0});var Fc=n(Ys);ea=o(Fc,"IMG",{src:!0,alt:!0,width:!0}),Fc.forEach(a),Il=c(e),sa=o(e,"OL",{start:!0});var Bc=n(sa);aa=o(Bc,"LI",{});var cr=n(aa);Iu=i(cr,"Leggi la "),ta=o(cr,"A",{href:!0,rel:!0});var Qc=n(ta);Gu=i(Qc,"guida \u{1F917} Datasets"),Qc.forEach(a),Ru=i(cr," sulla creazione di dataset card informative, e usala come template."),cr.forEach(a),Bc.forEach(a),Gl=c(e),re=o(e,"P",{});var Ia=n(re);Su=i(Ia,"Puoi creare il file "),Xt=o(Ia,"EM",{});var Jc=n(Xt);Uu=i(Jc,"README.md"),Jc.forEach(a),Lu=i(Ia," direttamente sull\u2019Hub, e puoi trovare un modello per una dataset card nella repository "),Wt=o(Ia,"CODE",{});var Vc=n(Wt);Mu=i(Vc,"lewtun/github-issues"),Vc.forEach(a),Fu=i(Ia,". Di seguito \xE8 mostrato uno screenshot di una dataset card gi\xE0 compilata."),Ia.forEach(a),Rl=c(e),ia=o(e,"DIV",{class:!0});var Zc=n(ia);la=o(Zc,"IMG",{src:!0,alt:!0,width:!0}),Zc.forEach(a),Sl=c(e),_(Ve.$$.fragment,e),Ul=c(e),wa=o(e,"P",{});var Kc=n(wa);Bu=i(Kc,"\xC8 tutto! Abbiamo visto in questa sezione che creare un buon dataset pu\xF2 essere un\u2019impresa, ma per fortuna caricarlo e condividerlo con la community \xE8 molto pi\xF9 semplice. Nella prossima sezione useremo il nostro nuovo dataset per creare un motore di ricerca semantico con \u{1F917} Datasets, che abbina alle domande gli issue e i commenti pi\xF9 rilevanti."),Kc.forEach(a),Ll=c(e),_(Ze.$$.fragment,e),this.h()},h(){m(d,"name","hf:doc:metadata"),m(d,"content",JSON.stringify(dd)),m(y,"id","creare-il-proprio-dataset"),m(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(y,"href","#creare-il-proprio-dataset"),m(h,"class","relative group"),m(k,"href","https://github.com/features/issues"),m(k,"rel","nofollow"),m(xe,"id","recuperare-i-dati"),m(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(xe,"href","#recuperare-i-dati"),m(ce,"class","relative group"),m(ss,"href","https://github.com/huggingface/datasets/issues"),m(ss,"rel","nofollow"),Ga(ts.src,Zu="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues.png")||m(ts,"src",Zu),m(ts,"alt","The GitHub issues associated with \u{1F917} Datasets."),m(ts,"width","80%"),m(as,"class","flex justify-center"),Ga(ls.src,Ku="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-single.png")||m(ls,"src",Ku),m(ls,"alt","A typical GitHub issue in the \u{1F917} Datasets repository."),m(ls,"width","80%"),m(is,"class","flex justify-center"),m(rs,"href","https://docs.github.com/en/rest"),m(rs,"rel","nofollow"),m(je,"href","https://docs.github.com/en/rest/reference/issues#list-repository-issues"),m(je,"rel","nofollow"),m(cs,"href","https://it.wikipedia.org/wiki/Codici_di_stato_HTTP"),m(cs,"rel","nofollow"),m(hs,"href","https://docs.github.com/en/rest/overview/resources-in-the-rest-api#rate-limiting"),m(hs,"rel","nofollow"),m(gs,"href","https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token"),m(gs,"rel","nofollow"),m(fa,"href","/course/chaper5/2"),m($s,"href","https://github.com/huggingface/datasets/issues"),m($s,"rel","nofollow"),m(js,"href","https://docs.github.com/en/rest/reference/issues#list-issues-assigned-to-the-authenticated-user"),m(js,"rel","nofollow"),m(Pe,"id","pulire-i-dati"),m(Pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Pe,"href","#pulire-i-dati"),m(me,"class","relative group"),m(va,"href","/course/chapter5/3"),m(He,"id","estendere-il-dataset"),m(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(He,"href","#estendere-il-dataset"),m(he,"class","relative group"),Ga(Ps.src,Xu="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-issues-comment.png")||m(Ps,"src",Xu),m(Ps,"alt","Comments associated with an issue about \u{1F917} Datasets."),m(Ps,"width","80%"),m(zs,"class","flex justify-center"),m(Ce,"href","https://docs.github.com/en/rest/reference/issues#list-issue-comments"),m(Ce,"rel","nofollow"),m(Te,"id","caricare-il-dataset-sullhub-hugging-face"),m(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Te,"href","#caricare-il-dataset-sullhub-hugging-face"),m(ge,"class","relative group"),m(Gs,"href","https://github.com/huggingface/huggingface_hub"),m(Gs,"rel","nofollow"),Ga(Zs.src,Wu="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/hub-repo.png")||m(Zs,"src",Wu),m(Zs,"alt","Our dataset repository on the Hugging Face Hub."),m(Zs,"width","80%"),m(Vs,"class","flex justify-center"),m(Be,"id","creare-una-dataset-card"),m(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Be,"href","#creare-una-dataset-card"),m(fe,"class","relative group"),m(Je,"href","https://huggingface.co/datasets/tagging/"),m(Je,"rel","nofollow"),Ga(ea.src,Yu="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/datasets-tagger.png")||m(ea,"src",Yu),m(ea,"alt","The `datasets-tagging` interface."),m(ea,"width","80%"),m(Ys,"class","flex justify-center"),m(ta,"href","https://github.com/huggingface/datasets/blob/master/templates/README_guide.md"),m(ta,"rel","nofollow"),m(sa,"start","2"),Ga(la.src,ep="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter5/dataset-card.png")||m(la,"src",ep),m(la,"alt","A dataset card."),m(la,"width","80%"),m(ia,"class","flex justify-center")},m(e,l){s(document.head,d),u(e,z,l),u(e,h,l),s(h,y),s(y,w),b(g,w,null),s(h,q),s(h,P),s(P,j),u(e,E,l),b(H,e,l),u(e,D,l),u(e,O,l),s(O,A),s(O,k),s(k,T),s(O,B),u(e,R,l),u(e,N,l),s(N,Q),s(Q,pe),s(N,I),s(N,X),s(X,ua),s(X,ve),s(ve,pa),s(X,ca),s(N,da),s(N,Sa),s(Sa,dr),u(e,ti,l),u(e,ma,l),s(ma,mr),u(e,ii,l),u(e,ce,l),s(ce,xe),s(xe,Ua),b(es,Ua,null),s(ce,hr),s(ce,La),s(La,gr),u(e,li,l),u(e,$e,l),s($e,fr),s($e,ss),s(ss,_r),s($e,br),u(e,ri,l),u(e,as,l),s(as,ts),u(e,oi,l),u(e,ha,l),s(ha,vr),u(e,ni,l),u(e,is,l),s(is,ls),u(e,ui,l),u(e,W,l),s(W,xr),s(W,rs),s(rs,$r),s(W,jr),s(W,je),s(je,Er),s(je,Ma),s(Ma,yr),s(W,qr),u(e,pi,l),u(e,Ee,l),s(Ee,wr),s(Ee,Fa),s(Fa,kr),s(Ee,zr),u(e,ci,l),b(os,e,l),u(e,di,l),u(e,Y,l),s(Y,Pr),s(Y,Ba),s(Ba,Dr),s(Y,Hr),s(Y,Qa),s(Qa,Or),s(Y,Cr),u(e,mi,l),b(ns,e,l),u(e,hi,l),u(e,ye,l),s(ye,Tr),s(ye,Ja),s(Ja,Ar),s(ye,Nr),u(e,gi,l),b(us,e,l),u(e,fi,l),b(ps,e,l),u(e,_i,l),u(e,J,l),s(J,Ir),s(J,Va),s(Va,Gr),s(J,Rr),s(J,cs),s(cs,Sr),s(J,Ur),s(J,Za),s(Za,Lr),s(J,Mr),u(e,bi,l),b(ds,e,l),u(e,vi,l),b(ms,e,l),u(e,xi,l),u(e,V,l),s(V,Fr),s(V,Ka),s(Ka,Br),s(V,Qr),s(V,Xa),s(Xa,Jr),s(V,Vr),s(V,Wa),s(Wa,Zr),s(V,Kr),u(e,$i,l),b(qe,e,l),u(e,ji,l),u(e,U,l),s(U,Xr),s(U,hs),s(hs,Wr),s(U,Yr),s(U,Ya),s(Ya,eo),s(U,so),s(U,gs),s(gs,ao),s(U,to),s(U,et),s(et,io),s(U,lo),u(e,Ei,l),b(fs,e,l),u(e,yi,l),b(we,e,l),u(e,qi,l),u(e,ga,l),s(ga,ro),u(e,wi,l),b(_s,e,l),u(e,ki,l),u(e,ee,l),s(ee,oo),s(ee,st),s(st,no),s(ee,uo),s(ee,at),s(at,po),s(ee,co),u(e,zi,l),b(bs,e,l),u(e,Pi,l),u(e,ke,l),s(ke,mo),s(ke,fa),s(fa,ho),s(ke,go),u(e,Di,l),b(vs,e,l),u(e,Hi,l),b(xs,e,l),u(e,Oi,l),u(e,se,l),s(se,fo),s(se,$s),s($s,_o),s(se,bo),s(se,js),s(js,vo),s(se,xo),u(e,Ci,l),u(e,_a,l),s(_a,de),s(de,$o),s(de,tt),s(tt,jo),s(de,Eo),s(de,it),s(it,yo),s(de,qo),u(e,Ti,l),u(e,ze,l),s(ze,wo),s(ze,K),s(K,ko),s(K,lt),s(lt,zo),s(K,Po),s(K,rt),s(rt,Do),s(K,Ho),s(K,ot),s(ot,Oo),s(K,Co),s(ze,To),u(e,Ai,l),u(e,ba,l),s(ba,Ao),u(e,Ni,l),u(e,me,l),s(me,Pe),s(Pe,nt),b(Es,nt,null),s(me,No),s(me,ut),s(ut,Io),u(e,Ii,l),u(e,G,l),s(G,Go),s(G,pt),s(pt,Ro),s(G,So),s(G,va),s(va,Uo),s(G,Lo),s(G,ct),s(ct,Mo),s(G,Fo),s(G,dt),s(dt,Bo),s(G,Qo),s(G,mt),s(mt,Jo),s(G,Vo),s(G,ht),s(ht,Zo),s(G,Ko),u(e,Gi,l),b(ys,e,l),u(e,Ri,l),b(qs,e,l),u(e,Si,l),u(e,L,l),s(L,Xo),s(L,gt),s(gt,Wo),s(L,Yo),s(L,ft),s(ft,en),s(L,sn),s(L,_t),s(_t,an),s(L,tn),s(L,bt),s(bt,ln),s(L,rn),u(e,Ui,l),b(ws,e,l),u(e,Li,l),b(De,e,l),u(e,Mi,l),u(e,xa,l),s(xa,on),u(e,Fi,l),u(e,$a,l),s($a,nn),u(e,Bi,l),u(e,he,l),s(he,He),s(He,vt),b(ks,vt,null),s(he,un),s(he,xt),s(xt,pn),u(e,Qi,l),u(e,ja,l),s(ja,cn),u(e,Ji,l),u(e,zs,l),s(zs,Ps),u(e,Vi,l),u(e,Oe,l),s(Oe,dn),s(Oe,Ce),s(Ce,mn),s(Ce,$t),s($t,hn),s(Oe,gn),u(e,Zi,l),b(Ds,e,l),u(e,Ki,l),b(Hs,e,l),u(e,Xi,l),u(e,Z,l),s(Z,fn),s(Z,jt),s(jt,_n),s(Z,bn),s(Z,Et),s(Et,vn),s(Z,xn),s(Z,yt),s(yt,$n),s(Z,jn),u(e,Wi,l),b(Os,e,l),u(e,Yi,l),b(Cs,e,l),u(e,el,l),u(e,ae,l),s(ae,En),s(ae,qt),s(qt,yn),s(ae,qn),s(ae,wt),s(wt,wn),s(ae,kn),u(e,sl,l),b(Ts,e,l),u(e,al,l),u(e,Ea,l),s(Ea,zn),u(e,tl,l),b(As,e,l),u(e,il,l),u(e,ge,l),s(ge,Te),s(Te,kt),b(Ns,kt,null),s(ge,Pn),s(ge,zt),s(zt,Dn),u(e,ll,l),b(Is,e,l),u(e,rl,l),u(e,te,l),s(te,Hn),s(te,Gs),s(Gs,On),s(te,Cn),s(te,Pt),s(Pt,Tn),s(te,An),u(e,ol,l),b(Rs,e,l),u(e,nl,l),b(Ss,e,l),u(e,ul,l),u(e,Ae,l),s(Ae,Nn),s(Ae,Dt),s(Dt,In),s(Ae,Gn),u(e,pl,l),u(e,Ne,l),s(Ne,Rn),s(Ne,Ht),s(Ht,Sn),s(Ne,Un),u(e,cl,l),b(Us,e,l),u(e,dl,l),u(e,Ie,l),s(Ie,Ln),s(Ie,Ot),s(Ot,Mn),s(Ie,Fn),u(e,ml,l),b(Ls,e,l),u(e,hl,l),u(e,Ge,l),s(Ge,Bn),s(Ge,Ct),s(Ct,Qn),s(Ge,Jn),u(e,gl,l),b(Ms,e,l),u(e,fl,l),b(Fs,e,l),u(e,_l,l),u(e,ie,l),s(ie,Vn),s(ie,Tt),s(Tt,Zn),s(ie,Kn),s(ie,At),s(At,Xn),s(ie,Wn),u(e,bl,l),b(Re,e,l),u(e,vl,l),u(e,Se,l),s(Se,Yn),s(Se,Nt),s(Nt,eu),s(Se,su),u(e,xl,l),b(Bs,e,l),u(e,$l,l),u(e,M,l),s(M,au),s(M,It),s(It,tu),s(M,iu),s(M,Gt),s(Gt,lu),s(M,ru),s(M,Rt),s(Rt,ou),s(M,nu),s(M,St),s(St,uu),s(M,pu),u(e,jl,l),b(Qs,e,l),u(e,El,l),u(e,Ue,l),s(Ue,cu),s(Ue,Ut),s(Ut,du),s(Ue,mu),u(e,yl,l),b(Js,e,l),u(e,ql,l),u(e,Le,l),s(Le,hu),s(Le,Lt),s(Lt,gu),s(Le,fu),u(e,wl,l),u(e,Vs,l),s(Vs,Zs),u(e,kl,l),u(e,le,l),s(le,_u),s(le,Mt),s(Mt,bu),s(le,vu),s(le,Ft),s(Ft,xu),s(le,$u),u(e,zl,l),b(Ks,e,l),u(e,Pl,l),b(Xs,e,l),u(e,Dl,l),u(e,Me,l),s(Me,ju),s(Me,Bt),s(Bt,Eu),s(Me,yu),u(e,Hl,l),b(Fe,e,l),u(e,Ol,l),u(e,fe,l),s(fe,Be),s(Be,Qt),b(Ws,Qt,null),s(fe,qu),s(fe,Jt),s(Jt,wu),u(e,Cl,l),u(e,ya,l),s(ya,ku),u(e,Tl,l),u(e,Qe,l),s(Qe,zu),s(Qe,Vt),s(Vt,Pu),s(Qe,Du),u(e,Al,l),u(e,qa,l),s(qa,_e),s(_e,Hu),s(_e,Je),s(Je,Ou),s(Je,Zt),s(Zt,Cu),s(_e,Tu),s(_e,Kt),s(Kt,Au),s(_e,Nu),u(e,Nl,l),u(e,Ys,l),s(Ys,ea),u(e,Il,l),u(e,sa,l),s(sa,aa),s(aa,Iu),s(aa,ta),s(ta,Gu),s(aa,Ru),u(e,Gl,l),u(e,re,l),s(re,Su),s(re,Xt),s(Xt,Uu),s(re,Lu),s(re,Wt),s(Wt,Mu),s(re,Fu),u(e,Rl,l),u(e,ia,l),s(ia,la),u(e,Sl,l),b(Ve,e,l),u(e,Ul,l),u(e,wa,l),s(wa,Bu),u(e,Ll,l),b(Ze,e,l),Ml=!0},p(e,[l]){const ra={};l&2&&(ra.$$scope={dirty:l,ctx:e}),qe.$set(ra);const Yt={};l&2&&(Yt.$$scope={dirty:l,ctx:e}),we.$set(Yt);const ei={};l&2&&(ei.$$scope={dirty:l,ctx:e}),De.$set(ei);const si={};l&2&&(si.$$scope={dirty:l,ctx:e}),Re.$set(si);const oa={};l&2&&(oa.$$scope={dirty:l,ctx:e}),Fe.$set(oa);const ai={};l&2&&(ai.$$scope={dirty:l,ctx:e}),Ve.$set(ai);const be={};l&2&&(be.$$scope={dirty:l,ctx:e}),Ze.$set(be)},i(e){Ml||(v(g.$$.fragment,e),v(H.$$.fragment,e),v(es.$$.fragment,e),v(os.$$.fragment,e),v(ns.$$.fragment,e),v(us.$$.fragment,e),v(ps.$$.fragment,e),v(ds.$$.fragment,e),v(ms.$$.fragment,e),v(qe.$$.fragment,e),v(fs.$$.fragment,e),v(we.$$.fragment,e),v(_s.$$.fragment,e),v(bs.$$.fragment,e),v(vs.$$.fragment,e),v(xs.$$.fragment,e),v(Es.$$.fragment,e),v(ys.$$.fragment,e),v(qs.$$.fragment,e),v(ws.$$.fragment,e),v(De.$$.fragment,e),v(ks.$$.fragment,e),v(Ds.$$.fragment,e),v(Hs.$$.fragment,e),v(Os.$$.fragment,e),v(Cs.$$.fragment,e),v(Ts.$$.fragment,e),v(As.$$.fragment,e),v(Ns.$$.fragment,e),v(Is.$$.fragment,e),v(Rs.$$.fragment,e),v(Ss.$$.fragment,e),v(Us.$$.fragment,e),v(Ls.$$.fragment,e),v(Ms.$$.fragment,e),v(Fs.$$.fragment,e),v(Re.$$.fragment,e),v(Bs.$$.fragment,e),v(Qs.$$.fragment,e),v(Js.$$.fragment,e),v(Ks.$$.fragment,e),v(Xs.$$.fragment,e),v(Fe.$$.fragment,e),v(Ws.$$.fragment,e),v(Ve.$$.fragment,e),v(Ze.$$.fragment,e),Ml=!0)},o(e){x(g.$$.fragment,e),x(H.$$.fragment,e),x(es.$$.fragment,e),x(os.$$.fragment,e),x(ns.$$.fragment,e),x(us.$$.fragment,e),x(ps.$$.fragment,e),x(ds.$$.fragment,e),x(ms.$$.fragment,e),x(qe.$$.fragment,e),x(fs.$$.fragment,e),x(we.$$.fragment,e),x(_s.$$.fragment,e),x(bs.$$.fragment,e),x(vs.$$.fragment,e),x(xs.$$.fragment,e),x(Es.$$.fragment,e),x(ys.$$.fragment,e),x(qs.$$.fragment,e),x(ws.$$.fragment,e),x(De.$$.fragment,e),x(ks.$$.fragment,e),x(Ds.$$.fragment,e),x(Hs.$$.fragment,e),x(Os.$$.fragment,e),x(Cs.$$.fragment,e),x(Ts.$$.fragment,e),x(As.$$.fragment,e),x(Ns.$$.fragment,e),x(Is.$$.fragment,e),x(Rs.$$.fragment,e),x(Ss.$$.fragment,e),x(Us.$$.fragment,e),x(Ls.$$.fragment,e),x(Ms.$$.fragment,e),x(Fs.$$.fragment,e),x(Re.$$.fragment,e),x(Bs.$$.fragment,e),x(Qs.$$.fragment,e),x(Js.$$.fragment,e),x(Ks.$$.fragment,e),x(Xs.$$.fragment,e),x(Fe.$$.fragment,e),x(Ws.$$.fragment,e),x(Ve.$$.fragment,e),x(Ze.$$.fragment,e),Ml=!1},d(e){a(d),e&&a(z),e&&a(h),$(g),e&&a(E),$(H,e),e&&a(D),e&&a(O),e&&a(R),e&&a(N),e&&a(ti),e&&a(ma),e&&a(ii),e&&a(ce),$(es),e&&a(li),e&&a($e),e&&a(ri),e&&a(as),e&&a(oi),e&&a(ha),e&&a(ni),e&&a(is),e&&a(ui),e&&a(W),e&&a(pi),e&&a(Ee),e&&a(ci),$(os,e),e&&a(di),e&&a(Y),e&&a(mi),$(ns,e),e&&a(hi),e&&a(ye),e&&a(gi),$(us,e),e&&a(fi),$(ps,e),e&&a(_i),e&&a(J),e&&a(bi),$(ds,e),e&&a(vi),$(ms,e),e&&a(xi),e&&a(V),e&&a($i),$(qe,e),e&&a(ji),e&&a(U),e&&a(Ei),$(fs,e),e&&a(yi),$(we,e),e&&a(qi),e&&a(ga),e&&a(wi),$(_s,e),e&&a(ki),e&&a(ee),e&&a(zi),$(bs,e),e&&a(Pi),e&&a(ke),e&&a(Di),$(vs,e),e&&a(Hi),$(xs,e),e&&a(Oi),e&&a(se),e&&a(Ci),e&&a(_a),e&&a(Ti),e&&a(ze),e&&a(Ai),e&&a(ba),e&&a(Ni),e&&a(me),$(Es),e&&a(Ii),e&&a(G),e&&a(Gi),$(ys,e),e&&a(Ri),$(qs,e),e&&a(Si),e&&a(L),e&&a(Ui),$(ws,e),e&&a(Li),$(De,e),e&&a(Mi),e&&a(xa),e&&a(Fi),e&&a($a),e&&a(Bi),e&&a(he),$(ks),e&&a(Qi),e&&a(ja),e&&a(Ji),e&&a(zs),e&&a(Vi),e&&a(Oe),e&&a(Zi),$(Ds,e),e&&a(Ki),$(Hs,e),e&&a(Xi),e&&a(Z),e&&a(Wi),$(Os,e),e&&a(Yi),$(Cs,e),e&&a(el),e&&a(ae),e&&a(sl),$(Ts,e),e&&a(al),e&&a(Ea),e&&a(tl),$(As,e),e&&a(il),e&&a(ge),$(Ns),e&&a(ll),$(Is,e),e&&a(rl),e&&a(te),e&&a(ol),$(Rs,e),e&&a(nl),$(Ss,e),e&&a(ul),e&&a(Ae),e&&a(pl),e&&a(Ne),e&&a(cl),$(Us,e),e&&a(dl),e&&a(Ie),e&&a(ml),$(Ls,e),e&&a(hl),e&&a(Ge),e&&a(gl),$(Ms,e),e&&a(fl),$(Fs,e),e&&a(_l),e&&a(ie),e&&a(bl),$(Re,e),e&&a(vl),e&&a(Se),e&&a(xl),$(Bs,e),e&&a($l),e&&a(M),e&&a(jl),$(Qs,e),e&&a(El),e&&a(Ue),e&&a(yl),$(Js,e),e&&a(ql),e&&a(Le),e&&a(wl),e&&a(Vs),e&&a(kl),e&&a(le),e&&a(zl),$(Ks,e),e&&a(Pl),$(Xs,e),e&&a(Dl),e&&a(Me),e&&a(Hl),$(Fe,e),e&&a(Ol),e&&a(fe),$(Ws),e&&a(Cl),e&&a(ya),e&&a(Tl),e&&a(Qe),e&&a(Al),e&&a(qa),e&&a(Nl),e&&a(Ys),e&&a(Il),e&&a(sa),e&&a(Gl),e&&a(re),e&&a(Rl),e&&a(ia),e&&a(Sl),$(Ve,e),e&&a(Ul),e&&a(wa),e&&a(Ll),$(Ze,e)}}}const dd={local:"creare-il-proprio-dataset",sections:[{local:"recuperare-i-dati",title:"Recuperare i dati "},{local:"pulire-i-dati",title:"Pulire i dati"},{local:"estendere-il-dataset",title:"Estendere il dataset "},{local:"caricare-il-dataset-sullhub-hugging-face",title:"Caricare il dataset sull'Hub Hugging Face "},{local:"creare-una-dataset-card",title:"Creare una dataset card"}],title:"Creare il proprio dataset"};function md(S){return sd(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xd extends Xc{constructor(d){super();Wc(this,d,md,cd,Yc,{})}}export{xd as default,dd as metadata};
