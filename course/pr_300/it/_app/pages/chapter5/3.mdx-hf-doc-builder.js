import{S as U0,i as R0,s as M0,e as i,k as d,w as f,t as s,M as F0,c as n,d as a,m as p,a as l,x as h,h as o,b as m,f as L0,G as t,g as c,y as v,q as _,o as g,B as z,v as Q0}from"../../chunks/vendor-hf-doc-builder.js";import{T as fa}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Zz}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Bs}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as $}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as B0}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function J0(U){let u,T,b,D,k,E,x,C;return{c(){u=i("p"),T=s("\u270F\uFE0F "),b=i("strong"),D=s("Prova tu!"),k=s(" Usa la funzione "),E=i("code"),x=s("Dataset.unique()"),C=s(" per trovare il numero di medicine diverse e condizioni nelle sezioni di addestramento e di test.")},l(w){u=n(w,"P",{});var j=l(u);T=o(j,"\u270F\uFE0F "),b=n(j,"STRONG",{});var P=l(b);D=o(P,"Prova tu!"),P.forEach(a),k=o(j," Usa la funzione "),E=n(j,"CODE",{});var q=l(E);x=o(q,"Dataset.unique()"),q.forEach(a),C=o(j," per trovare il numero di medicine diverse e condizioni nelle sezioni di addestramento e di test."),j.forEach(a)},m(w,j){c(w,u,j),t(u,T),t(u,b),t(b,D),t(u,k),t(u,E),t(E,x),t(u,C)},d(w){w&&a(u)}}}function G0(U){let u,T,b,D,k,E,x,C;return{c(){u=i("p"),T=s("\u{1F64B}Un altro modo per aggiungere nuove colonne a un dataset \xE8 attraverso la funzione "),b=i("code"),D=s("Dataset.add_column()"),k=s(". Questo ti permette di inserire le colonne come una lista Python o unarray NumPy, e pu\xF2 tornare utile in situazioni in cui "),E=i("code"),x=s("Dataset.map()"),C=s(" non \xE8 indicata per le tue analisi.")},l(w){u=n(w,"P",{});var j=l(u);T=o(j,"\u{1F64B}Un altro modo per aggiungere nuove colonne a un dataset \xE8 attraverso la funzione "),b=n(j,"CODE",{});var P=l(b);D=o(P,"Dataset.add_column()"),P.forEach(a),k=o(j,". Questo ti permette di inserire le colonne come una lista Python o unarray NumPy, e pu\xF2 tornare utile in situazioni in cui "),E=n(j,"CODE",{});var q=l(E);x=o(q,"Dataset.map()"),q.forEach(a),C=o(j," non \xE8 indicata per le tue analisi."),j.forEach(a)},m(w,j){c(w,u,j),t(u,T),t(u,b),t(b,D),t(u,k),t(u,E),t(E,x),t(u,C)},d(w){w&&a(u)}}}function V0(U){let u,T,b,D,k,E,x,C,w,j,P;return{c(){u=i("p"),T=s("\u270F\uFE0F "),b=i("strong"),D=s("Prova tu!"),k=s(" Usa la funzione "),E=i("code"),x=s("Dataset.sort()"),C=s(" per analizzare le revisioni con il maggior numero di parole. Controlla la "),w=i("a"),j=s("documentazione"),P=s(" per vedere quali argomenti bisogna usare per ordinare le recensioni in ordine decrescente di lunghezza."),this.h()},l(q){u=n(q,"P",{});var y=l(u);T=o(y,"\u270F\uFE0F "),b=n(y,"STRONG",{});var G=l(b);D=o(G,"Prova tu!"),G.forEach(a),k=o(y," Usa la funzione "),E=n(y,"CODE",{});var N=l(E);x=o(N,"Dataset.sort()"),N.forEach(a),C=o(y," per analizzare le revisioni con il maggior numero di parole. Controlla la "),w=n(y,"A",{href:!0,rel:!0});var O=l(w);j=o(O,"documentazione"),O.forEach(a),P=o(y," per vedere quali argomenti bisogna usare per ordinare le recensioni in ordine decrescente di lunghezza."),y.forEach(a),this.h()},h(){m(w,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.sort"),m(w,"rel","nofollow")},m(q,y){c(q,u,y),t(u,T),t(u,b),t(b,D),t(u,k),t(u,E),t(E,x),t(u,C),t(u,w),t(w,j),t(u,P)},d(q){q&&a(u)}}}function Y0(U){let u,T,b,D,k,E,x,C,w,j,P,q,y,G;return{c(){u=i("p"),T=s("\u270F\uFE0F "),b=i("strong"),D=s("Prova tu!"),k=s(" Esegui la stessa istruzione con e senza "),E=i("code"),x=s("batched=True"),C=s(", poi prova con un tokenizzatore lento (aggiungi "),w=i("code"),j=s("add_fast=False"),P=s(" al metodo "),q=i("code"),y=s("AutoTokenizer.from_pretrained()"),G=s(") cos\xEC che puoi controllare i tempi sul tuo hardware.")},l(N){u=n(N,"P",{});var O=l(u);T=o(O,"\u270F\uFE0F "),b=n(O,"STRONG",{});var ge=l(b);D=o(ge,"Prova tu!"),ge.forEach(a),k=o(O," Esegui la stessa istruzione con e senza "),E=n(O,"CODE",{});var R=l(E);x=o(R,"batched=True"),R.forEach(a),C=o(O,", poi prova con un tokenizzatore lento (aggiungi "),w=n(O,"CODE",{});var W=l(w);j=o(W,"add_fast=False"),W.forEach(a),P=o(O," al metodo "),q=n(O,"CODE",{});var ie=l(q);y=o(ie,"AutoTokenizer.from_pretrained()"),ie.forEach(a),G=o(O,") cos\xEC che puoi controllare i tempi sul tuo hardware."),O.forEach(a)},m(N,O){c(N,u,O),t(u,T),t(u,b),t(b,D),t(u,k),t(u,E),t(E,x),t(u,C),t(u,w),t(w,j),t(u,P),t(u,q),t(q,y),t(u,G)},d(N){N&&a(u)}}}function W0(U){let u,T,b,D,k;return{c(){u=i("p"),T=s("Utilizzare "),b=i("code"),D=s("num_proc"),k=s(" per accelerare i processi \xE8 generalmente una buona idea, a patto che la funzione che stai utilizzando non stia gi\xE0 usando un qualche tipo di multiprocessing per conto proprio.")},l(E){u=n(E,"P",{});var x=l(u);T=o(x,"Utilizzare "),b=n(x,"CODE",{});var C=l(b);D=o(C,"num_proc"),C.forEach(a),k=o(x," per accelerare i processi \xE8 generalmente una buona idea, a patto che la funzione che stai utilizzando non stia gi\xE0 usando un qualche tipo di multiprocessing per conto proprio."),x.forEach(a)},m(E,x){c(E,u,x),t(u,T),t(u,b),t(b,D),t(u,k)},d(E){E&&a(u)}}}function X0(U){let u,T,b,D,k,E,x,C,w,j,P;return{c(){u=i("p"),T=s("\u{1F4A1} Nel machine learning, un "),b=i("em"),D=s("esempio"),k=s(" \xE8 solitamente definito come un insieme di "),E=i("em"),x=s("feature"),C=s(" che diamo in pasto al modello. In alcuni contesti, queste feature saranno l\u2019insieme delle colonne in un "),w=i("code"),j=s("Dataset"),P=s(", ma in altri casi (come ad esempio questo, o per il question answering), molte feature possono essere estratte da un singolo esempio, e appartenere a una sola colonna.")},l(q){u=n(q,"P",{});var y=l(u);T=o(y,"\u{1F4A1} Nel machine learning, un "),b=n(y,"EM",{});var G=l(b);D=o(G,"esempio"),G.forEach(a),k=o(y," \xE8 solitamente definito come un insieme di "),E=n(y,"EM",{});var N=l(E);x=o(N,"feature"),N.forEach(a),C=o(y," che diamo in pasto al modello. In alcuni contesti, queste feature saranno l\u2019insieme delle colonne in un "),w=n(y,"CODE",{});var O=l(w);j=o(O,"Dataset"),O.forEach(a),P=o(y,", ma in altri casi (come ad esempio questo, o per il question answering), molte feature possono essere estratte da un singolo esempio, e appartenere a una sola colonna."),y.forEach(a)},m(q,y){c(q,u,y),t(u,T),t(u,b),t(b,D),t(u,k),t(u,E),t(E,x),t(u,C),t(u,w),t(w,j),t(u,P)},d(q){q&&a(u)}}}function K0(U){let u,T,b,D,k,E,x,C,w,j,P,q,y,G,N,O,ge,R,W,ie,se,ha,Ge,Ve,zt,M;return{c(){u=i("p"),T=s("\u{1F6A8} Dietro le quinte, "),b=i("code"),D=s("Dataset.set_format()"),k=s(" modifica il formato di restituzione del meteodo dunder "),E=i("code"),x=s("__getitem__()"),C=s(" del dataset. Questo significa che quando vogliamo creare un nuovo oggetto come ad esempio "),w=i("code"),j=s("train_df"),P=s(" da un "),q=i("code"),y=s("Dataset"),G=s(" in formato "),N=i("code"),O=s('"pandas"'),ge=s(", abbiamo bisogno di suddividere l\u2019intero dataset per ottenere un "),R=i("code"),W=s("pandas.DataFrame"),ie=s(". Puoi verificare da te che "),se=i("code"),ha=s('drug_dataset["train"]'),Ge=s(" ha come tipo "),Ve=i("code"),zt=s("Dataset"),M=s(", a prescindere dal formato di output.")},l(Ye){u=n(Ye,"P",{});var A=l(u);T=o(A,"\u{1F6A8} Dietro le quinte, "),b=n(A,"CODE",{});var Js=l(b);D=o(Js,"Dataset.set_format()"),Js.forEach(a),k=o(A," modifica il formato di restituzione del meteodo dunder "),E=n(A,"CODE",{});var Gs=l(E);x=o(Gs,"__getitem__()"),Gs.forEach(a),C=o(A," del dataset. Questo significa che quando vogliamo creare un nuovo oggetto come ad esempio "),w=n(A,"CODE",{});var $t=l(w);j=o($t,"train_df"),$t.forEach(a),P=o(A," da un "),q=n(A,"CODE",{});var Vs=l(q);y=o(Vs,"Dataset"),Vs.forEach(a),G=o(A," in formato "),N=n(A,"CODE",{});var Ys=l(N);O=o(Ys,'"pandas"'),Ys.forEach(a),ge=o(A,", abbiamo bisogno di suddividere l\u2019intero dataset per ottenere un "),R=n(A,"CODE",{});var bt=l(R);W=o(bt,"pandas.DataFrame"),bt.forEach(a),ie=o(A,". Puoi verificare da te che "),se=n(A,"CODE",{});var Ws=l(se);ha=o(Ws,'drug_dataset["train"]'),Ws.forEach(a),Ge=o(A," ha come tipo "),Ve=n(A,"CODE",{});var Xs=l(Ve);zt=o(Xs,"Dataset"),Xs.forEach(a),M=o(A,", a prescindere dal formato di output."),A.forEach(a)},m(Ye,A){c(Ye,u,A),t(u,T),t(u,b),t(b,D),t(u,k),t(u,E),t(E,x),t(u,C),t(u,w),t(w,j),t(u,P),t(u,q),t(q,y),t(u,G),t(u,N),t(N,O),t(u,ge),t(u,R),t(R,W),t(u,ie),t(u,se),t(se,ha),t(u,Ge),t(u,Ve),t(Ve,zt),t(u,M)},d(Ye){Ye&&a(u)}}}function Z0(U){let u,T,b,D,k,E,x,C;return{c(){u=i("p"),T=s("\u270F\uFE0F "),b=i("strong"),D=s("Prova tu!"),k=s(" Calcola la valutazione media per i medicinali, e salviamo i risultati in un nuovo "),E=i("code"),x=s("Dataset"),C=s(".")},l(w){u=n(w,"P",{});var j=l(u);T=o(j,"\u270F\uFE0F "),b=n(j,"STRONG",{});var P=l(b);D=o(P,"Prova tu!"),P.forEach(a),k=o(j," Calcola la valutazione media per i medicinali, e salviamo i risultati in un nuovo "),E=n(j,"CODE",{});var q=l(E);x=o(q,"Dataset"),q.forEach(a),C=o(j,"."),j.forEach(a)},m(w,j){c(w,u,j),t(u,T),t(u,b),t(b,D),t(u,k),t(u,E),t(E,x),t(u,C)},d(w){w&&a(u)}}}function e3(U){let u,T,b,D,k,E,x,C,w,j,P,q,y,G,N,O,ge,R,W,ie,se,ha,Ge,Ve,zt,M,Ye,A,Js,Gs,$t,Vs,Ys,bt,Ws,Xs,Ks,Ru,Mu,md,ne,Fu,va,Qu,Bu,Hi,Ju,Gu,Si,Vu,Yu,fd,_a,hd,le,Wu,Li,Xu,Ku,Ui,Zu,em,Ri,tm,am,vd,ga,_d,be,sm,Mi,om,im,Fi,nm,lm,gd,za,zd,$a,$d,re,rm,Qi,dm,pm,Bi,cm,um,Ji,mm,fm,bd,Ee,ba,hm,Gi,vm,_m,gm,Ea,zm,Vi,$m,bm,Em,We,wm,Yi,jm,Dm,Wi,xm,km,Ed,we,qm,Xi,Tm,Cm,Ki,ym,Pm,wd,wa,jd,je,Om,Zi,Am,Nm,en,Im,Hm,Dd,ja,xd,Da,kd,Et,qd,X,Sm,tn,Lm,Um,an,Rm,Mm,Zs,Fm,Qm,sn,Bm,Jm,Td,xa,Cd,ka,yd,K,Gm,on,Vm,Ym,nn,Wm,Xm,ln,Km,Zm,rn,ef,tf,Pd,qa,Od,De,af,dn,sf,of,pn,nf,lf,Ad,Ta,Nd,xe,rf,cn,df,pf,un,cf,uf,Id,Ca,Hd,eo,mf,Sd,ya,Ld,Pa,Ud,to,ff,Rd,Oa,Md,Aa,Fd,ke,hf,Na,vf,_f,mn,gf,zf,Qd,Ia,Bd,qe,$f,fn,bf,Ef,hn,wf,jf,Jd,Ha,Gd,Sa,Vd,ao,Df,Yd,Xe,wt,vn,La,xf,_n,kf,Wd,so,qf,Xd,oo,Tf,Kd,Ua,Zd,V,Cf,gn,yf,Pf,zn,Of,Af,$n,Nf,If,bn,Hf,Sf,En,Lf,Uf,ep,Ra,tp,Ma,ap,Te,Rf,wn,Mf,Ff,jn,Qf,Bf,sp,Fa,op,Qa,ip,io,Jf,np,jt,lp,Ce,Gf,Dn,Vf,Yf,xn,Wf,Xf,rp,Ba,dp,Ja,pp,no,Kf,cp,Dt,up,xt,Zf,kn,eh,th,mp,Ga,fp,Va,hp,kt,ah,qn,sh,oh,vp,Ya,_p,qt,ih,Tn,nh,lh,gp,Ke,Tt,Cn,Wa,rh,lo,dh,yn,ph,zp,de,ch,Pn,uh,mh,On,fh,hh,An,vh,_h,$p,Z,gh,Nn,zh,$h,In,bh,Eh,Hn,wh,jh,Sn,Dh,xh,bp,Xa,Ep,Ct,kh,Ln,qh,Th,wp,pe,Ch,Un,yh,Ph,Rn,Oh,Ah,ro,Nh,Ih,jp,Ka,Dp,ce,Hh,po,Sh,Lh,Mn,Uh,Rh,Fn,Mh,Fh,xp,Za,kp,yt,Qh,Qn,Bh,Jh,qp,Pt,Tp,co,Gh,Cp,Ot,Bn,Ze,uo,Vh,Yh,mo,Wh,Xh,fo,Kh,Zh,es,et,ho,Jn,ev,tv,vo,av,sv,_o,ov,iv,tt,go,Gn,nv,lv,zo,rv,dv,$o,pv,yp,ue,cv,Vn,uv,mv,Yn,fv,hv,Wn,vv,_v,Pp,At,gv,Xn,zv,$v,Op,ze,Kn,bv,Ev,Zn,wv,jv,el,Dv,xv,Ap,ts,Np,bo,kv,Ip,Nt,tl,at,Eo,qv,Tv,wo,Cv,yv,jo,Pv,Ov,$e,st,Do,al,Av,Nv,xo,Iv,Hv,ko,Sv,Lv,ot,qo,sl,Uv,Rv,To,Mv,Fv,Co,Qv,Bv,it,It,ol,Jv,Gv,il,Vv,Yv,yo,Wv,Xv,Po,Kv,Zv,nt,Ht,nl,e_,t_,ll,a_,s_,Oo,o_,i_,Ao,n_,Hp,ee,l_,rl,r_,d_,dl,p_,c_,pl,u_,m_,cl,f_,h_,Sp,St,Lp,me,v_,ul,__,g_,ml,z_,$_,No,b_,E_,Up,Lt,Rp,ye,w_,fl,j_,D_,hl,x_,k_,Mp,as,Fp,Ut,q_,vl,T_,C_,Qp,ss,Bp,os,Jp,Io,y_,Gp,is,Vp,ns,Yp,Pe,P_,ls,O_,A_,_l,N_,I_,Wp,te,H_,gl,S_,L_,zl,U_,R_,$l,M_,F_,bl,Q_,B_,Xp,rs,Kp,Ho,J_,Zp,ds,ec,ps,tc,Oe,G_,El,V_,Y_,wl,W_,X_,ac,cs,sc,Rt,K_,jl,Z_,eg,oc,us,ic,ms,nc,So,tg,lc,Mt,ag,Dl,sg,og,rc,lt,Ft,xl,fs,ig,rt,ng,kl,lg,rg,ql,dg,pg,dc,hs,pc,ae,cg,Tl,ug,mg,Cl,fg,hg,yl,vg,_g,Pl,gg,zg,cc,vs,uc,Qt,$g,Ol,bg,Eg,mc,_s,fc,Ae,Al,I,hc,wg,Nl,jg,Dg,Il,xg,kg,Hl,qg,Tg,Sl,Cg,yg,Ll,Pg,Og,Ul,Ag,Ng,Rl,Ig,Hg,Ml,Sg,Lg,dt,H,Fl,Ug,Rg,Ql,Mg,Fg,Bl,Qg,Bg,Jl,Jg,Gg,Gl,Vg,Yg,Vl,Wg,Xg,Yl,Kg,Zg,Wl,e2,t2,Xl,a2,s2,S,Kl,o2,i2,Zl,n2,l2,er,r2,d2,tr,p2,c2,ar,u2,m2,sr,f2,h2,or,v2,_2,ir,g2,z2,nr,$2,b2,L,lr,E2,w2,rr,j2,D2,dr,x2,k2,pr,q2,T2,cr,C2,y2,ur,P2,O2,mr,A2,N2,fr,I2,H2,hr,S2,vc,Ne,L2,vr,U2,R2,_r,M2,F2,_c,gs,gc,Bt,zc,Jt,Q2,gr,B2,J2,$c,zs,bc,Ie,zr,He,Ec,G2,$r,V2,Y2,br,W2,X2,oe,pt,Er,K2,Z2,wr,e1,t1,jr,a1,s1,ct,Dr,o1,i1,xr,n1,l1,kr,r1,d1,ut,qr,p1,c1,Tr,u1,m1,Cr,f1,h1,mt,yr,v1,_1,Pr,g1,z1,Or,$1,b1,ft,Ar,E1,w1,Nr,j1,D1,Ir,x1,wc,Se,k1,Hr,q1,T1,Sr,C1,y1,jc,$s,Dc,bs,xc,Gt,kc,fe,P1,Lr,O1,A1,Ur,N1,I1,Rr,H1,S1,qc,Es,Tc,ht,Vt,Mr,ws,L1,Fr,U1,Cc,Lo,R1,yc,Y,M1,Qr,F1,Q1,Br,B1,J1,Jr,G1,V1,Gr,Y1,W1,Vr,X1,K1,Pc,js,Oc,Ds,Ac,Yt,Z1,Uo,ez,tz,Nc,vt,Wt,Yr,xs,az,Wr,sz,Ic,ks,Hc,Ro,oz,Sc,Xt,Xr,qs,Mo,iz,nz,Fo,lz,rz,_t,Ts,Qo,dz,pz,Bo,Kr,cz,uz,Cs,Jo,mz,fz,Go,Zr,hz,vz,ys,Vo,_z,gz,Yo,ed,zz,Lc,Wo,$z,Uc,Ps,Rc,Xo,bz,Mc,Os,Fc,he,Ez,td,wz,jz,ad,Dz,xz,sd,kz,qz,Qc,Kt,Tz,od,Cz,yz,Bc,As,Jc,Ns,Gc,Zt,Pz,id,Oz,Az,Vc,Is,Yc,ea,Nz,Hs,Iz,Hz,Wc,Ss,Xc,Ls,Kc,ta,Sz,Ko,Lz,Uz,Zc,Us,eu,Zo,Rz,tu,aa,Rs,Mz,ei,Fz,Qz,Bz,gt,Jz,nd,Gz,Vz,ti,Yz,Wz,au,ai,Xz,su;return E=new Bs({}),P=new B0({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"}]}}),O=new Zz({props:{id:"tqfSFcPMgOI"}}),se=new Bs({}),_a=new $({props:{code:`!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip`,highlighted:`!wget <span class="hljs-string">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip&quot;</span>
!unzip drugsCom_raw.<span class="hljs-built_in">zip</span>`}}),ga=new $({props:{code:`from datasets import load_dataset

data_files = {"train": "drugsComTrain_raw.tsv", "test": "drugsComTest_raw.tsv"}
# \\t rappresenta il tabulatore in Python
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\\t")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;drugsComTrain_raw.tsv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;drugsComTest_raw.tsv&quot;</span>}
<span class="hljs-comment"># \\t rappresenta il tabulatore in Python</span>
drug_dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="hljs-string">&quot;\\t&quot;</span>)`}}),za=new $({props:{code:`drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Diamo un'occhiata ai primi esempi
drug_sample[:3]`,highlighted:`drug_sample = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-comment"># Diamo un&#x27;occhiata ai primi esempi</span>
drug_sample[:<span class="hljs-number">3</span>]`}}),$a=new $({props:{code:`{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}`,highlighted:`{<span class="hljs-string">&#x27;Unnamed: 0&#x27;</span>: [<span class="hljs-number">87571</span>, <span class="hljs-number">178045</span>, <span class="hljs-number">80482</span>],
 <span class="hljs-string">&#x27;drugName&#x27;</span>: [<span class="hljs-string">&#x27;Naproxen&#x27;</span>, <span class="hljs-string">&#x27;Duloxetine&#x27;</span>, <span class="hljs-string">&#x27;Mobic&#x27;</span>],
 <span class="hljs-string">&#x27;condition&#x27;</span>: [<span class="hljs-string">&#x27;Gout, Acute&#x27;</span>, <span class="hljs-string">&#x27;ibromyalgia&#x27;</span>, <span class="hljs-string">&#x27;Inflammatory Conditions&#x27;</span>],
 <span class="hljs-string">&#x27;review&#x27;</span>: [<span class="hljs-string">&#x27;&quot;like the previous person mention, I&amp;#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!&quot;&#x27;</span>,
  <span class="hljs-string">&#x27;&quot;I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.&quot;&#x27;</span>,
  <span class="hljs-string">&#x27;&quot;I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.&quot;&#x27;</span>],
 <span class="hljs-string">&#x27;rating&#x27;</span>: [<span class="hljs-number">9.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">10.0</span>],
 <span class="hljs-string">&#x27;date&#x27;</span>: [<span class="hljs-string">&#x27;September 2, 2015&#x27;</span>, <span class="hljs-string">&#x27;November 7, 2011&#x27;</span>, <span class="hljs-string">&#x27;June 5, 2013&#x27;</span>],
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: [<span class="hljs-number">36</span>, <span class="hljs-number">13</span>, <span class="hljs-number">128</span>]}`}}),wa=new $({props:{code:`for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))`,highlighted:`<span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> drug_dataset.keys():
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(drug_dataset[split]) == <span class="hljs-built_in">len</span>(drug_dataset[split].unique(<span class="hljs-string">&quot;Unnamed: 0&quot;</span>))`}}),ja=new $({props:{code:`drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset`,highlighted:`drug_dataset = drug_dataset.rename_column(
    original_column_name=<span class="hljs-string">&quot;Unnamed: 0&quot;</span>, new_column_name=<span class="hljs-string">&quot;patient_id&quot;</span>
)
drug_dataset`}}),Da=new $({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">161297</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">53766</span>
    })
})`}}),Et=new fa({props:{$$slots:{default:[J0]},$$scope:{ctx:U}}}),xa=new $({props:{code:`def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">lowercase_condition</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;condition&quot;</span>: example[<span class="hljs-string">&quot;condition&quot;</span>].lower()}


drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)`}}),ka=new $({props:{code:"AttributeError: 'NoneType' object has no attribute 'lower'",highlighted:'AttributeError: <span class="hljs-string">&#x27;NoneType&#x27;</span> <span class="hljs-built_in">object</span> has no attribute <span class="hljs-string">&#x27;lower&#x27;</span>'}}),qa=new $({props:{code:`def filter_nones(x):
    return x["condition"] is not None`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_nones</span>(<span class="hljs-params">x</span>):
    <span class="hljs-keyword">return</span> x[<span class="hljs-string">&quot;condition&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>`}}),Ta=new $({props:{code:"lambda <argomenti> : <espressione>",highlighted:'lambda <span class="hljs-tag">&lt;<span class="hljs-name">argomenti</span>&gt;</span> : <span class="hljs-tag">&lt;<span class="hljs-name">espressione</span>&gt;</span>'}}),Ca=new $({props:{code:"lambda x : x * x",highlighted:'lambda <span class="hljs-keyword">x</span> : <span class="hljs-keyword">x</span> * <span class="hljs-keyword">x</span>'}}),ya=new $({props:{code:"(lambda x: x * x)(3)",highlighted:'(<span class="hljs-keyword">lambda</span> x: x * x)(<span class="hljs-number">3</span>)'}}),Pa=new $({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),Oa=new $({props:{code:"(lambda base, altezza: 0.5 * base * altezza)(4, 8)",highlighted:'(<span class="hljs-keyword">lambda</span> base, altezza: <span class="hljs-number">0.5</span> * base * altezza)(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>)'}}),Aa=new $({props:{code:"16.0",highlighted:'<span class="hljs-number">16.0</span>'}}),Ia=new $({props:{code:'drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)',highlighted:'drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;condition&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)'}}),Ha=new $({props:{code:`drug_dataset = drug_dataset.map(lowercase_condition)
# Check that lowercasing worked
drug_dataset["train"]["condition"][:3]`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)
<span class="hljs-comment"># Check that lowercasing worked</span>
drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;condition&quot;</span>][:<span class="hljs-number">3</span>]`}}),Sa=new $({props:{code:"['left ventricular dysfunction', 'adhd', 'birth control']",highlighted:'[<span class="hljs-string">&#x27;left ventricular dysfunction&#x27;</span>, <span class="hljs-string">&#x27;adhd&#x27;</span>, <span class="hljs-string">&#x27;birth control&#x27;</span>]'}}),La=new Bs({}),Ua=new $({props:{code:`def compute_review_length(example):
    return {"review_length": len(example["review"].split())}`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_review_length</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;review_length&quot;</span>: <span class="hljs-built_in">len</span>(example[<span class="hljs-string">&quot;review&quot;</span>].split())}`}}),Ra=new $({props:{code:`drug_dataset = drug_dataset.map(compute_review_length)
# Inspect the first training example
drug_dataset["train"][0]`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(compute_review_length)
<span class="hljs-comment"># Inspect the first training example</span>
drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]`}}),Ma=new $({props:{code:`{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}`,highlighted:`{<span class="hljs-string">&#x27;patient_id&#x27;</span>: <span class="hljs-number">206461</span>,
 <span class="hljs-string">&#x27;drugName&#x27;</span>: <span class="hljs-string">&#x27;Valsartan&#x27;</span>,
 <span class="hljs-string">&#x27;condition&#x27;</span>: <span class="hljs-string">&#x27;left ventricular dysfunction&#x27;</span>,
 <span class="hljs-string">&#x27;review&#x27;</span>: <span class="hljs-string">&#x27;&quot;It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil&quot;&#x27;</span>,
 <span class="hljs-string">&#x27;rating&#x27;</span>: <span class="hljs-number">9.0</span>,
 <span class="hljs-string">&#x27;date&#x27;</span>: <span class="hljs-string">&#x27;May 20, 2012&#x27;</span>,
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: <span class="hljs-number">27</span>,
 <span class="hljs-string">&#x27;review_length&#x27;</span>: <span class="hljs-number">17</span>}`}}),Fa=new $({props:{code:'drug_dataset["train"].sort("review_length")[:3]',highlighted:'drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].sort(<span class="hljs-string">&quot;review_length&quot;</span>)[:<span class="hljs-number">3</span>]'}}),Qa=new $({props:{code:`{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}`,highlighted:`{<span class="hljs-string">&#x27;patient_id&#x27;</span>: [<span class="hljs-number">103488</span>, <span class="hljs-number">23627</span>, <span class="hljs-number">20558</span>],
 <span class="hljs-string">&#x27;drugName&#x27;</span>: [<span class="hljs-string">&#x27;Loestrin 21 1 / 20&#x27;</span>, <span class="hljs-string">&#x27;Chlorzoxazone&#x27;</span>, <span class="hljs-string">&#x27;Nucynta&#x27;</span>],
 <span class="hljs-string">&#x27;condition&#x27;</span>: [<span class="hljs-string">&#x27;birth control&#x27;</span>, <span class="hljs-string">&#x27;muscle spasm&#x27;</span>, <span class="hljs-string">&#x27;pain&#x27;</span>],
 <span class="hljs-string">&#x27;review&#x27;</span>: [<span class="hljs-string">&#x27;&quot;Excellent.&quot;&#x27;</span>, <span class="hljs-string">&#x27;&quot;useless&quot;&#x27;</span>, <span class="hljs-string">&#x27;&quot;ok&quot;&#x27;</span>],
 <span class="hljs-string">&#x27;rating&#x27;</span>: [<span class="hljs-number">10.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">6.0</span>],
 <span class="hljs-string">&#x27;date&#x27;</span>: [<span class="hljs-string">&#x27;November 4, 2008&#x27;</span>, <span class="hljs-string">&#x27;March 24, 2017&#x27;</span>, <span class="hljs-string">&#x27;August 20, 2016&#x27;</span>],
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">10</span>],
 <span class="hljs-string">&#x27;review_length&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),jt=new fa({props:{$$slots:{default:[G0]},$$scope:{ctx:U}}}),Ba=new $({props:{code:`drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;review_length&quot;</span>] &gt; <span class="hljs-number">30</span>)
<span class="hljs-built_in">print</span>(drug_dataset.num_rows)`}}),Ja=new $({props:{code:"{'train': 138514, 'test': 46108}",highlighted:'{<span class="hljs-string">&#x27;train&#x27;</span>: <span class="hljs-number">138514</span>, <span class="hljs-string">&#x27;test&#x27;</span>: <span class="hljs-number">46108</span>}'}}),Dt=new fa({props:{$$slots:{default:[V0]},$$scope:{ctx:U}}}),Ga=new $({props:{code:`import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)`,highlighted:`<span class="hljs-keyword">import</span> html

text = <span class="hljs-string">&quot;I&amp;#039;m a transformer called BERT&quot;</span>
html.unescape(text)`}}),Va=new $({props:{code:`"I'm a transformer called BERT"`,highlighted:'<span class="hljs-string">&quot;I&#x27;m a transformer called BERT&quot;</span>'}}),Ya=new $({props:{code:'drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})',highlighted:'drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;review&quot;</span>: html.unescape(x[<span class="hljs-string">&quot;review&quot;</span>])})'}}),Wa=new Bs({}),Xa=new $({props:{code:`new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)`,highlighted:`new_drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(
    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;review&quot;</span>: [html.unescape(o) <span class="hljs-keyword">for</span> o <span class="hljs-keyword">in</span> x[<span class="hljs-string">&quot;review&quot;</span>]]}, batched=<span class="hljs-literal">True</span>
)`}}),Ka=new $({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")


def tokenize_function(examples):
    return tokenizer(examples["review"], truncation=True)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], truncation=<span class="hljs-literal">True</span>)`}}),Za=new $({props:{code:"%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)",highlighted:'%time tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)'}}),Pt=new fa({props:{$$slots:{default:[Y0]},$$scope:{ctx:U}}}),ts=new $({props:{code:`slow_tokenizer = AutoTokenizer.from_pretrained("bert-base-cased", use_fast=False)


def slow_tokenize_function(examples):
    return slow_tokenizer(examples["review"], truncation=True)


tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=True, num_proc=8)`,highlighted:`slow_tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, use_fast=<span class="hljs-literal">False</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">slow_tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> slow_tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(slow_tokenize_function, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">8</span>)`}}),St=new fa({props:{$$slots:{default:[W0]},$$scope:{ctx:U}}}),Lt=new fa({props:{$$slots:{default:[X0]},$$scope:{ctx:U}}}),as=new $({props:{code:`def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_split</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(
        examples[<span class="hljs-string">&quot;review&quot;</span>],
        truncation=<span class="hljs-literal">True</span>,
        max_length=<span class="hljs-number">128</span>,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
    )`}}),ss=new $({props:{code:`result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]`,highlighted:`result = tokenize_and_split(drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>])
[<span class="hljs-built_in">len</span>(inp) <span class="hljs-keyword">for</span> inp <span class="hljs-keyword">in</span> result[<span class="hljs-string">&quot;input_ids&quot;</span>]]`}}),os=new $({props:{code:"[128, 49]",highlighted:'[<span class="hljs-number">128</span>, <span class="hljs-number">49</span>]'}}),is=new $({props:{code:"tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)",highlighted:'tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_and_split, batched=<span class="hljs-literal">True</span>)'}}),ns=new $({props:{code:"ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000",highlighted:'ArrowInvalid: Column <span class="hljs-number">1</span> named condition expected length <span class="hljs-number">1463</span> but got length <span class="hljs-number">1000</span>'}}),rs=new $({props:{code:`tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)`,highlighted:`tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(
    tokenize_and_split, batched=<span class="hljs-literal">True</span>, remove_columns=drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].column_names
)`}}),ds=new $({props:{code:'len(tokenized_dataset["train"]), len(drug_dataset["train"])',highlighted:'<span class="hljs-built_in">len</span>(tokenized_dataset[<span class="hljs-string">&quot;train&quot;</span>]), <span class="hljs-built_in">len</span>(drug_dataset[<span class="hljs-string">&quot;train&quot;</span>])'}}),ps=new $({props:{code:"(206772, 138514)",highlighted:'(<span class="hljs-number">206772</span>, <span class="hljs-number">138514</span>)'}}),cs=new $({props:{code:`def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Estraiamo la mappatura tra gli indici vecchi e quelli nuovi
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_split</span>(<span class="hljs-params">examples</span>):
    result = tokenizer(
        examples[<span class="hljs-string">&quot;review&quot;</span>],
        truncation=<span class="hljs-literal">True</span>,
        max_length=<span class="hljs-number">128</span>,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
    )
    <span class="hljs-comment"># Estraiamo la mappatura tra gli indici vecchi e quelli nuovi</span>
    sample_map = result.pop(<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>)
    <span class="hljs-keyword">for</span> key, values <span class="hljs-keyword">in</span> examples.items():
        result[key] = [values[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sample_map]
    <span class="hljs-keyword">return</span> result`}}),us=new $({props:{code:`tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset`,highlighted:`tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_and_split, batched=<span class="hljs-literal">True</span>)
tokenized_dataset`}}),ms=new $({props:{code:`DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">206772</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">68876</span>
    })
})`}}),fs=new Bs({}),hs=new Zz({props:{id:"tfcY1067A5Q"}}),vs=new $({props:{code:'drug_dataset.set_format("pandas")',highlighted:'drug_dataset.set_format(<span class="hljs-string">&quot;pandas&quot;</span>)'}}),_s=new $({props:{code:'drug_dataset["train"][:3]',highlighted:'drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">3</span>]'}}),gs=new $({props:{code:'train_df = drug_dataset["train"][:]',highlighted:'train_df = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][:]'}}),Bt=new fa({props:{$$slots:{default:[K0]},$$scope:{ctx:U}}}),zs=new $({props:{code:`frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()`,highlighted:`frequencies = (
    train_df[<span class="hljs-string">&quot;condition&quot;</span>]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={<span class="hljs-string">&quot;index&quot;</span>: <span class="hljs-string">&quot;condition&quot;</span>, <span class="hljs-string">&quot;condition&quot;</span>: <span class="hljs-string">&quot;frequency&quot;</span>})
)
frequencies.head()`}}),$s=new $({props:{code:`from datasets import Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset`}}),bs=new $({props:{code:`Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;frequency&#x27;</span>],
    num_rows: <span class="hljs-number">819</span>
})`}}),Gt=new fa({props:{$$slots:{default:[Z0]},$$scope:{ctx:U}}}),Es=new $({props:{code:"drug_dataset.reset_format()",highlighted:"drug_dataset.reset_format()"}}),ws=new Bs({}),js=new $({props:{code:`drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# Rinominare la sezione di "test" in "validazione"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# Aggiungere il set "test" al nostor \`DatasetDict\`
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean`,highlighted:`drug_dataset_clean = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.8</span>, seed=<span class="hljs-number">42</span>)
<span class="hljs-comment"># Rinominare la sezione di &quot;test&quot; in &quot;validazione&quot;</span>
drug_dataset_clean[<span class="hljs-string">&quot;validation&quot;</span>] = drug_dataset_clean.pop(<span class="hljs-string">&quot;test&quot;</span>)
<span class="hljs-comment"># Aggiungere il set &quot;test&quot; al nostor \`DatasetDict\`</span>
drug_dataset_clean[<span class="hljs-string">&quot;test&quot;</span>] = drug_dataset[<span class="hljs-string">&quot;test&quot;</span>]
drug_dataset_clean`}}),Ds=new $({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">110811</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">27703</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">46108</span>
    })
})`}}),xs=new Bs({}),ks=new Zz({props:{id:"blF9uxYcKHo"}}),Ps=new $({props:{code:'drug_dataset_clean.save_to_disk("drug-reviews")',highlighted:'drug_dataset_clean.save_to_disk(<span class="hljs-string">&quot;drug-reviews&quot;</span>)'}}),Os=new $({props:{code:`drug-reviews/
\u251C\u2500\u2500 dataset_dict.json
\u251C\u2500\u2500 test
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u2514\u2500\u2500 state.json
\u251C\u2500\u2500 train
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u251C\u2500\u2500 indices.arrow
\u2502   \u2514\u2500\u2500 state.json
\u2514\u2500\u2500 validation
    \u251C\u2500\u2500 dataset.arrow
    \u251C\u2500\u2500 dataset_info.json
    \u251C\u2500\u2500 indices.arrow
    \u2514\u2500\u2500 state.json`,highlighted:`drug-reviews/
\u251C\u2500\u2500 dataset_dict.json
\u251C\u2500\u2500 test
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json
\u251C\u2500\u2500 train
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u251C\u2500\u2500 indices.arrow
\u2502   \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json
\u2514\u2500\u2500 validation
    \u251C\u2500\u2500 dataset.arrow
    \u251C\u2500\u2500 dataset_info.json
    \u251C\u2500\u2500 indices.arrow
    \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json`}}),As=new $({props:{code:`from datasets import load_from_disk

drug_dataset_reloaded = load_from_disk("drug-reviews")
drug_dataset_reloaded`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_from_disk

drug_dataset_reloaded = load_from_disk(<span class="hljs-string">&quot;drug-reviews&quot;</span>)
drug_dataset_reloaded`}}),Ns=new $({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">110811</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">27703</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">46108</span>
    })
})`}}),Is=new $({props:{code:`for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")`,highlighted:`<span class="hljs-keyword">for</span> split, dataset <span class="hljs-keyword">in</span> drug_dataset_clean.items():
    dataset.to_json(<span class="hljs-string">f&quot;drug-reviews-<span class="hljs-subst">{split}</span>.jsonl&quot;</span>)`}}),Ss=new $({props:{code:"!head -n 1 drug-reviews-train.jsonl",highlighted:'!head -n <span class="hljs-number">1</span> drug-reviews-train.jsonl'}}),Ls=new $({props:{code:`{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}`,highlighted:'{<span class="hljs-string">&quot;patient_id&quot;</span>:<span class="hljs-number">141780</span>,<span class="hljs-string">&quot;drugName&quot;</span>:<span class="hljs-string">&quot;Escitalopram&quot;</span>,<span class="hljs-string">&quot;condition&quot;</span>:<span class="hljs-string">&quot;depression&quot;</span>,<span class="hljs-string">&quot;review&quot;</span>:<span class="hljs-string">&quot;\\&quot;I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven&#x27;t worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\\&quot;&quot;</span>,<span class="hljs-string">&quot;rating&quot;</span>:<span class="hljs-number">9.0</span>,<span class="hljs-string">&quot;date&quot;</span>:<span class="hljs-string">&quot;May 29, 2011&quot;</span>,<span class="hljs-string">&quot;usefulCount&quot;</span>:<span class="hljs-number">10</span>,<span class="hljs-string">&quot;review_length&quot;</span>:<span class="hljs-number">125</span>}'}}),Us=new $({props:{code:`data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)`,highlighted:`data_files = {
    <span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;drug-reviews-train.jsonl&quot;</span>,
    <span class="hljs-string">&quot;validation&quot;</span>: <span class="hljs-string">&quot;drug-reviews-validation.jsonl&quot;</span>,
    <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;drug-reviews-test.jsonl&quot;</span>,
}
drug_dataset_reloaded = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files)`}}),{c(){u=i("meta"),T=d(),b=i("h1"),D=i("a"),k=i("span"),f(E.$$.fragment),x=d(),C=i("span"),w=s("\xC8 arrivato il momento di tagliuzzare"),j=d(),f(P.$$.fragment),q=d(),y=i("p"),G=s("La maggior parte delle volte, i dati su cui lavorerai non saranno perfettamente pronti a essere usati per l\u2019addestramento. In questa sezione esploreremo alcune funzionalit\xE0 di \u{1F917} Datasets per pulire i tuoi dataset."),N=d(),f(O.$$.fragment),ge=d(),R=i("h2"),W=i("a"),ie=i("span"),f(se.$$.fragment),ha=d(),Ge=i("span"),Ve=s("Tagliuzzare i tuoi dati"),zt=d(),M=i("p"),Ye=s("Proprio come Pandas, \u{1F917} Datasets offre diverse funzionalit\xE0 per manipolare il contenuto degli oggetti "),A=i("code"),Js=s("Dataset"),Gs=s(" e "),$t=i("code"),Vs=s("DatasetDict"),Ys=s(". Abbiamo gi\xE0 visto il metodo "),bt=i("code"),Ws=s("Dataset.map()"),Xs=s(" nel "),Ks=i("a"),Ru=s("Capitolo 3"),Mu=s(", e in questa sezione esploreremo altre funzioni a nostra disposizione."),md=d(),ne=i("p"),Fu=s("Ai fini di quest\u2019esempio useremo il "),va=i("a"),Qu=s("Drug Review Dataset"),Bu=s(`, che raccoglie le recensioni di pazienti su vari medicinali, assieme alla condizione curata e a una valutazione da 0 a 10 del grado di soddisfazione del paziente.
Prima di tutto scarichiamo ed estraiamo i dati, utilizzando i comandi `),Hi=i("code"),Ju=s("wget"),Gu=s(" e "),Si=i("code"),Vu=s("unzip"),Yu=s(":"),fd=d(),f(_a.$$.fragment),hd=d(),le=i("p"),Wu=s("Poich\xE9 TSV non \xE8 altro che una variante di CSV che usa come separatore tabulatori al posto delle virgole, caricheremo questi file utilizzando lo script "),Li=i("code"),Xu=s("csv"),Ku=s(" e specificando l\u2019argomento "),Ui=i("code"),Zu=s("delimiter"),em=s(" nella funzione "),Ri=i("code"),tm=s("load_dataset()"),am=s(", come segue:"),vd=d(),f(ga.$$.fragment),_d=d(),be=i("p"),sm=s("\xC8 buona prassi nell\u2019analisi dati recuperare un piccolo campione casuale per farsi un\u2019idea del tipo di dati con cui si sta lavorando. Utilizzando \u{1F917} Datasets, possiamo crare un campione casuale concatenando le funzioni "),Mi=i("code"),om=s("Dataset.shuffle()"),im=s(" e "),Fi=i("code"),nm=s("Dataset.select()"),lm=s(":"),gd=d(),f(za.$$.fragment),zd=d(),f($a.$$.fragment),$d=d(),re=i("p"),rm=s("Da notare che abbiamo impostato il seed in "),Qi=i("code"),dm=s("Dataset.shuffle()"),pm=s(" per motivi di riproducibilit\xE0. "),Bi=i("code"),cm=s("Dataset.select()"),um=s(" ha bisogno di un iterabile di indici, per cui abbiamo utilizzato "),Ji=i("code"),mm=s("range(1000)"),fm=s(" per recuperare i primi 1.000 esempi dal dataset mescolato. Da questo campione possiamo gi\xE0 vedere alcune particolarit\xE0 del nostor dataset:"),bd=d(),Ee=i("ul"),ba=i("li"),hm=s("La colonna "),Gi=i("code"),vm=s("Unnamed: 0"),_m=s(" assomiglia molto a un ID anonimizzato per ognuno dei pazienti."),gm=d(),Ea=i("li"),zm=s("La colonna "),Vi=i("code"),$m=s("condizione"),bm=s(" include un mix di etichette maiuscole e minuscole."),Em=d(),We=i("li"),wm=s("Le recensioni sono di diversa lunghezza e contengono un mix di separatori di riga Python ("),Yi=i("code"),jm=s("\\r\\n"),Dm=s(") e di codici di caratteri HTML come "),Wi=i("code"),xm=s("&\\#039"),km=s("."),Ed=d(),we=i("p"),qm=s("Ora vediamo come utilizzare \u{1F917} Datasets per risolvere alcuni di questi problemi. Per confermare l\u2019ipotesi che la colonna "),Xi=i("code"),Tm=s("Unnamed: 0"),Cm=s(" rappresenti gli ID dei pazienti, possiamo usare la funzione "),Ki=i("code"),ym=s("Dataset.unique()"),Pm=s(" per verificare che il numero di ID corrisponda al numero delle righe in ognuna delle sezioni:"),wd=d(),f(wa.$$.fragment),jd=d(),je=i("p"),Om=s("Questo sembra confermare la nostra ipotesi, quindi puliamo un po\u2019 il nostro dataset cambiando il nome della colonna "),Zi=i("code"),Am=s("Unnamed: 0"),Nm=s(" in qualcosa di un po\u2019 pi\xF9 comprensibile. Possiamo usare la funzione "),en=i("code"),Im=s("DatasetDict.rename_column()"),Hm=s(" per rinominare la colonna in entrambe le sezioni:"),Dd=d(),f(ja.$$.fragment),xd=d(),f(Da.$$.fragment),kd=d(),f(Et.$$.fragment),qd=d(),X=i("p"),Sm=s("Ora, normaliziamo le etichette in "),tn=i("code"),Lm=s("condition"),Um=s(" utilizzando "),an=i("code"),Rm=s("Dataset.map()"),Mm=s(". Cos\xEC come abbiamo fatto con la tokenizzazione nel "),Zs=i("a"),Fm=s("Capitolo 3"),Qm=s(", possiamo definire una semplice funzione che pu\xF2 essere applicata a tutte le righe di ogni sezione nel "),sn=i("code"),Bm=s("drug_dataset"),Jm=s(":"),Td=d(),f(xa.$$.fragment),Cd=d(),f(ka.$$.fragment),yd=d(),K=i("p"),Gm=s("Oh no, abbiamo incontrato un problema con la nostra funzione! Dall\u2019errore possiamo dedurre che alcuni dei valori nella colonna "),on=i("code"),Vm=s("condition"),Ym=s(" sono "),nn=i("code"),Wm=s("None"),Xm=s(", che non essendo stringhe non possono essere convertiti in lettere minuscole. Eliminiamo queste righe utilizzando "),ln=i("code"),Km=s("Dataset.filter()"),Zm=s(", che funziona come "),rn=i("code"),ef=s("Dataset.map()"),tf=s(" e accetta una funziona che riceve un singolo esempio del dataset. Invece di scrivere una funzione esplicita come:"),Pd=d(),f(qa.$$.fragment),Od=d(),De=i("p"),af=s("e utilizzare "),dn=i("code"),sf=s("drug_dataset.filter(filter_nones)"),of=s(", possiamo utilizzare una "),pn=i("em"),nf=s("funzione lambda"),lf=s(" e completare tutto in un\u2019unica riga. In Python, le funzioni lambda sono funzioni che possiamo definire senza nominarle esplicitamente. Hanno la forma generale:"),Ad=d(),f(Ta.$$.fragment),Nd=d(),xe=i("p"),rf=s("dove "),cn=i("code"),df=s("lambda' \xE8 una delle [keyword](https://docs.python.org/3/reference/lexical_analysis.html#keywords) speciali di Python, "),pf=s("<argomenti>"),un=i("code"),cf=s("\xE8 una lista/set di valori separati da virgole che definisce l'input della funzione, e"),uf=s("<espressione>` rappresenta le operazioni che vogliamo eseguire. Ad esempio, posiamo definire una semplice funzione lamda che calcola il quadrato di un numero:"),Id=d(),f(Ca.$$.fragment),Hd=d(),eo=i("p"),mf=s("Per applicare questa funzione a un input, dobbiamo includere sia la funzione che l\u2019input in parentesi:"),Sd=d(),f(ya.$$.fragment),Ld=d(),f(Pa.$$.fragment),Ud=d(),to=i("p"),ff=s("Allo stesso modo, possiamo definire funzioni lmabda con argomenti multipli separandoli con virgoli. Ad esempio, possiamo calcolare l\u2019area di un triangolo come segue:"),Rd=d(),f(Oa.$$.fragment),Md=d(),f(Aa.$$.fragment),Fd=d(),ke=i("p"),hf=s("Le funzioni lambda sono utili quando vogliamo definire piccole funzioni monouso (per maggiori informazioni, invitiamo alla lettura dell\u2019ottimo "),Na=i("a"),vf=s("tutorial di Real Python"),_f=s(" di Andre Burgaud). In \u{1F917} Datasets, possiamo usare le funzioni lambda per definire semplici operazioni di mappatura e filtraggio. Utilizziamo questo trucchetto per eliminare i valori "),mn=i("code"),gf=s("None"),zf=s(" nel nostro dataset:"),Qd=d(),f(Ia.$$.fragment),Bd=d(),qe=i("p"),$f=s("Una volta rimosse le voci "),fn=i("code"),bf=s("None"),Ef=s(", possiamo normalizzare la colonna "),hn=i("code"),wf=s("condition"),jf=s(":"),Jd=d(),f(Ha.$$.fragment),Gd=d(),f(Sa.$$.fragment),Vd=d(),ao=i("p"),Df=s("Funziona! Or ache abbiamo pulito le nostre etichette, diamo un\u2019occhiata a come pulire le recensioni."),Yd=d(),Xe=i("h2"),wt=i("a"),vn=i("span"),f(La.$$.fragment),xf=d(),_n=i("span"),kf=s("Creare nuove colonne"),Wd=d(),so=i("p"),qf=s("Quando abbiamo a che fare con le recensioni di clienti, \xE8 buona pratica controllare il numero di parole in ogni recensione. Una recensione potrebbe contenere solo una parola com \u201COttimo!\u201D o un vero e proprio saggio di migliaia di parole, e a seconda dell\u2019uso che ne farai dovrai affrontare queste situazioni in maniera diversa. Per calculare il numero di parole in ogni recensione, useremo un\u2019euristica grezza basata sulla divisione dei testi sugli spazi."),Xd=d(),oo=i("p"),Tf=s("Definiamo una semplice funzione che conta il numero di parole in ogni recensione:"),Kd=d(),f(Ua.$$.fragment),Zd=d(),V=i("p"),Cf=s("A differenza della nostra funzione "),gn=i("code"),yf=s("lowercase_condition()"),Pf=s(", "),zn=i("code"),Of=s("compute_review_length()"),Af=s(" ritorna un dizionario le cui chiavi non corrispondono a nessuna delle colonne nel dataset. In questo caso, quando "),$n=i("code"),Nf=s("compute_review_length()"),If=s(" \xE8 passata a "),bn=i("code"),Hf=s("Dataset.map()"),Sf=s(", si applicher\xE0 a tutte le righe nel dataset per creare una nuova colonna "),En=i("code"),Lf=s("review_lenght"),Uf=s(";"),ep=d(),f(Ra.$$.fragment),tp=d(),f(Ma.$$.fragment),ap=d(),Te=i("p"),Rf=s("Come previsto, una colonna "),wn=i("code"),Mf=s("review_length"),Ff=s(" \xE8 stata aggiunta al nostro set di addestramento. Possiamo ordinare questa nuova colonna utilizzando "),jn=i("code"),Qf=s("Dataset.sort()"),Bf=s(" per dare un\u2019occhiata ai valori estremi:"),sp=d(),f(Fa.$$.fragment),op=d(),f(Qa.$$.fragment),ip=d(),io=i("p"),Jf=s("Come sospettato, alcune revisioni contengono una sola parola che, bench\xE9 potrebbe essere utile per la sentiment analysis, non d\xE0 informazioni utili per predirre la condizione."),np=d(),f(jt.$$.fragment),lp=d(),Ce=i("p"),Gf=s("Usiamo la funzione "),Dn=i("code"),Vf=s("Dataset.filter()"),Yf=s(" per rimuovere le recensioni che contengono meno di 30 parole. Proprio come abbiamo fatto per la colonna "),xn=i("code"),Wf=s("condizione"),Xf=s(", possiamo eliminare le recensioni pi\xF9 brevi aggiungendo un filtro che lascia passare solo le recensioni pi\xF9 lunghe di una certa soglia:"),rp=d(),f(Ba.$$.fragment),dp=d(),f(Ja.$$.fragment),pp=d(),no=i("p"),Kf=s("Come puoi vedere, questo ha rimosso circa il 15% delle recensioni nelle sezioni di training e di test."),cp=d(),f(Dt.$$.fragment),up=d(),xt=i("p"),Zf=s("L\u2019ultima cosa che ci resta da risolvere \xE8 la presenza di codici HTML di caratteri nelle nostre recensioni. Possiamo usare il modulo Python "),kn=i("code"),eh=s("html"),th=s(" per sostituirli, cos\xEC:"),mp=d(),f(Ga.$$.fragment),fp=d(),f(Va.$$.fragment),hp=d(),kt=i("p"),ah=s("We\u2019ll use "),qn=i("code"),sh=s("Dataset.map()"),oh=s(" to unescape all the HTML characters in our corpus:"),vp=d(),f(Ya.$$.fragment),_p=d(),qt=i("p"),ih=s("Come puoi vedere, il metodo "),Tn=i("code"),nh=s("Dataset.map()"),lh=s(" \xE8 molto utile per processare i dati \u2014 e questo non \xE8 che la punta dell\u2019iceberg di ci\xF2 che \xE8 in grado di fare!"),gp=d(),Ke=i("h2"),Tt=i("a"),Cn=i("span"),f(Wa.$$.fragment),rh=d(),lo=i("span"),dh=s("I superpoteri del metodo "),yn=i("code"),ph=s("map()"),zp=d(),de=i("p"),ch=s("Il metodo "),Pn=i("code"),uh=s("Dataset.map()"),mh=s(" accetta un argomento "),On=i("code"),fh=s("batched"),hh=s(" che, se impostato su "),An=i("code"),vh=s("True"),_h=s(", gli fa inviare un batch di esempi alla funzione map in una sola volta (la grandezza del batch \xE8 configurabile, ma di default \xE8 impostta a 1.000). Ad esempio, l\u2019esecuzione delle funzione map precedente che ha sostituito tutti i caratteri HTML \xE8 stata un po\u2019 lenta (puoi leggere il tempo impiegato dalle barre di progresso). Possiamo accelerare questo processo processando diversi elementi in contemporanea usando una comprensione di lista."),$p=d(),Z=i("p"),gh=s("Quando si specifica "),Nn=i("code"),zh=s("batched=True"),$h=s(" la funzione riceva un dizionario con i campi del dataset, ma ogni valore \xE8 ora una "),In=i("em"),bh=s("lista di valori"),Eh=s(", e non un valore singolo. Il valore ritornato da "),Hn=i("code"),wh=s("Dataset.map()"),jh=s(" dovrebbe essere lo stesso: un dizionario con i campi che vogliano aggiornare o aggiungere al nostro dataset, e una lista di valori. Ad esempio, ecco un altro modo per sostituire tutti i carattere HTML, ma utilizzando "),Sn=i("code"),Dh=s("batched=True"),xh=s(":"),bp=d(),f(Xa.$$.fragment),Ep=d(),Ct=i("p"),kh=s("Se utilizzi questo codice in un notebook, noterai che questo comando \xE8 molto pi\xF9 veloce del precedente. E non perch\xE9 le nostre recensioni gi\xE0 state preprocessate, se esegui nuovamente le istruzioni della sezione precedente (senza "),Ln=i("code"),qh=s("batched=True'), ci metter\xE0 lo stesso tempo di prima. Questo \xE8 perch\xE8 le comprensioni di lista sono solitamente pi\xF9 veloci delle loro controparti con ciclo "),Th=s("for`, e inoltre abbiamo guadagnato performance permettendo l\u2019accesso a molti elementi in contemporanea invece di uno per volta."),wp=d(),pe=i("p"),Ch=s("Utilizzare "),Un=i("code"),yh=s("Dataset.map()"),Ph=s(" con "),Rn=i("code"),Oh=s("batched=True"),Ah=s(" sar\xE0 essenziale per sbloccare la velocit\xE0 dei tokenizzatori \u201Cfast\u201D che incontreremo nel "),ro=i("a"),Nh=s("Capitolo 6"),Ih=s(", che permettono di tokenizzare velocemente grandi liste di testi. Ad esempio, per tokenizzare tutte le recensioni di medicinali con un tokenizzatore veloce, potremmo usare una funzione come questa:"),jp=d(),f(Ka.$$.fragment),Dp=d(),ce=i("p"),Hh=s("Come visto nel "),po=i("a"),Sh=s("Capitolo 3"),Lh=s(", possiamo passare uno o pi\xF9 esempi al tokenizzatore. Le funzione pu\xF2 essere usata con o senza "),Mn=i("code"),Uh=s("batched=True"),Rh=s(". Approfittiamo di quest\u2019occasione per paragonare la performance delle diverse opzioni. In un notebook, possiamo cronomotrare un\u2019istruzione su una singola riga aggiungendo "),Fn=i("code"),Mh=s("%time"),Fh=s(" prima della riga di codice che desideri cronometrare:"),xp=d(),f(Za.$$.fragment),kp=d(),yt=i("p"),Qh=s("Possiamo cronometrare anche un\u2019intera cella inserento "),Qn=i("code"),Bh=s("%%time"),Jh=s(" all\u2019inizio della cella. Sull\u2019hardware che stiamo utilizzando, mostrava 10.8s pe rquest\u2019istruzione (\xE8 il numero scritto dopo \u201CWall time\u201D)."),qp=d(),f(Pt.$$.fragment),Tp=d(),co=i("p"),Gh=s("Ecco i risultati che otteniamo con e senza utilizzare batch, con un tokenizzatore lento e uno veloce:"),Cp=d(),Ot=i("table"),Bn=i("thead"),Ze=i("tr"),uo=i("th"),Vh=s("Opzioni"),Yh=d(),mo=i("th"),Wh=s("Tokenizzatore veloce"),Xh=d(),fo=i("th"),Kh=s("Tokenizzatore lento"),Zh=d(),es=i("tbody"),et=i("tr"),ho=i("td"),Jn=i("code"),ev=s("batched=True"),tv=d(),vo=i("td"),av=s("10.8s"),sv=d(),_o=i("td"),ov=s("4min41s"),iv=d(),tt=i("tr"),go=i("td"),Gn=i("code"),nv=s("batched=False"),lv=d(),zo=i("td"),rv=s("59.2s"),dv=d(),$o=i("td"),pv=s("5min3s"),yp=d(),ue=i("p"),cv=s("Questo significa che utilizzare un tokenizzatore veloce con l\u2019opzione "),Vn=i("code"),uv=s("batched=True"),mv=s(" \xE8 30 volte pi\xF9 veloce della sua controparte lenta con "),Yn=i("code"),fv=s("batched=False"),hv=s(" \u2014 ottimo! Questa \xE8 la ragione principale per cui i tokenizzatori veloci sono di default utilizzando "),Wn=i("code"),vv=s("AutoTokenizer"),_v=s(" (e il motivo per cui vengono chiamati \u201Cfast\u201D). Sono in grado di raggiungere certe velocit\xE0 perch\xE9 dietro le quinte il codice di tokenizzazione \xE8 eseguito in Rust, un linguaggio che rende semplice l\u2019esecuzione di codici in parallelo."),Pp=d(),At=i("p"),gv=s("L\u2019esecuzione in parallelo \xE8 anche il motivo per l\u2019aumento di velocit\xE0 x6 che il tokenizzatore veloce ottiene con "),Xn=i("code"),zv=s("batched=True"),$v=s(": non \xE8 possibile eseguire in parallelo una sola operazione di tokenizzazione, ma quando vuoi tokenizzare molti testi contemporaneamente puoi dividere l\u2019esecuzione su vari processi, ognuno responsabile dei propri testi."),Op=d(),ze=i("p"),Kn=i("code"),bv=s("Dataset.map()"),Ev=s(" possiede inoltre alcune capacit\xE0 di parallelizzazione per conto proprio. Non avendo per\xF2 Rust alle proprie spalle, non pu\xF2 permettere a un tokenizzatore lento di raggiungere uno veloce, ma possono comunque tornare utili (soprattutto se stai utilizzando un tokenizatore che non possiede una versione veloce). Per abilitare il multiprocessing, usa l\u2019argomenti "),Zn=i("code"),wv=s("num_proc"),jv=s(" e specifica il numero di processi da utilizzare quando evoci "),el=i("code"),Dv=s("Dataset.map()"),xv=s(":"),Ap=d(),f(ts.$$.fragment),Np=d(),bo=i("p"),kv=s("Puoi sperimentare con le tempistiche per determinare il numero ottimale di processi da utilizzare; nel nostro caso 8 sembra produrre i risultati migliori. Ecco i numeri che abbiamo ottenuto con e senza multiprocessing:"),Ip=d(),Nt=i("table"),tl=i("thead"),at=i("tr"),Eo=i("th"),qv=s("Opzioni"),Tv=d(),wo=i("th"),Cv=s("Tokenizzatore veloce"),yv=d(),jo=i("th"),Pv=s("Tokenizzatore lento"),Ov=d(),$e=i("tbody"),st=i("tr"),Do=i("td"),al=i("code"),Av=s("batched=True"),Nv=d(),xo=i("td"),Iv=s("10.8s"),Hv=d(),ko=i("td"),Sv=s("4min41s"),Lv=d(),ot=i("tr"),qo=i("td"),sl=i("code"),Uv=s("batched=False"),Rv=d(),To=i("td"),Mv=s("59.2s"),Fv=d(),Co=i("td"),Qv=s("5min3s"),Bv=d(),it=i("tr"),It=i("td"),ol=i("code"),Jv=s("batched=True"),Gv=s(", "),il=i("code"),Vv=s("num_proc=8"),Yv=d(),yo=i("td"),Wv=s("6.52s"),Xv=d(),Po=i("td"),Kv=s("41.3s"),Zv=d(),nt=i("tr"),Ht=i("td"),nl=i("code"),e_=s("batched=False"),t_=s(", "),ll=i("code"),a_=s("num_proc=8"),s_=d(),Oo=i("td"),o_=s("9.49s"),i_=d(),Ao=i("td"),n_=s("45.2s"),Hp=d(),ee=i("p"),l_=s("Questi sono dei risultati molto pi\xF9 accettabili per il tokenizzatore lento, ma anche la performance dei tokenizzatori veloci \xE8 notevolmente migliorata. Notare, comunque, che non \xE8 sempre questo il caso: per valori di "),rl=i("code"),r_=s("num_proc"),d_=s(" diversi da 8, i nostri test hanno mostrato che \xE8 pi\xF9 veloce utilizzare "),dl=i("code"),p_=s("batched=True"),c_=s(" senza l\u2019opzione "),pl=i("code"),u_=s("num_proc"),m_=s(". In generale, non raccomandiamo l\u2019utilizzo di multiprocessing Python per tokenizzatori veloci con "),cl=i("code"),f_=s("batched=True"),h_=s("."),Sp=d(),f(St.$$.fragment),Lp=d(),me=i("p"),v_=s("Tutte queste funzionalit\xE0 condensate in un unico metodo sono gi\xE0 molto utili, ma c\u2019\xE8 altro! Con "),ul=i("code"),__=s("Dataset.map()"),g_=s(" e "),ml=i("code"),z_=s("batched=True"),$_=s(", \xE8 possibile modificare il numero di elementi nel tuo dataset. \xC8 particolarmente utile quando vuoi creare diverse feature di addestramento da un unico esempio, e ne avremo bisogno come parte di preprocessing per molti dei task NLP che affronteremo nel "),No=i("a"),b_=s("Capitolo 7"),E_=s("."),Up=d(),f(Lt.$$.fragment),Rp=d(),ye=i("p"),w_=s("Diamo un\u2019occhiata a come funziona! Tokenizziamo i nostri esempi e tronchiamoli a una lunghezza massima di 128, ma chiediamo al tokenizzatore di restituire "),fl=i("em"),j_=s("tutti"),D_=s(" i pezzi di testo e non solo il primo. Questo pu\xF2 essere fatto con "),hl=i("code"),x_=s("return_overflowing_tokens=True"),k_=s(":"),Mp=d(),f(as.$$.fragment),Fp=d(),Ut=i("p"),q_=s("Testiamo questa funzione su un esempio prima di utilizzare "),vl=i("code"),T_=s("Dataset.map()"),C_=s(" sull\u2019intero dataset:"),Qp=d(),f(ss.$$.fragment),Bp=d(),f(os.$$.fragment),Jp=d(),Io=i("p"),y_=s("Quindi, il nostro primo esempio nel set di train \xE8 stato trasformaro in due feature perch\xE9 tokenizzato in un numero maggiore di token di quelli specificati: il primo gruppo di lunghezza 128 token e il secondo di lunghezza 49. Facciamo la stessa cosa per tutti gli elementi del dataset!"),Gp=d(),f(is.$$.fragment),Vp=d(),f(ns.$$.fragment),Yp=d(),Pe=i("p"),P_=s("Oh no! Non ha funzionato! Perch\xE9? Il messaggio di errore ci d\xE0 un indizio: c\u2019\xE8 una discordanza tra la lungheza di una delle colonne (una \xE8 lunga 1.463 e l\u2019altra 1.000). Se hai guardato la "),ls=i("a"),O_=s("documentazione"),A_=s(" di "),_l=i("code"),N_=s("Dataset.map()"),I_=s(", ricorderai che quello \xE8 il numero di campioni passati alla funzione map; qui quei 1.000 esempi danno 1.463 nuove feature, che risulta in un errore di shape."),Wp=d(),te=i("p"),H_=s("Il problema \xE8 che stiamo cercando di mescolare due dataset diversi di grandezze diverse: le colonne del "),gl=i("code"),S_=s("drug_dataset"),L_=s(" avranno un certo numero di esempi (il 1.000 del nostro errore), ma il "),zl=i("code"),U_=s("tokenized_dataset"),R_=s(" che stiamo costruendo ne avr\xE0 di pi\xF9 (il 1.463 nel nostro messaggio di errore). Non va bene per un "),$l=i("code"),M_=s("Dataset"),F_=s(", per cui abbiamo bisogno o di rimuovere le colonne dal dataset vecchio, o renderle della stessa dimensione del nuovo dataset. La prima opzione pu\xF2 essere effettuata utilizzando l\u2019argomento "),bl=i("code"),Q_=s("remove_columns"),B_=s(":"),Xp=d(),f(rs.$$.fragment),Kp=d(),Ho=i("p"),J_=s("Ora funziona senza errori. Possiamo controllare che il nostro nuovo dataset contiene pi\xF9 elementi del dataset originale paragonando le lunghezze:"),Zp=d(),f(ds.$$.fragment),ec=d(),f(ps.$$.fragment),tc=d(),Oe=i("p"),G_=s("Abbiamo gi\xE0 menzionato che possiamo risolvere il problema delle lunghezze discordanti cambiando la dimenzione delle vecchie colonne. Per far ci\xF2, abbiamo bisogno del campo "),El=i("code"),V_=s("overflow_to_sample_mapping"),Y_=s(" restituito dal tokenizzatore quando impostiamo "),wl=i("code"),W_=s("return_overflowing_tokens=True"),X_=s(". Cos\xEC facendo avremo una mappatura degli indici delle nuove feature all\u2019indice di campioni da cui sono state generate. Usando questa mappatura, possiamo associare a ogni chiava presente nel nostro dataset originale una lista di valori delle dimensioni giuste, ripetendo il valore di ogni esempio finch\xE9 genera nuove feature:"),ac=d(),f(cs.$$.fragment),sc=d(),Rt=i("p"),K_=s("Possiamo vedere come funziona con "),jl=i("code"),Z_=s("Dataset.map()"),eg=s(" senza aver bisogno di rimuovere le colonne vecchie:"),oc=d(),f(us.$$.fragment),ic=d(),f(ms.$$.fragment),nc=d(),So=i("p"),tg=s("Otteniamo lo stesso numero di feature di addestramento di prima, ma qui abbiamo conservato i campi originali. Se ti servono per un post-processing dopo aver applicato il tuo modello, potresti usare quest\u2019approccio."),lc=d(),Mt=i("p"),ag=s("Ora abbiamo visto come usare \u{1F917} Datasets per preprocessare un dataset in diversi modi. Bench\xE9 le funzioni di processamento di \u{1F917} Datasets soddisfer\xE0 la maggior parte delle esigenze del modello che vuoi addestrare, ci saranno momenti in cui avrai bisogno di utilizzare Pandas per avere funzionalit\xE0 ancora pi\xF9 potenti, come "),Dl=i("code"),sg=s("DataFrame.groupby()"),og=s(" o API di alto livello per visualizzazione. Per fortuna, \u{1F917} Datasets \xE8 progettato per essere utilizzato con librerie come Pandas, NumPy, PyTorch, TensorFlow e JAX. Diamo un\u2019occhiata a come funziona."),rc=d(),lt=i("h2"),Ft=i("a"),xl=i("span"),f(fs.$$.fragment),ig=d(),rt=i("span"),ng=s("Da "),kl=i("code"),lg=s("Dataset"),rg=s(" a "),ql=i("code"),dg=s("DataFrame"),pg=s(" e ritorno"),dc=d(),f(hs.$$.fragment),pc=d(),ae=i("p"),cg=s("Per permettere la conversione tra librerie terze, \u{1F917} Datasets fornisce una funzione "),Tl=i("code"),ug=s("Dataset.set_format()"),mg=s(". Questa funzione cambia il "),Cl=i("em"),fg=s("formato di output"),hg=s(" del dataset, cos\xEC che puoi passare a un altro formato senza modificare il "),yl=i("em"),vg=s("formato di dati"),_g=s(" soggiacente, che \xE8 Apache Arrow. La formattazione avviene direttamente "),Pl=i("em"),gg=s("in place"),zg=s(". Per provare, convertiamo il nostro dataset per Pandas:"),cc=d(),f(vs.$$.fragment),uc=d(),Qt=i("p"),$g=s("Ora quando accediamo agli elementi del dataset otteniamo un "),Ol=i("code"),bg=s("pandas.DataFrame"),Eg=s(" e non un dizionario:"),mc=d(),f(_s.$$.fragment),fc=d(),Ae=i("table"),Al=i("thead"),I=i("tr"),hc=i("th"),wg=d(),Nl=i("th"),jg=s("patient_id"),Dg=d(),Il=i("th"),xg=s("drugName"),kg=d(),Hl=i("th"),qg=s("condition"),Tg=d(),Sl=i("th"),Cg=s("review"),yg=d(),Ll=i("th"),Pg=s("rating"),Og=d(),Ul=i("th"),Ag=s("date"),Ng=d(),Rl=i("th"),Ig=s("usefulCount"),Hg=d(),Ml=i("th"),Sg=s("review_length"),Lg=d(),dt=i("tbody"),H=i("tr"),Fl=i("th"),Ug=s("0"),Rg=d(),Ql=i("td"),Mg=s("95260"),Fg=d(),Bl=i("td"),Qg=s("Guanfacine"),Bg=d(),Jl=i("td"),Jg=s("adhd"),Gg=d(),Gl=i("td"),Vg=s('"My son is halfway through his fourth week of Intuniv..."'),Yg=d(),Vl=i("td"),Wg=s("8.0"),Xg=d(),Yl=i("td"),Kg=s("April 27, 2010"),Zg=d(),Wl=i("td"),e2=s("192"),t2=d(),Xl=i("td"),a2=s("141"),s2=d(),S=i("tr"),Kl=i("th"),o2=s("1"),i2=d(),Zl=i("td"),n2=s("92703"),l2=d(),er=i("td"),r2=s("Lybrel"),d2=d(),tr=i("td"),p2=s("birth control"),c2=d(),ar=i("td"),u2=s('"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."'),m2=d(),sr=i("td"),f2=s("5.0"),h2=d(),or=i("td"),v2=s("December 14, 2009"),_2=d(),ir=i("td"),g2=s("17"),z2=d(),nr=i("td"),$2=s("134"),b2=d(),L=i("tr"),lr=i("th"),E2=s("2"),w2=d(),rr=i("td"),j2=s("138000"),D2=d(),dr=i("td"),x2=s("Ortho Evra"),k2=d(),pr=i("td"),q2=s("birth control"),T2=d(),cr=i("td"),C2=s('"This is my first time using any form of birth control..."'),y2=d(),ur=i("td"),P2=s("8.0"),O2=d(),mr=i("td"),A2=s("November 3, 2015"),N2=d(),fr=i("td"),I2=s("10"),H2=d(),hr=i("td"),S2=s("89"),vc=d(),Ne=i("p"),L2=s("Creiamo un "),vr=i("code"),U2=s("pandas.DataFrame"),R2=s(" per l\u2019intero set di addestramento selezionando tutti gli elementi di "),_r=i("code"),M2=s('drug_dataset["train"]'),F2=s(":"),_c=d(),f(gs.$$.fragment),gc=d(),f(Bt.$$.fragment),zc=d(),Jt=i("p"),Q2=s("Da qui possiamo usare tutte le funzionalit\xE0 Pandas che vogliamo. Ad esempio, possiamo creare un concatenamento per calcolare la distribuzione delle classi nelle voci "),gr=i("code"),B2=s("condition"),J2=s(":"),$c=d(),f(zs.$$.fragment),bc=d(),Ie=i("table"),zr=i("thead"),He=i("tr"),Ec=i("th"),G2=d(),$r=i("th"),V2=s("condition"),Y2=d(),br=i("th"),W2=s("frequency"),X2=d(),oe=i("tbody"),pt=i("tr"),Er=i("th"),K2=s("0"),Z2=d(),wr=i("td"),e1=s("birth control"),t1=d(),jr=i("td"),a1=s("27655"),s1=d(),ct=i("tr"),Dr=i("th"),o1=s("1"),i1=d(),xr=i("td"),n1=s("depression"),l1=d(),kr=i("td"),r1=s("8023"),d1=d(),ut=i("tr"),qr=i("th"),p1=s("2"),c1=d(),Tr=i("td"),u1=s("acne"),m1=d(),Cr=i("td"),f1=s("5209"),h1=d(),mt=i("tr"),yr=i("th"),v1=s("3"),_1=d(),Pr=i("td"),g1=s("anxiety"),z1=d(),Or=i("td"),$1=s("4991"),b1=d(),ft=i("tr"),Ar=i("th"),E1=s("4"),w1=d(),Nr=i("td"),j1=s("pain"),D1=d(),Ir=i("td"),x1=s("4744"),wc=d(),Se=i("p"),k1=s("E una volta che abbiamo finito con le nostre analisi su Pandas, possiamo sempre creare un nuovo oggetto "),Hr=i("code"),q1=s("Dataset"),T1=s(" utilizzando la funzione "),Sr=i("code"),C1=s("Dataset.from_pandas()"),y1=s(":"),jc=d(),f($s.$$.fragment),Dc=d(),f(bs.$$.fragment),xc=d(),f(Gt.$$.fragment),kc=d(),fe=i("p"),P1=s("Questo conclude il nostro tour delle diverse tecniche di prepocessamento disponibile in \u{1F917} Datasets. Per riepilogare la sezione, creiamo un set di validazione per preparare il dataset su cui addestreremo un classificatore. Prima di far ci\xF2, resettiamo il formato di output di "),Lr=i("code"),O1=s("drug_dataset"),A1=s(" da "),Ur=i("code"),N1=s('"pandas"'),I1=s(" a "),Rr=i("code"),H1=s('"arrow"'),S1=s(":"),qc=d(),f(Es.$$.fragment),Tc=d(),ht=i("h2"),Vt=i("a"),Mr=i("span"),f(ws.$$.fragment),L1=d(),Fr=i("span"),U1=s("Creare un set di validazione"),Cc=d(),Lo=i("p"),R1=s("Pur avendo un set di test che potremmo usare per la valutazione, \xE8 buona prassi lasciare il set di test intatto e creare un set di validazione sepearato durante lo sviluppo de lmodello. Una volta che sei soddisfatto della performance del tuo modello sul set di validazione, puoi proseguire con un ultimo check sul set di test. Questo processo aiuta a ridurre i rischi di overfitting sul set di test e di creare un modello che fallisce sui dati del mondo reale."),yc=d(),Y=i("p"),M1=s("\u{1F917} Datasets possiede una funzione "),Qr=i("code"),F1=s("Dataset.train_test_split()"),Q1=s(", basata sulla famosa funzionalit\xE0 da "),Br=i("code"),B1=s("scikit-learn"),J1=s(". Proviamo a utilizzarla per dividere il nostro set di addestramento in sezioni di "),Jr=i("code"),G1=s("addestramento"),V1=s(" e di "),Gr=i("code"),Y1=s("validazione"),W1=s(" (impostiamo l\u2019argomento "),Vr=i("code"),X1=s("seed"),K1=s(" per motivi di riproducibilit\xE0):"),Pc=d(),f(js.$$.fragment),Oc=d(),f(Ds.$$.fragment),Ac=d(),Yt=i("p"),Z1=s("Bene! Abbiamo preparato un dataset che \xE8 pronto per l\u2019addestramento di modelli! Nella "),Uo=i("a"),ez=s("sezione 5"),tz=s(" ti mostreremo come caricare i dataset nell\u2019Hub di Hugging Face, ma per ora concludiamo la nostra analisi esplorando alcuni modi per salvare i dataset sulla tua macchina locale."),Nc=d(),vt=i("h2"),Wt=i("a"),Yr=i("span"),f(xs.$$.fragment),az=d(),Wr=i("span"),sz=s("Salvare un dataset"),Ic=d(),f(ks.$$.fragment),Hc=d(),Ro=i("p"),oz=s("Bench\xE9 \u{1F917} Datasets memorizzi in cache tutti i dataset scaricati e le operazioni effettuate, ci sono momenti in cui vorrai salvare un dataset su disco (ad esempio, nel caso la cache venga eliminata). Come mostrato nella tabella successiva, \u{1F917} Datasets fornisce tre funzioni principali per salvare il tuo dataset in diversi formati:"),Sc=d(),Xt=i("table"),Xr=i("thead"),qs=i("tr"),Mo=i("th"),iz=s("Formato dati"),nz=d(),Fo=i("th"),lz=s("Funzione"),rz=d(),_t=i("tbody"),Ts=i("tr"),Qo=i("td"),dz=s("Arrow"),pz=d(),Bo=i("td"),Kr=i("code"),cz=s("Dataset.save_to_disk()"),uz=d(),Cs=i("tr"),Jo=i("td"),mz=s("CSV"),fz=d(),Go=i("td"),Zr=i("code"),hz=s("Dataset.to_csv()"),vz=d(),ys=i("tr"),Vo=i("td"),_z=s("JSON"),gz=d(),Yo=i("td"),ed=i("code"),zz=s("Dataset.to_json()"),Lc=d(),Wo=i("p"),$z=s("Ad esempio, salviamo il nostro dataset pulito in formato Arrow:"),Uc=d(),f(Ps.$$.fragment),Rc=d(),Xo=i("p"),bz=s("Questo creer\xE0 un dizionario con la seguente struttura:"),Mc=d(),f(Os.$$.fragment),Fc=d(),he=i("p"),Ez=s("dove possiamo vedere che ogni sezione \xE8 associata alla propria tavola "),td=i("em"),wz=s("dataset.arrow"),jz=s(", e alcuni metadata sono salvati in "),ad=i("em"),Dz=s("dataset_info.json"),xz=s(" e "),sd=i("em"),kz=s("state.json"),qz=s(". Puoi pensare al formato Arrow come a una tavola sofisticata di colonne e righe, ottimizzata per costruire applicazioni ad alte prestazioni che processano e trasportanto grandi dataset."),Qc=d(),Kt=i("p"),Tz=s("Una volta che il dataset \xE8 stato salvato, possiamo caricarlo utilizzando la funzione "),od=i("code"),Cz=s("load_from_disk()"),yz=s(":"),Bc=d(),f(As.$$.fragment),Jc=d(),f(Ns.$$.fragment),Gc=d(),Zt=i("p"),Pz=s("Per i formati CSV e JSON, dobbiamo salvare ogni sezione come file separato. Un modo per farlo \xE8 iterando sulle chiavi e i valori dell\u2019oggetti "),id=i("code"),Oz=s("DatasetDict"),Az=s(":"),Vc=d(),f(Is.$$.fragment),Yc=d(),ea=i("p"),Nz=s("Questo salva ogni sezione in "),Hs=i("a"),Iz=s("formato JSON Lines"),Hz=s(", in cui ogni riga del dataset \xE8 salvata come una singola riga di JSON. Ecco come appare il primo esempio:"),Wc=d(),f(Ss.$$.fragment),Xc=d(),f(Ls.$$.fragment),Kc=d(),ta=i("p"),Sz=s("Possiamo usare le tecniche studiate nella "),Ko=i("a"),Lz=s("sezione 2"),Uz=s(" per caricare i file JSON come segue:"),Zc=d(),f(Us.$$.fragment),eu=d(),Zo=i("p"),Rz=s("E questo \xE8 tutto per la nostra visita nel data wrangling con \u{1F917} Datasets! Ora che abbiamo un dataset pulito su cui addestrare un modello, ecco alcune idee che potresti testare:"),tu=d(),aa=i("ol"),Rs=i("li"),Mz=s("Usa le tecniche studiate nel "),ei=i("a"),Fz=s("Capitolo 3"),Qz=s(" per addestrare un classificatore che pu\xF2 predirre la condizione del pazionte sulla base della recensione del medicinale."),Bz=d(),gt=i("li"),Jz=s("Usa la pipeline "),nd=i("code"),Gz=s("summarization"),Vz=s(" del "),ti=i("a"),Yz=s("Capitolo 1"),Wz=s(" per generare riassunti delle recensioni."),au=d(),ai=i("p"),Xz=s("In seguito, daremo un\u2019occhiata a come \u{1F917} Datasets ti permette di lavorare su enormi dataset senza far scoppiare il tuo portatile!"),this.h()},l(e){const r=F0('[data-svelte="svelte-1phssyn"]',document.head);u=n(r,"META",{name:!0,content:!0}),r.forEach(a),T=p(e),b=n(e,"H1",{class:!0});var Ms=l(b);D=n(Ms,"A",{id:!0,class:!0,href:!0});var ld=l(D);k=n(ld,"SPAN",{});var rd=l(k);h(E.$$.fragment,rd),rd.forEach(a),ld.forEach(a),x=p(Ms),C=n(Ms,"SPAN",{});var dd=l(C);w=o(dd,"\xC8 arrivato il momento di tagliuzzare"),dd.forEach(a),Ms.forEach(a),j=p(e),h(P.$$.fragment,e),q=p(e),y=n(e,"P",{});var pd=l(y);G=o(pd,"La maggior parte delle volte, i dati su cui lavorerai non saranno perfettamente pronti a essere usati per l\u2019addestramento. In questa sezione esploreremo alcune funzionalit\xE0 di \u{1F917} Datasets per pulire i tuoi dataset."),pd.forEach(a),N=p(e),h(O.$$.fragment,e),ge=p(e),R=n(e,"H2",{class:!0});var Fs=l(R);W=n(Fs,"A",{id:!0,class:!0,href:!0});var cd=l(W);ie=n(cd,"SPAN",{});var ud=l(ie);h(se.$$.fragment,ud),ud.forEach(a),cd.forEach(a),ha=p(Fs),Ge=n(Fs,"SPAN",{});var e$=l(Ge);Ve=o(e$,"Tagliuzzare i tuoi dati"),e$.forEach(a),Fs.forEach(a),zt=p(e),M=n(e,"P",{});var Le=l(M);Ye=o(Le,"Proprio come Pandas, \u{1F917} Datasets offre diverse funzionalit\xE0 per manipolare il contenuto degli oggetti "),A=n(Le,"CODE",{});var t$=l(A);Js=o(t$,"Dataset"),t$.forEach(a),Gs=o(Le," e "),$t=n(Le,"CODE",{});var a$=l($t);Vs=o(a$,"DatasetDict"),a$.forEach(a),Ys=o(Le,". Abbiamo gi\xE0 visto il metodo "),bt=n(Le,"CODE",{});var s$=l(bt);Ws=o(s$,"Dataset.map()"),s$.forEach(a),Xs=o(Le," nel "),Ks=n(Le,"A",{href:!0});var o$=l(Ks);Ru=o(o$,"Capitolo 3"),o$.forEach(a),Mu=o(Le,", e in questa sezione esploreremo altre funzioni a nostra disposizione."),Le.forEach(a),md=p(e),ne=n(e,"P",{});var sa=l(ne);Fu=o(sa,"Ai fini di quest\u2019esempio useremo il "),va=n(sa,"A",{href:!0,rel:!0});var i$=l(va);Qu=o(i$,"Drug Review Dataset"),i$.forEach(a),Bu=o(sa,`, che raccoglie le recensioni di pazienti su vari medicinali, assieme alla condizione curata e a una valutazione da 0 a 10 del grado di soddisfazione del paziente.
Prima di tutto scarichiamo ed estraiamo i dati, utilizzando i comandi `),Hi=n(sa,"CODE",{});var n$=l(Hi);Ju=o(n$,"wget"),n$.forEach(a),Gu=o(sa," e "),Si=n(sa,"CODE",{});var l$=l(Si);Vu=o(l$,"unzip"),l$.forEach(a),Yu=o(sa,":"),sa.forEach(a),fd=p(e),h(_a.$$.fragment,e),hd=p(e),le=n(e,"P",{});var oa=l(le);Wu=o(oa,"Poich\xE9 TSV non \xE8 altro che una variante di CSV che usa come separatore tabulatori al posto delle virgole, caricheremo questi file utilizzando lo script "),Li=n(oa,"CODE",{});var r$=l(Li);Xu=o(r$,"csv"),r$.forEach(a),Ku=o(oa," e specificando l\u2019argomento "),Ui=n(oa,"CODE",{});var d$=l(Ui);Zu=o(d$,"delimiter"),d$.forEach(a),em=o(oa," nella funzione "),Ri=n(oa,"CODE",{});var p$=l(Ri);tm=o(p$,"load_dataset()"),p$.forEach(a),am=o(oa,", come segue:"),oa.forEach(a),vd=p(e),h(ga.$$.fragment,e),_d=p(e),be=n(e,"P",{});var si=l(be);sm=o(si,"\xC8 buona prassi nell\u2019analisi dati recuperare un piccolo campione casuale per farsi un\u2019idea del tipo di dati con cui si sta lavorando. Utilizzando \u{1F917} Datasets, possiamo crare un campione casuale concatenando le funzioni "),Mi=n(si,"CODE",{});var c$=l(Mi);om=o(c$,"Dataset.shuffle()"),c$.forEach(a),im=o(si," e "),Fi=n(si,"CODE",{});var u$=l(Fi);nm=o(u$,"Dataset.select()"),u$.forEach(a),lm=o(si,":"),si.forEach(a),gd=p(e),h(za.$$.fragment,e),zd=p(e),h($a.$$.fragment,e),$d=p(e),re=n(e,"P",{});var ia=l(re);rm=o(ia,"Da notare che abbiamo impostato il seed in "),Qi=n(ia,"CODE",{});var m$=l(Qi);dm=o(m$,"Dataset.shuffle()"),m$.forEach(a),pm=o(ia," per motivi di riproducibilit\xE0. "),Bi=n(ia,"CODE",{});var f$=l(Bi);cm=o(f$,"Dataset.select()"),f$.forEach(a),um=o(ia," ha bisogno di un iterabile di indici, per cui abbiamo utilizzato "),Ji=n(ia,"CODE",{});var h$=l(Ji);mm=o(h$,"range(1000)"),h$.forEach(a),fm=o(ia," per recuperare i primi 1.000 esempi dal dataset mescolato. Da questo campione possiamo gi\xE0 vedere alcune particolarit\xE0 del nostor dataset:"),ia.forEach(a),bd=p(e),Ee=n(e,"UL",{});var oi=l(Ee);ba=n(oi,"LI",{});var ou=l(ba);hm=o(ou,"La colonna "),Gi=n(ou,"CODE",{});var v$=l(Gi);vm=o(v$,"Unnamed: 0"),v$.forEach(a),_m=o(ou," assomiglia molto a un ID anonimizzato per ognuno dei pazienti."),ou.forEach(a),gm=p(oi),Ea=n(oi,"LI",{});var iu=l(Ea);zm=o(iu,"La colonna "),Vi=n(iu,"CODE",{});var _$=l(Vi);$m=o(_$,"condizione"),_$.forEach(a),bm=o(iu," include un mix di etichette maiuscole e minuscole."),iu.forEach(a),Em=p(oi),We=n(oi,"LI",{});var ii=l(We);wm=o(ii,"Le recensioni sono di diversa lunghezza e contengono un mix di separatori di riga Python ("),Yi=n(ii,"CODE",{});var g$=l(Yi);jm=o(g$,"\\r\\n"),g$.forEach(a),Dm=o(ii,") e di codici di caratteri HTML come "),Wi=n(ii,"CODE",{});var z$=l(Wi);xm=o(z$,"&\\#039"),z$.forEach(a),km=o(ii,"."),ii.forEach(a),oi.forEach(a),Ed=p(e),we=n(e,"P",{});var ni=l(we);qm=o(ni,"Ora vediamo come utilizzare \u{1F917} Datasets per risolvere alcuni di questi problemi. Per confermare l\u2019ipotesi che la colonna "),Xi=n(ni,"CODE",{});var $$=l(Xi);Tm=o($$,"Unnamed: 0"),$$.forEach(a),Cm=o(ni," rappresenti gli ID dei pazienti, possiamo usare la funzione "),Ki=n(ni,"CODE",{});var b$=l(Ki);ym=o(b$,"Dataset.unique()"),b$.forEach(a),Pm=o(ni," per verificare che il numero di ID corrisponda al numero delle righe in ognuna delle sezioni:"),ni.forEach(a),wd=p(e),h(wa.$$.fragment,e),jd=p(e),je=n(e,"P",{});var li=l(je);Om=o(li,"Questo sembra confermare la nostra ipotesi, quindi puliamo un po\u2019 il nostro dataset cambiando il nome della colonna "),Zi=n(li,"CODE",{});var E$=l(Zi);Am=o(E$,"Unnamed: 0"),E$.forEach(a),Nm=o(li," in qualcosa di un po\u2019 pi\xF9 comprensibile. Possiamo usare la funzione "),en=n(li,"CODE",{});var w$=l(en);Im=o(w$,"DatasetDict.rename_column()"),w$.forEach(a),Hm=o(li," per rinominare la colonna in entrambe le sezioni:"),li.forEach(a),Dd=p(e),h(ja.$$.fragment,e),xd=p(e),h(Da.$$.fragment,e),kd=p(e),h(Et.$$.fragment,e),qd=p(e),X=n(e,"P",{});var Ue=l(X);Sm=o(Ue,"Ora, normaliziamo le etichette in "),tn=n(Ue,"CODE",{});var j$=l(tn);Lm=o(j$,"condition"),j$.forEach(a),Um=o(Ue," utilizzando "),an=n(Ue,"CODE",{});var D$=l(an);Rm=o(D$,"Dataset.map()"),D$.forEach(a),Mm=o(Ue,". Cos\xEC come abbiamo fatto con la tokenizzazione nel "),Zs=n(Ue,"A",{href:!0});var x$=l(Zs);Fm=o(x$,"Capitolo 3"),x$.forEach(a),Qm=o(Ue,", possiamo definire una semplice funzione che pu\xF2 essere applicata a tutte le righe di ogni sezione nel "),sn=n(Ue,"CODE",{});var k$=l(sn);Bm=o(k$,"drug_dataset"),k$.forEach(a),Jm=o(Ue,":"),Ue.forEach(a),Td=p(e),h(xa.$$.fragment,e),Cd=p(e),h(ka.$$.fragment,e),yd=p(e),K=n(e,"P",{});var Re=l(K);Gm=o(Re,"Oh no, abbiamo incontrato un problema con la nostra funzione! Dall\u2019errore possiamo dedurre che alcuni dei valori nella colonna "),on=n(Re,"CODE",{});var q$=l(on);Vm=o(q$,"condition"),q$.forEach(a),Ym=o(Re," sono "),nn=n(Re,"CODE",{});var T$=l(nn);Wm=o(T$,"None"),T$.forEach(a),Xm=o(Re,", che non essendo stringhe non possono essere convertiti in lettere minuscole. Eliminiamo queste righe utilizzando "),ln=n(Re,"CODE",{});var C$=l(ln);Km=o(C$,"Dataset.filter()"),C$.forEach(a),Zm=o(Re,", che funziona come "),rn=n(Re,"CODE",{});var y$=l(rn);ef=o(y$,"Dataset.map()"),y$.forEach(a),tf=o(Re," e accetta una funziona che riceve un singolo esempio del dataset. Invece di scrivere una funzione esplicita come:"),Re.forEach(a),Pd=p(e),h(qa.$$.fragment,e),Od=p(e),De=n(e,"P",{});var ri=l(De);af=o(ri,"e utilizzare "),dn=n(ri,"CODE",{});var P$=l(dn);sf=o(P$,"drug_dataset.filter(filter_nones)"),P$.forEach(a),of=o(ri,", possiamo utilizzare una "),pn=n(ri,"EM",{});var O$=l(pn);nf=o(O$,"funzione lambda"),O$.forEach(a),lf=o(ri," e completare tutto in un\u2019unica riga. In Python, le funzioni lambda sono funzioni che possiamo definire senza nominarle esplicitamente. Hanno la forma generale:"),ri.forEach(a),Ad=p(e),h(Ta.$$.fragment,e),Nd=p(e),xe=n(e,"P",{});var di=l(xe);rf=o(di,"dove "),cn=n(di,"CODE",{});var A$=l(cn);df=o(A$,"lambda' \xE8 una delle [keyword](https://docs.python.org/3/reference/lexical_analysis.html#keywords) speciali di Python, "),A$.forEach(a),pf=o(di,"<argomenti>"),un=n(di,"CODE",{});var N$=l(un);cf=o(N$,"\xE8 una lista/set di valori separati da virgole che definisce l'input della funzione, e"),N$.forEach(a),uf=o(di,"<espressione>` rappresenta le operazioni che vogliamo eseguire. Ad esempio, posiamo definire una semplice funzione lamda che calcola il quadrato di un numero:"),di.forEach(a),Id=p(e),h(Ca.$$.fragment,e),Hd=p(e),eo=n(e,"P",{});var I$=l(eo);mf=o(I$,"Per applicare questa funzione a un input, dobbiamo includere sia la funzione che l\u2019input in parentesi:"),I$.forEach(a),Sd=p(e),h(ya.$$.fragment,e),Ld=p(e),h(Pa.$$.fragment,e),Ud=p(e),to=n(e,"P",{});var H$=l(to);ff=o(H$,"Allo stesso modo, possiamo definire funzioni lmabda con argomenti multipli separandoli con virgoli. Ad esempio, possiamo calcolare l\u2019area di un triangolo come segue:"),H$.forEach(a),Rd=p(e),h(Oa.$$.fragment,e),Md=p(e),h(Aa.$$.fragment,e),Fd=p(e),ke=n(e,"P",{});var pi=l(ke);hf=o(pi,"Le funzioni lambda sono utili quando vogliamo definire piccole funzioni monouso (per maggiori informazioni, invitiamo alla lettura dell\u2019ottimo "),Na=n(pi,"A",{href:!0,rel:!0});var S$=l(Na);vf=o(S$,"tutorial di Real Python"),S$.forEach(a),_f=o(pi," di Andre Burgaud). In \u{1F917} Datasets, possiamo usare le funzioni lambda per definire semplici operazioni di mappatura e filtraggio. Utilizziamo questo trucchetto per eliminare i valori "),mn=n(pi,"CODE",{});var L$=l(mn);gf=o(L$,"None"),L$.forEach(a),zf=o(pi," nel nostro dataset:"),pi.forEach(a),Qd=p(e),h(Ia.$$.fragment,e),Bd=p(e),qe=n(e,"P",{});var ci=l(qe);$f=o(ci,"Una volta rimosse le voci "),fn=n(ci,"CODE",{});var U$=l(fn);bf=o(U$,"None"),U$.forEach(a),Ef=o(ci,", possiamo normalizzare la colonna "),hn=n(ci,"CODE",{});var R$=l(hn);wf=o(R$,"condition"),R$.forEach(a),jf=o(ci,":"),ci.forEach(a),Jd=p(e),h(Ha.$$.fragment,e),Gd=p(e),h(Sa.$$.fragment,e),Vd=p(e),ao=n(e,"P",{});var M$=l(ao);Df=o(M$,"Funziona! Or ache abbiamo pulito le nostre etichette, diamo un\u2019occhiata a come pulire le recensioni."),M$.forEach(a),Yd=p(e),Xe=n(e,"H2",{class:!0});var nu=l(Xe);wt=n(nu,"A",{id:!0,class:!0,href:!0});var F$=l(wt);vn=n(F$,"SPAN",{});var Q$=l(vn);h(La.$$.fragment,Q$),Q$.forEach(a),F$.forEach(a),xf=p(nu),_n=n(nu,"SPAN",{});var B$=l(_n);kf=o(B$,"Creare nuove colonne"),B$.forEach(a),nu.forEach(a),Wd=p(e),so=n(e,"P",{});var J$=l(so);qf=o(J$,"Quando abbiamo a che fare con le recensioni di clienti, \xE8 buona pratica controllare il numero di parole in ogni recensione. Una recensione potrebbe contenere solo una parola com \u201COttimo!\u201D o un vero e proprio saggio di migliaia di parole, e a seconda dell\u2019uso che ne farai dovrai affrontare queste situazioni in maniera diversa. Per calculare il numero di parole in ogni recensione, useremo un\u2019euristica grezza basata sulla divisione dei testi sugli spazi."),J$.forEach(a),Xd=p(e),oo=n(e,"P",{});var G$=l(oo);Tf=o(G$,"Definiamo una semplice funzione che conta il numero di parole in ogni recensione:"),G$.forEach(a),Kd=p(e),h(Ua.$$.fragment,e),Zd=p(e),V=n(e,"P",{});var ve=l(V);Cf=o(ve,"A differenza della nostra funzione "),gn=n(ve,"CODE",{});var V$=l(gn);yf=o(V$,"lowercase_condition()"),V$.forEach(a),Pf=o(ve,", "),zn=n(ve,"CODE",{});var Y$=l(zn);Of=o(Y$,"compute_review_length()"),Y$.forEach(a),Af=o(ve," ritorna un dizionario le cui chiavi non corrispondono a nessuna delle colonne nel dataset. In questo caso, quando "),$n=n(ve,"CODE",{});var W$=l($n);Nf=o(W$,"compute_review_length()"),W$.forEach(a),If=o(ve," \xE8 passata a "),bn=n(ve,"CODE",{});var X$=l(bn);Hf=o(X$,"Dataset.map()"),X$.forEach(a),Sf=o(ve,", si applicher\xE0 a tutte le righe nel dataset per creare una nuova colonna "),En=n(ve,"CODE",{});var K$=l(En);Lf=o(K$,"review_lenght"),K$.forEach(a),Uf=o(ve,";"),ve.forEach(a),ep=p(e),h(Ra.$$.fragment,e),tp=p(e),h(Ma.$$.fragment,e),ap=p(e),Te=n(e,"P",{});var ui=l(Te);Rf=o(ui,"Come previsto, una colonna "),wn=n(ui,"CODE",{});var Z$=l(wn);Mf=o(Z$,"review_length"),Z$.forEach(a),Ff=o(ui," \xE8 stata aggiunta al nostro set di addestramento. Possiamo ordinare questa nuova colonna utilizzando "),jn=n(ui,"CODE",{});var eb=l(jn);Qf=o(eb,"Dataset.sort()"),eb.forEach(a),Bf=o(ui," per dare un\u2019occhiata ai valori estremi:"),ui.forEach(a),sp=p(e),h(Fa.$$.fragment,e),op=p(e),h(Qa.$$.fragment,e),ip=p(e),io=n(e,"P",{});var tb=l(io);Jf=o(tb,"Come sospettato, alcune revisioni contengono una sola parola che, bench\xE9 potrebbe essere utile per la sentiment analysis, non d\xE0 informazioni utili per predirre la condizione."),tb.forEach(a),np=p(e),h(jt.$$.fragment,e),lp=p(e),Ce=n(e,"P",{});var mi=l(Ce);Gf=o(mi,"Usiamo la funzione "),Dn=n(mi,"CODE",{});var ab=l(Dn);Vf=o(ab,"Dataset.filter()"),ab.forEach(a),Yf=o(mi," per rimuovere le recensioni che contengono meno di 30 parole. Proprio come abbiamo fatto per la colonna "),xn=n(mi,"CODE",{});var sb=l(xn);Wf=o(sb,"condizione"),sb.forEach(a),Xf=o(mi,", possiamo eliminare le recensioni pi\xF9 brevi aggiungendo un filtro che lascia passare solo le recensioni pi\xF9 lunghe di una certa soglia:"),mi.forEach(a),rp=p(e),h(Ba.$$.fragment,e),dp=p(e),h(Ja.$$.fragment,e),pp=p(e),no=n(e,"P",{});var ob=l(no);Kf=o(ob,"Come puoi vedere, questo ha rimosso circa il 15% delle recensioni nelle sezioni di training e di test."),ob.forEach(a),cp=p(e),h(Dt.$$.fragment,e),up=p(e),xt=n(e,"P",{});var lu=l(xt);Zf=o(lu,"L\u2019ultima cosa che ci resta da risolvere \xE8 la presenza di codici HTML di caratteri nelle nostre recensioni. Possiamo usare il modulo Python "),kn=n(lu,"CODE",{});var ib=l(kn);eh=o(ib,"html"),ib.forEach(a),th=o(lu," per sostituirli, cos\xEC:"),lu.forEach(a),mp=p(e),h(Ga.$$.fragment,e),fp=p(e),h(Va.$$.fragment,e),hp=p(e),kt=n(e,"P",{});var ru=l(kt);ah=o(ru,"We\u2019ll use "),qn=n(ru,"CODE",{});var nb=l(qn);sh=o(nb,"Dataset.map()"),nb.forEach(a),oh=o(ru," to unescape all the HTML characters in our corpus:"),ru.forEach(a),vp=p(e),h(Ya.$$.fragment,e),_p=p(e),qt=n(e,"P",{});var du=l(qt);ih=o(du,"Come puoi vedere, il metodo "),Tn=n(du,"CODE",{});var lb=l(Tn);nh=o(lb,"Dataset.map()"),lb.forEach(a),lh=o(du," \xE8 molto utile per processare i dati \u2014 e questo non \xE8 che la punta dell\u2019iceberg di ci\xF2 che \xE8 in grado di fare!"),du.forEach(a),gp=p(e),Ke=n(e,"H2",{class:!0});var pu=l(Ke);Tt=n(pu,"A",{id:!0,class:!0,href:!0});var rb=l(Tt);Cn=n(rb,"SPAN",{});var db=l(Cn);h(Wa.$$.fragment,db),db.forEach(a),rb.forEach(a),rh=p(pu),lo=n(pu,"SPAN",{});var Kz=l(lo);dh=o(Kz,"I superpoteri del metodo "),yn=n(Kz,"CODE",{});var pb=l(yn);ph=o(pb,"map()"),pb.forEach(a),Kz.forEach(a),pu.forEach(a),zp=p(e),de=n(e,"P",{});var na=l(de);ch=o(na,"Il metodo "),Pn=n(na,"CODE",{});var cb=l(Pn);uh=o(cb,"Dataset.map()"),cb.forEach(a),mh=o(na," accetta un argomento "),On=n(na,"CODE",{});var ub=l(On);fh=o(ub,"batched"),ub.forEach(a),hh=o(na," che, se impostato su "),An=n(na,"CODE",{});var mb=l(An);vh=o(mb,"True"),mb.forEach(a),_h=o(na,", gli fa inviare un batch di esempi alla funzione map in una sola volta (la grandezza del batch \xE8 configurabile, ma di default \xE8 impostta a 1.000). Ad esempio, l\u2019esecuzione delle funzione map precedente che ha sostituito tutti i caratteri HTML \xE8 stata un po\u2019 lenta (puoi leggere il tempo impiegato dalle barre di progresso). Possiamo accelerare questo processo processando diversi elementi in contemporanea usando una comprensione di lista."),na.forEach(a),$p=p(e),Z=n(e,"P",{});var Me=l(Z);gh=o(Me,"Quando si specifica "),Nn=n(Me,"CODE",{});var fb=l(Nn);zh=o(fb,"batched=True"),fb.forEach(a),$h=o(Me," la funzione riceva un dizionario con i campi del dataset, ma ogni valore \xE8 ora una "),In=n(Me,"EM",{});var hb=l(In);bh=o(hb,"lista di valori"),hb.forEach(a),Eh=o(Me,", e non un valore singolo. Il valore ritornato da "),Hn=n(Me,"CODE",{});var vb=l(Hn);wh=o(vb,"Dataset.map()"),vb.forEach(a),jh=o(Me," dovrebbe essere lo stesso: un dizionario con i campi che vogliano aggiornare o aggiungere al nostro dataset, e una lista di valori. Ad esempio, ecco un altro modo per sostituire tutti i carattere HTML, ma utilizzando "),Sn=n(Me,"CODE",{});var _b=l(Sn);Dh=o(_b,"batched=True"),_b.forEach(a),xh=o(Me,":"),Me.forEach(a),bp=p(e),h(Xa.$$.fragment,e),Ep=p(e),Ct=n(e,"P",{});var cu=l(Ct);kh=o(cu,"Se utilizzi questo codice in un notebook, noterai che questo comando \xE8 molto pi\xF9 veloce del precedente. E non perch\xE9 le nostre recensioni gi\xE0 state preprocessate, se esegui nuovamente le istruzioni della sezione precedente (senza "),Ln=n(cu,"CODE",{});var gb=l(Ln);qh=o(gb,"batched=True'), ci metter\xE0 lo stesso tempo di prima. Questo \xE8 perch\xE8 le comprensioni di lista sono solitamente pi\xF9 veloci delle loro controparti con ciclo "),gb.forEach(a),Th=o(cu,"for`, e inoltre abbiamo guadagnato performance permettendo l\u2019accesso a molti elementi in contemporanea invece di uno per volta."),cu.forEach(a),wp=p(e),pe=n(e,"P",{});var la=l(pe);Ch=o(la,"Utilizzare "),Un=n(la,"CODE",{});var zb=l(Un);yh=o(zb,"Dataset.map()"),zb.forEach(a),Ph=o(la," con "),Rn=n(la,"CODE",{});var $b=l(Rn);Oh=o($b,"batched=True"),$b.forEach(a),Ah=o(la," sar\xE0 essenziale per sbloccare la velocit\xE0 dei tokenizzatori \u201Cfast\u201D che incontreremo nel "),ro=n(la,"A",{href:!0});var bb=l(ro);Nh=o(bb,"Capitolo 6"),bb.forEach(a),Ih=o(la,", che permettono di tokenizzare velocemente grandi liste di testi. Ad esempio, per tokenizzare tutte le recensioni di medicinali con un tokenizzatore veloce, potremmo usare una funzione come questa:"),la.forEach(a),jp=p(e),h(Ka.$$.fragment,e),Dp=p(e),ce=n(e,"P",{});var ra=l(ce);Hh=o(ra,"Come visto nel "),po=n(ra,"A",{href:!0});var Eb=l(po);Sh=o(Eb,"Capitolo 3"),Eb.forEach(a),Lh=o(ra,", possiamo passare uno o pi\xF9 esempi al tokenizzatore. Le funzione pu\xF2 essere usata con o senza "),Mn=n(ra,"CODE",{});var wb=l(Mn);Uh=o(wb,"batched=True"),wb.forEach(a),Rh=o(ra,". Approfittiamo di quest\u2019occasione per paragonare la performance delle diverse opzioni. In un notebook, possiamo cronomotrare un\u2019istruzione su una singola riga aggiungendo "),Fn=n(ra,"CODE",{});var jb=l(Fn);Mh=o(jb,"%time"),jb.forEach(a),Fh=o(ra," prima della riga di codice che desideri cronometrare:"),ra.forEach(a),xp=p(e),h(Za.$$.fragment,e),kp=p(e),yt=n(e,"P",{});var uu=l(yt);Qh=o(uu,"Possiamo cronometrare anche un\u2019intera cella inserento "),Qn=n(uu,"CODE",{});var Db=l(Qn);Bh=o(Db,"%%time"),Db.forEach(a),Jh=o(uu," all\u2019inizio della cella. Sull\u2019hardware che stiamo utilizzando, mostrava 10.8s pe rquest\u2019istruzione (\xE8 il numero scritto dopo \u201CWall time\u201D)."),uu.forEach(a),qp=p(e),h(Pt.$$.fragment,e),Tp=p(e),co=n(e,"P",{});var xb=l(co);Gh=o(xb,"Ecco i risultati che otteniamo con e senza utilizzare batch, con un tokenizzatore lento e uno veloce:"),xb.forEach(a),Cp=p(e),Ot=n(e,"TABLE",{});var mu=l(Ot);Bn=n(mu,"THEAD",{});var kb=l(Bn);Ze=n(kb,"TR",{});var fi=l(Ze);uo=n(fi,"TH",{align:!0});var qb=l(uo);Vh=o(qb,"Opzioni"),qb.forEach(a),Yh=p(fi),mo=n(fi,"TH",{align:!0});var Tb=l(mo);Wh=o(Tb,"Tokenizzatore veloce"),Tb.forEach(a),Xh=p(fi),fo=n(fi,"TH",{align:!0});var Cb=l(fo);Kh=o(Cb,"Tokenizzatore lento"),Cb.forEach(a),fi.forEach(a),kb.forEach(a),Zh=p(mu),es=n(mu,"TBODY",{});var fu=l(es);et=n(fu,"TR",{});var hi=l(et);ho=n(hi,"TD",{align:!0});var yb=l(ho);Jn=n(yb,"CODE",{});var Pb=l(Jn);ev=o(Pb,"batched=True"),Pb.forEach(a),yb.forEach(a),tv=p(hi),vo=n(hi,"TD",{align:!0});var Ob=l(vo);av=o(Ob,"10.8s"),Ob.forEach(a),sv=p(hi),_o=n(hi,"TD",{align:!0});var Ab=l(_o);ov=o(Ab,"4min41s"),Ab.forEach(a),hi.forEach(a),iv=p(fu),tt=n(fu,"TR",{});var vi=l(tt);go=n(vi,"TD",{align:!0});var Nb=l(go);Gn=n(Nb,"CODE",{});var Ib=l(Gn);nv=o(Ib,"batched=False"),Ib.forEach(a),Nb.forEach(a),lv=p(vi),zo=n(vi,"TD",{align:!0});var Hb=l(zo);rv=o(Hb,"59.2s"),Hb.forEach(a),dv=p(vi),$o=n(vi,"TD",{align:!0});var Sb=l($o);pv=o(Sb,"5min3s"),Sb.forEach(a),vi.forEach(a),fu.forEach(a),mu.forEach(a),yp=p(e),ue=n(e,"P",{});var da=l(ue);cv=o(da,"Questo significa che utilizzare un tokenizzatore veloce con l\u2019opzione "),Vn=n(da,"CODE",{});var Lb=l(Vn);uv=o(Lb,"batched=True"),Lb.forEach(a),mv=o(da," \xE8 30 volte pi\xF9 veloce della sua controparte lenta con "),Yn=n(da,"CODE",{});var Ub=l(Yn);fv=o(Ub,"batched=False"),Ub.forEach(a),hv=o(da," \u2014 ottimo! Questa \xE8 la ragione principale per cui i tokenizzatori veloci sono di default utilizzando "),Wn=n(da,"CODE",{});var Rb=l(Wn);vv=o(Rb,"AutoTokenizer"),Rb.forEach(a),_v=o(da," (e il motivo per cui vengono chiamati \u201Cfast\u201D). Sono in grado di raggiungere certe velocit\xE0 perch\xE9 dietro le quinte il codice di tokenizzazione \xE8 eseguito in Rust, un linguaggio che rende semplice l\u2019esecuzione di codici in parallelo."),da.forEach(a),Pp=p(e),At=n(e,"P",{});var hu=l(At);gv=o(hu,"L\u2019esecuzione in parallelo \xE8 anche il motivo per l\u2019aumento di velocit\xE0 x6 che il tokenizzatore veloce ottiene con "),Xn=n(hu,"CODE",{});var Mb=l(Xn);zv=o(Mb,"batched=True"),Mb.forEach(a),$v=o(hu,": non \xE8 possibile eseguire in parallelo una sola operazione di tokenizzazione, ma quando vuoi tokenizzare molti testi contemporaneamente puoi dividere l\u2019esecuzione su vari processi, ognuno responsabile dei propri testi."),hu.forEach(a),Op=p(e),ze=n(e,"P",{});var Qs=l(ze);Kn=n(Qs,"CODE",{});var Fb=l(Kn);bv=o(Fb,"Dataset.map()"),Fb.forEach(a),Ev=o(Qs," possiede inoltre alcune capacit\xE0 di parallelizzazione per conto proprio. Non avendo per\xF2 Rust alle proprie spalle, non pu\xF2 permettere a un tokenizzatore lento di raggiungere uno veloce, ma possono comunque tornare utili (soprattutto se stai utilizzando un tokenizatore che non possiede una versione veloce). Per abilitare il multiprocessing, usa l\u2019argomenti "),Zn=n(Qs,"CODE",{});var Qb=l(Zn);wv=o(Qb,"num_proc"),Qb.forEach(a),jv=o(Qs," e specifica il numero di processi da utilizzare quando evoci "),el=n(Qs,"CODE",{});var Bb=l(el);Dv=o(Bb,"Dataset.map()"),Bb.forEach(a),xv=o(Qs,":"),Qs.forEach(a),Ap=p(e),h(ts.$$.fragment,e),Np=p(e),bo=n(e,"P",{});var Jb=l(bo);kv=o(Jb,"Puoi sperimentare con le tempistiche per determinare il numero ottimale di processi da utilizzare; nel nostro caso 8 sembra produrre i risultati migliori. Ecco i numeri che abbiamo ottenuto con e senza multiprocessing:"),Jb.forEach(a),Ip=p(e),Nt=n(e,"TABLE",{});var vu=l(Nt);tl=n(vu,"THEAD",{});var Gb=l(tl);at=n(Gb,"TR",{});var _i=l(at);Eo=n(_i,"TH",{align:!0});var Vb=l(Eo);qv=o(Vb,"Opzioni"),Vb.forEach(a),Tv=p(_i),wo=n(_i,"TH",{align:!0});var Yb=l(wo);Cv=o(Yb,"Tokenizzatore veloce"),Yb.forEach(a),yv=p(_i),jo=n(_i,"TH",{align:!0});var Wb=l(jo);Pv=o(Wb,"Tokenizzatore lento"),Wb.forEach(a),_i.forEach(a),Gb.forEach(a),Ov=p(vu),$e=n(vu,"TBODY",{});var pa=l($e);st=n(pa,"TR",{});var gi=l(st);Do=n(gi,"TD",{align:!0});var Xb=l(Do);al=n(Xb,"CODE",{});var Kb=l(al);Av=o(Kb,"batched=True"),Kb.forEach(a),Xb.forEach(a),Nv=p(gi),xo=n(gi,"TD",{align:!0});var Zb=l(xo);Iv=o(Zb,"10.8s"),Zb.forEach(a),Hv=p(gi),ko=n(gi,"TD",{align:!0});var eE=l(ko);Sv=o(eE,"4min41s"),eE.forEach(a),gi.forEach(a),Lv=p(pa),ot=n(pa,"TR",{});var zi=l(ot);qo=n(zi,"TD",{align:!0});var tE=l(qo);sl=n(tE,"CODE",{});var aE=l(sl);Uv=o(aE,"batched=False"),aE.forEach(a),tE.forEach(a),Rv=p(zi),To=n(zi,"TD",{align:!0});var sE=l(To);Mv=o(sE,"59.2s"),sE.forEach(a),Fv=p(zi),Co=n(zi,"TD",{align:!0});var oE=l(Co);Qv=o(oE,"5min3s"),oE.forEach(a),zi.forEach(a),Bv=p(pa),it=n(pa,"TR",{});var $i=l(it);It=n($i,"TD",{align:!0});var _u=l(It);ol=n(_u,"CODE",{});var iE=l(ol);Jv=o(iE,"batched=True"),iE.forEach(a),Gv=o(_u,", "),il=n(_u,"CODE",{});var nE=l(il);Vv=o(nE,"num_proc=8"),nE.forEach(a),_u.forEach(a),Yv=p($i),yo=n($i,"TD",{align:!0});var lE=l(yo);Wv=o(lE,"6.52s"),lE.forEach(a),Xv=p($i),Po=n($i,"TD",{align:!0});var rE=l(Po);Kv=o(rE,"41.3s"),rE.forEach(a),$i.forEach(a),Zv=p(pa),nt=n(pa,"TR",{});var bi=l(nt);Ht=n(bi,"TD",{align:!0});var gu=l(Ht);nl=n(gu,"CODE",{});var dE=l(nl);e_=o(dE,"batched=False"),dE.forEach(a),t_=o(gu,", "),ll=n(gu,"CODE",{});var pE=l(ll);a_=o(pE,"num_proc=8"),pE.forEach(a),gu.forEach(a),s_=p(bi),Oo=n(bi,"TD",{align:!0});var cE=l(Oo);o_=o(cE,"9.49s"),cE.forEach(a),i_=p(bi),Ao=n(bi,"TD",{align:!0});var uE=l(Ao);n_=o(uE,"45.2s"),uE.forEach(a),bi.forEach(a),pa.forEach(a),vu.forEach(a),Hp=p(e),ee=n(e,"P",{});var Fe=l(ee);l_=o(Fe,"Questi sono dei risultati molto pi\xF9 accettabili per il tokenizzatore lento, ma anche la performance dei tokenizzatori veloci \xE8 notevolmente migliorata. Notare, comunque, che non \xE8 sempre questo il caso: per valori di "),rl=n(Fe,"CODE",{});var mE=l(rl);r_=o(mE,"num_proc"),mE.forEach(a),d_=o(Fe," diversi da 8, i nostri test hanno mostrato che \xE8 pi\xF9 veloce utilizzare "),dl=n(Fe,"CODE",{});var fE=l(dl);p_=o(fE,"batched=True"),fE.forEach(a),c_=o(Fe," senza l\u2019opzione "),pl=n(Fe,"CODE",{});var hE=l(pl);u_=o(hE,"num_proc"),hE.forEach(a),m_=o(Fe,". In generale, non raccomandiamo l\u2019utilizzo di multiprocessing Python per tokenizzatori veloci con "),cl=n(Fe,"CODE",{});var vE=l(cl);f_=o(vE,"batched=True"),vE.forEach(a),h_=o(Fe,"."),Fe.forEach(a),Sp=p(e),h(St.$$.fragment,e),Lp=p(e),me=n(e,"P",{});var ca=l(me);v_=o(ca,"Tutte queste funzionalit\xE0 condensate in un unico metodo sono gi\xE0 molto utili, ma c\u2019\xE8 altro! Con "),ul=n(ca,"CODE",{});var _E=l(ul);__=o(_E,"Dataset.map()"),_E.forEach(a),g_=o(ca," e "),ml=n(ca,"CODE",{});var gE=l(ml);z_=o(gE,"batched=True"),gE.forEach(a),$_=o(ca,", \xE8 possibile modificare il numero di elementi nel tuo dataset. \xC8 particolarmente utile quando vuoi creare diverse feature di addestramento da un unico esempio, e ne avremo bisogno come parte di preprocessing per molti dei task NLP che affronteremo nel "),No=n(ca,"A",{href:!0});var zE=l(No);b_=o(zE,"Capitolo 7"),zE.forEach(a),E_=o(ca,"."),ca.forEach(a),Up=p(e),h(Lt.$$.fragment,e),Rp=p(e),ye=n(e,"P",{});var Ei=l(ye);w_=o(Ei,"Diamo un\u2019occhiata a come funziona! Tokenizziamo i nostri esempi e tronchiamoli a una lunghezza massima di 128, ma chiediamo al tokenizzatore di restituire "),fl=n(Ei,"EM",{});var $E=l(fl);j_=o($E,"tutti"),$E.forEach(a),D_=o(Ei," i pezzi di testo e non solo il primo. Questo pu\xF2 essere fatto con "),hl=n(Ei,"CODE",{});var bE=l(hl);x_=o(bE,"return_overflowing_tokens=True"),bE.forEach(a),k_=o(Ei,":"),Ei.forEach(a),Mp=p(e),h(as.$$.fragment,e),Fp=p(e),Ut=n(e,"P",{});var zu=l(Ut);q_=o(zu,"Testiamo questa funzione su un esempio prima di utilizzare "),vl=n(zu,"CODE",{});var EE=l(vl);T_=o(EE,"Dataset.map()"),EE.forEach(a),C_=o(zu," sull\u2019intero dataset:"),zu.forEach(a),Qp=p(e),h(ss.$$.fragment,e),Bp=p(e),h(os.$$.fragment,e),Jp=p(e),Io=n(e,"P",{});var wE=l(Io);y_=o(wE,"Quindi, il nostro primo esempio nel set di train \xE8 stato trasformaro in due feature perch\xE9 tokenizzato in un numero maggiore di token di quelli specificati: il primo gruppo di lunghezza 128 token e il secondo di lunghezza 49. Facciamo la stessa cosa per tutti gli elementi del dataset!"),wE.forEach(a),Gp=p(e),h(is.$$.fragment,e),Vp=p(e),h(ns.$$.fragment,e),Yp=p(e),Pe=n(e,"P",{});var wi=l(Pe);P_=o(wi,"Oh no! Non ha funzionato! Perch\xE9? Il messaggio di errore ci d\xE0 un indizio: c\u2019\xE8 una discordanza tra la lungheza di una delle colonne (una \xE8 lunga 1.463 e l\u2019altra 1.000). Se hai guardato la "),ls=n(wi,"A",{href:!0,rel:!0});var jE=l(ls);O_=o(jE,"documentazione"),jE.forEach(a),A_=o(wi," di "),_l=n(wi,"CODE",{});var DE=l(_l);N_=o(DE,"Dataset.map()"),DE.forEach(a),I_=o(wi,", ricorderai che quello \xE8 il numero di campioni passati alla funzione map; qui quei 1.000 esempi danno 1.463 nuove feature, che risulta in un errore di shape."),wi.forEach(a),Wp=p(e),te=n(e,"P",{});var Qe=l(te);H_=o(Qe,"Il problema \xE8 che stiamo cercando di mescolare due dataset diversi di grandezze diverse: le colonne del "),gl=n(Qe,"CODE",{});var xE=l(gl);S_=o(xE,"drug_dataset"),xE.forEach(a),L_=o(Qe," avranno un certo numero di esempi (il 1.000 del nostro errore), ma il "),zl=n(Qe,"CODE",{});var kE=l(zl);U_=o(kE,"tokenized_dataset"),kE.forEach(a),R_=o(Qe," che stiamo costruendo ne avr\xE0 di pi\xF9 (il 1.463 nel nostro messaggio di errore). Non va bene per un "),$l=n(Qe,"CODE",{});var qE=l($l);M_=o(qE,"Dataset"),qE.forEach(a),F_=o(Qe,", per cui abbiamo bisogno o di rimuovere le colonne dal dataset vecchio, o renderle della stessa dimensione del nuovo dataset. La prima opzione pu\xF2 essere effettuata utilizzando l\u2019argomento "),bl=n(Qe,"CODE",{});var TE=l(bl);Q_=o(TE,"remove_columns"),TE.forEach(a),B_=o(Qe,":"),Qe.forEach(a),Xp=p(e),h(rs.$$.fragment,e),Kp=p(e),Ho=n(e,"P",{});var CE=l(Ho);J_=o(CE,"Ora funziona senza errori. Possiamo controllare che il nostro nuovo dataset contiene pi\xF9 elementi del dataset originale paragonando le lunghezze:"),CE.forEach(a),Zp=p(e),h(ds.$$.fragment,e),ec=p(e),h(ps.$$.fragment,e),tc=p(e),Oe=n(e,"P",{});var ji=l(Oe);G_=o(ji,"Abbiamo gi\xE0 menzionato che possiamo risolvere il problema delle lunghezze discordanti cambiando la dimenzione delle vecchie colonne. Per far ci\xF2, abbiamo bisogno del campo "),El=n(ji,"CODE",{});var yE=l(El);V_=o(yE,"overflow_to_sample_mapping"),yE.forEach(a),Y_=o(ji," restituito dal tokenizzatore quando impostiamo "),wl=n(ji,"CODE",{});var PE=l(wl);W_=o(PE,"return_overflowing_tokens=True"),PE.forEach(a),X_=o(ji,". Cos\xEC facendo avremo una mappatura degli indici delle nuove feature all\u2019indice di campioni da cui sono state generate. Usando questa mappatura, possiamo associare a ogni chiava presente nel nostro dataset originale una lista di valori delle dimensioni giuste, ripetendo il valore di ogni esempio finch\xE9 genera nuove feature:"),ji.forEach(a),ac=p(e),h(cs.$$.fragment,e),sc=p(e),Rt=n(e,"P",{});var $u=l(Rt);K_=o($u,"Possiamo vedere come funziona con "),jl=n($u,"CODE",{});var OE=l(jl);Z_=o(OE,"Dataset.map()"),OE.forEach(a),eg=o($u," senza aver bisogno di rimuovere le colonne vecchie:"),$u.forEach(a),oc=p(e),h(us.$$.fragment,e),ic=p(e),h(ms.$$.fragment,e),nc=p(e),So=n(e,"P",{});var AE=l(So);tg=o(AE,"Otteniamo lo stesso numero di feature di addestramento di prima, ma qui abbiamo conservato i campi originali. Se ti servono per un post-processing dopo aver applicato il tuo modello, potresti usare quest\u2019approccio."),AE.forEach(a),lc=p(e),Mt=n(e,"P",{});var bu=l(Mt);ag=o(bu,"Ora abbiamo visto come usare \u{1F917} Datasets per preprocessare un dataset in diversi modi. Bench\xE9 le funzioni di processamento di \u{1F917} Datasets soddisfer\xE0 la maggior parte delle esigenze del modello che vuoi addestrare, ci saranno momenti in cui avrai bisogno di utilizzare Pandas per avere funzionalit\xE0 ancora pi\xF9 potenti, come "),Dl=n(bu,"CODE",{});var NE=l(Dl);sg=o(NE,"DataFrame.groupby()"),NE.forEach(a),og=o(bu," o API di alto livello per visualizzazione. Per fortuna, \u{1F917} Datasets \xE8 progettato per essere utilizzato con librerie come Pandas, NumPy, PyTorch, TensorFlow e JAX. Diamo un\u2019occhiata a come funziona."),bu.forEach(a),rc=p(e),lt=n(e,"H2",{class:!0});var Eu=l(lt);Ft=n(Eu,"A",{id:!0,class:!0,href:!0});var IE=l(Ft);xl=n(IE,"SPAN",{});var HE=l(xl);h(fs.$$.fragment,HE),HE.forEach(a),IE.forEach(a),ig=p(Eu),rt=n(Eu,"SPAN",{});var Di=l(rt);ng=o(Di,"Da "),kl=n(Di,"CODE",{});var SE=l(kl);lg=o(SE,"Dataset"),SE.forEach(a),rg=o(Di," a "),ql=n(Di,"CODE",{});var LE=l(ql);dg=o(LE,"DataFrame"),LE.forEach(a),pg=o(Di," e ritorno"),Di.forEach(a),Eu.forEach(a),dc=p(e),h(hs.$$.fragment,e),pc=p(e),ae=n(e,"P",{});var Be=l(ae);cg=o(Be,"Per permettere la conversione tra librerie terze, \u{1F917} Datasets fornisce una funzione "),Tl=n(Be,"CODE",{});var UE=l(Tl);ug=o(UE,"Dataset.set_format()"),UE.forEach(a),mg=o(Be,". Questa funzione cambia il "),Cl=n(Be,"EM",{});var RE=l(Cl);fg=o(RE,"formato di output"),RE.forEach(a),hg=o(Be," del dataset, cos\xEC che puoi passare a un altro formato senza modificare il "),yl=n(Be,"EM",{});var ME=l(yl);vg=o(ME,"formato di dati"),ME.forEach(a),_g=o(Be," soggiacente, che \xE8 Apache Arrow. La formattazione avviene direttamente "),Pl=n(Be,"EM",{});var FE=l(Pl);gg=o(FE,"in place"),FE.forEach(a),zg=o(Be,". Per provare, convertiamo il nostro dataset per Pandas:"),Be.forEach(a),cc=p(e),h(vs.$$.fragment,e),uc=p(e),Qt=n(e,"P",{});var wu=l(Qt);$g=o(wu,"Ora quando accediamo agli elementi del dataset otteniamo un "),Ol=n(wu,"CODE",{});var QE=l(Ol);bg=o(QE,"pandas.DataFrame"),QE.forEach(a),Eg=o(wu," e non un dizionario:"),wu.forEach(a),mc=p(e),h(_s.$$.fragment,e),fc=p(e),Ae=n(e,"TABLE",{border:!0,class:!0});var ju=l(Ae);Al=n(ju,"THEAD",{});var BE=l(Al);I=n(BE,"TR",{style:!0});var F=l(I);hc=n(F,"TH",{}),l(hc).forEach(a),wg=p(F),Nl=n(F,"TH",{});var JE=l(Nl);jg=o(JE,"patient_id"),JE.forEach(a),Dg=p(F),Il=n(F,"TH",{});var GE=l(Il);xg=o(GE,"drugName"),GE.forEach(a),kg=p(F),Hl=n(F,"TH",{});var VE=l(Hl);qg=o(VE,"condition"),VE.forEach(a),Tg=p(F),Sl=n(F,"TH",{});var YE=l(Sl);Cg=o(YE,"review"),YE.forEach(a),yg=p(F),Ll=n(F,"TH",{});var WE=l(Ll);Pg=o(WE,"rating"),WE.forEach(a),Og=p(F),Ul=n(F,"TH",{});var XE=l(Ul);Ag=o(XE,"date"),XE.forEach(a),Ng=p(F),Rl=n(F,"TH",{});var KE=l(Rl);Ig=o(KE,"usefulCount"),KE.forEach(a),Hg=p(F),Ml=n(F,"TH",{});var ZE=l(Ml);Sg=o(ZE,"review_length"),ZE.forEach(a),F.forEach(a),BE.forEach(a),Lg=p(ju),dt=n(ju,"TBODY",{});var xi=l(dt);H=n(xi,"TR",{});var Q=l(H);Fl=n(Q,"TH",{});var e7=l(Fl);Ug=o(e7,"0"),e7.forEach(a),Rg=p(Q),Ql=n(Q,"TD",{});var t7=l(Ql);Mg=o(t7,"95260"),t7.forEach(a),Fg=p(Q),Bl=n(Q,"TD",{});var a7=l(Bl);Qg=o(a7,"Guanfacine"),a7.forEach(a),Bg=p(Q),Jl=n(Q,"TD",{});var s7=l(Jl);Jg=o(s7,"adhd"),s7.forEach(a),Gg=p(Q),Gl=n(Q,"TD",{});var o7=l(Gl);Vg=o(o7,'"My son is halfway through his fourth week of Intuniv..."'),o7.forEach(a),Yg=p(Q),Vl=n(Q,"TD",{});var i7=l(Vl);Wg=o(i7,"8.0"),i7.forEach(a),Xg=p(Q),Yl=n(Q,"TD",{});var n7=l(Yl);Kg=o(n7,"April 27, 2010"),n7.forEach(a),Zg=p(Q),Wl=n(Q,"TD",{});var l7=l(Wl);e2=o(l7,"192"),l7.forEach(a),t2=p(Q),Xl=n(Q,"TD",{});var r7=l(Xl);a2=o(r7,"141"),r7.forEach(a),Q.forEach(a),s2=p(xi),S=n(xi,"TR",{});var B=l(S);Kl=n(B,"TH",{});var d7=l(Kl);o2=o(d7,"1"),d7.forEach(a),i2=p(B),Zl=n(B,"TD",{});var p7=l(Zl);n2=o(p7,"92703"),p7.forEach(a),l2=p(B),er=n(B,"TD",{});var c7=l(er);r2=o(c7,"Lybrel"),c7.forEach(a),d2=p(B),tr=n(B,"TD",{});var u7=l(tr);p2=o(u7,"birth control"),u7.forEach(a),c2=p(B),ar=n(B,"TD",{});var m7=l(ar);u2=o(m7,'"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."'),m7.forEach(a),m2=p(B),sr=n(B,"TD",{});var f7=l(sr);f2=o(f7,"5.0"),f7.forEach(a),h2=p(B),or=n(B,"TD",{});var h7=l(or);v2=o(h7,"December 14, 2009"),h7.forEach(a),_2=p(B),ir=n(B,"TD",{});var v7=l(ir);g2=o(v7,"17"),v7.forEach(a),z2=p(B),nr=n(B,"TD",{});var _7=l(nr);$2=o(_7,"134"),_7.forEach(a),B.forEach(a),b2=p(xi),L=n(xi,"TR",{});var J=l(L);lr=n(J,"TH",{});var g7=l(lr);E2=o(g7,"2"),g7.forEach(a),w2=p(J),rr=n(J,"TD",{});var z7=l(rr);j2=o(z7,"138000"),z7.forEach(a),D2=p(J),dr=n(J,"TD",{});var $7=l(dr);x2=o($7,"Ortho Evra"),$7.forEach(a),k2=p(J),pr=n(J,"TD",{});var b7=l(pr);q2=o(b7,"birth control"),b7.forEach(a),T2=p(J),cr=n(J,"TD",{});var E7=l(cr);C2=o(E7,'"This is my first time using any form of birth control..."'),E7.forEach(a),y2=p(J),ur=n(J,"TD",{});var w7=l(ur);P2=o(w7,"8.0"),w7.forEach(a),O2=p(J),mr=n(J,"TD",{});var j7=l(mr);A2=o(j7,"November 3, 2015"),j7.forEach(a),N2=p(J),fr=n(J,"TD",{});var D7=l(fr);I2=o(D7,"10"),D7.forEach(a),H2=p(J),hr=n(J,"TD",{});var x7=l(hr);S2=o(x7,"89"),x7.forEach(a),J.forEach(a),xi.forEach(a),ju.forEach(a),vc=p(e),Ne=n(e,"P",{});var ki=l(Ne);L2=o(ki,"Creiamo un "),vr=n(ki,"CODE",{});var k7=l(vr);U2=o(k7,"pandas.DataFrame"),k7.forEach(a),R2=o(ki," per l\u2019intero set di addestramento selezionando tutti gli elementi di "),_r=n(ki,"CODE",{});var q7=l(_r);M2=o(q7,'drug_dataset["train"]'),q7.forEach(a),F2=o(ki,":"),ki.forEach(a),_c=p(e),h(gs.$$.fragment,e),gc=p(e),h(Bt.$$.fragment,e),zc=p(e),Jt=n(e,"P",{});var Du=l(Jt);Q2=o(Du,"Da qui possiamo usare tutte le funzionalit\xE0 Pandas che vogliamo. Ad esempio, possiamo creare un concatenamento per calcolare la distribuzione delle classi nelle voci "),gr=n(Du,"CODE",{});var T7=l(gr);B2=o(T7,"condition"),T7.forEach(a),J2=o(Du,":"),Du.forEach(a),$c=p(e),h(zs.$$.fragment,e),bc=p(e),Ie=n(e,"TABLE",{border:!0,class:!0});var xu=l(Ie);zr=n(xu,"THEAD",{});var C7=l(zr);He=n(C7,"TR",{style:!0});var qi=l(He);Ec=n(qi,"TH",{}),l(Ec).forEach(a),G2=p(qi),$r=n(qi,"TH",{});var y7=l($r);V2=o(y7,"condition"),y7.forEach(a),Y2=p(qi),br=n(qi,"TH",{});var P7=l(br);W2=o(P7,"frequency"),P7.forEach(a),qi.forEach(a),C7.forEach(a),X2=p(xu),oe=n(xu,"TBODY",{});var Je=l(oe);pt=n(Je,"TR",{});var Ti=l(pt);Er=n(Ti,"TH",{});var O7=l(Er);K2=o(O7,"0"),O7.forEach(a),Z2=p(Ti),wr=n(Ti,"TD",{});var A7=l(wr);e1=o(A7,"birth control"),A7.forEach(a),t1=p(Ti),jr=n(Ti,"TD",{});var N7=l(jr);a1=o(N7,"27655"),N7.forEach(a),Ti.forEach(a),s1=p(Je),ct=n(Je,"TR",{});var Ci=l(ct);Dr=n(Ci,"TH",{});var I7=l(Dr);o1=o(I7,"1"),I7.forEach(a),i1=p(Ci),xr=n(Ci,"TD",{});var H7=l(xr);n1=o(H7,"depression"),H7.forEach(a),l1=p(Ci),kr=n(Ci,"TD",{});var S7=l(kr);r1=o(S7,"8023"),S7.forEach(a),Ci.forEach(a),d1=p(Je),ut=n(Je,"TR",{});var yi=l(ut);qr=n(yi,"TH",{});var L7=l(qr);p1=o(L7,"2"),L7.forEach(a),c1=p(yi),Tr=n(yi,"TD",{});var U7=l(Tr);u1=o(U7,"acne"),U7.forEach(a),m1=p(yi),Cr=n(yi,"TD",{});var R7=l(Cr);f1=o(R7,"5209"),R7.forEach(a),yi.forEach(a),h1=p(Je),mt=n(Je,"TR",{});var Pi=l(mt);yr=n(Pi,"TH",{});var M7=l(yr);v1=o(M7,"3"),M7.forEach(a),_1=p(Pi),Pr=n(Pi,"TD",{});var F7=l(Pr);g1=o(F7,"anxiety"),F7.forEach(a),z1=p(Pi),Or=n(Pi,"TD",{});var Q7=l(Or);$1=o(Q7,"4991"),Q7.forEach(a),Pi.forEach(a),b1=p(Je),ft=n(Je,"TR",{});var Oi=l(ft);Ar=n(Oi,"TH",{});var B7=l(Ar);E1=o(B7,"4"),B7.forEach(a),w1=p(Oi),Nr=n(Oi,"TD",{});var J7=l(Nr);j1=o(J7,"pain"),J7.forEach(a),D1=p(Oi),Ir=n(Oi,"TD",{});var G7=l(Ir);x1=o(G7,"4744"),G7.forEach(a),Oi.forEach(a),Je.forEach(a),xu.forEach(a),wc=p(e),Se=n(e,"P",{});var Ai=l(Se);k1=o(Ai,"E una volta che abbiamo finito con le nostre analisi su Pandas, possiamo sempre creare un nuovo oggetto "),Hr=n(Ai,"CODE",{});var V7=l(Hr);q1=o(V7,"Dataset"),V7.forEach(a),T1=o(Ai," utilizzando la funzione "),Sr=n(Ai,"CODE",{});var Y7=l(Sr);C1=o(Y7,"Dataset.from_pandas()"),Y7.forEach(a),y1=o(Ai,":"),Ai.forEach(a),jc=p(e),h($s.$$.fragment,e),Dc=p(e),h(bs.$$.fragment,e),xc=p(e),h(Gt.$$.fragment,e),kc=p(e),fe=n(e,"P",{});var ua=l(fe);P1=o(ua,"Questo conclude il nostro tour delle diverse tecniche di prepocessamento disponibile in \u{1F917} Datasets. Per riepilogare la sezione, creiamo un set di validazione per preparare il dataset su cui addestreremo un classificatore. Prima di far ci\xF2, resettiamo il formato di output di "),Lr=n(ua,"CODE",{});var W7=l(Lr);O1=o(W7,"drug_dataset"),W7.forEach(a),A1=o(ua," da "),Ur=n(ua,"CODE",{});var X7=l(Ur);N1=o(X7,'"pandas"'),X7.forEach(a),I1=o(ua," a "),Rr=n(ua,"CODE",{});var K7=l(Rr);H1=o(K7,'"arrow"'),K7.forEach(a),S1=o(ua,":"),ua.forEach(a),qc=p(e),h(Es.$$.fragment,e),Tc=p(e),ht=n(e,"H2",{class:!0});var ku=l(ht);Vt=n(ku,"A",{id:!0,class:!0,href:!0});var Z7=l(Vt);Mr=n(Z7,"SPAN",{});var e0=l(Mr);h(ws.$$.fragment,e0),e0.forEach(a),Z7.forEach(a),L1=p(ku),Fr=n(ku,"SPAN",{});var t0=l(Fr);U1=o(t0,"Creare un set di validazione"),t0.forEach(a),ku.forEach(a),Cc=p(e),Lo=n(e,"P",{});var a0=l(Lo);R1=o(a0,"Pur avendo un set di test che potremmo usare per la valutazione, \xE8 buona prassi lasciare il set di test intatto e creare un set di validazione sepearato durante lo sviluppo de lmodello. Una volta che sei soddisfatto della performance del tuo modello sul set di validazione, puoi proseguire con un ultimo check sul set di test. Questo processo aiuta a ridurre i rischi di overfitting sul set di test e di creare un modello che fallisce sui dati del mondo reale."),a0.forEach(a),yc=p(e),Y=n(e,"P",{});var _e=l(Y);M1=o(_e,"\u{1F917} Datasets possiede una funzione "),Qr=n(_e,"CODE",{});var s0=l(Qr);F1=o(s0,"Dataset.train_test_split()"),s0.forEach(a),Q1=o(_e,", basata sulla famosa funzionalit\xE0 da "),Br=n(_e,"CODE",{});var o0=l(Br);B1=o(o0,"scikit-learn"),o0.forEach(a),J1=o(_e,". Proviamo a utilizzarla per dividere il nostro set di addestramento in sezioni di "),Jr=n(_e,"CODE",{});var i0=l(Jr);G1=o(i0,"addestramento"),i0.forEach(a),V1=o(_e," e di "),Gr=n(_e,"CODE",{});var n0=l(Gr);Y1=o(n0,"validazione"),n0.forEach(a),W1=o(_e," (impostiamo l\u2019argomento "),Vr=n(_e,"CODE",{});var l0=l(Vr);X1=o(l0,"seed"),l0.forEach(a),K1=o(_e," per motivi di riproducibilit\xE0):"),_e.forEach(a),Pc=p(e),h(js.$$.fragment,e),Oc=p(e),h(Ds.$$.fragment,e),Ac=p(e),Yt=n(e,"P",{});var qu=l(Yt);Z1=o(qu,"Bene! Abbiamo preparato un dataset che \xE8 pronto per l\u2019addestramento di modelli! Nella "),Uo=n(qu,"A",{href:!0});var r0=l(Uo);ez=o(r0,"sezione 5"),r0.forEach(a),tz=o(qu," ti mostreremo come caricare i dataset nell\u2019Hub di Hugging Face, ma per ora concludiamo la nostra analisi esplorando alcuni modi per salvare i dataset sulla tua macchina locale."),qu.forEach(a),Nc=p(e),vt=n(e,"H2",{class:!0});var Tu=l(vt);Wt=n(Tu,"A",{id:!0,class:!0,href:!0});var d0=l(Wt);Yr=n(d0,"SPAN",{});var p0=l(Yr);h(xs.$$.fragment,p0),p0.forEach(a),d0.forEach(a),az=p(Tu),Wr=n(Tu,"SPAN",{});var c0=l(Wr);sz=o(c0,"Salvare un dataset"),c0.forEach(a),Tu.forEach(a),Ic=p(e),h(ks.$$.fragment,e),Hc=p(e),Ro=n(e,"P",{});var u0=l(Ro);oz=o(u0,"Bench\xE9 \u{1F917} Datasets memorizzi in cache tutti i dataset scaricati e le operazioni effettuate, ci sono momenti in cui vorrai salvare un dataset su disco (ad esempio, nel caso la cache venga eliminata). Come mostrato nella tabella successiva, \u{1F917} Datasets fornisce tre funzioni principali per salvare il tuo dataset in diversi formati:"),u0.forEach(a),Sc=p(e),Xt=n(e,"TABLE",{});var Cu=l(Xt);Xr=n(Cu,"THEAD",{});var m0=l(Xr);qs=n(m0,"TR",{});var yu=l(qs);Mo=n(yu,"TH",{align:!0});var f0=l(Mo);iz=o(f0,"Formato dati"),f0.forEach(a),nz=p(yu),Fo=n(yu,"TH",{align:!0});var h0=l(Fo);lz=o(h0,"Funzione"),h0.forEach(a),yu.forEach(a),m0.forEach(a),rz=p(Cu),_t=n(Cu,"TBODY",{});var Ni=l(_t);Ts=n(Ni,"TR",{});var Pu=l(Ts);Qo=n(Pu,"TD",{align:!0});var v0=l(Qo);dz=o(v0,"Arrow"),v0.forEach(a),pz=p(Pu),Bo=n(Pu,"TD",{align:!0});var _0=l(Bo);Kr=n(_0,"CODE",{});var g0=l(Kr);cz=o(g0,"Dataset.save_to_disk()"),g0.forEach(a),_0.forEach(a),Pu.forEach(a),uz=p(Ni),Cs=n(Ni,"TR",{});var Ou=l(Cs);Jo=n(Ou,"TD",{align:!0});var z0=l(Jo);mz=o(z0,"CSV"),z0.forEach(a),fz=p(Ou),Go=n(Ou,"TD",{align:!0});var $0=l(Go);Zr=n($0,"CODE",{});var b0=l(Zr);hz=o(b0,"Dataset.to_csv()"),b0.forEach(a),$0.forEach(a),Ou.forEach(a),vz=p(Ni),ys=n(Ni,"TR",{});var Au=l(ys);Vo=n(Au,"TD",{align:!0});var E0=l(Vo);_z=o(E0,"JSON"),E0.forEach(a),gz=p(Au),Yo=n(Au,"TD",{align:!0});var w0=l(Yo);ed=n(w0,"CODE",{});var j0=l(ed);zz=o(j0,"Dataset.to_json()"),j0.forEach(a),w0.forEach(a),Au.forEach(a),Ni.forEach(a),Cu.forEach(a),Lc=p(e),Wo=n(e,"P",{});var D0=l(Wo);$z=o(D0,"Ad esempio, salviamo il nostro dataset pulito in formato Arrow:"),D0.forEach(a),Uc=p(e),h(Ps.$$.fragment,e),Rc=p(e),Xo=n(e,"P",{});var x0=l(Xo);bz=o(x0,"Questo creer\xE0 un dizionario con la seguente struttura:"),x0.forEach(a),Mc=p(e),h(Os.$$.fragment,e),Fc=p(e),he=n(e,"P",{});var ma=l(he);Ez=o(ma,"dove possiamo vedere che ogni sezione \xE8 associata alla propria tavola "),td=n(ma,"EM",{});var k0=l(td);wz=o(k0,"dataset.arrow"),k0.forEach(a),jz=o(ma,", e alcuni metadata sono salvati in "),ad=n(ma,"EM",{});var q0=l(ad);Dz=o(q0,"dataset_info.json"),q0.forEach(a),xz=o(ma," e "),sd=n(ma,"EM",{});var T0=l(sd);kz=o(T0,"state.json"),T0.forEach(a),qz=o(ma,". Puoi pensare al formato Arrow come a una tavola sofisticata di colonne e righe, ottimizzata per costruire applicazioni ad alte prestazioni che processano e trasportanto grandi dataset."),ma.forEach(a),Qc=p(e),Kt=n(e,"P",{});var Nu=l(Kt);Tz=o(Nu,"Una volta che il dataset \xE8 stato salvato, possiamo caricarlo utilizzando la funzione "),od=n(Nu,"CODE",{});var C0=l(od);Cz=o(C0,"load_from_disk()"),C0.forEach(a),yz=o(Nu,":"),Nu.forEach(a),Bc=p(e),h(As.$$.fragment,e),Jc=p(e),h(Ns.$$.fragment,e),Gc=p(e),Zt=n(e,"P",{});var Iu=l(Zt);Pz=o(Iu,"Per i formati CSV e JSON, dobbiamo salvare ogni sezione come file separato. Un modo per farlo \xE8 iterando sulle chiavi e i valori dell\u2019oggetti "),id=n(Iu,"CODE",{});var y0=l(id);Oz=o(y0,"DatasetDict"),y0.forEach(a),Az=o(Iu,":"),Iu.forEach(a),Vc=p(e),h(Is.$$.fragment,e),Yc=p(e),ea=n(e,"P",{});var Hu=l(ea);Nz=o(Hu,"Questo salva ogni sezione in "),Hs=n(Hu,"A",{href:!0,rel:!0});var P0=l(Hs);Iz=o(P0,"formato JSON Lines"),P0.forEach(a),Hz=o(Hu,", in cui ogni riga del dataset \xE8 salvata come una singola riga di JSON. Ecco come appare il primo esempio:"),Hu.forEach(a),Wc=p(e),h(Ss.$$.fragment,e),Xc=p(e),h(Ls.$$.fragment,e),Kc=p(e),ta=n(e,"P",{});var Su=l(ta);Sz=o(Su,"Possiamo usare le tecniche studiate nella "),Ko=n(Su,"A",{href:!0});var O0=l(Ko);Lz=o(O0,"sezione 2"),O0.forEach(a),Uz=o(Su," per caricare i file JSON come segue:"),Su.forEach(a),Zc=p(e),h(Us.$$.fragment,e),eu=p(e),Zo=n(e,"P",{});var A0=l(Zo);Rz=o(A0,"E questo \xE8 tutto per la nostra visita nel data wrangling con \u{1F917} Datasets! Ora che abbiamo un dataset pulito su cui addestrare un modello, ecco alcune idee che potresti testare:"),A0.forEach(a),tu=p(e),aa=n(e,"OL",{});var Lu=l(aa);Rs=n(Lu,"LI",{});var Uu=l(Rs);Mz=o(Uu,"Usa le tecniche studiate nel "),ei=n(Uu,"A",{href:!0});var N0=l(ei);Fz=o(N0,"Capitolo 3"),N0.forEach(a),Qz=o(Uu," per addestrare un classificatore che pu\xF2 predirre la condizione del pazionte sulla base della recensione del medicinale."),Uu.forEach(a),Bz=p(Lu),gt=n(Lu,"LI",{});var Ii=l(gt);Jz=o(Ii,"Usa la pipeline "),nd=n(Ii,"CODE",{});var I0=l(nd);Gz=o(I0,"summarization"),I0.forEach(a),Vz=o(Ii," del "),ti=n(Ii,"A",{href:!0});var H0=l(ti);Yz=o(H0,"Capitolo 1"),H0.forEach(a),Wz=o(Ii," per generare riassunti delle recensioni."),Ii.forEach(a),Lu.forEach(a),au=p(e),ai=n(e,"P",{});var S0=l(ai);Xz=o(S0,"In seguito, daremo un\u2019occhiata a come \u{1F917} Datasets ti permette di lavorare su enormi dataset senza far scoppiare il tuo portatile!"),S0.forEach(a),this.h()},h(){m(u,"name","hf:doc:metadata"),m(u,"content",JSON.stringify(t3)),m(D,"id","arrivato-il-momento-di-tagliuzzare"),m(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(D,"href","#arrivato-il-momento-di-tagliuzzare"),m(b,"class","relative group"),m(W,"id","tagliuzzare-i-tuoi-dati"),m(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(W,"href","#tagliuzzare-i-tuoi-dati"),m(R,"class","relative group"),m(Ks,"href","/course/chapter3"),m(va,"href","https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29"),m(va,"rel","nofollow"),m(Zs,"href","/course/chapter3"),m(Na,"href","https://realpython.com/python-lambda/"),m(Na,"rel","nofollow"),m(wt,"id","creare-nuove-colonne"),m(wt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(wt,"href","#creare-nuove-colonne"),m(Xe,"class","relative group"),m(Tt,"id","i-superpoteri-del-metodo-map"),m(Tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Tt,"href","#i-superpoteri-del-metodo-map"),m(Ke,"class","relative group"),m(ro,"href","/course/chapter6"),m(po,"href","/course/chapter3"),m(uo,"align","center"),m(mo,"align","center"),m(fo,"align","center"),m(ho,"align","center"),m(vo,"align","center"),m(_o,"align","center"),m(go,"align","center"),m(zo,"align","center"),m($o,"align","center"),m(Eo,"align","center"),m(wo,"align","center"),m(jo,"align","center"),m(Do,"align","center"),m(xo,"align","center"),m(ko,"align","center"),m(qo,"align","center"),m(To,"align","center"),m(Co,"align","center"),m(It,"align","center"),m(yo,"align","center"),m(Po,"align","center"),m(Ht,"align","center"),m(Oo,"align","center"),m(Ao,"align","center"),m(No,"href","/course/chapter7"),m(ls,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),m(ls,"rel","nofollow"),m(Ft,"id","da-dataset-a-dataframe-e-ritorno"),m(Ft,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ft,"href","#da-dataset-a-dataframe-e-ritorno"),m(lt,"class","relative group"),L0(I,"text-align","right"),m(Ae,"border","1"),m(Ae,"class","dataframe"),L0(He,"text-align","right"),m(Ie,"border","1"),m(Ie,"class","dataframe"),m(Vt,"id","creare-un-set-di-validazione"),m(Vt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Vt,"href","#creare-un-set-di-validazione"),m(ht,"class","relative group"),m(Uo,"href","/course/chapter5/5"),m(Wt,"id","salvare-un-dataset"),m(Wt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Wt,"href","#salvare-un-dataset"),m(vt,"class","relative group"),m(Mo,"align","center"),m(Fo,"align","center"),m(Qo,"align","center"),m(Bo,"align","center"),m(Jo,"align","center"),m(Go,"align","center"),m(Vo,"align","center"),m(Yo,"align","center"),m(Hs,"href","https://jsonlines.org"),m(Hs,"rel","nofollow"),m(Ko,"href","/course/chapter5/2"),m(ei,"href","/course/chapter3"),m(ti,"href","/course/chapter1")},m(e,r){t(document.head,u),c(e,T,r),c(e,b,r),t(b,D),t(D,k),v(E,k,null),t(b,x),t(b,C),t(C,w),c(e,j,r),v(P,e,r),c(e,q,r),c(e,y,r),t(y,G),c(e,N,r),v(O,e,r),c(e,ge,r),c(e,R,r),t(R,W),t(W,ie),v(se,ie,null),t(R,ha),t(R,Ge),t(Ge,Ve),c(e,zt,r),c(e,M,r),t(M,Ye),t(M,A),t(A,Js),t(M,Gs),t(M,$t),t($t,Vs),t(M,Ys),t(M,bt),t(bt,Ws),t(M,Xs),t(M,Ks),t(Ks,Ru),t(M,Mu),c(e,md,r),c(e,ne,r),t(ne,Fu),t(ne,va),t(va,Qu),t(ne,Bu),t(ne,Hi),t(Hi,Ju),t(ne,Gu),t(ne,Si),t(Si,Vu),t(ne,Yu),c(e,fd,r),v(_a,e,r),c(e,hd,r),c(e,le,r),t(le,Wu),t(le,Li),t(Li,Xu),t(le,Ku),t(le,Ui),t(Ui,Zu),t(le,em),t(le,Ri),t(Ri,tm),t(le,am),c(e,vd,r),v(ga,e,r),c(e,_d,r),c(e,be,r),t(be,sm),t(be,Mi),t(Mi,om),t(be,im),t(be,Fi),t(Fi,nm),t(be,lm),c(e,gd,r),v(za,e,r),c(e,zd,r),v($a,e,r),c(e,$d,r),c(e,re,r),t(re,rm),t(re,Qi),t(Qi,dm),t(re,pm),t(re,Bi),t(Bi,cm),t(re,um),t(re,Ji),t(Ji,mm),t(re,fm),c(e,bd,r),c(e,Ee,r),t(Ee,ba),t(ba,hm),t(ba,Gi),t(Gi,vm),t(ba,_m),t(Ee,gm),t(Ee,Ea),t(Ea,zm),t(Ea,Vi),t(Vi,$m),t(Ea,bm),t(Ee,Em),t(Ee,We),t(We,wm),t(We,Yi),t(Yi,jm),t(We,Dm),t(We,Wi),t(Wi,xm),t(We,km),c(e,Ed,r),c(e,we,r),t(we,qm),t(we,Xi),t(Xi,Tm),t(we,Cm),t(we,Ki),t(Ki,ym),t(we,Pm),c(e,wd,r),v(wa,e,r),c(e,jd,r),c(e,je,r),t(je,Om),t(je,Zi),t(Zi,Am),t(je,Nm),t(je,en),t(en,Im),t(je,Hm),c(e,Dd,r),v(ja,e,r),c(e,xd,r),v(Da,e,r),c(e,kd,r),v(Et,e,r),c(e,qd,r),c(e,X,r),t(X,Sm),t(X,tn),t(tn,Lm),t(X,Um),t(X,an),t(an,Rm),t(X,Mm),t(X,Zs),t(Zs,Fm),t(X,Qm),t(X,sn),t(sn,Bm),t(X,Jm),c(e,Td,r),v(xa,e,r),c(e,Cd,r),v(ka,e,r),c(e,yd,r),c(e,K,r),t(K,Gm),t(K,on),t(on,Vm),t(K,Ym),t(K,nn),t(nn,Wm),t(K,Xm),t(K,ln),t(ln,Km),t(K,Zm),t(K,rn),t(rn,ef),t(K,tf),c(e,Pd,r),v(qa,e,r),c(e,Od,r),c(e,De,r),t(De,af),t(De,dn),t(dn,sf),t(De,of),t(De,pn),t(pn,nf),t(De,lf),c(e,Ad,r),v(Ta,e,r),c(e,Nd,r),c(e,xe,r),t(xe,rf),t(xe,cn),t(cn,df),t(xe,pf),t(xe,un),t(un,cf),t(xe,uf),c(e,Id,r),v(Ca,e,r),c(e,Hd,r),c(e,eo,r),t(eo,mf),c(e,Sd,r),v(ya,e,r),c(e,Ld,r),v(Pa,e,r),c(e,Ud,r),c(e,to,r),t(to,ff),c(e,Rd,r),v(Oa,e,r),c(e,Md,r),v(Aa,e,r),c(e,Fd,r),c(e,ke,r),t(ke,hf),t(ke,Na),t(Na,vf),t(ke,_f),t(ke,mn),t(mn,gf),t(ke,zf),c(e,Qd,r),v(Ia,e,r),c(e,Bd,r),c(e,qe,r),t(qe,$f),t(qe,fn),t(fn,bf),t(qe,Ef),t(qe,hn),t(hn,wf),t(qe,jf),c(e,Jd,r),v(Ha,e,r),c(e,Gd,r),v(Sa,e,r),c(e,Vd,r),c(e,ao,r),t(ao,Df),c(e,Yd,r),c(e,Xe,r),t(Xe,wt),t(wt,vn),v(La,vn,null),t(Xe,xf),t(Xe,_n),t(_n,kf),c(e,Wd,r),c(e,so,r),t(so,qf),c(e,Xd,r),c(e,oo,r),t(oo,Tf),c(e,Kd,r),v(Ua,e,r),c(e,Zd,r),c(e,V,r),t(V,Cf),t(V,gn),t(gn,yf),t(V,Pf),t(V,zn),t(zn,Of),t(V,Af),t(V,$n),t($n,Nf),t(V,If),t(V,bn),t(bn,Hf),t(V,Sf),t(V,En),t(En,Lf),t(V,Uf),c(e,ep,r),v(Ra,e,r),c(e,tp,r),v(Ma,e,r),c(e,ap,r),c(e,Te,r),t(Te,Rf),t(Te,wn),t(wn,Mf),t(Te,Ff),t(Te,jn),t(jn,Qf),t(Te,Bf),c(e,sp,r),v(Fa,e,r),c(e,op,r),v(Qa,e,r),c(e,ip,r),c(e,io,r),t(io,Jf),c(e,np,r),v(jt,e,r),c(e,lp,r),c(e,Ce,r),t(Ce,Gf),t(Ce,Dn),t(Dn,Vf),t(Ce,Yf),t(Ce,xn),t(xn,Wf),t(Ce,Xf),c(e,rp,r),v(Ba,e,r),c(e,dp,r),v(Ja,e,r),c(e,pp,r),c(e,no,r),t(no,Kf),c(e,cp,r),v(Dt,e,r),c(e,up,r),c(e,xt,r),t(xt,Zf),t(xt,kn),t(kn,eh),t(xt,th),c(e,mp,r),v(Ga,e,r),c(e,fp,r),v(Va,e,r),c(e,hp,r),c(e,kt,r),t(kt,ah),t(kt,qn),t(qn,sh),t(kt,oh),c(e,vp,r),v(Ya,e,r),c(e,_p,r),c(e,qt,r),t(qt,ih),t(qt,Tn),t(Tn,nh),t(qt,lh),c(e,gp,r),c(e,Ke,r),t(Ke,Tt),t(Tt,Cn),v(Wa,Cn,null),t(Ke,rh),t(Ke,lo),t(lo,dh),t(lo,yn),t(yn,ph),c(e,zp,r),c(e,de,r),t(de,ch),t(de,Pn),t(Pn,uh),t(de,mh),t(de,On),t(On,fh),t(de,hh),t(de,An),t(An,vh),t(de,_h),c(e,$p,r),c(e,Z,r),t(Z,gh),t(Z,Nn),t(Nn,zh),t(Z,$h),t(Z,In),t(In,bh),t(Z,Eh),t(Z,Hn),t(Hn,wh),t(Z,jh),t(Z,Sn),t(Sn,Dh),t(Z,xh),c(e,bp,r),v(Xa,e,r),c(e,Ep,r),c(e,Ct,r),t(Ct,kh),t(Ct,Ln),t(Ln,qh),t(Ct,Th),c(e,wp,r),c(e,pe,r),t(pe,Ch),t(pe,Un),t(Un,yh),t(pe,Ph),t(pe,Rn),t(Rn,Oh),t(pe,Ah),t(pe,ro),t(ro,Nh),t(pe,Ih),c(e,jp,r),v(Ka,e,r),c(e,Dp,r),c(e,ce,r),t(ce,Hh),t(ce,po),t(po,Sh),t(ce,Lh),t(ce,Mn),t(Mn,Uh),t(ce,Rh),t(ce,Fn),t(Fn,Mh),t(ce,Fh),c(e,xp,r),v(Za,e,r),c(e,kp,r),c(e,yt,r),t(yt,Qh),t(yt,Qn),t(Qn,Bh),t(yt,Jh),c(e,qp,r),v(Pt,e,r),c(e,Tp,r),c(e,co,r),t(co,Gh),c(e,Cp,r),c(e,Ot,r),t(Ot,Bn),t(Bn,Ze),t(Ze,uo),t(uo,Vh),t(Ze,Yh),t(Ze,mo),t(mo,Wh),t(Ze,Xh),t(Ze,fo),t(fo,Kh),t(Ot,Zh),t(Ot,es),t(es,et),t(et,ho),t(ho,Jn),t(Jn,ev),t(et,tv),t(et,vo),t(vo,av),t(et,sv),t(et,_o),t(_o,ov),t(es,iv),t(es,tt),t(tt,go),t(go,Gn),t(Gn,nv),t(tt,lv),t(tt,zo),t(zo,rv),t(tt,dv),t(tt,$o),t($o,pv),c(e,yp,r),c(e,ue,r),t(ue,cv),t(ue,Vn),t(Vn,uv),t(ue,mv),t(ue,Yn),t(Yn,fv),t(ue,hv),t(ue,Wn),t(Wn,vv),t(ue,_v),c(e,Pp,r),c(e,At,r),t(At,gv),t(At,Xn),t(Xn,zv),t(At,$v),c(e,Op,r),c(e,ze,r),t(ze,Kn),t(Kn,bv),t(ze,Ev),t(ze,Zn),t(Zn,wv),t(ze,jv),t(ze,el),t(el,Dv),t(ze,xv),c(e,Ap,r),v(ts,e,r),c(e,Np,r),c(e,bo,r),t(bo,kv),c(e,Ip,r),c(e,Nt,r),t(Nt,tl),t(tl,at),t(at,Eo),t(Eo,qv),t(at,Tv),t(at,wo),t(wo,Cv),t(at,yv),t(at,jo),t(jo,Pv),t(Nt,Ov),t(Nt,$e),t($e,st),t(st,Do),t(Do,al),t(al,Av),t(st,Nv),t(st,xo),t(xo,Iv),t(st,Hv),t(st,ko),t(ko,Sv),t($e,Lv),t($e,ot),t(ot,qo),t(qo,sl),t(sl,Uv),t(ot,Rv),t(ot,To),t(To,Mv),t(ot,Fv),t(ot,Co),t(Co,Qv),t($e,Bv),t($e,it),t(it,It),t(It,ol),t(ol,Jv),t(It,Gv),t(It,il),t(il,Vv),t(it,Yv),t(it,yo),t(yo,Wv),t(it,Xv),t(it,Po),t(Po,Kv),t($e,Zv),t($e,nt),t(nt,Ht),t(Ht,nl),t(nl,e_),t(Ht,t_),t(Ht,ll),t(ll,a_),t(nt,s_),t(nt,Oo),t(Oo,o_),t(nt,i_),t(nt,Ao),t(Ao,n_),c(e,Hp,r),c(e,ee,r),t(ee,l_),t(ee,rl),t(rl,r_),t(ee,d_),t(ee,dl),t(dl,p_),t(ee,c_),t(ee,pl),t(pl,u_),t(ee,m_),t(ee,cl),t(cl,f_),t(ee,h_),c(e,Sp,r),v(St,e,r),c(e,Lp,r),c(e,me,r),t(me,v_),t(me,ul),t(ul,__),t(me,g_),t(me,ml),t(ml,z_),t(me,$_),t(me,No),t(No,b_),t(me,E_),c(e,Up,r),v(Lt,e,r),c(e,Rp,r),c(e,ye,r),t(ye,w_),t(ye,fl),t(fl,j_),t(ye,D_),t(ye,hl),t(hl,x_),t(ye,k_),c(e,Mp,r),v(as,e,r),c(e,Fp,r),c(e,Ut,r),t(Ut,q_),t(Ut,vl),t(vl,T_),t(Ut,C_),c(e,Qp,r),v(ss,e,r),c(e,Bp,r),v(os,e,r),c(e,Jp,r),c(e,Io,r),t(Io,y_),c(e,Gp,r),v(is,e,r),c(e,Vp,r),v(ns,e,r),c(e,Yp,r),c(e,Pe,r),t(Pe,P_),t(Pe,ls),t(ls,O_),t(Pe,A_),t(Pe,_l),t(_l,N_),t(Pe,I_),c(e,Wp,r),c(e,te,r),t(te,H_),t(te,gl),t(gl,S_),t(te,L_),t(te,zl),t(zl,U_),t(te,R_),t(te,$l),t($l,M_),t(te,F_),t(te,bl),t(bl,Q_),t(te,B_),c(e,Xp,r),v(rs,e,r),c(e,Kp,r),c(e,Ho,r),t(Ho,J_),c(e,Zp,r),v(ds,e,r),c(e,ec,r),v(ps,e,r),c(e,tc,r),c(e,Oe,r),t(Oe,G_),t(Oe,El),t(El,V_),t(Oe,Y_),t(Oe,wl),t(wl,W_),t(Oe,X_),c(e,ac,r),v(cs,e,r),c(e,sc,r),c(e,Rt,r),t(Rt,K_),t(Rt,jl),t(jl,Z_),t(Rt,eg),c(e,oc,r),v(us,e,r),c(e,ic,r),v(ms,e,r),c(e,nc,r),c(e,So,r),t(So,tg),c(e,lc,r),c(e,Mt,r),t(Mt,ag),t(Mt,Dl),t(Dl,sg),t(Mt,og),c(e,rc,r),c(e,lt,r),t(lt,Ft),t(Ft,xl),v(fs,xl,null),t(lt,ig),t(lt,rt),t(rt,ng),t(rt,kl),t(kl,lg),t(rt,rg),t(rt,ql),t(ql,dg),t(rt,pg),c(e,dc,r),v(hs,e,r),c(e,pc,r),c(e,ae,r),t(ae,cg),t(ae,Tl),t(Tl,ug),t(ae,mg),t(ae,Cl),t(Cl,fg),t(ae,hg),t(ae,yl),t(yl,vg),t(ae,_g),t(ae,Pl),t(Pl,gg),t(ae,zg),c(e,cc,r),v(vs,e,r),c(e,uc,r),c(e,Qt,r),t(Qt,$g),t(Qt,Ol),t(Ol,bg),t(Qt,Eg),c(e,mc,r),v(_s,e,r),c(e,fc,r),c(e,Ae,r),t(Ae,Al),t(Al,I),t(I,hc),t(I,wg),t(I,Nl),t(Nl,jg),t(I,Dg),t(I,Il),t(Il,xg),t(I,kg),t(I,Hl),t(Hl,qg),t(I,Tg),t(I,Sl),t(Sl,Cg),t(I,yg),t(I,Ll),t(Ll,Pg),t(I,Og),t(I,Ul),t(Ul,Ag),t(I,Ng),t(I,Rl),t(Rl,Ig),t(I,Hg),t(I,Ml),t(Ml,Sg),t(Ae,Lg),t(Ae,dt),t(dt,H),t(H,Fl),t(Fl,Ug),t(H,Rg),t(H,Ql),t(Ql,Mg),t(H,Fg),t(H,Bl),t(Bl,Qg),t(H,Bg),t(H,Jl),t(Jl,Jg),t(H,Gg),t(H,Gl),t(Gl,Vg),t(H,Yg),t(H,Vl),t(Vl,Wg),t(H,Xg),t(H,Yl),t(Yl,Kg),t(H,Zg),t(H,Wl),t(Wl,e2),t(H,t2),t(H,Xl),t(Xl,a2),t(dt,s2),t(dt,S),t(S,Kl),t(Kl,o2),t(S,i2),t(S,Zl),t(Zl,n2),t(S,l2),t(S,er),t(er,r2),t(S,d2),t(S,tr),t(tr,p2),t(S,c2),t(S,ar),t(ar,u2),t(S,m2),t(S,sr),t(sr,f2),t(S,h2),t(S,or),t(or,v2),t(S,_2),t(S,ir),t(ir,g2),t(S,z2),t(S,nr),t(nr,$2),t(dt,b2),t(dt,L),t(L,lr),t(lr,E2),t(L,w2),t(L,rr),t(rr,j2),t(L,D2),t(L,dr),t(dr,x2),t(L,k2),t(L,pr),t(pr,q2),t(L,T2),t(L,cr),t(cr,C2),t(L,y2),t(L,ur),t(ur,P2),t(L,O2),t(L,mr),t(mr,A2),t(L,N2),t(L,fr),t(fr,I2),t(L,H2),t(L,hr),t(hr,S2),c(e,vc,r),c(e,Ne,r),t(Ne,L2),t(Ne,vr),t(vr,U2),t(Ne,R2),t(Ne,_r),t(_r,M2),t(Ne,F2),c(e,_c,r),v(gs,e,r),c(e,gc,r),v(Bt,e,r),c(e,zc,r),c(e,Jt,r),t(Jt,Q2),t(Jt,gr),t(gr,B2),t(Jt,J2),c(e,$c,r),v(zs,e,r),c(e,bc,r),c(e,Ie,r),t(Ie,zr),t(zr,He),t(He,Ec),t(He,G2),t(He,$r),t($r,V2),t(He,Y2),t(He,br),t(br,W2),t(Ie,X2),t(Ie,oe),t(oe,pt),t(pt,Er),t(Er,K2),t(pt,Z2),t(pt,wr),t(wr,e1),t(pt,t1),t(pt,jr),t(jr,a1),t(oe,s1),t(oe,ct),t(ct,Dr),t(Dr,o1),t(ct,i1),t(ct,xr),t(xr,n1),t(ct,l1),t(ct,kr),t(kr,r1),t(oe,d1),t(oe,ut),t(ut,qr),t(qr,p1),t(ut,c1),t(ut,Tr),t(Tr,u1),t(ut,m1),t(ut,Cr),t(Cr,f1),t(oe,h1),t(oe,mt),t(mt,yr),t(yr,v1),t(mt,_1),t(mt,Pr),t(Pr,g1),t(mt,z1),t(mt,Or),t(Or,$1),t(oe,b1),t(oe,ft),t(ft,Ar),t(Ar,E1),t(ft,w1),t(ft,Nr),t(Nr,j1),t(ft,D1),t(ft,Ir),t(Ir,x1),c(e,wc,r),c(e,Se,r),t(Se,k1),t(Se,Hr),t(Hr,q1),t(Se,T1),t(Se,Sr),t(Sr,C1),t(Se,y1),c(e,jc,r),v($s,e,r),c(e,Dc,r),v(bs,e,r),c(e,xc,r),v(Gt,e,r),c(e,kc,r),c(e,fe,r),t(fe,P1),t(fe,Lr),t(Lr,O1),t(fe,A1),t(fe,Ur),t(Ur,N1),t(fe,I1),t(fe,Rr),t(Rr,H1),t(fe,S1),c(e,qc,r),v(Es,e,r),c(e,Tc,r),c(e,ht,r),t(ht,Vt),t(Vt,Mr),v(ws,Mr,null),t(ht,L1),t(ht,Fr),t(Fr,U1),c(e,Cc,r),c(e,Lo,r),t(Lo,R1),c(e,yc,r),c(e,Y,r),t(Y,M1),t(Y,Qr),t(Qr,F1),t(Y,Q1),t(Y,Br),t(Br,B1),t(Y,J1),t(Y,Jr),t(Jr,G1),t(Y,V1),t(Y,Gr),t(Gr,Y1),t(Y,W1),t(Y,Vr),t(Vr,X1),t(Y,K1),c(e,Pc,r),v(js,e,r),c(e,Oc,r),v(Ds,e,r),c(e,Ac,r),c(e,Yt,r),t(Yt,Z1),t(Yt,Uo),t(Uo,ez),t(Yt,tz),c(e,Nc,r),c(e,vt,r),t(vt,Wt),t(Wt,Yr),v(xs,Yr,null),t(vt,az),t(vt,Wr),t(Wr,sz),c(e,Ic,r),v(ks,e,r),c(e,Hc,r),c(e,Ro,r),t(Ro,oz),c(e,Sc,r),c(e,Xt,r),t(Xt,Xr),t(Xr,qs),t(qs,Mo),t(Mo,iz),t(qs,nz),t(qs,Fo),t(Fo,lz),t(Xt,rz),t(Xt,_t),t(_t,Ts),t(Ts,Qo),t(Qo,dz),t(Ts,pz),t(Ts,Bo),t(Bo,Kr),t(Kr,cz),t(_t,uz),t(_t,Cs),t(Cs,Jo),t(Jo,mz),t(Cs,fz),t(Cs,Go),t(Go,Zr),t(Zr,hz),t(_t,vz),t(_t,ys),t(ys,Vo),t(Vo,_z),t(ys,gz),t(ys,Yo),t(Yo,ed),t(ed,zz),c(e,Lc,r),c(e,Wo,r),t(Wo,$z),c(e,Uc,r),v(Ps,e,r),c(e,Rc,r),c(e,Xo,r),t(Xo,bz),c(e,Mc,r),v(Os,e,r),c(e,Fc,r),c(e,he,r),t(he,Ez),t(he,td),t(td,wz),t(he,jz),t(he,ad),t(ad,Dz),t(he,xz),t(he,sd),t(sd,kz),t(he,qz),c(e,Qc,r),c(e,Kt,r),t(Kt,Tz),t(Kt,od),t(od,Cz),t(Kt,yz),c(e,Bc,r),v(As,e,r),c(e,Jc,r),v(Ns,e,r),c(e,Gc,r),c(e,Zt,r),t(Zt,Pz),t(Zt,id),t(id,Oz),t(Zt,Az),c(e,Vc,r),v(Is,e,r),c(e,Yc,r),c(e,ea,r),t(ea,Nz),t(ea,Hs),t(Hs,Iz),t(ea,Hz),c(e,Wc,r),v(Ss,e,r),c(e,Xc,r),v(Ls,e,r),c(e,Kc,r),c(e,ta,r),t(ta,Sz),t(ta,Ko),t(Ko,Lz),t(ta,Uz),c(e,Zc,r),v(Us,e,r),c(e,eu,r),c(e,Zo,r),t(Zo,Rz),c(e,tu,r),c(e,aa,r),t(aa,Rs),t(Rs,Mz),t(Rs,ei),t(ei,Fz),t(Rs,Qz),t(aa,Bz),t(aa,gt),t(gt,Jz),t(gt,nd),t(nd,Gz),t(gt,Vz),t(gt,ti),t(ti,Yz),t(gt,Wz),c(e,au,r),c(e,ai,r),t(ai,Xz),su=!0},p(e,[r]){const Ms={};r&2&&(Ms.$$scope={dirty:r,ctx:e}),Et.$set(Ms);const ld={};r&2&&(ld.$$scope={dirty:r,ctx:e}),jt.$set(ld);const rd={};r&2&&(rd.$$scope={dirty:r,ctx:e}),Dt.$set(rd);const dd={};r&2&&(dd.$$scope={dirty:r,ctx:e}),Pt.$set(dd);const pd={};r&2&&(pd.$$scope={dirty:r,ctx:e}),St.$set(pd);const Fs={};r&2&&(Fs.$$scope={dirty:r,ctx:e}),Lt.$set(Fs);const cd={};r&2&&(cd.$$scope={dirty:r,ctx:e}),Bt.$set(cd);const ud={};r&2&&(ud.$$scope={dirty:r,ctx:e}),Gt.$set(ud)},i(e){su||(_(E.$$.fragment,e),_(P.$$.fragment,e),_(O.$$.fragment,e),_(se.$$.fragment,e),_(_a.$$.fragment,e),_(ga.$$.fragment,e),_(za.$$.fragment,e),_($a.$$.fragment,e),_(wa.$$.fragment,e),_(ja.$$.fragment,e),_(Da.$$.fragment,e),_(Et.$$.fragment,e),_(xa.$$.fragment,e),_(ka.$$.fragment,e),_(qa.$$.fragment,e),_(Ta.$$.fragment,e),_(Ca.$$.fragment,e),_(ya.$$.fragment,e),_(Pa.$$.fragment,e),_(Oa.$$.fragment,e),_(Aa.$$.fragment,e),_(Ia.$$.fragment,e),_(Ha.$$.fragment,e),_(Sa.$$.fragment,e),_(La.$$.fragment,e),_(Ua.$$.fragment,e),_(Ra.$$.fragment,e),_(Ma.$$.fragment,e),_(Fa.$$.fragment,e),_(Qa.$$.fragment,e),_(jt.$$.fragment,e),_(Ba.$$.fragment,e),_(Ja.$$.fragment,e),_(Dt.$$.fragment,e),_(Ga.$$.fragment,e),_(Va.$$.fragment,e),_(Ya.$$.fragment,e),_(Wa.$$.fragment,e),_(Xa.$$.fragment,e),_(Ka.$$.fragment,e),_(Za.$$.fragment,e),_(Pt.$$.fragment,e),_(ts.$$.fragment,e),_(St.$$.fragment,e),_(Lt.$$.fragment,e),_(as.$$.fragment,e),_(ss.$$.fragment,e),_(os.$$.fragment,e),_(is.$$.fragment,e),_(ns.$$.fragment,e),_(rs.$$.fragment,e),_(ds.$$.fragment,e),_(ps.$$.fragment,e),_(cs.$$.fragment,e),_(us.$$.fragment,e),_(ms.$$.fragment,e),_(fs.$$.fragment,e),_(hs.$$.fragment,e),_(vs.$$.fragment,e),_(_s.$$.fragment,e),_(gs.$$.fragment,e),_(Bt.$$.fragment,e),_(zs.$$.fragment,e),_($s.$$.fragment,e),_(bs.$$.fragment,e),_(Gt.$$.fragment,e),_(Es.$$.fragment,e),_(ws.$$.fragment,e),_(js.$$.fragment,e),_(Ds.$$.fragment,e),_(xs.$$.fragment,e),_(ks.$$.fragment,e),_(Ps.$$.fragment,e),_(Os.$$.fragment,e),_(As.$$.fragment,e),_(Ns.$$.fragment,e),_(Is.$$.fragment,e),_(Ss.$$.fragment,e),_(Ls.$$.fragment,e),_(Us.$$.fragment,e),su=!0)},o(e){g(E.$$.fragment,e),g(P.$$.fragment,e),g(O.$$.fragment,e),g(se.$$.fragment,e),g(_a.$$.fragment,e),g(ga.$$.fragment,e),g(za.$$.fragment,e),g($a.$$.fragment,e),g(wa.$$.fragment,e),g(ja.$$.fragment,e),g(Da.$$.fragment,e),g(Et.$$.fragment,e),g(xa.$$.fragment,e),g(ka.$$.fragment,e),g(qa.$$.fragment,e),g(Ta.$$.fragment,e),g(Ca.$$.fragment,e),g(ya.$$.fragment,e),g(Pa.$$.fragment,e),g(Oa.$$.fragment,e),g(Aa.$$.fragment,e),g(Ia.$$.fragment,e),g(Ha.$$.fragment,e),g(Sa.$$.fragment,e),g(La.$$.fragment,e),g(Ua.$$.fragment,e),g(Ra.$$.fragment,e),g(Ma.$$.fragment,e),g(Fa.$$.fragment,e),g(Qa.$$.fragment,e),g(jt.$$.fragment,e),g(Ba.$$.fragment,e),g(Ja.$$.fragment,e),g(Dt.$$.fragment,e),g(Ga.$$.fragment,e),g(Va.$$.fragment,e),g(Ya.$$.fragment,e),g(Wa.$$.fragment,e),g(Xa.$$.fragment,e),g(Ka.$$.fragment,e),g(Za.$$.fragment,e),g(Pt.$$.fragment,e),g(ts.$$.fragment,e),g(St.$$.fragment,e),g(Lt.$$.fragment,e),g(as.$$.fragment,e),g(ss.$$.fragment,e),g(os.$$.fragment,e),g(is.$$.fragment,e),g(ns.$$.fragment,e),g(rs.$$.fragment,e),g(ds.$$.fragment,e),g(ps.$$.fragment,e),g(cs.$$.fragment,e),g(us.$$.fragment,e),g(ms.$$.fragment,e),g(fs.$$.fragment,e),g(hs.$$.fragment,e),g(vs.$$.fragment,e),g(_s.$$.fragment,e),g(gs.$$.fragment,e),g(Bt.$$.fragment,e),g(zs.$$.fragment,e),g($s.$$.fragment,e),g(bs.$$.fragment,e),g(Gt.$$.fragment,e),g(Es.$$.fragment,e),g(ws.$$.fragment,e),g(js.$$.fragment,e),g(Ds.$$.fragment,e),g(xs.$$.fragment,e),g(ks.$$.fragment,e),g(Ps.$$.fragment,e),g(Os.$$.fragment,e),g(As.$$.fragment,e),g(Ns.$$.fragment,e),g(Is.$$.fragment,e),g(Ss.$$.fragment,e),g(Ls.$$.fragment,e),g(Us.$$.fragment,e),su=!1},d(e){a(u),e&&a(T),e&&a(b),z(E),e&&a(j),z(P,e),e&&a(q),e&&a(y),e&&a(N),z(O,e),e&&a(ge),e&&a(R),z(se),e&&a(zt),e&&a(M),e&&a(md),e&&a(ne),e&&a(fd),z(_a,e),e&&a(hd),e&&a(le),e&&a(vd),z(ga,e),e&&a(_d),e&&a(be),e&&a(gd),z(za,e),e&&a(zd),z($a,e),e&&a($d),e&&a(re),e&&a(bd),e&&a(Ee),e&&a(Ed),e&&a(we),e&&a(wd),z(wa,e),e&&a(jd),e&&a(je),e&&a(Dd),z(ja,e),e&&a(xd),z(Da,e),e&&a(kd),z(Et,e),e&&a(qd),e&&a(X),e&&a(Td),z(xa,e),e&&a(Cd),z(ka,e),e&&a(yd),e&&a(K),e&&a(Pd),z(qa,e),e&&a(Od),e&&a(De),e&&a(Ad),z(Ta,e),e&&a(Nd),e&&a(xe),e&&a(Id),z(Ca,e),e&&a(Hd),e&&a(eo),e&&a(Sd),z(ya,e),e&&a(Ld),z(Pa,e),e&&a(Ud),e&&a(to),e&&a(Rd),z(Oa,e),e&&a(Md),z(Aa,e),e&&a(Fd),e&&a(ke),e&&a(Qd),z(Ia,e),e&&a(Bd),e&&a(qe),e&&a(Jd),z(Ha,e),e&&a(Gd),z(Sa,e),e&&a(Vd),e&&a(ao),e&&a(Yd),e&&a(Xe),z(La),e&&a(Wd),e&&a(so),e&&a(Xd),e&&a(oo),e&&a(Kd),z(Ua,e),e&&a(Zd),e&&a(V),e&&a(ep),z(Ra,e),e&&a(tp),z(Ma,e),e&&a(ap),e&&a(Te),e&&a(sp),z(Fa,e),e&&a(op),z(Qa,e),e&&a(ip),e&&a(io),e&&a(np),z(jt,e),e&&a(lp),e&&a(Ce),e&&a(rp),z(Ba,e),e&&a(dp),z(Ja,e),e&&a(pp),e&&a(no),e&&a(cp),z(Dt,e),e&&a(up),e&&a(xt),e&&a(mp),z(Ga,e),e&&a(fp),z(Va,e),e&&a(hp),e&&a(kt),e&&a(vp),z(Ya,e),e&&a(_p),e&&a(qt),e&&a(gp),e&&a(Ke),z(Wa),e&&a(zp),e&&a(de),e&&a($p),e&&a(Z),e&&a(bp),z(Xa,e),e&&a(Ep),e&&a(Ct),e&&a(wp),e&&a(pe),e&&a(jp),z(Ka,e),e&&a(Dp),e&&a(ce),e&&a(xp),z(Za,e),e&&a(kp),e&&a(yt),e&&a(qp),z(Pt,e),e&&a(Tp),e&&a(co),e&&a(Cp),e&&a(Ot),e&&a(yp),e&&a(ue),e&&a(Pp),e&&a(At),e&&a(Op),e&&a(ze),e&&a(Ap),z(ts,e),e&&a(Np),e&&a(bo),e&&a(Ip),e&&a(Nt),e&&a(Hp),e&&a(ee),e&&a(Sp),z(St,e),e&&a(Lp),e&&a(me),e&&a(Up),z(Lt,e),e&&a(Rp),e&&a(ye),e&&a(Mp),z(as,e),e&&a(Fp),e&&a(Ut),e&&a(Qp),z(ss,e),e&&a(Bp),z(os,e),e&&a(Jp),e&&a(Io),e&&a(Gp),z(is,e),e&&a(Vp),z(ns,e),e&&a(Yp),e&&a(Pe),e&&a(Wp),e&&a(te),e&&a(Xp),z(rs,e),e&&a(Kp),e&&a(Ho),e&&a(Zp),z(ds,e),e&&a(ec),z(ps,e),e&&a(tc),e&&a(Oe),e&&a(ac),z(cs,e),e&&a(sc),e&&a(Rt),e&&a(oc),z(us,e),e&&a(ic),z(ms,e),e&&a(nc),e&&a(So),e&&a(lc),e&&a(Mt),e&&a(rc),e&&a(lt),z(fs),e&&a(dc),z(hs,e),e&&a(pc),e&&a(ae),e&&a(cc),z(vs,e),e&&a(uc),e&&a(Qt),e&&a(mc),z(_s,e),e&&a(fc),e&&a(Ae),e&&a(vc),e&&a(Ne),e&&a(_c),z(gs,e),e&&a(gc),z(Bt,e),e&&a(zc),e&&a(Jt),e&&a($c),z(zs,e),e&&a(bc),e&&a(Ie),e&&a(wc),e&&a(Se),e&&a(jc),z($s,e),e&&a(Dc),z(bs,e),e&&a(xc),z(Gt,e),e&&a(kc),e&&a(fe),e&&a(qc),z(Es,e),e&&a(Tc),e&&a(ht),z(ws),e&&a(Cc),e&&a(Lo),e&&a(yc),e&&a(Y),e&&a(Pc),z(js,e),e&&a(Oc),z(Ds,e),e&&a(Ac),e&&a(Yt),e&&a(Nc),e&&a(vt),z(xs),e&&a(Ic),z(ks,e),e&&a(Hc),e&&a(Ro),e&&a(Sc),e&&a(Xt),e&&a(Lc),e&&a(Wo),e&&a(Uc),z(Ps,e),e&&a(Rc),e&&a(Xo),e&&a(Mc),z(Os,e),e&&a(Fc),e&&a(he),e&&a(Qc),e&&a(Kt),e&&a(Bc),z(As,e),e&&a(Jc),z(Ns,e),e&&a(Gc),e&&a(Zt),e&&a(Vc),z(Is,e),e&&a(Yc),e&&a(ea),e&&a(Wc),z(Ss,e),e&&a(Xc),z(Ls,e),e&&a(Kc),e&&a(ta),e&&a(Zc),z(Us,e),e&&a(eu),e&&a(Zo),e&&a(tu),e&&a(aa),e&&a(au),e&&a(ai)}}}const t3={local:"arrivato-il-momento-di-tagliuzzare",sections:[{local:"tagliuzzare-i-tuoi-dati",title:"Tagliuzzare i tuoi dati"},{local:"creare-nuove-colonne",title:"Creare nuove colonne"},{local:"i-superpoteri-del-metodo-map",title:"I superpoteri del metodo `map()` "},{local:"da-dataset-a-dataframe-e-ritorno",title:"Da `Dataset` a `DataFrame` e ritorno"},{local:"creare-un-set-di-validazione",title:"Creare un set di validazione"},{local:"salvare-un-dataset",title:"Salvare un dataset"}],title:"\xC8 arrivato il momento di tagliuzzare"};function a3(U){return Q0(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class d3 extends U0{constructor(u){super();R0(this,u,a3,e3,M0,{})}}export{d3 as default,t3 as metadata};
