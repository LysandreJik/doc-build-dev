import{S as fp,i as hp,s as bp,e as r,k as d,w as z,t as i,M as _p,c as p,d as s,m as f,x as w,a as c,h as n,b as E,N as So,G as t,g as u,y,o as $,p as ce,q as g,B as P,v as vp,n as ue}from"../../chunks/vendor-hf-doc-builder.js";import{T as up}from"../../chunks/Tip-hf-doc-builder.js";import{Y as mp}from"../../chunks/Youtube-hf-doc-builder.js";import{I as _t}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as I}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as dp}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as $p}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function gp(j){let a,m;return a=new dp({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section2_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section2_tf.ipynb"}]}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function kp(j){let a,m;return a=new dp({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section2_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section2_pt.ipynb"}]}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function jp(j){let a;return{c(){a=i("Questa \xE8 la prima sezione in cui il contenuto \xE8 leggermente diverso a seconda che si utilizzi PyTorch o TensorFlow. Attivate lo switch sopra il titolo per selezionare la tua piattaforma preferita!")},l(m){a=n(m,"Questa \xE8 la prima sezione in cui il contenuto \xE8 leggermente diverso a seconda che si utilizzi PyTorch o TensorFlow. Attivate lo switch sopra il titolo per selezionare la tua piattaforma preferita!")},m(m,o){u(m,a,o)},d(m){m&&s(a)}}}function Ep(j){let a,m;return a=new mp({props:{id:"wVN12smEvqg"}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function zp(j){let a,m;return a=new mp({props:{id:"1pedAIvTWXk"}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function wp(j){let a,m;return a=new I({props:{code:`raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="tf")
print(inputs)`,highlighted:`raw_inputs = [
    <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,
    <span class="hljs-string">&quot;I hate this so much!&quot;</span>,
]
inputs = tokenizer(raw_inputs, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-built_in">print</span>(inputs)`}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function yp(j){let a,m;return a=new I({props:{code:`raw_inputs = [
    "I've been waiting for a HuggingFace course my whole life.",
    "I hate this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)`,highlighted:`raw_inputs = [
    <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,
    <span class="hljs-string">&quot;I hate this so much!&quot;</span>,
]
inputs = tokenizer(raw_inputs, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-built_in">print</span>(inputs)`}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function Pp(j){let a,m,o,h,_;return h=new I({props:{code:`{
    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],
            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
        ], dtype=int32)>, 
    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=
        array([
            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
            [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
        ], dtype=int32)>
}`,highlighted:`{
    <span class="hljs-string">&#x27;input_ids&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">16</span>), dtype=int32, numpy=
        array([
            [  <span class="hljs-number">101</span>,  <span class="hljs-number">1045</span>,  <span class="hljs-number">1005</span>,  <span class="hljs-number">2310</span>,  <span class="hljs-number">2042</span>,  <span class="hljs-number">3403</span>,  <span class="hljs-number">2005</span>,  <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>, <span class="hljs-number">12172</span>,  <span class="hljs-number">2607</span>,  <span class="hljs-number">2026</span>,  <span class="hljs-number">2878</span>,  <span class="hljs-number">2166</span>,  <span class="hljs-number">1012</span>,   <span class="hljs-number">102</span>],
            [  <span class="hljs-number">101</span>,  <span class="hljs-number">1045</span>,  <span class="hljs-number">5223</span>,  <span class="hljs-number">2023</span>,  <span class="hljs-number">2061</span>,  <span class="hljs-number">2172</span>,   <span class="hljs-number">999</span>,   <span class="hljs-number">102</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>]
        ], dtype=int32)&gt;, 
    <span class="hljs-string">&#x27;attention_mask&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">16</span>), dtype=int32, numpy=
        array([
            [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
            [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]
        ], dtype=int32)&gt;
}`}}),{c(){a=r("p"),m=i("Ecco come appaiono i risultati come tensori TensorFlow:"),o=d(),z(h.$$.fragment)},l(b){a=p(b,"P",{});var q=c(a);m=n(q,"Ecco come appaiono i risultati come tensori TensorFlow:"),q.forEach(s),o=f(b),w(h.$$.fragment,b)},m(b,q){u(b,a,q),t(a,m),u(b,o,q),y(h,b,q),_=!0},i(b){_||(g(h.$$.fragment,b),_=!0)},o(b){$(h.$$.fragment,b),_=!1},d(b){b&&s(a),b&&s(o),P(h,b)}}}function Tp(j){let a,m,o,h,_;return h=new I({props:{code:`{
    'input_ids': tensor([
        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],
        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]
    ]), 
    'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
    ])
}`,highlighted:`{
    <span class="hljs-string">&#x27;input_ids&#x27;</span>: tensor([
        [  <span class="hljs-number">101</span>,  <span class="hljs-number">1045</span>,  <span class="hljs-number">1005</span>,  <span class="hljs-number">2310</span>,  <span class="hljs-number">2042</span>,  <span class="hljs-number">3403</span>,  <span class="hljs-number">2005</span>,  <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>, <span class="hljs-number">12172</span>, <span class="hljs-number">2607</span>,  <span class="hljs-number">2026</span>,  <span class="hljs-number">2878</span>,  <span class="hljs-number">2166</span>,  <span class="hljs-number">1012</span>,   <span class="hljs-number">102</span>],
        [  <span class="hljs-number">101</span>,  <span class="hljs-number">1045</span>,  <span class="hljs-number">5223</span>,  <span class="hljs-number">2023</span>,  <span class="hljs-number">2061</span>,  <span class="hljs-number">2172</span>,   <span class="hljs-number">999</span>,   <span class="hljs-number">102</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>]
    ]), 
    <span class="hljs-string">&#x27;attention_mask&#x27;</span>: tensor([
        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]
    ])
}`}}),{c(){a=r("p"),m=i("Ecco come appaiono i risultati come tensori PyTorch:"),o=d(),z(h.$$.fragment)},l(b){a=p(b,"P",{});var q=c(a);m=n(q,"Ecco come appaiono i risultati come tensori PyTorch:"),q.forEach(s),o=f(b),w(h.$$.fragment,b)},m(b,q){u(b,a,q),t(a,m),u(b,o,q),y(h,b,q),_=!0},i(b){_||(g(h.$$.fragment,b),_=!0)},o(b){$(h.$$.fragment,b),_=!1},d(b){b&&s(a),b&&s(o),P(h,b)}}}function qp(j){let a,m,o,h,_,b,q,A,S,T,C;return T=new I({props:{code:`from transformers import TFAutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModel.from_pretrained(checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
model = TFAutoModel.from_pretrained(checkpoint)`}}),{c(){a=r("p"),m=i("Possiamo scaricare il nostro modello preaddestrato nello stesso modo in cui abbiamo fatto con il nostro tokenizer.  \u{1F917} Transformers fornisce una classe "),o=r("code"),h=i("TFAutoModel"),_=i(" che ha anche un metodo "),b=r("code"),q=i("from_pretrained"),A=i(":"),S=d(),z(T.$$.fragment)},l(v){a=p(v,"P",{});var k=c(a);m=n(k,"Possiamo scaricare il nostro modello preaddestrato nello stesso modo in cui abbiamo fatto con il nostro tokenizer.  \u{1F917} Transformers fornisce una classe "),o=p(k,"CODE",{});var M=c(o);h=n(M,"TFAutoModel"),M.forEach(s),_=n(k," che ha anche un metodo "),b=p(k,"CODE",{});var N=c(b);q=n(N,"from_pretrained"),N.forEach(s),A=n(k,":"),k.forEach(s),S=f(v),w(T.$$.fragment,v)},m(v,k){u(v,a,k),t(a,m),t(a,o),t(o,h),t(a,_),t(a,b),t(b,q),t(a,A),u(v,S,k),y(T,v,k),C=!0},i(v){C||(g(T.$$.fragment,v),C=!0)},o(v){$(T.$$.fragment,v),C=!1},d(v){v&&s(a),v&&s(S),P(T,v)}}}function Ip(j){let a,m,o,h,_,b,q,A,S,T,C;return T=new I({props:{code:`from transformers import AutoModel

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModel.from_pretrained(checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
model = AutoModel.from_pretrained(checkpoint)`}}),{c(){a=r("p"),m=i("Possiamo scaricare il nostro modello preaddestrato nello stesso modo in cui abbiamo fatto con il nostro tokenizer. \u{1F917} Transformers fornisce una classe "),o=r("code"),h=i("AutoModel"),_=i(" che ha anche un metodo "),b=r("code"),q=i("from_pretrained()"),A=i(":"),S=d(),z(T.$$.fragment)},l(v){a=p(v,"P",{});var k=c(a);m=n(k,"Possiamo scaricare il nostro modello preaddestrato nello stesso modo in cui abbiamo fatto con il nostro tokenizer. \u{1F917} Transformers fornisce una classe "),o=p(k,"CODE",{});var M=c(o);h=n(M,"AutoModel"),M.forEach(s),_=n(k," che ha anche un metodo "),b=p(k,"CODE",{});var N=c(b);q=n(N,"from_pretrained()"),N.forEach(s),A=n(k,":"),k.forEach(s),S=f(v),w(T.$$.fragment,v)},m(v,k){u(v,a,k),t(a,m),t(a,o),t(o,h),t(a,_),t(a,b),t(b,q),t(a,A),u(v,S,k),y(T,v,k),C=!0},i(v){C||(g(T.$$.fragment,v),C=!0)},o(v){$(T.$$.fragment,v),C=!1},d(v){v&&s(a),v&&s(S),P(T,v)}}}function Ap(j){let a,m,o,h;return a=new I({props:{code:`outputs = model(inputs)
print(outputs.last_hidden_state.shape)`,highlighted:`outputs = model(inputs)
<span class="hljs-built_in">print</span>(outputs.last_hidden_state.shape)`}}),o=new I({props:{code:"(2, 16, 768)",highlighted:'(<span class="hljs-number">2</span>, <span class="hljs-number">16</span>, <span class="hljs-number">768</span>)'}}),{c(){z(a.$$.fragment),m=d(),z(o.$$.fragment)},l(_){w(a.$$.fragment,_),m=f(_),w(o.$$.fragment,_)},m(_,b){y(a,_,b),u(_,m,b),y(o,_,b),h=!0},i(_){h||(g(a.$$.fragment,_),g(o.$$.fragment,_),h=!0)},o(_){$(a.$$.fragment,_),$(o.$$.fragment,_),h=!1},d(_){P(a,_),_&&s(m),P(o,_)}}}function Sp(j){let a,m,o,h;return a=new I({props:{code:`outputs = model(**inputs)
print(outputs.last_hidden_state.shape)`,highlighted:`outputs = model(**inputs)
<span class="hljs-built_in">print</span>(outputs.last_hidden_state.shape)`}}),o=new I({props:{code:"torch.Size([2, 16, 768])",highlighted:'torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">16</span>, <span class="hljs-number">768</span>])'}}),{c(){z(a.$$.fragment),m=d(),z(o.$$.fragment)},l(_){w(a.$$.fragment,_),m=f(_),w(o.$$.fragment,_)},m(_,b){y(a,_,b),u(_,m,b),y(o,_,b),h=!0},i(_){h||(g(a.$$.fragment,_),g(o.$$.fragment,_),h=!0)},o(_){$(a.$$.fragment,_),$(o.$$.fragment,_),h=!1},d(_){P(a,_),_&&s(m),P(o,_)}}}function Cp(j){let a,m,o,h,_,b,q,A,S,T,C;return T=new I({props:{code:`from transformers import TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(inputs)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(inputs)`}}),{c(){a=r("p"),m=i("Per il nostro esempio, avremo bisogno di un modello con una classificazion head della sequenza (per poter classificare le frasi come positive o negative). Quindi, non useremo la classe "),o=r("code"),h=i("TFAutoModel"),_=i(", ma "),b=r("code"),q=i("TFAutoModelForSequenceClassification"),A=i(":"),S=d(),z(T.$$.fragment)},l(v){a=p(v,"P",{});var k=c(a);m=n(k,"Per il nostro esempio, avremo bisogno di un modello con una classificazion head della sequenza (per poter classificare le frasi come positive o negative). Quindi, non useremo la classe "),o=p(k,"CODE",{});var M=c(o);h=n(M,"TFAutoModel"),M.forEach(s),_=n(k,", ma "),b=p(k,"CODE",{});var N=c(b);q=n(N,"TFAutoModelForSequenceClassification"),N.forEach(s),A=n(k,":"),k.forEach(s),S=f(v),w(T.$$.fragment,v)},m(v,k){u(v,a,k),t(a,m),t(a,o),t(o,h),t(a,_),t(a,b),t(b,q),t(a,A),u(v,S,k),y(T,v,k),C=!0},i(v){C||(g(T.$$.fragment,v),C=!0)},o(v){$(T.$$.fragment,v),C=!1},d(v){v&&s(a),v&&s(S),P(T,v)}}}function Mp(j){let a,m,o,h,_,b,q,A,S,T,C;return T=new I({props:{code:`from transformers import AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
outputs = model(**inputs)`}}),{c(){a=r("p"),m=i("Per il nostro esempio, avremo bisogno di un modello con una classificazion head della sequenza (per poter classificare le frasi come positive o negative). Quindi, non useremo la classe "),o=r("code"),h=i("AutoModel"),_=i(", ma "),b=r("code"),q=i("AutoModelForSequenceClassification"),A=i(":"),S=d(),z(T.$$.fragment)},l(v){a=p(v,"P",{});var k=c(a);m=n(k,"Per il nostro esempio, avremo bisogno di un modello con una classificazion head della sequenza (per poter classificare le frasi come positive o negative). Quindi, non useremo la classe "),o=p(k,"CODE",{});var M=c(o);h=n(M,"AutoModel"),M.forEach(s),_=n(k,", ma "),b=p(k,"CODE",{});var N=c(b);q=n(N,"AutoModelForSequenceClassification"),N.forEach(s),A=n(k,":"),k.forEach(s),S=f(v),w(T.$$.fragment,v)},m(v,k){u(v,a,k),t(a,m),t(a,o),t(o,h),t(a,_),t(a,b),t(b,q),t(a,A),u(v,S,k),y(T,v,k),C=!0},i(v){C||(g(T.$$.fragment,v),C=!0)},o(v){$(T.$$.fragment,v),C=!1},d(v){v&&s(a),v&&s(S),P(T,v)}}}function Dp(j){let a,m;return a=new I({props:{code:"(2, 2)",highlighted:'(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)'}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function Np(j){let a,m;return a=new I({props:{code:"torch.Size([2, 2])",highlighted:'torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>])'}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function Fp(j){let a,m;return a=new I({props:{code:`<tf.Tensor: shape=(2, 2), dtype=float32, numpy=
    array([[-1.5606991,  1.6122842],
           [ 4.169231 , -3.3464472]], dtype=float32)>`,highlighted:`&lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=float32, numpy=
    array([[-<span class="hljs-number">1.5606991</span>,  <span class="hljs-number">1.6122842</span>],
           [ <span class="hljs-number">4.169231</span> , -<span class="hljs-number">3.3464472</span>]], dtype=float32)&gt;`}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function xp(j){let a,m;return a=new I({props:{code:`tensor([[-1.5607,  1.6123],
        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)`,highlighted:`tensor([[-<span class="hljs-number">1.5607</span>,  <span class="hljs-number">1.6123</span>],
        [ <span class="hljs-number">4.1692</span>, -<span class="hljs-number">3.3464</span>]], grad_fn=&lt;AddmmBackward&gt;)`}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function Op(j){let a,m;return a=new I({props:{code:`import tensorflow as tf

predictions = tf.math.softmax(outputs.logits, axis=-1)
print(predictions)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

predictions = tf.math.softmax(outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-built_in">print</span>(predictions)`}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function Lp(j){let a,m;return a=new I({props:{code:`import torch

predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
print(predictions)`,highlighted:`<span class="hljs-keyword">import</span> torch

predictions = torch.nn.functional.softmax(outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-built_in">print</span>(predictions)`}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function Gp(j){let a,m;return a=new I({props:{code:`tf.Tensor(
[[4.01951671e-02 9.59804833e-01]
 [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)`,highlighted:`tf.Tensor(
[[<span class="hljs-number">4.01951671e-02</span> <span class="hljs-number">9.59804833e-01</span>]
 [<span class="hljs-number">9.9945587e-01</span> <span class="hljs-number">5.4418424e-04</span>]], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), dtype=float32)`}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function Vp(j){let a,m;return a=new I({props:{code:`tensor([[4.0195e-02, 9.5980e-01],
        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)`,highlighted:`tensor([[<span class="hljs-number">4.0195e-02</span>, <span class="hljs-number">9.5980e-01</span>],
        [<span class="hljs-number">9.9946e-01</span>, <span class="hljs-number">5.4418e-04</span>]], grad_fn=&lt;SoftmaxBackward&gt;)`}}),{c(){z(a.$$.fragment)},l(o){w(a.$$.fragment,o)},m(o,h){y(a,o,h),m=!0},i(o){m||(g(a.$$.fragment,o),m=!0)},o(o){$(a.$$.fragment,o),m=!1},d(o){P(a,o)}}}function Up(j){let a;return{c(){a=i("\u270F\uFE0F **Provaci anche tu!** Scegli due (o pi\xF9) testi di tua propriet\xE0 e lanciali all'interno della pipeline `sentiment-analysis`. Successivamente, replica i passi che hai visto qui e verifica di aver ottenuto gli stessi risultati!")},l(m){a=n(m,"\u270F\uFE0F **Provaci anche tu!** Scegli due (o pi\xF9) testi di tua propriet\xE0 e lanciali all'interno della pipeline `sentiment-analysis`. Successivamente, replica i passi che hai visto qui e verifica di aver ottenuto gli stessi risultati!")},m(m,o){u(m,a,o)},d(m){m&&s(a)}}}function Hp(j){let a,m,o,h,_,b,q,A,S,T,C,v,k,M,N,we,ja,H,Q,ws,ye,Co,ys,Mo,Do,Ea,Re,za,Ps,No,wa,Ye,ya,Pe,Fo,Ts,xo,Oo,Pa,ve,Je,fn,Lo,We,hn,Ta,qs,Go,qa,$e,Te,vt,Xe,Vo,$t,Uo,Ia,qe,Ho,gt,Qo,Bo,Aa,me,Ke,Ro,kt,Yo,Jo,Wo,jt,Xo,Ko,Et,Zo,Sa,L,el,Ze,sl,tl,zt,al,ol,wt,ll,il,Ca,G,nl,yt,rl,pl,Pt,cl,ul,es,ml,dl,Ma,ss,Da,Is,fl,Na,Ie,hl,Tt,bl,_l,Fa,Ae,vl,qt,$l,gl,xa,B,R,As,Ss,kl,Oa,Y,J,Cs,x,jl,It,El,zl,At,wl,yl,St,Pl,Tl,Ct,ql,Il,La,ge,Se,Mt,ts,Al,Dt,Sl,Ga,W,X,Ms,Ds,Cl,Va,V,Ml,Nt,Dl,Nl,Ft,Fl,xl,xt,Ol,Ll,Ua,Ns,Gl,Ha,de,Vl,Ot,Ul,Hl,Fs,Ql,Bl,Qa,ke,Ce,Lt,as,Rl,Gt,Yl,Ba,xs,Jl,Ra,fe,Os,Vt,Wl,Xl,Kl,Ls,Ut,Zl,ei,si,Gs,Ht,ti,ai,Ya,Vs,oi,Ja,Us,li,Wa,K,Z,Hs,U,ii,Qt,ni,ri,Bt,pi,ci,Rt,ui,mi,Xa,je,Me,Yt,os,di,Jt,fi,Ka,Qs,hi,Za,Ee,ls,bn,bi,is,_n,eo,Bs,_i,so,Rs,vi,to,Ys,$i,ao,D,Js,Wt,gi,ki,ji,Xt,Kt,Ei,zi,Zt,ea,wi,yi,sa,ta,Pi,Ti,aa,oa,qi,Ii,la,ia,Ai,Si,na,ra,Ci,Mi,pa,Di,oo,ee,se,Ws,Xs,Ni,lo,ns,io,te,ae,Ks,Zs,Fi,no,ze,De,ca,rs,xi,ua,Oi,ro,et,Li,po,ps,co,oe,le,st,O,Gi,ma,Vi,Ui,da,Hi,Qi,fa,Bi,Ri,cs,Yi,Ji,uo,ie,ne,tt,re,pe,at,he,Wi,ha,Xi,Ki,ba,Zi,en,mo,Ne,sn,_a,tn,an,fo,us,ho,ms,bo,ot,on,_o,Fe,va,ln,nn,$a,rn,vo,lt,pn,$o,xe,go;o=new $p({props:{fw:j[0]}}),A=new _t({});const vn=[kp,gp],ds=[];function $n(e,l){return e[0]==="pt"?0:1}k=$n(j),M=ds[k]=vn[k](j),we=new up({props:{$$slots:{default:[jp]},$$scope:{ctx:j}}});const gn=[zp,Ep],fs=[];function kn(e,l){return e[0]==="pt"?0:1}H=kn(j),Q=fs[H]=gn[H](j),Re=new I({props:{code:`from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier(
    [
        "I've been waiting for a HuggingFace course my whole life.",
        "I hate this so much!",
    ]
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)
classifier(
    [
        <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>,
        <span class="hljs-string">&quot;I hate this so much!&quot;</span>,
    ]
)`}}),Ye=new I({props:{code:`[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]`,highlighted:`[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9598047137260437</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;NEGATIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9994558095932007</span>}]`}}),Xe=new _t({}),ss=new I({props:{code:`from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)`}});const jn=[yp,wp],hs=[];function En(e,l){return e[0]==="pt"?0:1}B=En(j),R=hs[B]=jn[B](j);const zn=[Tp,Pp],bs=[];function wn(e,l){return e[0]==="pt"?0:1}Y=wn(j),J=bs[Y]=zn[Y](j),ts=new _t({});const yn=[Ip,qp],_s=[];function Pn(e,l){return e[0]==="pt"?0:1}W=Pn(j),X=_s[W]=yn[W](j),as=new _t({});const Tn=[Sp,Ap],vs=[];function qn(e,l){return e[0]==="pt"?0:1}K=qn(j),Z=vs[K]=Tn[K](j),os=new _t({});const In=[Mp,Cp],$s=[];function An(e,l){return e[0]==="pt"?0:1}ee=An(j),se=$s[ee]=In[ee](j),ns=new I({props:{code:"print(outputs.logits.shape)",highlighted:'<span class="hljs-built_in">print</span>(outputs.logits.shape)'}});const Sn=[Np,Dp],gs=[];function Cn(e,l){return e[0]==="pt"?0:1}te=Cn(j),ae=gs[te]=Sn[te](j),rs=new _t({}),ps=new I({props:{code:"print(outputs.logits)",highlighted:'<span class="hljs-built_in">print</span>(outputs.logits)'}});const Mn=[xp,Fp],ks=[];function Dn(e,l){return e[0]==="pt"?0:1}oe=Dn(j),le=ks[oe]=Mn[oe](j);const Nn=[Lp,Op],js=[];function Fn(e,l){return e[0]==="pt"?0:1}ie=Fn(j),ne=js[ie]=Nn[ie](j);const xn=[Vp,Gp],Es=[];function On(e,l){return e[0]==="pt"?0:1}return re=On(j),pe=Es[re]=xn[re](j),us=new I({props:{code:"model.config.id2label",highlighted:"model.config.id2label"}}),ms=new I({props:{code:"{0: 'NEGATIVE', 1: 'POSITIVE'}",highlighted:'{<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;NEGATIVE&#x27;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>}'}}),xe=new up({props:{$$slots:{default:[Up]},$$scope:{ctx:j}}}),{c(){a=r("meta"),m=d(),z(o.$$.fragment),h=d(),_=r("h1"),b=r("a"),q=r("span"),z(A.$$.fragment),S=d(),T=r("span"),C=i("Dietro la pipeline"),v=d(),M.c(),N=d(),z(we.$$.fragment),ja=d(),Q.c(),ws=d(),ye=r("p"),Co=i("Cominciamo con un esempio completo, dando un\u2019occhiata a ci\xF2 che \xE8 successo dietro le quinte quando abbiamo eseguito il seguente codice nel "),ys=r("a"),Mo=i("Capitolo 1"),Do=i(":"),Ea=d(),z(Re.$$.fragment),za=d(),Ps=r("p"),No=i("e ottenuto:"),wa=d(),z(Ye.$$.fragment),ya=d(),Pe=r("p"),Fo=i("Come abbiamo visto nel "),Ts=r("a"),xo=i("Capitolo 1"),Oo=i(", questa pipeline raggruppa tre fasi: la pre-elaborazione, il passaggio degli input attraverso il modello e la post-elaborazione:"),Pa=d(),ve=r("div"),Je=r("img"),Lo=d(),We=r("img"),Ta=d(),qs=r("p"),Go=i("Esaminiamo rapidamente ciascuno di essi."),qa=d(),$e=r("h2"),Te=r("a"),vt=r("span"),z(Xe.$$.fragment),Vo=d(),$t=r("span"),Uo=i("Preelaborazione con un tokenizer"),Ia=d(),qe=r("p"),Ho=i("Come altre reti neurali, i modelli Transformer non possono elaborare direttamente il testo non elaborato, quindi la prima fase della nostra pipeline consiste nel convertire gli input testuali in numeri che il modello possa interpretare. Per fare ci\xF2, utilizziamo un "),gt=r("em"),Qo=i("tokenizer"),Bo=i(", che sar\xE0 responsabile di:"),Aa=d(),me=r("ul"),Ke=r("li"),Ro=i("Suddivisione dell\u2019input in parole, sottoparole o simboli (come la punteggiatura) che vengono chiamati "),kt=r("em"),Yo=i("token"),Jo=i("."),Wo=d(),jt=r("li"),Xo=i("Mappare ogni token in un numero intero"),Ko=d(),Et=r("li"),Zo=i("Aggiunta di ulteriori input che possono essere utili per il modello"),Sa=d(),L=r("p"),el=i("Tutta questa preelaborazione deve essere fatta esattamente nello stesso modo in cui \xE8 stato preaddestrato il modello, quindi dobbiamo prima scaricare queste informazioni dal "),Ze=r("a"),sl=i("Model Hub"),tl=i(". Per farlo, si usa la classe "),zt=r("code"),al=i("AutoTokenizer"),ol=i(" e il suo metodo "),wt=r("code"),ll=i("from_pretrained()"),il=i(". Utilizzando il nome del checkpoint del nostro modello, recuperer\xE0 automaticamente i dati associati al tokenizer del modello e li metter\xE0 in cache (in modo che vengano scaricati solo la prima volta che si esegue il codice sottostante)."),Ca=d(),G=r("p"),nl=i("Poich\xE9 il checkpoint predefinito della pipeline "),yt=r("code"),rl=i("sentiment-analysis"),pl=i(" \xE8 "),Pt=r("code"),cl=i("distilbert-base-uncased-finetuned-sst-2-english"),ul=i(" (si pu\xF2 vedere la sua scheda modello "),es=r("a"),ml=i("qui"),dl=i("), eseguiamo quanto segue:"),Ma=d(),z(ss.$$.fragment),Da=d(),Is=r("p"),fl=i("Una volta che abbiamo il tokenizer, possiamo passargli direttamente le nostre frasi e otterremo un dizionario pronto per il nostro modello! L\u2019unica cosa che resta da fare \xE8 convertire l\u2019elenco degli ID in ingresso in tensori."),Na=d(),Ie=r("p"),hl=i("\xC8 possibile utilizzare i \u{1F917} Transformer senza doversi preoccupare di quale framework ML venga utilizzato come backend;potrebbe essere PyTorch o TensorFlow, o Flax per alcuni modelli. Tuttavia, i modelli Transformer accettano solo "),Tt=r("em"),bl=i("tensors"),_l=i(" come input. Se \xE8 la prima volta che sentite parlare di tensori, potete pensare a loro come array NumPy. Un array NumPy pu\xF2 essere uno scalare (0D), un vettore (1D), una matrice (2D) o avere pi\xF9 dimensioni. Si tratta effettivamente di un tensore; i tensori di altri framework ML si comportano in modo simile e di solito sono semplici da istanziare come gli array NumPy."),Fa=d(),Ae=r("p"),vl=i("Per specificare il tipo di tensori che vogliamo ottenere (PyTorch, TensorFlow o NumPy), usiamo l\u2019argomento "),qt=r("code"),$l=i("return_tensors"),gl=i(":"),xa=d(),R.c(),As=d(),Ss=r("p"),kl=i("Non preoccupatevi ancora di padding e truncation; li spiegheremo pi\xF9 avanti.Le cose principali da ricordare sono che si pu\xF2 passare una frase o un elenco di frasi, oltre a specificare il tipo di tensori che si desidera ottenere (se non viene passato alcun tipo, si otterr\xE0 una lista di liste come risultato)."),Oa=d(),J.c(),Cs=d(),x=r("p"),jl=i("L\u2019output stesso \xE8 un dizionario contenente due chiavi, "),It=r("code"),El=i("input_ids"),zl=i(" e "),At=r("code"),wl=i("attention_mask"),yl=i(". "),St=r("code"),Pl=i("input_ids"),Tl=i(" contiene due righe di interi (uno per ogni frase) che sono gli identificatori unici dei token in ogni frase. Spiegheremo cosa sia la "),Ct=r("code"),ql=i("attention_mask"),Il=i(" pi\xF9 avanti in questo capitolo."),La=d(),ge=r("h2"),Se=r("a"),Mt=r("span"),z(ts.$$.fragment),Al=d(),Dt=r("span"),Sl=i("Passare attraverso il modello"),Ga=d(),X.c(),Ms=d(),Ds=r("p"),Cl=i("In questo frammento di codice, abbiamo scaricato lo stesso checkpoint usato in precedenza nella nostra pipeline (in realt\xE0 dovrebbe essere gi\xE0 nella cache) e abbiamo istanziato un modello con esso."),Va=d(),V=r("p"),Ml=i("Questa architettura contiene solo il modulo Transformer di base: dati alcuni input, produce quelli che chiameremo "),Nt=r("em"),Dl=i("hidden states"),Nl=i(", noti anche come "),Ft=r("em"),Fl=i("features"),xl=i(". Per ogni input del modello, recupereremo un vettore ad alta dimensionalit\xE0 che rappresenta la "),xt=r("strong"),Ol=i("comprensione contestuale di quell\u2019input da parte del modello Transformer"),Ll=i("."),Ua=d(),Ns=r("p"),Gl=i("Se per te tutto questo non ha senso, non preoccuparti. Ti spiegheremo tutto pi\xF9 avanti."),Ha=d(),de=r("p"),Vl=i("Anche se questi stati nascosti possono essere utili da soli, di solito sono input di un\u2019altra parte del modello, nota come "),Ot=r("em"),Ul=i("head"),Hl=i(". Nel "),Fs=r("a"),Ql=i("Capitolo 1"),Bl=i(", i diversi compiti potrebbero essere eseguiti con la stessa architettura, ma a ciascuno di essi sar\xE0 associata una head diversa."),Qa=d(),ke=r("h3"),Ce=r("a"),Lt=r("span"),z(as.$$.fragment),Rl=d(),Gt=r("span"),Yl=i("Un vettore ad alta dimensionalit\xE0?"),Ba=d(),xs=r("p"),Jl=i("Il vettore emesso dal modulo Transformer \xE8 solitamente di grandi dimensioni. In genere ha tre dimensioni:"),Ra=d(),fe=r("ul"),Os=r("li"),Vt=r("strong"),Wl=i("Dimensione del batch"),Xl=i(": Il numero di sequenze elaborate alla volta (2 nel nostro esempio)."),Kl=d(),Ls=r("li"),Ut=r("strong"),Zl=i("Lunghezza della sequenza"),ei=i(": La lunghezza della rappresentazione numerica della sequenza (16 nel nostro esempio)."),si=d(),Gs=r("li"),Ht=r("strong"),ti=i("Dimensione nascosta"),ai=i(": La dimensione del vettore di ciascun ingresso del modello."),Ya=d(),Vs=r("p"),oi=i("Si dice che \xE8 \u201Cad alta dimensionalit\xE0\u201D a causa dell\u2019ultimo valore. La dimensione nascosta pu\xF2 essere molto grande (768 \xE8 comune per i modelli pi\xF9 piccoli, mentre nei modelli pi\xF9 grandi pu\xF2 arrivare a 3072 o pi\xF9)."),Ja=d(),Us=r("p"),li=i("Lo possiamo vedere se alimentiamo il nostro modello con gli input che abbiamo preelaborato:"),Wa=d(),Z.c(),Hs=d(),U=r("p"),ii=i("Si noti che gli output dei modelli \u{1F917} Transformers si comportano come "),Qt=r("code"),ni=i("namedtuple"),ri=i(" o dizionari. Si pu\xF2 accedere agli elementi per attributi (come abbiamo fatto noi) sia per chiave ("),Bt=r("code"),pi=i('outputs["last_hidden_state"]'),ci=i("), sia per indice se si sa esattamente dove si trova ci\xF2 che si sta cercando ("),Rt=r("code"),ui=i("outputs[0]"),mi=i(")."),Xa=d(),je=r("h3"),Me=r("a"),Yt=r("span"),z(os.$$.fragment),di=d(),Jt=r("span"),fi=i("Model heads: Dare un senso ai numeri"),Ka=d(),Qs=r("p"),hi=i("Le model head prendono in input il vettore ad alta dimensione degli stati nascosti e lo proiettano su una dimensione diversa. Di solito sono composte da uno o pochi strati lineari:"),Za=d(),Ee=r("div"),ls=r("img"),bi=d(),is=r("img"),eo=d(),Bs=r("p"),_i=i("Gli output del modello Transformer vengono inviati direttamente alla model head per essere elaborati."),so=d(),Rs=r("p"),vi=i("In questo diagramma, il modello \xE8 rappresentato dallo strato embeddings e dagli strati successivi. Il livello embeddings converte ogni ID dell\u2019input tokenizzato in un vettore che rappresenta il token associato. I livelli successivi manipolano questi vettori utilizzando il meccanismo di attenzione per produrre la rappresentazione finale delle frasi."),to=d(),Ys=r("p"),$i=i("Esistono diverse architetture disponibili nei \u{1F917} Transformers, ognuna delle quali \xE8 stata progettata per affrontare un compito specifico. Ecco un elenco non esaustivo:"),ao=d(),D=r("ul"),Js=r("li"),Wt=r("code"),gi=i("*Model"),ki=i(" (retrieve the hidden states)"),ji=d(),Xt=r("li"),Kt=r("code"),Ei=i("*ForCausalLM"),zi=d(),Zt=r("li"),ea=r("code"),wi=i("*ForMaskedLM"),yi=d(),sa=r("li"),ta=r("code"),Pi=i("*ForMultipleChoice"),Ti=d(),aa=r("li"),oa=r("code"),qi=i("*ForQuestionAnswering"),Ii=d(),la=r("li"),ia=r("code"),Ai=i("*ForSequenceClassification"),Si=d(),na=r("li"),ra=r("code"),Ci=i("*ForTokenClassification"),Mi=d(),pa=r("li"),Di=i("e altre \u{1F917}"),oo=d(),se.c(),Ws=d(),Xs=r("p"),Ni=i("Ora, se osserviamo la forma dei nostri input, la dimensionalit\xE0 sar\xE0 molto pi\xF9 bassa: la model head prende in input i vettori ad alta dimensionalit\xE0 che abbiamo visto prima e produce vettori contenenti due valori (uno per etichetta):"),lo=d(),z(ns.$$.fragment),io=d(),ae.c(),Ks=d(),Zs=r("p"),Fi=i("Dato che abbiamo solo due frasi e due etichette, il risultato che otteniamo dal nostro modello \xE8 di forma 2 x 2."),no=d(),ze=r("h2"),De=r("a"),ca=r("span"),z(rs.$$.fragment),xi=d(),ua=r("span"),Oi=i("Postprocessing the output"),ro=d(),et=r("p"),Li=i("I valori che otteniamo come output dal nostro modello non hanno necessariamente senso da soli. Diamo un\u2019occhiata:"),po=d(),z(ps.$$.fragment),co=d(),le.c(),st=d(),O=r("p"),Gi=i("Il nostro modello ha previsto "),ma=r("code"),Vi=i("[-1.5607, 1.6123]"),Ui=i(" per la prima frase e "),da=r("code"),Hi=i("[ 4.1692, -3.3464]"),Qi=i(" per la seconda. Non si tratta di probabilit\xE0 ma di "),fa=r("em"),Bi=i("logit"),Ri=i(", i punteggi non normalizzati emessi dall\u2019ultimo livello del modello. Per poterli convertire in probabilit\xE0, devono passare attraverso un layer "),cs=r("a"),Yi=i("SoftMax"),Ji=i(" (tutti i modelli \u{1F917} Transformers producono i logits, poich\xE9 la funzione di perdita per l\u2019addestramento generalmente fonde l\u2019ultima funzione di attivazione, come SoftMax, con la funzione di perdita effettiva, come la cross entropy):"),uo=d(),ne.c(),tt=d(),pe.c(),at=d(),he=r("p"),Wi=i("Ora possiamo vedere che il modello ha previsto "),ha=r("code"),Xi=i("[0,0402, 0,9598]"),Ki=i(" per la prima frase e "),ba=r("code"),Zi=i("[0,9995, 0,0005]"),en=i(" per la seconda. Si tratta di punteggi di probabilit\xE0 riconoscibili."),mo=d(),Ne=r("p"),sn=i("Per ottenere le etichette corrispondenti a ogni posizione, si pu\xF2 ispezionare l\u2019attributo "),_a=r("code"),tn=i("id2label"),an=i(" della configurazione del modello (si veda la prossima sezione):"),fo=d(),z(us.$$.fragment),ho=d(),z(ms.$$.fragment),bo=d(),ot=r("p"),on=i("Ora possiamo concludere che il modello ha previsto quanto segue:"),_o=d(),Fe=r("ul"),va=r("li"),ln=i("Prima frase: NEGATIVE: 0.0402, POSITIVE: 0.9598"),nn=d(),$a=r("li"),rn=i("Seconda frase: NEGATIVE: 0.9995, POSITIVE: 0.0005"),vo=d(),lt=r("p"),pn=i("Abbiamo riprodotto con successo le tre fasi della pipeline: preelaborazione con i tokenizer, passaggio degli input attraverso il modello e postelaborazione! Ora prendiamoci un po\u2019 di tempo per approfondire ognuna di queste fasi."),$o=d(),z(xe.$$.fragment),this.h()},l(e){const l=_p('[data-svelte="svelte-1phssyn"]',document.head);a=p(l,"META",{name:!0,content:!0}),l.forEach(s),m=f(e),w(o.$$.fragment,e),h=f(e),_=p(e,"H1",{class:!0});var zs=c(_);b=p(zs,"A",{id:!0,class:!0,href:!0});var it=c(b);q=p(it,"SPAN",{});var ga=c(q);w(A.$$.fragment,ga),ga.forEach(s),it.forEach(s),S=f(zs),T=p(zs,"SPAN",{});var nt=c(T);C=n(nt,"Dietro la pipeline"),nt.forEach(s),zs.forEach(s),v=f(e),M.l(e),N=f(e),w(we.$$.fragment,e),ja=f(e),Q.l(e),ws=f(e),ye=p(e,"P",{});var Oe=c(ye);Co=n(Oe,"Cominciamo con un esempio completo, dando un\u2019occhiata a ci\xF2 che \xE8 successo dietro le quinte quando abbiamo eseguito il seguente codice nel "),ys=p(Oe,"A",{href:!0});var rt=c(ys);Mo=n(rt,"Capitolo 1"),rt.forEach(s),Do=n(Oe,":"),Oe.forEach(s),Ea=f(e),w(Re.$$.fragment,e),za=f(e),Ps=p(e,"P",{});var pt=c(Ps);No=n(pt,"e ottenuto:"),pt.forEach(s),wa=f(e),w(Ye.$$.fragment,e),ya=f(e),Pe=p(e,"P",{});var Le=c(Pe);Fo=n(Le,"Come abbiamo visto nel "),Ts=p(Le,"A",{href:!0});var ct=c(Ts);xo=n(ct,"Capitolo 1"),ct.forEach(s),Oo=n(Le,", questa pipeline raggruppa tre fasi: la pre-elaborazione, il passaggio degli input attraverso il modello e la post-elaborazione:"),Le.forEach(s),Pa=f(e),ve=p(e,"DIV",{class:!0});var Ge=c(ve);Je=p(Ge,"IMG",{class:!0,src:!0,alt:!0}),Lo=f(Ge),We=p(Ge,"IMG",{class:!0,src:!0,alt:!0}),Ge.forEach(s),Ta=f(e),qs=p(e,"P",{});var ut=c(qs);Go=n(ut,"Esaminiamo rapidamente ciascuno di essi."),ut.forEach(s),qa=f(e),$e=p(e,"H2",{class:!0});var Ve=c($e);Te=p(Ve,"A",{id:!0,class:!0,href:!0});var mt=c(Te);vt=p(mt,"SPAN",{});var ka=c(vt);w(Xe.$$.fragment,ka),ka.forEach(s),mt.forEach(s),Vo=f(Ve),$t=p(Ve,"SPAN",{});var Ln=c($t);Uo=n(Ln,"Preelaborazione con un tokenizer"),Ln.forEach(s),Ve.forEach(s),Ia=f(e),qe=p(e,"P",{});var ko=c(qe);Ho=n(ko,"Come altre reti neurali, i modelli Transformer non possono elaborare direttamente il testo non elaborato, quindi la prima fase della nostra pipeline consiste nel convertire gli input testuali in numeri che il modello possa interpretare. Per fare ci\xF2, utilizziamo un "),gt=p(ko,"EM",{});var Gn=c(gt);Qo=n(Gn,"tokenizer"),Gn.forEach(s),Bo=n(ko,", che sar\xE0 responsabile di:"),ko.forEach(s),Aa=f(e),me=p(e,"UL",{});var dt=c(me);Ke=p(dt,"LI",{});var jo=c(Ke);Ro=n(jo,"Suddivisione dell\u2019input in parole, sottoparole o simboli (come la punteggiatura) che vengono chiamati "),kt=p(jo,"EM",{});var Vn=c(kt);Yo=n(Vn,"token"),Vn.forEach(s),Jo=n(jo,"."),jo.forEach(s),Wo=f(dt),jt=p(dt,"LI",{});var Un=c(jt);Xo=n(Un,"Mappare ogni token in un numero intero"),Un.forEach(s),Ko=f(dt),Et=p(dt,"LI",{});var Hn=c(Et);Zo=n(Hn,"Aggiunta di ulteriori input che possono essere utili per il modello"),Hn.forEach(s),dt.forEach(s),Sa=f(e),L=p(e,"P",{});var Ue=c(L);el=n(Ue,"Tutta questa preelaborazione deve essere fatta esattamente nello stesso modo in cui \xE8 stato preaddestrato il modello, quindi dobbiamo prima scaricare queste informazioni dal "),Ze=p(Ue,"A",{href:!0,rel:!0});var Qn=c(Ze);sl=n(Qn,"Model Hub"),Qn.forEach(s),tl=n(Ue,". Per farlo, si usa la classe "),zt=p(Ue,"CODE",{});var Bn=c(zt);al=n(Bn,"AutoTokenizer"),Bn.forEach(s),ol=n(Ue," e il suo metodo "),wt=p(Ue,"CODE",{});var Rn=c(wt);ll=n(Rn,"from_pretrained()"),Rn.forEach(s),il=n(Ue,". Utilizzando il nome del checkpoint del nostro modello, recuperer\xE0 automaticamente i dati associati al tokenizer del modello e li metter\xE0 in cache (in modo che vengano scaricati solo la prima volta che si esegue il codice sottostante)."),Ue.forEach(s),Ca=f(e),G=p(e,"P",{});var He=c(G);nl=n(He,"Poich\xE9 il checkpoint predefinito della pipeline "),yt=p(He,"CODE",{});var Yn=c(yt);rl=n(Yn,"sentiment-analysis"),Yn.forEach(s),pl=n(He," \xE8 "),Pt=p(He,"CODE",{});var Jn=c(Pt);cl=n(Jn,"distilbert-base-uncased-finetuned-sst-2-english"),Jn.forEach(s),ul=n(He," (si pu\xF2 vedere la sua scheda modello "),es=p(He,"A",{href:!0,rel:!0});var Wn=c(es);ml=n(Wn,"qui"),Wn.forEach(s),dl=n(He,"), eseguiamo quanto segue:"),He.forEach(s),Ma=f(e),w(ss.$$.fragment,e),Da=f(e),Is=p(e,"P",{});var Xn=c(Is);fl=n(Xn,"Una volta che abbiamo il tokenizer, possiamo passargli direttamente le nostre frasi e otterremo un dizionario pronto per il nostro modello! L\u2019unica cosa che resta da fare \xE8 convertire l\u2019elenco degli ID in ingresso in tensori."),Xn.forEach(s),Na=f(e),Ie=p(e,"P",{});var Eo=c(Ie);hl=n(Eo,"\xC8 possibile utilizzare i \u{1F917} Transformer senza doversi preoccupare di quale framework ML venga utilizzato come backend;potrebbe essere PyTorch o TensorFlow, o Flax per alcuni modelli. Tuttavia, i modelli Transformer accettano solo "),Tt=p(Eo,"EM",{});var Kn=c(Tt);bl=n(Kn,"tensors"),Kn.forEach(s),_l=n(Eo," come input. Se \xE8 la prima volta che sentite parlare di tensori, potete pensare a loro come array NumPy. Un array NumPy pu\xF2 essere uno scalare (0D), un vettore (1D), una matrice (2D) o avere pi\xF9 dimensioni. Si tratta effettivamente di un tensore; i tensori di altri framework ML si comportano in modo simile e di solito sono semplici da istanziare come gli array NumPy."),Eo.forEach(s),Fa=f(e),Ae=p(e,"P",{});var zo=c(Ae);vl=n(zo,"Per specificare il tipo di tensori che vogliamo ottenere (PyTorch, TensorFlow o NumPy), usiamo l\u2019argomento "),qt=p(zo,"CODE",{});var Zn=c(qt);$l=n(Zn,"return_tensors"),Zn.forEach(s),gl=n(zo,":"),zo.forEach(s),xa=f(e),R.l(e),As=f(e),Ss=p(e,"P",{});var er=c(Ss);kl=n(er,"Non preoccupatevi ancora di padding e truncation; li spiegheremo pi\xF9 avanti.Le cose principali da ricordare sono che si pu\xF2 passare una frase o un elenco di frasi, oltre a specificare il tipo di tensori che si desidera ottenere (se non viene passato alcun tipo, si otterr\xE0 una lista di liste come risultato)."),er.forEach(s),Oa=f(e),J.l(e),Cs=f(e),x=p(e,"P",{});var be=c(x);jl=n(be,"L\u2019output stesso \xE8 un dizionario contenente due chiavi, "),It=p(be,"CODE",{});var sr=c(It);El=n(sr,"input_ids"),sr.forEach(s),zl=n(be," e "),At=p(be,"CODE",{});var tr=c(At);wl=n(tr,"attention_mask"),tr.forEach(s),yl=n(be,". "),St=p(be,"CODE",{});var ar=c(St);Pl=n(ar,"input_ids"),ar.forEach(s),Tl=n(be," contiene due righe di interi (uno per ogni frase) che sono gli identificatori unici dei token in ogni frase. Spiegheremo cosa sia la "),Ct=p(be,"CODE",{});var or=c(Ct);ql=n(or,"attention_mask"),or.forEach(s),Il=n(be," pi\xF9 avanti in questo capitolo."),be.forEach(s),La=f(e),ge=p(e,"H2",{class:!0});var wo=c(ge);Se=p(wo,"A",{id:!0,class:!0,href:!0});var lr=c(Se);Mt=p(lr,"SPAN",{});var ir=c(Mt);w(ts.$$.fragment,ir),ir.forEach(s),lr.forEach(s),Al=f(wo),Dt=p(wo,"SPAN",{});var nr=c(Dt);Sl=n(nr,"Passare attraverso il modello"),nr.forEach(s),wo.forEach(s),Ga=f(e),X.l(e),Ms=f(e),Ds=p(e,"P",{});var rr=c(Ds);Cl=n(rr,"In questo frammento di codice, abbiamo scaricato lo stesso checkpoint usato in precedenza nella nostra pipeline (in realt\xE0 dovrebbe essere gi\xE0 nella cache) e abbiamo istanziato un modello con esso."),rr.forEach(s),Va=f(e),V=p(e,"P",{});var Qe=c(V);Ml=n(Qe,"Questa architettura contiene solo il modulo Transformer di base: dati alcuni input, produce quelli che chiameremo "),Nt=p(Qe,"EM",{});var pr=c(Nt);Dl=n(pr,"hidden states"),pr.forEach(s),Nl=n(Qe,", noti anche come "),Ft=p(Qe,"EM",{});var cr=c(Ft);Fl=n(cr,"features"),cr.forEach(s),xl=n(Qe,". Per ogni input del modello, recupereremo un vettore ad alta dimensionalit\xE0 che rappresenta la "),xt=p(Qe,"STRONG",{});var ur=c(xt);Ol=n(ur,"comprensione contestuale di quell\u2019input da parte del modello Transformer"),ur.forEach(s),Ll=n(Qe,"."),Qe.forEach(s),Ua=f(e),Ns=p(e,"P",{});var mr=c(Ns);Gl=n(mr,"Se per te tutto questo non ha senso, non preoccuparti. Ti spiegheremo tutto pi\xF9 avanti."),mr.forEach(s),Ha=f(e),de=p(e,"P",{});var ft=c(de);Vl=n(ft,"Anche se questi stati nascosti possono essere utili da soli, di solito sono input di un\u2019altra parte del modello, nota come "),Ot=p(ft,"EM",{});var dr=c(Ot);Ul=n(dr,"head"),dr.forEach(s),Hl=n(ft,". Nel "),Fs=p(ft,"A",{href:!0});var fr=c(Fs);Ql=n(fr,"Capitolo 1"),fr.forEach(s),Bl=n(ft,", i diversi compiti potrebbero essere eseguiti con la stessa architettura, ma a ciascuno di essi sar\xE0 associata una head diversa."),ft.forEach(s),Qa=f(e),ke=p(e,"H3",{class:!0});var yo=c(ke);Ce=p(yo,"A",{id:!0,class:!0,href:!0});var hr=c(Ce);Lt=p(hr,"SPAN",{});var br=c(Lt);w(as.$$.fragment,br),br.forEach(s),hr.forEach(s),Rl=f(yo),Gt=p(yo,"SPAN",{});var _r=c(Gt);Yl=n(_r,"Un vettore ad alta dimensionalit\xE0?"),_r.forEach(s),yo.forEach(s),Ba=f(e),xs=p(e,"P",{});var vr=c(xs);Jl=n(vr,"Il vettore emesso dal modulo Transformer \xE8 solitamente di grandi dimensioni. In genere ha tre dimensioni:"),vr.forEach(s),Ra=f(e),fe=p(e,"UL",{});var ht=c(fe);Os=p(ht,"LI",{});var cn=c(Os);Vt=p(cn,"STRONG",{});var $r=c(Vt);Wl=n($r,"Dimensione del batch"),$r.forEach(s),Xl=n(cn,": Il numero di sequenze elaborate alla volta (2 nel nostro esempio)."),cn.forEach(s),Kl=f(ht),Ls=p(ht,"LI",{});var un=c(Ls);Ut=p(un,"STRONG",{});var gr=c(Ut);Zl=n(gr,"Lunghezza della sequenza"),gr.forEach(s),ei=n(un,": La lunghezza della rappresentazione numerica della sequenza (16 nel nostro esempio)."),un.forEach(s),si=f(ht),Gs=p(ht,"LI",{});var mn=c(Gs);Ht=p(mn,"STRONG",{});var kr=c(Ht);ti=n(kr,"Dimensione nascosta"),kr.forEach(s),ai=n(mn,": La dimensione del vettore di ciascun ingresso del modello."),mn.forEach(s),ht.forEach(s),Ya=f(e),Vs=p(e,"P",{});var jr=c(Vs);oi=n(jr,"Si dice che \xE8 \u201Cad alta dimensionalit\xE0\u201D a causa dell\u2019ultimo valore. La dimensione nascosta pu\xF2 essere molto grande (768 \xE8 comune per i modelli pi\xF9 piccoli, mentre nei modelli pi\xF9 grandi pu\xF2 arrivare a 3072 o pi\xF9)."),jr.forEach(s),Ja=f(e),Us=p(e,"P",{});var Er=c(Us);li=n(Er,"Lo possiamo vedere se alimentiamo il nostro modello con gli input che abbiamo preelaborato:"),Er.forEach(s),Wa=f(e),Z.l(e),Hs=f(e),U=p(e,"P",{});var Be=c(U);ii=n(Be,"Si noti che gli output dei modelli \u{1F917} Transformers si comportano come "),Qt=p(Be,"CODE",{});var zr=c(Qt);ni=n(zr,"namedtuple"),zr.forEach(s),ri=n(Be," o dizionari. Si pu\xF2 accedere agli elementi per attributi (come abbiamo fatto noi) sia per chiave ("),Bt=p(Be,"CODE",{});var wr=c(Bt);pi=n(wr,'outputs["last_hidden_state"]'),wr.forEach(s),ci=n(Be,"), sia per indice se si sa esattamente dove si trova ci\xF2 che si sta cercando ("),Rt=p(Be,"CODE",{});var yr=c(Rt);ui=n(yr,"outputs[0]"),yr.forEach(s),mi=n(Be,")."),Be.forEach(s),Xa=f(e),je=p(e,"H3",{class:!0});var Po=c(je);Me=p(Po,"A",{id:!0,class:!0,href:!0});var Pr=c(Me);Yt=p(Pr,"SPAN",{});var Tr=c(Yt);w(os.$$.fragment,Tr),Tr.forEach(s),Pr.forEach(s),di=f(Po),Jt=p(Po,"SPAN",{});var qr=c(Jt);fi=n(qr,"Model heads: Dare un senso ai numeri"),qr.forEach(s),Po.forEach(s),Ka=f(e),Qs=p(e,"P",{});var Ir=c(Qs);hi=n(Ir,"Le model head prendono in input il vettore ad alta dimensione degli stati nascosti e lo proiettano su una dimensione diversa. Di solito sono composte da uno o pochi strati lineari:"),Ir.forEach(s),Za=f(e),Ee=p(e,"DIV",{class:!0});var To=c(Ee);ls=p(To,"IMG",{class:!0,src:!0,alt:!0}),bi=f(To),is=p(To,"IMG",{class:!0,src:!0,alt:!0}),To.forEach(s),eo=f(e),Bs=p(e,"P",{});var Ar=c(Bs);_i=n(Ar,"Gli output del modello Transformer vengono inviati direttamente alla model head per essere elaborati."),Ar.forEach(s),so=f(e),Rs=p(e,"P",{});var Sr=c(Rs);vi=n(Sr,"In questo diagramma, il modello \xE8 rappresentato dallo strato embeddings e dagli strati successivi. Il livello embeddings converte ogni ID dell\u2019input tokenizzato in un vettore che rappresenta il token associato. I livelli successivi manipolano questi vettori utilizzando il meccanismo di attenzione per produrre la rappresentazione finale delle frasi."),Sr.forEach(s),to=f(e),Ys=p(e,"P",{});var Cr=c(Ys);$i=n(Cr,"Esistono diverse architetture disponibili nei \u{1F917} Transformers, ognuna delle quali \xE8 stata progettata per affrontare un compito specifico. Ecco un elenco non esaustivo:"),Cr.forEach(s),ao=f(e),D=p(e,"UL",{});var F=c(D);Js=p(F,"LI",{});var dn=c(Js);Wt=p(dn,"CODE",{});var Mr=c(Wt);gi=n(Mr,"*Model"),Mr.forEach(s),ki=n(dn," (retrieve the hidden states)"),dn.forEach(s),ji=f(F),Xt=p(F,"LI",{});var Dr=c(Xt);Kt=p(Dr,"CODE",{});var Nr=c(Kt);Ei=n(Nr,"*ForCausalLM"),Nr.forEach(s),Dr.forEach(s),zi=f(F),Zt=p(F,"LI",{});var Fr=c(Zt);ea=p(Fr,"CODE",{});var xr=c(ea);wi=n(xr,"*ForMaskedLM"),xr.forEach(s),Fr.forEach(s),yi=f(F),sa=p(F,"LI",{});var Or=c(sa);ta=p(Or,"CODE",{});var Lr=c(ta);Pi=n(Lr,"*ForMultipleChoice"),Lr.forEach(s),Or.forEach(s),Ti=f(F),aa=p(F,"LI",{});var Gr=c(aa);oa=p(Gr,"CODE",{});var Vr=c(oa);qi=n(Vr,"*ForQuestionAnswering"),Vr.forEach(s),Gr.forEach(s),Ii=f(F),la=p(F,"LI",{});var Ur=c(la);ia=p(Ur,"CODE",{});var Hr=c(ia);Ai=n(Hr,"*ForSequenceClassification"),Hr.forEach(s),Ur.forEach(s),Si=f(F),na=p(F,"LI",{});var Qr=c(na);ra=p(Qr,"CODE",{});var Br=c(ra);Ci=n(Br,"*ForTokenClassification"),Br.forEach(s),Qr.forEach(s),Mi=f(F),pa=p(F,"LI",{});var Rr=c(pa);Di=n(Rr,"e altre \u{1F917}"),Rr.forEach(s),F.forEach(s),oo=f(e),se.l(e),Ws=f(e),Xs=p(e,"P",{});var Yr=c(Xs);Ni=n(Yr,"Ora, se osserviamo la forma dei nostri input, la dimensionalit\xE0 sar\xE0 molto pi\xF9 bassa: la model head prende in input i vettori ad alta dimensionalit\xE0 che abbiamo visto prima e produce vettori contenenti due valori (uno per etichetta):"),Yr.forEach(s),lo=f(e),w(ns.$$.fragment,e),io=f(e),ae.l(e),Ks=f(e),Zs=p(e,"P",{});var Jr=c(Zs);Fi=n(Jr,"Dato che abbiamo solo due frasi e due etichette, il risultato che otteniamo dal nostro modello \xE8 di forma 2 x 2."),Jr.forEach(s),no=f(e),ze=p(e,"H2",{class:!0});var qo=c(ze);De=p(qo,"A",{id:!0,class:!0,href:!0});var Wr=c(De);ca=p(Wr,"SPAN",{});var Xr=c(ca);w(rs.$$.fragment,Xr),Xr.forEach(s),Wr.forEach(s),xi=f(qo),ua=p(qo,"SPAN",{});var Kr=c(ua);Oi=n(Kr,"Postprocessing the output"),Kr.forEach(s),qo.forEach(s),ro=f(e),et=p(e,"P",{});var Zr=c(et);Li=n(Zr,"I valori che otteniamo come output dal nostro modello non hanno necessariamente senso da soli. Diamo un\u2019occhiata:"),Zr.forEach(s),po=f(e),w(ps.$$.fragment,e),co=f(e),le.l(e),st=f(e),O=p(e,"P",{});var _e=c(O);Gi=n(_e,"Il nostro modello ha previsto "),ma=p(_e,"CODE",{});var ep=c(ma);Vi=n(ep,"[-1.5607, 1.6123]"),ep.forEach(s),Ui=n(_e," per la prima frase e "),da=p(_e,"CODE",{});var sp=c(da);Hi=n(sp,"[ 4.1692, -3.3464]"),sp.forEach(s),Qi=n(_e," per la seconda. Non si tratta di probabilit\xE0 ma di "),fa=p(_e,"EM",{});var tp=c(fa);Bi=n(tp,"logit"),tp.forEach(s),Ri=n(_e,", i punteggi non normalizzati emessi dall\u2019ultimo livello del modello. Per poterli convertire in probabilit\xE0, devono passare attraverso un layer "),cs=p(_e,"A",{href:!0,rel:!0});var ap=c(cs);Yi=n(ap,"SoftMax"),ap.forEach(s),Ji=n(_e," (tutti i modelli \u{1F917} Transformers producono i logits, poich\xE9 la funzione di perdita per l\u2019addestramento generalmente fonde l\u2019ultima funzione di attivazione, come SoftMax, con la funzione di perdita effettiva, come la cross entropy):"),_e.forEach(s),uo=f(e),ne.l(e),tt=f(e),pe.l(e),at=f(e),he=p(e,"P",{});var bt=c(he);Wi=n(bt,"Ora possiamo vedere che il modello ha previsto "),ha=p(bt,"CODE",{});var op=c(ha);Xi=n(op,"[0,0402, 0,9598]"),op.forEach(s),Ki=n(bt," per la prima frase e "),ba=p(bt,"CODE",{});var lp=c(ba);Zi=n(lp,"[0,9995, 0,0005]"),lp.forEach(s),en=n(bt," per la seconda. Si tratta di punteggi di probabilit\xE0 riconoscibili."),bt.forEach(s),mo=f(e),Ne=p(e,"P",{});var Io=c(Ne);sn=n(Io,"Per ottenere le etichette corrispondenti a ogni posizione, si pu\xF2 ispezionare l\u2019attributo "),_a=p(Io,"CODE",{});var ip=c(_a);tn=n(ip,"id2label"),ip.forEach(s),an=n(Io," della configurazione del modello (si veda la prossima sezione):"),Io.forEach(s),fo=f(e),w(us.$$.fragment,e),ho=f(e),w(ms.$$.fragment,e),bo=f(e),ot=p(e,"P",{});var np=c(ot);on=n(np,"Ora possiamo concludere che il modello ha previsto quanto segue:"),np.forEach(s),_o=f(e),Fe=p(e,"UL",{});var Ao=c(Fe);va=p(Ao,"LI",{});var rp=c(va);ln=n(rp,"Prima frase: NEGATIVE: 0.0402, POSITIVE: 0.9598"),rp.forEach(s),nn=f(Ao),$a=p(Ao,"LI",{});var pp=c($a);rn=n(pp,"Seconda frase: NEGATIVE: 0.9995, POSITIVE: 0.0005"),pp.forEach(s),Ao.forEach(s),vo=f(e),lt=p(e,"P",{});var cp=c(lt);pn=n(cp,"Abbiamo riprodotto con successo le tre fasi della pipeline: preelaborazione con i tokenizer, passaggio degli input attraverso il modello e postelaborazione! Ora prendiamoci un po\u2019 di tempo per approfondire ognuna di queste fasi."),cp.forEach(s),$o=f(e),w(xe.$$.fragment,e),this.h()},h(){E(a,"name","hf:doc:metadata"),E(a,"content",JSON.stringify(Qp)),E(b,"id","dietro-la-pipeline"),E(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),E(b,"href","#dietro-la-pipeline"),E(_,"class","relative group"),E(ys,"href","/course/chapter1"),E(Ts,"href","/course/chapter1"),E(Je,"class","block dark:hidden"),So(Je.src,fn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg")||E(Je,"src",fn),E(Je,"alt","La pipeline NLP completa: tokenizzazione del testo, conversione in ID e inferenza attraverso il modello Transformer ed il modello head."),E(We,"class","hidden dark:block"),So(We.src,hn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg")||E(We,"src",hn),E(We,"alt","La pipeline NLP completa: tokenizzazione del testo, conversione in ID e inferenza attraverso il modello Transformer ed il modello head.."),E(ve,"class","flex justify-center"),E(Te,"id","preelaborazione-con-un-tokenizer"),E(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),E(Te,"href","#preelaborazione-con-un-tokenizer"),E($e,"class","relative group"),E(Ze,"href","https://huggingface.co/models"),E(Ze,"rel","nofollow"),E(es,"href","https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),E(es,"rel","nofollow"),E(Se,"id","passare-attraverso-il-modello"),E(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),E(Se,"href","#passare-attraverso-il-modello"),E(ge,"class","relative group"),E(Fs,"href","/course/chapter1"),E(Ce,"id","un-vettore-ad-alta-dimensionalit"),E(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),E(Ce,"href","#un-vettore-ad-alta-dimensionalit"),E(ke,"class","relative group"),E(Me,"id","model-heads-dare-un-senso-ai-numeri"),E(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),E(Me,"href","#model-heads-dare-un-senso-ai-numeri"),E(je,"class","relative group"),E(ls,"class","block dark:hidden"),So(ls.src,bn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg")||E(ls,"src",bn),E(ls,"alt","Una rete di Transformer accanto alla sua head."),E(is,"class","hidden dark:block"),So(is.src,_n="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg")||E(is,"src",_n),E(is,"alt","Una rete di Transformer accanto alla sua head."),E(Ee,"class","flex justify-center"),E(De,"id","postprocessing-the-output"),E(De,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),E(De,"href","#postprocessing-the-output"),E(ze,"class","relative group"),E(cs,"href","https://en.wikipedia.org/wiki/Softmax_function"),E(cs,"rel","nofollow")},m(e,l){t(document.head,a),u(e,m,l),y(o,e,l),u(e,h,l),u(e,_,l),t(_,b),t(b,q),y(A,q,null),t(_,S),t(_,T),t(T,C),u(e,v,l),ds[k].m(e,l),u(e,N,l),y(we,e,l),u(e,ja,l),fs[H].m(e,l),u(e,ws,l),u(e,ye,l),t(ye,Co),t(ye,ys),t(ys,Mo),t(ye,Do),u(e,Ea,l),y(Re,e,l),u(e,za,l),u(e,Ps,l),t(Ps,No),u(e,wa,l),y(Ye,e,l),u(e,ya,l),u(e,Pe,l),t(Pe,Fo),t(Pe,Ts),t(Ts,xo),t(Pe,Oo),u(e,Pa,l),u(e,ve,l),t(ve,Je),t(ve,Lo),t(ve,We),u(e,Ta,l),u(e,qs,l),t(qs,Go),u(e,qa,l),u(e,$e,l),t($e,Te),t(Te,vt),y(Xe,vt,null),t($e,Vo),t($e,$t),t($t,Uo),u(e,Ia,l),u(e,qe,l),t(qe,Ho),t(qe,gt),t(gt,Qo),t(qe,Bo),u(e,Aa,l),u(e,me,l),t(me,Ke),t(Ke,Ro),t(Ke,kt),t(kt,Yo),t(Ke,Jo),t(me,Wo),t(me,jt),t(jt,Xo),t(me,Ko),t(me,Et),t(Et,Zo),u(e,Sa,l),u(e,L,l),t(L,el),t(L,Ze),t(Ze,sl),t(L,tl),t(L,zt),t(zt,al),t(L,ol),t(L,wt),t(wt,ll),t(L,il),u(e,Ca,l),u(e,G,l),t(G,nl),t(G,yt),t(yt,rl),t(G,pl),t(G,Pt),t(Pt,cl),t(G,ul),t(G,es),t(es,ml),t(G,dl),u(e,Ma,l),y(ss,e,l),u(e,Da,l),u(e,Is,l),t(Is,fl),u(e,Na,l),u(e,Ie,l),t(Ie,hl),t(Ie,Tt),t(Tt,bl),t(Ie,_l),u(e,Fa,l),u(e,Ae,l),t(Ae,vl),t(Ae,qt),t(qt,$l),t(Ae,gl),u(e,xa,l),hs[B].m(e,l),u(e,As,l),u(e,Ss,l),t(Ss,kl),u(e,Oa,l),bs[Y].m(e,l),u(e,Cs,l),u(e,x,l),t(x,jl),t(x,It),t(It,El),t(x,zl),t(x,At),t(At,wl),t(x,yl),t(x,St),t(St,Pl),t(x,Tl),t(x,Ct),t(Ct,ql),t(x,Il),u(e,La,l),u(e,ge,l),t(ge,Se),t(Se,Mt),y(ts,Mt,null),t(ge,Al),t(ge,Dt),t(Dt,Sl),u(e,Ga,l),_s[W].m(e,l),u(e,Ms,l),u(e,Ds,l),t(Ds,Cl),u(e,Va,l),u(e,V,l),t(V,Ml),t(V,Nt),t(Nt,Dl),t(V,Nl),t(V,Ft),t(Ft,Fl),t(V,xl),t(V,xt),t(xt,Ol),t(V,Ll),u(e,Ua,l),u(e,Ns,l),t(Ns,Gl),u(e,Ha,l),u(e,de,l),t(de,Vl),t(de,Ot),t(Ot,Ul),t(de,Hl),t(de,Fs),t(Fs,Ql),t(de,Bl),u(e,Qa,l),u(e,ke,l),t(ke,Ce),t(Ce,Lt),y(as,Lt,null),t(ke,Rl),t(ke,Gt),t(Gt,Yl),u(e,Ba,l),u(e,xs,l),t(xs,Jl),u(e,Ra,l),u(e,fe,l),t(fe,Os),t(Os,Vt),t(Vt,Wl),t(Os,Xl),t(fe,Kl),t(fe,Ls),t(Ls,Ut),t(Ut,Zl),t(Ls,ei),t(fe,si),t(fe,Gs),t(Gs,Ht),t(Ht,ti),t(Gs,ai),u(e,Ya,l),u(e,Vs,l),t(Vs,oi),u(e,Ja,l),u(e,Us,l),t(Us,li),u(e,Wa,l),vs[K].m(e,l),u(e,Hs,l),u(e,U,l),t(U,ii),t(U,Qt),t(Qt,ni),t(U,ri),t(U,Bt),t(Bt,pi),t(U,ci),t(U,Rt),t(Rt,ui),t(U,mi),u(e,Xa,l),u(e,je,l),t(je,Me),t(Me,Yt),y(os,Yt,null),t(je,di),t(je,Jt),t(Jt,fi),u(e,Ka,l),u(e,Qs,l),t(Qs,hi),u(e,Za,l),u(e,Ee,l),t(Ee,ls),t(Ee,bi),t(Ee,is),u(e,eo,l),u(e,Bs,l),t(Bs,_i),u(e,so,l),u(e,Rs,l),t(Rs,vi),u(e,to,l),u(e,Ys,l),t(Ys,$i),u(e,ao,l),u(e,D,l),t(D,Js),t(Js,Wt),t(Wt,gi),t(Js,ki),t(D,ji),t(D,Xt),t(Xt,Kt),t(Kt,Ei),t(D,zi),t(D,Zt),t(Zt,ea),t(ea,wi),t(D,yi),t(D,sa),t(sa,ta),t(ta,Pi),t(D,Ti),t(D,aa),t(aa,oa),t(oa,qi),t(D,Ii),t(D,la),t(la,ia),t(ia,Ai),t(D,Si),t(D,na),t(na,ra),t(ra,Ci),t(D,Mi),t(D,pa),t(pa,Di),u(e,oo,l),$s[ee].m(e,l),u(e,Ws,l),u(e,Xs,l),t(Xs,Ni),u(e,lo,l),y(ns,e,l),u(e,io,l),gs[te].m(e,l),u(e,Ks,l),u(e,Zs,l),t(Zs,Fi),u(e,no,l),u(e,ze,l),t(ze,De),t(De,ca),y(rs,ca,null),t(ze,xi),t(ze,ua),t(ua,Oi),u(e,ro,l),u(e,et,l),t(et,Li),u(e,po,l),y(ps,e,l),u(e,co,l),ks[oe].m(e,l),u(e,st,l),u(e,O,l),t(O,Gi),t(O,ma),t(ma,Vi),t(O,Ui),t(O,da),t(da,Hi),t(O,Qi),t(O,fa),t(fa,Bi),t(O,Ri),t(O,cs),t(cs,Yi),t(O,Ji),u(e,uo,l),js[ie].m(e,l),u(e,tt,l),Es[re].m(e,l),u(e,at,l),u(e,he,l),t(he,Wi),t(he,ha),t(ha,Xi),t(he,Ki),t(he,ba),t(ba,Zi),t(he,en),u(e,mo,l),u(e,Ne,l),t(Ne,sn),t(Ne,_a),t(_a,tn),t(Ne,an),u(e,fo,l),y(us,e,l),u(e,ho,l),y(ms,e,l),u(e,bo,l),u(e,ot,l),t(ot,on),u(e,_o,l),u(e,Fe,l),t(Fe,va),t(va,ln),t(Fe,nn),t(Fe,$a),t($a,rn),u(e,vo,l),u(e,lt,l),t(lt,pn),u(e,$o,l),y(xe,e,l),go=!0},p(e,[l]){const zs={};l&1&&(zs.fw=e[0]),o.$set(zs);let it=k;k=$n(e),k!==it&&(ue(),$(ds[it],1,1,()=>{ds[it]=null}),ce(),M=ds[k],M||(M=ds[k]=vn[k](e),M.c()),g(M,1),M.m(N.parentNode,N));const ga={};l&2&&(ga.$$scope={dirty:l,ctx:e}),we.$set(ga);let nt=H;H=kn(e),H!==nt&&(ue(),$(fs[nt],1,1,()=>{fs[nt]=null}),ce(),Q=fs[H],Q||(Q=fs[H]=gn[H](e),Q.c()),g(Q,1),Q.m(ws.parentNode,ws));let Oe=B;B=En(e),B!==Oe&&(ue(),$(hs[Oe],1,1,()=>{hs[Oe]=null}),ce(),R=hs[B],R||(R=hs[B]=jn[B](e),R.c()),g(R,1),R.m(As.parentNode,As));let rt=Y;Y=wn(e),Y!==rt&&(ue(),$(bs[rt],1,1,()=>{bs[rt]=null}),ce(),J=bs[Y],J||(J=bs[Y]=zn[Y](e),J.c()),g(J,1),J.m(Cs.parentNode,Cs));let pt=W;W=Pn(e),W!==pt&&(ue(),$(_s[pt],1,1,()=>{_s[pt]=null}),ce(),X=_s[W],X||(X=_s[W]=yn[W](e),X.c()),g(X,1),X.m(Ms.parentNode,Ms));let Le=K;K=qn(e),K!==Le&&(ue(),$(vs[Le],1,1,()=>{vs[Le]=null}),ce(),Z=vs[K],Z||(Z=vs[K]=Tn[K](e),Z.c()),g(Z,1),Z.m(Hs.parentNode,Hs));let ct=ee;ee=An(e),ee!==ct&&(ue(),$($s[ct],1,1,()=>{$s[ct]=null}),ce(),se=$s[ee],se||(se=$s[ee]=In[ee](e),se.c()),g(se,1),se.m(Ws.parentNode,Ws));let Ge=te;te=Cn(e),te!==Ge&&(ue(),$(gs[Ge],1,1,()=>{gs[Ge]=null}),ce(),ae=gs[te],ae||(ae=gs[te]=Sn[te](e),ae.c()),g(ae,1),ae.m(Ks.parentNode,Ks));let ut=oe;oe=Dn(e),oe!==ut&&(ue(),$(ks[ut],1,1,()=>{ks[ut]=null}),ce(),le=ks[oe],le||(le=ks[oe]=Mn[oe](e),le.c()),g(le,1),le.m(st.parentNode,st));let Ve=ie;ie=Fn(e),ie!==Ve&&(ue(),$(js[Ve],1,1,()=>{js[Ve]=null}),ce(),ne=js[ie],ne||(ne=js[ie]=Nn[ie](e),ne.c()),g(ne,1),ne.m(tt.parentNode,tt));let mt=re;re=On(e),re!==mt&&(ue(),$(Es[mt],1,1,()=>{Es[mt]=null}),ce(),pe=Es[re],pe||(pe=Es[re]=xn[re](e),pe.c()),g(pe,1),pe.m(at.parentNode,at));const ka={};l&2&&(ka.$$scope={dirty:l,ctx:e}),xe.$set(ka)},i(e){go||(g(o.$$.fragment,e),g(A.$$.fragment,e),g(M),g(we.$$.fragment,e),g(Q),g(Re.$$.fragment,e),g(Ye.$$.fragment,e),g(Xe.$$.fragment,e),g(ss.$$.fragment,e),g(R),g(J),g(ts.$$.fragment,e),g(X),g(as.$$.fragment,e),g(Z),g(os.$$.fragment,e),g(se),g(ns.$$.fragment,e),g(ae),g(rs.$$.fragment,e),g(ps.$$.fragment,e),g(le),g(ne),g(pe),g(us.$$.fragment,e),g(ms.$$.fragment,e),g(xe.$$.fragment,e),go=!0)},o(e){$(o.$$.fragment,e),$(A.$$.fragment,e),$(M),$(we.$$.fragment,e),$(Q),$(Re.$$.fragment,e),$(Ye.$$.fragment,e),$(Xe.$$.fragment,e),$(ss.$$.fragment,e),$(R),$(J),$(ts.$$.fragment,e),$(X),$(as.$$.fragment,e),$(Z),$(os.$$.fragment,e),$(se),$(ns.$$.fragment,e),$(ae),$(rs.$$.fragment,e),$(ps.$$.fragment,e),$(le),$(ne),$(pe),$(us.$$.fragment,e),$(ms.$$.fragment,e),$(xe.$$.fragment,e),go=!1},d(e){s(a),e&&s(m),P(o,e),e&&s(h),e&&s(_),P(A),e&&s(v),ds[k].d(e),e&&s(N),P(we,e),e&&s(ja),fs[H].d(e),e&&s(ws),e&&s(ye),e&&s(Ea),P(Re,e),e&&s(za),e&&s(Ps),e&&s(wa),P(Ye,e),e&&s(ya),e&&s(Pe),e&&s(Pa),e&&s(ve),e&&s(Ta),e&&s(qs),e&&s(qa),e&&s($e),P(Xe),e&&s(Ia),e&&s(qe),e&&s(Aa),e&&s(me),e&&s(Sa),e&&s(L),e&&s(Ca),e&&s(G),e&&s(Ma),P(ss,e),e&&s(Da),e&&s(Is),e&&s(Na),e&&s(Ie),e&&s(Fa),e&&s(Ae),e&&s(xa),hs[B].d(e),e&&s(As),e&&s(Ss),e&&s(Oa),bs[Y].d(e),e&&s(Cs),e&&s(x),e&&s(La),e&&s(ge),P(ts),e&&s(Ga),_s[W].d(e),e&&s(Ms),e&&s(Ds),e&&s(Va),e&&s(V),e&&s(Ua),e&&s(Ns),e&&s(Ha),e&&s(de),e&&s(Qa),e&&s(ke),P(as),e&&s(Ba),e&&s(xs),e&&s(Ra),e&&s(fe),e&&s(Ya),e&&s(Vs),e&&s(Ja),e&&s(Us),e&&s(Wa),vs[K].d(e),e&&s(Hs),e&&s(U),e&&s(Xa),e&&s(je),P(os),e&&s(Ka),e&&s(Qs),e&&s(Za),e&&s(Ee),e&&s(eo),e&&s(Bs),e&&s(so),e&&s(Rs),e&&s(to),e&&s(Ys),e&&s(ao),e&&s(D),e&&s(oo),$s[ee].d(e),e&&s(Ws),e&&s(Xs),e&&s(lo),P(ns,e),e&&s(io),gs[te].d(e),e&&s(Ks),e&&s(Zs),e&&s(no),e&&s(ze),P(rs),e&&s(ro),e&&s(et),e&&s(po),P(ps,e),e&&s(co),ks[oe].d(e),e&&s(st),e&&s(O),e&&s(uo),js[ie].d(e),e&&s(tt),Es[re].d(e),e&&s(at),e&&s(he),e&&s(mo),e&&s(Ne),e&&s(fo),P(us,e),e&&s(ho),P(ms,e),e&&s(bo),e&&s(ot),e&&s(_o),e&&s(Fe),e&&s(vo),e&&s(lt),e&&s($o),P(xe,e)}}}const Qp={local:"dietro-la-pipeline",sections:[{local:"preelaborazione-con-un-tokenizer",title:"Preelaborazione con un tokenizer"},{local:"passare-attraverso-il-modello",sections:[{local:"un-vettore-ad-alta-dimensionalit",title:"Un vettore ad alta dimensionalit\xE0?"},{local:"model-heads-dare-un-senso-ai-numeri",title:"Model heads: Dare un senso ai numeri"}],title:"Passare attraverso il modello"},{local:"postprocessing-the-output",title:"Postprocessing the output"}],title:"Dietro la pipeline"};function Bp(j,a,m){let o="pt";return vp(()=>{const h=new URLSearchParams(window.location.search);m(0,o=h.get("fw")||"pt")}),[o]}class ec extends fp{constructor(a){super();hp(this,a,Bp,Hp,bp,{})}}export{ec as default,Qp as metadata};
