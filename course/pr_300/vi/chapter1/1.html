<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;gii-thiu&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;cho-mng-ti-kho-hc&quot;,&quot;title&quot;:&quot;Chào mừng tới 🤗 Khoá học!&quot;},{&quot;local&quot;:&quot;kha-hc-c-g&quot;,&quot;title&quot;:&quot;Khóa học có gì?&quot;},{&quot;local&quot;:&quot;chng-ta-l-ai&quot;,&quot;title&quot;:&quot;Chúng ta là ai?&quot;}],&quot;title&quot;:&quot;Giới thiệu&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/pr_300/vi/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/course/pr_300/vi/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_300/vi/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_300/vi/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_300/vi/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_300/vi/_app/pages/chapter1/1.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_300/vi/_app/chunks/Youtube-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_300/vi/_app/chunks/IconCopyLink-hf-doc-builder.js"> 





<h1 class="relative group"><a id="gii-thiu" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#gii-thiu"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Giới thiệu
	</span></h1>

<h2 class="relative group"><a id="cho-mng-ti-kho-hc" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#cho-mng-ti-kho-hc"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Chào mừng tới 🤗 Khoá học!
	</span></h2>

<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/00GKzGyWFEs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>Khóa học này sẽ dạy bạn về Xử lý Ngôn ngữ Tự nhiên (NLP) sử dụng các thư viện từ hệ sinh thái <a href="https://huggingface.co/" rel="nofollow">Hugging Face</a> — <a href="https://github.com/huggingface/transformers" rel="nofollow">🤗 Transformers</a>, <a href="https://github.com/huggingface/datasets" rel="nofollow">🤗 Datasets</a>, <a href="https://github.com/huggingface/tokenizers" rel="nofollow">🤗 Tokenizers</a>, và <a href="https://github.com/huggingface/accelerate" rel="nofollow">🤗 Accelerate</a> — cũng như <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a>. Khoá học hoàn toàn miễn phí và không có quảng cáo.</p>
<h2 class="relative group"><a id="kha-hc-c-g" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#kha-hc-c-g"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Khóa học có gì?
	</span></h2>

<p>Dưới đây là tổng quan ngắn gọn về khóa học:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course."></div>
<ul><li>Các chương từ 1 đến 4 giới thiệu các khái niệm chính của thư viện 🤗 Transformers. Đến cuối học phần này, bạn sẽ quen thuộc với cách hoạt động của các mô hình Transformer và sẽ biết cách sử dụng mô hình từ <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a>, tinh chỉnh nó trên một tập dữ liệu cụ thể, và chia sẻ kết quả của bạn lên Hub!</li>
<li>Các chương từ 5 đến 8 dạy các kiến thức cơ bản về 🤗 Datasets và 🤗 Tokenizers trước khi đi sâu vào các tác vụ NLP kinh điển. Đến cuối học phần này, bạn sẽ có thể tự mình giải quyết các vấn đề NLP phổ biến nhất.</li>
<li>Các chương từ 9 đến 12 vượt ra ngoài phạm vi NLP và khám phá cách sử dụng các mô hình Transformer để giải quyết các tác vụ trong xử lý giọng nói và thị giác máy tính. Trong quá trình này, bạn sẽ học cách xây dựng và chia sẻ các bản demo về mô hình của mình cũng như cách tối ưu hóa chúng cho môi trường sản xuất. Đến cuối học phần này, bạn sẽ sẵn sàng áp dụng 🤗 Transformers cho (hầu hết) bất kỳ vấn đề học máy nào!</li></ul>
<p>Khoá học:</p>
<ul><li>Yêu cầu có kiến thức tốt về Python.</li>
<li>Nên tìm hiểu sau khi đã hoàn thành một khóa nhập môn về Học sâu, chẳng hạn như <a href="https://course.fast.ai/" rel="nofollow">Practical Deep Learning for Coders</a> của <a href="https://www.fast.ai/" rel="nofollow">fast.ai</a> hoặc một trong những chương trình được phát triển bởi <a href="https://www.deeplearning.ai/" rel="nofollow">DeepLearning.AI</a>.</li>
<li>Không yêu cầu biết trước các kiến thức về <a href="https://pytorch.org/" rel="nofollow">PyTorch</a> hoặc <a href="https://www.tensorflow.org/" rel="nofollow">TensorFlow</a>, mặc dù quen thuộc với một số kiến thức này sẽ hữu ích.</li></ul>
<p>Sau khi bạn hoàn thành khóa học này, chúng tôi khuyến khích bạn xem thêm khoá <a href="https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh" rel="nofollow">Natural Language Processing Specialization</a> của DeepLearning.AI với nội dung bao gồm một loạt các mô hình NLP truyền thống đáng để biết như Naive Bayes và LSTM!</p>
<h2 class="relative group"><a id="chng-ta-l-ai" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#chng-ta-l-ai"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Chúng ta là ai?
	</span></h2>

<p>Giới thiệu về tác giả:</p>
<p><strong>Abubakar Abid</strong> đã hoàn thành chương trình Tiến sĩ về học máy ứng dụng tại Stanford. Trong thời gian học tiến sĩ, anh ấy đã tạo ra <a href="https://github.com/gradio-app/gradio" rel="nofollow">Gradio</a>, một thư viện Python mã nguồn mở được sử dụng để xây dựng hơn 600,000 bản demo học máy. Gradio được mua lại bởi Hugging Face, nơi Abubakar hiện đóng vai trò là trưởng nhóm học máy.</p>
<p><strong>Matthew Carrigan</strong> là một Kỹ sư Học máy tại Hugging Face. Anh ấy sống ở Dublin, Ireland, trước đây là kỹ sư Học máy tại Parse.ly và trước đó là nhà nghiên cứu sau tiến sĩ tại Trinity College Dublin. Anh ấy không tin rằng chúng ta sẽ đạt được AGI bằng cách mở rộng các kiến ​​trúc hiện có, nhưng có niềm tin vào sự bất tử của robot.</p>
<p><strong>Lysandre Debut</strong> là một Kỹ sư Học máy tại Hugging Face và đã làm việc với thư viện 🤗 Transformers từ những giai đoạn đầu phát triển. Mục tiêu của anh ấy là làm cho NLP có thể dễ dàng truy cập được từ tất cả mọi người bằng cách phát triển các công cụ với một API rất đơn giản.</p>
<p><strong>Sylvain Gugger</strong> là Kỹ sư nghiên cứu tại Hugging Face và là một trong những thành viên cốt lõi của thư viện 🤗 Transformers. Trước đây, anh ấy là Nhà nghiên cứu khoa học tại fast.ai và anh ấy là đồng sáng tác đầu sách <em><a href="https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/" rel="nofollow">Deep Learning for Coders with fastai and PyTorch</a></em> cùng với Jeremy Howard. Hướng nghiên cứu chính của anh ấy là làm cho việc học sâu trở nên dễ tiếp cận hơn, bằng cách thiết kế và cải tiến các kỹ thuật cho phép các mô hình huấn luyện nhanh trên các tài nguyên hạn chế.</p>
<p><strong>Dawood Khan</strong> là một Kỹ sư Học máy tại Hugging Face. Anh ấy đến từ New York và tốt nghiệp Đại học New York chuyên ngành Khoa học máy tính. Sau khi làm việc với tư cách là Kỹ sư iOS trong một vài năm, Dawood đã nghỉ việc để bắt đầu phát triển Gradio cùng với những người đồng sáng lập của mình. Gradio cuối cùng đã được mua lại bởi Hugging Face.</p>
<p><strong>Merve Noyan</strong> là Chuyên gia về Quan hệ lập trình viên tại Hugging Face, hiện đang phát triển các công cụ và xây dựng nội dung xung quanh chúng để tất cả mọi người có thể tiếp cận học máy dễ dàng hơn.</p>
<p><strong>Lucile Saulnier</strong> là một Kỹ sư Học máy tại Hugging Face, phát triển và hỗ trợ việc sử dụng các công cụ mã nguồn mở. Cô cũng tích cực tham gia vào nhiều dự án nghiên cứu trong lĩnh vực Xử lý Ngôn ngữ Tự nhiên như huấn luyện cộng tác và BigScience.</p>
<p><strong>Lewis Tunstall</strong> là một Kỹ sư Học máy tại Hugging Face, tập trung vào việc phát triển các công cụ mã nguồn mở và giúp chúng có thể tiếp cận được với cộng đồng rộng lớn hơn. Anh cũng là đồng tác giả của cuốn sách O’Reilly <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">Natural Language Processing with Transformers</a>.</p>
<p><strong>Leandro von Werra</strong> là một Kỹ sư Học máy trong nhóm mã nguồn mở tại Hugging Face và cũng là đồng tác giả của cuốn sách O’Reilly <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">Natural Language Processing with Transformers</a>. Anh ấy có nhiều năm kinh nghiệm thực tế triển khai các dự án NLP vào sản xuất bằng cách làm việc trên toàn bộ hệ thống học máy.</p>
<p>Bạn đã sẵn sàng chưa? Trong chương này, bạn sẽ học:</p>
<ul><li>Cách sử dụng hàm <code>pipeline()</code> để giải quyết các tác vụ NLP như tạo và phân loại văn bản.</li>
<li>Về cấu trúc của mạng Transformer.</li>
<li>Làm thế nào để phân biệt giữa các kiến trúc encoder, decoder, và encoder-decoder cũng như các trường hợp sử dụng.</li></ul>


		<script type="module" data-hydrate="19jzjvs">
		import { start } from "/docs/course/pr_300/vi/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="19jzjvs"]').parentNode,
			paths: {"base":"/docs/course/pr_300/vi","assets":"/docs/course/pr_300/vi"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/pr_300/vi/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/course/pr_300/vi/_app/pages/chapter1/1.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
