import{S as Uo,i as Yo,s as Jo,e as o,k as c,w as Ie,t as a,M as Ko,c as l,d as r,m as d,a as n,x as Te,h as s,b as i,N as Ro,G as e,g as p,y as Se,L as Qo,q as Me,o as He,B as xe,v as Vo}from"../../chunks/vendor-hf-doc-builder.js";import{Y as Wo}from"../../chunks/Youtube-hf-doc-builder.js";import{I as mr}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Xo}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function Zo(Ns){let P,St,L,D,ke,K,fr,De,hr,Mt,Q,Ht,y,F,Fe,V,vr,Ge,gr,xt,W,kt,m,Er,X,_r,br,G,wr,Ce,qr,Pr,C,Lr,Oe,yr,Ar,O,$r,je,Nr,zr,j,Ir,Be,Tr,Sr,Z,Re,Mr,Hr,Dt,A,B,Ue,ee,xr,Ye,kr,Ft,be,Dr,Gt,$,te,zs,Fr,re,Is,Ct,b,f,Gr,Je,Cr,Or,Ke,jr,Br,ae,Qe,Rr,Ur,Ve,Yr,Jr,We,Kr,Qr,Vr,N,Wr,Xe,Xr,Zr,Ze,ea,ta,ra,z,aa,et,sa,oa,tt,la,na,Ot,we,ia,jt,w,rt,ua,pa,g,ca,se,da,ma,oe,at,fa,ha,le,st,va,ga,Ea,I,_a,ne,ba,wa,ie,qa,Pa,Bt,R,La,ue,ya,Aa,Rt,T,U,ot,pe,$a,lt,Na,Ut,qe,za,Yt,Y,Ia,ce,Ta,Sa,Jt,S,nt,Ma,Ha,it,xa,ka,Kt,M,ut,Da,Fa,pt,Ga,Ca,Qt,E,ct,Oa,ja,dt,Ba,Ra,de,mt,Ua,Ya,Vt,me,ft,Ja,Ka,Wt,H,ht,Qa,Va,vt,Wa,Xa,Xt,x,gt,Za,es,Et,ts,rs,Zt,k,_t,as,ss,fe,bt,os,ls,er,_,wt,ns,is,qt,us,ps,he,Pt,cs,ds,tr,Pe,ms,rr,q,ve,fs,Lt,hs,vs,gs,ge,Es,yt,_s,bs,ws,At,qs,ar;return K=new mr({}),Q=new Xo({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),V=new mr({}),W=new Wo({props:{id:"00GKzGyWFEs"}}),ee=new mr({}),pe=new mr({}),{c(){P=o("meta"),St=c(),L=o("h1"),D=o("a"),ke=o("span"),Ie(K.$$.fragment),fr=c(),De=o("span"),hr=a("Introduction"),Mt=c(),Ie(Q.$$.fragment),Ht=c(),y=o("h2"),F=o("a"),Fe=o("span"),Ie(V.$$.fragment),vr=c(),Ge=o("span"),gr=a("Bienvenue au cours \u{1F917} !"),xt=c(),Ie(W.$$.fragment),kt=c(),m=o("p"),Er=a("Ce cours vous apprendra \xE0 utiliser les biblioth\xE8ques de NLP de l\u2019\xE9cosyst\xE8me "),X=o("a"),_r=a("Hugging Face"),br=a(" : "),G=o("a"),wr=a("\u{1F917} "),Ce=o("em"),qr=a("Transformers"),Pr=a(", "),C=o("a"),Lr=a("\u{1F917} "),Oe=o("em"),yr=a("Datasets"),Ar=a(", "),O=o("a"),$r=a("\u{1F917} "),je=o("em"),Nr=a("Tokenizers"),zr=a(" et "),j=o("a"),Ir=a("\u{1F917} "),Be=o("em"),Tr=a("Accelerate"),Sr=a(", ainsi que le "),Z=o("a"),Re=o("em"),Mr=a("Hub"),Hr=a(". C\u2019est totalement gratuit et sans publicit\xE9."),Dt=c(),A=o("h2"),B=o("a"),Ue=o("span"),Ie(ee.$$.fragment),xr=c(),Ye=o("span"),kr=a("\xC0 quoi s'attendre ?"),Ft=c(),be=o("p"),Dr=a("Voici un bref aper\xE7u du cours :"),Gt=c(),$=o("div"),te=o("img"),Fr=c(),re=o("img"),Ct=c(),b=o("ul"),f=o("li"),Gr=a("Les chapitres 1 \xE0 4 pr\xE9sentent les principaux concepts de la biblioth\xE8que \u{1F917} "),Je=o("em"),Cr=a("Transformers"),Or=a(". \xC0 la fin de ce chapitre, vous serez familier avec le fonctionnement des "),Ke=o("em"),jr=a("transformers"),Br=a(" et vous saurez comment utiliser un mod\xE8le pr\xE9sent sur le "),ae=o("a"),Qe=o("em"),Rr=a("Hub"),Ur=a(", le "),Ve=o("em"),Yr=a("finetuner"),Jr=a(" sur un jeu de donn\xE9es, et partager vos r\xE9sultats sur le "),We=o("em"),Kr=a("Hub"),Qr=a(" !"),Vr=c(),N=o("li"),Wr=a("Les chapitres 5 \xE0 8 pr\xE9sentent les bases des librairies \u{1F917} "),Xe=o("em"),Xr=a("Datasets"),Zr=a(" et \u{1F917} "),Ze=o("em"),ea=a("Tokenizers"),ta=a(" ainsi qu\u2019une d\xE9couverte des probl\xE8mes classiques de NLP. \xC0 la fin de ce chapitre, vous serez capable de r\xE9soudre les probl\xE8mes de NLP les plus communs par vous-m\xEAme."),ra=c(),z=o("li"),aa=a("Les chapitres 9 \xE0 12 proposent d\u2019aller plus loin et d\u2019explorer comment les "),et=o("em"),sa=a("transformers"),oa=a(" peuvent \xEAtre utilis\xE9s pour r\xE9soudre des probl\xE8mes de traitement de la parole et de vision par ordinateur. En suivant ces chapitres, vous apprendrez \xE0 construire et \xE0 partager vos mod\xE8les via des d\xE9monstrateurs, et vous serez capable d\u2019optimiser ces mod\xE8les pour des environnements de production. Enfin, vous serez pr\xEAt \xE0 appliquer \u{1F917} "),tt=o("em"),la=a("Transformers"),na=a(" \xE0 (presque) n\u2019importe quel probl\xE8me d\u2019apprentissage automatique !"),Ot=c(),we=o("p"),ia=a("Ce cours :"),jt=c(),w=o("ul"),rt=o("li"),ua=a("requiert un bon niveau en Python,"),pa=c(),g=o("li"),ca=a("se comprend mieux si vous avez d\xE9j\xE0 suivi un cours d\u2019introduction \xE0 l\u2019apprentissage profond comme "),se=o("a"),da=a("fast.ai\u2019s"),ma=a(", "),oe=o("a"),at=o("em"),fa=a("Practical Deep Learning for Coders"),ha=a(" ou un des cours d\xE9velopp\xE9s par "),le=o("a"),st=o("em"),va=a("DeepLearning.AI"),ga=a(","),Ea=c(),I=o("li"),_a=a("n\u2019attend pas une connaissance appronfondie de "),ne=o("a"),ba=a("PyTorch"),wa=a(" ou de "),ie=o("a"),qa=a("TensorFlow"),Pa=a(", bien qu\u2019\xEAtre familiaris\xE9 avec l\u2019un d\u2019entre eux peut aider."),Bt=c(),R=o("p"),La=a("Apr\xE8s avoir termin\xE9 ce cours, nous vous recommandons de suivre la "),ue=o("a"),ya=a("Sp\xE9cialisation en NLP"),Aa=a(" dispens\xE9e par DeepLearning.AI, qui couvre une grande partie des mod\xE8les traditionnels de NLP comme le Bay\xE9sien na\xEFf et les LSTMs qui sont importants \xE0 conna\xEEtre!"),Rt=c(),T=o("h2"),U=o("a"),ot=o("span"),Ie(pe.$$.fragment),$a=c(),lt=o("span"),Na=a("Qui sommes-nous ?"),Ut=c(),qe=o("p"),za=a("\xC0 propos des auteurs de ce cours :"),Yt=c(),Y=o("p"),Ia=a("*Abubakar Abid** a obtenu son doctorat \xE0 Stanford en apprentissage automatique appliqu\xE9. Pendant son doctorat, il a fond\xE9 "),ce=o("a"),Ta=a("Gradio"),Sa=a(", une biblioth\xE8que Python open-source qui a \xE9t\xE9 utilis\xE9e pour construire plus de 600 000 d\xE9mos d\u2019apprentissage automatique. Gradio a \xE9t\xE9 rachet\xE9e par Hugging Face, o\xF9 Abubakar occupe d\xE9sormais le poste de responsable de l\u2019\xE9quipe d\u2019apprentissage automatique."),Jt=c(),S=o("p"),nt=o("strong"),Ma=a("Matthew Carrigan"),Ha=a(" est ing\xE9nieur en apprentissage machine chez Hugging Face. Il vit \xE0 Dublin en Irlande. Il a travaill\xE9 auparavant comme ing\xE9nieur en apprentissage machine chez Parse.ly et avant cela comme chercheur postdoctoral au Trinity College Dublin. Il ne croit pas que nous arrivions \xE0 l\u2019"),it=o("em"),xa=a("AGI"),ka=a(" en mettant \xE0 l\u2019\xE9chelle les architectures existantes mais a tout de m\xEAme beaucoup d\u2019espoir dans l\u2019immortalit\xE9 des robots."),Kt=c(),M=o("p"),ut=o("strong"),Da=a("Lysandre Debut"),Fa=a(" est ing\xE9nieur en apprentissage machine chez Hugging Face et a travaill\xE9 sur la biblioth\xE8que \u{1F917} "),pt=o("em"),Ga=a("Transformers"),Ca=a(" depuis les premi\xE8res phases de d\xE9veloppement. Son but est de rendre le NLP accessible \xE0 tous en d\xE9veloppant des outils disposant d\u2019une API tr\xE8s simple."),Qt=c(),E=o("p"),ct=o("strong"),Oa=a("Sylvain Gugger"),ja=a(" est ing\xE9nieur recherche chez Hugging Face et un des principaux responsables de la biblioth\xE8que \u{1F917} "),dt=o("em"),Ba=a("Transformers"),Ra=a(". Avant cela, il \xE9tait chercheur en en apprentissage machine chez fast.ai et a \xE9crit le livre "),de=o("a"),mt=o("em"),Ua=a("Deep Learning for Coders with fastai and PyTorch"),Ya=a(" avec Jeremy Howard. Son but est de rendre l\u2019apprentissage profond plus accessible, en d\xE9veloppant et en am\xE9liorant des techniques permettant aux mod\xE8les d\u2019apprendre rapidement sur des ressources limit\xE9es."),Vt=c(),me=o("p"),ft=o("strong"),Ja=a("Dawood Khan"),Ka=a(" est un ing\xE9nieur en apprentissage automatique chez Hugging Face. Il vient de New York et est dipl\xF4m\xE9 de l\u2019Universit\xE9 de New York en informatique. Apr\xE8s avoir travaill\xE9 comme ing\xE9nieur iOS pendant quelques ann\xE9es, Dawood a quitt\xE9 son poste pour cr\xE9er Gradio avec ses cofondateurs. Gradio a finalement \xE9t\xE9 acquis par Hugging Face."),Wt=c(),H=o("p"),ht=o("strong"),Qa=a("Merve Noyan"),Va=a(" est d\xE9veloppeuse "),vt=o("em"),Wa=a("advocate"),Xa=a(" chez Hugging Face et travaille \xE0 la cr\xE9ation d\u2019outils et de contenus visant \xE0 d\xE9mocratiser l\u2019apprentissage machine pour tous."),Xt=c(),x=o("p"),gt=o("strong"),Za=a("Lucile Saulnier"),es=a(" est ing\xE9nieure en apprentissage machine chez Hugging Face et travaille au d\xE9veloppement et \xE0 l\u2019impl\xE9mentation de nombreux outils "),Et=o("em"),ts=a("open source"),rs=a(". Elle est \xE9galement activement impliqu\xE9e dans de nombreux projets de recherche dans le domaine du NLP comme l\u2019entra\xEEnement collaboratif de mod\xE8les et le projet BigScience."),Zt=c(),k=o("p"),_t=o("strong"),as=a("Lewis Tunstall"),ss=a(" est ing\xE9nieur en apprentissage machine chez Hugging Face et d\xE9vou\xE9 au d\xE9veloppement d\u2019outils open source avec la volont\xE9 de les rendre accessibles \xE0 une communaut\xE9 plus large. Il est \xE9galement co-auteur du livre "),fe=o("a"),bt=o("em"),os=a("Natural Language Processing with Transformers"),ls=a("."),er=c(),_=o("p"),wt=o("strong"),ns=a("Leandro von Werra"),is=a(" est ing\xE9nieur en apprentissage machine dans l\u2019\xE9quipe "),qt=o("em"),us=a("open source"),ps=a(" d\u2019Hugging Face et \xE9galement co-auteur du livre "),he=o("a"),Pt=o("em"),cs=a("Natural Language Processing with Transformers"),ds=a(". Il a plusieurs ann\xE9es d\u2019exp\xE9rience dans l\u2019industrie o\xF9 il a pu d\xE9ployer des projets de NLP en production et travailler sur toutes les \xE9tapes clefs du d\xE9ploiement."),tr=c(),Pe=o("p"),ms=a("\xCAtes-vous pr\xEAt \xE0 commencer ? Dans ce chapitre, vous apprendrez :"),rr=c(),q=o("ul"),ve=o("li"),fs=a("\xE0 utiliser la fonction "),Lt=o("code"),hs=a("pipeline()"),vs=a(" pour r\xE9soudre des probl\xE8mes de NLP comme la g\xE9n\xE9ration de texte et la classification,"),gs=c(),ge=o("li"),Es=a("l\u2019architecture d\u2019un "),yt=o("em"),_s=a("transformer"),bs=a(","),ws=c(),At=o("li"),qs=a("comment faire la distinction entre les diff\xE9rentes architectures d\u2019encodeur, de d\xE9codeur et d\u2019encodeur-d\xE9codeur ainsi que leurs diff\xE9rents cas d\u2019usage."),this.h()},l(t){const u=Ko('[data-svelte="svelte-1phssyn"]',document.head);P=l(u,"META",{name:!0,content:!0}),u.forEach(r),St=d(t),L=l(t,"H1",{class:!0});var sr=n(L);D=l(sr,"A",{id:!0,class:!0,href:!0});var Ts=n(D);ke=l(Ts,"SPAN",{});var Ss=n(ke);Te(K.$$.fragment,Ss),Ss.forEach(r),Ts.forEach(r),fr=d(sr),De=l(sr,"SPAN",{});var Ms=n(De);hr=s(Ms,"Introduction"),Ms.forEach(r),sr.forEach(r),Mt=d(t),Te(Q.$$.fragment,t),Ht=d(t),y=l(t,"H2",{class:!0});var or=n(y);F=l(or,"A",{id:!0,class:!0,href:!0});var Hs=n(F);Fe=l(Hs,"SPAN",{});var xs=n(Fe);Te(V.$$.fragment,xs),xs.forEach(r),Hs.forEach(r),vr=d(or),Ge=l(or,"SPAN",{});var ks=n(Ge);gr=s(ks,"Bienvenue au cours \u{1F917} !"),ks.forEach(r),or.forEach(r),xt=d(t),Te(W.$$.fragment,t),kt=d(t),m=l(t,"P",{});var h=n(m);Er=s(h,"Ce cours vous apprendra \xE0 utiliser les biblioth\xE8ques de NLP de l\u2019\xE9cosyst\xE8me "),X=l(h,"A",{href:!0,rel:!0});var Ds=n(X);_r=s(Ds,"Hugging Face"),Ds.forEach(r),br=s(h," : "),G=l(h,"A",{href:!0,rel:!0});var Ps=n(G);wr=s(Ps,"\u{1F917} "),Ce=l(Ps,"EM",{});var Fs=n(Ce);qr=s(Fs,"Transformers"),Fs.forEach(r),Ps.forEach(r),Pr=s(h,", "),C=l(h,"A",{href:!0,rel:!0});var Ls=n(C);Lr=s(Ls,"\u{1F917} "),Oe=l(Ls,"EM",{});var Gs=n(Oe);yr=s(Gs,"Datasets"),Gs.forEach(r),Ls.forEach(r),Ar=s(h,", "),O=l(h,"A",{href:!0,rel:!0});var ys=n(O);$r=s(ys,"\u{1F917} "),je=l(ys,"EM",{});var Cs=n(je);Nr=s(Cs,"Tokenizers"),Cs.forEach(r),ys.forEach(r),zr=s(h," et "),j=l(h,"A",{href:!0,rel:!0});var As=n(j);Ir=s(As,"\u{1F917} "),Be=l(As,"EM",{});var Os=n(Be);Tr=s(Os,"Accelerate"),Os.forEach(r),As.forEach(r),Sr=s(h,", ainsi que le "),Z=l(h,"A",{href:!0,rel:!0});var js=n(Z);Re=l(js,"EM",{});var Bs=n(Re);Mr=s(Bs,"Hub"),Bs.forEach(r),js.forEach(r),Hr=s(h,". C\u2019est totalement gratuit et sans publicit\xE9."),h.forEach(r),Dt=d(t),A=l(t,"H2",{class:!0});var lr=n(A);B=l(lr,"A",{id:!0,class:!0,href:!0});var Rs=n(B);Ue=l(Rs,"SPAN",{});var Us=n(Ue);Te(ee.$$.fragment,Us),Us.forEach(r),Rs.forEach(r),xr=d(lr),Ye=l(lr,"SPAN",{});var Ys=n(Ye);kr=s(Ys,"\xC0 quoi s'attendre ?"),Ys.forEach(r),lr.forEach(r),Ft=d(t),be=l(t,"P",{});var Js=n(be);Dr=s(Js,"Voici un bref aper\xE7u du cours :"),Js.forEach(r),Gt=d(t),$=l(t,"DIV",{class:!0});var nr=n($);te=l(nr,"IMG",{class:!0,src:!0,alt:!0}),Fr=d(nr),re=l(nr,"IMG",{class:!0,src:!0,alt:!0}),nr.forEach(r),Ct=d(t),b=l(t,"UL",{});var Le=n(b);f=l(Le,"LI",{});var v=n(f);Gr=s(v,"Les chapitres 1 \xE0 4 pr\xE9sentent les principaux concepts de la biblioth\xE8que \u{1F917} "),Je=l(v,"EM",{});var Ks=n(Je);Cr=s(Ks,"Transformers"),Ks.forEach(r),Or=s(v,". \xC0 la fin de ce chapitre, vous serez familier avec le fonctionnement des "),Ke=l(v,"EM",{});var Qs=n(Ke);jr=s(Qs,"transformers"),Qs.forEach(r),Br=s(v," et vous saurez comment utiliser un mod\xE8le pr\xE9sent sur le "),ae=l(v,"A",{href:!0,rel:!0});var Vs=n(ae);Qe=l(Vs,"EM",{});var Ws=n(Qe);Rr=s(Ws,"Hub"),Ws.forEach(r),Vs.forEach(r),Ur=s(v,", le "),Ve=l(v,"EM",{});var Xs=n(Ve);Yr=s(Xs,"finetuner"),Xs.forEach(r),Jr=s(v," sur un jeu de donn\xE9es, et partager vos r\xE9sultats sur le "),We=l(v,"EM",{});var Zs=n(We);Kr=s(Zs,"Hub"),Zs.forEach(r),Qr=s(v," !"),v.forEach(r),Vr=d(Le),N=l(Le,"LI",{});var ye=n(N);Wr=s(ye,"Les chapitres 5 \xE0 8 pr\xE9sentent les bases des librairies \u{1F917} "),Xe=l(ye,"EM",{});var eo=n(Xe);Xr=s(eo,"Datasets"),eo.forEach(r),Zr=s(ye," et \u{1F917} "),Ze=l(ye,"EM",{});var to=n(Ze);ea=s(to,"Tokenizers"),to.forEach(r),ta=s(ye," ainsi qu\u2019une d\xE9couverte des probl\xE8mes classiques de NLP. \xC0 la fin de ce chapitre, vous serez capable de r\xE9soudre les probl\xE8mes de NLP les plus communs par vous-m\xEAme."),ye.forEach(r),ra=d(Le),z=l(Le,"LI",{});var Ae=n(z);aa=s(Ae,"Les chapitres 9 \xE0 12 proposent d\u2019aller plus loin et d\u2019explorer comment les "),et=l(Ae,"EM",{});var ro=n(et);sa=s(ro,"transformers"),ro.forEach(r),oa=s(Ae," peuvent \xEAtre utilis\xE9s pour r\xE9soudre des probl\xE8mes de traitement de la parole et de vision par ordinateur. En suivant ces chapitres, vous apprendrez \xE0 construire et \xE0 partager vos mod\xE8les via des d\xE9monstrateurs, et vous serez capable d\u2019optimiser ces mod\xE8les pour des environnements de production. Enfin, vous serez pr\xEAt \xE0 appliquer \u{1F917} "),tt=l(Ae,"EM",{});var ao=n(tt);la=s(ao,"Transformers"),ao.forEach(r),na=s(Ae," \xE0 (presque) n\u2019importe quel probl\xE8me d\u2019apprentissage automatique !"),Ae.forEach(r),Le.forEach(r),Ot=d(t),we=l(t,"P",{});var so=n(we);ia=s(so,"Ce cours :"),so.forEach(r),jt=d(t),w=l(t,"UL",{});var $e=n(w);rt=l($e,"LI",{});var oo=n(rt);ua=s(oo,"requiert un bon niveau en Python,"),oo.forEach(r),pa=d($e),g=l($e,"LI",{});var J=n(g);ca=s(J,"se comprend mieux si vous avez d\xE9j\xE0 suivi un cours d\u2019introduction \xE0 l\u2019apprentissage profond comme "),se=l(J,"A",{href:!0,rel:!0});var lo=n(se);da=s(lo,"fast.ai\u2019s"),lo.forEach(r),ma=s(J,", "),oe=l(J,"A",{href:!0,rel:!0});var no=n(oe);at=l(no,"EM",{});var io=n(at);fa=s(io,"Practical Deep Learning for Coders"),io.forEach(r),no.forEach(r),ha=s(J," ou un des cours d\xE9velopp\xE9s par "),le=l(J,"A",{href:!0,rel:!0});var uo=n(le);st=l(uo,"EM",{});var po=n(st);va=s(po,"DeepLearning.AI"),po.forEach(r),uo.forEach(r),ga=s(J,","),J.forEach(r),Ea=d($e),I=l($e,"LI",{});var Ne=n(I);_a=s(Ne,"n\u2019attend pas une connaissance appronfondie de "),ne=l(Ne,"A",{href:!0,rel:!0});var co=n(ne);ba=s(co,"PyTorch"),co.forEach(r),wa=s(Ne," ou de "),ie=l(Ne,"A",{href:!0,rel:!0});var mo=n(ie);qa=s(mo,"TensorFlow"),mo.forEach(r),Pa=s(Ne,", bien qu\u2019\xEAtre familiaris\xE9 avec l\u2019un d\u2019entre eux peut aider."),Ne.forEach(r),$e.forEach(r),Bt=d(t),R=l(t,"P",{});var ir=n(R);La=s(ir,"Apr\xE8s avoir termin\xE9 ce cours, nous vous recommandons de suivre la "),ue=l(ir,"A",{href:!0,rel:!0});var fo=n(ue);ya=s(fo,"Sp\xE9cialisation en NLP"),fo.forEach(r),Aa=s(ir," dispens\xE9e par DeepLearning.AI, qui couvre une grande partie des mod\xE8les traditionnels de NLP comme le Bay\xE9sien na\xEFf et les LSTMs qui sont importants \xE0 conna\xEEtre!"),ir.forEach(r),Rt=d(t),T=l(t,"H2",{class:!0});var ur=n(T);U=l(ur,"A",{id:!0,class:!0,href:!0});var ho=n(U);ot=l(ho,"SPAN",{});var vo=n(ot);Te(pe.$$.fragment,vo),vo.forEach(r),ho.forEach(r),$a=d(ur),lt=l(ur,"SPAN",{});var go=n(lt);Na=s(go,"Qui sommes-nous ?"),go.forEach(r),ur.forEach(r),Ut=d(t),qe=l(t,"P",{});var Eo=n(qe);za=s(Eo,"\xC0 propos des auteurs de ce cours :"),Eo.forEach(r),Yt=d(t),Y=l(t,"P",{});var pr=n(Y);Ia=s(pr,"*Abubakar Abid** a obtenu son doctorat \xE0 Stanford en apprentissage automatique appliqu\xE9. Pendant son doctorat, il a fond\xE9 "),ce=l(pr,"A",{href:!0,rel:!0});var _o=n(ce);Ta=s(_o,"Gradio"),_o.forEach(r),Sa=s(pr,", une biblioth\xE8que Python open-source qui a \xE9t\xE9 utilis\xE9e pour construire plus de 600 000 d\xE9mos d\u2019apprentissage automatique. Gradio a \xE9t\xE9 rachet\xE9e par Hugging Face, o\xF9 Abubakar occupe d\xE9sormais le poste de responsable de l\u2019\xE9quipe d\u2019apprentissage automatique."),pr.forEach(r),Jt=d(t),S=l(t,"P",{});var $t=n(S);nt=l($t,"STRONG",{});var bo=n(nt);Ma=s(bo,"Matthew Carrigan"),bo.forEach(r),Ha=s($t," est ing\xE9nieur en apprentissage machine chez Hugging Face. Il vit \xE0 Dublin en Irlande. Il a travaill\xE9 auparavant comme ing\xE9nieur en apprentissage machine chez Parse.ly et avant cela comme chercheur postdoctoral au Trinity College Dublin. Il ne croit pas que nous arrivions \xE0 l\u2019"),it=l($t,"EM",{});var wo=n(it);xa=s(wo,"AGI"),wo.forEach(r),ka=s($t," en mettant \xE0 l\u2019\xE9chelle les architectures existantes mais a tout de m\xEAme beaucoup d\u2019espoir dans l\u2019immortalit\xE9 des robots."),$t.forEach(r),Kt=d(t),M=l(t,"P",{});var Nt=n(M);ut=l(Nt,"STRONG",{});var qo=n(ut);Da=s(qo,"Lysandre Debut"),qo.forEach(r),Fa=s(Nt," est ing\xE9nieur en apprentissage machine chez Hugging Face et a travaill\xE9 sur la biblioth\xE8que \u{1F917} "),pt=l(Nt,"EM",{});var Po=n(pt);Ga=s(Po,"Transformers"),Po.forEach(r),Ca=s(Nt," depuis les premi\xE8res phases de d\xE9veloppement. Son but est de rendre le NLP accessible \xE0 tous en d\xE9veloppant des outils disposant d\u2019une API tr\xE8s simple."),Nt.forEach(r),Qt=d(t),E=l(t,"P",{});var Ee=n(E);ct=l(Ee,"STRONG",{});var Lo=n(ct);Oa=s(Lo,"Sylvain Gugger"),Lo.forEach(r),ja=s(Ee," est ing\xE9nieur recherche chez Hugging Face et un des principaux responsables de la biblioth\xE8que \u{1F917} "),dt=l(Ee,"EM",{});var yo=n(dt);Ba=s(yo,"Transformers"),yo.forEach(r),Ra=s(Ee,". Avant cela, il \xE9tait chercheur en en apprentissage machine chez fast.ai et a \xE9crit le livre "),de=l(Ee,"A",{href:!0,rel:!0});var Ao=n(de);mt=l(Ao,"EM",{});var $o=n(mt);Ua=s($o,"Deep Learning for Coders with fastai and PyTorch"),$o.forEach(r),Ao.forEach(r),Ya=s(Ee," avec Jeremy Howard. Son but est de rendre l\u2019apprentissage profond plus accessible, en d\xE9veloppant et en am\xE9liorant des techniques permettant aux mod\xE8les d\u2019apprendre rapidement sur des ressources limit\xE9es."),Ee.forEach(r),Vt=d(t),me=l(t,"P",{});var $s=n(me);ft=l($s,"STRONG",{});var No=n(ft);Ja=s(No,"Dawood Khan"),No.forEach(r),Ka=s($s," est un ing\xE9nieur en apprentissage automatique chez Hugging Face. Il vient de New York et est dipl\xF4m\xE9 de l\u2019Universit\xE9 de New York en informatique. Apr\xE8s avoir travaill\xE9 comme ing\xE9nieur iOS pendant quelques ann\xE9es, Dawood a quitt\xE9 son poste pour cr\xE9er Gradio avec ses cofondateurs. Gradio a finalement \xE9t\xE9 acquis par Hugging Face."),$s.forEach(r),Wt=d(t),H=l(t,"P",{});var zt=n(H);ht=l(zt,"STRONG",{});var zo=n(ht);Qa=s(zo,"Merve Noyan"),zo.forEach(r),Va=s(zt," est d\xE9veloppeuse "),vt=l(zt,"EM",{});var Io=n(vt);Wa=s(Io,"advocate"),Io.forEach(r),Xa=s(zt," chez Hugging Face et travaille \xE0 la cr\xE9ation d\u2019outils et de contenus visant \xE0 d\xE9mocratiser l\u2019apprentissage machine pour tous."),zt.forEach(r),Xt=d(t),x=l(t,"P",{});var It=n(x);gt=l(It,"STRONG",{});var To=n(gt);Za=s(To,"Lucile Saulnier"),To.forEach(r),es=s(It," est ing\xE9nieure en apprentissage machine chez Hugging Face et travaille au d\xE9veloppement et \xE0 l\u2019impl\xE9mentation de nombreux outils "),Et=l(It,"EM",{});var So=n(Et);ts=s(So,"open source"),So.forEach(r),rs=s(It,". Elle est \xE9galement activement impliqu\xE9e dans de nombreux projets de recherche dans le domaine du NLP comme l\u2019entra\xEEnement collaboratif de mod\xE8les et le projet BigScience."),It.forEach(r),Zt=d(t),k=l(t,"P",{});var Tt=n(k);_t=l(Tt,"STRONG",{});var Mo=n(_t);as=s(Mo,"Lewis Tunstall"),Mo.forEach(r),ss=s(Tt," est ing\xE9nieur en apprentissage machine chez Hugging Face et d\xE9vou\xE9 au d\xE9veloppement d\u2019outils open source avec la volont\xE9 de les rendre accessibles \xE0 une communaut\xE9 plus large. Il est \xE9galement co-auteur du livre "),fe=l(Tt,"A",{href:!0,rel:!0});var Ho=n(fe);bt=l(Ho,"EM",{});var xo=n(bt);os=s(xo,"Natural Language Processing with Transformers"),xo.forEach(r),Ho.forEach(r),ls=s(Tt,"."),Tt.forEach(r),er=d(t),_=l(t,"P",{});var _e=n(_);wt=l(_e,"STRONG",{});var ko=n(wt);ns=s(ko,"Leandro von Werra"),ko.forEach(r),is=s(_e," est ing\xE9nieur en apprentissage machine dans l\u2019\xE9quipe "),qt=l(_e,"EM",{});var Do=n(qt);us=s(Do,"open source"),Do.forEach(r),ps=s(_e," d\u2019Hugging Face et \xE9galement co-auteur du livre "),he=l(_e,"A",{href:!0,rel:!0});var Fo=n(he);Pt=l(Fo,"EM",{});var Go=n(Pt);cs=s(Go,"Natural Language Processing with Transformers"),Go.forEach(r),Fo.forEach(r),ds=s(_e,". Il a plusieurs ann\xE9es d\u2019exp\xE9rience dans l\u2019industrie o\xF9 il a pu d\xE9ployer des projets de NLP en production et travailler sur toutes les \xE9tapes clefs du d\xE9ploiement."),_e.forEach(r),tr=d(t),Pe=l(t,"P",{});var Co=n(Pe);ms=s(Co,"\xCAtes-vous pr\xEAt \xE0 commencer ? Dans ce chapitre, vous apprendrez :"),Co.forEach(r),rr=d(t),q=l(t,"UL",{});var ze=n(q);ve=l(ze,"LI",{});var cr=n(ve);fs=s(cr,"\xE0 utiliser la fonction "),Lt=l(cr,"CODE",{});var Oo=n(Lt);hs=s(Oo,"pipeline()"),Oo.forEach(r),vs=s(cr," pour r\xE9soudre des probl\xE8mes de NLP comme la g\xE9n\xE9ration de texte et la classification,"),cr.forEach(r),gs=d(ze),ge=l(ze,"LI",{});var dr=n(ge);Es=s(dr,"l\u2019architecture d\u2019un "),yt=l(dr,"EM",{});var jo=n(yt);_s=s(jo,"transformer"),jo.forEach(r),bs=s(dr,","),dr.forEach(r),ws=d(ze),At=l(ze,"LI",{});var Bo=n(At);qs=s(Bo,"comment faire la distinction entre les diff\xE9rentes architectures d\u2019encodeur, de d\xE9codeur et d\u2019encodeur-d\xE9codeur ainsi que leurs diff\xE9rents cas d\u2019usage."),Bo.forEach(r),ze.forEach(r),this.h()},h(){i(P,"name","hf:doc:metadata"),i(P,"content",JSON.stringify(el)),i(D,"id","introduction"),i(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(D,"href","#introduction"),i(L,"class","relative group"),i(F,"id","bienvenue-au-cours"),i(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(F,"href","#bienvenue-au-cours"),i(y,"class","relative group"),i(X,"href","https://huggingface.co/"),i(X,"rel","nofollow"),i(G,"href","https://github.com/huggingface/transformers"),i(G,"rel","nofollow"),i(C,"href","https://github.com/huggingface/datasets"),i(C,"rel","nofollow"),i(O,"href","https://github.com/huggingface/tokenizers"),i(O,"rel","nofollow"),i(j,"href","https://github.com/huggingface/accelerate"),i(j,"rel","nofollow"),i(Z,"href","https://huggingface.co/models"),i(Z,"rel","nofollow"),i(B,"id","quoi-sattendre"),i(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(B,"href","#quoi-sattendre"),i(A,"class","relative group"),i(te,"class","block dark:hidden"),Ro(te.src,zs="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg")||i(te,"src",zs),i(te,"alt","Bref aper\xE7u du contenu du cours."),i(re,"class","hidden dark:block"),Ro(re.src,Is="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg")||i(re,"src",Is),i(re,"alt","Bref aper\xE7u des diff\xE9rents chapitres du cours."),i($,"class","flex justify-center"),i(ae,"href","https://huggingface.co/models"),i(ae,"rel","nofollow"),i(se,"href","https://www.fast.ai/"),i(se,"rel","nofollow"),i(oe,"href","https://course.fast.ai/"),i(oe,"rel","nofollow"),i(le,"href","https://www.deeplearning.ai/"),i(le,"rel","nofollow"),i(ne,"href","https://pytorch.org/"),i(ne,"rel","nofollow"),i(ie,"href","https://www.tensorflow.org/"),i(ie,"rel","nofollow"),i(ue,"href","https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh"),i(ue,"rel","nofollow"),i(U,"id","qui-sommesnous"),i(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(U,"href","#qui-sommesnous"),i(T,"class","relative group"),i(ce,"href","https://github.com/gradio-app/gradio"),i(ce,"rel","nofollow"),i(de,"href","https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/"),i(de,"rel","nofollow"),i(fe,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(fe,"rel","nofollow"),i(he,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(he,"rel","nofollow")},m(t,u){e(document.head,P),p(t,St,u),p(t,L,u),e(L,D),e(D,ke),Se(K,ke,null),e(L,fr),e(L,De),e(De,hr),p(t,Mt,u),Se(Q,t,u),p(t,Ht,u),p(t,y,u),e(y,F),e(F,Fe),Se(V,Fe,null),e(y,vr),e(y,Ge),e(Ge,gr),p(t,xt,u),Se(W,t,u),p(t,kt,u),p(t,m,u),e(m,Er),e(m,X),e(X,_r),e(m,br),e(m,G),e(G,wr),e(G,Ce),e(Ce,qr),e(m,Pr),e(m,C),e(C,Lr),e(C,Oe),e(Oe,yr),e(m,Ar),e(m,O),e(O,$r),e(O,je),e(je,Nr),e(m,zr),e(m,j),e(j,Ir),e(j,Be),e(Be,Tr),e(m,Sr),e(m,Z),e(Z,Re),e(Re,Mr),e(m,Hr),p(t,Dt,u),p(t,A,u),e(A,B),e(B,Ue),Se(ee,Ue,null),e(A,xr),e(A,Ye),e(Ye,kr),p(t,Ft,u),p(t,be,u),e(be,Dr),p(t,Gt,u),p(t,$,u),e($,te),e($,Fr),e($,re),p(t,Ct,u),p(t,b,u),e(b,f),e(f,Gr),e(f,Je),e(Je,Cr),e(f,Or),e(f,Ke),e(Ke,jr),e(f,Br),e(f,ae),e(ae,Qe),e(Qe,Rr),e(f,Ur),e(f,Ve),e(Ve,Yr),e(f,Jr),e(f,We),e(We,Kr),e(f,Qr),e(b,Vr),e(b,N),e(N,Wr),e(N,Xe),e(Xe,Xr),e(N,Zr),e(N,Ze),e(Ze,ea),e(N,ta),e(b,ra),e(b,z),e(z,aa),e(z,et),e(et,sa),e(z,oa),e(z,tt),e(tt,la),e(z,na),p(t,Ot,u),p(t,we,u),e(we,ia),p(t,jt,u),p(t,w,u),e(w,rt),e(rt,ua),e(w,pa),e(w,g),e(g,ca),e(g,se),e(se,da),e(g,ma),e(g,oe),e(oe,at),e(at,fa),e(g,ha),e(g,le),e(le,st),e(st,va),e(g,ga),e(w,Ea),e(w,I),e(I,_a),e(I,ne),e(ne,ba),e(I,wa),e(I,ie),e(ie,qa),e(I,Pa),p(t,Bt,u),p(t,R,u),e(R,La),e(R,ue),e(ue,ya),e(R,Aa),p(t,Rt,u),p(t,T,u),e(T,U),e(U,ot),Se(pe,ot,null),e(T,$a),e(T,lt),e(lt,Na),p(t,Ut,u),p(t,qe,u),e(qe,za),p(t,Yt,u),p(t,Y,u),e(Y,Ia),e(Y,ce),e(ce,Ta),e(Y,Sa),p(t,Jt,u),p(t,S,u),e(S,nt),e(nt,Ma),e(S,Ha),e(S,it),e(it,xa),e(S,ka),p(t,Kt,u),p(t,M,u),e(M,ut),e(ut,Da),e(M,Fa),e(M,pt),e(pt,Ga),e(M,Ca),p(t,Qt,u),p(t,E,u),e(E,ct),e(ct,Oa),e(E,ja),e(E,dt),e(dt,Ba),e(E,Ra),e(E,de),e(de,mt),e(mt,Ua),e(E,Ya),p(t,Vt,u),p(t,me,u),e(me,ft),e(ft,Ja),e(me,Ka),p(t,Wt,u),p(t,H,u),e(H,ht),e(ht,Qa),e(H,Va),e(H,vt),e(vt,Wa),e(H,Xa),p(t,Xt,u),p(t,x,u),e(x,gt),e(gt,Za),e(x,es),e(x,Et),e(Et,ts),e(x,rs),p(t,Zt,u),p(t,k,u),e(k,_t),e(_t,as),e(k,ss),e(k,fe),e(fe,bt),e(bt,os),e(k,ls),p(t,er,u),p(t,_,u),e(_,wt),e(wt,ns),e(_,is),e(_,qt),e(qt,us),e(_,ps),e(_,he),e(he,Pt),e(Pt,cs),e(_,ds),p(t,tr,u),p(t,Pe,u),e(Pe,ms),p(t,rr,u),p(t,q,u),e(q,ve),e(ve,fs),e(ve,Lt),e(Lt,hs),e(ve,vs),e(q,gs),e(q,ge),e(ge,Es),e(ge,yt),e(yt,_s),e(ge,bs),e(q,ws),e(q,At),e(At,qs),ar=!0},p:Qo,i(t){ar||(Me(K.$$.fragment,t),Me(Q.$$.fragment,t),Me(V.$$.fragment,t),Me(W.$$.fragment,t),Me(ee.$$.fragment,t),Me(pe.$$.fragment,t),ar=!0)},o(t){He(K.$$.fragment,t),He(Q.$$.fragment,t),He(V.$$.fragment,t),He(W.$$.fragment,t),He(ee.$$.fragment,t),He(pe.$$.fragment,t),ar=!1},d(t){r(P),t&&r(St),t&&r(L),xe(K),t&&r(Mt),xe(Q,t),t&&r(Ht),t&&r(y),xe(V),t&&r(xt),xe(W,t),t&&r(kt),t&&r(m),t&&r(Dt),t&&r(A),xe(ee),t&&r(Ft),t&&r(be),t&&r(Gt),t&&r($),t&&r(Ct),t&&r(b),t&&r(Ot),t&&r(we),t&&r(jt),t&&r(w),t&&r(Bt),t&&r(R),t&&r(Rt),t&&r(T),xe(pe),t&&r(Ut),t&&r(qe),t&&r(Yt),t&&r(Y),t&&r(Jt),t&&r(S),t&&r(Kt),t&&r(M),t&&r(Qt),t&&r(E),t&&r(Vt),t&&r(me),t&&r(Wt),t&&r(H),t&&r(Xt),t&&r(x),t&&r(Zt),t&&r(k),t&&r(er),t&&r(_),t&&r(tr),t&&r(Pe),t&&r(rr),t&&r(q)}}}const el={local:"introduction",sections:[{local:"bienvenue-au-cours",title:"Bienvenue au cours \u{1F917} !"},{local:"quoi-sattendre",title:"\xC0 quoi s'attendre ?"},{local:"qui-sommesnous",title:"Qui sommes-nous ?"}],title:"Introduction"};function tl(Ns){return Vo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ll extends Uo{constructor(P){super();Yo(this,P,tl,Zo,Jo,{})}}export{ll as default,el as metadata};
