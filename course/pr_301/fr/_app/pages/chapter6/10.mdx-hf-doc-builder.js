import{S as on,i as ln,s as un,e as n,k as u,w as m,t as d,M as pn,c as s,d as t,m as p,a as r,x as f,h as c,b as o,G as i,g as l,y as h,L as dn,q as v,o as $,B as g,v as cn}from"../../chunks/vendor-hf-doc-builder.js";import{I as x}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as mn}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import{Q as q}from"../../chunks/Question-hf-doc-builder.js";function fn(_i){let k,Ge,z,Q,we,V,Lt,_e,Ut,Re,G,Fe,ke,Ht,Je,w,L,Ee,R,Bt,F,Wt,be,jt,Dt,Ke,J,Xe,_,U,ye,K,Ot,X,Tt,Pe,Mt,Vt,Ye,Y,Ze,E,H,Ce,Z,Gt,ee,Rt,Ae,Ft,Jt,et,te,tt,b,B,Se,ie,Kt,y,Xt,Ne,Yt,Zt,Ie,ei,ti,it,ne,nt,P,W,Qe,se,ii,re,ni,Le,si,ri,st,ae,rt,C,j,Ue,oe,ai,He,oi,at,le,ot,A,D,Be,ue,li,pe,ui,We,pi,di,lt,de,ut,S,O,je,ce,ci,me,mi,De,fi,hi,pt,fe,dt,N,T,Oe,he,vi,ve,$i,Te,gi,xi,ct,$e,mt,I,M,Me,ge,qi,xe,ki,Ve,zi,wi,ft,qe,ht;return V=new x({}),G=new mn({props:{chapter:6,classNames:"absolute z-10 right-0 top-0"}}),R=new x({}),J=new q({props:{choices:[{text:"Lorsque votre jeu de donn\xE9es est similaire \xE0 celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous voulez pr\xE9-entra\xEEner un nouveau mod\xE8le",explain:"Dans ce cas, pour \xE9conomiser du temps et des ressources de calcul, il est pr\xE9f\xE9rable d'utiliser le m\xEAme <i>tokenizer</i> que le mod\xE8le pr\xE9-entra\xEEn\xE9 et de <i>finetuner</i> ce mod\xE8le \xE0 la place."},{text:"Lorsque votre jeu de donn\xE9es est similaire \xE0 celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous souhaitez <i>finetuner</i> un nouveau mod\xE8le en utilisant ce mod\xE8le pr\xE9-entra\xEEn\xE9.",explain:"Pour <i>finetuner</i> un mod\xE8le \xE0 partir d'un mod\xE8le pr\xE9-entra\xEEn\xE9, vous devez toujours utiliser le m\xEAme <i>tokenizer</i>."},{text:"Lorsque votre jeu de donn\xE9es est diff\xE9rent de celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous souhaitez pr\xE9-entra\xEEner un nouveau mod\xE8le.",explain:"Dans ce cas, il n'y a aucun avantage \xE0 utiliser le m\xEAme <i>tokenizer</i>.",correct:!0},{text:"Lorsque votre jeu de donn\xE9es est diff\xE9rent de celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant mais que vous souhaitez <i>finetuner</i> un nouveau mod\xE8le en utilisant ce mod\xE8le pr\xE9-entra\xEEn\xE9.",explain:"Pour <i>finetuner</i> un mod\xE8le \xE0 partir d'un mod\xE8le pr\xE9-entra\xEEn\xE9, vous devez toujours utiliser le m\xEAme <i>tokenizer</i>."}]}}),K=new x({}),Y=new q({props:{choices:[{text:"C'est le seul type que la m\xE9thode <code>train_new_from_iterator()</code> accepte.",explain:"Une liste de listes de textes est un type particulier de g\xE9n\xE9rateur de listes de textes, la m\xE9thode l'acceptera donc aussi. Essayez \xE0 nouveau !"},{text:"Vous \xE9viterez de charger l'ensemble des donn\xE9es en m\xE9moire en une seule fois.",explain:"Chaque batch de textes sera lib\xE9r\xE9 de la m\xE9moire lorsque vous it\xE9rerez et le gain sera particuli\xE8rement visible si vous utilisez des \u{1F917} <i>Datasets</i> pour stocker vos textes.",correct:!0},{text:"Cela permettra \xE0 la biblioth\xE8que \u{1F917} <i>Tokenizers</i> d'utiliser le multitraitement.",explain:"Il utilisera le multiprocesseur dans tous les cas."},{text:"Le <i>tokenizer</i> que vous entra\xEEnez g\xE9n\xE9rera de meilleurs textes.",explain:"Le <i>tokenizer</i> ne g\xE9n\xE8re pas de texte. Vous le confondez avec un mod\xE8le de langage ?"}]}}),Z=new x({}),te=new q({props:{choices:[{text:"Il peut traiter les entr\xE9es plus rapidement qu'un <i>tokenizer</i> lent lorsque vous faites des batchs d'entr\xE9es.",explain:"Gr\xE2ce au parall\xE9lisme impl\xE9ment\xE9 dans Rust, il sera plus rapide sur les batchs d'entr\xE9es. Quel autre avantage pouvez-vous imaginer ?",correct:!0},{text:"Les <i>tokenizers</i> rapides sont toujours plus rapides que leurs homologues lents.",explain:"Un <i>tokenizer</i> rapide peut en fait \xEAtre plus lent si vous ne lui donnez qu'un seul ou tr\xE8s peu de textes, car il ne peut pas utiliser le parall\xE9lisme."},{text:"Il peut appliquer le <i>padding</i> et la troncature.",explain:"C'est vrai, mais les <i>tokenizers</i> lents le font aussi."},{text:"Il poss\xE8de des fonctionnalit\xE9s suppl\xE9mentaires qui vous permettent d'associer les <i>tokens</i> \xE0 l'extrait de texte qui les a cr\xE9\xE9s.",explain:"En effet, c'est ce qu'on appelle des correspondances d'<i>offset</i>. Ce n'est pas le seul avantage, cependant.",correct:!0}]}}),ie=new x({}),ne=new q({props:{choices:[{text:"Les entit\xE9s ayant la m\xEAme \xE9tiquette sont fusionn\xE9es en une seule entit\xE9.",explain:"C'est un peu trop simplifier les choses. Essayez encore !"},{text:"Il existe une \xE9tiquette pour le d\xE9but d'une entit\xE9 et une \xE9tiquette pour la suite d'une entit\xE9.",explain:" ",correct:!0},{text:"Dans un mot donn\xE9, tant que le premier <i>token</i> porte l'\xE9tiquette de l'entit\xE9, le mot entier est consid\xE9r\xE9 comme \xE9tiquet\xE9 avec cette entit\xE9.",explain:"C'est une strat\xE9gie pour g\xE9rer les entit\xE9s. Quelles autres r\xE9ponses s'appliquent ici ?",correct:!0},{text:"Lorsqu'un <i>token</i> a l'\xE9tiquette d'une entit\xE9 donn\xE9e, tout autre <i>token</i> suivant ayant la m\xEAme \xE9tiquette est consid\xE9r\xE9 comme faisant partie de la m\xEAme entit\xE9, \xE0 moins qu'il ne soit \xE9tiquet\xE9 comme le d\xE9but d'une nouvelle entit\xE9.",explain:"C'est la fa\xE7on la plus courante de regrouper des entit\xE9s, mais ce n'est pas la seule bonne r\xE9ponse.",correct:!0}]}}),se=new x({}),ae=new q({props:{choices:[{text:"Ce n'est pas vraiment le cas car il tronque le long contexte \xE0 la longueur maximale accept\xE9e par le mod\xE8le.",explain:"Il existe une astuce que vous pouvez utiliser pour g\xE9rer les longs contextes. Vous en souvenez-vous ?"},{text:"Il divise le contexte en plusieurs parties et fait la moyenne des r\xE9sultats obtenus.",explain:"Cela n'aurait pas de sens de faire la moyenne des r\xE9sultats car certaines parties du contexte n'incluront pas la r\xE9ponse."},{text:"Il divise le contexte en plusieurs parties (avec chevauchement) et trouve le score maximum pour une r\xE9ponse dans chaque partie.",explain:"C'est la bonne r\xE9ponse !",correct:!0},{text:"Il divise le contexte en plusieurs parties (sans chevauchemen par souci d'efficacit\xE9) et trouve le score maximum pour une r\xE9ponse dans chaque partie.",explain:"Il comprend un certain chevauchement entre les parties pour \xE9viter une situation o\xF9 la r\xE9ponse serait divis\xE9e en deux parties."}]}}),oe=new x({}),le=new q({props:{choices:[{text:"C'est le nettoyage que le <i>tokenizer</i> effectue sur les textes lors des \xE9tapes initiales.",explain:"Par exemple, il peut s'agir de supprimer les accents ou les espaces, ou de mettre les entr\xE9es en minuscules.",correct:!0},{text:"Il s'agit d'une technique d'augmentation de donn\xE9es qui consiste \xE0 rendre le texte plus normal en supprimant les mots rares.",explain:"Essayez encore."},{text:"C'est l'\xE9tape finale du post-traitement o\xF9 le <i>tokenizer</i> ajoute les <i>tokens</i> sp\xE9ciaux.",explain:"Cette \xE9tape est simplement appel\xE9e post-traitement."},{text:"C'est lorsque les ench\xE2ssements sont faits avec une moyenne nulle et un \xE9cart-type de 1, en soustrayant la moyenne et en divisant par l'\xE9cart-type.",explain:"Ce processus est commun\xE9ment appel\xE9 normalisation lorsqu'il est appliqu\xE9 aux valeurs des pixels en vision par ordinateur, mais ce n'est pas ce que signifie la normalisation en NLP."}]}}),ue=new x({}),de=new q({props:{choices:[{text:"C'est l'\xE9tape qui pr\xE9c\xE8de la tok\xE9nisation, o\xF9 l'augmentation des donn\xE9es (comme le masquage al\xE9atoire) est appliqu\xE9e.",explain:"Cette \xE9tape fait partie du pr\xE9traitement."},{text:"C'est l'\xE9tape avant la tok\xE9nisation, o\xF9 les op\xE9rations de nettoyage souhait\xE9es sont appliqu\xE9es au texte.",explain:"C'est l'\xE9tape de normalisation."},{text:"C'est l'\xE9tape qui pr\xE9c\xE8de l'application du mod\xE8le <i>tokenizer</i>, pour diviser l'entr\xE9e en mots.",explain:"C'est la bonne r\xE9ponse !",correct:!0},{text:"Il s'agit de l'\xE9tape pr\xE9c\xE9dant l'application du mod\xE8le <i>tokenizer</i>, qui divise l'entr\xE9e en <i>tokens</i>.",explain:"La division en <i>tokens</i> est le travail du mod\xE8le <i>tokenizer</i>."}]}}),ce=new x({}),fe=new q({props:{choices:[{text:"BPE est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est le cas en effet !",correct:!0},{text:"BPE est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:"C'est l'approche adopt\xE9e par un algorithme de tok\xE9nisation diff\xE9rent."},{text:"Un <i>tokenizer</i> BPE apprend les r\xE8gles de fusion en fusionnant la paire de <i>tokens</i> la plus fr\xE9quente.",explain:"C'est exact !",correct:!0},{text:"Un <i>tokenizer</i> BPE apprend une r\xE8gle de fusion en fusionnant la paire de <i>tokens</i> qui maximise un score qui privil\xE9gie les paires fr\xE9quentes avec des parties individuelles moins fr\xE9quentes.",explain:"C'est la strat\xE9gie appliqu\xE9e par un autre algorithme de tokenization."},{text:"BPE tokenise les mots en sous-mots en les divisant en caract\xE8res, puis en appliquant les r\xE8gles de fusion.",explain:" ",correct:!0},{text:"BPE tokenise les mots en sous-mots en trouvant le plus long sous-mot du vocabulaire en commen\xE7ant par le d\xE9but, puis en r\xE9p\xE9tant le processus pour le reste du texte.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."}]}}),he=new x({}),$e=new q({props:{choices:[{text:"WordPiece est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est le cas en effet !",correct:!0},{text:"WordPiece est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"WordPiece Les <i>tokenizer</i> apprennent les r\xE8gles de fusion en fusionnant la paire de <i>tokens</i> la plus fr\xE9quente.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"Un <i>tokenizer</i> WordPiece apprend une r\xE8gle de fusion en fusionnant la paire de <i>tokens</i> qui maximise un score qui privil\xE9gie les paires fr\xE9quentes avec des parties individuelles moins fr\xE9quentes.",explain:" ",correct:!0},{text:"WordPiece tokenise les mots en sous-mots en trouvant la segmentation en <i>tokens</i> la plus probable, selon le mod\xE8le.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"WordPiece tokenise les mots en sous-mots en trouvant le plus long sous-mot du vocabulaire en commen\xE7ant par le d\xE9but, puis en r\xE9p\xE9tant le processus pour le reste du texte.",explain:"C'est ainsi que WordPiece proc\xE8de pour l'encodage.",correct:!0}]}}),ge=new x({}),qe=new q({props:{choices:[{text:"Unigram est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"Unigram est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:" ",correct:!0},{text:"Unigram adapte son vocabulaire en minimisant une perte calcul\xE9e sur l'ensemble du corpus.",explain:" ",correct:!0},{text:"Unigram adapte son vocabulaire en conservant les sous-mots les plus fr\xE9quents.",explain:" "},{text:"Unigram segmente les mots en sous-mots en trouvant la segmentation la plus probable en <i>tokens</i>, selon le mod\xE8le.",explain:" ",correct:!0},{text:"Unigram d\xE9compose les mots en sous-mots en les divisant en caract\xE8res puis en appliquant les r\xE8gles de fusion.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."}]}}),{c(){k=n("meta"),Ge=u(),z=n("h1"),Q=n("a"),we=n("span"),m(V.$$.fragment),Lt=u(),_e=n("span"),Ut=d("Quiz de fin de chapitre"),Re=u(),m(G.$$.fragment),Fe=u(),ke=n("p"),Ht=d("Testons ce que vous avez appris dans ce chapitre !"),Je=u(),w=n("h3"),L=n("a"),Ee=n("span"),m(R.$$.fragment),Bt=u(),F=n("span"),Wt=d("1. Quand devez-vous entra\xEEner un nouveau "),be=n("i"),jt=d("tokenizer"),Dt=d(" ?"),Ke=u(),m(J.$$.fragment),Xe=u(),_=n("h3"),U=n("a"),ye=n("span"),m(K.$$.fragment),Ot=u(),X=n("span"),Tt=d("2. Quel est l\u2019avantage d\u2019utiliser un g\xE9n\xE9rateur de listes par rapport \xE0 une liste de listes lors de l\u2019utilisation de "),Pe=n("code"),Mt=d("train_new_from_iterator()"),Vt=d(" ?"),Ye=u(),m(Y.$$.fragment),Ze=u(),E=n("h3"),H=n("a"),Ce=n("span"),m(Z.$$.fragment),Gt=u(),ee=n("span"),Rt=d("3. Quels sont les avantages d\u2019utiliser un "),Ae=n("i"),Ft=d("tokenizer"),Jt=d(" \xAB rapide \xBB ?"),et=u(),m(te.$$.fragment),tt=u(),b=n("h3"),B=n("a"),Se=n("span"),m(ie.$$.fragment),Kt=u(),y=n("span"),Xt=d("4. Comment le pipeline "),Ne=n("code"),Yt=d("token-classification"),Zt=d(" g\xE8re-t-il les entit\xE9s qui s\u2019\xE9tendent sur plusieurs "),Ie=n("i"),ei=d("tokens"),ti=d(" ?"),it=u(),m(ne.$$.fragment),nt=u(),P=n("h3"),W=n("a"),Qe=n("span"),m(se.$$.fragment),ii=u(),re=n("span"),ni=d("5. Comment le pipeline "),Le=n("code"),si=d("question-answering"),ri=d(" g\xE8re-t-il les contextes longs ?"),st=u(),m(ae.$$.fragment),rt=u(),C=n("h3"),j=n("a"),Ue=n("span"),m(oe.$$.fragment),ai=u(),He=n("span"),oi=d("6. Qu\u2019est-ce que la normalisation ?"),at=u(),m(le.$$.fragment),ot=u(),A=n("h3"),D=n("a"),Be=n("span"),m(ue.$$.fragment),li=u(),pe=n("span"),ui=d("7. Qu\u2019est-ce que la pr\xE9-tok\xE9nisation pour un "),We=n("i"),pi=d("tokenizer"),di=d(" en sous-mots ?"),lt=u(),m(de.$$.fragment),ut=u(),S=n("h3"),O=n("a"),je=n("span"),m(ce.$$.fragment),ci=u(),me=n("span"),mi=d("8. S\xE9lectionnez les phrases qui s\u2019appliquent au "),De=n("i"),fi=d("tokenizer"),hi=d(" BPE."),pt=u(),m(fe.$$.fragment),dt=u(),N=n("h3"),T=n("a"),Oe=n("span"),m(he.$$.fragment),vi=u(),ve=n("span"),$i=d("9. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Te=n("i"),gi=d("tokenizer"),xi=d(" WordPiece."),ct=u(),m($e.$$.fragment),mt=u(),I=n("h3"),M=n("a"),Me=n("span"),m(ge.$$.fragment),qi=u(),xe=n("span"),ki=d("10. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Ve=n("i"),zi=d("tokenizer"),wi=d(" Unigram."),ft=u(),m(qe.$$.fragment),this.h()},l(e){const a=pn('[data-svelte="svelte-1phssyn"]',document.head);k=s(a,"META",{name:!0,content:!0}),a.forEach(t),Ge=p(e),z=s(e,"H1",{class:!0});var vt=r(z);Q=s(vt,"A",{id:!0,class:!0,href:!0});var Ei=r(Q);we=s(Ei,"SPAN",{});var bi=r(we);f(V.$$.fragment,bi),bi.forEach(t),Ei.forEach(t),Lt=p(vt),_e=s(vt,"SPAN",{});var yi=r(_e);Ut=c(yi,"Quiz de fin de chapitre"),yi.forEach(t),vt.forEach(t),Re=p(e),f(G.$$.fragment,e),Fe=p(e),ke=s(e,"P",{});var Pi=r(ke);Ht=c(Pi,"Testons ce que vous avez appris dans ce chapitre !"),Pi.forEach(t),Je=p(e),w=s(e,"H3",{class:!0});var $t=r(w);L=s($t,"A",{id:!0,class:!0,href:!0});var Ci=r(L);Ee=s(Ci,"SPAN",{});var Ai=r(Ee);f(R.$$.fragment,Ai),Ai.forEach(t),Ci.forEach(t),Bt=p($t),F=s($t,"SPAN",{});var gt=r(F);Wt=c(gt,"1. Quand devez-vous entra\xEEner un nouveau "),be=s(gt,"I",{});var Si=r(be);jt=c(Si,"tokenizer"),Si.forEach(t),Dt=c(gt," ?"),gt.forEach(t),$t.forEach(t),Ke=p(e),f(J.$$.fragment,e),Xe=p(e),_=s(e,"H3",{class:!0});var xt=r(_);U=s(xt,"A",{id:!0,class:!0,href:!0});var Ni=r(U);ye=s(Ni,"SPAN",{});var Ii=r(ye);f(K.$$.fragment,Ii),Ii.forEach(t),Ni.forEach(t),Ot=p(xt),X=s(xt,"SPAN",{});var qt=r(X);Tt=c(qt,"2. Quel est l\u2019avantage d\u2019utiliser un g\xE9n\xE9rateur de listes par rapport \xE0 une liste de listes lors de l\u2019utilisation de "),Pe=s(qt,"CODE",{});var Qi=r(Pe);Mt=c(Qi,"train_new_from_iterator()"),Qi.forEach(t),Vt=c(qt," ?"),qt.forEach(t),xt.forEach(t),Ye=p(e),f(Y.$$.fragment,e),Ze=p(e),E=s(e,"H3",{class:!0});var kt=r(E);H=s(kt,"A",{id:!0,class:!0,href:!0});var Li=r(H);Ce=s(Li,"SPAN",{});var Ui=r(Ce);f(Z.$$.fragment,Ui),Ui.forEach(t),Li.forEach(t),Gt=p(kt),ee=s(kt,"SPAN",{});var zt=r(ee);Rt=c(zt,"3. Quels sont les avantages d\u2019utiliser un "),Ae=s(zt,"I",{});var Hi=r(Ae);Ft=c(Hi,"tokenizer"),Hi.forEach(t),Jt=c(zt," \xAB rapide \xBB ?"),zt.forEach(t),kt.forEach(t),et=p(e),f(te.$$.fragment,e),tt=p(e),b=s(e,"H3",{class:!0});var wt=r(b);B=s(wt,"A",{id:!0,class:!0,href:!0});var Bi=r(B);Se=s(Bi,"SPAN",{});var Wi=r(Se);f(ie.$$.fragment,Wi),Wi.forEach(t),Bi.forEach(t),Kt=p(wt),y=s(wt,"SPAN",{});var ze=r(y);Xt=c(ze,"4. Comment le pipeline "),Ne=s(ze,"CODE",{});var ji=r(Ne);Yt=c(ji,"token-classification"),ji.forEach(t),Zt=c(ze," g\xE8re-t-il les entit\xE9s qui s\u2019\xE9tendent sur plusieurs "),Ie=s(ze,"I",{});var Di=r(Ie);ei=c(Di,"tokens"),Di.forEach(t),ti=c(ze," ?"),ze.forEach(t),wt.forEach(t),it=p(e),f(ne.$$.fragment,e),nt=p(e),P=s(e,"H3",{class:!0});var _t=r(P);W=s(_t,"A",{id:!0,class:!0,href:!0});var Oi=r(W);Qe=s(Oi,"SPAN",{});var Ti=r(Qe);f(se.$$.fragment,Ti),Ti.forEach(t),Oi.forEach(t),ii=p(_t),re=s(_t,"SPAN",{});var Et=r(re);ni=c(Et,"5. Comment le pipeline "),Le=s(Et,"CODE",{});var Mi=r(Le);si=c(Mi,"question-answering"),Mi.forEach(t),ri=c(Et," g\xE8re-t-il les contextes longs ?"),Et.forEach(t),_t.forEach(t),st=p(e),f(ae.$$.fragment,e),rt=p(e),C=s(e,"H3",{class:!0});var bt=r(C);j=s(bt,"A",{id:!0,class:!0,href:!0});var Vi=r(j);Ue=s(Vi,"SPAN",{});var Gi=r(Ue);f(oe.$$.fragment,Gi),Gi.forEach(t),Vi.forEach(t),ai=p(bt),He=s(bt,"SPAN",{});var Ri=r(He);oi=c(Ri,"6. Qu\u2019est-ce que la normalisation ?"),Ri.forEach(t),bt.forEach(t),at=p(e),f(le.$$.fragment,e),ot=p(e),A=s(e,"H3",{class:!0});var yt=r(A);D=s(yt,"A",{id:!0,class:!0,href:!0});var Fi=r(D);Be=s(Fi,"SPAN",{});var Ji=r(Be);f(ue.$$.fragment,Ji),Ji.forEach(t),Fi.forEach(t),li=p(yt),pe=s(yt,"SPAN",{});var Pt=r(pe);ui=c(Pt,"7. Qu\u2019est-ce que la pr\xE9-tok\xE9nisation pour un "),We=s(Pt,"I",{});var Ki=r(We);pi=c(Ki,"tokenizer"),Ki.forEach(t),di=c(Pt," en sous-mots ?"),Pt.forEach(t),yt.forEach(t),lt=p(e),f(de.$$.fragment,e),ut=p(e),S=s(e,"H3",{class:!0});var Ct=r(S);O=s(Ct,"A",{id:!0,class:!0,href:!0});var Xi=r(O);je=s(Xi,"SPAN",{});var Yi=r(je);f(ce.$$.fragment,Yi),Yi.forEach(t),Xi.forEach(t),ci=p(Ct),me=s(Ct,"SPAN",{});var At=r(me);mi=c(At,"8. S\xE9lectionnez les phrases qui s\u2019appliquent au "),De=s(At,"I",{});var Zi=r(De);fi=c(Zi,"tokenizer"),Zi.forEach(t),hi=c(At," BPE."),At.forEach(t),Ct.forEach(t),pt=p(e),f(fe.$$.fragment,e),dt=p(e),N=s(e,"H3",{class:!0});var St=r(N);T=s(St,"A",{id:!0,class:!0,href:!0});var en=r(T);Oe=s(en,"SPAN",{});var tn=r(Oe);f(he.$$.fragment,tn),tn.forEach(t),en.forEach(t),vi=p(St),ve=s(St,"SPAN",{});var Nt=r(ve);$i=c(Nt,"9. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Te=s(Nt,"I",{});var nn=r(Te);gi=c(nn,"tokenizer"),nn.forEach(t),xi=c(Nt," WordPiece."),Nt.forEach(t),St.forEach(t),ct=p(e),f($e.$$.fragment,e),mt=p(e),I=s(e,"H3",{class:!0});var It=r(I);M=s(It,"A",{id:!0,class:!0,href:!0});var sn=r(M);Me=s(sn,"SPAN",{});var rn=r(Me);f(ge.$$.fragment,rn),rn.forEach(t),sn.forEach(t),qi=p(It),xe=s(It,"SPAN",{});var Qt=r(xe);ki=c(Qt,"10. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Ve=s(Qt,"I",{});var an=r(Ve);zi=c(an,"tokenizer"),an.forEach(t),wi=c(Qt," Unigram."),Qt.forEach(t),It.forEach(t),ft=p(e),f(qe.$$.fragment,e),this.h()},h(){o(k,"name","hf:doc:metadata"),o(k,"content",JSON.stringify(hn)),o(Q,"id","quiz-de-fin-de-chapitre"),o(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(Q,"href","#quiz-de-fin-de-chapitre"),o(z,"class","relative group"),o(L,"id","1.-quand-devez-vous-entra\xEEner-un-nouveau-<i>tokenizer</i>-?"),o(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(L,"href","#1.-quand-devez-vous-entra\xEEner-un-nouveau-<i>tokenizer</i>-?"),o(w,"class","relative group"),o(U,"id","2.-quel-est-l\u2019avantage-d\u2019utiliser-un-g\xE9n\xE9rateur-de-listes-par-rapport-\xE0-une-liste-de-listes-lors-de-l\u2019utilisation-de-<code>train_new_from_iterator()</code>-?"),o(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(U,"href","#2.-quel-est-l\u2019avantage-d\u2019utiliser-un-g\xE9n\xE9rateur-de-listes-par-rapport-\xE0-une-liste-de-listes-lors-de-l\u2019utilisation-de-<code>train_new_from_iterator()</code>-?"),o(_,"class","relative group"),o(H,"id","3.-quels-sont-les-avantages-d\u2019utiliser-un-<i>tokenizer</i>-\xAB-rapide-\xBB-?"),o(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(H,"href","#3.-quels-sont-les-avantages-d\u2019utiliser-un-<i>tokenizer</i>-\xAB-rapide-\xBB-?"),o(E,"class","relative group"),o(B,"id","4.-comment-le-pipeline-<code>token-classification</code>-g\xE8re-t-il-les-entit\xE9s-qui-s\u2019\xE9tendent-sur-plusieurs-<i>tokens</i>-?"),o(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(B,"href","#4.-comment-le-pipeline-<code>token-classification</code>-g\xE8re-t-il-les-entit\xE9s-qui-s\u2019\xE9tendent-sur-plusieurs-<i>tokens</i>-?"),o(b,"class","relative group"),o(W,"id","5.-comment-le-pipeline-<code>question-answering</code>-g\xE8re-t-il-les-contextes-longs-?"),o(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(W,"href","#5.-comment-le-pipeline-<code>question-answering</code>-g\xE8re-t-il-les-contextes-longs-?"),o(P,"class","relative group"),o(j,"id","6.-qu\u2019est-ce-que-la-normalisation-?"),o(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(j,"href","#6.-qu\u2019est-ce-que-la-normalisation-?"),o(C,"class","relative group"),o(D,"id","7.-qu\u2019est-ce-que-la-pr\xE9-tok\xE9nisation-pour-un-<i>tokenizer</i>-en-sous-mots-?"),o(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(D,"href","#7.-qu\u2019est-ce-que-la-pr\xE9-tok\xE9nisation-pour-un-<i>tokenizer</i>-en-sous-mots-?"),o(A,"class","relative group"),o(O,"id","8.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-bpe."),o(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(O,"href","#8.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-bpe."),o(S,"class","relative group"),o(T,"id","9.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-wordpiece."),o(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(T,"href","#9.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-wordpiece."),o(N,"class","relative group"),o(M,"id","10.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-unigram."),o(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(M,"href","#10.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-unigram."),o(I,"class","relative group")},m(e,a){i(document.head,k),l(e,Ge,a),l(e,z,a),i(z,Q),i(Q,we),h(V,we,null),i(z,Lt),i(z,_e),i(_e,Ut),l(e,Re,a),h(G,e,a),l(e,Fe,a),l(e,ke,a),i(ke,Ht),l(e,Je,a),l(e,w,a),i(w,L),i(L,Ee),h(R,Ee,null),i(w,Bt),i(w,F),i(F,Wt),i(F,be),i(be,jt),i(F,Dt),l(e,Ke,a),h(J,e,a),l(e,Xe,a),l(e,_,a),i(_,U),i(U,ye),h(K,ye,null),i(_,Ot),i(_,X),i(X,Tt),i(X,Pe),i(Pe,Mt),i(X,Vt),l(e,Ye,a),h(Y,e,a),l(e,Ze,a),l(e,E,a),i(E,H),i(H,Ce),h(Z,Ce,null),i(E,Gt),i(E,ee),i(ee,Rt),i(ee,Ae),i(Ae,Ft),i(ee,Jt),l(e,et,a),h(te,e,a),l(e,tt,a),l(e,b,a),i(b,B),i(B,Se),h(ie,Se,null),i(b,Kt),i(b,y),i(y,Xt),i(y,Ne),i(Ne,Yt),i(y,Zt),i(y,Ie),i(Ie,ei),i(y,ti),l(e,it,a),h(ne,e,a),l(e,nt,a),l(e,P,a),i(P,W),i(W,Qe),h(se,Qe,null),i(P,ii),i(P,re),i(re,ni),i(re,Le),i(Le,si),i(re,ri),l(e,st,a),h(ae,e,a),l(e,rt,a),l(e,C,a),i(C,j),i(j,Ue),h(oe,Ue,null),i(C,ai),i(C,He),i(He,oi),l(e,at,a),h(le,e,a),l(e,ot,a),l(e,A,a),i(A,D),i(D,Be),h(ue,Be,null),i(A,li),i(A,pe),i(pe,ui),i(pe,We),i(We,pi),i(pe,di),l(e,lt,a),h(de,e,a),l(e,ut,a),l(e,S,a),i(S,O),i(O,je),h(ce,je,null),i(S,ci),i(S,me),i(me,mi),i(me,De),i(De,fi),i(me,hi),l(e,pt,a),h(fe,e,a),l(e,dt,a),l(e,N,a),i(N,T),i(T,Oe),h(he,Oe,null),i(N,vi),i(N,ve),i(ve,$i),i(ve,Te),i(Te,gi),i(ve,xi),l(e,ct,a),h($e,e,a),l(e,mt,a),l(e,I,a),i(I,M),i(M,Me),h(ge,Me,null),i(I,qi),i(I,xe),i(xe,ki),i(xe,Ve),i(Ve,zi),i(xe,wi),l(e,ft,a),h(qe,e,a),ht=!0},p:dn,i(e){ht||(v(V.$$.fragment,e),v(G.$$.fragment,e),v(R.$$.fragment,e),v(J.$$.fragment,e),v(K.$$.fragment,e),v(Y.$$.fragment,e),v(Z.$$.fragment,e),v(te.$$.fragment,e),v(ie.$$.fragment,e),v(ne.$$.fragment,e),v(se.$$.fragment,e),v(ae.$$.fragment,e),v(oe.$$.fragment,e),v(le.$$.fragment,e),v(ue.$$.fragment,e),v(de.$$.fragment,e),v(ce.$$.fragment,e),v(fe.$$.fragment,e),v(he.$$.fragment,e),v($e.$$.fragment,e),v(ge.$$.fragment,e),v(qe.$$.fragment,e),ht=!0)},o(e){$(V.$$.fragment,e),$(G.$$.fragment,e),$(R.$$.fragment,e),$(J.$$.fragment,e),$(K.$$.fragment,e),$(Y.$$.fragment,e),$(Z.$$.fragment,e),$(te.$$.fragment,e),$(ie.$$.fragment,e),$(ne.$$.fragment,e),$(se.$$.fragment,e),$(ae.$$.fragment,e),$(oe.$$.fragment,e),$(le.$$.fragment,e),$(ue.$$.fragment,e),$(de.$$.fragment,e),$(ce.$$.fragment,e),$(fe.$$.fragment,e),$(he.$$.fragment,e),$($e.$$.fragment,e),$(ge.$$.fragment,e),$(qe.$$.fragment,e),ht=!1},d(e){t(k),e&&t(Ge),e&&t(z),g(V),e&&t(Re),g(G,e),e&&t(Fe),e&&t(ke),e&&t(Je),e&&t(w),g(R),e&&t(Ke),g(J,e),e&&t(Xe),e&&t(_),g(K),e&&t(Ye),g(Y,e),e&&t(Ze),e&&t(E),g(Z),e&&t(et),g(te,e),e&&t(tt),e&&t(b),g(ie),e&&t(it),g(ne,e),e&&t(nt),e&&t(P),g(se),e&&t(st),g(ae,e),e&&t(rt),e&&t(C),g(oe),e&&t(at),g(le,e),e&&t(ot),e&&t(A),g(ue),e&&t(lt),g(de,e),e&&t(ut),e&&t(S),g(ce),e&&t(pt),g(fe,e),e&&t(dt),e&&t(N),g(he),e&&t(ct),g($e,e),e&&t(mt),e&&t(I),g(ge),e&&t(ft),g(qe,e)}}}const hn={local:"quiz-de-fin-de-chapitre",title:"Quiz de fin de chapitre"};function vn(_i){return cn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class kn extends on{constructor(k){super();ln(this,k,vn,fn,un,{})}}export{kn as default,hn as metadata};
