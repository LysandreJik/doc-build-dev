import{S as xr,i as _r,s as br,e as s,k as f,w as b,t as N,l as qr,M as wr,c as o,d as t,m,x as w,a,h as M,b as l,G as r,g as d,y as A,o as q,p as gr,q as g,B as y,v as Ar,n as kr}from"../../chunks/vendor-hf-doc-builder.js";import{I as T}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Bt}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as yr}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import{Q as C}from"../../chunks/Question-hf-doc-builder.js";import{F as zr}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Er(H){let p,c,$,h,E,k,S,z,v,P;return h=new T({}),v=new C({props:{choices:[{text:"Un mod\xE8le qui s'entra\xEEne automatiquement sur vos donn\xE9es",explain:"Vous confondez cela avec notre produit <a href='https://huggingface.co/autotrain>AutoTrain</a>"},{text:"Un objet qui renvoie la bonne architecture bas\xE9e sur le <i>checkpoint</i> .",explain:"Exactement : <code>TFAutoModel</code> a seulement besoin de conna\xEEtre le <i>checkpoint</i> \xE0 partir duquel il doit s'initialiser pour retourner \xE0 la bonne architecture.",correct:!0},{text:"Un mod\xE8le qui d\xE9tecte automatiquement la langue utilis\xE9e pour ses entr\xE9es afin de charger les bonnes pond\xE9rations.",explain:"Bien que certains <i>checkpoints</i> et mod\xE8les soient capables de g\xE9rer plusieurs langues, il n'existe pas d'outils int\xE9gr\xE9s pour la s\xE9lection automatique des <i>checkpoints</i> en fonction de la langue. Vous devez vous rendre sur le <a href='https://huggingface.co/models'>Hub des mod\xE8les</a> pour trouver le meilleur <i>checkpoint</i> pour votre t\xE2che !"}]}}),{c(){p=s("h3"),c=s("a"),$=s("span"),b(h.$$.fragment),E=f(),k=s("span"),S=N("5. What is an AutoModel?"),z=f(),b(v.$$.fragment),this.h()},l(i){p=o(i,"H3",{class:!0});var x=a(p);c=o(x,"A",{id:!0,class:!0,href:!0});var n=a(c);$=o(n,"SPAN",{});var _=a($);w(h.$$.fragment,_),_.forEach(t),n.forEach(t),E=m(x),k=o(x,"SPAN",{});var L=a(k);S=M(L,"5. What is an AutoModel?"),L.forEach(t),x.forEach(t),z=m(i),w(v.$$.fragment,i),this.h()},h(){l(c,"id","5.-what-is-an-automodel?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#5.-what-is-an-automodel?"),l(p,"class","relative group")},m(i,x){d(i,p,x),r(p,c),r(c,$),A(h,$,null),r(p,E),r(p,k),r(k,S),d(i,z,x),A(v,i,x),P=!0},i(i){P||(g(h.$$.fragment,i),g(v.$$.fragment,i),P=!0)},o(i){q(h.$$.fragment,i),q(v.$$.fragment,i),P=!1},d(i){i&&t(p),y(h),i&&t(z),y(v,i)}}}function Pr(H){let p,c,$,h,E,k,S,z,v,P;return h=new T({}),v=new C({props:{choices:[{text:"Un mod\xE8le qui s'entra\xEEne automatiquement sur vos donn\xE9es",explain:"Vous confondez cela avec notre produit <a href='https://huggingface.co/autotrain>AutoTrain</a>"},{text:"Un objet qui renvoie la bonne architecture bas\xE9e sur le <i>checkpoint</i> .",explain:"Exactement : <code>AutoModel</code> a seulement besoin de conna\xEEtre le <i>checkpoint</i> \xE0 partir duquel il doit s'initialiser pour retourner \xE0 la bonne architecture.",correct:!0},{text:"Un mod\xE8le qui d\xE9tecte automatiquement la langue utilis\xE9e pour ses entr\xE9es afin de charger les bonnes pond\xE9rations.",explain:"Bien que certains <i>checkpoints</i> et mod\xE8les soient capables de g\xE9rer plusieurs langues, il n'existe pas d'outils int\xE9gr\xE9s pour la s\xE9lection automatique des <i>checkpoints</i> en fonction de la langue. Vous devez vous rendre sur le <a href='https://huggingface.co/models'>Hub des mod\xE8les</a> pour trouver le meilleur <i>checkpoint</i> pour votre t\xE2che !"}]}}),{c(){p=s("h3"),c=s("a"),$=s("span"),b(h.$$.fragment),E=f(),k=s("span"),S=N("5. Qu\u2019est-ce qu\u2019un AutoModel?"),z=f(),b(v.$$.fragment),this.h()},l(i){p=o(i,"H3",{class:!0});var x=a(p);c=o(x,"A",{id:!0,class:!0,href:!0});var n=a(c);$=o(n,"SPAN",{});var _=a($);w(h.$$.fragment,_),_.forEach(t),n.forEach(t),E=m(x),k=o(x,"SPAN",{});var L=a(k);S=M(L,"5. Qu\u2019est-ce qu\u2019un AutoModel?"),L.forEach(t),x.forEach(t),z=m(i),w(v.$$.fragment,i),this.h()},h(){l(c,"id","5.-qu\u2019est-ce-qu\u2019un-automodel?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#5.-qu\u2019est-ce-qu\u2019un-automodel?"),l(p,"class","relative group")},m(i,x){d(i,p,x),r(p,c),r(c,$),A(h,$,null),r(p,E),r(p,k),r(k,S),d(i,z,x),A(v,i,x),P=!0},i(i){P||(g(h.$$.fragment,i),g(v.$$.fragment,i),P=!0)},o(i){q(h.$$.fragment,i),q(v.$$.fragment,i),P=!1},d(i){i&&t(p),y(h),i&&t(z),y(v,i)}}}function Sr(H){let p,c,$,h,E,k,S,z,v,P,i,x;return h=new T({}),v=new Bt({props:{code:`from transformers import AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = TFAutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),i=new C({props:{choices:[{text:"Non, \xE7a semble correct.",explain:"Malheureusement, coupler un mod\xE8le avec un <i>tokenizer</i> qui a \xE9t\xE9 entra\xEEn\xE9 avec un <i>checkpoint</i> diff\xE9rent est rarement une bonne id\xE9e. Le mod\xE8le n'a pas \xE9t\xE9 entra\xEEn\xE9 pour donner du sens \xE0 la sortie de ce <i>tokenizer</i> donc la sortie du mod\xE8le (s'il peut m\xEAme fonctionner !) n'aura aucun sens."},{text:" Le <i>tokenizer</i> et le mod\xE8le doivent toujours provenir du m\xEAme <i>checkpoint</i>.",explain:"",correct:!0},{text:" C'est une bonne pratique de faire du <i>padding</i> et de troncage avec le <i>tokenizer</i> car chaque entr\xE9e est un batch.",explain:"Il est vrai que chaque entr\xE9e de mod\xE8le doit \xEAtre un batch. Cependant, tronquer ou compl\xE9ter cette s\xE9quence n'aurait pas n\xE9cessairement de sens puisqu'il n'y en a qu'une seule. Il s'agit l\xE0 de techniques permettant de mettre en batch une liste de phrases."}]}}),{c(){p=s("h3"),c=s("a"),$=s("span"),b(h.$$.fragment),E=f(),k=s("span"),S=N("10. Y a-t-il un probl\xE8me avec le code suivant ?"),z=f(),b(v.$$.fragment),P=f(),b(i.$$.fragment),this.h()},l(n){p=o(n,"H3",{class:!0});var _=a(p);c=o(_,"A",{id:!0,class:!0,href:!0});var L=a(c);$=o(L,"SPAN",{});var j=a($);w(h.$$.fragment,j),j.forEach(t),L.forEach(t),E=m(_),k=o(_,"SPAN",{});var Q=a(k);S=M(Q,"10. Y a-t-il un probl\xE8me avec le code suivant ?"),Q.forEach(t),_.forEach(t),z=m(n),w(v.$$.fragment,n),P=m(n),w(i.$$.fragment,n),this.h()},h(){l(c,"id","10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(p,"class","relative group")},m(n,_){d(n,p,_),r(p,c),r(c,$),A(h,$,null),r(p,E),r(p,k),r(k,S),d(n,z,_),A(v,n,_),d(n,P,_),A(i,n,_),x=!0},i(n){x||(g(h.$$.fragment,n),g(v.$$.fragment,n),g(i.$$.fragment,n),x=!0)},o(n){q(h.$$.fragment,n),q(v.$$.fragment,n),q(i.$$.fragment,n),x=!1},d(n){n&&t(p),y(h),n&&t(z),y(v,n),n&&t(P),y(i,n)}}}function Lr(H){let p,c,$,h,E,k,S,z,v,P,i,x;return h=new T({}),v=new Bt({props:{code:`from transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = AutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),i=new C({props:{choices:[{text:"Non, \xE7a semble correct.",explain:"Malheureusement, coupler un mod\xE8le avec un <i>tokenizer</i> qui a \xE9t\xE9 entra\xEEn\xE9 avec un <i>checkpoint</i> diff\xE9rent est rarement une bonne id\xE9e. Le mod\xE8le n'a pas \xE9t\xE9 entra\xEEn\xE9 pour donner du sens \xE0 la sortie de ce <i>tokenizer</i> donc la sortie du mod\xE8le (s'il peut m\xEAme fonctionner !) n'aura aucun sens."},{text:" Le <i>tokenizer</i> et le mod\xE8le doivent toujours provenir du m\xEAme <i>checkpoint</i>.",explain:"",correct:!0},{text:" C'est une bonne pratique de faire du <i>padding</i> et de troncage avec le <i>tokenizer</i> car chaque entr\xE9e est un batch.",explain:"Il est vrai que chaque entr\xE9e de mod\xE8le doit \xEAtre un batch. Cependant, tronquer ou compl\xE9ter cette s\xE9quence n'aurait pas n\xE9cessairement de sens puisqu'il n'y en a qu'une seule. Il s'agit l\xE0 de techniques permettant de mettre en batch une liste de phrases."}]}}),{c(){p=s("h3"),c=s("a"),$=s("span"),b(h.$$.fragment),E=f(),k=s("span"),S=N("10. Y a-t-il un probl\xE8me avec le code suivant ?"),z=f(),b(v.$$.fragment),P=f(),b(i.$$.fragment),this.h()},l(n){p=o(n,"H3",{class:!0});var _=a(p);c=o(_,"A",{id:!0,class:!0,href:!0});var L=a(c);$=o(L,"SPAN",{});var j=a($);w(h.$$.fragment,j),j.forEach(t),L.forEach(t),E=m(_),k=o(_,"SPAN",{});var Q=a(k);S=M(Q,"10. Y a-t-il un probl\xE8me avec le code suivant ?"),Q.forEach(t),_.forEach(t),z=m(n),w(v.$$.fragment,n),P=m(n),w(i.$$.fragment,n),this.h()},h(){l(c,"id","10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(p,"class","relative group")},m(n,_){d(n,p,_),r(p,c),r(c,$),A(h,$,null),r(p,E),r(p,k),r(k,S),d(n,z,_),A(v,n,_),d(n,P,_),A(i,n,_),x=!0},i(n){x||(g(h.$$.fragment,n),g(v.$$.fragment,n),g(i.$$.fragment,n),x=!0)},o(n){q(h.$$.fragment,n),q(v.$$.fragment,n),q(i.$$.fragment,n),x=!1},d(n){n&&t(p),y(h),n&&t(z),y(v,n),n&&t(P),y(i,n)}}}function Nr(H){let p,c,$,h,E,k,S,z,v,P,i,x,n,_,L,j,Q,ne,kt,Se,xt,Ye,se,We,O,J,Le,oe,_t,ie,bt,Ne,wt,At,De,ae,Re,V,K,Me,le,yt,je,zt,Ge,ue,Je,Y,X,Te,pe,Et,Ce,Pt,Ke,ce,Xe,I,U,ye,W,Z,He,de,St,Qe,Lt,Ze,fe,et,D,ee,Ie,me,Nt,Ue,Mt,tt,he,rt,R,te,Fe,$e,jt,ve,Tt,Be,Ct,Ht,nt,qe,st,G,re,Oe,ge,Qt,ke,It,Ve,Ut,Ft,ot,xe,it,_e,at,F,B,ze,lt;$=new zr({props:{fw:H[0]}}),z=new T({}),n=new yr({props:{chapter:2,classNames:"absolute z-10 right-0 top-0"}}),ne=new T({}),se=new C({props:{choices:[{text:" Tout d'abord, le mod\xE8le, qui traite le texte et renvoie des pr\xE9dictions brutes. Puis le <i>tokenizer</i> donne un sens \xE0 ces pr\xE9dictions et les reconvertit en texte si n\xE9cessaire.",explain:" Le mod\xE8le ne peut pas comprendre le texte ! Le <i>tokenizer</i> doit d'abord tokeniser le texte et le convertir en identifiants afin qu'il soit compr\xE9hensible par le mod\xE8le."},{text:" Tout d'abord, le <i>tokenizer</i>, qui traite le texte et renvoie des identifiants. Puis le mod\xE8le traite ces identifiants et produit une pr\xE9diction, qui peut \xEAtre du texte.",explain:" La pr\xE9diction du mod\xE8le ne peut pas \xEAtre du texte imm\xE9diatement. Le <i>tokenizer</i> doit \xEAtre utilis\xE9 afin de reconvertir la pr\xE9diction en texte !"},{text:" Le <i>tokenizer</i> traite le texte et renvoie des identifiants. Le mod\xE8le traite ces identifiants et produit une pr\xE9diction. Le <i>tokenizer</i> peut alors \xEAtre utilis\xE9 \xE0 nouveau pour reconvertir ces pr\xE9dictions en texte.",explain:" Le <i>tokenizer</i> peut \xEAtre utilis\xE9 \xE0 la fois pour la tokenisation et la d\xE9-tok\xE9nisation.",correct:!0}]}}),oe=new T({}),ae=new C({props:{choices:[{text:"2: la longueur de la s\xE9quence et la taille du batch",explain:"Le tenseur produit par le mod\xE8le poss\xE8de une troisi\xE8me dimension : la taille cach\xE9e."},{text:"2: la longueur de la s\xE9quence et la taille cach\xE9e",explain:"Tous les <i>transformers</i>  g\xE8rent les batchs, m\xEAme avec une seule s\xE9quence ce serait une taille de batch de 1 !"},{text:"3: la longueur de la s\xE9quence, la taille du batch et la taille cach\xE9e.",explain:"",correct:!0}]}}),le=new T({}),ue=new C({props:{choices:[{text:"WordPiece",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"La tokenization bas\xE9e sur les caract\xE8res",explain:"La tokenization bas\xE9e sur les caract\xE8res n\u2019est pas un type de tokenisation en sous-mots."},{text:"D\xE9coupage sur les espaces et la ponctuation",explain:"C\u2019est une tokenisation bas\xE9e sur les mots !"},{text:"BPE",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"Unigram",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"Aucune des propositions ci-dessus",explain:""}]}}),pe=new T({}),ce=new C({props:{choices:[{text:" Un composant du <i>transformer</i>  de base qui redirige les tenseurs vers leurs couches correctes.",explain:"Il n'y a pas de tel composant."},{text:"\xC9galement connu sous le nom de m\xE9canisme d'auto-attention, il adapte la repr\xE9sentation d'un <i>token</i>  en fonction des autres <i>tokens</i>  de la s\xE9quence.",explain:"La couche d'auto-attention contient des t\xEAtes d'attention mais ce ne sont pas des t\xEAtes d'adaptation."},{text:"Un composant suppl\xE9mentaire, g\xE9n\xE9ralement constitu\xE9 d'une ou plusieurs couches, pour convertir les pr\xE9dictions du <i>transformer</i>  en une sortie sp\xE9cifique \xE0 la t\xE2che.",explain:"Les t\xEAtes d'adaptation, aussi appel\xE9es simplement t\xEAtes, se pr\xE9sentent sous diff\xE9rentes formes : t\xEAtes de mod\xE9lisation du langage, t\xEAtes de r\xE9ponse aux questions, t\xEAtes de classification des s\xE9quences, etc.",correct:!0}]}});const Ot=[Pr,Er],be=[];function Vt(e,u){return e[0]==="pt"?0:1}I=Vt(H),U=be[I]=Ot[I](H),de=new T({}),fe=new C({props:{choices:[{text:"La troncature",explain:" La troncature est une fa\xE7on correcte d'\xE9galiser les s\xE9quences pour qu'elles s'inscrivent dans une forme rectangulaire. Mais est-ce la seule ?",correct:!0},{text:"Retourner les tenseurs",explain:"Alors que les autres techniques vous permettent de renvoyer des tenseurs rectangulaires, retourner les tenseurs n'est pas utile lorsque vous mettez en batch des s\xE9quences."},{text:"Le <i>padding</i>",explain:"Le <i>padding</i> est une fa\xE7on correcte d'\xE9galiser les s\xE9quences pour qu'elles tiennent dans une forme rectangulaire. Mais est-ce le seul moyen ?",correct:!0},{text:"Les masques d'attention ",explain:"Les masques d'attention sont d'une importance capitale lorsqu'on manipule des s\xE9quences de longueurs diff\xE9rentes. Ce n'est cependant pas la seule technique \xE0 laquelle il faut faire attention.",correct:!0}]}}),me=new T({}),he=new C({props:{choices:[{text:"Elle adoucit les logits pour qu'ils soient plus fiables.",explain:"La fonction SoftMax n'affecte pas la fiabilit\xE9 des r\xE9sultats."},{text:"Elle applique une limite inf\xE9rieure et sup\xE9rieure pour qu'ils soient compr\xE9hensibles.",explain:"Les valeurs r\xE9sultantes sont comprises entre 0 et 1. Ce n'est cependant pas la seule raison pour laquelle nous utilisons une fonction SoftMax.",correct:!0},{text:"La somme totale des sorties est alors \xE9gale \xE0 1, ce qui permet une interpr\xE9tation probabiliste.",explain:"Mais ce n'est pas la seule raison pour laquelle nous utilisons une fonction SoftMax.",correct:!0}]}}),$e=new T({}),qe=new C({props:{choices:[{text:"<code>encode</code>, car elle peut encoder du texte en identifiants et des identifiants en pr\xE9dictions.",explain:"Bien que la m\xE9thode <code>encode</code> existe sur les <i>tokenizer</i>, elle n'existe pas sur les mod\xE8les."},{text:"Appeler directement l'objet tokenizer",explain:"La m\xE9thode <code>__call__</code> du <i>tokenizer</i> est une m\xE9thode tr\xE8s puissante qui peut traiter \xE0 peu pr\xE8s tout. C'est \xE9galement la m\xE9thode utilis\xE9e pour r\xE9cup\xE9rer les pr\xE9dictions d'un mod\xE8le.",correct:!0},{text:"<code>pad</code>",explain:"Le <i>padding</i> est tr\xE8s utile mais ce n'est qu'une partie de l'API <i>tokenizer</i>."},{text:"<code>tokenize</code>",explain:"La m\xE9thode <code>tokenize</code> est est sans doute l'une des m\xE9thodes les plus utiles, mais elle ne constitue pas le c\u0153ur de l'API <i>tokenizer</i>."}]}}),ge=new T({}),xe=new Bt({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
result = tokenizer.tokenize("Hello!")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
result = tokenizer.tokenize(<span class="hljs-string">&quot;Hello!&quot;</span>)`}}),_e=new C({props:{choices:[{text:"Une liste de cha\xEEnes de caract\xE8res, chaque cha\xEEne \xE9tant un <i>token</i>.",explain:"Convertissez cela en identifiants, et donnez-les \xE0 un mod\xE8le !",correct:!0},{text:"Une liste d'identifiants",explain:"C'est \xE0 cela que la m\xE9thode <code>__call__</code> ou la m\xE9thode <code>convert_tokens_to_ids</code> sert !"},{text:"Une cha\xEEne contenant tous les <i>tokens</i>",explain:"Ce serait sous-optimal car le but est de diviser la cha\xEEne de caract\xE8res en plusieurs \xE9l\xE9ments."}]}});const Yt=[Lr,Sr],we=[];function Wt(e,u){return e[0]==="pt"?0:1}return F=Wt(H),B=we[F]=Yt[F](H),{c(){p=s("meta"),c=f(),b($.$$.fragment),h=f(),E=s("h1"),k=s("a"),S=s("span"),b(z.$$.fragment),v=f(),P=s("span"),i=N("Quiz de fin de chapitre"),x=f(),b(n.$$.fragment),_=f(),L=s("h3"),j=s("a"),Q=s("span"),b(ne.$$.fragment),kt=f(),Se=s("span"),xt=N("1. Quel est l\u2019ordre du pipeline de mod\xE9lisation du langage ?"),Ye=f(),b(se.$$.fragment),We=f(),O=s("h3"),J=s("a"),Le=s("span"),b(oe.$$.fragment),_t=f(),ie=s("span"),bt=N("2. Combien de dimensions le tenseur produit par le "),Ne=s("i"),wt=N("transformer"),At=N(" de base poss\xE8de-t-il et quelles sont-elles ?"),De=f(),b(ae.$$.fragment),Re=f(),V=s("h3"),K=s("a"),Me=s("span"),b(le.$$.fragment),yt=f(),je=s("span"),zt=N("3. Lequel des \xE9l\xE9ments suivants est un exemple de tokenisation en sous-mots ?"),Ge=f(),b(ue.$$.fragment),Je=f(),Y=s("h3"),X=s("a"),Te=s("span"),b(pe.$$.fragment),Et=f(),Ce=s("span"),Pt=N("4. Qu\u2019est-ce qu\u2019une t\xEAte de mod\xE8le ?"),Ke=f(),b(ce.$$.fragment),Xe=f(),U.c(),ye=f(),W=s("h3"),Z=s("a"),He=s("span"),b(de.$$.fragment),St=f(),Qe=s("span"),Lt=N("6. Quelles sont les techniques \xE0 conna\xEEtre lors de la mise en batch de s\xE9quences de longueurs diff\xE9rentes ?"),Ze=f(),b(fe.$$.fragment),et=f(),D=s("h3"),ee=s("a"),Ie=s("span"),b(me.$$.fragment),Nt=f(),Ue=s("span"),Mt=N("7. Quel est l\u2019int\xE9r\xEAt d\u2019appliquer une fonction SoftMax aux logits produits par un mod\xE8le de classification de s\xE9quences ?"),tt=f(),b(he.$$.fragment),rt=f(),R=s("h3"),te=s("a"),Fe=s("span"),b($e.$$.fragment),jt=f(),ve=s("span"),Tt=N("8. Autour de quelle m\xE9thode s\u2019articule la majeure partie de l\u2019API "),Be=s("i"),Ct=N("tokenizer"),Ht=N(" ?"),nt=f(),b(qe.$$.fragment),st=f(),G=s("h3"),re=s("a"),Oe=s("span"),b(ge.$$.fragment),Qt=f(),ke=s("span"),It=N("9. Que contient la variable "),Ve=s("code"),Ut=N("result"),Ft=N(" dans cet exemple de code ?"),ot=f(),b(xe.$$.fragment),it=f(),b(_e.$$.fragment),at=f(),B.c(),ze=qr(),this.h()},l(e){const u=wr('[data-svelte="svelte-1phssyn"]',document.head);p=o(u,"META",{name:!0,content:!0}),u.forEach(t),c=m(e),w($.$$.fragment,e),h=m(e),E=o(e,"H1",{class:!0});var Ae=a(E);k=o(Ae,"A",{id:!0,class:!0,href:!0});var Ee=a(k);S=o(Ee,"SPAN",{});var Pe=a(S);w(z.$$.fragment,Pe),Pe.forEach(t),Ee.forEach(t),v=m(Ae),P=o(Ae,"SPAN",{});var Dt=a(P);i=M(Dt,"Quiz de fin de chapitre"),Dt.forEach(t),Ae.forEach(t),x=m(e),w(n.$$.fragment,e),_=m(e),L=o(e,"H3",{class:!0});var ut=a(L);j=o(ut,"A",{id:!0,class:!0,href:!0});var Rt=a(j);Q=o(Rt,"SPAN",{});var Gt=a(Q);w(ne.$$.fragment,Gt),Gt.forEach(t),Rt.forEach(t),kt=m(ut),Se=o(ut,"SPAN",{});var Jt=a(Se);xt=M(Jt,"1. Quel est l\u2019ordre du pipeline de mod\xE9lisation du langage ?"),Jt.forEach(t),ut.forEach(t),Ye=m(e),w(se.$$.fragment,e),We=m(e),O=o(e,"H3",{class:!0});var pt=a(O);J=o(pt,"A",{id:!0,class:!0,href:!0});var Kt=a(J);Le=o(Kt,"SPAN",{});var Xt=a(Le);w(oe.$$.fragment,Xt),Xt.forEach(t),Kt.forEach(t),_t=m(pt),ie=o(pt,"SPAN",{});var ct=a(ie);bt=M(ct,"2. Combien de dimensions le tenseur produit par le "),Ne=o(ct,"I",{});var Zt=a(Ne);wt=M(Zt,"transformer"),Zt.forEach(t),At=M(ct," de base poss\xE8de-t-il et quelles sont-elles ?"),ct.forEach(t),pt.forEach(t),De=m(e),w(ae.$$.fragment,e),Re=m(e),V=o(e,"H3",{class:!0});var dt=a(V);K=o(dt,"A",{id:!0,class:!0,href:!0});var er=a(K);Me=o(er,"SPAN",{});var tr=a(Me);w(le.$$.fragment,tr),tr.forEach(t),er.forEach(t),yt=m(dt),je=o(dt,"SPAN",{});var rr=a(je);zt=M(rr,"3. Lequel des \xE9l\xE9ments suivants est un exemple de tokenisation en sous-mots ?"),rr.forEach(t),dt.forEach(t),Ge=m(e),w(ue.$$.fragment,e),Je=m(e),Y=o(e,"H3",{class:!0});var ft=a(Y);X=o(ft,"A",{id:!0,class:!0,href:!0});var nr=a(X);Te=o(nr,"SPAN",{});var sr=a(Te);w(pe.$$.fragment,sr),sr.forEach(t),nr.forEach(t),Et=m(ft),Ce=o(ft,"SPAN",{});var or=a(Ce);Pt=M(or,"4. Qu\u2019est-ce qu\u2019une t\xEAte de mod\xE8le ?"),or.forEach(t),ft.forEach(t),Ke=m(e),w(ce.$$.fragment,e),Xe=m(e),U.l(e),ye=m(e),W=o(e,"H3",{class:!0});var mt=a(W);Z=o(mt,"A",{id:!0,class:!0,href:!0});var ir=a(Z);He=o(ir,"SPAN",{});var ar=a(He);w(de.$$.fragment,ar),ar.forEach(t),ir.forEach(t),St=m(mt),Qe=o(mt,"SPAN",{});var lr=a(Qe);Lt=M(lr,"6. Quelles sont les techniques \xE0 conna\xEEtre lors de la mise en batch de s\xE9quences de longueurs diff\xE9rentes ?"),lr.forEach(t),mt.forEach(t),Ze=m(e),w(fe.$$.fragment,e),et=m(e),D=o(e,"H3",{class:!0});var ht=a(D);ee=o(ht,"A",{id:!0,class:!0,href:!0});var ur=a(ee);Ie=o(ur,"SPAN",{});var pr=a(Ie);w(me.$$.fragment,pr),pr.forEach(t),ur.forEach(t),Nt=m(ht),Ue=o(ht,"SPAN",{});var cr=a(Ue);Mt=M(cr,"7. Quel est l\u2019int\xE9r\xEAt d\u2019appliquer une fonction SoftMax aux logits produits par un mod\xE8le de classification de s\xE9quences ?"),cr.forEach(t),ht.forEach(t),tt=m(e),w(he.$$.fragment,e),rt=m(e),R=o(e,"H3",{class:!0});var $t=a(R);te=o($t,"A",{id:!0,class:!0,href:!0});var dr=a(te);Fe=o(dr,"SPAN",{});var fr=a(Fe);w($e.$$.fragment,fr),fr.forEach(t),dr.forEach(t),jt=m($t),ve=o($t,"SPAN",{});var vt=a(ve);Tt=M(vt,"8. Autour de quelle m\xE9thode s\u2019articule la majeure partie de l\u2019API "),Be=o(vt,"I",{});var mr=a(Be);Ct=M(mr,"tokenizer"),mr.forEach(t),Ht=M(vt," ?"),vt.forEach(t),$t.forEach(t),nt=m(e),w(qe.$$.fragment,e),st=m(e),G=o(e,"H3",{class:!0});var qt=a(G);re=o(qt,"A",{id:!0,class:!0,href:!0});var hr=a(re);Oe=o(hr,"SPAN",{});var $r=a(Oe);w(ge.$$.fragment,$r),$r.forEach(t),hr.forEach(t),Qt=m(qt),ke=o(qt,"SPAN",{});var gt=a(ke);It=M(gt,"9. Que contient la variable "),Ve=o(gt,"CODE",{});var vr=a(Ve);Ut=M(vr,"result"),vr.forEach(t),Ft=M(gt," dans cet exemple de code ?"),gt.forEach(t),qt.forEach(t),ot=m(e),w(xe.$$.fragment,e),it=m(e),w(_e.$$.fragment,e),at=m(e),B.l(e),ze=qr(),this.h()},h(){l(p,"name","hf:doc:metadata"),l(p,"content",JSON.stringify(Mr)),l(k,"id","quiz-de-fin-de-chapitre"),l(k,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(k,"href","#quiz-de-fin-de-chapitre"),l(E,"class","relative group"),l(j,"id","1.-quel-est-l\u2019ordre-du-pipeline-de-mod\xE9lisation-du-langage-?"),l(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(j,"href","#1.-quel-est-l\u2019ordre-du-pipeline-de-mod\xE9lisation-du-langage-?"),l(L,"class","relative group"),l(J,"id","2.-combien-de-dimensions-le-tenseur-produit-par-le-<i>transformer</i>-de-base-poss\xE8de-t-il-et-quelles-sont-elles-?"),l(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(J,"href","#2.-combien-de-dimensions-le-tenseur-produit-par-le-<i>transformer</i>-de-base-poss\xE8de-t-il-et-quelles-sont-elles-?"),l(O,"class","relative group"),l(K,"id","3.-lequel-des-\xE9l\xE9ments-suivants-est-un-exemple-de-tokenisation-en-sous-mots-?"),l(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(K,"href","#3.-lequel-des-\xE9l\xE9ments-suivants-est-un-exemple-de-tokenisation-en-sous-mots-?"),l(V,"class","relative group"),l(X,"id","4.-qu\u2019est-ce-qu\u2019une-t\xEAte-de-mod\xE8le-?"),l(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(X,"href","#4.-qu\u2019est-ce-qu\u2019une-t\xEAte-de-mod\xE8le-?"),l(Y,"class","relative group"),l(Z,"id","6.-quelles-sont-les-techniques-\xE0-conna\xEEtre-lors-de-la-mise-en-batch-de-s\xE9quences-de-longueurs-diff\xE9rentes-?"),l(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Z,"href","#6.-quelles-sont-les-techniques-\xE0-conna\xEEtre-lors-de-la-mise-en-batch-de-s\xE9quences-de-longueurs-diff\xE9rentes-?"),l(W,"class","relative group"),l(ee,"id","7.-quel-est-l\u2019int\xE9r\xEAt-d\u2019appliquer-une-fonction-softmax-aux-logits-produits-par-un-mod\xE8le-de-classification-de-s\xE9quences-?"),l(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ee,"href","#7.-quel-est-l\u2019int\xE9r\xEAt-d\u2019appliquer-une-fonction-softmax-aux-logits-produits-par-un-mod\xE8le-de-classification-de-s\xE9quences-?"),l(D,"class","relative group"),l(te,"id","8.-autour-de-quelle-m\xE9thode-s\u2019articule-la-majeure-partie-de-l\u2019api-<i>tokenizer</i>-?"),l(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(te,"href","#8.-autour-de-quelle-m\xE9thode-s\u2019articule-la-majeure-partie-de-l\u2019api-<i>tokenizer</i>-?"),l(R,"class","relative group"),l(re,"id","9.-que-contient-la-variable-<code>result</code>-dans-cet-exemple-de-code-?"),l(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(re,"href","#9.-que-contient-la-variable-<code>result</code>-dans-cet-exemple-de-code-?"),l(G,"class","relative group")},m(e,u){r(document.head,p),d(e,c,u),A($,e,u),d(e,h,u),d(e,E,u),r(E,k),r(k,S),A(z,S,null),r(E,v),r(E,P),r(P,i),d(e,x,u),A(n,e,u),d(e,_,u),d(e,L,u),r(L,j),r(j,Q),A(ne,Q,null),r(L,kt),r(L,Se),r(Se,xt),d(e,Ye,u),A(se,e,u),d(e,We,u),d(e,O,u),r(O,J),r(J,Le),A(oe,Le,null),r(O,_t),r(O,ie),r(ie,bt),r(ie,Ne),r(Ne,wt),r(ie,At),d(e,De,u),A(ae,e,u),d(e,Re,u),d(e,V,u),r(V,K),r(K,Me),A(le,Me,null),r(V,yt),r(V,je),r(je,zt),d(e,Ge,u),A(ue,e,u),d(e,Je,u),d(e,Y,u),r(Y,X),r(X,Te),A(pe,Te,null),r(Y,Et),r(Y,Ce),r(Ce,Pt),d(e,Ke,u),A(ce,e,u),d(e,Xe,u),be[I].m(e,u),d(e,ye,u),d(e,W,u),r(W,Z),r(Z,He),A(de,He,null),r(W,St),r(W,Qe),r(Qe,Lt),d(e,Ze,u),A(fe,e,u),d(e,et,u),d(e,D,u),r(D,ee),r(ee,Ie),A(me,Ie,null),r(D,Nt),r(D,Ue),r(Ue,Mt),d(e,tt,u),A(he,e,u),d(e,rt,u),d(e,R,u),r(R,te),r(te,Fe),A($e,Fe,null),r(R,jt),r(R,ve),r(ve,Tt),r(ve,Be),r(Be,Ct),r(ve,Ht),d(e,nt,u),A(qe,e,u),d(e,st,u),d(e,G,u),r(G,re),r(re,Oe),A(ge,Oe,null),r(G,Qt),r(G,ke),r(ke,It),r(ke,Ve),r(Ve,Ut),r(ke,Ft),d(e,ot,u),A(xe,e,u),d(e,it,u),A(_e,e,u),d(e,at,u),we[F].m(e,u),d(e,ze,u),lt=!0},p(e,[u]){const Ae={};u&1&&(Ae.fw=e[0]),$.$set(Ae);let Ee=I;I=Vt(e),I!==Ee&&(kr(),q(be[Ee],1,1,()=>{be[Ee]=null}),gr(),U=be[I],U||(U=be[I]=Ot[I](e),U.c()),g(U,1),U.m(ye.parentNode,ye));let Pe=F;F=Wt(e),F!==Pe&&(kr(),q(we[Pe],1,1,()=>{we[Pe]=null}),gr(),B=we[F],B||(B=we[F]=Yt[F](e),B.c()),g(B,1),B.m(ze.parentNode,ze))},i(e){lt||(g($.$$.fragment,e),g(z.$$.fragment,e),g(n.$$.fragment,e),g(ne.$$.fragment,e),g(se.$$.fragment,e),g(oe.$$.fragment,e),g(ae.$$.fragment,e),g(le.$$.fragment,e),g(ue.$$.fragment,e),g(pe.$$.fragment,e),g(ce.$$.fragment,e),g(U),g(de.$$.fragment,e),g(fe.$$.fragment,e),g(me.$$.fragment,e),g(he.$$.fragment,e),g($e.$$.fragment,e),g(qe.$$.fragment,e),g(ge.$$.fragment,e),g(xe.$$.fragment,e),g(_e.$$.fragment,e),g(B),lt=!0)},o(e){q($.$$.fragment,e),q(z.$$.fragment,e),q(n.$$.fragment,e),q(ne.$$.fragment,e),q(se.$$.fragment,e),q(oe.$$.fragment,e),q(ae.$$.fragment,e),q(le.$$.fragment,e),q(ue.$$.fragment,e),q(pe.$$.fragment,e),q(ce.$$.fragment,e),q(U),q(de.$$.fragment,e),q(fe.$$.fragment,e),q(me.$$.fragment,e),q(he.$$.fragment,e),q($e.$$.fragment,e),q(qe.$$.fragment,e),q(ge.$$.fragment,e),q(xe.$$.fragment,e),q(_e.$$.fragment,e),q(B),lt=!1},d(e){t(p),e&&t(c),y($,e),e&&t(h),e&&t(E),y(z),e&&t(x),y(n,e),e&&t(_),e&&t(L),y(ne),e&&t(Ye),y(se,e),e&&t(We),e&&t(O),y(oe),e&&t(De),y(ae,e),e&&t(Re),e&&t(V),y(le),e&&t(Ge),y(ue,e),e&&t(Je),e&&t(Y),y(pe),e&&t(Ke),y(ce,e),e&&t(Xe),be[I].d(e),e&&t(ye),e&&t(W),y(de),e&&t(Ze),y(fe,e),e&&t(et),e&&t(D),y(me),e&&t(tt),y(he,e),e&&t(rt),e&&t(R),y($e),e&&t(nt),y(qe,e),e&&t(st),e&&t(G),y(ge),e&&t(ot),y(xe,e),e&&t(it),y(_e,e),e&&t(at),we[F].d(e),e&&t(ze)}}}const Mr={local:"quiz-de-fin-de-chapitre",title:"Quiz de fin de chapitre"};function jr(H,p,c){let $="pt";return Ar(()=>{const h=new URLSearchParams(window.location.search);c(0,$=h.get("fw")||"pt")}),[$]}class Fr extends xr{constructor(p){super();_r(this,p,jr,Nr,br,{})}}export{Fr as default,Mr as metadata};
