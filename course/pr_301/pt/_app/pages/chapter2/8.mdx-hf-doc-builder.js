import{S as go,i as ko,s as xo,e as s,k as p,w as b,t as T,l as ho,M as _o,c as n,d as a,m as f,x as q,a as i,h as O,b as l,G as o,g as c,y as w,o as g,p as $o,q as k,B as z,v as bo,n as vo}from"../../chunks/vendor-hf-doc-builder.js";import{I as H}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ca}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as qo}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import{Q as C}from"../../chunks/Question-hf-doc-builder.js";import{F as wo}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function zo(Q){let d,u,v,h,N,$,S,A,y,P,E,_,t;return h=new H({}),_=new C({props:{choices:[{text:"Um modelo que treina automaticamente com seus dados",explain:"Incorreto. Voc\xEA est\xE1 confundindo isto com nosso produto de <a href='https://huggingface.co/autonlp'>AutoNLP</a>?"},{text:"Um objeto que devolve a arquitetura correta com base em um checkpoint",explain:"Exatamente: o <code>TFAutoModel</code> s\xF3 precisa saber o checkpoint para saber como inicializar ent\xE3o devolver a arquitetura correta.",correct:!0},{text:"Um modelo que detecta automaticamente a linguagem utilizada para suas entradas a fim de carregar os pesos corretos",explain:"Incorreto; embora alguns checkpoints e modelos sejam capazes de lidar com v\xE1rios idiomas, n\xE3o h\xE1 ferramentas embutidas para sele\xE7\xE3o autom\xE1tica de checkpoints de acordo com o idioma. Voc\xEA deve ir para o  <a href='https://huggingface.co/models'>Model Hub</a> para encontrar o melhor checkpoint para realizar sua tarefa!"}]}}),{c(){d=s("h3"),u=s("a"),v=s("span"),b(h.$$.fragment),N=p(),$=s("span"),S=T("5. O que seria um "),A=s("code"),y=T("TFAutoModel"),P=T("?"),E=p(),b(_.$$.fragment),this.h()},l(r){d=n(r,"H3",{class:!0});var x=i(d);u=n(x,"A",{id:!0,class:!0,href:!0});var j=i(u);v=n(j,"SPAN",{});var M=i(v);q(h.$$.fragment,M),M.forEach(a),j.forEach(a),N=f(x),$=n(x,"SPAN",{});var I=i($);S=O(I,"5. O que seria um "),A=n(I,"CODE",{});var L=i(A);y=O(L,"TFAutoModel"),L.forEach(a),P=O(I,"?"),I.forEach(a),x.forEach(a),E=f(r),q(_.$$.fragment,r),this.h()},h(){l(u,"id","5.-o-que-seria-um-<code>tfautomodel</code>?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#5.-o-que-seria-um-<code>tfautomodel</code>?"),l(d,"class","relative group")},m(r,x){c(r,d,x),o(d,u),o(u,v),w(h,v,null),o(d,N),o(d,$),o($,S),o($,A),o(A,y),o($,P),c(r,E,x),w(_,r,x),t=!0},i(r){t||(k(h.$$.fragment,r),k(_.$$.fragment,r),t=!0)},o(r){g(h.$$.fragment,r),g(_.$$.fragment,r),t=!1},d(r){r&&a(d),z(h),r&&a(E),z(_,r)}}}function Ao(Q){let d,u,v,h,N,$,S,A,y,P,E,_,t;return h=new H({}),_=new C({props:{choices:[{text:"Um modelo que treina automaticamente com seus dados",explain:"Incorreto. Voc\xEA est\xE1 confundindo isto com nosso produto de <a href='https://huggingface.co/autonlp'>AutoNLP</a>?"},{text:"Um objeto que devolve a arquitetura correta com base em um checkpoint",explain:"Exatamente: o <code>AutoModel</code> s\xF3 precisa saber o checkpoint para saber como inicializar ent\xE3o devolver a arquitetura correta.",correct:!0},{text:"Um modelo que detecta automaticamente a linguagem utilizada para suas entradas a fim de carregar os pesos corretos",explain:"Incorreto; embora alguns checkpoints e modelos sejam capazes de lidar com v\xE1rios idiomas, n\xE3o h\xE1 ferramentas embutidas para sele\xE7\xE3o autom\xE1tica de checkpoints de acordo com o idioma. Voc\xEA deve ir para o  <a href='https://huggingface.co/models'>Model Hub</a> para encontrar o melhor checkpoint para realizar sua tarefa!"}]}}),{c(){d=s("h3"),u=s("a"),v=s("span"),b(h.$$.fragment),N=p(),$=s("span"),S=T("5. O que seria um "),A=s("code"),y=T("AutoModel"),P=T("?"),E=p(),b(_.$$.fragment),this.h()},l(r){d=n(r,"H3",{class:!0});var x=i(d);u=n(x,"A",{id:!0,class:!0,href:!0});var j=i(u);v=n(j,"SPAN",{});var M=i(v);q(h.$$.fragment,M),M.forEach(a),j.forEach(a),N=f(x),$=n(x,"SPAN",{});var I=i($);S=O(I,"5. O que seria um "),A=n(I,"CODE",{});var L=i(A);y=O(L,"AutoModel"),L.forEach(a),P=O(I,"?"),I.forEach(a),x.forEach(a),E=f(r),q(_.$$.fragment,r),this.h()},h(){l(u,"id","5.-o-que-seria-um-<code>automodel</code>?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#5.-o-que-seria-um-<code>automodel</code>?"),l(d,"class","relative group")},m(r,x){c(r,d,x),o(d,u),o(u,v),w(h,v,null),o(d,N),o(d,$),o($,S),o($,A),o(A,y),o($,P),c(r,E,x),w(_,r,x),t=!0},i(r){t||(k(h.$$.fragment,r),k(_.$$.fragment,r),t=!0)},o(r){g(h.$$.fragment,r),g(_.$$.fragment,r),t=!1},d(r){r&&a(d),z(h),r&&a(E),z(_,r)}}}function Eo(Q){let d,u,v,h,N,$,S,A,y,P,E,_;return h=new H({}),y=new Ca({props:{code:`from transformers import AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = TFAutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),E=new C({props:{choices:[{text:"N\xE3o, parece correto.",explain:"Infelizmente, acoplar um modelo com um tokenizer que foi treinado com um checkpoint diferente raramente \xE9 uma boa ideia. O modelo n\xE3o foi treinado para fazer sentido a partir da sa\xEDda deste tokenizer, ent\xE3o a sa\xEDda do modelo (isto se ele realmente funcionar!) n\xE3o far\xE1 nenhum sentido."},{text:"O tokenizer e o modelo devem ser sempre a partir do mesmo checkpoint.",explain:"Correto!",correct:!0},{text:"\xC9 uma boa pr\xE1tica realizar o padding e truncar com o tokenizer, pois cada entrada \xE9 um batch.",explain:"\xC9 verdade que cada entrada do modelo precisa ser um batch. Entretanto, truncando ou realizando o padding desta sequ\xEAncia n\xE3o faria necessariamente sentido, pois existe apenas uma delas, e estas s\xE3o t\xE9cnicas para criar batches de uma lista de senten\xE7as."}]}}),{c(){d=s("h3"),u=s("a"),v=s("span"),b(h.$$.fragment),N=p(),$=s("span"),S=T("10. Tem algo errado com o c\xF3digo abaixo?"),A=p(),b(y.$$.fragment),P=p(),b(E.$$.fragment),this.h()},l(t){d=n(t,"H3",{class:!0});var r=i(d);u=n(r,"A",{id:!0,class:!0,href:!0});var x=i(u);v=n(x,"SPAN",{});var j=i(v);q(h.$$.fragment,j),j.forEach(a),x.forEach(a),N=f(r),$=n(r,"SPAN",{});var M=i($);S=O(M,"10. Tem algo errado com o c\xF3digo abaixo?"),M.forEach(a),r.forEach(a),A=f(t),q(y.$$.fragment,t),P=f(t),q(E.$$.fragment,t),this.h()},h(){l(u,"id","10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(d,"class","relative group")},m(t,r){c(t,d,r),o(d,u),o(u,v),w(h,v,null),o(d,N),o(d,$),o($,S),c(t,A,r),w(y,t,r),c(t,P,r),w(E,t,r),_=!0},i(t){_||(k(h.$$.fragment,t),k(y.$$.fragment,t),k(E.$$.fragment,t),_=!0)},o(t){g(h.$$.fragment,t),g(y.$$.fragment,t),g(E.$$.fragment,t),_=!1},d(t){t&&a(d),z(h),t&&a(A),z(y,t),t&&a(P),z(E,t)}}}function yo(Q){let d,u,v,h,N,$,S,A,y,P,E,_;return h=new H({}),y=new Ca({props:{code:`from transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = AutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),E=new C({props:{choices:[{text:"N\xE3o, parece correto.",explain:"Infelizmente, acoplar um modelo com um tokenizer que foi treinado com um checkpoint diferente raramente \xE9 uma boa ideia. O modelo n\xE3o foi treinado para fazer sentido a partir da sa\xEDda deste tokenizer, ent\xE3o a sa\xEDda do modelo (isto se ele realmente funcionar!) n\xE3o far\xE1 nenhum sentido."},{text:"O tokenizer e o modelo devem ser sempre a partir do mesmo checkpoint.",explain:"Correto!",correct:!0},{text:"\xC9 uma boa pr\xE1tica realizar o padding e truncar com o tokenizer, pois cada entrada \xE9 um batch.",explain:"\xC9 verdade que cada entrada do modelo precisa ser um batch. Entretanto, truncando ou realizando o padding desta sequ\xEAncia n\xE3o faria necessariamente sentido, pois existe apenas uma delas, e estas s\xE3o t\xE9cnicas para criar batches de uma lista de senten\xE7as."}]}}),{c(){d=s("h3"),u=s("a"),v=s("span"),b(h.$$.fragment),N=p(),$=s("span"),S=T("10. Tem algo errado com o c\xF3digo abaixo?"),A=p(),b(y.$$.fragment),P=p(),b(E.$$.fragment),this.h()},l(t){d=n(t,"H3",{class:!0});var r=i(d);u=n(r,"A",{id:!0,class:!0,href:!0});var x=i(u);v=n(x,"SPAN",{});var j=i(v);q(h.$$.fragment,j),j.forEach(a),x.forEach(a),N=f(r),$=n(r,"SPAN",{});var M=i($);S=O(M,"10. Tem algo errado com o c\xF3digo abaixo?"),M.forEach(a),r.forEach(a),A=f(t),q(y.$$.fragment,t),P=f(t),q(E.$$.fragment,t),this.h()},h(){l(u,"id","10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(d,"class","relative group")},m(t,r){c(t,d,r),o(d,u),o(u,v),w(h,v,null),o(d,N),o(d,$),o($,S),c(t,A,r),w(y,t,r),c(t,P,r),w(E,t,r),_=!0},i(t){_||(k(h.$$.fragment,t),k(y.$$.fragment,t),k(E.$$.fragment,t),_=!0)},o(t){g(h.$$.fragment,t),g(y.$$.fragment,t),g(E.$$.fragment,t),_=!1},d(t){t&&a(d),z(h),t&&a(A),z(y,t),t&&a(P),z(E,t)}}}function No(Q){let d,u,v,h,N,$,S,A,y,P,E,_,t,r,x,j,M,I,L,Pe,ka,Ve,se,Re,V,Y,Se,ne,xa,Te,_a,Ge,ie,Je,R,Z,Oe,le,ba,je,qa,We,me,Ke,G,ee,Me,de,wa,ue,za,Ie,Aa,Ea,Xe,ce,Ye,U,D,Ae,J,ae,He,pe,ya,Ce,Na,Ze,fe,ea,W,oe,Qe,he,Pa,Ue,Sa,aa,$e,oa,K,te,De,ve,Ta,Fe,Oa,ta,ge,ra,X,re,Be,ke,ja,xe,Ma,Le,Ia,Ha,sa,_e,na,be,ia,F,B,Ee,la;v=new wo({props:{fw:Q[0]}}),A=new H({}),t=new qo({props:{chapter:2,classNames:"absolute z-10 right-0 top-0"}}),I=new H({}),se=new C({props:{choices:[{text:"Primeiro, o modelo trata de textos e devolve previs\xF5es em bruto. O tokenizer, ent\xE3o, tr\xE1s sentido a estas previs\xF5es e as converte de volta ao texto quando necess\xE1rio.",explain:"O modelo n\xE3o consegue entender o texto! O tokenizer deve primeiro simbolizar o texto e convert\xEA-lo em IDs para que seja compreens\xEDvel pelo modelo."},{text:"Primeiro, o tokenizer trata de textos e devolve as identifica\xE7\xF5es (IDs). O modelo lida com estas identifica\xE7\xF5es e produz uma predi\xE7\xE3o, que pode ser algum texto.",explain:"A predi\xE7\xE3o do modelo n\xE3o pode ser feita de imediato. O tokenizer tem que ser usado para converter a predi\xE7\xE3o de volta ao texto!"},{text:"O tokenizer trata de textos e devolve os IDs. O modelo lida com estes IDs e produz uma predi\xE7\xE3o. O tokenizer pode ent\xE3o ser usado mais uma vez para converter estas previs\xF5es de volta para algum texto.",explain:"Correto! O tokenizer pode ser usado tanto para a tokeniza\xE7\xE3o quanto para a destokeniza\xE7\xE3o.",correct:!0}]}}),ne=new H({}),ie=new C({props:{choices:[{text:"2: O comprimento da sequ\xEAncia e o tamanho do batch (lote)",explain:"Falso! A sa\xEDda do tensor pelo modelo tem uma terceira dimens\xE3o: o tamanho das camadas ocultas"},{text:"2: O comprimento da sequ\xEAncia e o tamanho das camadas ocultas",explain:"Falso! Todos os Transformer lidam com batches, mesmo com uma \xFAnica sequ\xEAncia; isso seria um tamanho de batch de 1!"},{text:"3: O comprimento da sequ\xEAncia, o tamanho do batch (lote) e o tamanho das camadas ocultas",explain:"Correto!",correct:!0}]}}),le=new H({}),me=new C({props:{choices:[{text:"WordPiece",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Character-based tokenization",explain:"Character-based tokenization n\xE3o \xE9 uma tokeniza\xE7\xE3o por sub-palavra!."},{text:"Divis\xE3o no espa\xE7o em branco e pontua\xE7\xE3o",explain:"Esse \xE9 um esquema de tokenization baseado em palavras!"},{text:"BPE",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Unigram",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Nenhuma das acimas",explain:"Errado!"}]}}),de=new H({}),ce=new C({props:{choices:[{text:"Um componente dos transformers de base que redireciona os tensores para suas camadas corretas",explain:"Incorreto! N\xE3o existe tal componente."},{text:"Tamb\xE9m conhecido como mecanismo de auto-aten\xE7\xE3o (*self-attention*), ele adapta a representa\xE7\xE3o de um s\xEDmbolo de acordo com os outros tokens da sequ\xEAncia",explain:"Incorreto! A camada de auto-aten\xE7\xE3o cont\xE9m 'attention heads', mas estas n\xE3o s\xE3o as heads de adapta\xE7\xE3o."},{text:"Um componente adicional, geralmente composto de uma ou poucas camadas, para converter as previs\xF5es do Transformer em uma sa\xEDda espec\xEDfica de tarefa",explain:"\xC9 isso mesmo. As heads de adapta\xE7\xE3o, tamb\xE9m conhecidos simplesmente como heads, surgem em diferentes formas: heads de modelagem de linguagem, heads de resposta a perguntas, heads de classifica\xE7\xE3o de sequ\xEAncia.. ",correct:!0}]}});const Qa=[Ao,zo],qe=[];function Ua(e,m){return e[0]==="pt"?0:1}U=Ua(Q),D=qe[U]=Qa[U](Q),pe=new H({}),fe=new C({props:{choices:[{text:"Truncar",explain:"Sim, a truncagem \xE9 uma forma correta de sequ\xEAncias de sa\xEDda noturna para que elas se encaixem em forma retangular.No entanto, seria a \xFAnica?",correct:!0},{text:"Retornar tensores",explain:"Enquanto as outras t\xE9cnicas permitem retornar tensores retangulares, retornar tensores n\xE3o \xE9 \xFAtil quando realizar batches de sequ\xEAncias juntas."},{text:"Padding",explain:"Sim, padding \xE9 uma forma correta para as sequ\xEAncias de sa\xEDda para que elas se encaixem em uma forma retangular. No entanto, seria a \xFAnica?",correct:!0},{text:"Attention masking",explain:"Exatamente! As attention masks s\xE3o de primordial import\xE2ncia quando se trata de sequ\xEAncias de diferentes tamanhos. No entanto, essa n\xE3o \xE9 a \xFAnica t\xE9cnica a ser conhecida.",correct:!0}]}}),he=new H({}),$e=new C({props:{choices:[{text:"Suaviza os logits para que sejam mais confi\xE1veis.",explain:"N\xE3o, a fun\xE7\xE3o SoftMax n\xE3o afeta a confiabilidade dos resultados."},{text:"Aplica um limite inferior e um limite superior para que eles sejam compreens\xEDveis.",explain:"Correto! Os valores resultantes est\xE3o vinculados entre 0 e 1. Mas essa n\xE3o \xE9 a \xFAnica raz\xE3o pela qual usamos uma fun\xE7\xE3o SoftMax.",correct:!0},{text:"A soma total da sa\xEDda \xE9 1, resultando em uma poss\xEDvel interpreta\xE7\xE3o probabil\xEDstica.",explain:"Correto! Mas essa n\xE3o \xE9 a \xFAnica raz\xE3o pela qual usamos uma fun\xE7\xE3o SoftMax.",correct:!0}]}}),ve=new H({}),ge=new C({props:{choices:[{text:"<code>encode</code>, pois pode codificar texto em IDs e IDs em predi\xE7\xF5es",explain:"Errado! O m\xE9todo <code>encode</code> existe na tokeniza\xE7\xE3o, por\xE9m n\xE3o existe nos modelos."},{text:"Chamando diretamente o objeto de tokeniza\xE7\xE3o (tokenizer).",explain:"Exatamente! O m\xE9todo <code>__call__</code> do tokenizer \xE9 um m\xE9todo muito poderoso que pode lidar com praticamente qualquer coisa. \xC9 tamb\xE9m o m\xE9todo usado para recuperar as predi\xE7\xF5es de um modelo.",correct:!0},{text:"<code>padding</code>",explain:"Errado! O padding \xE9 muito \xFAtil, mas \xE9 apenas uma parte da API do tokenizer."},{text:"<code>tokenize</code>",explain:"O m\xE9todo <code>tokenize</code> \xE9 indiscutivelmente um dos m\xE9todos mais \xFAteis, mas n\xE3o \xE9 o n\xFAcleo do API do tokenizer."}]}}),ke=new H({}),_e=new Ca({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
result = tokenizer.tokenize("Hello!")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
result = tokenizer.tokenize(<span class="hljs-string">&quot;Hello!&quot;</span>)`}}),be=new C({props:{choices:[{text:"Uma lista de strings, sendo cada uma delas um token",explain:"Exatamente! Converta isto em IDs, e envie-os para um modelo!",correct:!0},{text:"Uma lista de IDs",explain:"Incorreto; isto \xE9 o para o os m\xE9todos <code>__call__</code> ou <code>convert_tokens_to_ids</code>!"},{text:"Uma string contendo todos os tokens ",explain:"Isto seria sub\xF3timo, pois o objetivo \xE9 dividir a string em v\xE1rios tokens."}]}});const Da=[yo,Eo],we=[];function Fa(e,m){return e[0]==="pt"?0:1}return F=Fa(Q),B=we[F]=Da[F](Q),{c(){d=s("meta"),u=p(),b(v.$$.fragment),h=p(),N=s("h1"),$=s("a"),S=s("span"),b(A.$$.fragment),y=p(),P=s("span"),E=T("Question\xE1rio de fim de cap\xEDtulo"),_=p(),b(t.$$.fragment),r=p(),x=s("h3"),j=s("a"),M=s("span"),b(I.$$.fragment),L=p(),Pe=s("span"),ka=T("1. Qual \xE9 a ordem do pipeline para a modelagem de linguagem?"),Ve=p(),b(se.$$.fragment),Re=p(),V=s("h3"),Y=s("a"),Se=s("span"),b(ne.$$.fragment),xa=p(),Te=s("span"),_a=T("2. Quantas dimens\xF5es tem o tensor do Transformer de base, e quais s\xE3o elas?"),Ge=p(),b(ie.$$.fragment),Je=p(),R=s("h3"),Z=s("a"),Oe=s("span"),b(le.$$.fragment),ba=p(),je=s("span"),qa=T("3. Qual dos seguintes \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavras?"),We=p(),b(me.$$.fragment),Ke=p(),G=s("h3"),ee=s("a"),Me=s("span"),b(de.$$.fragment),wa=p(),ue=s("span"),za=T("4. O que \xE9 uma "),Ie=s("em"),Aa=T("model head"),Ea=T("?"),Xe=p(),b(ce.$$.fragment),Ye=p(),D.c(),Ae=p(),J=s("h3"),ae=s("a"),He=s("span"),b(pe.$$.fragment),ya=p(),Ce=s("span"),Na=T("6. Quais s\xE3o as t\xE9cnicas a serem observadas quando realizar batches com sequ\xEAncias de diferentes tamanhos?"),Ze=p(),b(fe.$$.fragment),ea=p(),W=s("h3"),oe=s("a"),Qe=s("span"),b(he.$$.fragment),Pa=p(),Ue=s("span"),Sa=T("7. Qual \xE9 o objetivo de aplicar uma fun\xE7\xE3o SoftMax \xE0 sa\xEDda de logits para um modelo de classifica\xE7\xE3o sequencial??"),aa=p(),b($e.$$.fragment),oa=p(),K=s("h3"),te=s("a"),De=s("span"),b(ve.$$.fragment),Ta=p(),Fe=s("span"),Oa=T("8. Qual \xE9 o m\xE9todo core da API tokenizer?"),ta=p(),b(ge.$$.fragment),ra=p(),X=s("h3"),re=s("a"),Be=s("span"),b(ke.$$.fragment),ja=p(),xe=s("span"),Ma=T("9. O que a vari\xE1vel "),Le=s("code"),Ia=T("result"),Ha=T(" cont\xE9m nesta peda\xE7o de c\xF3digo?"),sa=p(),b(_e.$$.fragment),na=p(),b(be.$$.fragment),ia=p(),B.c(),Ee=ho(),this.h()},l(e){const m=_o('[data-svelte="svelte-1phssyn"]',document.head);d=n(m,"META",{name:!0,content:!0}),m.forEach(a),u=f(e),q(v.$$.fragment,e),h=f(e),N=n(e,"H1",{class:!0});var ze=i(N);$=n(ze,"A",{id:!0,class:!0,href:!0});var ye=i($);S=n(ye,"SPAN",{});var Ne=i(S);q(A.$$.fragment,Ne),Ne.forEach(a),ye.forEach(a),y=f(ze),P=n(ze,"SPAN",{});var Ba=i(P);E=O(Ba,"Question\xE1rio de fim de cap\xEDtulo"),Ba.forEach(a),ze.forEach(a),_=f(e),q(t.$$.fragment,e),r=f(e),x=n(e,"H3",{class:!0});var ma=i(x);j=n(ma,"A",{id:!0,class:!0,href:!0});var La=i(j);M=n(La,"SPAN",{});var Va=i(M);q(I.$$.fragment,Va),Va.forEach(a),La.forEach(a),L=f(ma),Pe=n(ma,"SPAN",{});var Ra=i(Pe);ka=O(Ra,"1. Qual \xE9 a ordem do pipeline para a modelagem de linguagem?"),Ra.forEach(a),ma.forEach(a),Ve=f(e),q(se.$$.fragment,e),Re=f(e),V=n(e,"H3",{class:!0});var da=i(V);Y=n(da,"A",{id:!0,class:!0,href:!0});var Ga=i(Y);Se=n(Ga,"SPAN",{});var Ja=i(Se);q(ne.$$.fragment,Ja),Ja.forEach(a),Ga.forEach(a),xa=f(da),Te=n(da,"SPAN",{});var Wa=i(Te);_a=O(Wa,"2. Quantas dimens\xF5es tem o tensor do Transformer de base, e quais s\xE3o elas?"),Wa.forEach(a),da.forEach(a),Ge=f(e),q(ie.$$.fragment,e),Je=f(e),R=n(e,"H3",{class:!0});var ua=i(R);Z=n(ua,"A",{id:!0,class:!0,href:!0});var Ka=i(Z);Oe=n(Ka,"SPAN",{});var Xa=i(Oe);q(le.$$.fragment,Xa),Xa.forEach(a),Ka.forEach(a),ba=f(ua),je=n(ua,"SPAN",{});var Ya=i(je);qa=O(Ya,"3. Qual dos seguintes \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavras?"),Ya.forEach(a),ua.forEach(a),We=f(e),q(me.$$.fragment,e),Ke=f(e),G=n(e,"H3",{class:!0});var ca=i(G);ee=n(ca,"A",{id:!0,class:!0,href:!0});var Za=i(ee);Me=n(Za,"SPAN",{});var eo=i(Me);q(de.$$.fragment,eo),eo.forEach(a),Za.forEach(a),wa=f(ca),ue=n(ca,"SPAN",{});var pa=i(ue);za=O(pa,"4. O que \xE9 uma "),Ie=n(pa,"EM",{});var ao=i(Ie);Aa=O(ao,"model head"),ao.forEach(a),Ea=O(pa,"?"),pa.forEach(a),ca.forEach(a),Xe=f(e),q(ce.$$.fragment,e),Ye=f(e),D.l(e),Ae=f(e),J=n(e,"H3",{class:!0});var fa=i(J);ae=n(fa,"A",{id:!0,class:!0,href:!0});var oo=i(ae);He=n(oo,"SPAN",{});var to=i(He);q(pe.$$.fragment,to),to.forEach(a),oo.forEach(a),ya=f(fa),Ce=n(fa,"SPAN",{});var ro=i(Ce);Na=O(ro,"6. Quais s\xE3o as t\xE9cnicas a serem observadas quando realizar batches com sequ\xEAncias de diferentes tamanhos?"),ro.forEach(a),fa.forEach(a),Ze=f(e),q(fe.$$.fragment,e),ea=f(e),W=n(e,"H3",{class:!0});var ha=i(W);oe=n(ha,"A",{id:!0,class:!0,href:!0});var so=i(oe);Qe=n(so,"SPAN",{});var no=i(Qe);q(he.$$.fragment,no),no.forEach(a),so.forEach(a),Pa=f(ha),Ue=n(ha,"SPAN",{});var io=i(Ue);Sa=O(io,"7. Qual \xE9 o objetivo de aplicar uma fun\xE7\xE3o SoftMax \xE0 sa\xEDda de logits para um modelo de classifica\xE7\xE3o sequencial??"),io.forEach(a),ha.forEach(a),aa=f(e),q($e.$$.fragment,e),oa=f(e),K=n(e,"H3",{class:!0});var $a=i(K);te=n($a,"A",{id:!0,class:!0,href:!0});var lo=i(te);De=n(lo,"SPAN",{});var mo=i(De);q(ve.$$.fragment,mo),mo.forEach(a),lo.forEach(a),Ta=f($a),Fe=n($a,"SPAN",{});var uo=i(Fe);Oa=O(uo,"8. Qual \xE9 o m\xE9todo core da API tokenizer?"),uo.forEach(a),$a.forEach(a),ta=f(e),q(ge.$$.fragment,e),ra=f(e),X=n(e,"H3",{class:!0});var va=i(X);re=n(va,"A",{id:!0,class:!0,href:!0});var co=i(re);Be=n(co,"SPAN",{});var po=i(Be);q(ke.$$.fragment,po),po.forEach(a),co.forEach(a),ja=f(va),xe=n(va,"SPAN",{});var ga=i(xe);Ma=O(ga,"9. O que a vari\xE1vel "),Le=n(ga,"CODE",{});var fo=i(Le);Ia=O(fo,"result"),fo.forEach(a),Ha=O(ga," cont\xE9m nesta peda\xE7o de c\xF3digo?"),ga.forEach(a),va.forEach(a),sa=f(e),q(_e.$$.fragment,e),na=f(e),q(be.$$.fragment,e),ia=f(e),B.l(e),Ee=ho(),this.h()},h(){l(d,"name","hf:doc:metadata"),l(d,"content",JSON.stringify(Po)),l($,"id","questionrio-de-fim-de-captulo"),l($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l($,"href","#questionrio-de-fim-de-captulo"),l(N,"class","relative group"),l(j,"id","1.-qual-\xE9-a-ordem-do-pipeline-para-a-modelagem-de-linguagem?"),l(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(j,"href","#1.-qual-\xE9-a-ordem-do-pipeline-para-a-modelagem-de-linguagem?"),l(x,"class","relative group"),l(Y,"id","2.-quantas-dimens\xF5es-tem-o-tensor-do-transformer-de-base,-e-quais-s\xE3o-elas?"),l(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Y,"href","#2.-quantas-dimens\xF5es-tem-o-tensor-do-transformer-de-base,-e-quais-s\xE3o-elas?"),l(V,"class","relative group"),l(Z,"id","3.-qual-dos-seguintes-\xE9-um-exemplo-de-tokeniza\xE7\xE3o-por-sub-palavras?"),l(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Z,"href","#3.-qual-dos-seguintes-\xE9-um-exemplo-de-tokeniza\xE7\xE3o-por-sub-palavras?"),l(R,"class","relative group"),l(ee,"id","4.-o-que-\xE9-uma-<em>model-head</em>?"),l(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ee,"href","#4.-o-que-\xE9-uma-<em>model-head</em>?"),l(G,"class","relative group"),l(ae,"id","6.-quais-s\xE3o-as-t\xE9cnicas-a-serem-observadas-quando-realizar-batches-com-sequ\xEAncias-de-diferentes-tamanhos?"),l(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ae,"href","#6.-quais-s\xE3o-as-t\xE9cnicas-a-serem-observadas-quando-realizar-batches-com-sequ\xEAncias-de-diferentes-tamanhos?"),l(J,"class","relative group"),l(oe,"id","7.-qual-\xE9-o-objetivo-de-aplicar-uma-fun\xE7\xE3o-softmax-\xE0-sa\xEDda-de-logits-para-um-modelo-de-classifica\xE7\xE3o-sequencial??"),l(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(oe,"href","#7.-qual-\xE9-o-objetivo-de-aplicar-uma-fun\xE7\xE3o-softmax-\xE0-sa\xEDda-de-logits-para-um-modelo-de-classifica\xE7\xE3o-sequencial??"),l(W,"class","relative group"),l(te,"id","8.-qual-\xE9-o-m\xE9todo-core-da-api-tokenizer?"),l(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(te,"href","#8.-qual-\xE9-o-m\xE9todo-core-da-api-tokenizer?"),l(K,"class","relative group"),l(re,"id","9.-o-que-a-vari\xE1vel-<code>result</code>-cont\xE9m-nesta-peda\xE7o-de-c\xF3digo?"),l(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(re,"href","#9.-o-que-a-vari\xE1vel-<code>result</code>-cont\xE9m-nesta-peda\xE7o-de-c\xF3digo?"),l(X,"class","relative group")},m(e,m){o(document.head,d),c(e,u,m),w(v,e,m),c(e,h,m),c(e,N,m),o(N,$),o($,S),w(A,S,null),o(N,y),o(N,P),o(P,E),c(e,_,m),w(t,e,m),c(e,r,m),c(e,x,m),o(x,j),o(j,M),w(I,M,null),o(x,L),o(x,Pe),o(Pe,ka),c(e,Ve,m),w(se,e,m),c(e,Re,m),c(e,V,m),o(V,Y),o(Y,Se),w(ne,Se,null),o(V,xa),o(V,Te),o(Te,_a),c(e,Ge,m),w(ie,e,m),c(e,Je,m),c(e,R,m),o(R,Z),o(Z,Oe),w(le,Oe,null),o(R,ba),o(R,je),o(je,qa),c(e,We,m),w(me,e,m),c(e,Ke,m),c(e,G,m),o(G,ee),o(ee,Me),w(de,Me,null),o(G,wa),o(G,ue),o(ue,za),o(ue,Ie),o(Ie,Aa),o(ue,Ea),c(e,Xe,m),w(ce,e,m),c(e,Ye,m),qe[U].m(e,m),c(e,Ae,m),c(e,J,m),o(J,ae),o(ae,He),w(pe,He,null),o(J,ya),o(J,Ce),o(Ce,Na),c(e,Ze,m),w(fe,e,m),c(e,ea,m),c(e,W,m),o(W,oe),o(oe,Qe),w(he,Qe,null),o(W,Pa),o(W,Ue),o(Ue,Sa),c(e,aa,m),w($e,e,m),c(e,oa,m),c(e,K,m),o(K,te),o(te,De),w(ve,De,null),o(K,Ta),o(K,Fe),o(Fe,Oa),c(e,ta,m),w(ge,e,m),c(e,ra,m),c(e,X,m),o(X,re),o(re,Be),w(ke,Be,null),o(X,ja),o(X,xe),o(xe,Ma),o(xe,Le),o(Le,Ia),o(xe,Ha),c(e,sa,m),w(_e,e,m),c(e,na,m),w(be,e,m),c(e,ia,m),we[F].m(e,m),c(e,Ee,m),la=!0},p(e,[m]){const ze={};m&1&&(ze.fw=e[0]),v.$set(ze);let ye=U;U=Ua(e),U!==ye&&(vo(),g(qe[ye],1,1,()=>{qe[ye]=null}),$o(),D=qe[U],D||(D=qe[U]=Qa[U](e),D.c()),k(D,1),D.m(Ae.parentNode,Ae));let Ne=F;F=Fa(e),F!==Ne&&(vo(),g(we[Ne],1,1,()=>{we[Ne]=null}),$o(),B=we[F],B||(B=we[F]=Da[F](e),B.c()),k(B,1),B.m(Ee.parentNode,Ee))},i(e){la||(k(v.$$.fragment,e),k(A.$$.fragment,e),k(t.$$.fragment,e),k(I.$$.fragment,e),k(se.$$.fragment,e),k(ne.$$.fragment,e),k(ie.$$.fragment,e),k(le.$$.fragment,e),k(me.$$.fragment,e),k(de.$$.fragment,e),k(ce.$$.fragment,e),k(D),k(pe.$$.fragment,e),k(fe.$$.fragment,e),k(he.$$.fragment,e),k($e.$$.fragment,e),k(ve.$$.fragment,e),k(ge.$$.fragment,e),k(ke.$$.fragment,e),k(_e.$$.fragment,e),k(be.$$.fragment,e),k(B),la=!0)},o(e){g(v.$$.fragment,e),g(A.$$.fragment,e),g(t.$$.fragment,e),g(I.$$.fragment,e),g(se.$$.fragment,e),g(ne.$$.fragment,e),g(ie.$$.fragment,e),g(le.$$.fragment,e),g(me.$$.fragment,e),g(de.$$.fragment,e),g(ce.$$.fragment,e),g(D),g(pe.$$.fragment,e),g(fe.$$.fragment,e),g(he.$$.fragment,e),g($e.$$.fragment,e),g(ve.$$.fragment,e),g(ge.$$.fragment,e),g(ke.$$.fragment,e),g(_e.$$.fragment,e),g(be.$$.fragment,e),g(B),la=!1},d(e){a(d),e&&a(u),z(v,e),e&&a(h),e&&a(N),z(A),e&&a(_),z(t,e),e&&a(r),e&&a(x),z(I),e&&a(Ve),z(se,e),e&&a(Re),e&&a(V),z(ne),e&&a(Ge),z(ie,e),e&&a(Je),e&&a(R),z(le),e&&a(We),z(me,e),e&&a(Ke),e&&a(G),z(de),e&&a(Xe),z(ce,e),e&&a(Ye),qe[U].d(e),e&&a(Ae),e&&a(J),z(pe),e&&a(Ze),z(fe,e),e&&a(ea),e&&a(W),z(he),e&&a(aa),z($e,e),e&&a(oa),e&&a(K),z(ve),e&&a(ta),z(ge,e),e&&a(ra),e&&a(X),z(ke),e&&a(sa),z(_e,e),e&&a(na),z(be,e),e&&a(ia),we[F].d(e),e&&a(Ee)}}}const Po={local:"questionrio-de-fim-de-captulo",title:"Question\xE1rio de fim de cap\xEDtulo"};function So(Q,d,u){let v="pt";return bo(()=>{const h=new URLSearchParams(window.location.search);u(0,v=h.get("fw")||"pt")}),[v]}class Co extends go{constructor(d){super();ko(this,d,So,No,xo,{})}}export{Co as default,Po as metadata};
