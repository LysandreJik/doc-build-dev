import{S as Be,i as Ie,s as Se,e as s,k as u,w as ye,t as d,M as ke,c as t,d as a,m as p,a as r,x as Me,h as i,b as n,G as o,g as m,y as Pe,L as Re,q as Te,o as Le,B as Oe,v as je}from"../../chunks/vendor-hf-doc-builder.js";import{I as Ce}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ne}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function Ue(me){let f,R,v,h,T,b,K,L,Q,j,g,C,_,V,O,W,X,N,q,Y,$,Z,ee,U,M,ae,z,P,oe,F,c,B,w,se,te,I,x,re,le,S,A,ne,de,k,y,ie,G;return b=new Ce({}),g=new Ne({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),{c(){f=s("meta"),R=u(),v=s("h1"),h=s("a"),T=s("span"),ye(b.$$.fragment),K=u(),L=s("span"),Q=d("Modelos sequ\xEAncia a sequ\xEAncia"),j=u(),ye(g.$$.fragment),C=u(),_=s("p"),V=d("Modelos encoder-decoder (tamb\xE9m chamados de modelos "),O=s("em"),W=d("sequence-to-sequence"),X=d(") usam ambas as partes da arquitetura Transformer. Em cada est\xE1gio, as camadas de aten\xE7\xE3o do codificador podem acessar todas as palavras da frase inicial, enquanto as camadas de aten\xE7\xE3o do decodificador podem acessar apenas as palavras posicionadas antes de uma determinada palavra na entrada."),N=u(),q=s("p"),Y=d("O pr\xE9-treinamento desses modelos pode ser feito usando os objetivos dos modelos de codificador ou decodificador, mas geralmente envolve algo um pouco mais complexo. Por exemplo,\xA0"),$=s("a"),Z=d("T5"),ee=d("\xA0\xE9 pr\xE9-treinado substituindo trechos aleat\xF3rios de texto (que podem conter v\xE1rias palavras) por uma \xFAnica palavra especial de m\xE1scara, e o objetivo \xE9 prever o texto que esta palavra de m\xE1scara substitui."),U=u(),M=s("p"),ae=d("Os modelos de sequ\xEAncia a sequ\xEAncia s\xE3o mais adequados para tarefas que envolvem a gera\xE7\xE3o de novas frases dependendo de uma determinada entrada, como resumo, tradu\xE7\xE3o ou resposta a perguntas generativas."),z=u(),P=s("p"),oe=d("Os representantes desta fam\xEDlia de modelos incluem:"),F=u(),c=s("ul"),B=s("li"),w=s("a"),se=d("BART"),te=u(),I=s("li"),x=s("a"),re=d("mBART"),le=u(),S=s("li"),A=s("a"),ne=d("Marian"),de=u(),k=s("li"),y=s("a"),ie=d("T5"),this.h()},l(e){const l=ke('[data-svelte="svelte-1phssyn"]',document.head);f=t(l,"META",{name:!0,content:!0}),l.forEach(a),R=p(e),v=t(e,"H1",{class:!0});var H=r(v);h=t(H,"A",{id:!0,class:!0,href:!0});var ce=r(h);T=t(ce,"SPAN",{});var ue=r(T);Me(b.$$.fragment,ue),ue.forEach(a),ce.forEach(a),K=p(H),L=t(H,"SPAN",{});var pe=r(L);Q=i(pe,"Modelos sequ\xEAncia a sequ\xEAncia"),pe.forEach(a),H.forEach(a),j=p(e),Me(g.$$.fragment,e),C=p(e),_=t(e,"P",{});var J=r(_);V=i(J,"Modelos encoder-decoder (tamb\xE9m chamados de modelos "),O=t(J,"EM",{});var fe=r(O);W=i(fe,"sequence-to-sequence"),fe.forEach(a),X=i(J,") usam ambas as partes da arquitetura Transformer. Em cada est\xE1gio, as camadas de aten\xE7\xE3o do codificador podem acessar todas as palavras da frase inicial, enquanto as camadas de aten\xE7\xE3o do decodificador podem acessar apenas as palavras posicionadas antes de uma determinada palavra na entrada."),J.forEach(a),N=p(e),q=t(e,"P",{});var D=r(q);Y=i(D,"O pr\xE9-treinamento desses modelos pode ser feito usando os objetivos dos modelos de codificador ou decodificador, mas geralmente envolve algo um pouco mais complexo. Por exemplo,\xA0"),$=t(D,"A",{href:!0,rel:!0});var ve=r($);Z=i(ve,"T5"),ve.forEach(a),ee=i(D,"\xA0\xE9 pr\xE9-treinado substituindo trechos aleat\xF3rios de texto (que podem conter v\xE1rias palavras) por uma \xFAnica palavra especial de m\xE1scara, e o objetivo \xE9 prever o texto que esta palavra de m\xE1scara substitui."),D.forEach(a),U=p(e),M=t(e,"P",{});var he=r(M);ae=i(he,"Os modelos de sequ\xEAncia a sequ\xEAncia s\xE3o mais adequados para tarefas que envolvem a gera\xE7\xE3o de novas frases dependendo de uma determinada entrada, como resumo, tradu\xE7\xE3o ou resposta a perguntas generativas."),he.forEach(a),z=p(e),P=t(e,"P",{});var _e=r(P);oe=i(_e,"Os representantes desta fam\xEDlia de modelos incluem:"),_e.forEach(a),F=p(e),c=t(e,"UL",{});var E=r(c);B=t(E,"LI",{});var qe=r(B);w=t(qe,"A",{href:!0,rel:!0});var Ee=r(w);se=i(Ee,"BART"),Ee.forEach(a),qe.forEach(a),te=p(E),I=t(E,"LI",{});var be=r(I);x=t(be,"A",{href:!0,rel:!0});var ge=r(x);re=i(ge,"mBART"),ge.forEach(a),be.forEach(a),le=p(E),S=t(E,"LI",{});var $e=r(S);A=t($e,"A",{href:!0,rel:!0});var we=r(A);ne=i(we,"Marian"),we.forEach(a),$e.forEach(a),de=p(E),k=t(E,"LI",{});var xe=r(k);y=t(xe,"A",{href:!0,rel:!0});var Ae=r(y);ie=i(Ae,"T5"),Ae.forEach(a),xe.forEach(a),E.forEach(a),this.h()},h(){n(f,"name","hf:doc:metadata"),n(f,"content",JSON.stringify(ze)),n(h,"id","modelos-sequncia-a-sequncia"),n(h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(h,"href","#modelos-sequncia-a-sequncia"),n(v,"class","relative group"),n($,"href","https://huggingface.co/t5-base"),n($,"rel","nofollow"),n(w,"href","https://huggingface.co/transformers/model_doc/bart.html"),n(w,"rel","nofollow"),n(x,"href","https://huggingface.co/transformers/model_doc/mbart.html"),n(x,"rel","nofollow"),n(A,"href","https://huggingface.co/transformers/model_doc/marian.html"),n(A,"rel","nofollow"),n(y,"href","https://huggingface.co/transformers/model_doc/t5.html"),n(y,"rel","nofollow")},m(e,l){o(document.head,f),m(e,R,l),m(e,v,l),o(v,h),o(h,T),Pe(b,T,null),o(v,K),o(v,L),o(L,Q),m(e,j,l),Pe(g,e,l),m(e,C,l),m(e,_,l),o(_,V),o(_,O),o(O,W),o(_,X),m(e,N,l),m(e,q,l),o(q,Y),o(q,$),o($,Z),o(q,ee),m(e,U,l),m(e,M,l),o(M,ae),m(e,z,l),m(e,P,l),o(P,oe),m(e,F,l),m(e,c,l),o(c,B),o(B,w),o(w,se),o(c,te),o(c,I),o(I,x),o(x,re),o(c,le),o(c,S),o(S,A),o(A,ne),o(c,de),o(c,k),o(k,y),o(y,ie),G=!0},p:Re,i(e){G||(Te(b.$$.fragment,e),Te(g.$$.fragment,e),G=!0)},o(e){Le(b.$$.fragment,e),Le(g.$$.fragment,e),G=!1},d(e){a(f),e&&a(R),e&&a(v),Oe(b),e&&a(j),Oe(g,e),e&&a(C),e&&a(_),e&&a(N),e&&a(q),e&&a(U),e&&a(M),e&&a(z),e&&a(P),e&&a(F),e&&a(c)}}}const ze={local:"modelos-sequncia-a-sequncia",title:"Modelos sequ\xEAncia a sequ\xEAncia"};function Fe(me){return je(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class De extends Be{constructor(f){super();Ie(this,f,Fe,Ue,Se,{})}}export{De as default,ze as metadata};
