import{S as Xi,i as Zi,s as el,e as i,k as f,w as ve,t,R as al,c as l,d as r,m as d,a as n,x as ye,h as o,b as s,T as Qi,G as a,g as m,y as be,L as rl,q as ze,o as _e,B as we,v as il}from"../../chunks/vendor-hf-doc-builder.js";import{Y as ll}from"../../chunks/Youtube-hf-doc-builder.js";import{I as $a}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as nl}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function tl(ri){let y,Ve,b,$,Ee,S,Ta,Ae,Ma,Qe,F,Xe,z,T,Pe,I,Da,Le,Ha,Ze,G,ea,k,Na,C,Ba,Sa,K,Fa,Ia,O,Ga,Ca,R,Ka,Oa,x,Ra,xa,j,ja,Ua,aa,_,M,$e,U,qa,Te,Ja,ra,fe,Wa,ia,w,q,ii,Ya,J,li,la,p,W,Va,Y,Qa,Xa,Za,Me,er,ar,De,rr,na,de,ir,ta,g,He,lr,nr,h,tr,V,or,sr,Q,ur,mr,X,fr,dr,kr,D,Z,cr,hr,ee,pr,gr,oa,H,vr,ae,yr,br,sa,E,N,Ne,re,zr,Be,_r,ua,ke,wr,ma,ie,Se,Er,Ar,fa,le,Fe,Pr,Lr,da,A,Ie,$r,Tr,Ge,ne,Mr,Dr,ka,te,Ce,Hr,Nr,ca,oe,Ke,Br,Sr,ha,P,Oe,Fr,Ir,se,Gr,Cr,pa,L,Re,Kr,Or,ue,Rr,xr,ga,ce,jr,va,v,me,Ur,xe,qr,Jr,Wr,je,Yr,Vr,Ue,Qr,ya;return S=new $a({}),F=new nl({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),I=new $a({}),G=new ll({props:{id:"00GKzGyWFEs"}}),U=new $a({}),re=new $a({}),{c(){y=i("meta"),Ve=f(),b=i("h1"),$=i("a"),Ee=i("span"),ve(S.$$.fragment),Ta=f(),Ae=i("span"),Ma=t("Giri\u015F"),Qe=f(),ve(F.$$.fragment),Xe=f(),z=i("h2"),T=i("a"),Pe=i("span"),ve(I.$$.fragment),Da=f(),Le=i("span"),Ha=t("\u{1F917} Kursuna Ho\u015Fgeldiniz!"),Ze=f(),ve(G.$$.fragment),ea=f(),k=i("p"),Na=t("Bu kurs size "),C=i("a"),Ba=t("Hugging Face"),Sa=t(" ekosistemindeki k\xFCt\xFCphaneleri \u2014 "),K=i("a"),Fa=t("\u{1F917} Transformers"),Ia=t(", "),O=i("a"),Ga=t("\u{1F917} Datasets"),Ca=t(", "),R=i("a"),Ka=t("\u{1F917} Tokenizers"),Oa=t(", ve "),x=i("a"),Ra=t("\u{1F917} Accelerate"),xa=t(" \u2014 ayr\u0131ca tabiki de "),j=i("a"),ja=t("Hugging Face Hub"),Ua=t(" kullanarak Do\u011Fal Dil \u0130\u015Fleme\u2019yi (NLP) \xF6\u011Fretecektir. Kurs tamamen \xFCcretsiz ve reklam bulunmuyor."),aa=f(),_=i("h2"),M=i("a"),$e=i("span"),ve(U.$$.fragment),qa=f(),Te=i("span"),Ja=t("Beklentiniz ne olmal\u0131?"),ra=f(),fe=i("p"),Wa=t("Burada kursa genel bak\u0131\u015F bulunmaktad\u0131r:"),ia=f(),w=i("div"),q=i("img"),Ya=f(),J=i("img"),la=f(),p=i("ul"),W=i("li"),Va=t("1\u2019den 4\u2019\xFCnc\xFC b\xF6l\xFCme kadar olan k\u0131s\u0131mda \u{1F917} Transformers k\xFCt\xFCphanesinin ana konseptlerine giri\u015F yapaca\u011F\u0131z. Kursun bu b\xF6l\xFCm\xFCn\xFCn sonunda, Transformer modellerinin nas\u0131l \xE7al\u0131\u015Ft\u0131\u011F\u0131n\u0131 \xF6\u011Frenecek, ve "),Y=i("a"),Qa=t("Hugging Face Hub"),Xa=t(" \xFCzerinden bir modeli nasil kullanabilece\u011Finizi, verisetine ince ayar (fine-tune) yapmay\u0131, ve sonu\xE7lar\u0131n\u0131z\u0131 Hub \xFCzerinde nas\u0131l payla\u015Faca\u011F\u0131n\u0131z\u0131 bileceksiniz!"),Za=f(),Me=i("li"),er=t("B\xF6l\xFCm 5 ila 8, klasik NLP g\xF6revlerine dalmadan \xF6nce \u{1F917} Datasets ve \u{1F917} Tokenizers\u2019in temellerini \xF6\u011Fretiyor. Bu b\xF6l\xFCm\xFCn sonunda, en yayg\u0131n NLP problemlerini kendiniz \xE7\xF6zebileceksiniz."),ar=f(),De=i("li"),rr=t("9\u2019dan 12\u2019ye kadar olan b\xF6l\xFCmler NLP\u2019nin \xF6tesine ge\xE7er ve Transformer modellerinin konu\u015Fma i\u015Fleme ve bilgisayarl\u0131 g\xF6r\xFC alanlar\u0131ndaki problemleri nas\u0131l \xE7\xF6zece\u011Fini ele al\u0131r. S\xFCre\xE7 boyunca, model demolar\u0131n\u0131z\u0131 nas\u0131l olu\u015Fturup payla\u015Faca\u011F\u0131n\u0131z\u0131 ve bunlar\u0131 \xFCretim ortamlar\u0131nda nas\u0131l optimize edece\u011Finizi \xF6\u011Freneceksiniz. Bu b\xF6l\xFCm\xFCn sonunda, \u{1F917} Transformers\u2019i (neredeyse) herhangi bir makine \xF6\u011Frenmesi problemine uygulamaya haz\u0131r olacaks\u0131n\u0131z!"),na=f(),de=i("p"),ir=t("Bu kurs:"),ta=f(),g=i("ul"),He=i("li"),lr=t("Python hakk\u0131nda iyi d\xFCzeyde bilgi gerektirir."),nr=f(),h=i("li"),tr=t("Giri\u015F d\xFCzeyinde derin \xF6\u011Frenme derslerinden sonra al\u0131n\u0131rsa daha iyi olur. \xD6rne\u011Fin: "),V=i("a"),or=t("fast.ai"),sr=f(),Q=i("a"),ur=t("Practical Deep Learning for Coders kursu"),mr=t(" veya "),X=i("a"),fr=t("DeepLearning.AI"),dr=t(" taraf\u0131ndan verilen herhangi program."),kr=f(),D=i("li"),Z=i("a"),cr=t("PyTorch"),hr=t(" veya "),ee=i("a"),pr=t("TensorFlow"),gr=t(" ile herhangi bir \xF6n bilgi beklenmiyor, buna ra\u011Fmen bunlardan birisine a\u015Finalik yard\u0131mc\u0131 olur."),oa=f(),H=i("p"),vr=t("Kursu bitirdikten sonra, DeepLearning.AI "),ae=i("a"),yr=t("Do\u011Fal Dil \u0130\u015Fleme Uzmanl\u0131k"),br=t(" naive Bayes ve LSTM gibi bilmeye de\u011Fer geleneksel NLP modellerinin bulundu\u011Fu seriyi izlemenizi tavsiye ediyoruz."),sa=f(),E=i("h2"),N=i("a"),Ne=i("span"),ve(re.$$.fragment),zr=f(),Be=i("span"),_r=t("Biz Kimiz?"),ua=f(),ke=i("p"),wr=t("E\u011Fitmenler hakk\u0131nda:"),ma=f(),ie=i("p"),Se=i("strong"),Er=t("Matthew Carrigan"),Ar=t(" Hugging Face\u2019de Makine \xD6\u011Frenmesi M\xFChendisi. Dublin, \u0130rlanda\u2019da ya\u015F\u0131yor ve daha \xF6nce Parse.ly\u2019de ML Engineer olarak \xE7al\u0131\u015Ft\u0131 ve onunda \xF6ncesinde Doktora sonras\u0131 Ara\u015Ft\u0131rmac\u0131 olarak Trinity College Dublin\u2019de idi. Mevcut AI mimarilerini \xF6l\xE7eklendirerek AGI\u2019a ula\u015Faca\u011F\u0131m\u0131za inanm\u0131yor, ancak ne olursa olsun robot \xF6l\xFCms\xFCzl\xFC\u011F\xFC i\xE7in b\xFCy\xFCk umutlar\u0131 var."),fa=f(),le=i("p"),Fe=i("strong"),Pr=t("Lysandre Debut"),Lr=t(" Hugging Face\u2019de Makine \xD6\u011Frenmesi M\xFChendisi  ve \u{1F917} Transformers k\xFCt\xFCphanesi \xFCzerine erken geli\u015Fim a\u015Famas\u0131ndan beri \xE7al\u0131\u015F\u0131yor. Hedefi \xE7ok basit bir API geli\u015Ftirerek NLP\u2019yi herkes i\xE7in ula\u015F\u0131labilir k\u0131lmak."),da=f(),A=i("p"),Ie=i("strong"),$r=t("Sylvain Guggeat"),Tr=t(" Hugging Face\u2019de Ara\u015Ft\u0131rma M\xFChendisi ve \u{1F917} Transformers k\xFCt\xFCphanesinin proje y\xFCr\xFCt\xFCc\xFClerinden biri. \xD6ncesinde Ara\u015Ft\u0131rma Bilimci olarak fast.ai\u2019da \xE7al\u0131\u015Ft\u0131, ve "),Ge=i("em"),ne=i("a"),Mr=t("Deep Learning for Coders with fastai and PyTorch"),Dr=t(" kitab\u0131n\u0131 Jeremy Howard ile birlikte yazd\u0131. Sylvain\u2019in ara\u015Ft\u0131rmalar\u0131n\u0131n ana oda\u011F\u0131 modellerin s\u0131n\u0131rl\u0131 kaynaklarda daha h\u0131zl\u0131 e\u011Fitilmesine izin veren teknikleri tasarlay\u0131p geli\u015Ftirerek derin \xF6\u011Frenmeyi herkes i\xE7in ula\u015F\u0131labilir k\u0131lmak."),ka=f(),te=i("p"),Ce=i("strong"),Hr=t("Merve Noyan"),Nr=t(" Hugging Face\u2019de Developer Advocate, ara\xE7lar geli\u015Ftirerek ve bu ara\xE7lar etraf\u0131nda i\xE7erik \xFCreterek makine \xF6\u011Frenmesini herkes i\xE7in demokratikle\u015Ftirme \xFCzerine \xE7al\u0131\u015F\u0131yor."),ca=f(),oe=i("p"),Ke=i("strong"),Br=t("Lucile Saulnier"),Sr=t(" Hugging Face\u2019de Makine \xD6\u011Frenmesi M\xFChendisi, a\xE7\u0131k kaynak ara\xE7lar\u0131n\u0131n geli\u015Ftirilmesi ve desteklenmesi \xFCzerine u\u011Fra\u015F\u0131yor. Ayr\u0131ca Do\u011Fal Dil \u0130\u015Fleme i\xE7inde Collaborative Training ve BigScience gibi bir\xE7ok ara\u015Ft\u0131rma projesine dahil."),ha=f(),P=i("p"),Oe=i("strong"),Fr=t("Lewis Tunstall"),Ir=t(" Hugging Face\u2019de Makine \xD6\u011Frenmesi M\xFChendisi, a\xE7\u0131k kaynak ara\xE7lar\u0131 geli\u015Ftirmeye ve bunlari daha geni\u015F bir topluluk i\xE7in ula\u015F\u0131labilir hale getirmeye odaklanm\u0131\u015F. Ayr\u0131ca yak\u0131nda gelecek olan "),se=i("a"),Gr=t("Transformers \xFCzerine O\u2019Reilly kitab\u0131n\u0131n"),Cr=t(" yazarlar\u0131ndan biri."),pa=f(),L=i("p"),Re=i("strong"),Kr=t("Leandro von Werra"),Or=t("  Hugging Face\u2019de A\xE7\u0131k-Kaynak tak\u0131m\u0131nda Makine \xD6\u011Frenmesi M\xFChendisi ve ayrica yak\u0131nda gelecek olan "),ue=i("a"),Rr=t("Transformers \xFCzerine olan O\u2019Reilly kitabinin"),xr=t(" yazarlar\u0131ndan biri. T\xFCm Makine \xD6\u011Frenmesi stack\u2019inde \xE7ali\u015Farak NLP projelerini \xFCretime getiren birka\xE7 y\u0131ll\u0131k end\xFCstri deneyimine sahiptir."),ga=f(),ce=i("p"),jr=t("Ba\u015Flamaya haz\u0131r m\u0131s\u0131n? Bu b\xF6l\xFCmde, \u015Funlar\u0131 \xF6\u011Freneceksin:"),va=f(),v=i("ul"),me=i("li"),Ur=t("Metin olu\u015Fturma ve s\u0131n\u0131fland\u0131rma gibi NLP g\xF6revlerini \xE7\xF6zmek i\xE7in "),xe=i("code"),qr=t("pipeline ()"),Jr=t(" fonksiyonu nas\u0131l kullan\u0131laca\u011F\u0131?"),Wr=f(),je=i("li"),Yr=t("Transformer mimarisi"),Vr=f(),Ue=i("li"),Qr=t("Encoder, Decoder, ve Encoder-Decoder mimarilerini nasil ay\u0131rt edilece\u011Fi ve kullan\u0131m alanlari"),this.h()},l(e){const u=al('[data-svelte="svelte-1phssyn"]',document.head);y=l(u,"META",{name:!0,content:!0}),u.forEach(r),Ve=d(e),b=l(e,"H1",{class:!0});var ba=n(b);$=l(ba,"A",{id:!0,class:!0,href:!0});var ni=n($);Ee=l(ni,"SPAN",{});var ti=n(Ee);ye(S.$$.fragment,ti),ti.forEach(r),ni.forEach(r),Ta=d(ba),Ae=l(ba,"SPAN",{});var oi=n(Ae);Ma=o(oi,"Giri\u015F"),oi.forEach(r),ba.forEach(r),Qe=d(e),ye(F.$$.fragment,e),Xe=d(e),z=l(e,"H2",{class:!0});var za=n(z);T=l(za,"A",{id:!0,class:!0,href:!0});var si=n(T);Pe=l(si,"SPAN",{});var ui=n(Pe);ye(I.$$.fragment,ui),ui.forEach(r),si.forEach(r),Da=d(za),Le=l(za,"SPAN",{});var mi=n(Le);Ha=o(mi,"\u{1F917} Kursuna Ho\u015Fgeldiniz!"),mi.forEach(r),za.forEach(r),Ze=d(e),ye(G.$$.fragment,e),ea=d(e),k=l(e,"P",{});var c=n(k);Na=o(c,"Bu kurs size "),C=l(c,"A",{href:!0,rel:!0});var fi=n(C);Ba=o(fi,"Hugging Face"),fi.forEach(r),Sa=o(c," ekosistemindeki k\xFCt\xFCphaneleri \u2014 "),K=l(c,"A",{href:!0,rel:!0});var di=n(K);Fa=o(di,"\u{1F917} Transformers"),di.forEach(r),Ia=o(c,", "),O=l(c,"A",{href:!0,rel:!0});var ki=n(O);Ga=o(ki,"\u{1F917} Datasets"),ki.forEach(r),Ca=o(c,", "),R=l(c,"A",{href:!0,rel:!0});var ci=n(R);Ka=o(ci,"\u{1F917} Tokenizers"),ci.forEach(r),Oa=o(c,", ve "),x=l(c,"A",{href:!0,rel:!0});var hi=n(x);Ra=o(hi,"\u{1F917} Accelerate"),hi.forEach(r),xa=o(c," \u2014 ayr\u0131ca tabiki de "),j=l(c,"A",{href:!0,rel:!0});var pi=n(j);ja=o(pi,"Hugging Face Hub"),pi.forEach(r),Ua=o(c," kullanarak Do\u011Fal Dil \u0130\u015Fleme\u2019yi (NLP) \xF6\u011Fretecektir. Kurs tamamen \xFCcretsiz ve reklam bulunmuyor."),c.forEach(r),aa=d(e),_=l(e,"H2",{class:!0});var _a=n(_);M=l(_a,"A",{id:!0,class:!0,href:!0});var gi=n(M);$e=l(gi,"SPAN",{});var vi=n($e);ye(U.$$.fragment,vi),vi.forEach(r),gi.forEach(r),qa=d(_a),Te=l(_a,"SPAN",{});var yi=n(Te);Ja=o(yi,"Beklentiniz ne olmal\u0131?"),yi.forEach(r),_a.forEach(r),ra=d(e),fe=l(e,"P",{});var bi=n(fe);Wa=o(bi,"Burada kursa genel bak\u0131\u015F bulunmaktad\u0131r:"),bi.forEach(r),ia=d(e),w=l(e,"DIV",{class:!0});var wa=n(w);q=l(wa,"IMG",{class:!0,src:!0,alt:!0}),Ya=d(wa),J=l(wa,"IMG",{class:!0,src:!0,alt:!0}),wa.forEach(r),la=d(e),p=l(e,"UL",{});var he=n(p);W=l(he,"LI",{});var Ea=n(W);Va=o(Ea,"1\u2019den 4\u2019\xFCnc\xFC b\xF6l\xFCme kadar olan k\u0131s\u0131mda \u{1F917} Transformers k\xFCt\xFCphanesinin ana konseptlerine giri\u015F yapaca\u011F\u0131z. Kursun bu b\xF6l\xFCm\xFCn\xFCn sonunda, Transformer modellerinin nas\u0131l \xE7al\u0131\u015Ft\u0131\u011F\u0131n\u0131 \xF6\u011Frenecek, ve "),Y=l(Ea,"A",{href:!0,rel:!0});var zi=n(Y);Qa=o(zi,"Hugging Face Hub"),zi.forEach(r),Xa=o(Ea," \xFCzerinden bir modeli nasil kullanabilece\u011Finizi, verisetine ince ayar (fine-tune) yapmay\u0131, ve sonu\xE7lar\u0131n\u0131z\u0131 Hub \xFCzerinde nas\u0131l payla\u015Faca\u011F\u0131n\u0131z\u0131 bileceksiniz!"),Ea.forEach(r),Za=d(he),Me=l(he,"LI",{});var _i=n(Me);er=o(_i,"B\xF6l\xFCm 5 ila 8, klasik NLP g\xF6revlerine dalmadan \xF6nce \u{1F917} Datasets ve \u{1F917} Tokenizers\u2019in temellerini \xF6\u011Fretiyor. Bu b\xF6l\xFCm\xFCn sonunda, en yayg\u0131n NLP problemlerini kendiniz \xE7\xF6zebileceksiniz."),_i.forEach(r),ar=d(he),De=l(he,"LI",{});var wi=n(De);rr=o(wi,"9\u2019dan 12\u2019ye kadar olan b\xF6l\xFCmler NLP\u2019nin \xF6tesine ge\xE7er ve Transformer modellerinin konu\u015Fma i\u015Fleme ve bilgisayarl\u0131 g\xF6r\xFC alanlar\u0131ndaki problemleri nas\u0131l \xE7\xF6zece\u011Fini ele al\u0131r. S\xFCre\xE7 boyunca, model demolar\u0131n\u0131z\u0131 nas\u0131l olu\u015Fturup payla\u015Faca\u011F\u0131n\u0131z\u0131 ve bunlar\u0131 \xFCretim ortamlar\u0131nda nas\u0131l optimize edece\u011Finizi \xF6\u011Freneceksiniz. Bu b\xF6l\xFCm\xFCn sonunda, \u{1F917} Transformers\u2019i (neredeyse) herhangi bir makine \xF6\u011Frenmesi problemine uygulamaya haz\u0131r olacaks\u0131n\u0131z!"),wi.forEach(r),he.forEach(r),na=d(e),de=l(e,"P",{});var Ei=n(de);ir=o(Ei,"Bu kurs:"),Ei.forEach(r),ta=d(e),g=l(e,"UL",{});var pe=n(g);He=l(pe,"LI",{});var Ai=n(He);lr=o(Ai,"Python hakk\u0131nda iyi d\xFCzeyde bilgi gerektirir."),Ai.forEach(r),nr=d(pe),h=l(pe,"LI",{});var B=n(h);tr=o(B,"Giri\u015F d\xFCzeyinde derin \xF6\u011Frenme derslerinden sonra al\u0131n\u0131rsa daha iyi olur. \xD6rne\u011Fin: "),V=l(B,"A",{href:!0,rel:!0});var Pi=n(V);or=o(Pi,"fast.ai"),Pi.forEach(r),sr=d(B),Q=l(B,"A",{href:!0,rel:!0});var Li=n(Q);ur=o(Li,"Practical Deep Learning for Coders kursu"),Li.forEach(r),mr=o(B," veya "),X=l(B,"A",{href:!0,rel:!0});var $i=n(X);fr=o($i,"DeepLearning.AI"),$i.forEach(r),dr=o(B," taraf\u0131ndan verilen herhangi program."),B.forEach(r),kr=d(pe),D=l(pe,"LI",{});var qe=n(D);Z=l(qe,"A",{href:!0,rel:!0});var Ti=n(Z);cr=o(Ti,"PyTorch"),Ti.forEach(r),hr=o(qe," veya "),ee=l(qe,"A",{href:!0,rel:!0});var Mi=n(ee);pr=o(Mi,"TensorFlow"),Mi.forEach(r),gr=o(qe," ile herhangi bir \xF6n bilgi beklenmiyor, buna ra\u011Fmen bunlardan birisine a\u015Finalik yard\u0131mc\u0131 olur."),qe.forEach(r),pe.forEach(r),oa=d(e),H=l(e,"P",{});var Aa=n(H);vr=o(Aa,"Kursu bitirdikten sonra, DeepLearning.AI "),ae=l(Aa,"A",{href:!0,rel:!0});var Di=n(ae);yr=o(Di,"Do\u011Fal Dil \u0130\u015Fleme Uzmanl\u0131k"),Di.forEach(r),br=o(Aa," naive Bayes ve LSTM gibi bilmeye de\u011Fer geleneksel NLP modellerinin bulundu\u011Fu seriyi izlemenizi tavsiye ediyoruz."),Aa.forEach(r),sa=d(e),E=l(e,"H2",{class:!0});var Pa=n(E);N=l(Pa,"A",{id:!0,class:!0,href:!0});var Hi=n(N);Ne=l(Hi,"SPAN",{});var Ni=n(Ne);ye(re.$$.fragment,Ni),Ni.forEach(r),Hi.forEach(r),zr=d(Pa),Be=l(Pa,"SPAN",{});var Bi=n(Be);_r=o(Bi,"Biz Kimiz?"),Bi.forEach(r),Pa.forEach(r),ua=d(e),ke=l(e,"P",{});var Si=n(ke);wr=o(Si,"E\u011Fitmenler hakk\u0131nda:"),Si.forEach(r),ma=d(e),ie=l(e,"P",{});var Xr=n(ie);Se=l(Xr,"STRONG",{});var Fi=n(Se);Er=o(Fi,"Matthew Carrigan"),Fi.forEach(r),Ar=o(Xr," Hugging Face\u2019de Makine \xD6\u011Frenmesi M\xFChendisi. Dublin, \u0130rlanda\u2019da ya\u015F\u0131yor ve daha \xF6nce Parse.ly\u2019de ML Engineer olarak \xE7al\u0131\u015Ft\u0131 ve onunda \xF6ncesinde Doktora sonras\u0131 Ara\u015Ft\u0131rmac\u0131 olarak Trinity College Dublin\u2019de idi. Mevcut AI mimarilerini \xF6l\xE7eklendirerek AGI\u2019a ula\u015Faca\u011F\u0131m\u0131za inanm\u0131yor, ancak ne olursa olsun robot \xF6l\xFCms\xFCzl\xFC\u011F\xFC i\xE7in b\xFCy\xFCk umutlar\u0131 var."),Xr.forEach(r),fa=d(e),le=l(e,"P",{});var Zr=n(le);Fe=l(Zr,"STRONG",{});var Ii=n(Fe);Pr=o(Ii,"Lysandre Debut"),Ii.forEach(r),Lr=o(Zr," Hugging Face\u2019de Makine \xD6\u011Frenmesi M\xFChendisi  ve \u{1F917} Transformers k\xFCt\xFCphanesi \xFCzerine erken geli\u015Fim a\u015Famas\u0131ndan beri \xE7al\u0131\u015F\u0131yor. Hedefi \xE7ok basit bir API geli\u015Ftirerek NLP\u2019yi herkes i\xE7in ula\u015F\u0131labilir k\u0131lmak."),Zr.forEach(r),da=d(e),A=l(e,"P",{});var Je=n(A);Ie=l(Je,"STRONG",{});var Gi=n(Ie);$r=o(Gi,"Sylvain Guggeat"),Gi.forEach(r),Tr=o(Je," Hugging Face\u2019de Ara\u015Ft\u0131rma M\xFChendisi ve \u{1F917} Transformers k\xFCt\xFCphanesinin proje y\xFCr\xFCt\xFCc\xFClerinden biri. \xD6ncesinde Ara\u015Ft\u0131rma Bilimci olarak fast.ai\u2019da \xE7al\u0131\u015Ft\u0131, ve "),Ge=l(Je,"EM",{});var Ci=n(Ge);ne=l(Ci,"A",{href:!0,rel:!0});var Ki=n(ne);Mr=o(Ki,"Deep Learning for Coders with fastai and PyTorch"),Ki.forEach(r),Ci.forEach(r),Dr=o(Je," kitab\u0131n\u0131 Jeremy Howard ile birlikte yazd\u0131. Sylvain\u2019in ara\u015Ft\u0131rmalar\u0131n\u0131n ana oda\u011F\u0131 modellerin s\u0131n\u0131rl\u0131 kaynaklarda daha h\u0131zl\u0131 e\u011Fitilmesine izin veren teknikleri tasarlay\u0131p geli\u015Ftirerek derin \xF6\u011Frenmeyi herkes i\xE7in ula\u015F\u0131labilir k\u0131lmak."),Je.forEach(r),ka=d(e),te=l(e,"P",{});var ei=n(te);Ce=l(ei,"STRONG",{});var Oi=n(Ce);Hr=o(Oi,"Merve Noyan"),Oi.forEach(r),Nr=o(ei," Hugging Face\u2019de Developer Advocate, ara\xE7lar geli\u015Ftirerek ve bu ara\xE7lar etraf\u0131nda i\xE7erik \xFCreterek makine \xF6\u011Frenmesini herkes i\xE7in demokratikle\u015Ftirme \xFCzerine \xE7al\u0131\u015F\u0131yor."),ei.forEach(r),ca=d(e),oe=l(e,"P",{});var ai=n(oe);Ke=l(ai,"STRONG",{});var Ri=n(Ke);Br=o(Ri,"Lucile Saulnier"),Ri.forEach(r),Sr=o(ai," Hugging Face\u2019de Makine \xD6\u011Frenmesi M\xFChendisi, a\xE7\u0131k kaynak ara\xE7lar\u0131n\u0131n geli\u015Ftirilmesi ve desteklenmesi \xFCzerine u\u011Fra\u015F\u0131yor. Ayr\u0131ca Do\u011Fal Dil \u0130\u015Fleme i\xE7inde Collaborative Training ve BigScience gibi bir\xE7ok ara\u015Ft\u0131rma projesine dahil."),ai.forEach(r),ha=d(e),P=l(e,"P",{});var We=n(P);Oe=l(We,"STRONG",{});var xi=n(Oe);Fr=o(xi,"Lewis Tunstall"),xi.forEach(r),Ir=o(We," Hugging Face\u2019de Makine \xD6\u011Frenmesi M\xFChendisi, a\xE7\u0131k kaynak ara\xE7lar\u0131 geli\u015Ftirmeye ve bunlari daha geni\u015F bir topluluk i\xE7in ula\u015F\u0131labilir hale getirmeye odaklanm\u0131\u015F. Ayr\u0131ca yak\u0131nda gelecek olan "),se=l(We,"A",{href:!0,rel:!0});var ji=n(se);Gr=o(ji,"Transformers \xFCzerine O\u2019Reilly kitab\u0131n\u0131n"),ji.forEach(r),Cr=o(We," yazarlar\u0131ndan biri."),We.forEach(r),pa=d(e),L=l(e,"P",{});var Ye=n(L);Re=l(Ye,"STRONG",{});var Ui=n(Re);Kr=o(Ui,"Leandro von Werra"),Ui.forEach(r),Or=o(Ye,"  Hugging Face\u2019de A\xE7\u0131k-Kaynak tak\u0131m\u0131nda Makine \xD6\u011Frenmesi M\xFChendisi ve ayrica yak\u0131nda gelecek olan "),ue=l(Ye,"A",{href:!0,rel:!0});var qi=n(ue);Rr=o(qi,"Transformers \xFCzerine olan O\u2019Reilly kitabinin"),qi.forEach(r),xr=o(Ye," yazarlar\u0131ndan biri. T\xFCm Makine \xD6\u011Frenmesi stack\u2019inde \xE7ali\u015Farak NLP projelerini \xFCretime getiren birka\xE7 y\u0131ll\u0131k end\xFCstri deneyimine sahiptir."),Ye.forEach(r),ga=d(e),ce=l(e,"P",{});var Ji=n(ce);jr=o(Ji,"Ba\u015Flamaya haz\u0131r m\u0131s\u0131n? Bu b\xF6l\xFCmde, \u015Funlar\u0131 \xF6\u011Freneceksin:"),Ji.forEach(r),va=d(e),v=l(e,"UL",{});var ge=n(v);me=l(ge,"LI",{});var La=n(me);Ur=o(La,"Metin olu\u015Fturma ve s\u0131n\u0131fland\u0131rma gibi NLP g\xF6revlerini \xE7\xF6zmek i\xE7in "),xe=l(La,"CODE",{});var Wi=n(xe);qr=o(Wi,"pipeline ()"),Wi.forEach(r),Jr=o(La," fonksiyonu nas\u0131l kullan\u0131laca\u011F\u0131?"),La.forEach(r),Wr=d(ge),je=l(ge,"LI",{});var Yi=n(je);Yr=o(Yi,"Transformer mimarisi"),Yi.forEach(r),Vr=d(ge),Ue=l(ge,"LI",{});var Vi=n(Ue);Qr=o(Vi,"Encoder, Decoder, ve Encoder-Decoder mimarilerini nasil ay\u0131rt edilece\u011Fi ve kullan\u0131m alanlari"),Vi.forEach(r),ge.forEach(r),this.h()},h(){s(y,"name","hf:doc:metadata"),s(y,"content",JSON.stringify(ol)),s($,"id","giri"),s($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s($,"href","#giri"),s(b,"class","relative group"),s(T,"id","kursuna-hogeldiniz"),s(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(T,"href","#kursuna-hogeldiniz"),s(z,"class","relative group"),s(C,"href","https://huggingface.co/"),s(C,"rel","nofollow"),s(K,"href","https://github.com/huggingface/transformers"),s(K,"rel","nofollow"),s(O,"href","https://github.com/huggingface/datasets"),s(O,"rel","nofollow"),s(R,"href","https://github.com/huggingface/tokenizers"),s(R,"rel","nofollow"),s(x,"href","https://github.com/huggingface/accelerate"),s(x,"rel","nofollow"),s(j,"href","https://huggingface.co/models"),s(j,"rel","nofollow"),s(M,"id","beklentiniz-ne-olmal"),s(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(M,"href","#beklentiniz-ne-olmal"),s(_,"class","relative group"),s(q,"class","block dark:hidden"),Qi(q.src,ii="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg")||s(q,"src",ii),s(q,"alt","Brief overview of the chapters of the course."),s(J,"class","hidden dark:block"),Qi(J.src,li="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg")||s(J,"src",li),s(J,"alt","Brief overview of the chapters of the course."),s(w,"class","flex justify-center"),s(Y,"href","https://huggingface.co/models"),s(Y,"rel","nofollow"),s(V,"href","https://www.fast.ai/"),s(V,"rel","nofollow"),s(Q,"href","https://course.fast.ai/"),s(Q,"rel","nofollow"),s(X,"href","https://www.deeplearning.ai/"),s(X,"rel","nofollow"),s(Z,"href","https://pytorch.org/"),s(Z,"rel","nofollow"),s(ee,"href","https://www.tensorflow.org/"),s(ee,"rel","nofollow"),s(ae,"href","https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh"),s(ae,"rel","nofollow"),s(N,"id","biz-kimiz"),s(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),s(N,"href","#biz-kimiz"),s(E,"class","relative group"),s(ne,"href","https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/"),s(ne,"rel","nofollow"),s(se,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),s(se,"rel","nofollow"),s(ue,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),s(ue,"rel","nofollow")},m(e,u){a(document.head,y),m(e,Ve,u),m(e,b,u),a(b,$),a($,Ee),be(S,Ee,null),a(b,Ta),a(b,Ae),a(Ae,Ma),m(e,Qe,u),be(F,e,u),m(e,Xe,u),m(e,z,u),a(z,T),a(T,Pe),be(I,Pe,null),a(z,Da),a(z,Le),a(Le,Ha),m(e,Ze,u),be(G,e,u),m(e,ea,u),m(e,k,u),a(k,Na),a(k,C),a(C,Ba),a(k,Sa),a(k,K),a(K,Fa),a(k,Ia),a(k,O),a(O,Ga),a(k,Ca),a(k,R),a(R,Ka),a(k,Oa),a(k,x),a(x,Ra),a(k,xa),a(k,j),a(j,ja),a(k,Ua),m(e,aa,u),m(e,_,u),a(_,M),a(M,$e),be(U,$e,null),a(_,qa),a(_,Te),a(Te,Ja),m(e,ra,u),m(e,fe,u),a(fe,Wa),m(e,ia,u),m(e,w,u),a(w,q),a(w,Ya),a(w,J),m(e,la,u),m(e,p,u),a(p,W),a(W,Va),a(W,Y),a(Y,Qa),a(W,Xa),a(p,Za),a(p,Me),a(Me,er),a(p,ar),a(p,De),a(De,rr),m(e,na,u),m(e,de,u),a(de,ir),m(e,ta,u),m(e,g,u),a(g,He),a(He,lr),a(g,nr),a(g,h),a(h,tr),a(h,V),a(V,or),a(h,sr),a(h,Q),a(Q,ur),a(h,mr),a(h,X),a(X,fr),a(h,dr),a(g,kr),a(g,D),a(D,Z),a(Z,cr),a(D,hr),a(D,ee),a(ee,pr),a(D,gr),m(e,oa,u),m(e,H,u),a(H,vr),a(H,ae),a(ae,yr),a(H,br),m(e,sa,u),m(e,E,u),a(E,N),a(N,Ne),be(re,Ne,null),a(E,zr),a(E,Be),a(Be,_r),m(e,ua,u),m(e,ke,u),a(ke,wr),m(e,ma,u),m(e,ie,u),a(ie,Se),a(Se,Er),a(ie,Ar),m(e,fa,u),m(e,le,u),a(le,Fe),a(Fe,Pr),a(le,Lr),m(e,da,u),m(e,A,u),a(A,Ie),a(Ie,$r),a(A,Tr),a(A,Ge),a(Ge,ne),a(ne,Mr),a(A,Dr),m(e,ka,u),m(e,te,u),a(te,Ce),a(Ce,Hr),a(te,Nr),m(e,ca,u),m(e,oe,u),a(oe,Ke),a(Ke,Br),a(oe,Sr),m(e,ha,u),m(e,P,u),a(P,Oe),a(Oe,Fr),a(P,Ir),a(P,se),a(se,Gr),a(P,Cr),m(e,pa,u),m(e,L,u),a(L,Re),a(Re,Kr),a(L,Or),a(L,ue),a(ue,Rr),a(L,xr),m(e,ga,u),m(e,ce,u),a(ce,jr),m(e,va,u),m(e,v,u),a(v,me),a(me,Ur),a(me,xe),a(xe,qr),a(me,Jr),a(v,Wr),a(v,je),a(je,Yr),a(v,Vr),a(v,Ue),a(Ue,Qr),ya=!0},p:rl,i(e){ya||(ze(S.$$.fragment,e),ze(F.$$.fragment,e),ze(I.$$.fragment,e),ze(G.$$.fragment,e),ze(U.$$.fragment,e),ze(re.$$.fragment,e),ya=!0)},o(e){_e(S.$$.fragment,e),_e(F.$$.fragment,e),_e(I.$$.fragment,e),_e(G.$$.fragment,e),_e(U.$$.fragment,e),_e(re.$$.fragment,e),ya=!1},d(e){r(y),e&&r(Ve),e&&r(b),we(S),e&&r(Qe),we(F,e),e&&r(Xe),e&&r(z),we(I),e&&r(Ze),we(G,e),e&&r(ea),e&&r(k),e&&r(aa),e&&r(_),we(U),e&&r(ra),e&&r(fe),e&&r(ia),e&&r(w),e&&r(la),e&&r(p),e&&r(na),e&&r(de),e&&r(ta),e&&r(g),e&&r(oa),e&&r(H),e&&r(sa),e&&r(E),we(re),e&&r(ua),e&&r(ke),e&&r(ma),e&&r(ie),e&&r(fa),e&&r(le),e&&r(da),e&&r(A),e&&r(ka),e&&r(te),e&&r(ca),e&&r(oe),e&&r(ha),e&&r(P),e&&r(pa),e&&r(L),e&&r(ga),e&&r(ce),e&&r(va),e&&r(v)}}}const ol={local:"giri",sections:[{local:"kursuna-hogeldiniz",title:"\u{1F917} Kursuna Ho\u015Fgeldiniz!"},{local:"beklentiniz-ne-olmal",title:"Beklentiniz ne olmal\u0131?"},{local:"biz-kimiz",title:"Biz Kimiz?"}],title:"Giri\u015F"};function sl(ri){return il(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class kl extends Xi{constructor(y){super();Zi(this,y,sl,tl,el,{})}}export{kl as default,ol as metadata};
