import{S as mr,i as hr,s as _r,e as s,k as d,w as g,t as o,M as gr,c as r,d as a,m as u,a as l,x as v,h as i,b as f,G as t,g as c,y as $,q as E,o as D,B as q,v as vr}from"../../chunks/vendor-hf-doc-builder.js";import{T as Xi}from"../../chunks/Tip-hf-doc-builder.js";import{Y as $r}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Ba}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as J}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as Er}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function Dr(oe){let p,Q,m,b,w;return{c(){p=s("p"),Q=o("\u270E Se ti stai chiedendo perch\xE9 c\u2019\xE8 un "),m=s("code"),b=o("!"),w=o(" nei comandi di shell precedenti, \xE8 perch\xE9 li stiamo eseguendo da un notebook Jupyter. Se vuoi scaricare e decomprimere i dataset da un terminale, non devi fare altro che rimuovere il prefisso.")},l(h){p=r(h,"P",{});var j=l(p);Q=i(j,"\u270E Se ti stai chiedendo perch\xE9 c\u2019\xE8 un "),m=r(j,"CODE",{});var C=l(m);b=i(C,"!"),C.forEach(a),w=i(j," nei comandi di shell precedenti, \xE8 perch\xE9 li stiamo eseguendo da un notebook Jupyter. Se vuoi scaricare e decomprimere i dataset da un terminale, non devi fare altro che rimuovere il prefisso."),j.forEach(a)},m(h,j){c(h,p,j),t(p,Q),t(p,m),t(m,b),t(p,w)},d(h){h&&a(p)}}}function qr(oe){let p,Q,m,b,w,h,j,C,A,y,x,S,_,R;return{c(){p=s("p"),Q=o("L\u2019argomento "),m=s("code"),b=o("data_files"),w=o(" della funzione "),h=s("code"),j=o("load_dataset()"),C=o(" \xE8 molto flessibile, e pu\xF2 essere usato con un percorso file singolo, con una lista di percorsi file, o un dizionario che mappa i nomi delle sezioni ai percorsi file. \xC8 anche possibile usare comandi glob per recuperare tutti i file che soddisfano uno specifico pattern secondo le regole dello shell di Unix (ad esempio, \xE8 possibile recuperare tutti i file JSON presenti in una cartella usando il pattern "),A=s("code"),y=o('data_files="*.json"'),x=o("). Consulta la "),S=s("a"),_=o("documentazione"),R=o(" \u{1F917} Datasets per maggiori informazioni."),this.h()},l(O){p=r(O,"P",{});var z=l(p);Q=i(z,"L\u2019argomento "),m=r(z,"CODE",{});var Ne=l(m);b=i(Ne,"data_files"),Ne.forEach(a),w=i(z," della funzione "),h=r(z,"CODE",{});var $e=l(h);j=i($e,"load_dataset()"),$e.forEach(a),C=i(z," \xE8 molto flessibile, e pu\xF2 essere usato con un percorso file singolo, con una lista di percorsi file, o un dizionario che mappa i nomi delle sezioni ai percorsi file. \xC8 anche possibile usare comandi glob per recuperare tutti i file che soddisfano uno specifico pattern secondo le regole dello shell di Unix (ad esempio, \xE8 possibile recuperare tutti i file JSON presenti in una cartella usando il pattern "),A=r(z,"CODE",{});var F=l(A);y=i(F,'data_files="*.json"'),F.forEach(a),x=i(z,"). Consulta la "),S=r(z,"A",{href:!0,rel:!0});var Ee=l(S);_=i(Ee,"documentazione"),Ee.forEach(a),R=i(z," \u{1F917} Datasets per maggiori informazioni."),z.forEach(a),this.h()},h(){f(S,"href","https://huggingface.co/docs/datasets/loading.html#local-and-remote-files"),f(S,"rel","nofollow")},m(O,z){c(O,p,z),t(p,Q),t(p,m),t(m,b),t(p,w),t(p,h),t(h,j),t(p,C),t(p,A),t(A,y),t(p,x),t(p,S),t(S,_),t(p,R)},d(O){O&&a(p)}}}function br(oe){let p,Q,m,b,w,h,j,C,A,y,x;return{c(){p=s("p"),Q=o("\u270F\uFE0F "),m=s("strong"),b=o("Prova tu!"),w=o(" Scegli un altro dataset presente su GitHub o sulla "),h=s("a"),j=o("Repository di Machine Learning UCI"),C=o(" e cerca di caricare sia in locale che in remoto usando le tecniche introdotte in precedenza. Per punti extra, prova a caricare un dataset archiviato in formato CSV o testuale (vedi la "),A=s("a"),y=o("documentazione"),x=o(" per ulteriori informazioni su questi formati)."),this.h()},l(S){p=r(S,"P",{});var _=l(p);Q=i(_,"\u270F\uFE0F "),m=r(_,"STRONG",{});var R=l(m);b=i(R,"Prova tu!"),R.forEach(a),w=i(_," Scegli un altro dataset presente su GitHub o sulla "),h=r(_,"A",{href:!0,rel:!0});var O=l(h);j=i(O,"Repository di Machine Learning UCI"),O.forEach(a),C=i(_," e cerca di caricare sia in locale che in remoto usando le tecniche introdotte in precedenza. Per punti extra, prova a caricare un dataset archiviato in formato CSV o testuale (vedi la "),A=r(_,"A",{href:!0,rel:!0});var z=l(A);y=i(z,"documentazione"),z.forEach(a),x=i(_," per ulteriori informazioni su questi formati)."),_.forEach(a),this.h()},h(){f(h,"href","https://archive.ics.uci.edu/ml/index.php"),f(h,"rel","nofollow"),f(A,"href","https://huggingface.co/docs/datasets/loading.html#local-and-remote-files"),f(A,"rel","nofollow")},m(S,_){c(S,p,_),t(p,Q),t(p,m),t(m,b),t(p,w),t(p,h),t(h,j),t(p,C),t(p,A),t(A,y),t(p,x)},d(S){S&&a(p)}}}function zr(oe){let p,Q,m,b,w,h,j,C,A,y,x,S,_,R,O,z,Ne,$e,F,Ee,Z,ie,pt,De,Za,ft,Ya,ia,Le,Ka,sa,se,mt,Y,Je,Wa,Xa,Ie,eo,to,Re,ao,oo,I,K,Fe,io,so,Ge,ht,ro,lo,Me,_t,no,co,W,Ue,uo,po,Ve,gt,fo,mo,Be,vt,ho,_o,X,Ze,go,vo,Ye,$t,$o,Eo,Ke,Et,Do,qo,ee,We,bo,zo,Xe,Dt,jo,So,et,qt,wo,ra,G,Ao,bt,Qo,Co,zt,Oo,Po,la,te,re,jt,qe,xo,St,ko,na,le,yo,be,To,Ho,ca,ne,No,wt,Lo,Jo,da,ze,ua,T,Io,At,Ro,Fo,Qt,Go,Mo,Ct,Uo,Vo,pa,je,fa,Se,ma,M,Bo,Ot,Zo,Yo,Pt,Ko,Wo,ha,ce,_a,H,Xo,xt,ei,ti,kt,ai,oi,yt,ii,si,ga,we,va,N,ri,Tt,li,ni,Ht,ci,di,Nt,ui,pi,$a,Ae,Ea,Qe,Da,de,fi,Lt,mi,hi,qa,Ce,ba,Oe,za,P,_i,Jt,gi,vi,It,$i,Ei,Rt,Di,qi,Ft,bi,zi,Gt,ji,Si,ja,Pe,Sa,xe,wa,tt,wi,Aa,ue,Qa,U,Ai,Mt,Qi,Ci,Ut,Oi,Pi,Ca,ke,Oa,pe,xi,Vt,ki,yi,Pa,at,Ti,xa,ae,fe,Bt,ye,Hi,Zt,Ni,ka,k,Li,Yt,Ji,Ii,Kt,Ri,Fi,Wt,Gi,Mi,Xt,Ui,Vi,ya,Te,Ta,V,Bi,ea,Zi,Yi,ta,Ki,Wi,Ha,me,Na;return h=new Ba({}),x=new Er({props:{chapter:5,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section2.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section2.ipynb"}]}}),F=new $r({props:{id:"HyQgpJTkRdE"}}),De=new Ba({}),qe=new Ba({}),ze=new J({props:{code:`!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz`,highlighted:`!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz`}}),je=new J({props:{code:"!gzip -dkv SQuAD_it-*.json.gz",highlighted:"!gzip -dkv SQuAD_it-*.json.gz"}}),Se=new J({props:{code:`SQuAD_it-test.json.gz:	   87.4% -- replaced with SQuAD_it-test.json
SQuAD_it-train.json.gz:	   82.2% -- replaced with SQuAD_it-train.json`,highlighted:`SQuAD_it-test.json.gz:	   87.4% -- replaced with SQuAD_it-test.json
SQuAD_it-train.json.gz:	   82.2% -- replaced with SQuAD_it-train.json`}}),ce=new Xi({props:{$$slots:{default:[Dr]},$$scope:{ctx:oe}}}),we=new J({props:{code:`from datasets import load_dataset

squad_it_dataset = load_dataset("json", data_files="SQuAD_it-train.json", field="data")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=<span class="hljs-string">&quot;SQuAD_it-train.json&quot;</span>, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),Ae=new J({props:{code:"squad_it_dataset",highlighted:"squad_it_dataset"}}),Qe=new J({props:{code:`DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">442</span>
    })
})`}}),Ce=new J({props:{code:'squad_it_dataset["train"][0]',highlighted:'squad_it_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]'}}),Oe=new J({props:{code:`{
    "title": "Terremoto del Sichuan del 2008",
    "paragraphs": [
        {
            "context": "Il terremoto del Sichuan del 2008 o il terremoto...",
            "qas": [
                {
                    "answers": [{"answer_start": 29, "text": "2008"}],
                    "id": "56cdca7862d2951400fa6826",
                    "question": "In quale anno si \xE8 verificato il terremoto nel Sichuan?",
                },
                ...
            ],
        },
        ...
    ],
}`,highlighted:`{
    <span class="hljs-string">&quot;title&quot;</span>: <span class="hljs-string">&quot;Terremoto del Sichuan del 2008&quot;</span>,
    <span class="hljs-string">&quot;paragraphs&quot;</span>: [
        {
            <span class="hljs-string">&quot;context&quot;</span>: <span class="hljs-string">&quot;Il terremoto del Sichuan del 2008 o il terremoto...&quot;</span>,
            <span class="hljs-string">&quot;qas&quot;</span>: [
                {
                    <span class="hljs-string">&quot;answers&quot;</span>: [{<span class="hljs-string">&quot;answer_start&quot;</span>: <span class="hljs-number">29</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;2008&quot;</span>}],
                    <span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-string">&quot;56cdca7862d2951400fa6826&quot;</span>,
                    <span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;In quale anno si \xE8 verificato il terremoto nel Sichuan?&quot;</span>,
                },
                ...
            ],
        },
        ...
    ],
}`}}),Pe=new J({props:{code:`data_files = {"train": "SQuAD_it-train.json", "test": "SQuAD_it-test.json"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
squad_it_dataset`,highlighted:`data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-train.json&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-test.json&quot;</span>}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)
squad_it_dataset`}}),xe=new J({props:{code:`DatasetDict({
    train: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 442
    })
    test: Dataset({
        features: ['title', 'paragraphs'],
        num_rows: 48
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">442</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;paragraphs&#x27;</span>],
        num_rows: <span class="hljs-number">48</span>
    })
})`}}),ue=new Xi({props:{$$slots:{default:[qr]},$$scope:{ctx:oe}}}),ke=new J({props:{code:`data_files = {"train": "SQuAD_it-train.json.gz", "test": "SQuAD_it-test.json.gz"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")`,highlighted:`data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-train.json.gz&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;SQuAD_it-test.json.gz&quot;</span>}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),ye=new Ba({}),Te=new J({props:{code:`url = "https://github.com/crux82/squad-it/raw/master/"
data_files = {
    "train": url + "SQuAD_it-train.json.gz",
    "test": url + "SQuAD_it-test.json.gz",
}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")`,highlighted:`url = <span class="hljs-string">&quot;https://github.com/crux82/squad-it/raw/master/&quot;</span>
data_files = {
    <span class="hljs-string">&quot;train&quot;</span>: url + <span class="hljs-string">&quot;SQuAD_it-train.json.gz&quot;</span>,
    <span class="hljs-string">&quot;test&quot;</span>: url + <span class="hljs-string">&quot;SQuAD_it-test.json.gz&quot;</span>,
}
squad_it_dataset = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files, field=<span class="hljs-string">&quot;data&quot;</span>)`}}),me=new Xi({props:{$$slots:{default:[br]},$$scope:{ctx:oe}}}),{c(){p=s("meta"),Q=d(),m=s("h1"),b=s("a"),w=s("span"),g(h.$$.fragment),j=d(),C=s("span"),A=o("E se il mio dataset non \xE8 sull'Hub?"),y=d(),g(x.$$.fragment),S=d(),_=s("p"),R=o("Sai come usare l\u2019"),O=s("a"),z=o("Hub Hugging Face"),Ne=o(" per scaricare i dataset, ma spessa dovrai lavorare con dati che si trovano sul tuo computer, o so un server remoto. In questa sezione vederemo come usare \u{1F917} Datasets per caricare dataset che non sono disponibile nell\u2019Hub Hugging Face."),$e=d(),g(F.$$.fragment),Ee=d(),Z=s("h2"),ie=s("a"),pt=s("span"),g(De.$$.fragment),Za=d(),ft=s("span"),Ya=o("Lavorare con dataset locali e in remoto"),ia=d(),Le=s("p"),Ka=o("\u{1F917} Datasets mette a tua disposizione diversi script per caricare dataset in locale e in remoto. Sono supportati diversi formati di dati, tra cui:"),sa=d(),se=s("table"),mt=s("thead"),Y=s("tr"),Je=s("th"),Wa=o("Formato dati"),Xa=d(),Ie=s("th"),eo=o("Script"),to=d(),Re=s("th"),ao=o("Esempio"),oo=d(),I=s("tbody"),K=s("tr"),Fe=s("td"),io=o("CSV & TSV"),so=d(),Ge=s("td"),ht=s("code"),ro=o("csv"),lo=d(),Me=s("td"),_t=s("code"),no=o('load_dataset("csv", data_files="my_file.csv")'),co=d(),W=s("tr"),Ue=s("td"),uo=o("File di testo"),po=d(),Ve=s("td"),gt=s("code"),fo=o("text"),mo=d(),Be=s("td"),vt=s("code"),ho=o('load_dataset("text", data_files="my_file.txt")'),_o=d(),X=s("tr"),Ze=s("td"),go=o("JSON & JSON Lines"),vo=d(),Ye=s("td"),$t=s("code"),$o=o("json"),Eo=d(),Ke=s("td"),Et=s("code"),Do=o('load_dataset("json", data_files="my_file.jsonl")'),qo=d(),ee=s("tr"),We=s("td"),bo=o("DataFrame serializzati in Pickle"),zo=d(),Xe=s("td"),Dt=s("code"),jo=o("pandas"),So=d(),et=s("td"),qt=s("code"),wo=o('load_dataset("pandas", data_files="my_dataframe.pkl")'),ra=d(),G=s("p"),Ao=o("Come mostrato nella tabella, per ogni formato di dati abbiamo bisogno di specificare, all\u2019interno della funzione "),bt=s("code"),Qo=o("load_dataset()"),Co=o(", il tipo di script da utilizzare, assieme a "),zt=s("code"),Oo=o("data_files"),Po=o(", che specifica il percorso verso uno o pi\xF9 file. Iniziamo a caricare un dataset proveniente da file locali; pi\xF9 tardi vederemo come fare la stessa cosa con file in remoto."),la=d(),te=s("h2"),re=s("a"),jt=s("span"),g(qe.$$.fragment),xo=d(),St=s("span"),ko=o("Caricare un dataset locale"),na=d(),le=s("p"),yo=o("Per questo esempio useremo il "),be=s("a"),To=o("dataset SQuAD-it"),Ho=o(", un ampio dataset per il question answering in italiano"),ca=d(),ne=s("p"),No=o("Le sezioni di addestramento e di test si trovano su GitHub, quindi possiamo scaricarle con un semplice comando "),wt=s("code"),Lo=o("wget"),Jo=o(":"),da=d(),g(ze.$$.fragment),ua=d(),T=s("p"),Io=o("Questo scaricher\xE0 due file compressi chiamati "),At=s("em"),Ro=o("SQuAD_it-train.json.gz"),Fo=o(" e "),Qt=s("em"),Go=o("SQuAD_it-test.json.gz"),Mo=o(", che possiamo decomprimere con il comandi Linux "),Ct=s("code"),Uo=o("gzip"),Vo=o(":"),pa=d(),g(je.$$.fragment),fa=d(),g(Se.$$.fragment),ma=d(),M=s("p"),Bo=o("Vediamo che i dati compressi sono stati sostituiti da "),Ot=s("em"),Zo=o("SQuAD_it-train.json"),Yo=o(" e "),Pt=s("em"),Ko=o("SQuAD_it-text.json"),Wo=o(", e che i dati sono archiviati in formato JSON."),ha=d(),g(ce.$$.fragment),_a=d(),H=s("p"),Xo=o("Per caricare un file JSON con la funzione "),xt=s("code"),ei=o("load_dataset()"),ti=o(", ci serve solo sapere se abbiamo a che fare con un normale JSON (simile a un dizionario annidato) o con un JSON Lines (JSON separato da righe). Come molti dataset per il question asnwring, SQuAD-it usa il formato annidato, con tutto il testo immagazzinato nel campo "),kt=s("code"),ai=o("data"),oi=o(". Questo significa che possiamo caricare il dataset specificando l\u2019argomento "),yt=s("code"),ii=o("field"),si=o(" come segue:"),ga=d(),g(we.$$.fragment),va=d(),N=s("p"),ri=o("Di default, caricare file locali create un oggetto "),Tt=s("code"),li=o("DatasetDict"),ni=o(" con una sezione "),Ht=s("code"),ci=o("train"),di=o(". Possiamo vederlo ispezionando l\u2019oggetto "),Nt=s("code"),ui=o("squad_it_dataset"),pi=o(":"),$a=d(),g(Ae.$$.fragment),Ea=d(),g(Qe.$$.fragment),Da=d(),de=s("p"),fi=o("Questo ci mostra il numero di righe e i nomi delle colonne associate con il set di addestraento. Possiamo vedere uno degli esempi indicizzando la sezione "),Lt=s("code"),mi=o("train"),hi=o(", come segue:"),qa=d(),g(Ce.$$.fragment),ba=d(),g(Oe.$$.fragment),za=d(),P=s("p"),_i=o("Benissimo, abbiamo caricare il nostro primo dataset locale! Ma anche se questo ha funzionato per la sezione di addestramento, vogliamo includere entrambe le sezioni "),Jt=s("code"),gi=o("train"),vi=o(" e "),It=s("code"),$i=o("test"),Ei=o(" in un unico oggetto "),Rt=s("code"),Di=o("DatasetDict"),qi=o(" cos\xEC da poter applicare le funzioni "),Ft=s("code"),bi=o("Dataset.map()"),zi=o(" su entrambi i dataset simultaneamente. Per fare questo, possiamo dare un dizionaro all\u2019argomento "),Gt=s("code"),ji=o("data_files"),Si=o(", per mappare ogni sezione a un file associato con quella sezione:"),ja=d(),g(Pe.$$.fragment),Sa=d(),g(xe.$$.fragment),wa=d(),tt=s("p"),wi=o("Questo \xE8 proprio ci\xF2 che volevamo. Ora possiamo applicare diverse tecniche di preprocessamento per pulire i dati, tokenizzare le revisioni, e altro."),Aa=d(),g(ue.$$.fragment),Qa=d(),U=s("p"),Ai=o("Gli script presenti in \u{1F917} Datasets supportano la decompressione atuomatica dei file in input, quindi possiamo saltare l\u2019uso di "),Mt=s("code"),Qi=o("gzip"),Ci=o(" puntando "),Ut=s("code"),Oi=o("data_files"),Pi=o(" direttamente ai file compressi:"),Ca=d(),g(ke.$$.fragment),Oa=d(),pe=s("p"),xi=o("Questo pu\xF2 essere utile se non vuoi decomprimere manualmente molti file GZIP. La decompressione automatica si applica inoltre ad altri formati comuni, come ZIP e TAR, basta solo puntare  "),Vt=s("code"),ki=o("data_files"),yi=o(" ai file compressi ed \xE8 fatta!"),Pa=d(),at=s("p"),Ti=o("Ora che sai come caricare i file locali dal tuo computer, guardiamo come caricare i file remoti."),xa=d(),ae=s("h2"),fe=s("a"),Bt=s("span"),g(ye.$$.fragment),Hi=d(),Zt=s("span"),Ni=o("Caricare un dataset in remoto"),ka=d(),k=s("p"),Li=o("Se lavori come data scientist o come programmatore per un\u2019azienda, ci sono buone probabilit\xE0 che i dataset da analizzare sono archiaviati su un qualche server in remoto. Per fortuna, caricare file remoti \xE8 semplice come caricare quelli locali! Invece di dare un percorso a file locali, puntiamo l\u2019argomento "),Yt=s("code"),Ji=o("data_files"),Ii=o(" di "),Kt=s("code"),Ri=o("load_dataset()"),Fi=o(" a uno o pi\xF9 URL dove si trovano i file in remoto. Ad esempio, per il dataset SQuAD-it presente su GitHub, possiamo puntare "),Wt=s("code"),Gi=o("data_files"),Mi=o(" agli URL "),Xt=s("em"),Ui=o("SQuAD_it-*.json.gz"),Vi=o(" come segue:"),ya=d(),g(Te.$$.fragment),Ta=d(),V=s("p"),Bi=o("Questo codice restituisce lo stesso oggetto "),ea=s("code"),Zi=o("DatasetDict"),Yi=o(" visto in precedenza, ma ci risparmia il passaggio manuale di scaricare e decomprimere i file "),ta=s("em"),Ki=o("SQuAD_it-*.json.gz"),Wi=o(". Questo conclude la nostra incursione nei diversi modi di caricare dataset che non sono presenti nell\u2019Hub Hugging Face. Ora che abbiamo un dataset con cui giocare, sporchiamoci le mani con diverse tecniche di data-wrangling!"),Ha=d(),g(me.$$.fragment),this.h()},l(e){const n=gr('[data-svelte="svelte-1phssyn"]',document.head);p=r(n,"META",{name:!0,content:!0}),n.forEach(a),Q=u(e),m=r(e,"H1",{class:!0});var He=l(m);b=r(He,"A",{id:!0,class:!0,href:!0});var aa=l(b);w=r(aa,"SPAN",{});var oa=l(w);v(h.$$.fragment,oa),oa.forEach(a),aa.forEach(a),j=u(He),C=r(He,"SPAN",{});var es=l(C);A=i(es,"E se il mio dataset non \xE8 sull'Hub?"),es.forEach(a),He.forEach(a),y=u(e),v(x.$$.fragment,e),S=u(e),_=r(e,"P",{});var La=l(_);R=i(La,"Sai come usare l\u2019"),O=r(La,"A",{href:!0,rel:!0});var ts=l(O);z=i(ts,"Hub Hugging Face"),ts.forEach(a),Ne=i(La," per scaricare i dataset, ma spessa dovrai lavorare con dati che si trovano sul tuo computer, o so un server remoto. In questa sezione vederemo come usare \u{1F917} Datasets per caricare dataset che non sono disponibile nell\u2019Hub Hugging Face."),La.forEach(a),$e=u(e),v(F.$$.fragment,e),Ee=u(e),Z=r(e,"H2",{class:!0});var Ja=l(Z);ie=r(Ja,"A",{id:!0,class:!0,href:!0});var as=l(ie);pt=r(as,"SPAN",{});var os=l(pt);v(De.$$.fragment,os),os.forEach(a),as.forEach(a),Za=u(Ja),ft=r(Ja,"SPAN",{});var is=l(ft);Ya=i(is,"Lavorare con dataset locali e in remoto"),is.forEach(a),Ja.forEach(a),ia=u(e),Le=r(e,"P",{});var ss=l(Le);Ka=i(ss,"\u{1F917} Datasets mette a tua disposizione diversi script per caricare dataset in locale e in remoto. Sono supportati diversi formati di dati, tra cui:"),ss.forEach(a),sa=u(e),se=r(e,"TABLE",{});var Ia=l(se);mt=r(Ia,"THEAD",{});var rs=l(mt);Y=r(rs,"TR",{});var ot=l(Y);Je=r(ot,"TH",{align:!0});var ls=l(Je);Wa=i(ls,"Formato dati"),ls.forEach(a),Xa=u(ot),Ie=r(ot,"TH",{align:!0});var ns=l(Ie);eo=i(ns,"Script"),ns.forEach(a),to=u(ot),Re=r(ot,"TH",{align:!0});var cs=l(Re);ao=i(cs,"Esempio"),cs.forEach(a),ot.forEach(a),rs.forEach(a),oo=u(Ia),I=r(Ia,"TBODY",{});var he=l(I);K=r(he,"TR",{});var it=l(K);Fe=r(it,"TD",{align:!0});var ds=l(Fe);io=i(ds,"CSV & TSV"),ds.forEach(a),so=u(it),Ge=r(it,"TD",{align:!0});var us=l(Ge);ht=r(us,"CODE",{});var ps=l(ht);ro=i(ps,"csv"),ps.forEach(a),us.forEach(a),lo=u(it),Me=r(it,"TD",{align:!0});var fs=l(Me);_t=r(fs,"CODE",{});var ms=l(_t);no=i(ms,'load_dataset("csv", data_files="my_file.csv")'),ms.forEach(a),fs.forEach(a),it.forEach(a),co=u(he),W=r(he,"TR",{});var st=l(W);Ue=r(st,"TD",{align:!0});var hs=l(Ue);uo=i(hs,"File di testo"),hs.forEach(a),po=u(st),Ve=r(st,"TD",{align:!0});var _s=l(Ve);gt=r(_s,"CODE",{});var gs=l(gt);fo=i(gs,"text"),gs.forEach(a),_s.forEach(a),mo=u(st),Be=r(st,"TD",{align:!0});var vs=l(Be);vt=r(vs,"CODE",{});var $s=l(vt);ho=i($s,'load_dataset("text", data_files="my_file.txt")'),$s.forEach(a),vs.forEach(a),st.forEach(a),_o=u(he),X=r(he,"TR",{});var rt=l(X);Ze=r(rt,"TD",{align:!0});var Es=l(Ze);go=i(Es,"JSON & JSON Lines"),Es.forEach(a),vo=u(rt),Ye=r(rt,"TD",{align:!0});var Ds=l(Ye);$t=r(Ds,"CODE",{});var qs=l($t);$o=i(qs,"json"),qs.forEach(a),Ds.forEach(a),Eo=u(rt),Ke=r(rt,"TD",{align:!0});var bs=l(Ke);Et=r(bs,"CODE",{});var zs=l(Et);Do=i(zs,'load_dataset("json", data_files="my_file.jsonl")'),zs.forEach(a),bs.forEach(a),rt.forEach(a),qo=u(he),ee=r(he,"TR",{});var lt=l(ee);We=r(lt,"TD",{align:!0});var js=l(We);bo=i(js,"DataFrame serializzati in Pickle"),js.forEach(a),zo=u(lt),Xe=r(lt,"TD",{align:!0});var Ss=l(Xe);Dt=r(Ss,"CODE",{});var ws=l(Dt);jo=i(ws,"pandas"),ws.forEach(a),Ss.forEach(a),So=u(lt),et=r(lt,"TD",{align:!0});var As=l(et);qt=r(As,"CODE",{});var Qs=l(qt);wo=i(Qs,'load_dataset("pandas", data_files="my_dataframe.pkl")'),Qs.forEach(a),As.forEach(a),lt.forEach(a),he.forEach(a),Ia.forEach(a),ra=u(e),G=r(e,"P",{});var nt=l(G);Ao=i(nt,"Come mostrato nella tabella, per ogni formato di dati abbiamo bisogno di specificare, all\u2019interno della funzione "),bt=r(nt,"CODE",{});var Cs=l(bt);Qo=i(Cs,"load_dataset()"),Cs.forEach(a),Co=i(nt,", il tipo di script da utilizzare, assieme a "),zt=r(nt,"CODE",{});var Os=l(zt);Oo=i(Os,"data_files"),Os.forEach(a),Po=i(nt,", che specifica il percorso verso uno o pi\xF9 file. Iniziamo a caricare un dataset proveniente da file locali; pi\xF9 tardi vederemo come fare la stessa cosa con file in remoto."),nt.forEach(a),la=u(e),te=r(e,"H2",{class:!0});var Ra=l(te);re=r(Ra,"A",{id:!0,class:!0,href:!0});var Ps=l(re);jt=r(Ps,"SPAN",{});var xs=l(jt);v(qe.$$.fragment,xs),xs.forEach(a),Ps.forEach(a),xo=u(Ra),St=r(Ra,"SPAN",{});var ks=l(St);ko=i(ks,"Caricare un dataset locale"),ks.forEach(a),Ra.forEach(a),na=u(e),le=r(e,"P",{});var Fa=l(le);yo=i(Fa,"Per questo esempio useremo il "),be=r(Fa,"A",{href:!0,rel:!0});var ys=l(be);To=i(ys,"dataset SQuAD-it"),ys.forEach(a),Ho=i(Fa,", un ampio dataset per il question answering in italiano"),Fa.forEach(a),ca=u(e),ne=r(e,"P",{});var Ga=l(ne);No=i(Ga,"Le sezioni di addestramento e di test si trovano su GitHub, quindi possiamo scaricarle con un semplice comando "),wt=r(Ga,"CODE",{});var Ts=l(wt);Lo=i(Ts,"wget"),Ts.forEach(a),Jo=i(Ga,":"),Ga.forEach(a),da=u(e),v(ze.$$.fragment,e),ua=u(e),T=r(e,"P",{});var _e=l(T);Io=i(_e,"Questo scaricher\xE0 due file compressi chiamati "),At=r(_e,"EM",{});var Hs=l(At);Ro=i(Hs,"SQuAD_it-train.json.gz"),Hs.forEach(a),Fo=i(_e," e "),Qt=r(_e,"EM",{});var Ns=l(Qt);Go=i(Ns,"SQuAD_it-test.json.gz"),Ns.forEach(a),Mo=i(_e,", che possiamo decomprimere con il comandi Linux "),Ct=r(_e,"CODE",{});var Ls=l(Ct);Uo=i(Ls,"gzip"),Ls.forEach(a),Vo=i(_e,":"),_e.forEach(a),pa=u(e),v(je.$$.fragment,e),fa=u(e),v(Se.$$.fragment,e),ma=u(e),M=r(e,"P",{});var ct=l(M);Bo=i(ct,"Vediamo che i dati compressi sono stati sostituiti da "),Ot=r(ct,"EM",{});var Js=l(Ot);Zo=i(Js,"SQuAD_it-train.json"),Js.forEach(a),Yo=i(ct," e "),Pt=r(ct,"EM",{});var Is=l(Pt);Ko=i(Is,"SQuAD_it-text.json"),Is.forEach(a),Wo=i(ct,", e che i dati sono archiviati in formato JSON."),ct.forEach(a),ha=u(e),v(ce.$$.fragment,e),_a=u(e),H=r(e,"P",{});var ge=l(H);Xo=i(ge,"Per caricare un file JSON con la funzione "),xt=r(ge,"CODE",{});var Rs=l(xt);ei=i(Rs,"load_dataset()"),Rs.forEach(a),ti=i(ge,", ci serve solo sapere se abbiamo a che fare con un normale JSON (simile a un dizionario annidato) o con un JSON Lines (JSON separato da righe). Come molti dataset per il question asnwring, SQuAD-it usa il formato annidato, con tutto il testo immagazzinato nel campo "),kt=r(ge,"CODE",{});var Fs=l(kt);ai=i(Fs,"data"),Fs.forEach(a),oi=i(ge,". Questo significa che possiamo caricare il dataset specificando l\u2019argomento "),yt=r(ge,"CODE",{});var Gs=l(yt);ii=i(Gs,"field"),Gs.forEach(a),si=i(ge," come segue:"),ge.forEach(a),ga=u(e),v(we.$$.fragment,e),va=u(e),N=r(e,"P",{});var ve=l(N);ri=i(ve,"Di default, caricare file locali create un oggetto "),Tt=r(ve,"CODE",{});var Ms=l(Tt);li=i(Ms,"DatasetDict"),Ms.forEach(a),ni=i(ve," con una sezione "),Ht=r(ve,"CODE",{});var Us=l(Ht);ci=i(Us,"train"),Us.forEach(a),di=i(ve,". Possiamo vederlo ispezionando l\u2019oggetto "),Nt=r(ve,"CODE",{});var Vs=l(Nt);ui=i(Vs,"squad_it_dataset"),Vs.forEach(a),pi=i(ve,":"),ve.forEach(a),$a=u(e),v(Ae.$$.fragment,e),Ea=u(e),v(Qe.$$.fragment,e),Da=u(e),de=r(e,"P",{});var Ma=l(de);fi=i(Ma,"Questo ci mostra il numero di righe e i nomi delle colonne associate con il set di addestraento. Possiamo vedere uno degli esempi indicizzando la sezione "),Lt=r(Ma,"CODE",{});var Bs=l(Lt);mi=i(Bs,"train"),Bs.forEach(a),hi=i(Ma,", come segue:"),Ma.forEach(a),qa=u(e),v(Ce.$$.fragment,e),ba=u(e),v(Oe.$$.fragment,e),za=u(e),P=r(e,"P",{});var L=l(P);_i=i(L,"Benissimo, abbiamo caricare il nostro primo dataset locale! Ma anche se questo ha funzionato per la sezione di addestramento, vogliamo includere entrambe le sezioni "),Jt=r(L,"CODE",{});var Zs=l(Jt);gi=i(Zs,"train"),Zs.forEach(a),vi=i(L," e "),It=r(L,"CODE",{});var Ys=l(It);$i=i(Ys,"test"),Ys.forEach(a),Ei=i(L," in un unico oggetto "),Rt=r(L,"CODE",{});var Ks=l(Rt);Di=i(Ks,"DatasetDict"),Ks.forEach(a),qi=i(L," cos\xEC da poter applicare le funzioni "),Ft=r(L,"CODE",{});var Ws=l(Ft);bi=i(Ws,"Dataset.map()"),Ws.forEach(a),zi=i(L," su entrambi i dataset simultaneamente. Per fare questo, possiamo dare un dizionaro all\u2019argomento "),Gt=r(L,"CODE",{});var Xs=l(Gt);ji=i(Xs,"data_files"),Xs.forEach(a),Si=i(L,", per mappare ogni sezione a un file associato con quella sezione:"),L.forEach(a),ja=u(e),v(Pe.$$.fragment,e),Sa=u(e),v(xe.$$.fragment,e),wa=u(e),tt=r(e,"P",{});var er=l(tt);wi=i(er,"Questo \xE8 proprio ci\xF2 che volevamo. Ora possiamo applicare diverse tecniche di preprocessamento per pulire i dati, tokenizzare le revisioni, e altro."),er.forEach(a),Aa=u(e),v(ue.$$.fragment,e),Qa=u(e),U=r(e,"P",{});var dt=l(U);Ai=i(dt,"Gli script presenti in \u{1F917} Datasets supportano la decompressione atuomatica dei file in input, quindi possiamo saltare l\u2019uso di "),Mt=r(dt,"CODE",{});var tr=l(Mt);Qi=i(tr,"gzip"),tr.forEach(a),Ci=i(dt," puntando "),Ut=r(dt,"CODE",{});var ar=l(Ut);Oi=i(ar,"data_files"),ar.forEach(a),Pi=i(dt," direttamente ai file compressi:"),dt.forEach(a),Ca=u(e),v(ke.$$.fragment,e),Oa=u(e),pe=r(e,"P",{});var Ua=l(pe);xi=i(Ua,"Questo pu\xF2 essere utile se non vuoi decomprimere manualmente molti file GZIP. La decompressione automatica si applica inoltre ad altri formati comuni, come ZIP e TAR, basta solo puntare  "),Vt=r(Ua,"CODE",{});var or=l(Vt);ki=i(or,"data_files"),or.forEach(a),yi=i(Ua," ai file compressi ed \xE8 fatta!"),Ua.forEach(a),Pa=u(e),at=r(e,"P",{});var ir=l(at);Ti=i(ir,"Ora che sai come caricare i file locali dal tuo computer, guardiamo come caricare i file remoti."),ir.forEach(a),xa=u(e),ae=r(e,"H2",{class:!0});var Va=l(ae);fe=r(Va,"A",{id:!0,class:!0,href:!0});var sr=l(fe);Bt=r(sr,"SPAN",{});var rr=l(Bt);v(ye.$$.fragment,rr),rr.forEach(a),sr.forEach(a),Hi=u(Va),Zt=r(Va,"SPAN",{});var lr=l(Zt);Ni=i(lr,"Caricare un dataset in remoto"),lr.forEach(a),Va.forEach(a),ka=u(e),k=r(e,"P",{});var B=l(k);Li=i(B,"Se lavori come data scientist o come programmatore per un\u2019azienda, ci sono buone probabilit\xE0 che i dataset da analizzare sono archiaviati su un qualche server in remoto. Per fortuna, caricare file remoti \xE8 semplice come caricare quelli locali! Invece di dare un percorso a file locali, puntiamo l\u2019argomento "),Yt=r(B,"CODE",{});var nr=l(Yt);Ji=i(nr,"data_files"),nr.forEach(a),Ii=i(B," di "),Kt=r(B,"CODE",{});var cr=l(Kt);Ri=i(cr,"load_dataset()"),cr.forEach(a),Fi=i(B," a uno o pi\xF9 URL dove si trovano i file in remoto. Ad esempio, per il dataset SQuAD-it presente su GitHub, possiamo puntare "),Wt=r(B,"CODE",{});var dr=l(Wt);Gi=i(dr,"data_files"),dr.forEach(a),Mi=i(B," agli URL "),Xt=r(B,"EM",{});var ur=l(Xt);Ui=i(ur,"SQuAD_it-*.json.gz"),ur.forEach(a),Vi=i(B," come segue:"),B.forEach(a),ya=u(e),v(Te.$$.fragment,e),Ta=u(e),V=r(e,"P",{});var ut=l(V);Bi=i(ut,"Questo codice restituisce lo stesso oggetto "),ea=r(ut,"CODE",{});var pr=l(ea);Zi=i(pr,"DatasetDict"),pr.forEach(a),Yi=i(ut," visto in precedenza, ma ci risparmia il passaggio manuale di scaricare e decomprimere i file "),ta=r(ut,"EM",{});var fr=l(ta);Ki=i(fr,"SQuAD_it-*.json.gz"),fr.forEach(a),Wi=i(ut,". Questo conclude la nostra incursione nei diversi modi di caricare dataset che non sono presenti nell\u2019Hub Hugging Face. Ora che abbiamo un dataset con cui giocare, sporchiamoci le mani con diverse tecniche di data-wrangling!"),ut.forEach(a),Ha=u(e),v(me.$$.fragment,e),this.h()},h(){f(p,"name","hf:doc:metadata"),f(p,"content",JSON.stringify(jr)),f(b,"id","e-se-il-mio-dataset-non-sullhub"),f(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(b,"href","#e-se-il-mio-dataset-non-sullhub"),f(m,"class","relative group"),f(O,"href","https://huggingface.co/datasets"),f(O,"rel","nofollow"),f(ie,"id","lavorare-con-dataset-locali-e-in-remoto"),f(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ie,"href","#lavorare-con-dataset-locali-e-in-remoto"),f(Z,"class","relative group"),f(Je,"align","center"),f(Ie,"align","center"),f(Re,"align","center"),f(Fe,"align","center"),f(Ge,"align","center"),f(Me,"align","center"),f(Ue,"align","center"),f(Ve,"align","center"),f(Be,"align","center"),f(Ze,"align","center"),f(Ye,"align","center"),f(Ke,"align","center"),f(We,"align","center"),f(Xe,"align","center"),f(et,"align","center"),f(re,"id","caricare-un-dataset-locale"),f(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(re,"href","#caricare-un-dataset-locale"),f(te,"class","relative group"),f(be,"href","https://github.com/crux82/squad-it/"),f(be,"rel","nofollow"),f(fe,"id","caricare-un-dataset-in-remoto"),f(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(fe,"href","#caricare-un-dataset-in-remoto"),f(ae,"class","relative group")},m(e,n){t(document.head,p),c(e,Q,n),c(e,m,n),t(m,b),t(b,w),$(h,w,null),t(m,j),t(m,C),t(C,A),c(e,y,n),$(x,e,n),c(e,S,n),c(e,_,n),t(_,R),t(_,O),t(O,z),t(_,Ne),c(e,$e,n),$(F,e,n),c(e,Ee,n),c(e,Z,n),t(Z,ie),t(ie,pt),$(De,pt,null),t(Z,Za),t(Z,ft),t(ft,Ya),c(e,ia,n),c(e,Le,n),t(Le,Ka),c(e,sa,n),c(e,se,n),t(se,mt),t(mt,Y),t(Y,Je),t(Je,Wa),t(Y,Xa),t(Y,Ie),t(Ie,eo),t(Y,to),t(Y,Re),t(Re,ao),t(se,oo),t(se,I),t(I,K),t(K,Fe),t(Fe,io),t(K,so),t(K,Ge),t(Ge,ht),t(ht,ro),t(K,lo),t(K,Me),t(Me,_t),t(_t,no),t(I,co),t(I,W),t(W,Ue),t(Ue,uo),t(W,po),t(W,Ve),t(Ve,gt),t(gt,fo),t(W,mo),t(W,Be),t(Be,vt),t(vt,ho),t(I,_o),t(I,X),t(X,Ze),t(Ze,go),t(X,vo),t(X,Ye),t(Ye,$t),t($t,$o),t(X,Eo),t(X,Ke),t(Ke,Et),t(Et,Do),t(I,qo),t(I,ee),t(ee,We),t(We,bo),t(ee,zo),t(ee,Xe),t(Xe,Dt),t(Dt,jo),t(ee,So),t(ee,et),t(et,qt),t(qt,wo),c(e,ra,n),c(e,G,n),t(G,Ao),t(G,bt),t(bt,Qo),t(G,Co),t(G,zt),t(zt,Oo),t(G,Po),c(e,la,n),c(e,te,n),t(te,re),t(re,jt),$(qe,jt,null),t(te,xo),t(te,St),t(St,ko),c(e,na,n),c(e,le,n),t(le,yo),t(le,be),t(be,To),t(le,Ho),c(e,ca,n),c(e,ne,n),t(ne,No),t(ne,wt),t(wt,Lo),t(ne,Jo),c(e,da,n),$(ze,e,n),c(e,ua,n),c(e,T,n),t(T,Io),t(T,At),t(At,Ro),t(T,Fo),t(T,Qt),t(Qt,Go),t(T,Mo),t(T,Ct),t(Ct,Uo),t(T,Vo),c(e,pa,n),$(je,e,n),c(e,fa,n),$(Se,e,n),c(e,ma,n),c(e,M,n),t(M,Bo),t(M,Ot),t(Ot,Zo),t(M,Yo),t(M,Pt),t(Pt,Ko),t(M,Wo),c(e,ha,n),$(ce,e,n),c(e,_a,n),c(e,H,n),t(H,Xo),t(H,xt),t(xt,ei),t(H,ti),t(H,kt),t(kt,ai),t(H,oi),t(H,yt),t(yt,ii),t(H,si),c(e,ga,n),$(we,e,n),c(e,va,n),c(e,N,n),t(N,ri),t(N,Tt),t(Tt,li),t(N,ni),t(N,Ht),t(Ht,ci),t(N,di),t(N,Nt),t(Nt,ui),t(N,pi),c(e,$a,n),$(Ae,e,n),c(e,Ea,n),$(Qe,e,n),c(e,Da,n),c(e,de,n),t(de,fi),t(de,Lt),t(Lt,mi),t(de,hi),c(e,qa,n),$(Ce,e,n),c(e,ba,n),$(Oe,e,n),c(e,za,n),c(e,P,n),t(P,_i),t(P,Jt),t(Jt,gi),t(P,vi),t(P,It),t(It,$i),t(P,Ei),t(P,Rt),t(Rt,Di),t(P,qi),t(P,Ft),t(Ft,bi),t(P,zi),t(P,Gt),t(Gt,ji),t(P,Si),c(e,ja,n),$(Pe,e,n),c(e,Sa,n),$(xe,e,n),c(e,wa,n),c(e,tt,n),t(tt,wi),c(e,Aa,n),$(ue,e,n),c(e,Qa,n),c(e,U,n),t(U,Ai),t(U,Mt),t(Mt,Qi),t(U,Ci),t(U,Ut),t(Ut,Oi),t(U,Pi),c(e,Ca,n),$(ke,e,n),c(e,Oa,n),c(e,pe,n),t(pe,xi),t(pe,Vt),t(Vt,ki),t(pe,yi),c(e,Pa,n),c(e,at,n),t(at,Ti),c(e,xa,n),c(e,ae,n),t(ae,fe),t(fe,Bt),$(ye,Bt,null),t(ae,Hi),t(ae,Zt),t(Zt,Ni),c(e,ka,n),c(e,k,n),t(k,Li),t(k,Yt),t(Yt,Ji),t(k,Ii),t(k,Kt),t(Kt,Ri),t(k,Fi),t(k,Wt),t(Wt,Gi),t(k,Mi),t(k,Xt),t(Xt,Ui),t(k,Vi),c(e,ya,n),$(Te,e,n),c(e,Ta,n),c(e,V,n),t(V,Bi),t(V,ea),t(ea,Zi),t(V,Yi),t(V,ta),t(ta,Ki),t(V,Wi),c(e,Ha,n),$(me,e,n),Na=!0},p(e,[n]){const He={};n&2&&(He.$$scope={dirty:n,ctx:e}),ce.$set(He);const aa={};n&2&&(aa.$$scope={dirty:n,ctx:e}),ue.$set(aa);const oa={};n&2&&(oa.$$scope={dirty:n,ctx:e}),me.$set(oa)},i(e){Na||(E(h.$$.fragment,e),E(x.$$.fragment,e),E(F.$$.fragment,e),E(De.$$.fragment,e),E(qe.$$.fragment,e),E(ze.$$.fragment,e),E(je.$$.fragment,e),E(Se.$$.fragment,e),E(ce.$$.fragment,e),E(we.$$.fragment,e),E(Ae.$$.fragment,e),E(Qe.$$.fragment,e),E(Ce.$$.fragment,e),E(Oe.$$.fragment,e),E(Pe.$$.fragment,e),E(xe.$$.fragment,e),E(ue.$$.fragment,e),E(ke.$$.fragment,e),E(ye.$$.fragment,e),E(Te.$$.fragment,e),E(me.$$.fragment,e),Na=!0)},o(e){D(h.$$.fragment,e),D(x.$$.fragment,e),D(F.$$.fragment,e),D(De.$$.fragment,e),D(qe.$$.fragment,e),D(ze.$$.fragment,e),D(je.$$.fragment,e),D(Se.$$.fragment,e),D(ce.$$.fragment,e),D(we.$$.fragment,e),D(Ae.$$.fragment,e),D(Qe.$$.fragment,e),D(Ce.$$.fragment,e),D(Oe.$$.fragment,e),D(Pe.$$.fragment,e),D(xe.$$.fragment,e),D(ue.$$.fragment,e),D(ke.$$.fragment,e),D(ye.$$.fragment,e),D(Te.$$.fragment,e),D(me.$$.fragment,e),Na=!1},d(e){a(p),e&&a(Q),e&&a(m),q(h),e&&a(y),q(x,e),e&&a(S),e&&a(_),e&&a($e),q(F,e),e&&a(Ee),e&&a(Z),q(De),e&&a(ia),e&&a(Le),e&&a(sa),e&&a(se),e&&a(ra),e&&a(G),e&&a(la),e&&a(te),q(qe),e&&a(na),e&&a(le),e&&a(ca),e&&a(ne),e&&a(da),q(ze,e),e&&a(ua),e&&a(T),e&&a(pa),q(je,e),e&&a(fa),q(Se,e),e&&a(ma),e&&a(M),e&&a(ha),q(ce,e),e&&a(_a),e&&a(H),e&&a(ga),q(we,e),e&&a(va),e&&a(N),e&&a($a),q(Ae,e),e&&a(Ea),q(Qe,e),e&&a(Da),e&&a(de),e&&a(qa),q(Ce,e),e&&a(ba),q(Oe,e),e&&a(za),e&&a(P),e&&a(ja),q(Pe,e),e&&a(Sa),q(xe,e),e&&a(wa),e&&a(tt),e&&a(Aa),q(ue,e),e&&a(Qa),e&&a(U),e&&a(Ca),q(ke,e),e&&a(Oa),e&&a(pe),e&&a(Pa),e&&a(at),e&&a(xa),e&&a(ae),q(ye),e&&a(ka),e&&a(k),e&&a(ya),q(Te,e),e&&a(Ta),e&&a(V),e&&a(Ha),q(me,e)}}}const jr={local:"e-se-il-mio-dataset-non-sullhub",sections:[{local:"lavorare-con-dataset-locali-e-in-remoto",title:"Lavorare con dataset locali e in remoto"},{local:"caricare-un-dataset-locale",title:"Caricare un dataset locale"},{local:"caricare-un-dataset-in-remoto",title:"Caricare un dataset in remoto"}],title:"E se il mio dataset non \xE8 sull'Hub?"};function Sr(oe){return vr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xr extends mr{constructor(p){super();hr(this,p,Sr,zr,_r,{})}}export{xr as default,jr as metadata};
