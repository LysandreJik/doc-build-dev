import{S as ut,i as mt,s as wt,e as r,k as d,w as x,t as p,l as pt,M as $t,c as s,d as e,m as f,x as _,a as n,h as u,b as h,G as o,g as l,y as b,o as $,p as gt,q as g,B as k,v as vt,n as yt}from"../../chunks/vendor-hf-doc-builder.js";import{I as be}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as xt}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import{Q as ke}from"../../chunks/Question-hf-doc-builder.js";import{F as _t}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function bt(ze){let w,E,T,C,X,v,$e,M,Ee,ge,pe,j,J,O,A,ue,N,S,se,Q,ve,L,V,B,Z,me,F,ee,z,q,Y,H,te,P,U,ne,ae,ie,I;return C=new be({}),A=new ke({props:{choices:[{text:"Nothing, but you get a warning.",explain:"You do get a warning, but that's not all!"},{text:"The head of the pretrained model is discarded and a new head suitable for the task is inserted instead.",explain:"Correct. For example, when we used <code>TFAutoModelForSequenceClassification</code> with <code>bert-base-uncased</code>, we got warnings when instantiating the model. The pretrained head is not used for the sequence classification task, so it's discarded and a new head is instantiated with random weights.",correct:!0},{text:"The head of the pretrained model is discarded.",explain:"Something else needs to happen. Try again!"},{text:"Nothing, since the model can still be fine-tuned for the different task.",explain:"The head of the pretrained model was not trained to solve this task, so we should discard the head!"}]}}),Q=new be({}),ee=new ke({props:{choices:[{text:"The models work on a TPU out of the box.",explain:"Almost! There are some small additional changes required. For example, you need to run everything in a <code>TPUStrategy</code> scope, including the initialization of the model."},{text:"You can leverage existing methods such as <code>compile()</code>, <code>fit()</code>, and <code>predict()</code>.",explain:"Correct! Once you have the data, training on it requires very little work.",correct:!0},{text:"You get to learn Keras as well as transformers.",explain:"Correct, but we're looking for something else :)",correct:!0},{text:"You can easily compute metrics related to the dataset.",explain:"Keras helps us with training and evaluating the model, not computing dataset-related metrics."}]}}),te=new be({}),ie=new ke({props:{choices:[{text:"By subclassing <code>tf.keras.metrics.Metric</code>.",explain:"Great!",correct:!0},{text:"Using the Keras functional API.",explain:"Try again!"},{text:"By using a callable with signature <code>metric_fn(y_true, y_pred)</code>.",explain:"Correct!",correct:!0},{text:"By Googling it.",explain:"That's not the answer we're looking for, but it should help you find it.",correct:!0}]}}),{c(){w=r("h3"),E=r("a"),T=r("span"),x(C.$$.fragment),X=d(),v=r("span"),$e=p("4. What happens when you instantiate one of the "),M=r("code"),Ee=p("TFAutoModelForXxx"),ge=p(" classes with a pretrained language model (such as "),pe=r("code"),j=p("bert-base-uncased"),J=p(") that corresponds to a different task than the one for which it was trained?"),O=d(),x(A.$$.fragment),ue=d(),N=r("h3"),S=r("a"),se=r("span"),x(Q.$$.fragment),ve=d(),L=r("span"),V=p("5. The TensorFlow models from "),B=r("code"),Z=p("transformers"),me=p(" are already Keras models. What benefit does this offer?"),F=d(),x(ee.$$.fragment),z=d(),q=r("h3"),Y=r("a"),H=r("span"),x(te.$$.fragment),P=d(),U=r("span"),ne=p("6. How can you define your own custom metric?"),ae=d(),x(ie.$$.fragment),this.h()},l(i){w=s(i,"H3",{class:!0});var y=n(w);E=s(y,"A",{id:!0,class:!0,href:!0});var Te=n(E);T=s(Te,"SPAN",{});var we=n(T);_(C.$$.fragment,we),we.forEach(e),Te.forEach(e),X=f(y),v=s(y,"SPAN",{});var R=n(v);$e=u(R,"4. What happens when you instantiate one of the "),M=s(R,"CODE",{});var oe=n(M);Ee=u(oe,"TFAutoModelForXxx"),oe.forEach(e),ge=u(R," classes with a pretrained language model (such as "),pe=s(R,"CODE",{});var he=n(pe);j=u(he,"bert-base-uncased"),he.forEach(e),J=u(R,") that corresponds to a different task than the one for which it was trained?"),R.forEach(e),y.forEach(e),O=f(i),_(A.$$.fragment,i),ue=f(i),N=s(i,"H3",{class:!0});var le=n(N);S=s(le,"A",{id:!0,class:!0,href:!0});var K=n(S);se=s(K,"SPAN",{});var Ae=n(se);_(Q.$$.fragment,Ae),Ae.forEach(e),K.forEach(e),ve=f(le),L=s(le,"SPAN",{});var D=n(L);V=u(D,"5. The TensorFlow models from "),B=s(D,"CODE",{});var ce=n(B);Z=u(ce,"transformers"),ce.forEach(e),me=u(D," are already Keras models. What benefit does this offer?"),D.forEach(e),le.forEach(e),F=f(i),_(ee.$$.fragment,i),z=f(i),q=s(i,"H3",{class:!0});var de=n(q);Y=s(de,"A",{id:!0,class:!0,href:!0});var G=n(Y);H=s(G,"SPAN",{});var Se=n(H);_(te.$$.fragment,Se),Se.forEach(e),G.forEach(e),P=f(de),U=s(de,"SPAN",{});var W=n(U);ne=u(W,"6. How can you define your own custom metric?"),W.forEach(e),de.forEach(e),ae=f(i),_(ie.$$.fragment,i),this.h()},h(){h(E,"id","4.-what-happens-when-you-instantiate-one-of-the-<code>tfautomodelforxxx</code>-classes-with-a-pretrained-language-model-(such-as-<code>bert-base-uncased</code>)-that-corresponds-to-a-different-task-than-the-one-for-which-it-was-trained?"),h(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(E,"href","#4.-what-happens-when-you-instantiate-one-of-the-<code>tfautomodelforxxx</code>-classes-with-a-pretrained-language-model-(such-as-<code>bert-base-uncased</code>)-that-corresponds-to-a-different-task-than-the-one-for-which-it-was-trained?"),h(w,"class","relative group"),h(S,"id","5.-the-tensorflow-models-from-<code>transformers</code>-are-already-keras-models.-what-benefit-does-this-offer?"),h(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(S,"href","#5.-the-tensorflow-models-from-<code>transformers</code>-are-already-keras-models.-what-benefit-does-this-offer?"),h(N,"class","relative group"),h(Y,"id","6.-how-can-you-define-your-own-custom-metric?"),h(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Y,"href","#6.-how-can-you-define-your-own-custom-metric?"),h(q,"class","relative group")},m(i,y){l(i,w,y),o(w,E),o(E,T),b(C,T,null),o(w,X),o(w,v),o(v,$e),o(v,M),o(M,Ee),o(v,ge),o(v,pe),o(pe,j),o(v,J),l(i,O,y),b(A,i,y),l(i,ue,y),l(i,N,y),o(N,S),o(S,se),b(Q,se,null),o(N,ve),o(N,L),o(L,V),o(L,B),o(B,Z),o(L,me),l(i,F,y),b(ee,i,y),l(i,z,y),l(i,q,y),o(q,Y),o(Y,H),b(te,H,null),o(q,P),o(q,U),o(U,ne),l(i,ae,y),b(ie,i,y),I=!0},i(i){I||(g(C.$$.fragment,i),g(A.$$.fragment,i),g(Q.$$.fragment,i),g(ee.$$.fragment,i),g(te.$$.fragment,i),g(ie.$$.fragment,i),I=!0)},o(i){$(C.$$.fragment,i),$(A.$$.fragment,i),$(Q.$$.fragment,i),$(ee.$$.fragment,i),$(te.$$.fragment,i),$(ie.$$.fragment,i),I=!1},d(i){i&&e(w),k(C),i&&e(O),k(A,i),i&&e(ue),i&&e(N),k(Q),i&&e(F),k(ee,i),i&&e(z),i&&e(q),k(te),i&&e(ae),k(ie,i)}}}function kt(ze){let w,E,T,C,X,v,$e,M,Ee,ge,pe,j,J,O,A,ue,N,S,se,Q,ve,L,V,B,Z,me,F,ee,z,q,Y,H,te,P,U,ne,ae,ie,I,i,y,Te,we,R,oe,he,le,K,Ae,D,ce,de,G,Se,W,fe,ye,He,Be,xe,Pe,a,c,re,_e,Ce,Ye,Fe,Ne,De,qe,Ie;return C=new be({}),j=new ke({props:{choices:[{text:"The results of the function are cached, so it won't take any time if we re-execute the code.",explain:"That is indeed one of the neat benefits of this method! It's not the only one, though...",correct:!0},{text:"It can apply multiprocessing to go faster than applying the function on each element of the dataset.",explain:"This is a neat feature of this method, but it's not the only one!",correct:!0},{text:"It does not load the whole dataset into memory, saving the results as soon as one element is processed.",explain:"That's one advantage of this method. There are others, though!",correct:!0}]}}),N=new be({}),L=new ke({props:{choices:[{text:"It's when you pad the inputs for each batch to the maximum length in the whole dataset.",explain:"It does imply padding when creating the batch, but not to the maximum length in the whole dataset."},{text:"It's when you pad your inputs when the batch is created, to the maximum length of the sentences inside that batch.",explain:`That's correct! The "dynamic" part comes from the fact that the size of each batch is determined at the time of creation, and all your batches might have different shapes as a result.`,correct:!0},{text:"It's when you pad your inputs so that each sentence has the same number of tokens as the previous one in the dataset.",explain:"That's incorrect, plus it doesn't make sense to look at the order in the dataset since we shuffle it during training."}]}}),F=new be({}),H=new ke({props:{choices:[{text:"It ensures all the sequences in the dataset have the same length.",explain:"A collate function is involved in handling individual batches, not the whole dataset. Additionally, we're talking about generic collate functions, not <code>DataCollatorWithPadding</code> specifically."},{text:"It puts together all the samples in a batch.",explain:"Correct! You can pass the collate function as an argument of a <code>DataLoader</code>. We used the <code>DataCollatorWithPadding</code> function, which pads all items in a batch so they have the same length.",correct:!0},{text:"It preprocesses the whole dataset.",explain:"That would be a preprocessing function, not a collate function."},{text:"It truncates the sequences in the dataset.",explain:"A collate function is involved in handling individual batches, not the whole dataset. If you're interested in truncating, you can use the <code>truncate</code> argument of <code>tokenizer</code>."}]}}),ae=new be({}),K=new ke({props:{choices:[{text:"Nothing, but you get a warning.",explain:"You do get a warning, but that's not all!"},{text:"The head of the pretrained model is discarded and a new head suitable for the task is inserted instead.",explain:"Correct. For example, when we used <code>AutoModelForSequenceClassification</code> with <code>bert-base-uncased</code>, we got warnings when instantiating the model. The pretrained head is not used for the sequence classification task, so it's discarded and a new head is instantiated with random weights.",correct:!0},{text:"The head of the pretrained model is discarded.",explain:"Something else needs to happen. Try again!"},{text:"Nothing, since the model can still be fine-tuned for the different task.",explain:"The head of the pretrained model was not trained to solve this task, so we should discard the head!"}]}}),G=new be({}),Pe=new ke({props:{choices:[{text:"It contains all the hyperparameters used for training and evaluation with the <code>Trainer</code>.",explain:"Correct!",correct:!0},{text:"It specifies the size of the model.",explain:"The model size is defined by the model configuration, not the class <code>TrainingArguments</code>."},{text:"It just contains the hyperparameters used for evaluation.",explain:"In the example, we specified where the model and its checkpoints will be saved. Try again!"},{text:"It just contains the hyperparameters used for training.",explain:"In the example, we used an <code>evaluation_strategy</code> as well, so this impacts evaluation. Try again!"}]}}),Ce=new be({}),qe=new ke({props:{choices:[{text:"It provides access to faster models.",explain:"No, the \u{1F917} Accelerate library does not provide any models."},{text:"It provides a high-level API so I don't have to implement my own training loop.",explain:"This is what we did with <code>Trainer</code>, not the \u{1F917} Accelerate library. Try again!"},{text:"It makes our training loops work on distributed strategies",explain:"Correct! With \u{1F917} Accelerate, your training loops will work for multiple GPUs and TPUs.",correct:!0},{text:"It provides more optimization functions.",explain:"No, the \u{1F917} Accelerate library does not provide any optimization functions."}]}}),{c(){w=r("h3"),E=r("a"),T=r("span"),x(C.$$.fragment),X=d(),v=r("span"),$e=p("4. What are the benefits of the "),M=r("code"),Ee=p("Dataset.map()"),ge=p(" method?"),pe=d(),x(j.$$.fragment),J=d(),O=r("h3"),A=r("a"),ue=r("span"),x(N.$$.fragment),S=d(),se=r("span"),Q=p("5. What does dynamic padding mean?"),ve=d(),x(L.$$.fragment),V=d(),B=r("h3"),Z=r("a"),me=r("span"),x(F.$$.fragment),ee=d(),z=r("span"),q=p("6. What is the purpose of a collate function?"),Y=d(),x(H.$$.fragment),te=d(),P=r("h3"),U=r("a"),ne=r("span"),x(ae.$$.fragment),ie=d(),I=r("span"),i=p("7. What happens when you instantiate one of the "),y=r("code"),Te=p("AutoModelForXxx"),we=p(" classes with a pretrained language model (such as "),R=r("code"),oe=p("bert-base-uncased"),he=p(") that corresponds to a different task than the one for which it was trained?"),le=d(),x(K.$$.fragment),Ae=d(),D=r("h3"),ce=r("a"),de=r("span"),x(G.$$.fragment),Se=d(),W=r("span"),fe=p("8. What\u2019s the purpose of "),ye=r("code"),He=p("TrainingArguments"),Be=p("?"),xe=d(),x(Pe.$$.fragment),a=d(),c=r("h3"),re=r("a"),_e=r("span"),x(Ce.$$.fragment),Ye=d(),Fe=r("span"),Ne=p("9. Why should you use the \u{1F917} Accelerate library?"),De=d(),x(qe.$$.fragment),this.h()},l(t){w=s(t,"H3",{class:!0});var m=n(w);E=s(m,"A",{id:!0,class:!0,href:!0});var We=n(E);T=s(We,"SPAN",{});var Ke=n(T);_(C.$$.fragment,Ke),Ke.forEach(e),We.forEach(e),X=f(m),v=s(m,"SPAN",{});var Me=n(v);$e=u(Me,"4. What are the benefits of the "),M=s(Me,"CODE",{});var Oe=n(M);Ee=u(Oe,"Dataset.map()"),Oe.forEach(e),ge=u(Me," method?"),Me.forEach(e),m.forEach(e),pe=f(t),_(j.$$.fragment,t),J=f(t),O=s(t,"H3",{class:!0});var Le=n(O);A=s(Le,"A",{id:!0,class:!0,href:!0});var Ge=n(A);ue=s(Ge,"SPAN",{});var Xe=n(ue);_(N.$$.fragment,Xe),Xe.forEach(e),Ge.forEach(e),S=f(Le),se=s(Le,"SPAN",{});var Ze=n(se);Q=u(Ze,"5. What does dynamic padding mean?"),Ze.forEach(e),Le.forEach(e),ve=f(t),_(L.$$.fragment,t),V=f(t),B=s(t,"H3",{class:!0});var Qe=n(B);Z=s(Qe,"A",{id:!0,class:!0,href:!0});var et=n(Z);me=s(et,"SPAN",{});var tt=n(me);_(F.$$.fragment,tt),tt.forEach(e),et.forEach(e),ee=f(Qe),z=s(Qe,"SPAN",{});var at=n(z);q=u(at,"6. What is the purpose of a collate function?"),at.forEach(e),Qe.forEach(e),Y=f(t),_(H.$$.fragment,t),te=f(t),P=s(t,"H3",{class:!0});var Re=n(P);U=s(Re,"A",{id:!0,class:!0,href:!0});var ot=n(U);ne=s(ot,"SPAN",{});var rt=n(ne);_(ae.$$.fragment,rt),rt.forEach(e),ot.forEach(e),ie=f(Re),I=s(Re,"SPAN",{});var Ue=n(I);i=u(Ue,"7. What happens when you instantiate one of the "),y=s(Ue,"CODE",{});var st=n(y);Te=u(st,"AutoModelForXxx"),st.forEach(e),we=u(Ue," classes with a pretrained language model (such as "),R=s(Ue,"CODE",{});var nt=n(R);oe=u(nt,"bert-base-uncased"),nt.forEach(e),he=u(Ue,") that corresponds to a different task than the one for which it was trained?"),Ue.forEach(e),Re.forEach(e),le=f(t),_(K.$$.fragment,t),Ae=f(t),D=s(t,"H3",{class:!0});var je=n(D);ce=s(je,"A",{id:!0,class:!0,href:!0});var it=n(ce);de=s(it,"SPAN",{});var ht=n(de);_(G.$$.fragment,ht),ht.forEach(e),it.forEach(e),Se=f(je),W=s(je,"SPAN",{});var Je=n(W);fe=u(Je,"8. What\u2019s the purpose of "),ye=s(Je,"CODE",{});var lt=n(ye);He=u(lt,"TrainingArguments"),lt.forEach(e),Be=u(Je,"?"),Je.forEach(e),je.forEach(e),xe=f(t),_(Pe.$$.fragment,t),a=f(t),c=s(t,"H3",{class:!0});var Ve=n(c);re=s(Ve,"A",{id:!0,class:!0,href:!0});var ct=n(re);_e=s(ct,"SPAN",{});var dt=n(_e);_(Ce.$$.fragment,dt),dt.forEach(e),ct.forEach(e),Ye=f(Ve),Fe=s(Ve,"SPAN",{});var ft=n(Fe);Ne=u(ft,"9. Why should you use the \u{1F917} Accelerate library?"),ft.forEach(e),Ve.forEach(e),De=f(t),_(qe.$$.fragment,t),this.h()},h(){h(E,"id","4.-what-are-the-benefits-of-the-<code>dataset.map()</code>-method?"),h(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(E,"href","#4.-what-are-the-benefits-of-the-<code>dataset.map()</code>-method?"),h(w,"class","relative group"),h(A,"id","5.-what-does-dynamic-padding-mean?"),h(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(A,"href","#5.-what-does-dynamic-padding-mean?"),h(O,"class","relative group"),h(Z,"id","6.-what-is-the-purpose-of-a-collate-function?"),h(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Z,"href","#6.-what-is-the-purpose-of-a-collate-function?"),h(B,"class","relative group"),h(U,"id","7.-what-happens-when-you-instantiate-one-of-the-<code>automodelforxxx</code>-classes-with-a-pretrained-language-model-(such-as-<code>bert-base-uncased</code>)-that-corresponds-to-a-different-task-than-the-one-for-which-it-was-trained?"),h(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(U,"href","#7.-what-happens-when-you-instantiate-one-of-the-<code>automodelforxxx</code>-classes-with-a-pretrained-language-model-(such-as-<code>bert-base-uncased</code>)-that-corresponds-to-a-different-task-than-the-one-for-which-it-was-trained?"),h(P,"class","relative group"),h(ce,"id","8.-what\u2019s-the-purpose-of-<code>trainingarguments</code>?"),h(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ce,"href","#8.-what\u2019s-the-purpose-of-<code>trainingarguments</code>?"),h(D,"class","relative group"),h(re,"id","9.-why-should-you-use-the-\u{1F917}-accelerate-library?"),h(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(re,"href","#9.-why-should-you-use-the-\u{1F917}-accelerate-library?"),h(c,"class","relative group")},m(t,m){l(t,w,m),o(w,E),o(E,T),b(C,T,null),o(w,X),o(w,v),o(v,$e),o(v,M),o(M,Ee),o(v,ge),l(t,pe,m),b(j,t,m),l(t,J,m),l(t,O,m),o(O,A),o(A,ue),b(N,ue,null),o(O,S),o(O,se),o(se,Q),l(t,ve,m),b(L,t,m),l(t,V,m),l(t,B,m),o(B,Z),o(Z,me),b(F,me,null),o(B,ee),o(B,z),o(z,q),l(t,Y,m),b(H,t,m),l(t,te,m),l(t,P,m),o(P,U),o(U,ne),b(ae,ne,null),o(P,ie),o(P,I),o(I,i),o(I,y),o(y,Te),o(I,we),o(I,R),o(R,oe),o(I,he),l(t,le,m),b(K,t,m),l(t,Ae,m),l(t,D,m),o(D,ce),o(ce,de),b(G,de,null),o(D,Se),o(D,W),o(W,fe),o(W,ye),o(ye,He),o(W,Be),l(t,xe,m),b(Pe,t,m),l(t,a,m),l(t,c,m),o(c,re),o(re,_e),b(Ce,_e,null),o(c,Ye),o(c,Fe),o(Fe,Ne),l(t,De,m),b(qe,t,m),Ie=!0},i(t){Ie||(g(C.$$.fragment,t),g(j.$$.fragment,t),g(N.$$.fragment,t),g(L.$$.fragment,t),g(F.$$.fragment,t),g(H.$$.fragment,t),g(ae.$$.fragment,t),g(K.$$.fragment,t),g(G.$$.fragment,t),g(Pe.$$.fragment,t),g(Ce.$$.fragment,t),g(qe.$$.fragment,t),Ie=!0)},o(t){$(C.$$.fragment,t),$(j.$$.fragment,t),$(N.$$.fragment,t),$(L.$$.fragment,t),$(F.$$.fragment,t),$(H.$$.fragment,t),$(ae.$$.fragment,t),$(K.$$.fragment,t),$(G.$$.fragment,t),$(Pe.$$.fragment,t),$(Ce.$$.fragment,t),$(qe.$$.fragment,t),Ie=!1},d(t){t&&e(w),k(C),t&&e(pe),k(j,t),t&&e(J),t&&e(O),k(N),t&&e(ve),k(L,t),t&&e(V),t&&e(B),k(F),t&&e(Y),k(H,t),t&&e(te),t&&e(P),k(ae),t&&e(le),k(K,t),t&&e(Ae),t&&e(D),k(G),t&&e(xe),k(Pe,t),t&&e(a),t&&e(c),k(Ce),t&&e(De),k(qe,t)}}}function Et(ze){let w,E,T,C,X,v,$e,M,Ee,ge,pe,j,J,O,A,ue,N,S,se,Q,ve,L,V,B,Z,me,F,ee,z,q,Y,H,te,P,U,ne,ae,ie,I,i,y,Te,we,R,oe,he,le,K,Ae,D,ce,de,G,Se,W,fe,ye,He;T=new _t({props:{fw:ze[0]}}),M=new be({}),J=new xt({props:{chapter:3,classNames:"absolute z-10 right-0 top-0"}}),F=new ke({props:{choices:[{text:"Joy",explain:"Try again \u2014 this emotion is present in that dataset!"},{text:"Love",explain:"Try again \u2014 this emotion is present in that dataset!"},{text:"Confusion",explain:"Correct! Confusion is not one of the six basic emotions.",correct:!0},{text:"Surprise",explain:"Surprise! Try another one!"}]}}),H=new be({}),we=new ke({props:{choices:[{text:"Sentiment classification",explain:"That's right! You can tell thanks to the tags.",correct:!0},{text:"Machine translation",explain:"That's not it \u2014 take another look at the <a href='https://huggingface.co/datasets/ar_sarcasm'>dataset card</a>!"},{text:"Named entity recognition",explain:"That's not it \u2014 take another look at the <a href='https://huggingface.co/datasets/ar_sarcasm'>dataset card</a>!"},{text:"Question answering",explain:"Alas, this question was not answered correctly. Try again!"}]}}),K=new be({}),G=new ke({props:{choices:[{text:"Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2",explain:"A <code>[SEP]</code> special token is needed to separate the two sentences, but that's not the only thing!"},{text:"[CLS] Tokens_of_sentence_1 Tokens_of_sentence_2",explain:"A <code>[CLS]</code> special token is required at the beginning, but that's not the only thing!"},{text:"[CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2 [SEP]",explain:"That's correct!",correct:!0},{text:"[CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2",explain:"A <code>[CLS]</code> special token is needed at the beginning as well as a <code>[SEP]</code> special token to separate the two sentences, but that's not all!"}]}});const Be=[kt,bt],xe=[];function Pe(a,c){return a[0]==="pt"?0:1}return W=Pe(ze),fe=xe[W]=Be[W](ze),{c(){w=r("meta"),E=d(),x(T.$$.fragment),C=d(),X=r("h1"),v=r("a"),$e=r("span"),x(M.$$.fragment),Ee=d(),ge=r("span"),pe=p("End-of-chapter quiz"),j=d(),x(J.$$.fragment),O=d(),A=r("p"),ue=p("Test what you learned in this chapter!"),N=d(),S=r("h3"),se=p("1. The "),Q=r("code"),ve=p("emotion"),L=p(" dataset contains Twitter messages labeled with emotions. Search for it in the "),V=r("a"),B=p("Hub"),Z=p(", and read the dataset card. Which of these is not one of its basic emotions?"),me=d(),x(F.$$.fragment),ee=d(),z=r("h3"),q=r("a"),Y=r("span"),x(H.$$.fragment),te=d(),P=r("span"),U=p("2. Search for the "),ne=r("code"),ae=p("ar_sarcasm"),ie=p(" dataset in the "),I=r("a"),i=p("Hub"),y=p(". Which task does it support?"),Te=d(),x(we.$$.fragment),R=d(),oe=r("h3"),he=r("a"),le=r("span"),x(K.$$.fragment),Ae=d(),D=r("span"),ce=p("3. How does the BERT model expect a pair of sentences to be processed?"),de=d(),x(G.$$.fragment),Se=d(),fe.c(),ye=pt(),this.h()},l(a){const c=$t('[data-svelte="svelte-1phssyn"]',document.head);w=s(c,"META",{name:!0,content:!0}),c.forEach(e),E=f(a),_(T.$$.fragment,a),C=f(a),X=s(a,"H1",{class:!0});var re=n(X);v=s(re,"A",{id:!0,class:!0,href:!0});var _e=n(v);$e=s(_e,"SPAN",{});var Ce=n($e);_(M.$$.fragment,Ce),Ce.forEach(e),_e.forEach(e),Ee=f(re),ge=s(re,"SPAN",{});var Ye=n(ge);pe=u(Ye,"End-of-chapter quiz"),Ye.forEach(e),re.forEach(e),j=f(a),_(J.$$.fragment,a),O=f(a),A=s(a,"P",{});var Fe=n(A);ue=u(Fe,"Test what you learned in this chapter!"),Fe.forEach(e),N=f(a),S=s(a,"H3",{});var Ne=n(S);se=u(Ne,"1. The "),Q=s(Ne,"CODE",{});var De=n(Q);ve=u(De,"emotion"),De.forEach(e),L=u(Ne," dataset contains Twitter messages labeled with emotions. Search for it in the "),V=s(Ne,"A",{href:!0,rel:!0});var qe=n(V);B=u(qe,"Hub"),qe.forEach(e),Z=u(Ne,", and read the dataset card. Which of these is not one of its basic emotions?"),Ne.forEach(e),me=f(a),_(F.$$.fragment,a),ee=f(a),z=s(a,"H3",{class:!0});var Ie=n(z);q=s(Ie,"A",{id:!0,class:!0,href:!0});var t=n(q);Y=s(t,"SPAN",{});var m=n(Y);_(H.$$.fragment,m),m.forEach(e),t.forEach(e),te=f(Ie),P=s(Ie,"SPAN",{});var We=n(P);U=u(We,"2. Search for the "),ne=s(We,"CODE",{});var Ke=n(ne);ae=u(Ke,"ar_sarcasm"),Ke.forEach(e),ie=u(We," dataset in the "),I=s(We,"A",{href:!0,rel:!0});var Me=n(I);i=u(Me,"Hub"),Me.forEach(e),y=u(We,". Which task does it support?"),We.forEach(e),Ie.forEach(e),Te=f(a),_(we.$$.fragment,a),R=f(a),oe=s(a,"H3",{class:!0});var Oe=n(oe);he=s(Oe,"A",{id:!0,class:!0,href:!0});var Le=n(he);le=s(Le,"SPAN",{});var Ge=n(le);_(K.$$.fragment,Ge),Ge.forEach(e),Le.forEach(e),Ae=f(Oe),D=s(Oe,"SPAN",{});var Xe=n(D);ce=u(Xe,"3. How does the BERT model expect a pair of sentences to be processed?"),Xe.forEach(e),Oe.forEach(e),de=f(a),_(G.$$.fragment,a),Se=f(a),fe.l(a),ye=pt(),this.h()},h(){h(w,"name","hf:doc:metadata"),h(w,"content",JSON.stringify(Tt)),h(v,"id","endofchapter-quiz"),h(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(v,"href","#endofchapter-quiz"),h(X,"class","relative group"),h(V,"href","https://huggingface.co/datasets"),h(V,"rel","nofollow"),h(q,"id","2.-search-for-the-<code>ar_sarcasm</code>-dataset-in-the-hub.-which-task-does-it-support?"),h(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(q,"href","#2.-search-for-the-<code>ar_sarcasm</code>-dataset-in-the-hub.-which-task-does-it-support?"),h(I,"href","https://huggingface.co/datasets"),h(I,"rel","nofollow"),h(z,"class","relative group"),h(he,"id","3.-how-does-the-bert-model-expect-a-pair-of-sentences-to-be-processed?"),h(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(he,"href","#3.-how-does-the-bert-model-expect-a-pair-of-sentences-to-be-processed?"),h(oe,"class","relative group")},m(a,c){o(document.head,w),l(a,E,c),b(T,a,c),l(a,C,c),l(a,X,c),o(X,v),o(v,$e),b(M,$e,null),o(X,Ee),o(X,ge),o(ge,pe),l(a,j,c),b(J,a,c),l(a,O,c),l(a,A,c),o(A,ue),l(a,N,c),l(a,S,c),o(S,se),o(S,Q),o(Q,ve),o(S,L),o(S,V),o(V,B),o(S,Z),l(a,me,c),b(F,a,c),l(a,ee,c),l(a,z,c),o(z,q),o(q,Y),b(H,Y,null),o(z,te),o(z,P),o(P,U),o(P,ne),o(ne,ae),o(P,ie),o(P,I),o(I,i),o(P,y),l(a,Te,c),b(we,a,c),l(a,R,c),l(a,oe,c),o(oe,he),o(he,le),b(K,le,null),o(oe,Ae),o(oe,D),o(D,ce),l(a,de,c),b(G,a,c),l(a,Se,c),xe[W].m(a,c),l(a,ye,c),He=!0},p(a,[c]){const re={};c&1&&(re.fw=a[0]),T.$set(re);let _e=W;W=Pe(a),W!==_e&&(yt(),$(xe[_e],1,1,()=>{xe[_e]=null}),gt(),fe=xe[W],fe||(fe=xe[W]=Be[W](a),fe.c()),g(fe,1),fe.m(ye.parentNode,ye))},i(a){He||(g(T.$$.fragment,a),g(M.$$.fragment,a),g(J.$$.fragment,a),g(F.$$.fragment,a),g(H.$$.fragment,a),g(we.$$.fragment,a),g(K.$$.fragment,a),g(G.$$.fragment,a),g(fe),He=!0)},o(a){$(T.$$.fragment,a),$(M.$$.fragment,a),$(J.$$.fragment,a),$(F.$$.fragment,a),$(H.$$.fragment,a),$(we.$$.fragment,a),$(K.$$.fragment,a),$(G.$$.fragment,a),$(fe),He=!1},d(a){e(w),a&&e(E),k(T,a),a&&e(C),a&&e(X),k(M),a&&e(j),k(J,a),a&&e(O),a&&e(A),a&&e(N),a&&e(S),a&&e(me),k(F,a),a&&e(ee),a&&e(z),k(H),a&&e(Te),k(we,a),a&&e(R),a&&e(oe),k(K),a&&e(de),k(G,a),a&&e(Se),xe[W].d(a),a&&e(ye)}}}const Tt={local:"endofchapter-quiz",title:"End-of-chapter quiz"};function At(ze,w,E){let T="pt";return vt(()=>{const C=new URLSearchParams(window.location.search);E(0,T=C.get("fw")||"pt")}),[T]}class It extends ut{constructor(w){super();mt(this,w,At,Et,wt,{})}}export{It as default,Tt as metadata};
