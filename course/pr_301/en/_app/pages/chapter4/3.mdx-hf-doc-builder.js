import{S as Nm,i as Um,s as Rm,e as a,k as c,w as E,t as i,l as Gm,M as Wm,c as s,d as t,m as p,x as j,a as f,h as l,b as _,N as Ge,G as o,g as n,y as z,o as b,p as ut,q as v,B as T,v as Bm,n as ct}from"../../chunks/vendor-hf-doc-builder.js";import{T as Lm}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Yc}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Zt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as q}from"../../chunks/CodeBlock-hf-doc-builder.js";import{C as Sm}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";import{F as Ym}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Vm(O){let u,d;return u=new Sm({props:{chapter:4,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter4/section3_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter4/section3_tf.ipynb"}]}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function Km(O){let u,d;return u=new Sm({props:{chapter:4,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter4/section3_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter4/section3_pt.ipynb"}]}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function Jm(O){let u,d;return u=new Yc({props:{id:"pUh5cGmNV8Y"}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function Xm(O){let u,d;return u=new Yc({props:{id:"Zh0FfmVrKX0"}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function Zm(O){let u,d,h,g,k,A,F,P,M,I,D,m,y,w,$,H,N,G,L,W,J,ie,B,le,ye,te,R,oe,re,Y,be,ae;return I=new q({props:{code:`from transformers import PushToHubCallback

callback = PushToHubCallback(
    "bert-finetuned-mrpc", save_strategy="epoch", tokenizer=tokenizer
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(
    <span class="hljs-string">&quot;bert-finetuned-mrpc&quot;</span>, save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>, tokenizer=tokenizer
)`}}),{c(){u=a("p"),d=i("If you are using Keras to train your model, the easiest way to upload it to the Hub is to pass along a "),h=a("code"),g=i("PushToHubCallback"),k=i(" when you call "),A=a("code"),F=i("model.fit()"),P=i(":"),M=c(),E(I.$$.fragment),D=c(),m=a("p"),y=i("Then you should add "),w=a("code"),$=i("callbacks=[callback]"),H=i(" in your call to "),N=a("code"),G=i("model.fit()"),L=i(". The callback will then upload your model to the Hub each time it is saved (here every epoch) in a repository in your namespace. That repository will be named like the output directory you picked (here "),W=a("code"),J=i("bert-finetuned-mrpc"),ie=i(") but you can choose a different name with "),B=a("code"),le=i('hub_model_id = "a_different_name"'),ye=i("."),te=c(),R=a("p"),oe=i("To upload you model to an organization you are a member of, just pass it with "),re=a("code"),Y=i('hub_model_id = "my_organization/my_repo_name"'),be=i(".")},l(x){u=s(x,"P",{});var U=f(u);d=l(U,"If you are using Keras to train your model, the easiest way to upload it to the Hub is to pass along a "),h=s(U,"CODE",{});var ve=f(h);g=l(ve,"PushToHubCallback"),ve.forEach(t),k=l(U," when you call "),A=s(U,"CODE",{});var X=f(A);F=l(X,"model.fit()"),X.forEach(t),P=l(U,":"),U.forEach(t),M=p(x),j(I.$$.fragment,x),D=p(x),m=s(x,"P",{});var V=f(m);y=l(V,"Then you should add "),w=s(V,"CODE",{});var ce=f(w);$=l(ce,"callbacks=[callback]"),ce.forEach(t),H=l(V," in your call to "),N=s(V,"CODE",{});var Le=f(N);G=l(Le,"model.fit()"),Le.forEach(t),L=l(V,". The callback will then upload your model to the Hub each time it is saved (here every epoch) in a repository in your namespace. That repository will be named like the output directory you picked (here "),W=s(V,"CODE",{});var pe=f(W);J=l(pe,"bert-finetuned-mrpc"),pe.forEach(t),ie=l(V,") but you can choose a different name with "),B=s(V,"CODE",{});var we=f(B);le=l(we,'hub_model_id = "a_different_name"'),we.forEach(t),ye=l(V,"."),V.forEach(t),te=p(x),R=s(x,"P",{});var Z=f(R);oe=l(Z,"To upload you model to an organization you are a member of, just pass it with "),re=s(Z,"CODE",{});var Q=f(re);Y=l(Q,'hub_model_id = "my_organization/my_repo_name"'),Q.forEach(t),be=l(Z,"."),Z.forEach(t)},m(x,U){n(x,u,U),o(u,d),o(u,h),o(h,g),o(u,k),o(u,A),o(A,F),o(u,P),n(x,M,U),z(I,x,U),n(x,D,U),n(x,m,U),o(m,y),o(m,w),o(w,$),o(m,H),o(m,N),o(N,G),o(m,L),o(m,W),o(W,J),o(m,ie),o(m,B),o(B,le),o(m,ye),n(x,te,U),n(x,R,U),o(R,oe),o(R,re),o(re,Y),o(R,be),ae=!0},i(x){ae||(v(I.$$.fragment,x),ae=!0)},o(x){b(I.$$.fragment,x),ae=!1},d(x){x&&t(u),x&&t(M),T(I,x),x&&t(D),x&&t(m),x&&t(te),x&&t(R)}}}function Qm(O){let u,d,h,g,k,A,F,P,M,I,D,m,y,w,$,H,N,G,L,W,J,ie,B,le,ye,te,R,oe,re,Y,be,ae,x,U,ve,X,V,ce,Le,pe,we,Z,Q,pi,et;return y=new q({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments(
    "bert-finetuned-mrpc", save_strategy="epoch", push_to_hub=True
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

training_args = TrainingArguments(
    <span class="hljs-string">&quot;bert-finetuned-mrpc&quot;</span>, save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>, push_to_hub=<span class="hljs-literal">True</span>
)`}}),{c(){u=a("p"),d=i("If you have played around with the "),h=a("code"),g=i("Trainer"),k=i(" API to train a model, the easiest way to upload it to the Hub is to set "),A=a("code"),F=i("push_to_hub=True"),P=i(" when you define your "),M=a("code"),I=i("TrainingArguments"),D=i(":"),m=c(),E(y.$$.fragment),w=c(),$=a("p"),H=i("When you call "),N=a("code"),G=i("trainer.train()"),L=i(", the "),W=a("code"),J=i("Trainer"),ie=i(" will then upload your model to the Hub each time it is saved (here every epoch) in a repository in your namespace. That repository will be named like the output directory you picked (here "),B=a("code"),le=i("bert-finetuned-mrpc"),ye=i(") but you can choose a different name with "),te=a("code"),R=i('hub_model_id = "a_different_name"'),oe=i("."),re=c(),Y=a("p"),be=i("To upload you model to an organization you are a member of, just pass it with "),ae=a("code"),x=i('hub_model_id = "my_organization/my_repo_name"'),U=i("."),ve=c(),X=a("p"),V=i("Once your training is finished, you should do a final "),ce=a("code"),Le=i("trainer.push_to_hub()"),pe=i(" to upload the last version of your model. It will also generate a model card with all the relevant metadata, reporting the hyperparameters used and the evaluation results! Here is an example of the content you might find in a such a model card:"),we=c(),Z=a("div"),Q=a("img"),this.h()},l(C){u=s(C,"P",{});var S=f(u);d=l(S,"If you have played around with the "),h=s(S,"CODE",{});var pt=f(h);g=l(pt,"Trainer"),pt.forEach(t),k=l(S," API to train a model, the easiest way to upload it to the Hub is to set "),A=s(S,"CODE",{});var Se=f(A);F=l(Se,"push_to_hub=True"),Se.forEach(t),P=l(S," when you define your "),M=s(S,"CODE",{});var di=f(M);I=l(di,"TrainingArguments"),di.forEach(t),D=l(S,":"),S.forEach(t),m=p(C),j(y.$$.fragment,C),w=p(C),$=s(C,"P",{});var K=f($);H=l(K,"When you call "),N=s(K,"CODE",{});var mi=f(N);G=l(mi,"trainer.train()"),mi.forEach(t),L=l(K,", the "),W=s(K,"CODE",{});var dt=f(W);J=l(dt,"Trainer"),dt.forEach(t),ie=l(K," will then upload your model to the Hub each time it is saved (here every epoch) in a repository in your namespace. That repository will be named like the output directory you picked (here "),B=s(K,"CODE",{});var _i=f(B);le=l(_i,"bert-finetuned-mrpc"),_i.forEach(t),ye=l(K,") but you can choose a different name with "),te=s(K,"CODE",{});var gi=f(te);R=l(gi,'hub_model_id = "a_different_name"'),gi.forEach(t),oe=l(K,"."),K.forEach(t),re=p(C),Y=s(C,"P",{});var tt=f(Y);be=l(tt,"To upload you model to an organization you are a member of, just pass it with "),ae=s(tt,"CODE",{});var se=f(ae);x=l(se,'hub_model_id = "my_organization/my_repo_name"'),se.forEach(t),U=l(tt,"."),tt.forEach(t),ve=p(C),X=s(C,"P",{});var ee=f(X);V=l(ee,"Once your training is finished, you should do a final "),ce=s(ee,"CODE",{});var ot=f(ce);Le=l(ot,"trainer.push_to_hub()"),ot.forEach(t),pe=l(ee," to upload the last version of your model. It will also generate a model card with all the relevant metadata, reporting the hyperparameters used and the evaluation results! Here is an example of the content you might find in a such a model card:"),ee.forEach(t),we=p(C),Z=s(C,"DIV",{class:!0});var ke=f(Z);Q=s(ke,"IMG",{src:!0,alt:!0,width:!0}),ke.forEach(t),this.h()},h(){Ge(Q.src,pi="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/model_card.png")||_(Q,"src",pi),_(Q,"alt","An example of an auto-generated model card."),_(Q,"width","100%"),_(Z,"class","flex justify-center")},m(C,S){n(C,u,S),o(u,d),o(u,h),o(h,g),o(u,k),o(u,A),o(A,F),o(u,P),o(u,M),o(M,I),o(u,D),n(C,m,S),z(y,C,S),n(C,w,S),n(C,$,S),o($,H),o($,N),o(N,G),o($,L),o($,W),o(W,J),o($,ie),o($,B),o(B,le),o($,ye),o($,te),o(te,R),o($,oe),n(C,re,S),n(C,Y,S),o(Y,be),o(Y,ae),o(ae,x),o(Y,U),n(C,ve,S),n(C,X,S),o(X,V),o(X,ce),o(ce,Le),o(X,pe),n(C,we,S),n(C,Z,S),o(Z,Q),et=!0},i(C){et||(v(y.$$.fragment,C),et=!0)},o(C){b(y.$$.fragment,C),et=!1},d(C){C&&t(u),C&&t(m),T(y,C),C&&t(w),C&&t($),C&&t(re),C&&t(Y),C&&t(ve),C&&t(X),C&&t(we),C&&t(Z)}}}function e_(O){let u,d;return u=new q({props:{code:`from transformers import TFAutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForMaskedLM, AutoTokenizer

checkpoint = <span class="hljs-string">&quot;camembert-base&quot;</span>

model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function t_(O){let u,d;return u=new q({props:{code:`from transformers import AutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM, AutoTokenizer

checkpoint = <span class="hljs-string">&quot;camembert-base&quot;</span>

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function o_(O){let u,d,h;return{c(){u=a("div"),d=a("img"),this.h()},l(g){u=s(g,"DIV",{class:!0});var k=f(u);d=s(k,"IMG",{src:!0,alt:!0,width:!0}),k.forEach(t),this.h()},h(){Ge(d.src,h="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/push_to_hub_dummy_model_tf.png")||_(d,"src",h),_(d,"alt","Dummy model containing both the tokenizer and model files."),_(d,"width","80%"),_(u,"class","flex justify-center")},m(g,k){n(g,u,k),o(u,d)},d(g){g&&t(u)}}}function i_(O){let u,d,h;return{c(){u=a("div"),d=a("img"),this.h()},l(g){u=s(g,"DIV",{class:!0});var k=f(u);d=s(k,"IMG",{src:!0,alt:!0,width:!0}),k.forEach(t),this.h()},h(){Ge(d.src,h="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/push_to_hub_dummy_model.png")||_(d,"src",h),_(d,"alt","Dummy model containing both the tokenizer and model files."),_(d,"width","80%"),_(u,"class","flex justify-center")},m(g,k){n(g,u,k),o(u,d)},d(g){g&&t(u)}}}function l_(O){let u,d,h,g,k,A,F,P,M,I,D;return{c(){u=a("p"),d=i("\u270F\uFE0F "),h=a("strong"),g=i("Try it out!"),k=i(" Take the model and tokenizer associated with the "),A=a("code"),F=i("bert-base-cased"),P=i(" checkpoint and upload them to a repo in your namespace using the "),M=a("code"),I=i("push_to_hub()"),D=i(" method. Double-check that the repo appears properly on your page before deleting it.")},l(m){u=s(m,"P",{});var y=f(u);d=l(y,"\u270F\uFE0F "),h=s(y,"STRONG",{});var w=f(h);g=l(w,"Try it out!"),w.forEach(t),k=l(y," Take the model and tokenizer associated with the "),A=s(y,"CODE",{});var $=f(A);F=l($,"bert-base-cased"),$.forEach(t),P=l(y," checkpoint and upload them to a repo in your namespace using the "),M=s(y,"CODE",{});var H=f(M);I=l(H,"push_to_hub()"),H.forEach(t),D=l(y," method. Double-check that the repo appears properly on your page before deleting it."),y.forEach(t)},m(m,y){n(m,u,y),o(u,d),o(u,h),o(h,g),o(u,k),o(u,A),o(A,F),o(u,P),o(u,M),o(M,I),o(u,D)},d(m){m&&t(u)}}}function r_(O){let u,d;return u=new q({props:{code:`from transformers import TFAutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Do whatever with the model, train it, fine-tune it...

model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForMaskedLM, AutoTokenizer

checkpoint = <span class="hljs-string">&quot;camembert-base&quot;</span>

model = TFAutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

<span class="hljs-comment"># Do whatever with the model, train it, fine-tune it...</span>

model.save_pretrained(<span class="hljs-string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span>)
tokenizer.save_pretrained(<span class="hljs-string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span>)`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function a_(O){let u,d;return u=new q({props:{code:`from transformers import AutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Do whatever with the model, train it, fine-tune it...

model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM, AutoTokenizer

checkpoint = <span class="hljs-string">&quot;camembert-base&quot;</span>

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

<span class="hljs-comment"># Do whatever with the model, train it, fine-tune it...</span>

model.save_pretrained(<span class="hljs-string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span>)
tokenizer.save_pretrained(<span class="hljs-string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span>)`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function s_(O){let u,d,h,g,k,A,F,P,M,I,D;return u=new q({props:{code:"config.json  README.md  sentencepiece.bpe.model  special_tokens_map.json  tf_model.h5  tokenizer_config.json  tokenizer.json",highlighted:"config.json  README.md  sentencepiece.bpe.model  special_tokens_map.json  tf_model.h5  tokenizer_config.json  tokenizer.json"}}),{c(){E(u.$$.fragment),d=c(),h=a("p"),g=i("If you look at the file sizes (for example, with "),k=a("code"),A=i("ls -lh"),F=i("), you should see that the model state dict file ("),P=a("em"),M=i("t5_model.h5"),I=i(") is the only outlier, at more than 400 MB.")},l(m){j(u.$$.fragment,m),d=p(m),h=s(m,"P",{});var y=f(h);g=l(y,"If you look at the file sizes (for example, with "),k=s(y,"CODE",{});var w=f(k);A=l(w,"ls -lh"),w.forEach(t),F=l(y,"), you should see that the model state dict file ("),P=s(y,"EM",{});var $=f(P);M=l($,"t5_model.h5"),$.forEach(t),I=l(y,") is the only outlier, at more than 400 MB."),y.forEach(t)},m(m,y){z(u,m,y),n(m,d,y),n(m,h,y),o(h,g),o(h,k),o(k,A),o(h,F),o(h,P),o(P,M),o(h,I),D=!0},i(m){D||(v(u.$$.fragment,m),D=!0)},o(m){b(u.$$.fragment,m),D=!1},d(m){T(u,m),m&&t(d),m&&t(h)}}}function n_(O){let u,d,h,g,k,A,F,P,M,I,D;return u=new q({props:{code:"config.json  pytorch_model.bin  README.md  sentencepiece.bpe.model  special_tokens_map.json tokenizer_config.json  tokenizer.json",highlighted:"config.json  pytorch_model.bin  README.md  sentencepiece.bpe.model  special_tokens_map.json tokenizer_config.json  tokenizer.json"}}),{c(){E(u.$$.fragment),d=c(),h=a("p"),g=i("If you look at the file sizes (for example, with "),k=a("code"),A=i("ls -lh"),F=i("), you should see that the model state dict file ("),P=a("em"),M=i("pytorch_model.bin"),I=i(") is the only outlier, at more than 400 MB.")},l(m){j(u.$$.fragment,m),d=p(m),h=s(m,"P",{});var y=f(h);g=l(y,"If you look at the file sizes (for example, with "),k=s(y,"CODE",{});var w=f(k);A=l(w,"ls -lh"),w.forEach(t),F=l(y,"), you should see that the model state dict file ("),P=s(y,"EM",{});var $=f(P);M=l($,"pytorch_model.bin"),$.forEach(t),I=l(y,") is the only outlier, at more than 400 MB."),y.forEach(t)},m(m,y){z(u,m,y),n(m,d,y),n(m,h,y),o(h,g),o(h,k),o(k,A),o(h,F),o(h,P),o(P,M),o(h,I),D=!0},i(m){D||(v(u.$$.fragment,m),D=!0)},o(m){b(u.$$.fragment,m),D=!1},d(m){T(u,m),m&&t(d),m&&t(h)}}}function f_(O){let u;return{c(){u=i("\u270F\uFE0F When creating the repository from the web interface, the *.gitattributes* file is automatically set up to consider files with certain extensions, such as *.bin* and *.h5*, as large files, and git-lfs will track them with no necessary setup on your side.")},l(d){u=l(d,"\u270F\uFE0F When creating the repository from the web interface, the *.gitattributes* file is automatically set up to consider files with certain extensions, such as *.bin* and *.h5*, as large files, and git-lfs will track them with no necessary setup on your side.")},m(d,h){n(d,u,h)},d(d){d&&t(u)}}}function h_(O){let u,d;return u=new q({props:{code:`On branch main
Your branch is up to date with 'origin/main'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
  modified:   .gitattributes
  	new file:   config.json
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tf_model.h5
	new file:   tokenizer.json
	new file:   tokenizer_config.json`,highlighted:`On branch main
Your branch is up to <span class="hljs-built_in">date</span> with <span class="hljs-string">&#x27;origin/main&#x27;</span>.

Changes to be committed:
  (use <span class="hljs-string">&quot;git restore --staged &lt;file&gt;...&quot;</span> to unstage)
  modified:   .gitattributes
  	new file:   config.json
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tf_model.h5
	new file:   tokenizer.json
	new file:   tokenizer_config.json`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function u_(O){let u,d;return u=new q({props:{code:`On branch main
Your branch is up to date with 'origin/main'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
  modified:   .gitattributes
	new file:   config.json
	new file:   pytorch_model.bin
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tokenizer.json
	new file:   tokenizer_config.json`,highlighted:`On branch main
Your branch is up to <span class="hljs-built_in">date</span> with <span class="hljs-string">&#x27;origin/main&#x27;</span>.

Changes to be committed:
  (use <span class="hljs-string">&quot;git restore --staged &lt;file&gt;...&quot;</span> to unstage)
  modified:   .gitattributes
	new file:   config.json
	new file:   pytorch_model.bin
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tokenizer.json
	new file:   tokenizer_config.json`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function c_(O){let u,d,h,g,k,A,F,P,M,I,D,m,y,w;return u=new q({props:{code:`On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tf_model.h5 (LFS: 86fce29)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged for commit:

`,highlighted:`On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tf_model.h5 (LFS: 86fce29)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged <span class="hljs-keyword">for</span> commit:

`}}),{c(){E(u.$$.fragment),d=c(),h=a("p"),g=i("We can see that all files have "),k=a("code"),A=i("Git"),F=i(" as a handler, except "),P=a("em"),M=i("t5_model.h5"),I=i(", which has "),D=a("code"),m=i("LFS"),y=i(". Great!")},l($){j(u.$$.fragment,$),d=p($),h=s($,"P",{});var H=f(h);g=l(H,"We can see that all files have "),k=s(H,"CODE",{});var N=f(k);A=l(N,"Git"),N.forEach(t),F=l(H," as a handler, except "),P=s(H,"EM",{});var G=f(P);M=l(G,"t5_model.h5"),G.forEach(t),I=l(H,", which has "),D=s(H,"CODE",{});var L=f(D);m=l(L,"LFS"),L.forEach(t),y=l(H,". Great!"),H.forEach(t)},m($,H){z(u,$,H),n($,d,H),n($,h,H),o(h,g),o(h,k),o(k,A),o(h,F),o(h,P),o(P,M),o(h,I),o(h,D),o(D,m),o(h,y),w=!0},i($){w||(v(u.$$.fragment,$),w=!0)},o($){b(u.$$.fragment,$),w=!1},d($){T(u,$),$&&t(d),$&&t(h)}}}function p_(O){let u,d,h,g,k,A,F,P,M,I,D,m,y,w,$,H,N;return u=new q({props:{code:`On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	pytorch_model.bin (LFS: 35686c2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged for commit:

`,highlighted:`On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	pytorch_model.bin (LFS: 35686c2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged <span class="hljs-keyword">for</span> commit:

`}}),{c(){E(u.$$.fragment),d=c(),h=a("p"),g=i("We can see that all files have "),k=a("code"),A=i("Git"),F=i(" as a handler, except "),P=a("em"),M=i("pytorch_model.bin"),I=i(" and "),D=a("em"),m=i("sentencepiece.bpe.model"),y=i(", which have "),w=a("code"),$=i("LFS"),H=i(". Great!")},l(G){j(u.$$.fragment,G),d=p(G),h=s(G,"P",{});var L=f(h);g=l(L,"We can see that all files have "),k=s(L,"CODE",{});var W=f(k);A=l(W,"Git"),W.forEach(t),F=l(L," as a handler, except "),P=s(L,"EM",{});var J=f(P);M=l(J,"pytorch_model.bin"),J.forEach(t),I=l(L," and "),D=s(L,"EM",{});var ie=f(D);m=l(ie,"sentencepiece.bpe.model"),ie.forEach(t),y=l(L,", which have "),w=s(L,"CODE",{});var B=f(w);$=l(B,"LFS"),B.forEach(t),H=l(L,". Great!"),L.forEach(t)},m(G,L){z(u,G,L),n(G,d,L),n(G,h,L),o(h,g),o(h,k),o(k,A),o(h,F),o(h,P),o(P,M),o(h,I),o(h,D),o(D,m),o(h,y),o(h,w),o(w,$),o(h,H),N=!0},i(G){N||(v(u.$$.fragment,G),N=!0)},o(G){b(u.$$.fragment,G),N=!1},d(G){T(u,G),G&&t(d),G&&t(h)}}}function d_(O){let u,d;return u=new q({props:{code:`[main b08aab1] First model version
 6 files changed, 36 insertions(+)
 create mode 100644 config.json
 create mode 100644 sentencepiece.bpe.model
 create mode 100644 special_tokens_map.json
 create mode 100644 tf_model.h5
 create mode 100644 tokenizer.json
 create mode 100644 tokenizer_config.json`,highlighted:`[main b08aab1] First model version
 6 files changed, 36 insertions(+)
 create mode 100644 config.json
 create mode 100644 sentencepiece.bpe.model
 create mode 100644 special_tokens_map.json
 create mode 100644 tf_model.h5
 create mode 100644 tokenizer.json
 create mode 100644 tokenizer_config.json`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function m_(O){let u,d;return u=new q({props:{code:`[main b08aab1] First model version
 7 files changed, 29027 insertions(+)
  6 files changed, 36 insertions(+)
 create mode 100644 config.json
 create mode 100644 pytorch_model.bin
 create mode 100644 sentencepiece.bpe.model
 create mode 100644 special_tokens_map.json
 create mode 100644 tokenizer.json
 create mode 100644 tokenizer_config.json`,highlighted:`[main b08aab1] First model version
 7 files changed, 29027 insertions(+)
  6 files changed, 36 insertions(+)
 create mode 100644 config.json
 create mode 100644 pytorch_model.bin
 create mode 100644 sentencepiece.bpe.model
 create mode 100644 special_tokens_map.json
 create mode 100644 tokenizer.json
 create mode 100644 tokenizer_config.json`}}),{c(){E(u.$$.fragment)},l(h){j(u.$$.fragment,h)},m(h,g){z(u,h,g),d=!0},i(h){d||(v(u.$$.fragment,h),d=!0)},o(h){b(u.$$.fragment,h),d=!1},d(h){T(u,h)}}}function __(O){let u,d,h,g,k,A,F,P,M,I,D;return{c(){u=i(`If we take a look at the model repository when this is finished, we can see all the recently added files:
`),d=a("div"),h=a("img"),k=c(),A=a("p"),F=i("The UI allows you to explore the model files and commits and to see the diff introduced by each commit:"),P=c(),M=a("div"),I=a("img"),this.h()},l(m){u=l(m,`If we take a look at the model repository when this is finished, we can see all the recently added files:
`),d=s(m,"DIV",{class:!0});var y=f(d);h=s(y,"IMG",{src:!0,alt:!0,width:!0}),y.forEach(t),k=p(m),A=s(m,"P",{});var w=f(A);F=l(w,"The UI allows you to explore the model files and commits and to see the diff introduced by each commit:"),w.forEach(t),P=p(m),M=s(m,"DIV",{class:!0});var $=f(M);I=s($,"IMG",{src:!0,alt:!0,width:!0}),$.forEach(t),this.h()},h(){Ge(h.src,g="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/full_model_tf.png")||_(h,"src",g),_(h,"alt","The 'Files and versions' tab now contains all the recently uploaded files."),_(h,"width","80%"),_(d,"class","flex justify-center"),Ge(I.src,D="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/diffstf.gif")||_(I,"src",D),_(I,"alt","The diff introduced by the recent commit."),_(I,"width","80%"),_(M,"class","flex justify-center")},m(m,y){n(m,u,y),n(m,d,y),o(d,h),n(m,k,y),n(m,A,y),o(A,F),n(m,P,y),n(m,M,y),o(M,I)},d(m){m&&t(u),m&&t(d),m&&t(k),m&&t(A),m&&t(P),m&&t(M)}}}function g_(O){let u,d,h,g,k,A,F,P,M,I,D,m,y;return{c(){u=a("p"),d=i("If we take a look at the model repository when this is finished, we can see all the recently added files:"),h=c(),g=a("div"),k=a("img"),F=c(),P=a("p"),M=i("The UI allows you to explore the model files and commits and to see the diff introduced by each commit:"),I=c(),D=a("div"),m=a("img"),this.h()},l(w){u=s(w,"P",{});var $=f(u);d=l($,"If we take a look at the model repository when this is finished, we can see all the recently added files:"),$.forEach(t),h=p(w),g=s(w,"DIV",{class:!0});var H=f(g);k=s(H,"IMG",{src:!0,alt:!0,width:!0}),H.forEach(t),F=p(w),P=s(w,"P",{});var N=f(P);M=l(N,"The UI allows you to explore the model files and commits and to see the diff introduced by each commit:"),N.forEach(t),I=p(w),D=s(w,"DIV",{class:!0});var G=f(D);m=s(G,"IMG",{src:!0,alt:!0,width:!0}),G.forEach(t),this.h()},h(){Ge(k.src,A="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/full_model.png")||_(k,"src",A),_(k,"alt","The 'Files and versions' tab now contains all the recently uploaded files."),_(k,"width","80%"),_(g,"class","flex justify-center"),Ge(m.src,y="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/diffs.gif")||_(m,"src",y),_(m,"alt","The diff introduced by the recent commit."),_(m,"width","80%"),_(D,"class","flex justify-center")},m(w,$){n(w,u,$),o(u,d),n(w,h,$),n(w,g,$),o(g,k),n(w,F,$),n(w,P,$),o(P,M),n(w,I,$),n(w,D,$),o(D,m)},d(w){w&&t(u),w&&t(h),w&&t(g),w&&t(F),w&&t(P),w&&t(I),w&&t(D)}}}function y_(O){let u,d,h,g,k,A,F,P,M,I,D,m,y,w,$,H,N,G,L,W,J,ie,B,le,ye,te,R,oe,re,Y,be,ae,x,U,ve,X,V,ce,Le,pe,we,Z,Q,pi,et,C,S,pt,Se,di,K,mi,dt,_i,gi,tt,se,ee,ot,ke,Pn,bl,An,On,Ur,de,In,vl,Dn,Cn,wl,Mn,qn,yi,Fn,Hn,Rr,Qt,Wr,bi,xn,Br,eo,Yr,mt,Gn,to,Ln,Sn,Vr,vi,Nn,Kr,$e,Ee,wi,_t,Un,kl,Rn,Wn,Jr,ki,Bn,Xr,je,ze,$i,Ne,Yn,$l,Vn,Kn,El,Jn,Xn,Zr,oo,Qr,gt,Zn,jl,Qn,ef,ea,io,ta,yt,tf,zl,of,lf,oa,lo,ia,bt,rf,Tl,af,sf,la,ro,ra,vt,nf,Pl,ao,ff,hf,aa,Ei,uf,sa,ji,wt,na,Ue,cf,Al,pf,df,so,mf,_f,fa,me,gf,Ol,yf,bf,no,Il,vf,wf,fo,Dl,kf,$f,ha,zi,Ef,ua,it,kt,Cl,ho,jf,uo,zf,Ml,Tf,Pf,ca,$t,Af,ql,Of,If,pa,_e,Df,Fl,Cf,Mf,Hl,qf,Ff,xl,Hf,xf,da,co,ma,Et,Gf,Gl,Lf,Sf,_a,po,ga,jt,Nf,Ll,Uf,Rf,ya,zt,Wf,Sl,Bf,Yf,ba,mo,va,Re,Vf,Nl,Kf,Jf,Ul,Xf,Zf,wa,_o,ka,We,Qf,Rl,eh,th,Wl,oh,ih,$a,Be,Ti,Bl,lh,rh,ah,Pi,Yl,sh,nh,fh,ne,Vl,hh,uh,Kl,ch,ph,Jl,dh,mh,Xl,_h,gh,Zl,yh,bh,Ea,Ai,vh,ja,lt,Tt,Ql,go,wh,er,kh,za,Oi,$h,Ta,Pt,Eh,yo,jh,zh,Pa,bo,vo,Vc,Aa,Ii,Th,Oa,Di,Ph,Ia,Ci,Ah,Da,wo,ko,Kc,Ca,Mi,Oh,Ma,$o,Eo,Jc,qa,qi,Ih,Fa,Ye,Dh,tr,Ch,Mh,or,qh,Fh,Ha,jo,zo,Xc,xa,Fi,Hh,Ga,rt,At,ir,To,xh,lr,Gh,La,Ot,Lh,Po,Sh,Nh,Sa,It,Uh,rr,Rh,Wh,Na,at,Dt,ar,Ao,Bh,Oo,Yh,sr,Vh,Kh,Ua,Ct,Jh,nr,Xh,Zh,Ra,Hi,Qh,Wa,Io,Ba,fe,eu,fr,tu,ou,hr,iu,lu,ur,ru,au,cr,su,nu,Ya,Mt,xi,pr,fu,hu,uu,he,dr,cu,pu,mr,du,mu,_r,_u,gu,gr,yu,bu,yr,vu,wu,Va,st,qt,br,Do,ku,Co,$u,vr,Eu,ju,Ka,Ft,zu,wr,Tu,Pu,Ja,Ht,Au,Mo,Ou,Iu,Xa,Gi,Du,Za,qo,Qa,ge,Cu,kr,Mu,qu,$r,Fu,Hu,Er,xu,Gu,es,Li,Lu,ts,Fo,os,Ve,Su,jr,Nu,Uu,Ho,Ru,Wu,is,Si,Bu,ls,Ni,Yu,rs,xo,as,Ui,Vu,ss,Go,ns,xt,Ku,zr,Ju,Xu,fs,Lo,hs,Ri,Zu,us,nt,Gt,Tr,So,Qu,Pr,ec,cs,Wi,tc,ps,Lt,oc,No,ic,lc,ds,Bi,rc,ms,Uo,_s,Ro,gs,Yi,ac,ys,Wo,bs,Ke,sc,Ar,nc,fc,Or,hc,uc,vs,Bo,ws,Je,cc,Ir,pc,dc,Dr,mc,_c,ks,Yo,$s,Vo,Es,ue,gc,Cr,yc,bc,Mr,vc,wc,qr,kc,$c,Fr,Ec,jc,js,St,zc,Hr,Tc,Pc,zs,Vi,Ac,Ts,Te,Pe,Ki,Nt,Oc,xr,Ic,Dc,Ps,Ko,As,Ae,Oe,Ji,Ut,Os,Rt,Cc,Gr,Mc,qc,Is,Jo,Ds,Xi,Fc,Cs,Xo,Ms,Ie,De,Zi,Wt,Hc,Lr,xc,Gc,qs,Zo,Fs,Ce,Me,Qi,Bt,Lc,Sr,Sc,Nc,Hs,Qo,xs,qe,Fe,el,tl,Uc,Gs,ei,Ls,ti,Ss,ol,Ns;h=new Ym({props:{fw:O[0]}}),P=new Zt({});const Zc=[Km,Vm],oi=[];function Qc(e,r){return e[0]==="pt"?0:1}y=Qc(O),w=oi[y]=Zc[y](O),L=new Yc({props:{id:"9yY3RB_GSPM"}}),Se=new Zt({});const ep=[Xm,Jm],ii=[];function tp(e,r){return e[0]==="pt"?0:1}se=tp(O),ee=ii[se]=ep[se](O),Qt=new q({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),eo=new q({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}});const op=[Qm,Zm],li=[];function ip(e,r){return e[0]==="pt"?0:1}$e=ip(O),Ee=li[$e]=op[$e](O);const lp=[t_,e_],ri=[];function rp(e,r){return e[0]==="pt"?0:1}je=rp(O),ze=ri[je]=lp[je](O),oo=new q({props:{code:'model.push_to_hub("dummy-model")',highlighted:'model.push_to_hub(<span class="hljs-string">&quot;dummy-model&quot;</span>)'}}),io=new q({props:{code:'tokenizer.push_to_hub("dummy-model")',highlighted:'tokenizer.push_to_hub(<span class="hljs-string">&quot;dummy-model&quot;</span>)'}}),lo=new q({props:{code:'tokenizer.push_to_hub("dummy-model", organization="huggingface")',highlighted:'tokenizer.push_to_hub(<span class="hljs-string">&quot;dummy-model&quot;</span>, organization=<span class="hljs-string">&quot;huggingface&quot;</span>)'}}),ro=new q({props:{code:'tokenizer.push_to_hub("dummy-model", organization="huggingface", use_auth_token="<TOKEN>")',highlighted:'tokenizer.push_to_hub(<span class="hljs-string">&quot;dummy-model&quot;</span>, organization=<span class="hljs-string">&quot;huggingface&quot;</span>, use_auth_token=<span class="hljs-string">&quot;&lt;TOKEN&gt;&quot;</span>)'}});function ap(e,r){return e[0]==="pt"?i_:o_}let Us=ap(O),ft=Us(O);wt=new Lm({props:{$$slots:{default:[l_]},$$scope:{ctx:O}}}),ho=new Zt({}),co=new q({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),po=new q({props:{code:`from huggingface_hub import (
    # User management
    login,
    logout,
    whoami,

    # Repository creation and management
    create_repo,
    delete_repo,
    update_repo_visibility,

    # And some methods to retrieve/change information about the content
    list_models,
    list_datasets,
    list_metrics,
    list_repo_files,
    upload_file,
    delete_file,
)`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> (
    <span class="hljs-comment"># User management</span>
    login,
    logout,
    whoami,

    <span class="hljs-comment"># Repository creation and management</span>
    create_repo,
    delete_repo,
    update_repo_visibility,

    <span class="hljs-comment"># And some methods to retrieve/change information about the content</span>
    list_models,
    list_datasets,
    list_metrics,
    list_repo_files,
    upload_file,
    delete_file,
)`}}),mo=new q({props:{code:`from huggingface_hub import create_repo

create_repo("dummy-model")`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> create_repo

create_repo(<span class="hljs-string">&quot;dummy-model&quot;</span>)`}}),_o=new q({props:{code:`from huggingface_hub import create_repo

create_repo("dummy-model", organization="huggingface")`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> create_repo

create_repo(<span class="hljs-string">&quot;dummy-model&quot;</span>, organization=<span class="hljs-string">&quot;huggingface&quot;</span>)`}}),go=new Zt({}),To=new Zt({}),Ao=new Zt({}),Io=new q({props:{code:`from huggingface_hub import upload_file

upload_file(
    "<path_to_file>/config.json",
    path_in_repo="config.json",
    repo_id="<namespace>/dummy-model",
)`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> upload_file

upload_file(
    <span class="hljs-string">&quot;&lt;path_to_file&gt;/config.json&quot;</span>,
    path_in_repo=<span class="hljs-string">&quot;config.json&quot;</span>,
    repo_id=<span class="hljs-string">&quot;&lt;namespace&gt;/dummy-model&quot;</span>,
)`}}),Do=new Zt({}),qo=new q({props:{code:`from huggingface_hub import Repository

repo = Repository("<path_to_dummy_folder>", clone_from="<namespace>/dummy-model")`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository

repo = Repository(<span class="hljs-string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span>, clone_from=<span class="hljs-string">&quot;&lt;namespace&gt;/dummy-model&quot;</span>)`}}),Fo=new q({props:{code:`repo.git_pull()
repo.git_add()
repo.git_commit()
repo.git_push()
repo.git_tag()`,highlighted:`repo.git_pull()
repo.git_add()
repo.git_commit()
repo.git_push()
repo.git_tag()`}}),xo=new q({props:{code:"repo.git_pull()",highlighted:"repo.git_pull()"}}),Go=new q({props:{code:`model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")`,highlighted:`model.save_pretrained(<span class="hljs-string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span>)
tokenizer.save_pretrained(<span class="hljs-string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span>)`}}),Lo=new q({props:{code:`repo.git_add()
repo.git_commit("Add model and tokenizer files")
repo.git_push()`,highlighted:`repo.git_add()
repo.git_commit(<span class="hljs-string">&quot;Add model and tokenizer files&quot;</span>)
repo.git_push()`}}),So=new Zt({}),Uo=new q({props:{code:"git lfs install",highlighted:"git lfs install"}}),Ro=new q({props:{code:`Updated git hooks.
Git LFS initialized.`,highlighted:`Updated git hooks.
Git LFS initialized.`}}),Wo=new q({props:{code:"git clone https://huggingface.co/<namespace>/<your-model-id>",highlighted:'git <span class="hljs-built_in">clone</span> https://huggingface.co/&lt;namespace&gt;/&lt;your-model-id&gt;'}}),Bo=new q({props:{code:"git clone https://huggingface.co/lysandre/dummy",highlighted:'git clone https:<span class="hljs-regexp">//</span>huggingface.co<span class="hljs-regexp">/lysandre/</span>dummy'}}),Yo=new q({props:{code:"cd dummy && ls",highlighted:'<span class="hljs-built_in">cd</span> dummy &amp;&amp; <span class="hljs-built_in">ls</span>'}}),Vo=new q({props:{code:"README.md",highlighted:"README.md"}});const sp=[a_,r_],ai=[];function np(e,r){return e[0]==="pt"?0:1}Te=np(O),Pe=ai[Te]=sp[Te](O),Ko=new q({props:{code:"ls",highlighted:'<span class="hljs-built_in">ls</span>'}});const fp=[n_,s_],si=[];function hp(e,r){return e[0]==="pt"?0:1}Ae=hp(O),Oe=si[Ae]=fp[Ae](O),Ut=new Lm({props:{$$slots:{default:[f_]},$$scope:{ctx:O}}}),Jo=new q({props:{code:"git add .",highlighted:"git add ."}}),Xo=new q({props:{code:"git status",highlighted:"git status"}});const up=[u_,h_],ni=[];function cp(e,r){return e[0]==="pt"?0:1}Ie=cp(O),De=ni[Ie]=up[Ie](O),Zo=new q({props:{code:"git lfs status",highlighted:"git lfs status"}});const pp=[p_,c_],fi=[];function dp(e,r){return e[0]==="pt"?0:1}Ce=dp(O),Me=fi[Ce]=pp[Ce](O),Qo=new q({props:{code:'git commit -m "First model version"',highlighted:'git commit -m <span class="hljs-string">&quot;First model version&quot;</span>'}});const mp=[m_,d_],hi=[];function _p(e,r){return e[0]==="pt"?0:1}qe=_p(O),Fe=hi[qe]=mp[qe](O),ei=new q({props:{code:"git push",highlighted:"git push"}}),ti=new q({props:{code:`Uploading LFS objects: 100% (1/1), 433 MB | 1.3 MB/s, done.
Enumerating objects: 11, done.
Counting objects: 100% (11/11), done.
Delta compression using up to 12 threads
Compressing objects: 100% (9/9), done.
Writing objects: 100% (9/9), 288.27 KiB | 6.27 MiB/s, done.
Total 9 (delta 1), reused 0 (delta 0), pack-reused 0
To https://huggingface.co/lysandre/dummy
   891b41d..b08aab1  main -> main`,highlighted:`Uploading LFS objects: 100% (1/1), 433 MB | 1.3 MB/s, <span class="hljs-keyword">done</span>.
Enumerating objects: 11, <span class="hljs-keyword">done</span>.
Counting objects: 100% (11/11), <span class="hljs-keyword">done</span>.
Delta compression using up to 12 threads
Compressing objects: 100% (9/9), <span class="hljs-keyword">done</span>.
Writing objects: 100% (9/9), 288.27 KiB | 6.27 MiB/s, <span class="hljs-keyword">done</span>.
Total 9 (delta 1), reused 0 (delta 0), pack-reused 0
To https://huggingface.co/lysandre/dummy
   891b41d..b08aab1  main -&gt; main`}});function gp(e,r){return e[0]==="pt"?g_:__}let Rs=gp(O),ht=Rs(O);return{c(){u=a("meta"),d=c(),E(h.$$.fragment),g=c(),k=a("h1"),A=a("a"),F=a("span"),E(P.$$.fragment),M=c(),I=a("span"),D=i("Sharing pretrained models"),m=c(),w.c(),$=c(),H=a("p"),N=i("In the steps below, we\u2019ll take a look at the easiest ways to share pretrained models to the \u{1F917} Hub. There are tools and utilities available that make it simple to share and update models directly on the Hub, which we will explore below."),G=c(),E(L.$$.fragment),W=c(),J=a("p"),ie=i("We encourage all users that train models to contribute by sharing them with the community \u2014 sharing models, even when trained on very specific datasets, will help others, saving them time and compute resources and providing access to useful trained artifacts. In turn, you can benefit from the work that others have done!"),B=c(),le=a("p"),ye=i("There are three ways to go about creating new model repositories:"),te=c(),R=a("ul"),oe=a("li"),re=i("Using the "),Y=a("code"),be=i("push_to_hub"),ae=i(" API"),x=c(),U=a("li"),ve=i("Using the "),X=a("code"),V=i("huggingface_hub"),ce=i(" Python library"),Le=c(),pe=a("li"),we=i("Using the web interface"),Z=c(),Q=a("p"),pi=i("Once you\u2019ve created a repository, you can upload files to it via git and git-lfs. We\u2019ll walk you through creating model repositories and uploading files to them in the following sections."),et=c(),C=a("h2"),S=a("a"),pt=a("span"),E(Se.$$.fragment),di=c(),K=a("span"),mi=i("Using the "),dt=a("code"),_i=i("push_to_hub"),gi=i(" API"),tt=c(),ee.c(),ot=c(),ke=a("p"),Pn=i("The simplest way to upload files to the Hub is by leveraging the "),bl=a("code"),An=i("push_to_hub"),On=i(" API."),Ur=c(),de=a("p"),In=i("Before going further, you\u2019ll need to generate an authentication token so that the "),vl=a("code"),Dn=i("huggingface_hub"),Cn=i(" API knows who you are and what namespaces you have write access to. Make sure you are in an environment where you have "),wl=a("code"),Mn=i("transformers"),qn=i(" installed (see "),yi=a("a"),Fn=i("Setup"),Hn=i("). If you are in a notebook, you can use the following function to login:"),Rr=c(),E(Qt.$$.fragment),Wr=c(),bi=a("p"),xn=i("In a terminal, you can run:"),Br=c(),E(eo.$$.fragment),Yr=c(),mt=a("p"),Gn=i("In both cases, you should be prompted for your username and password, which are the same ones you use to log in to the Hub. If you do not have a Hub profile yet, you should create one "),to=a("a"),Ln=i("here"),Sn=i("."),Vr=c(),vi=a("p"),Nn=i("Great! You now have your authentication token stored in your cache folder. Let\u2019s create some repositories!"),Kr=c(),Ee.c(),wi=c(),_t=a("p"),Un=i("At a lower level, accessing the Model Hub can be done directly on models, tokenizers, and configuration objects via their "),kl=a("code"),Rn=i("push_to_hub()"),Wn=i(" method. This method takes care of both the repository creation and pushing the model and tokenizer files directly to the repository. No manual handling is required, unlike with the API we\u2019ll see below."),Jr=c(),ki=a("p"),Bn=i("To get an idea of how it works, let\u2019s first initialize a model and a tokenizer:"),Xr=c(),ze.c(),$i=c(),Ne=a("p"),Yn=i("You\u2019re free to do whatever you want with these \u2014 add tokens to the tokenizer, train the model, fine-tune it. Once you\u2019re happy with the resulting model, weights, and tokenizer, you can leverage the "),$l=a("code"),Vn=i("push_to_hub()"),Kn=i(" method directly available on the "),El=a("code"),Jn=i("model"),Xn=i(" object:"),Zr=c(),E(oo.$$.fragment),Qr=c(),gt=a("p"),Zn=i("This will create the new repository "),jl=a("code"),Qn=i("dummy-model"),ef=i(` in your profile, and populate it with your model files.
Do the same with the tokenizer, so that all the files are now available in this repository:`),ea=c(),E(io.$$.fragment),ta=c(),yt=a("p"),tf=i("If you belong to an organization, simply specify the "),zl=a("code"),of=i("organization"),lf=i(" argument to upload to that organization\u2019s namespace:"),oa=c(),E(lo.$$.fragment),ia=c(),bt=a("p"),rf=i("If you wish to use a specific Hugging Face token, you\u2019re free to specify it to the "),Tl=a("code"),af=i("push_to_hub()"),sf=i(" method as well:"),la=c(),E(ro.$$.fragment),ra=c(),vt=a("p"),nf=i("Now head to the Model Hub to find your newly uploaded model: "),Pl=a("em"),ao=a("a"),ff=i("https://huggingface.co/user-or-organization/dummy-model"),hf=i("."),aa=c(),Ei=a("p"),uf=i("Click on the \u201CFiles and versions\u201D tab, and you should see the files visible in the following screenshot:"),sa=c(),ft.c(),ji=c(),E(wt.$$.fragment),na=c(),Ue=a("p"),cf=i("As you\u2019ve seen, the "),Al=a("code"),pf=i("push_to_hub()"),df=i(" method accepts several arguments, making it possible to upload to a specific repository or organization namespace, or to use a different API token. We recommend you take a look at the method specification available directly in the "),so=a("a"),mf=i("\u{1F917} Transformers documentation"),_f=i(" to get an idea of what is possible."),fa=c(),me=a("p"),gf=i("The "),Ol=a("code"),yf=i("push_to_hub()"),bf=i(" method is backed by the "),no=a("a"),Il=a("code"),vf=i("huggingface_hub"),wf=i(" Python package, which offers a direct API to the Hugging Face Hub. It\u2019s integrated within \u{1F917} Transformers and several other machine learning libraries, like "),fo=a("a"),Dl=a("code"),kf=i("allenlp"),$f=i(". Although we focus on the \u{1F917} Transformers integration in this chapter, integrating it into your own code or library is simple."),ha=c(),zi=a("p"),Ef=i("Jump to the last section to see how to upload files to your newly created repository!"),ua=c(),it=a("h2"),kt=a("a"),Cl=a("span"),E(ho.$$.fragment),jf=c(),uo=a("span"),zf=i("Using the "),Ml=a("code"),Tf=i("huggingface_hub"),Pf=i(" Python library"),ca=c(),$t=a("p"),Af=i("The "),ql=a("code"),Of=i("huggingface_hub"),If=i(` Python library is a package which offers a set of tools for the model and datasets hubs. It provides simple methods and classes for common tasks like
getting information about repositories on the hub and managing them. It provides simple APIs that work on top of git to manage those repositories\u2019 content and to integrate the Hub
in your projects and libraries.`),pa=c(),_e=a("p"),Df=i("Similarly to using the "),Fl=a("code"),Cf=i("push_to_hub"),Mf=i(" API, this will require you to have your API token saved in your cache. In order to do this, you will need to use the "),Hl=a("code"),qf=i("login"),Ff=i(" command from the CLI, as mentioned in the previous section (again, make sure to prepend these commands with the "),xl=a("code"),Hf=i("!"),xf=i(" character if running in Google Colab):"),da=c(),E(co.$$.fragment),ma=c(),Et=a("p"),Gf=i("The "),Gl=a("code"),Lf=i("huggingface_hub"),Sf=i(" package offers several methods and classes which are useful for our purpose. Firstly, there are a few methods to manage repository creation, deletion, and others:"),_a=c(),E(po.$$.fragment),ga=c(),jt=a("p"),Nf=i("Additionally, it offers the very powerful "),Ll=a("code"),Uf=i("Repository"),Rf=i(" class to manage a local repository. We will explore these methods and that class in the next few section to understand how to leverage them."),ya=c(),zt=a("p"),Wf=i("The "),Sl=a("code"),Bf=i("create_repo"),Yf=i(" method can be used to create a new repository on the hub:"),ba=c(),E(mo.$$.fragment),va=c(),Re=a("p"),Vf=i("This will create the repository "),Nl=a("code"),Kf=i("dummy-model"),Jf=i(" in your namespace. If you like, you can specify which organization the repository should belong to using the "),Ul=a("code"),Xf=i("organization"),Zf=i(" argument:"),wa=c(),E(_o.$$.fragment),ka=c(),We=a("p"),Qf=i("This will create the "),Rl=a("code"),eh=i("dummy-model"),th=i(" repository in the "),Wl=a("code"),oh=i("huggingface"),ih=i(` namespace, assuming you belong to that organization.
Other arguments which may be useful are:`),$a=c(),Be=a("ul"),Ti=a("li"),Bl=a("code"),lh=i("private"),rh=i(", in order to specify if the repository should be visible from others or not."),ah=c(),Pi=a("li"),Yl=a("code"),sh=i("token"),nh=i(", if you would like to override the token stored in your cache by a given token."),fh=c(),ne=a("li"),Vl=a("code"),hh=i("repo_type"),uh=i(", if you would like to create a "),Kl=a("code"),ch=i("dataset"),ph=i(" or a "),Jl=a("code"),dh=i("space"),mh=i(" instead of a model. Accepted values are "),Xl=a("code"),_h=i('"dataset"'),gh=i(" and "),Zl=a("code"),yh=i('"space"'),bh=i("."),Ea=c(),Ai=a("p"),vh=i("Once the repository is created, we should add files to it! Jump to the next section to see the three ways this can be handled."),ja=c(),lt=a("h2"),Tt=a("a"),Ql=a("span"),E(go.$$.fragment),wh=c(),er=a("span"),kh=i("Using the web interface"),za=c(),Oi=a("p"),$h=i("The web interface offers tools to manage repositories directly in the Hub. Using the interface, you can easily create repositories, add files (even large ones!), explore models, visualize diffs, and much more."),Ta=c(),Pt=a("p"),Eh=i("To create a new repository, visit "),yo=a("a"),jh=i("huggingface.co/new"),zh=i(":"),Pa=c(),bo=a("div"),vo=a("img"),Aa=c(),Ii=a("p"),Th=i("First, specify the owner of the repository: this can be either you or any of the organizations you\u2019re affiliated with. If you choose an organization, the model will be featured on the organization\u2019s page and every member of the organization will have the ability to contribute to the repository."),Oa=c(),Di=a("p"),Ph=i("Next, enter your model\u2019s name. This will also be the name of the repository. Finally, you can specify whether you want your model to be public or private. Private models are hidden from public view."),Ia=c(),Ci=a("p"),Ah=i("After creating your model repository, you should see a page like this:"),Da=c(),wo=a("div"),ko=a("img"),Ca=c(),Mi=a("p"),Oh=i("This is where your model will be hosted. To start populating it, you can add a README file directly from the web interface."),Ma=c(),$o=a("div"),Eo=a("img"),qa=c(),qi=a("p"),Ih=i("The README file is in Markdown \u2014 feel free to go wild with it! The third part of this chapter is dedicated to building a model card. These are of prime importance in bringing value to your model, as they\u2019re where you tell others what it can do."),Fa=c(),Ye=a("p"),Dh=i("If you look at the \u201CFiles and versions\u201D tab, you\u2019ll see that there aren\u2019t many files there yet \u2014 just the "),tr=a("em"),Ch=i("README.md"),Mh=i(" you just created and the "),or=a("em"),qh=i(".gitattributes"),Fh=i(" file that keeps track of large files."),Ha=c(),jo=a("div"),zo=a("img"),xa=c(),Fi=a("p"),Hh=i("We\u2019ll take a look at how to add some new files next."),Ga=c(),rt=a("h2"),At=a("a"),ir=a("span"),E(To.$$.fragment),xh=c(),lr=a("span"),Gh=i("Uploading the model files"),La=c(),Ot=a("p"),Lh=i("The system to manage files on the Hugging Face Hub is based on git for regular files, and git-lfs (which stands for "),Po=a("a"),Sh=i("Git Large File Storage"),Nh=i(") for larger files."),Sa=c(),It=a("p"),Uh=i("In the next section, we go over three different ways of uploading files to the Hub: through "),rr=a("code"),Rh=i("huggingface_hub"),Wh=i(" and through git commands."),Na=c(),at=a("h3"),Dt=a("a"),ar=a("span"),E(Ao.$$.fragment),Bh=c(),Oo=a("span"),Yh=i("The "),sr=a("code"),Vh=i("upload_file"),Kh=i(" approach"),Ua=c(),Ct=a("p"),Jh=i("Using "),nr=a("code"),Xh=i("upload_file"),Zh=i(` does not require git and git-lfs to be installed on your system. It pushes files directly to the \u{1F917} Hub using HTTP POST requests. A limitation of this approach is that it doesn\u2019t handle files that are larger than 5GB in size.
If your files are larger than 5GB, please follow the two other methods detailed below.`),Ra=c(),Hi=a("p"),Qh=i("The API may be used as follows:"),Wa=c(),E(Io.$$.fragment),Ba=c(),fe=a("p"),eu=i("This will upload the file "),fr=a("code"),tu=i("config.json"),ou=i(" available at "),hr=a("code"),iu=i("<path_to_file>"),lu=i(" to the root of the repository as "),ur=a("code"),ru=i("config.json"),au=i(", to the "),cr=a("code"),su=i("dummy-model"),nu=i(` repository.
Other arguments which may be useful are:`),Ya=c(),Mt=a("ul"),xi=a("li"),pr=a("code"),fu=i("token"),hu=i(", if you would like to override the token stored in your cache by a given token."),uu=c(),he=a("li"),dr=a("code"),cu=i("repo_type"),pu=i(", if you would like to upload to a "),mr=a("code"),du=i("dataset"),mu=i(" or a "),_r=a("code"),_u=i("space"),gu=i(" instead of a model. Accepted values are "),gr=a("code"),yu=i('"dataset"'),bu=i(" and "),yr=a("code"),vu=i('"space"'),wu=i("."),Va=c(),st=a("h3"),qt=a("a"),br=a("span"),E(Do.$$.fragment),ku=c(),Co=a("span"),$u=i("The "),vr=a("code"),Eu=i("Repository"),ju=i(" class"),Ka=c(),Ft=a("p"),zu=i("The "),wr=a("code"),Tu=i("Repository"),Pu=i(" class manages a local repository in a git-like manner. It abstracts most of the pain points one may have with git to provide all features that we require."),Ja=c(),Ht=a("p"),Au=i("Using this class requires having git and git-lfs installed, so make sure you have git-lfs installed (see "),Mo=a("a"),Ou=i("here"),Iu=i(" for installation instructions) and set up before you begin."),Xa=c(),Gi=a("p"),Du=i("In order to start playing around with the repository we have just created, we can start by initialising it into a local folder by cloning the remote repository:"),Za=c(),E(qo.$$.fragment),Qa=c(),ge=a("p"),Cu=i("This created the folder "),kr=a("code"),Mu=i("<path_to_dummy_folder>"),qu=i(" in our working directory. This folder only contains the "),$r=a("code"),Fu=i(".gitattributes"),Hu=i(" file as that\u2019s the only file created when instantiating the repository through "),Er=a("code"),xu=i("create_repo"),Gu=i("."),es=c(),Li=a("p"),Lu=i("From this point on, we may leverage several of the traditional git methods:"),ts=c(),E(Fo.$$.fragment),os=c(),Ve=a("p"),Su=i("And others! We recommend taking a look at the "),jr=a("code"),Nu=i("Repository"),Uu=i(" documentation available "),Ho=a("a"),Ru=i("here"),Wu=i(" for an overview of all available methods."),is=c(),Si=a("p"),Bu=i("At present, we have a model and a tokenizer that we would like to push to the hub. We have successfully cloned the repository, we can therefore save the files within that repository."),ls=c(),Ni=a("p"),Yu=i("We first make sure that our local clone is up to date by pulling the latest changes:"),rs=c(),E(xo.$$.fragment),as=c(),Ui=a("p"),Vu=i("Once that is done, we save the model and tokenizer files:"),ss=c(),E(Go.$$.fragment),ns=c(),xt=a("p"),Ku=i("The "),zr=a("code"),Ju=i("<path_to_dummy_folder>"),Xu=i(" now contains all the model and tokenizer files. We follow the usual git workflow by adding files to the staging area, committing them and pushing them to the hub:"),fs=c(),E(Lo.$$.fragment),hs=c(),Ri=a("p"),Zu=i("Congratulations! You just pushed your first files on the hub."),us=c(),nt=a("h3"),Gt=a("a"),Tr=a("span"),E(So.$$.fragment),Qu=c(),Pr=a("span"),ec=i("The git-based approach"),cs=c(),Wi=a("p"),tc=i("This is the very barebones approach to uploading files: we\u2019ll do so with git and git-lfs directly. Most of the difficulty is abstracted away by previous approaches, but there are a few caveats with the following method so we\u2019ll follow a more complex use-case."),ps=c(),Lt=a("p"),oc=i("Using this class requires having git and git-lfs installed, so make sure you have "),No=a("a"),ic=i("git-lfs"),lc=i(" installed (see here for installation instructions) and set up before you begin."),ds=c(),Bi=a("p"),rc=i("First start by initializing git-lfs:"),ms=c(),E(Uo.$$.fragment),_s=c(),E(Ro.$$.fragment),gs=c(),Yi=a("p"),ac=i("Once that\u2019s done, the first step is to clone your model repository:"),ys=c(),E(Wo.$$.fragment),bs=c(),Ke=a("p"),sc=i("My username is "),Ar=a("code"),nc=i("lysandre"),fc=i(" and I\u2019ve used the model name "),Or=a("code"),hc=i("dummy"),uc=i(", so for me the command ends up looking like the following:"),vs=c(),E(Bo.$$.fragment),ws=c(),Je=a("p"),cc=i("I now have a folder named "),Ir=a("em"),pc=i("dummy"),dc=i(" in my working directory. I can "),Dr=a("code"),mc=i("cd"),_c=i(" into the folder and have a look at the contents:"),ks=c(),E(Yo.$$.fragment),$s=c(),E(Vo.$$.fragment),Es=c(),ue=a("p"),gc=i("If you just created your repository using Hugging Face Hub\u2019s "),Cr=a("code"),yc=i("create_repo"),bc=i(" method, this folder should only contain a hidden "),Mr=a("code"),vc=i(".gitattributes"),wc=i(" file. If you followed the instructions in the previous section to create a repository using the web interface, the folder should contain a single "),qr=a("em"),kc=i("README.md"),$c=i(" file alongside the hidden "),Fr=a("code"),Ec=i(".gitattributes"),jc=i(" file, as shown here."),js=c(),St=a("p"),zc=i("Adding a regular-sized file, such as a configuration file, a vocabulary file, or basically any file under a few megabytes, is done exactly as one would do it in any git-based system. However, bigger files must be registered through git-lfs in order to push them to "),Hr=a("em"),Tc=i("huggingface.co"),Pc=i("."),zs=c(),Vi=a("p"),Ac=i("Let\u2019s go back to Python for a bit to generate a model and tokenizer that we\u2019d like to commit to our dummy repository:"),Ts=c(),Pe.c(),Ki=c(),Nt=a("p"),Oc=i("Now that we\u2019ve saved some model and tokenizer artifacts, let\u2019s take another look at the "),xr=a("em"),Ic=i("dummy"),Dc=i(" folder:"),Ps=c(),E(Ko.$$.fragment),As=c(),Oe.c(),Ji=c(),E(Ut.$$.fragment),Os=c(),Rt=a("p"),Cc=i("We can now go ahead and proceed like we would usually do with traditional Git repositories. We can add all the files to Git\u2019s staging environment using the "),Gr=a("code"),Mc=i("git add"),qc=i(" command:"),Is=c(),E(Jo.$$.fragment),Ds=c(),Xi=a("p"),Fc=i("We can then have a look at the files that are currently staged:"),Cs=c(),E(Xo.$$.fragment),Ms=c(),De.c(),Zi=c(),Wt=a("p"),Hc=i("Similarly, we can make sure that git-lfs is tracking the correct files by using its "),Lr=a("code"),xc=i("status"),Gc=i(" command:"),qs=c(),E(Zo.$$.fragment),Fs=c(),Me.c(),Qi=c(),Bt=a("p"),Lc=i("Let\u2019s proceed to the final steps, committing and pushing to the "),Sr=a("em"),Sc=i("huggingface.co"),Nc=i(" remote repository:"),Hs=c(),E(Qo.$$.fragment),xs=c(),Fe.c(),el=c(),tl=a("p"),Uc=i("Pushing can take a bit of time, depending on the speed of your internet connection and the size of your files:"),Gs=c(),E(ei.$$.fragment),Ls=c(),E(ti.$$.fragment),Ss=c(),ht.c(),ol=Gm(),this.h()},l(e){const r=Wm('[data-svelte="svelte-1phssyn"]',document.head);u=s(r,"META",{name:!0,content:!0}),r.forEach(t),d=p(e),j(h.$$.fragment,e),g=p(e),k=s(e,"H1",{class:!0});var ui=f(k);A=s(ui,"A",{id:!0,class:!0,href:!0});var il=f(A);F=s(il,"SPAN",{});var ll=f(F);j(P.$$.fragment,ll),ll.forEach(t),il.forEach(t),M=p(ui),I=s(ui,"SPAN",{});var rl=f(I);D=l(rl,"Sharing pretrained models"),rl.forEach(t),ui.forEach(t),m=p(e),w.l(e),$=p(e),H=s(e,"P",{});var al=f(H);N=l(al,"In the steps below, we\u2019ll take a look at the easiest ways to share pretrained models to the \u{1F917} Hub. There are tools and utilities available that make it simple to share and update models directly on the Hub, which we will explore below."),al.forEach(t),G=p(e),j(L.$$.fragment,e),W=p(e),J=s(e,"P",{});var Nr=f(J);ie=l(Nr,"We encourage all users that train models to contribute by sharing them with the community \u2014 sharing models, even when trained on very specific datasets, will help others, saving them time and compute resources and providing access to useful trained artifacts. In turn, you can benefit from the work that others have done!"),Nr.forEach(t),B=p(e),le=s(e,"P",{});var sl=f(le);ye=l(sl,"There are three ways to go about creating new model repositories:"),sl.forEach(t),te=p(e),R=s(e,"UL",{});var Xe=f(R);oe=s(Xe,"LI",{});var ci=f(oe);re=l(ci,"Using the "),Y=s(ci,"CODE",{});var nl=f(Y);be=l(nl,"push_to_hub"),nl.forEach(t),ae=l(ci," API"),ci.forEach(t),x=p(Xe),U=s(Xe,"LI",{});var Yt=f(U);ve=l(Yt,"Using the "),X=s(Yt,"CODE",{});var fl=f(X);V=l(fl,"huggingface_hub"),fl.forEach(t),ce=l(Yt," Python library"),Yt.forEach(t),Le=p(Xe),pe=s(Xe,"LI",{});var yp=f(pe);we=l(yp,"Using the web interface"),yp.forEach(t),Xe.forEach(t),Z=p(e),Q=s(e,"P",{});var bp=f(Q);pi=l(bp,"Once you\u2019ve created a repository, you can upload files to it via git and git-lfs. We\u2019ll walk you through creating model repositories and uploading files to them in the following sections."),bp.forEach(t),et=p(e),C=s(e,"H2",{class:!0});var Ws=f(C);S=s(Ws,"A",{id:!0,class:!0,href:!0});var vp=f(S);pt=s(vp,"SPAN",{});var wp=f(pt);j(Se.$$.fragment,wp),wp.forEach(t),vp.forEach(t),di=p(Ws),K=s(Ws,"SPAN",{});var Bs=f(K);mi=l(Bs,"Using the "),dt=s(Bs,"CODE",{});var kp=f(dt);_i=l(kp,"push_to_hub"),kp.forEach(t),gi=l(Bs," API"),Bs.forEach(t),Ws.forEach(t),tt=p(e),ee.l(e),ot=p(e),ke=s(e,"P",{});var Ys=f(ke);Pn=l(Ys,"The simplest way to upload files to the Hub is by leveraging the "),bl=s(Ys,"CODE",{});var $p=f(bl);An=l($p,"push_to_hub"),$p.forEach(t),On=l(Ys," API."),Ys.forEach(t),Ur=p(e),de=s(e,"P",{});var Vt=f(de);In=l(Vt,"Before going further, you\u2019ll need to generate an authentication token so that the "),vl=s(Vt,"CODE",{});var Ep=f(vl);Dn=l(Ep,"huggingface_hub"),Ep.forEach(t),Cn=l(Vt," API knows who you are and what namespaces you have write access to. Make sure you are in an environment where you have "),wl=s(Vt,"CODE",{});var jp=f(wl);Mn=l(jp,"transformers"),jp.forEach(t),qn=l(Vt," installed (see "),yi=s(Vt,"A",{href:!0});var zp=f(yi);Fn=l(zp,"Setup"),zp.forEach(t),Hn=l(Vt,"). If you are in a notebook, you can use the following function to login:"),Vt.forEach(t),Rr=p(e),j(Qt.$$.fragment,e),Wr=p(e),bi=s(e,"P",{});var Tp=f(bi);xn=l(Tp,"In a terminal, you can run:"),Tp.forEach(t),Br=p(e),j(eo.$$.fragment,e),Yr=p(e),mt=s(e,"P",{});var Vs=f(mt);Gn=l(Vs,"In both cases, you should be prompted for your username and password, which are the same ones you use to log in to the Hub. If you do not have a Hub profile yet, you should create one "),to=s(Vs,"A",{href:!0,rel:!0});var Pp=f(to);Ln=l(Pp,"here"),Pp.forEach(t),Sn=l(Vs,"."),Vs.forEach(t),Vr=p(e),vi=s(e,"P",{});var Ap=f(vi);Nn=l(Ap,"Great! You now have your authentication token stored in your cache folder. Let\u2019s create some repositories!"),Ap.forEach(t),Kr=p(e),Ee.l(e),wi=p(e),_t=s(e,"P",{});var Ks=f(_t);Un=l(Ks,"At a lower level, accessing the Model Hub can be done directly on models, tokenizers, and configuration objects via their "),kl=s(Ks,"CODE",{});var Op=f(kl);Rn=l(Op,"push_to_hub()"),Op.forEach(t),Wn=l(Ks," method. This method takes care of both the repository creation and pushing the model and tokenizer files directly to the repository. No manual handling is required, unlike with the API we\u2019ll see below."),Ks.forEach(t),Jr=p(e),ki=s(e,"P",{});var Ip=f(ki);Bn=l(Ip,"To get an idea of how it works, let\u2019s first initialize a model and a tokenizer:"),Ip.forEach(t),Xr=p(e),ze.l(e),$i=p(e),Ne=s(e,"P",{});var hl=f(Ne);Yn=l(hl,"You\u2019re free to do whatever you want with these \u2014 add tokens to the tokenizer, train the model, fine-tune it. Once you\u2019re happy with the resulting model, weights, and tokenizer, you can leverage the "),$l=s(hl,"CODE",{});var Dp=f($l);Vn=l(Dp,"push_to_hub()"),Dp.forEach(t),Kn=l(hl," method directly available on the "),El=s(hl,"CODE",{});var Cp=f(El);Jn=l(Cp,"model"),Cp.forEach(t),Xn=l(hl," object:"),hl.forEach(t),Zr=p(e),j(oo.$$.fragment,e),Qr=p(e),gt=s(e,"P",{});var Js=f(gt);Zn=l(Js,"This will create the new repository "),jl=s(Js,"CODE",{});var Mp=f(jl);Qn=l(Mp,"dummy-model"),Mp.forEach(t),ef=l(Js,` in your profile, and populate it with your model files.
Do the same with the tokenizer, so that all the files are now available in this repository:`),Js.forEach(t),ea=p(e),j(io.$$.fragment,e),ta=p(e),yt=s(e,"P",{});var Xs=f(yt);tf=l(Xs,"If you belong to an organization, simply specify the "),zl=s(Xs,"CODE",{});var qp=f(zl);of=l(qp,"organization"),qp.forEach(t),lf=l(Xs," argument to upload to that organization\u2019s namespace:"),Xs.forEach(t),oa=p(e),j(lo.$$.fragment,e),ia=p(e),bt=s(e,"P",{});var Zs=f(bt);rf=l(Zs,"If you wish to use a specific Hugging Face token, you\u2019re free to specify it to the "),Tl=s(Zs,"CODE",{});var Fp=f(Tl);af=l(Fp,"push_to_hub()"),Fp.forEach(t),sf=l(Zs," method as well:"),Zs.forEach(t),la=p(e),j(ro.$$.fragment,e),ra=p(e),vt=s(e,"P",{});var Qs=f(vt);nf=l(Qs,"Now head to the Model Hub to find your newly uploaded model: "),Pl=s(Qs,"EM",{});var Hp=f(Pl);ao=s(Hp,"A",{href:!0,rel:!0});var xp=f(ao);ff=l(xp,"https://huggingface.co/user-or-organization/dummy-model"),xp.forEach(t),Hp.forEach(t),hf=l(Qs,"."),Qs.forEach(t),aa=p(e),Ei=s(e,"P",{});var Gp=f(Ei);uf=l(Gp,"Click on the \u201CFiles and versions\u201D tab, and you should see the files visible in the following screenshot:"),Gp.forEach(t),sa=p(e),ft.l(e),ji=p(e),j(wt.$$.fragment,e),na=p(e),Ue=s(e,"P",{});var ul=f(Ue);cf=l(ul,"As you\u2019ve seen, the "),Al=s(ul,"CODE",{});var Lp=f(Al);pf=l(Lp,"push_to_hub()"),Lp.forEach(t),df=l(ul," method accepts several arguments, making it possible to upload to a specific repository or organization namespace, or to use a different API token. We recommend you take a look at the method specification available directly in the "),so=s(ul,"A",{href:!0,rel:!0});var Sp=f(so);mf=l(Sp,"\u{1F917} Transformers documentation"),Sp.forEach(t),_f=l(ul," to get an idea of what is possible."),ul.forEach(t),fa=p(e),me=s(e,"P",{});var Kt=f(me);gf=l(Kt,"The "),Ol=s(Kt,"CODE",{});var Np=f(Ol);yf=l(Np,"push_to_hub()"),Np.forEach(t),bf=l(Kt," method is backed by the "),no=s(Kt,"A",{href:!0,rel:!0});var Up=f(no);Il=s(Up,"CODE",{});var Rp=f(Il);vf=l(Rp,"huggingface_hub"),Rp.forEach(t),Up.forEach(t),wf=l(Kt," Python package, which offers a direct API to the Hugging Face Hub. It\u2019s integrated within \u{1F917} Transformers and several other machine learning libraries, like "),fo=s(Kt,"A",{href:!0,rel:!0});var Wp=f(fo);Dl=s(Wp,"CODE",{});var Bp=f(Dl);kf=l(Bp,"allenlp"),Bp.forEach(t),Wp.forEach(t),$f=l(Kt,". Although we focus on the \u{1F917} Transformers integration in this chapter, integrating it into your own code or library is simple."),Kt.forEach(t),ha=p(e),zi=s(e,"P",{});var Yp=f(zi);Ef=l(Yp,"Jump to the last section to see how to upload files to your newly created repository!"),Yp.forEach(t),ua=p(e),it=s(e,"H2",{class:!0});var en=f(it);kt=s(en,"A",{id:!0,class:!0,href:!0});var Vp=f(kt);Cl=s(Vp,"SPAN",{});var Kp=f(Cl);j(ho.$$.fragment,Kp),Kp.forEach(t),Vp.forEach(t),jf=p(en),uo=s(en,"SPAN",{});var tn=f(uo);zf=l(tn,"Using the "),Ml=s(tn,"CODE",{});var Jp=f(Ml);Tf=l(Jp,"huggingface_hub"),Jp.forEach(t),Pf=l(tn," Python library"),tn.forEach(t),en.forEach(t),ca=p(e),$t=s(e,"P",{});var on=f($t);Af=l(on,"The "),ql=s(on,"CODE",{});var Xp=f(ql);Of=l(Xp,"huggingface_hub"),Xp.forEach(t),If=l(on,` Python library is a package which offers a set of tools for the model and datasets hubs. It provides simple methods and classes for common tasks like
getting information about repositories on the hub and managing them. It provides simple APIs that work on top of git to manage those repositories\u2019 content and to integrate the Hub
in your projects and libraries.`),on.forEach(t),pa=p(e),_e=s(e,"P",{});var Jt=f(_e);Df=l(Jt,"Similarly to using the "),Fl=s(Jt,"CODE",{});var Zp=f(Fl);Cf=l(Zp,"push_to_hub"),Zp.forEach(t),Mf=l(Jt," API, this will require you to have your API token saved in your cache. In order to do this, you will need to use the "),Hl=s(Jt,"CODE",{});var Qp=f(Hl);qf=l(Qp,"login"),Qp.forEach(t),Ff=l(Jt," command from the CLI, as mentioned in the previous section (again, make sure to prepend these commands with the "),xl=s(Jt,"CODE",{});var ed=f(xl);Hf=l(ed,"!"),ed.forEach(t),xf=l(Jt," character if running in Google Colab):"),Jt.forEach(t),da=p(e),j(co.$$.fragment,e),ma=p(e),Et=s(e,"P",{});var ln=f(Et);Gf=l(ln,"The "),Gl=s(ln,"CODE",{});var td=f(Gl);Lf=l(td,"huggingface_hub"),td.forEach(t),Sf=l(ln," package offers several methods and classes which are useful for our purpose. Firstly, there are a few methods to manage repository creation, deletion, and others:"),ln.forEach(t),_a=p(e),j(po.$$.fragment,e),ga=p(e),jt=s(e,"P",{});var rn=f(jt);Nf=l(rn,"Additionally, it offers the very powerful "),Ll=s(rn,"CODE",{});var od=f(Ll);Uf=l(od,"Repository"),od.forEach(t),Rf=l(rn," class to manage a local repository. We will explore these methods and that class in the next few section to understand how to leverage them."),rn.forEach(t),ya=p(e),zt=s(e,"P",{});var an=f(zt);Wf=l(an,"The "),Sl=s(an,"CODE",{});var id=f(Sl);Bf=l(id,"create_repo"),id.forEach(t),Yf=l(an," method can be used to create a new repository on the hub:"),an.forEach(t),ba=p(e),j(mo.$$.fragment,e),va=p(e),Re=s(e,"P",{});var cl=f(Re);Vf=l(cl,"This will create the repository "),Nl=s(cl,"CODE",{});var ld=f(Nl);Kf=l(ld,"dummy-model"),ld.forEach(t),Jf=l(cl," in your namespace. If you like, you can specify which organization the repository should belong to using the "),Ul=s(cl,"CODE",{});var rd=f(Ul);Xf=l(rd,"organization"),rd.forEach(t),Zf=l(cl," argument:"),cl.forEach(t),wa=p(e),j(_o.$$.fragment,e),ka=p(e),We=s(e,"P",{});var pl=f(We);Qf=l(pl,"This will create the "),Rl=s(pl,"CODE",{});var ad=f(Rl);eh=l(ad,"dummy-model"),ad.forEach(t),th=l(pl," repository in the "),Wl=s(pl,"CODE",{});var sd=f(Wl);oh=l(sd,"huggingface"),sd.forEach(t),ih=l(pl,` namespace, assuming you belong to that organization.
Other arguments which may be useful are:`),pl.forEach(t),$a=p(e),Be=s(e,"UL",{});var dl=f(Be);Ti=s(dl,"LI",{});var Rc=f(Ti);Bl=s(Rc,"CODE",{});var nd=f(Bl);lh=l(nd,"private"),nd.forEach(t),rh=l(Rc,", in order to specify if the repository should be visible from others or not."),Rc.forEach(t),ah=p(dl),Pi=s(dl,"LI",{});var Wc=f(Pi);Yl=s(Wc,"CODE",{});var fd=f(Yl);sh=l(fd,"token"),fd.forEach(t),nh=l(Wc,", if you would like to override the token stored in your cache by a given token."),Wc.forEach(t),fh=p(dl),ne=s(dl,"LI",{});var He=f(ne);Vl=s(He,"CODE",{});var hd=f(Vl);hh=l(hd,"repo_type"),hd.forEach(t),uh=l(He,", if you would like to create a "),Kl=s(He,"CODE",{});var ud=f(Kl);ch=l(ud,"dataset"),ud.forEach(t),ph=l(He," or a "),Jl=s(He,"CODE",{});var cd=f(Jl);dh=l(cd,"space"),cd.forEach(t),mh=l(He," instead of a model. Accepted values are "),Xl=s(He,"CODE",{});var pd=f(Xl);_h=l(pd,'"dataset"'),pd.forEach(t),gh=l(He," and "),Zl=s(He,"CODE",{});var dd=f(Zl);yh=l(dd,'"space"'),dd.forEach(t),bh=l(He,"."),He.forEach(t),dl.forEach(t),Ea=p(e),Ai=s(e,"P",{});var md=f(Ai);vh=l(md,"Once the repository is created, we should add files to it! Jump to the next section to see the three ways this can be handled."),md.forEach(t),ja=p(e),lt=s(e,"H2",{class:!0});var sn=f(lt);Tt=s(sn,"A",{id:!0,class:!0,href:!0});var _d=f(Tt);Ql=s(_d,"SPAN",{});var gd=f(Ql);j(go.$$.fragment,gd),gd.forEach(t),_d.forEach(t),wh=p(sn),er=s(sn,"SPAN",{});var yd=f(er);kh=l(yd,"Using the web interface"),yd.forEach(t),sn.forEach(t),za=p(e),Oi=s(e,"P",{});var bd=f(Oi);$h=l(bd,"The web interface offers tools to manage repositories directly in the Hub. Using the interface, you can easily create repositories, add files (even large ones!), explore models, visualize diffs, and much more."),bd.forEach(t),Ta=p(e),Pt=s(e,"P",{});var nn=f(Pt);Eh=l(nn,"To create a new repository, visit "),yo=s(nn,"A",{href:!0,rel:!0});var vd=f(yo);jh=l(vd,"huggingface.co/new"),vd.forEach(t),zh=l(nn,":"),nn.forEach(t),Pa=p(e),bo=s(e,"DIV",{class:!0});var wd=f(bo);vo=s(wd,"IMG",{src:!0,alt:!0,width:!0}),wd.forEach(t),Aa=p(e),Ii=s(e,"P",{});var kd=f(Ii);Th=l(kd,"First, specify the owner of the repository: this can be either you or any of the organizations you\u2019re affiliated with. If you choose an organization, the model will be featured on the organization\u2019s page and every member of the organization will have the ability to contribute to the repository."),kd.forEach(t),Oa=p(e),Di=s(e,"P",{});var $d=f(Di);Ph=l($d,"Next, enter your model\u2019s name. This will also be the name of the repository. Finally, you can specify whether you want your model to be public or private. Private models are hidden from public view."),$d.forEach(t),Ia=p(e),Ci=s(e,"P",{});var Ed=f(Ci);Ah=l(Ed,"After creating your model repository, you should see a page like this:"),Ed.forEach(t),Da=p(e),wo=s(e,"DIV",{class:!0});var jd=f(wo);ko=s(jd,"IMG",{src:!0,alt:!0,width:!0}),jd.forEach(t),Ca=p(e),Mi=s(e,"P",{});var zd=f(Mi);Oh=l(zd,"This is where your model will be hosted. To start populating it, you can add a README file directly from the web interface."),zd.forEach(t),Ma=p(e),$o=s(e,"DIV",{class:!0});var Td=f($o);Eo=s(Td,"IMG",{src:!0,alt:!0,width:!0}),Td.forEach(t),qa=p(e),qi=s(e,"P",{});var Pd=f(qi);Ih=l(Pd,"The README file is in Markdown \u2014 feel free to go wild with it! The third part of this chapter is dedicated to building a model card. These are of prime importance in bringing value to your model, as they\u2019re where you tell others what it can do."),Pd.forEach(t),Fa=p(e),Ye=s(e,"P",{});var ml=f(Ye);Dh=l(ml,"If you look at the \u201CFiles and versions\u201D tab, you\u2019ll see that there aren\u2019t many files there yet \u2014 just the "),tr=s(ml,"EM",{});var Ad=f(tr);Ch=l(Ad,"README.md"),Ad.forEach(t),Mh=l(ml," you just created and the "),or=s(ml,"EM",{});var Od=f(or);qh=l(Od,".gitattributes"),Od.forEach(t),Fh=l(ml," file that keeps track of large files."),ml.forEach(t),Ha=p(e),jo=s(e,"DIV",{class:!0});var Id=f(jo);zo=s(Id,"IMG",{src:!0,alt:!0,width:!0}),Id.forEach(t),xa=p(e),Fi=s(e,"P",{});var Dd=f(Fi);Hh=l(Dd,"We\u2019ll take a look at how to add some new files next."),Dd.forEach(t),Ga=p(e),rt=s(e,"H2",{class:!0});var fn=f(rt);At=s(fn,"A",{id:!0,class:!0,href:!0});var Cd=f(At);ir=s(Cd,"SPAN",{});var Md=f(ir);j(To.$$.fragment,Md),Md.forEach(t),Cd.forEach(t),xh=p(fn),lr=s(fn,"SPAN",{});var qd=f(lr);Gh=l(qd,"Uploading the model files"),qd.forEach(t),fn.forEach(t),La=p(e),Ot=s(e,"P",{});var hn=f(Ot);Lh=l(hn,"The system to manage files on the Hugging Face Hub is based on git for regular files, and git-lfs (which stands for "),Po=s(hn,"A",{href:!0,rel:!0});var Fd=f(Po);Sh=l(Fd,"Git Large File Storage"),Fd.forEach(t),Nh=l(hn,") for larger files."),hn.forEach(t),Sa=p(e),It=s(e,"P",{});var un=f(It);Uh=l(un,"In the next section, we go over three different ways of uploading files to the Hub: through "),rr=s(un,"CODE",{});var Hd=f(rr);Rh=l(Hd,"huggingface_hub"),Hd.forEach(t),Wh=l(un," and through git commands."),un.forEach(t),Na=p(e),at=s(e,"H3",{class:!0});var cn=f(at);Dt=s(cn,"A",{id:!0,class:!0,href:!0});var xd=f(Dt);ar=s(xd,"SPAN",{});var Gd=f(ar);j(Ao.$$.fragment,Gd),Gd.forEach(t),xd.forEach(t),Bh=p(cn),Oo=s(cn,"SPAN",{});var pn=f(Oo);Yh=l(pn,"The "),sr=s(pn,"CODE",{});var Ld=f(sr);Vh=l(Ld,"upload_file"),Ld.forEach(t),Kh=l(pn," approach"),pn.forEach(t),cn.forEach(t),Ua=p(e),Ct=s(e,"P",{});var dn=f(Ct);Jh=l(dn,"Using "),nr=s(dn,"CODE",{});var Sd=f(nr);Xh=l(Sd,"upload_file"),Sd.forEach(t),Zh=l(dn,` does not require git and git-lfs to be installed on your system. It pushes files directly to the \u{1F917} Hub using HTTP POST requests. A limitation of this approach is that it doesn\u2019t handle files that are larger than 5GB in size.
If your files are larger than 5GB, please follow the two other methods detailed below.`),dn.forEach(t),Ra=p(e),Hi=s(e,"P",{});var Nd=f(Hi);Qh=l(Nd,"The API may be used as follows:"),Nd.forEach(t),Wa=p(e),j(Io.$$.fragment,e),Ba=p(e),fe=s(e,"P",{});var Ze=f(fe);eu=l(Ze,"This will upload the file "),fr=s(Ze,"CODE",{});var Ud=f(fr);tu=l(Ud,"config.json"),Ud.forEach(t),ou=l(Ze," available at "),hr=s(Ze,"CODE",{});var Rd=f(hr);iu=l(Rd,"<path_to_file>"),Rd.forEach(t),lu=l(Ze," to the root of the repository as "),ur=s(Ze,"CODE",{});var Wd=f(ur);ru=l(Wd,"config.json"),Wd.forEach(t),au=l(Ze,", to the "),cr=s(Ze,"CODE",{});var Bd=f(cr);su=l(Bd,"dummy-model"),Bd.forEach(t),nu=l(Ze,` repository.
Other arguments which may be useful are:`),Ze.forEach(t),Ya=p(e),Mt=s(e,"UL",{});var mn=f(Mt);xi=s(mn,"LI",{});var Bc=f(xi);pr=s(Bc,"CODE",{});var Yd=f(pr);fu=l(Yd,"token"),Yd.forEach(t),hu=l(Bc,", if you would like to override the token stored in your cache by a given token."),Bc.forEach(t),uu=p(mn),he=s(mn,"LI",{});var xe=f(he);dr=s(xe,"CODE",{});var Vd=f(dr);cu=l(Vd,"repo_type"),Vd.forEach(t),pu=l(xe,", if you would like to upload to a "),mr=s(xe,"CODE",{});var Kd=f(mr);du=l(Kd,"dataset"),Kd.forEach(t),mu=l(xe," or a "),_r=s(xe,"CODE",{});var Jd=f(_r);_u=l(Jd,"space"),Jd.forEach(t),gu=l(xe," instead of a model. Accepted values are "),gr=s(xe,"CODE",{});var Xd=f(gr);yu=l(Xd,'"dataset"'),Xd.forEach(t),bu=l(xe," and "),yr=s(xe,"CODE",{});var Zd=f(yr);vu=l(Zd,'"space"'),Zd.forEach(t),wu=l(xe,"."),xe.forEach(t),mn.forEach(t),Va=p(e),st=s(e,"H3",{class:!0});var _n=f(st);qt=s(_n,"A",{id:!0,class:!0,href:!0});var Qd=f(qt);br=s(Qd,"SPAN",{});var em=f(br);j(Do.$$.fragment,em),em.forEach(t),Qd.forEach(t),ku=p(_n),Co=s(_n,"SPAN",{});var gn=f(Co);$u=l(gn,"The "),vr=s(gn,"CODE",{});var tm=f(vr);Eu=l(tm,"Repository"),tm.forEach(t),ju=l(gn," class"),gn.forEach(t),_n.forEach(t),Ka=p(e),Ft=s(e,"P",{});var yn=f(Ft);zu=l(yn,"The "),wr=s(yn,"CODE",{});var om=f(wr);Tu=l(om,"Repository"),om.forEach(t),Pu=l(yn," class manages a local repository in a git-like manner. It abstracts most of the pain points one may have with git to provide all features that we require."),yn.forEach(t),Ja=p(e),Ht=s(e,"P",{});var bn=f(Ht);Au=l(bn,"Using this class requires having git and git-lfs installed, so make sure you have git-lfs installed (see "),Mo=s(bn,"A",{href:!0,rel:!0});var im=f(Mo);Ou=l(im,"here"),im.forEach(t),Iu=l(bn," for installation instructions) and set up before you begin."),bn.forEach(t),Xa=p(e),Gi=s(e,"P",{});var lm=f(Gi);Du=l(lm,"In order to start playing around with the repository we have just created, we can start by initialising it into a local folder by cloning the remote repository:"),lm.forEach(t),Za=p(e),j(qo.$$.fragment,e),Qa=p(e),ge=s(e,"P",{});var Xt=f(ge);Cu=l(Xt,"This created the folder "),kr=s(Xt,"CODE",{});var rm=f(kr);Mu=l(rm,"<path_to_dummy_folder>"),rm.forEach(t),qu=l(Xt," in our working directory. This folder only contains the "),$r=s(Xt,"CODE",{});var am=f($r);Fu=l(am,".gitattributes"),am.forEach(t),Hu=l(Xt," file as that\u2019s the only file created when instantiating the repository through "),Er=s(Xt,"CODE",{});var sm=f(Er);xu=l(sm,"create_repo"),sm.forEach(t),Gu=l(Xt,"."),Xt.forEach(t),es=p(e),Li=s(e,"P",{});var nm=f(Li);Lu=l(nm,"From this point on, we may leverage several of the traditional git methods:"),nm.forEach(t),ts=p(e),j(Fo.$$.fragment,e),os=p(e),Ve=s(e,"P",{});var _l=f(Ve);Su=l(_l,"And others! We recommend taking a look at the "),jr=s(_l,"CODE",{});var fm=f(jr);Nu=l(fm,"Repository"),fm.forEach(t),Uu=l(_l," documentation available "),Ho=s(_l,"A",{href:!0,rel:!0});var hm=f(Ho);Ru=l(hm,"here"),hm.forEach(t),Wu=l(_l," for an overview of all available methods."),_l.forEach(t),is=p(e),Si=s(e,"P",{});var um=f(Si);Bu=l(um,"At present, we have a model and a tokenizer that we would like to push to the hub. We have successfully cloned the repository, we can therefore save the files within that repository."),um.forEach(t),ls=p(e),Ni=s(e,"P",{});var cm=f(Ni);Yu=l(cm,"We first make sure that our local clone is up to date by pulling the latest changes:"),cm.forEach(t),rs=p(e),j(xo.$$.fragment,e),as=p(e),Ui=s(e,"P",{});var pm=f(Ui);Vu=l(pm,"Once that is done, we save the model and tokenizer files:"),pm.forEach(t),ss=p(e),j(Go.$$.fragment,e),ns=p(e),xt=s(e,"P",{});var vn=f(xt);Ku=l(vn,"The "),zr=s(vn,"CODE",{});var dm=f(zr);Ju=l(dm,"<path_to_dummy_folder>"),dm.forEach(t),Xu=l(vn," now contains all the model and tokenizer files. We follow the usual git workflow by adding files to the staging area, committing them and pushing them to the hub:"),vn.forEach(t),fs=p(e),j(Lo.$$.fragment,e),hs=p(e),Ri=s(e,"P",{});var mm=f(Ri);Zu=l(mm,"Congratulations! You just pushed your first files on the hub."),mm.forEach(t),us=p(e),nt=s(e,"H3",{class:!0});var wn=f(nt);Gt=s(wn,"A",{id:!0,class:!0,href:!0});var _m=f(Gt);Tr=s(_m,"SPAN",{});var gm=f(Tr);j(So.$$.fragment,gm),gm.forEach(t),_m.forEach(t),Qu=p(wn),Pr=s(wn,"SPAN",{});var ym=f(Pr);ec=l(ym,"The git-based approach"),ym.forEach(t),wn.forEach(t),cs=p(e),Wi=s(e,"P",{});var bm=f(Wi);tc=l(bm,"This is the very barebones approach to uploading files: we\u2019ll do so with git and git-lfs directly. Most of the difficulty is abstracted away by previous approaches, but there are a few caveats with the following method so we\u2019ll follow a more complex use-case."),bm.forEach(t),ps=p(e),Lt=s(e,"P",{});var kn=f(Lt);oc=l(kn,"Using this class requires having git and git-lfs installed, so make sure you have "),No=s(kn,"A",{href:!0,rel:!0});var vm=f(No);ic=l(vm,"git-lfs"),vm.forEach(t),lc=l(kn," installed (see here for installation instructions) and set up before you begin."),kn.forEach(t),ds=p(e),Bi=s(e,"P",{});var wm=f(Bi);rc=l(wm,"First start by initializing git-lfs:"),wm.forEach(t),ms=p(e),j(Uo.$$.fragment,e),_s=p(e),j(Ro.$$.fragment,e),gs=p(e),Yi=s(e,"P",{});var km=f(Yi);ac=l(km,"Once that\u2019s done, the first step is to clone your model repository:"),km.forEach(t),ys=p(e),j(Wo.$$.fragment,e),bs=p(e),Ke=s(e,"P",{});var gl=f(Ke);sc=l(gl,"My username is "),Ar=s(gl,"CODE",{});var $m=f(Ar);nc=l($m,"lysandre"),$m.forEach(t),fc=l(gl," and I\u2019ve used the model name "),Or=s(gl,"CODE",{});var Em=f(Or);hc=l(Em,"dummy"),Em.forEach(t),uc=l(gl,", so for me the command ends up looking like the following:"),gl.forEach(t),vs=p(e),j(Bo.$$.fragment,e),ws=p(e),Je=s(e,"P",{});var yl=f(Je);cc=l(yl,"I now have a folder named "),Ir=s(yl,"EM",{});var jm=f(Ir);pc=l(jm,"dummy"),jm.forEach(t),dc=l(yl," in my working directory. I can "),Dr=s(yl,"CODE",{});var zm=f(Dr);mc=l(zm,"cd"),zm.forEach(t),_c=l(yl," into the folder and have a look at the contents:"),yl.forEach(t),ks=p(e),j(Yo.$$.fragment,e),$s=p(e),j(Vo.$$.fragment,e),Es=p(e),ue=s(e,"P",{});var Qe=f(ue);gc=l(Qe,"If you just created your repository using Hugging Face Hub\u2019s "),Cr=s(Qe,"CODE",{});var Tm=f(Cr);yc=l(Tm,"create_repo"),Tm.forEach(t),bc=l(Qe," method, this folder should only contain a hidden "),Mr=s(Qe,"CODE",{});var Pm=f(Mr);vc=l(Pm,".gitattributes"),Pm.forEach(t),wc=l(Qe," file. If you followed the instructions in the previous section to create a repository using the web interface, the folder should contain a single "),qr=s(Qe,"EM",{});var Am=f(qr);kc=l(Am,"README.md"),Am.forEach(t),$c=l(Qe," file alongside the hidden "),Fr=s(Qe,"CODE",{});var Om=f(Fr);Ec=l(Om,".gitattributes"),Om.forEach(t),jc=l(Qe," file, as shown here."),Qe.forEach(t),js=p(e),St=s(e,"P",{});var $n=f(St);zc=l($n,"Adding a regular-sized file, such as a configuration file, a vocabulary file, or basically any file under a few megabytes, is done exactly as one would do it in any git-based system. However, bigger files must be registered through git-lfs in order to push them to "),Hr=s($n,"EM",{});var Im=f(Hr);Tc=l(Im,"huggingface.co"),Im.forEach(t),Pc=l($n,"."),$n.forEach(t),zs=p(e),Vi=s(e,"P",{});var Dm=f(Vi);Ac=l(Dm,"Let\u2019s go back to Python for a bit to generate a model and tokenizer that we\u2019d like to commit to our dummy repository:"),Dm.forEach(t),Ts=p(e),Pe.l(e),Ki=p(e),Nt=s(e,"P",{});var En=f(Nt);Oc=l(En,"Now that we\u2019ve saved some model and tokenizer artifacts, let\u2019s take another look at the "),xr=s(En,"EM",{});var Cm=f(xr);Ic=l(Cm,"dummy"),Cm.forEach(t),Dc=l(En," folder:"),En.forEach(t),Ps=p(e),j(Ko.$$.fragment,e),As=p(e),Oe.l(e),Ji=p(e),j(Ut.$$.fragment,e),Os=p(e),Rt=s(e,"P",{});var jn=f(Rt);Cc=l(jn,"We can now go ahead and proceed like we would usually do with traditional Git repositories. We can add all the files to Git\u2019s staging environment using the "),Gr=s(jn,"CODE",{});var Mm=f(Gr);Mc=l(Mm,"git add"),Mm.forEach(t),qc=l(jn," command:"),jn.forEach(t),Is=p(e),j(Jo.$$.fragment,e),Ds=p(e),Xi=s(e,"P",{});var qm=f(Xi);Fc=l(qm,"We can then have a look at the files that are currently staged:"),qm.forEach(t),Cs=p(e),j(Xo.$$.fragment,e),Ms=p(e),De.l(e),Zi=p(e),Wt=s(e,"P",{});var zn=f(Wt);Hc=l(zn,"Similarly, we can make sure that git-lfs is tracking the correct files by using its "),Lr=s(zn,"CODE",{});var Fm=f(Lr);xc=l(Fm,"status"),Fm.forEach(t),Gc=l(zn," command:"),zn.forEach(t),qs=p(e),j(Zo.$$.fragment,e),Fs=p(e),Me.l(e),Qi=p(e),Bt=s(e,"P",{});var Tn=f(Bt);Lc=l(Tn,"Let\u2019s proceed to the final steps, committing and pushing to the "),Sr=s(Tn,"EM",{});var Hm=f(Sr);Sc=l(Hm,"huggingface.co"),Hm.forEach(t),Nc=l(Tn," remote repository:"),Tn.forEach(t),Hs=p(e),j(Qo.$$.fragment,e),xs=p(e),Fe.l(e),el=p(e),tl=s(e,"P",{});var xm=f(tl);Uc=l(xm,"Pushing can take a bit of time, depending on the speed of your internet connection and the size of your files:"),xm.forEach(t),Gs=p(e),j(ei.$$.fragment,e),Ls=p(e),j(ti.$$.fragment,e),Ss=p(e),ht.l(e),ol=Gm(),this.h()},h(){_(u,"name","hf:doc:metadata"),_(u,"content",JSON.stringify(b_)),_(A,"id","sharing-pretrained-models"),_(A,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(A,"href","#sharing-pretrained-models"),_(k,"class","relative group"),_(S,"id","using-the-pushtohub-api"),_(S,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(S,"href","#using-the-pushtohub-api"),_(C,"class","relative group"),_(yi,"href","/course/chapter0"),_(to,"href","https://huggingface.co/join"),_(to,"rel","nofollow"),_(ao,"href","https://huggingface.co/user-or-organization/dummy-model"),_(ao,"rel","nofollow"),_(so,"href","https://huggingface.co/transformers/model_sharing.html"),_(so,"rel","nofollow"),_(no,"href","https://github.com/huggingface/huggingface_hub"),_(no,"rel","nofollow"),_(fo,"href","https://github.com/allenai/allennlp"),_(fo,"rel","nofollow"),_(kt,"id","using-the-huggingfacehub-python-library"),_(kt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(kt,"href","#using-the-huggingfacehub-python-library"),_(it,"class","relative group"),_(Tt,"id","using-the-web-interface"),_(Tt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Tt,"href","#using-the-web-interface"),_(lt,"class","relative group"),_(yo,"href","https://huggingface.co/new"),_(yo,"rel","nofollow"),Ge(vo.src,Vc="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/new_model.png")||_(vo,"src",Vc),_(vo,"alt","Page showcasing the model used for the creation of a new model repository."),_(vo,"width","80%"),_(bo,"class","flex justify-center"),Ge(ko.src,Kc="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/empty_model.png")||_(ko,"src",Kc),_(ko,"alt","An empty model page after creating a new repository."),_(ko,"width","80%"),_(wo,"class","flex justify-center"),Ge(Eo.src,Jc="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/dummy_model.png")||_(Eo,"src",Jc),_(Eo,"alt","The README file showing the Markdown capabilities."),_(Eo,"width","80%"),_($o,"class","flex justify-center"),Ge(zo.src,Xc="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter4/files.png")||_(zo,"src",Xc),_(zo,"alt","The 'Files and versions' tab only shows the .gitattributes and README.md files."),_(zo,"width","80%"),_(jo,"class","flex justify-center"),_(At,"id","uploading-the-model-files"),_(At,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(At,"href","#uploading-the-model-files"),_(rt,"class","relative group"),_(Po,"href","https://git-lfs.github.com/"),_(Po,"rel","nofollow"),_(Dt,"id","the-uploadfile-approach"),_(Dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Dt,"href","#the-uploadfile-approach"),_(at,"class","relative group"),_(qt,"id","the-repository-class"),_(qt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(qt,"href","#the-repository-class"),_(st,"class","relative group"),_(Mo,"href","https://git-lfs.github.com/"),_(Mo,"rel","nofollow"),_(Ho,"href","https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub#advanced-programmatic-repository-management"),_(Ho,"rel","nofollow"),_(Gt,"id","the-gitbased-approach"),_(Gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Gt,"href","#the-gitbased-approach"),_(nt,"class","relative group"),_(No,"href","https://git-lfs.github.com/"),_(No,"rel","nofollow")},m(e,r){o(document.head,u),n(e,d,r),z(h,e,r),n(e,g,r),n(e,k,r),o(k,A),o(A,F),z(P,F,null),o(k,M),o(k,I),o(I,D),n(e,m,r),oi[y].m(e,r),n(e,$,r),n(e,H,r),o(H,N),n(e,G,r),z(L,e,r),n(e,W,r),n(e,J,r),o(J,ie),n(e,B,r),n(e,le,r),o(le,ye),n(e,te,r),n(e,R,r),o(R,oe),o(oe,re),o(oe,Y),o(Y,be),o(oe,ae),o(R,x),o(R,U),o(U,ve),o(U,X),o(X,V),o(U,ce),o(R,Le),o(R,pe),o(pe,we),n(e,Z,r),n(e,Q,r),o(Q,pi),n(e,et,r),n(e,C,r),o(C,S),o(S,pt),z(Se,pt,null),o(C,di),o(C,K),o(K,mi),o(K,dt),o(dt,_i),o(K,gi),n(e,tt,r),ii[se].m(e,r),n(e,ot,r),n(e,ke,r),o(ke,Pn),o(ke,bl),o(bl,An),o(ke,On),n(e,Ur,r),n(e,de,r),o(de,In),o(de,vl),o(vl,Dn),o(de,Cn),o(de,wl),o(wl,Mn),o(de,qn),o(de,yi),o(yi,Fn),o(de,Hn),n(e,Rr,r),z(Qt,e,r),n(e,Wr,r),n(e,bi,r),o(bi,xn),n(e,Br,r),z(eo,e,r),n(e,Yr,r),n(e,mt,r),o(mt,Gn),o(mt,to),o(to,Ln),o(mt,Sn),n(e,Vr,r),n(e,vi,r),o(vi,Nn),n(e,Kr,r),li[$e].m(e,r),n(e,wi,r),n(e,_t,r),o(_t,Un),o(_t,kl),o(kl,Rn),o(_t,Wn),n(e,Jr,r),n(e,ki,r),o(ki,Bn),n(e,Xr,r),ri[je].m(e,r),n(e,$i,r),n(e,Ne,r),o(Ne,Yn),o(Ne,$l),o($l,Vn),o(Ne,Kn),o(Ne,El),o(El,Jn),o(Ne,Xn),n(e,Zr,r),z(oo,e,r),n(e,Qr,r),n(e,gt,r),o(gt,Zn),o(gt,jl),o(jl,Qn),o(gt,ef),n(e,ea,r),z(io,e,r),n(e,ta,r),n(e,yt,r),o(yt,tf),o(yt,zl),o(zl,of),o(yt,lf),n(e,oa,r),z(lo,e,r),n(e,ia,r),n(e,bt,r),o(bt,rf),o(bt,Tl),o(Tl,af),o(bt,sf),n(e,la,r),z(ro,e,r),n(e,ra,r),n(e,vt,r),o(vt,nf),o(vt,Pl),o(Pl,ao),o(ao,ff),o(vt,hf),n(e,aa,r),n(e,Ei,r),o(Ei,uf),n(e,sa,r),ft.m(e,r),n(e,ji,r),z(wt,e,r),n(e,na,r),n(e,Ue,r),o(Ue,cf),o(Ue,Al),o(Al,pf),o(Ue,df),o(Ue,so),o(so,mf),o(Ue,_f),n(e,fa,r),n(e,me,r),o(me,gf),o(me,Ol),o(Ol,yf),o(me,bf),o(me,no),o(no,Il),o(Il,vf),o(me,wf),o(me,fo),o(fo,Dl),o(Dl,kf),o(me,$f),n(e,ha,r),n(e,zi,r),o(zi,Ef),n(e,ua,r),n(e,it,r),o(it,kt),o(kt,Cl),z(ho,Cl,null),o(it,jf),o(it,uo),o(uo,zf),o(uo,Ml),o(Ml,Tf),o(uo,Pf),n(e,ca,r),n(e,$t,r),o($t,Af),o($t,ql),o(ql,Of),o($t,If),n(e,pa,r),n(e,_e,r),o(_e,Df),o(_e,Fl),o(Fl,Cf),o(_e,Mf),o(_e,Hl),o(Hl,qf),o(_e,Ff),o(_e,xl),o(xl,Hf),o(_e,xf),n(e,da,r),z(co,e,r),n(e,ma,r),n(e,Et,r),o(Et,Gf),o(Et,Gl),o(Gl,Lf),o(Et,Sf),n(e,_a,r),z(po,e,r),n(e,ga,r),n(e,jt,r),o(jt,Nf),o(jt,Ll),o(Ll,Uf),o(jt,Rf),n(e,ya,r),n(e,zt,r),o(zt,Wf),o(zt,Sl),o(Sl,Bf),o(zt,Yf),n(e,ba,r),z(mo,e,r),n(e,va,r),n(e,Re,r),o(Re,Vf),o(Re,Nl),o(Nl,Kf),o(Re,Jf),o(Re,Ul),o(Ul,Xf),o(Re,Zf),n(e,wa,r),z(_o,e,r),n(e,ka,r),n(e,We,r),o(We,Qf),o(We,Rl),o(Rl,eh),o(We,th),o(We,Wl),o(Wl,oh),o(We,ih),n(e,$a,r),n(e,Be,r),o(Be,Ti),o(Ti,Bl),o(Bl,lh),o(Ti,rh),o(Be,ah),o(Be,Pi),o(Pi,Yl),o(Yl,sh),o(Pi,nh),o(Be,fh),o(Be,ne),o(ne,Vl),o(Vl,hh),o(ne,uh),o(ne,Kl),o(Kl,ch),o(ne,ph),o(ne,Jl),o(Jl,dh),o(ne,mh),o(ne,Xl),o(Xl,_h),o(ne,gh),o(ne,Zl),o(Zl,yh),o(ne,bh),n(e,Ea,r),n(e,Ai,r),o(Ai,vh),n(e,ja,r),n(e,lt,r),o(lt,Tt),o(Tt,Ql),z(go,Ql,null),o(lt,wh),o(lt,er),o(er,kh),n(e,za,r),n(e,Oi,r),o(Oi,$h),n(e,Ta,r),n(e,Pt,r),o(Pt,Eh),o(Pt,yo),o(yo,jh),o(Pt,zh),n(e,Pa,r),n(e,bo,r),o(bo,vo),n(e,Aa,r),n(e,Ii,r),o(Ii,Th),n(e,Oa,r),n(e,Di,r),o(Di,Ph),n(e,Ia,r),n(e,Ci,r),o(Ci,Ah),n(e,Da,r),n(e,wo,r),o(wo,ko),n(e,Ca,r),n(e,Mi,r),o(Mi,Oh),n(e,Ma,r),n(e,$o,r),o($o,Eo),n(e,qa,r),n(e,qi,r),o(qi,Ih),n(e,Fa,r),n(e,Ye,r),o(Ye,Dh),o(Ye,tr),o(tr,Ch),o(Ye,Mh),o(Ye,or),o(or,qh),o(Ye,Fh),n(e,Ha,r),n(e,jo,r),o(jo,zo),n(e,xa,r),n(e,Fi,r),o(Fi,Hh),n(e,Ga,r),n(e,rt,r),o(rt,At),o(At,ir),z(To,ir,null),o(rt,xh),o(rt,lr),o(lr,Gh),n(e,La,r),n(e,Ot,r),o(Ot,Lh),o(Ot,Po),o(Po,Sh),o(Ot,Nh),n(e,Sa,r),n(e,It,r),o(It,Uh),o(It,rr),o(rr,Rh),o(It,Wh),n(e,Na,r),n(e,at,r),o(at,Dt),o(Dt,ar),z(Ao,ar,null),o(at,Bh),o(at,Oo),o(Oo,Yh),o(Oo,sr),o(sr,Vh),o(Oo,Kh),n(e,Ua,r),n(e,Ct,r),o(Ct,Jh),o(Ct,nr),o(nr,Xh),o(Ct,Zh),n(e,Ra,r),n(e,Hi,r),o(Hi,Qh),n(e,Wa,r),z(Io,e,r),n(e,Ba,r),n(e,fe,r),o(fe,eu),o(fe,fr),o(fr,tu),o(fe,ou),o(fe,hr),o(hr,iu),o(fe,lu),o(fe,ur),o(ur,ru),o(fe,au),o(fe,cr),o(cr,su),o(fe,nu),n(e,Ya,r),n(e,Mt,r),o(Mt,xi),o(xi,pr),o(pr,fu),o(xi,hu),o(Mt,uu),o(Mt,he),o(he,dr),o(dr,cu),o(he,pu),o(he,mr),o(mr,du),o(he,mu),o(he,_r),o(_r,_u),o(he,gu),o(he,gr),o(gr,yu),o(he,bu),o(he,yr),o(yr,vu),o(he,wu),n(e,Va,r),n(e,st,r),o(st,qt),o(qt,br),z(Do,br,null),o(st,ku),o(st,Co),o(Co,$u),o(Co,vr),o(vr,Eu),o(Co,ju),n(e,Ka,r),n(e,Ft,r),o(Ft,zu),o(Ft,wr),o(wr,Tu),o(Ft,Pu),n(e,Ja,r),n(e,Ht,r),o(Ht,Au),o(Ht,Mo),o(Mo,Ou),o(Ht,Iu),n(e,Xa,r),n(e,Gi,r),o(Gi,Du),n(e,Za,r),z(qo,e,r),n(e,Qa,r),n(e,ge,r),o(ge,Cu),o(ge,kr),o(kr,Mu),o(ge,qu),o(ge,$r),o($r,Fu),o(ge,Hu),o(ge,Er),o(Er,xu),o(ge,Gu),n(e,es,r),n(e,Li,r),o(Li,Lu),n(e,ts,r),z(Fo,e,r),n(e,os,r),n(e,Ve,r),o(Ve,Su),o(Ve,jr),o(jr,Nu),o(Ve,Uu),o(Ve,Ho),o(Ho,Ru),o(Ve,Wu),n(e,is,r),n(e,Si,r),o(Si,Bu),n(e,ls,r),n(e,Ni,r),o(Ni,Yu),n(e,rs,r),z(xo,e,r),n(e,as,r),n(e,Ui,r),o(Ui,Vu),n(e,ss,r),z(Go,e,r),n(e,ns,r),n(e,xt,r),o(xt,Ku),o(xt,zr),o(zr,Ju),o(xt,Xu),n(e,fs,r),z(Lo,e,r),n(e,hs,r),n(e,Ri,r),o(Ri,Zu),n(e,us,r),n(e,nt,r),o(nt,Gt),o(Gt,Tr),z(So,Tr,null),o(nt,Qu),o(nt,Pr),o(Pr,ec),n(e,cs,r),n(e,Wi,r),o(Wi,tc),n(e,ps,r),n(e,Lt,r),o(Lt,oc),o(Lt,No),o(No,ic),o(Lt,lc),n(e,ds,r),n(e,Bi,r),o(Bi,rc),n(e,ms,r),z(Uo,e,r),n(e,_s,r),z(Ro,e,r),n(e,gs,r),n(e,Yi,r),o(Yi,ac),n(e,ys,r),z(Wo,e,r),n(e,bs,r),n(e,Ke,r),o(Ke,sc),o(Ke,Ar),o(Ar,nc),o(Ke,fc),o(Ke,Or),o(Or,hc),o(Ke,uc),n(e,vs,r),z(Bo,e,r),n(e,ws,r),n(e,Je,r),o(Je,cc),o(Je,Ir),o(Ir,pc),o(Je,dc),o(Je,Dr),o(Dr,mc),o(Je,_c),n(e,ks,r),z(Yo,e,r),n(e,$s,r),z(Vo,e,r),n(e,Es,r),n(e,ue,r),o(ue,gc),o(ue,Cr),o(Cr,yc),o(ue,bc),o(ue,Mr),o(Mr,vc),o(ue,wc),o(ue,qr),o(qr,kc),o(ue,$c),o(ue,Fr),o(Fr,Ec),o(ue,jc),n(e,js,r),n(e,St,r),o(St,zc),o(St,Hr),o(Hr,Tc),o(St,Pc),n(e,zs,r),n(e,Vi,r),o(Vi,Ac),n(e,Ts,r),ai[Te].m(e,r),n(e,Ki,r),n(e,Nt,r),o(Nt,Oc),o(Nt,xr),o(xr,Ic),o(Nt,Dc),n(e,Ps,r),z(Ko,e,r),n(e,As,r),si[Ae].m(e,r),n(e,Ji,r),z(Ut,e,r),n(e,Os,r),n(e,Rt,r),o(Rt,Cc),o(Rt,Gr),o(Gr,Mc),o(Rt,qc),n(e,Is,r),z(Jo,e,r),n(e,Ds,r),n(e,Xi,r),o(Xi,Fc),n(e,Cs,r),z(Xo,e,r),n(e,Ms,r),ni[Ie].m(e,r),n(e,Zi,r),n(e,Wt,r),o(Wt,Hc),o(Wt,Lr),o(Lr,xc),o(Wt,Gc),n(e,qs,r),z(Zo,e,r),n(e,Fs,r),fi[Ce].m(e,r),n(e,Qi,r),n(e,Bt,r),o(Bt,Lc),o(Bt,Sr),o(Sr,Sc),o(Bt,Nc),n(e,Hs,r),z(Qo,e,r),n(e,xs,r),hi[qe].m(e,r),n(e,el,r),n(e,tl,r),o(tl,Uc),n(e,Gs,r),z(ei,e,r),n(e,Ls,r),z(ti,e,r),n(e,Ss,r),ht.m(e,r),n(e,ol,r),Ns=!0},p(e,[r]){const ui={};r&1&&(ui.fw=e[0]),h.$set(ui);let il=y;y=Qc(e),y!==il&&(ct(),b(oi[il],1,1,()=>{oi[il]=null}),ut(),w=oi[y],w||(w=oi[y]=Zc[y](e),w.c()),v(w,1),w.m($.parentNode,$));let ll=se;se=tp(e),se!==ll&&(ct(),b(ii[ll],1,1,()=>{ii[ll]=null}),ut(),ee=ii[se],ee||(ee=ii[se]=ep[se](e),ee.c()),v(ee,1),ee.m(ot.parentNode,ot));let rl=$e;$e=ip(e),$e!==rl&&(ct(),b(li[rl],1,1,()=>{li[rl]=null}),ut(),Ee=li[$e],Ee||(Ee=li[$e]=op[$e](e),Ee.c()),v(Ee,1),Ee.m(wi.parentNode,wi));let al=je;je=rp(e),je!==al&&(ct(),b(ri[al],1,1,()=>{ri[al]=null}),ut(),ze=ri[je],ze||(ze=ri[je]=lp[je](e),ze.c()),v(ze,1),ze.m($i.parentNode,$i)),Us!==(Us=ap(e))&&(ft.d(1),ft=Us(e),ft&&(ft.c(),ft.m(ji.parentNode,ji)));const Nr={};r&2&&(Nr.$$scope={dirty:r,ctx:e}),wt.$set(Nr);let sl=Te;Te=np(e),Te!==sl&&(ct(),b(ai[sl],1,1,()=>{ai[sl]=null}),ut(),Pe=ai[Te],Pe||(Pe=ai[Te]=sp[Te](e),Pe.c()),v(Pe,1),Pe.m(Ki.parentNode,Ki));let Xe=Ae;Ae=hp(e),Ae!==Xe&&(ct(),b(si[Xe],1,1,()=>{si[Xe]=null}),ut(),Oe=si[Ae],Oe||(Oe=si[Ae]=fp[Ae](e),Oe.c()),v(Oe,1),Oe.m(Ji.parentNode,Ji));const ci={};r&2&&(ci.$$scope={dirty:r,ctx:e}),Ut.$set(ci);let nl=Ie;Ie=cp(e),Ie!==nl&&(ct(),b(ni[nl],1,1,()=>{ni[nl]=null}),ut(),De=ni[Ie],De||(De=ni[Ie]=up[Ie](e),De.c()),v(De,1),De.m(Zi.parentNode,Zi));let Yt=Ce;Ce=dp(e),Ce!==Yt&&(ct(),b(fi[Yt],1,1,()=>{fi[Yt]=null}),ut(),Me=fi[Ce],Me||(Me=fi[Ce]=pp[Ce](e),Me.c()),v(Me,1),Me.m(Qi.parentNode,Qi));let fl=qe;qe=_p(e),qe!==fl&&(ct(),b(hi[fl],1,1,()=>{hi[fl]=null}),ut(),Fe=hi[qe],Fe||(Fe=hi[qe]=mp[qe](e),Fe.c()),v(Fe,1),Fe.m(el.parentNode,el)),Rs!==(Rs=gp(e))&&(ht.d(1),ht=Rs(e),ht&&(ht.c(),ht.m(ol.parentNode,ol)))},i(e){Ns||(v(h.$$.fragment,e),v(P.$$.fragment,e),v(w),v(L.$$.fragment,e),v(Se.$$.fragment,e),v(ee),v(Qt.$$.fragment,e),v(eo.$$.fragment,e),v(Ee),v(ze),v(oo.$$.fragment,e),v(io.$$.fragment,e),v(lo.$$.fragment,e),v(ro.$$.fragment,e),v(wt.$$.fragment,e),v(ho.$$.fragment,e),v(co.$$.fragment,e),v(po.$$.fragment,e),v(mo.$$.fragment,e),v(_o.$$.fragment,e),v(go.$$.fragment,e),v(To.$$.fragment,e),v(Ao.$$.fragment,e),v(Io.$$.fragment,e),v(Do.$$.fragment,e),v(qo.$$.fragment,e),v(Fo.$$.fragment,e),v(xo.$$.fragment,e),v(Go.$$.fragment,e),v(Lo.$$.fragment,e),v(So.$$.fragment,e),v(Uo.$$.fragment,e),v(Ro.$$.fragment,e),v(Wo.$$.fragment,e),v(Bo.$$.fragment,e),v(Yo.$$.fragment,e),v(Vo.$$.fragment,e),v(Pe),v(Ko.$$.fragment,e),v(Oe),v(Ut.$$.fragment,e),v(Jo.$$.fragment,e),v(Xo.$$.fragment,e),v(De),v(Zo.$$.fragment,e),v(Me),v(Qo.$$.fragment,e),v(Fe),v(ei.$$.fragment,e),v(ti.$$.fragment,e),Ns=!0)},o(e){b(h.$$.fragment,e),b(P.$$.fragment,e),b(w),b(L.$$.fragment,e),b(Se.$$.fragment,e),b(ee),b(Qt.$$.fragment,e),b(eo.$$.fragment,e),b(Ee),b(ze),b(oo.$$.fragment,e),b(io.$$.fragment,e),b(lo.$$.fragment,e),b(ro.$$.fragment,e),b(wt.$$.fragment,e),b(ho.$$.fragment,e),b(co.$$.fragment,e),b(po.$$.fragment,e),b(mo.$$.fragment,e),b(_o.$$.fragment,e),b(go.$$.fragment,e),b(To.$$.fragment,e),b(Ao.$$.fragment,e),b(Io.$$.fragment,e),b(Do.$$.fragment,e),b(qo.$$.fragment,e),b(Fo.$$.fragment,e),b(xo.$$.fragment,e),b(Go.$$.fragment,e),b(Lo.$$.fragment,e),b(So.$$.fragment,e),b(Uo.$$.fragment,e),b(Ro.$$.fragment,e),b(Wo.$$.fragment,e),b(Bo.$$.fragment,e),b(Yo.$$.fragment,e),b(Vo.$$.fragment,e),b(Pe),b(Ko.$$.fragment,e),b(Oe),b(Ut.$$.fragment,e),b(Jo.$$.fragment,e),b(Xo.$$.fragment,e),b(De),b(Zo.$$.fragment,e),b(Me),b(Qo.$$.fragment,e),b(Fe),b(ei.$$.fragment,e),b(ti.$$.fragment,e),Ns=!1},d(e){t(u),e&&t(d),T(h,e),e&&t(g),e&&t(k),T(P),e&&t(m),oi[y].d(e),e&&t($),e&&t(H),e&&t(G),T(L,e),e&&t(W),e&&t(J),e&&t(B),e&&t(le),e&&t(te),e&&t(R),e&&t(Z),e&&t(Q),e&&t(et),e&&t(C),T(Se),e&&t(tt),ii[se].d(e),e&&t(ot),e&&t(ke),e&&t(Ur),e&&t(de),e&&t(Rr),T(Qt,e),e&&t(Wr),e&&t(bi),e&&t(Br),T(eo,e),e&&t(Yr),e&&t(mt),e&&t(Vr),e&&t(vi),e&&t(Kr),li[$e].d(e),e&&t(wi),e&&t(_t),e&&t(Jr),e&&t(ki),e&&t(Xr),ri[je].d(e),e&&t($i),e&&t(Ne),e&&t(Zr),T(oo,e),e&&t(Qr),e&&t(gt),e&&t(ea),T(io,e),e&&t(ta),e&&t(yt),e&&t(oa),T(lo,e),e&&t(ia),e&&t(bt),e&&t(la),T(ro,e),e&&t(ra),e&&t(vt),e&&t(aa),e&&t(Ei),e&&t(sa),ft.d(e),e&&t(ji),T(wt,e),e&&t(na),e&&t(Ue),e&&t(fa),e&&t(me),e&&t(ha),e&&t(zi),e&&t(ua),e&&t(it),T(ho),e&&t(ca),e&&t($t),e&&t(pa),e&&t(_e),e&&t(da),T(co,e),e&&t(ma),e&&t(Et),e&&t(_a),T(po,e),e&&t(ga),e&&t(jt),e&&t(ya),e&&t(zt),e&&t(ba),T(mo,e),e&&t(va),e&&t(Re),e&&t(wa),T(_o,e),e&&t(ka),e&&t(We),e&&t($a),e&&t(Be),e&&t(Ea),e&&t(Ai),e&&t(ja),e&&t(lt),T(go),e&&t(za),e&&t(Oi),e&&t(Ta),e&&t(Pt),e&&t(Pa),e&&t(bo),e&&t(Aa),e&&t(Ii),e&&t(Oa),e&&t(Di),e&&t(Ia),e&&t(Ci),e&&t(Da),e&&t(wo),e&&t(Ca),e&&t(Mi),e&&t(Ma),e&&t($o),e&&t(qa),e&&t(qi),e&&t(Fa),e&&t(Ye),e&&t(Ha),e&&t(jo),e&&t(xa),e&&t(Fi),e&&t(Ga),e&&t(rt),T(To),e&&t(La),e&&t(Ot),e&&t(Sa),e&&t(It),e&&t(Na),e&&t(at),T(Ao),e&&t(Ua),e&&t(Ct),e&&t(Ra),e&&t(Hi),e&&t(Wa),T(Io,e),e&&t(Ba),e&&t(fe),e&&t(Ya),e&&t(Mt),e&&t(Va),e&&t(st),T(Do),e&&t(Ka),e&&t(Ft),e&&t(Ja),e&&t(Ht),e&&t(Xa),e&&t(Gi),e&&t(Za),T(qo,e),e&&t(Qa),e&&t(ge),e&&t(es),e&&t(Li),e&&t(ts),T(Fo,e),e&&t(os),e&&t(Ve),e&&t(is),e&&t(Si),e&&t(ls),e&&t(Ni),e&&t(rs),T(xo,e),e&&t(as),e&&t(Ui),e&&t(ss),T(Go,e),e&&t(ns),e&&t(xt),e&&t(fs),T(Lo,e),e&&t(hs),e&&t(Ri),e&&t(us),e&&t(nt),T(So),e&&t(cs),e&&t(Wi),e&&t(ps),e&&t(Lt),e&&t(ds),e&&t(Bi),e&&t(ms),T(Uo,e),e&&t(_s),T(Ro,e),e&&t(gs),e&&t(Yi),e&&t(ys),T(Wo,e),e&&t(bs),e&&t(Ke),e&&t(vs),T(Bo,e),e&&t(ws),e&&t(Je),e&&t(ks),T(Yo,e),e&&t($s),T(Vo,e),e&&t(Es),e&&t(ue),e&&t(js),e&&t(St),e&&t(zs),e&&t(Vi),e&&t(Ts),ai[Te].d(e),e&&t(Ki),e&&t(Nt),e&&t(Ps),T(Ko,e),e&&t(As),si[Ae].d(e),e&&t(Ji),T(Ut,e),e&&t(Os),e&&t(Rt),e&&t(Is),T(Jo,e),e&&t(Ds),e&&t(Xi),e&&t(Cs),T(Xo,e),e&&t(Ms),ni[Ie].d(e),e&&t(Zi),e&&t(Wt),e&&t(qs),T(Zo,e),e&&t(Fs),fi[Ce].d(e),e&&t(Qi),e&&t(Bt),e&&t(Hs),T(Qo,e),e&&t(xs),hi[qe].d(e),e&&t(el),e&&t(tl),e&&t(Gs),T(ei,e),e&&t(Ls),T(ti,e),e&&t(Ss),ht.d(e),e&&t(ol)}}}const b_={local:"sharing-pretrained-models",sections:[{local:"using-the-pushtohub-api",title:"Using the `push_to_hub` API"},{local:"using-the-huggingfacehub-python-library",title:"Using the `huggingface_hub` Python library"},{local:"using-the-web-interface",title:"Using the web interface"},{local:"uploading-the-model-files",sections:[{local:"the-uploadfile-approach",title:"The `upload_file` approach"},{local:"the-repository-class",title:"The `Repository` class"},{local:"the-gitbased-approach",title:"The git-based approach"}],title:"Uploading the model files"}],title:"Sharing pretrained models"};function v_(O,u,d){let h="pt";return Bm(()=>{const g=new URLSearchParams(window.location.search);d(0,h=g.get("fw")||"pt")}),[h]}class P_ extends Nm{constructor(u){super();Um(this,u,v_,y_,Rm,{})}}export{P_ as default,b_ as metadata};
