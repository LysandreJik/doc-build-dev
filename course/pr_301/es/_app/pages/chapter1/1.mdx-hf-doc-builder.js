import{S as Zo,i as et,s as at,e as o,k as u,w as ye,t as l,M as rt,c as t,d as r,m as f,a as s,x as _e,h as n,b as i,N as Xo,G as a,g as d,y as Ee,L as ot,q as we,o as Le,B as Pe,v as tt}from"../../chunks/vendor-hf-doc-builder.js";import{Y as st}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Na}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as lt}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function nt(ro){let y,Ye,_,I,Ae,j,Ia,Te,qa,Ke,D,Xe,E,q,$e,x,Ha,Ne,Sa,Ze,k,ea,p,Ma,F,ja,Da,z,xa,ka,C,Fa,za,G,Ca,Ga,R,Ra,Oa,O,Ba,Qa,aa,w,H,Ie,B,Ua,qe,Ja,ra,ue,Va,oa,L,Q,oo,Wa,U,to,ta,g,J,Ya,V,Ka,Xa,Za,He,er,ar,Se,rr,sa,fe,or,la,h,Me,tr,sr,v,lr,W,nr,ir,Y,cr,dr,K,ur,fr,P,pr,X,mr,gr,Z,hr,vr,na,S,br,ee,yr,_r,ia,A,M,je,ae,Er,De,wr,ca,pe,Lr,da,re,xe,Pr,Ar,ua,oe,ke,Tr,$r,fa,T,Fe,Nr,Ir,ze,te,qr,Hr,pa,se,Ce,Sr,Mr,ma,le,Ge,jr,Dr,ga,$,Re,xr,kr,ne,Fr,zr,ha,N,Oe,Cr,Gr,ie,Rr,Or,va,me,Br,ba,b,ce,Qr,Be,Ur,Jr,Vr,Qe,Wr,Yr,Ue,Kr,ya;return j=new Na({}),D=new lt({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),x=new Na({}),k=new st({props:{id:"00GKzGyWFEs"}}),B=new Na({}),ae=new Na({}),{c(){y=o("meta"),Ye=u(),_=o("h1"),I=o("a"),Ae=o("span"),ye(j.$$.fragment),Ia=u(),Te=o("span"),qa=l("Introducci\xF3n"),Ke=u(),ye(D.$$.fragment),Xe=u(),E=o("h2"),q=o("a"),$e=o("span"),ye(x.$$.fragment),Ha=u(),Ne=o("span"),Sa=l("\xA1Te damos la bienvenida al curso de \u{1F917}!"),Ze=u(),ye(k.$$.fragment),ea=u(),p=o("p"),Ma=l("Este curso te ense\xF1ar\xE1 sobre procesamiento de lenguaje natural (PLN) usando librer\xEDas del ecosistema "),F=o("a"),ja=l("Hugging Face"),Da=l(" - "),z=o("a"),xa=l("\u{1F917} Transformers"),ka=l(", "),C=o("a"),Fa=l("\u{1F917} Datasets"),za=l(", "),G=o("a"),Ca=l("\u{1F917} Tokenizers"),Ga=l(" y "),R=o("a"),Ra=l("\u{1F917} Accelerate"),Oa=l(" \u2014 as\xED como el "),O=o("a"),Ba=l("Hub de Hugging Face"),Qa=l(". El curso es completamente gratuito y sin anuncios."),aa=u(),w=o("h2"),H=o("a"),Ie=o("span"),ye(B.$$.fragment),Ua=u(),qe=o("span"),Ja=l("\xBFQu\xE9 esperar?"),ra=u(),ue=o("p"),Va=l("Esta es una peque\xF1a descripci\xF3n del curso:"),oa=u(),L=o("div"),Q=o("img"),Wa=u(),U=o("img"),ta=u(),g=o("ul"),J=o("li"),Ya=l("Los cap\xEDtulos 1 a 4 ofrecen una introducci\xF3n a los conceptos principales de la librer\xEDa \u{1F917} Transformers. Al final de esta secci\xF3n del curso, estar\xE1s familiarizado con la manera en que trabajan los Transformadores y sabr\xE1s c\xF3mo usar un modelo del "),V=o("a"),Ka=l("Hub de Hugging Face"),Xa=l(", ajustarlo a tu conjunto de datos y compartir tus resultados en el Hub."),Za=u(),He=o("li"),er=l("Los cap\xEDtulos 5 a 8 ense\xF1an lo b\xE1sico de \u{1F917} Datasets y \u{1F917} Tokenizers antes de entrar en tareas cl\xE1sicas de PLN. Al final de esta secci\xF3n, podr\xE1s abordar por ti mismo los problemas m\xE1s comunes de PLN."),ar=u(),Se=o("li"),rr=l("Los cap\xEDtulos 9 al 12 van m\xE1s all\xE1 del PLN y exploran c\xF3mo los Transformadores pueden abordar tareas de procesamiento del habla y visi\xF3n por computador. A lo largo del camino, aprender\xE1s a construir y compartir demos de tus modelos, as\xED como optimizarlos para entornos de producci\xF3n. Al final de esta secci\xF3n, estar\xE1s listo para aplicar \u{1F917} Transformers a (casi) cualquier problema de Machine Learning."),sa=u(),fe=o("p"),or=l("Este curso:"),la=u(),h=o("ul"),Me=o("li"),tr=l("Requiere amplio conocimiento de Python"),sr=u(),v=o("li"),lr=l("Deber\xEDa ser tomado despu\xE9s de un curso de introducci\xF3n a deep learning, como "),W=o("a"),nr=l("Practical Deep Learning for Coders"),ir=l(" de "),Y=o("a"),cr=l("fast.ai\u2019s"),dr=l(" o alguno de los programas desarrollados por "),K=o("a"),ur=l("DeepLearning.AI"),fr=u(),P=o("li"),pr=l("No necesita conocimiento previo de "),X=o("a"),mr=l("PyTorch"),gr=l(" o "),Z=o("a"),hr=l("TensorFlow"),vr=l(", aunque un nivel de familiaridad con alguno de los dos podr\xEDa ser \xFAtil"),na=u(),S=o("p"),br=l("Despu\xE9s de que hayas completado este curso, te recomendamos revisar la "),ee=o("a"),yr=l("Especializaci\xF3n en Procesamiento de Lenguaje Natural"),_r=l(" de DeepLearning.AI, que cubre un gran n\xFAmero de modelos tradicionales de PLN como Naive Bayes y LSTMs."),ia=u(),A=o("h2"),M=o("a"),je=o("span"),ye(ae.$$.fragment),Er=u(),De=o("span"),wr=l("\xBFQui\xE9nes somos?"),ca=u(),pe=o("p"),Lr=l("Acerca de los autores:"),da=u(),re=o("p"),xe=o("strong"),Pr=l("Matthew Carrigan"),Ar=l(" es Ingeniero de Machine Learning en Hugging Face. Vive en Dublin, Irlanda y anteriormente trabaj\xF3 como Ingeniero ML en Parse.ly y como investigador post-doctoral en Trinity College Dublin. No cree que vamos a alcanzar una Inteligencia Artificial General escalando arquitecturas existentes, pero en todo caso tiene grandes expectativas sobre la inmortalidad rob\xF3tica."),ua=u(),oe=o("p"),ke=o("strong"),Tr=l("Lysandre Debut"),$r=l(" es Ingeniero de Machine Learning en Hugging Face y ha trabajado en la librer\xEDa \u{1F917} Transformers desde sus etapas de desarrollo m\xE1s tempranas. Su objetivo es hacer que el PLN sea accesible para todos a trav\xE9s del desarrollo de herramientas con una API muy simple."),fa=u(),T=o("p"),Fe=o("strong"),Nr=l("Sylvain Gugger"),Ir=l(" es Ingeniero de Investigaci\xF3n en Hugging Face y uno de los principales mantenedores de la librer\xEDa \u{1F917} Transformers. Anteriormente fue Cient\xEDfico de Investigaci\xF3n en fast.ai y escribi\xF3 "),ze=o("em"),te=o("a"),qr=l("Deep Learning for Coders with fastai and PyTorch"),Hr=l(" junto con Jeremy Howard. El foco principal de su investigaci\xF3n es hacer el deep learning m\xE1s accesible, al dise\xF1ar y mejorar t\xE9cnicas que permiten un entrenamiento r\xE1pido de modelos con recursos limitados."),pa=u(),se=o("p"),Ce=o("strong"),Sr=l("Merve Noyan"),Mr=l(" es Promotora de Desarrolladores en Hugging Face, trabaja en el desarrollo de herramientas y construcci\xF3n de contenido relacionado, con el f\xEDn de democratizar el machine learning para todos."),ma=u(),le=o("p"),Ge=o("strong"),jr=l("Lucile Saulnier"),Dr=l(" es Ingeniera de Machine Learning en Hugging Face, donde desarrolla y apoya el uso de herramientas de c\xF3digo abierto. Ella est\xE1 activamente involucrada en varios proyectos de investigaci\xF3n en el campo del Procesamiento de Lenguaje Natural como entrenamiento colaborativo y BigScience."),ga=u(),$=o("p"),Re=o("strong"),xr=l("Lewis Tunstall"),kr=l("  es Ingeniero de Machine Learning en Hugging Face, enfocado en desarrollar herramientas de c\xF3digo abierto y hacerlas accesibles a la comunidad en general. Tambi\xE9n es coautor de un pr\xF3ximo "),ne=o("a"),Fr=l("libro de O\u2019Reilly sobre Transformadores"),zr=l("."),ha=u(),N=o("p"),Oe=o("strong"),Cr=l("Leandro von Werra"),Gr=l("  es Ingeniero de Machine Learning en el equipo de c\xF3digo abierto en Hugging Face y coautor de un pr\xF3ximo "),ie=o("a"),Rr=l("libro de O\u2019Reilly sobre Transformadores"),Or=l(". Tiene varios a\xF1os de experiencia en la industria llevando modelos de PLN a producci\xF3n, trabajando a lo largo de todo el entorno de Machine Learning."),va=u(),me=o("p"),Br=l("\xBFEst\xE1s listo para comenzar? En este cap\xEDtulo vas a aprender:"),ba=u(),b=o("ul"),ce=o("li"),Qr=l("C\xF3mo usar la funci\xF3n "),Be=o("code"),Ur=l("pipeline()"),Jr=l(" para resolver tareas de PLN como la generaci\xF3n y clasificaci\xF3n de texto"),Vr=u(),Qe=o("li"),Wr=l("Sobre la arquitectura de los Transformadores"),Yr=u(),Ue=o("li"),Kr=l("C\xF3mo distinguir entre las arquitecturas de codificador, decodificador y codificador-decofidicador, adem\xE1s de sus casos de uso"),this.h()},l(e){const c=rt('[data-svelte="svelte-1phssyn"]',document.head);y=t(c,"META",{name:!0,content:!0}),c.forEach(r),Ye=f(e),_=t(e,"H1",{class:!0});var _a=s(_);I=t(_a,"A",{id:!0,class:!0,href:!0});var so=s(I);Ae=t(so,"SPAN",{});var lo=s(Ae);_e(j.$$.fragment,lo),lo.forEach(r),so.forEach(r),Ia=f(_a),Te=t(_a,"SPAN",{});var no=s(Te);qa=n(no,"Introducci\xF3n"),no.forEach(r),_a.forEach(r),Ke=f(e),_e(D.$$.fragment,e),Xe=f(e),E=t(e,"H2",{class:!0});var Ea=s(E);q=t(Ea,"A",{id:!0,class:!0,href:!0});var io=s(q);$e=t(io,"SPAN",{});var co=s($e);_e(x.$$.fragment,co),co.forEach(r),io.forEach(r),Ha=f(Ea),Ne=t(Ea,"SPAN",{});var uo=s(Ne);Sa=n(uo,"\xA1Te damos la bienvenida al curso de \u{1F917}!"),uo.forEach(r),Ea.forEach(r),Ze=f(e),_e(k.$$.fragment,e),ea=f(e),p=t(e,"P",{});var m=s(p);Ma=n(m,"Este curso te ense\xF1ar\xE1 sobre procesamiento de lenguaje natural (PLN) usando librer\xEDas del ecosistema "),F=t(m,"A",{href:!0,rel:!0});var fo=s(F);ja=n(fo,"Hugging Face"),fo.forEach(r),Da=n(m," - "),z=t(m,"A",{href:!0,rel:!0});var po=s(z);xa=n(po,"\u{1F917} Transformers"),po.forEach(r),ka=n(m,", "),C=t(m,"A",{href:!0,rel:!0});var mo=s(C);Fa=n(mo,"\u{1F917} Datasets"),mo.forEach(r),za=n(m,", "),G=t(m,"A",{href:!0,rel:!0});var go=s(G);Ca=n(go,"\u{1F917} Tokenizers"),go.forEach(r),Ga=n(m," y "),R=t(m,"A",{href:!0,rel:!0});var ho=s(R);Ra=n(ho,"\u{1F917} Accelerate"),ho.forEach(r),Oa=n(m," \u2014 as\xED como el "),O=t(m,"A",{href:!0,rel:!0});var vo=s(O);Ba=n(vo,"Hub de Hugging Face"),vo.forEach(r),Qa=n(m,". El curso es completamente gratuito y sin anuncios."),m.forEach(r),aa=f(e),w=t(e,"H2",{class:!0});var wa=s(w);H=t(wa,"A",{id:!0,class:!0,href:!0});var bo=s(H);Ie=t(bo,"SPAN",{});var yo=s(Ie);_e(B.$$.fragment,yo),yo.forEach(r),bo.forEach(r),Ua=f(wa),qe=t(wa,"SPAN",{});var _o=s(qe);Ja=n(_o,"\xBFQu\xE9 esperar?"),_o.forEach(r),wa.forEach(r),ra=f(e),ue=t(e,"P",{});var Eo=s(ue);Va=n(Eo,"Esta es una peque\xF1a descripci\xF3n del curso:"),Eo.forEach(r),oa=f(e),L=t(e,"DIV",{class:!0});var La=s(L);Q=t(La,"IMG",{class:!0,src:!0,alt:!0}),Wa=f(La),U=t(La,"IMG",{class:!0,src:!0,alt:!0}),La.forEach(r),ta=f(e),g=t(e,"UL",{});var ge=s(g);J=t(ge,"LI",{});var Pa=s(J);Ya=n(Pa,"Los cap\xEDtulos 1 a 4 ofrecen una introducci\xF3n a los conceptos principales de la librer\xEDa \u{1F917} Transformers. Al final de esta secci\xF3n del curso, estar\xE1s familiarizado con la manera en que trabajan los Transformadores y sabr\xE1s c\xF3mo usar un modelo del "),V=t(Pa,"A",{href:!0,rel:!0});var wo=s(V);Ka=n(wo,"Hub de Hugging Face"),wo.forEach(r),Xa=n(Pa,", ajustarlo a tu conjunto de datos y compartir tus resultados en el Hub."),Pa.forEach(r),Za=f(ge),He=t(ge,"LI",{});var Lo=s(He);er=n(Lo,"Los cap\xEDtulos 5 a 8 ense\xF1an lo b\xE1sico de \u{1F917} Datasets y \u{1F917} Tokenizers antes de entrar en tareas cl\xE1sicas de PLN. Al final de esta secci\xF3n, podr\xE1s abordar por ti mismo los problemas m\xE1s comunes de PLN."),Lo.forEach(r),ar=f(ge),Se=t(ge,"LI",{});var Po=s(Se);rr=n(Po,"Los cap\xEDtulos 9 al 12 van m\xE1s all\xE1 del PLN y exploran c\xF3mo los Transformadores pueden abordar tareas de procesamiento del habla y visi\xF3n por computador. A lo largo del camino, aprender\xE1s a construir y compartir demos de tus modelos, as\xED como optimizarlos para entornos de producci\xF3n. Al final de esta secci\xF3n, estar\xE1s listo para aplicar \u{1F917} Transformers a (casi) cualquier problema de Machine Learning."),Po.forEach(r),ge.forEach(r),sa=f(e),fe=t(e,"P",{});var Ao=s(fe);or=n(Ao,"Este curso:"),Ao.forEach(r),la=f(e),h=t(e,"UL",{});var he=s(h);Me=t(he,"LI",{});var To=s(Me);tr=n(To,"Requiere amplio conocimiento de Python"),To.forEach(r),sr=f(he),v=t(he,"LI",{});var de=s(v);lr=n(de,"Deber\xEDa ser tomado despu\xE9s de un curso de introducci\xF3n a deep learning, como "),W=t(de,"A",{href:!0,rel:!0});var $o=s(W);nr=n($o,"Practical Deep Learning for Coders"),$o.forEach(r),ir=n(de," de "),Y=t(de,"A",{href:!0,rel:!0});var No=s(Y);cr=n(No,"fast.ai\u2019s"),No.forEach(r),dr=n(de," o alguno de los programas desarrollados por "),K=t(de,"A",{href:!0,rel:!0});var Io=s(K);ur=n(Io,"DeepLearning.AI"),Io.forEach(r),de.forEach(r),fr=f(he),P=t(he,"LI",{});var ve=s(P);pr=n(ve,"No necesita conocimiento previo de "),X=t(ve,"A",{href:!0,rel:!0});var qo=s(X);mr=n(qo,"PyTorch"),qo.forEach(r),gr=n(ve," o "),Z=t(ve,"A",{href:!0,rel:!0});var Ho=s(Z);hr=n(Ho,"TensorFlow"),Ho.forEach(r),vr=n(ve,", aunque un nivel de familiaridad con alguno de los dos podr\xEDa ser \xFAtil"),ve.forEach(r),he.forEach(r),na=f(e),S=t(e,"P",{});var Aa=s(S);br=n(Aa,"Despu\xE9s de que hayas completado este curso, te recomendamos revisar la "),ee=t(Aa,"A",{href:!0,rel:!0});var So=s(ee);yr=n(So,"Especializaci\xF3n en Procesamiento de Lenguaje Natural"),So.forEach(r),_r=n(Aa," de DeepLearning.AI, que cubre un gran n\xFAmero de modelos tradicionales de PLN como Naive Bayes y LSTMs."),Aa.forEach(r),ia=f(e),A=t(e,"H2",{class:!0});var Ta=s(A);M=t(Ta,"A",{id:!0,class:!0,href:!0});var Mo=s(M);je=t(Mo,"SPAN",{});var jo=s(je);_e(ae.$$.fragment,jo),jo.forEach(r),Mo.forEach(r),Er=f(Ta),De=t(Ta,"SPAN",{});var Do=s(De);wr=n(Do,"\xBFQui\xE9nes somos?"),Do.forEach(r),Ta.forEach(r),ca=f(e),pe=t(e,"P",{});var xo=s(pe);Lr=n(xo,"Acerca de los autores:"),xo.forEach(r),da=f(e),re=t(e,"P",{});var Xr=s(re);xe=t(Xr,"STRONG",{});var ko=s(xe);Pr=n(ko,"Matthew Carrigan"),ko.forEach(r),Ar=n(Xr," es Ingeniero de Machine Learning en Hugging Face. Vive en Dublin, Irlanda y anteriormente trabaj\xF3 como Ingeniero ML en Parse.ly y como investigador post-doctoral en Trinity College Dublin. No cree que vamos a alcanzar una Inteligencia Artificial General escalando arquitecturas existentes, pero en todo caso tiene grandes expectativas sobre la inmortalidad rob\xF3tica."),Xr.forEach(r),ua=f(e),oe=t(e,"P",{});var Zr=s(oe);ke=t(Zr,"STRONG",{});var Fo=s(ke);Tr=n(Fo,"Lysandre Debut"),Fo.forEach(r),$r=n(Zr," es Ingeniero de Machine Learning en Hugging Face y ha trabajado en la librer\xEDa \u{1F917} Transformers desde sus etapas de desarrollo m\xE1s tempranas. Su objetivo es hacer que el PLN sea accesible para todos a trav\xE9s del desarrollo de herramientas con una API muy simple."),Zr.forEach(r),fa=f(e),T=t(e,"P",{});var Je=s(T);Fe=t(Je,"STRONG",{});var zo=s(Fe);Nr=n(zo,"Sylvain Gugger"),zo.forEach(r),Ir=n(Je," es Ingeniero de Investigaci\xF3n en Hugging Face y uno de los principales mantenedores de la librer\xEDa \u{1F917} Transformers. Anteriormente fue Cient\xEDfico de Investigaci\xF3n en fast.ai y escribi\xF3 "),ze=t(Je,"EM",{});var Co=s(ze);te=t(Co,"A",{href:!0,rel:!0});var Go=s(te);qr=n(Go,"Deep Learning for Coders with fastai and PyTorch"),Go.forEach(r),Co.forEach(r),Hr=n(Je," junto con Jeremy Howard. El foco principal de su investigaci\xF3n es hacer el deep learning m\xE1s accesible, al dise\xF1ar y mejorar t\xE9cnicas que permiten un entrenamiento r\xE1pido de modelos con recursos limitados."),Je.forEach(r),pa=f(e),se=t(e,"P",{});var eo=s(se);Ce=t(eo,"STRONG",{});var Ro=s(Ce);Sr=n(Ro,"Merve Noyan"),Ro.forEach(r),Mr=n(eo," es Promotora de Desarrolladores en Hugging Face, trabaja en el desarrollo de herramientas y construcci\xF3n de contenido relacionado, con el f\xEDn de democratizar el machine learning para todos."),eo.forEach(r),ma=f(e),le=t(e,"P",{});var ao=s(le);Ge=t(ao,"STRONG",{});var Oo=s(Ge);jr=n(Oo,"Lucile Saulnier"),Oo.forEach(r),Dr=n(ao," es Ingeniera de Machine Learning en Hugging Face, donde desarrolla y apoya el uso de herramientas de c\xF3digo abierto. Ella est\xE1 activamente involucrada en varios proyectos de investigaci\xF3n en el campo del Procesamiento de Lenguaje Natural como entrenamiento colaborativo y BigScience."),ao.forEach(r),ga=f(e),$=t(e,"P",{});var Ve=s($);Re=t(Ve,"STRONG",{});var Bo=s(Re);xr=n(Bo,"Lewis Tunstall"),Bo.forEach(r),kr=n(Ve,"  es Ingeniero de Machine Learning en Hugging Face, enfocado en desarrollar herramientas de c\xF3digo abierto y hacerlas accesibles a la comunidad en general. Tambi\xE9n es coautor de un pr\xF3ximo "),ne=t(Ve,"A",{href:!0,rel:!0});var Qo=s(ne);Fr=n(Qo,"libro de O\u2019Reilly sobre Transformadores"),Qo.forEach(r),zr=n(Ve,"."),Ve.forEach(r),ha=f(e),N=t(e,"P",{});var We=s(N);Oe=t(We,"STRONG",{});var Uo=s(Oe);Cr=n(Uo,"Leandro von Werra"),Uo.forEach(r),Gr=n(We,"  es Ingeniero de Machine Learning en el equipo de c\xF3digo abierto en Hugging Face y coautor de un pr\xF3ximo "),ie=t(We,"A",{href:!0,rel:!0});var Jo=s(ie);Rr=n(Jo,"libro de O\u2019Reilly sobre Transformadores"),Jo.forEach(r),Or=n(We,". Tiene varios a\xF1os de experiencia en la industria llevando modelos de PLN a producci\xF3n, trabajando a lo largo de todo el entorno de Machine Learning."),We.forEach(r),va=f(e),me=t(e,"P",{});var Vo=s(me);Br=n(Vo,"\xBFEst\xE1s listo para comenzar? En este cap\xEDtulo vas a aprender:"),Vo.forEach(r),ba=f(e),b=t(e,"UL",{});var be=s(b);ce=t(be,"LI",{});var $a=s(ce);Qr=n($a,"C\xF3mo usar la funci\xF3n "),Be=t($a,"CODE",{});var Wo=s(Be);Ur=n(Wo,"pipeline()"),Wo.forEach(r),Jr=n($a," para resolver tareas de PLN como la generaci\xF3n y clasificaci\xF3n de texto"),$a.forEach(r),Vr=f(be),Qe=t(be,"LI",{});var Yo=s(Qe);Wr=n(Yo,"Sobre la arquitectura de los Transformadores"),Yo.forEach(r),Yr=f(be),Ue=t(be,"LI",{});var Ko=s(Ue);Kr=n(Ko,"C\xF3mo distinguir entre las arquitecturas de codificador, decodificador y codificador-decofidicador, adem\xE1s de sus casos de uso"),Ko.forEach(r),be.forEach(r),this.h()},h(){i(y,"name","hf:doc:metadata"),i(y,"content",JSON.stringify(it)),i(I,"id","introduccin"),i(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(I,"href","#introduccin"),i(_,"class","relative group"),i(q,"id","te-damos-la-bienvenida-al-curso-de"),i(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(q,"href","#te-damos-la-bienvenida-al-curso-de"),i(E,"class","relative group"),i(F,"href","https://huggingface.co/"),i(F,"rel","nofollow"),i(z,"href","https://github.com/huggingface/transformers"),i(z,"rel","nofollow"),i(C,"href","https://github.com/huggingface/datasets"),i(C,"rel","nofollow"),i(G,"href","https://github.com/huggingface/tokenizers"),i(G,"rel","nofollow"),i(R,"href","https://github.com/huggingface/accelerate"),i(R,"rel","nofollow"),i(O,"href","https://huggingface.co/models"),i(O,"rel","nofollow"),i(H,"id","qu-esperar"),i(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(H,"href","#qu-esperar"),i(w,"class","relative group"),i(Q,"class","block dark:hidden"),Xo(Q.src,oo="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg")||i(Q,"src",oo),i(Q,"alt","Brief overview of the chapters of the course."),i(U,"class","hidden dark:block"),Xo(U.src,to="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg")||i(U,"src",to),i(U,"alt","Brief overview of the chapters of the course."),i(L,"class","flex justify-center"),i(V,"href","https://huggingface.co/models"),i(V,"rel","nofollow"),i(W,"href","https://course.fast.ai/"),i(W,"rel","nofollow"),i(Y,"href","https://www.fast.ai/"),i(Y,"rel","nofollow"),i(K,"href","https://www.deeplearning.ai/"),i(K,"rel","nofollow"),i(X,"href","https://pytorch.org/"),i(X,"rel","nofollow"),i(Z,"href","https://www.tensorflow.org/"),i(Z,"rel","nofollow"),i(ee,"href","https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-PLN-2-hugging_face-page-PLN-refresh"),i(ee,"rel","nofollow"),i(M,"id","quines-somos"),i(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(M,"href","#quines-somos"),i(A,"class","relative group"),i(te,"href","https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/"),i(te,"rel","nofollow"),i(ne,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(ne,"rel","nofollow"),i(ie,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(ie,"rel","nofollow")},m(e,c){a(document.head,y),d(e,Ye,c),d(e,_,c),a(_,I),a(I,Ae),Ee(j,Ae,null),a(_,Ia),a(_,Te),a(Te,qa),d(e,Ke,c),Ee(D,e,c),d(e,Xe,c),d(e,E,c),a(E,q),a(q,$e),Ee(x,$e,null),a(E,Ha),a(E,Ne),a(Ne,Sa),d(e,Ze,c),Ee(k,e,c),d(e,ea,c),d(e,p,c),a(p,Ma),a(p,F),a(F,ja),a(p,Da),a(p,z),a(z,xa),a(p,ka),a(p,C),a(C,Fa),a(p,za),a(p,G),a(G,Ca),a(p,Ga),a(p,R),a(R,Ra),a(p,Oa),a(p,O),a(O,Ba),a(p,Qa),d(e,aa,c),d(e,w,c),a(w,H),a(H,Ie),Ee(B,Ie,null),a(w,Ua),a(w,qe),a(qe,Ja),d(e,ra,c),d(e,ue,c),a(ue,Va),d(e,oa,c),d(e,L,c),a(L,Q),a(L,Wa),a(L,U),d(e,ta,c),d(e,g,c),a(g,J),a(J,Ya),a(J,V),a(V,Ka),a(J,Xa),a(g,Za),a(g,He),a(He,er),a(g,ar),a(g,Se),a(Se,rr),d(e,sa,c),d(e,fe,c),a(fe,or),d(e,la,c),d(e,h,c),a(h,Me),a(Me,tr),a(h,sr),a(h,v),a(v,lr),a(v,W),a(W,nr),a(v,ir),a(v,Y),a(Y,cr),a(v,dr),a(v,K),a(K,ur),a(h,fr),a(h,P),a(P,pr),a(P,X),a(X,mr),a(P,gr),a(P,Z),a(Z,hr),a(P,vr),d(e,na,c),d(e,S,c),a(S,br),a(S,ee),a(ee,yr),a(S,_r),d(e,ia,c),d(e,A,c),a(A,M),a(M,je),Ee(ae,je,null),a(A,Er),a(A,De),a(De,wr),d(e,ca,c),d(e,pe,c),a(pe,Lr),d(e,da,c),d(e,re,c),a(re,xe),a(xe,Pr),a(re,Ar),d(e,ua,c),d(e,oe,c),a(oe,ke),a(ke,Tr),a(oe,$r),d(e,fa,c),d(e,T,c),a(T,Fe),a(Fe,Nr),a(T,Ir),a(T,ze),a(ze,te),a(te,qr),a(T,Hr),d(e,pa,c),d(e,se,c),a(se,Ce),a(Ce,Sr),a(se,Mr),d(e,ma,c),d(e,le,c),a(le,Ge),a(Ge,jr),a(le,Dr),d(e,ga,c),d(e,$,c),a($,Re),a(Re,xr),a($,kr),a($,ne),a(ne,Fr),a($,zr),d(e,ha,c),d(e,N,c),a(N,Oe),a(Oe,Cr),a(N,Gr),a(N,ie),a(ie,Rr),a(N,Or),d(e,va,c),d(e,me,c),a(me,Br),d(e,ba,c),d(e,b,c),a(b,ce),a(ce,Qr),a(ce,Be),a(Be,Ur),a(ce,Jr),a(b,Vr),a(b,Qe),a(Qe,Wr),a(b,Yr),a(b,Ue),a(Ue,Kr),ya=!0},p:ot,i(e){ya||(we(j.$$.fragment,e),we(D.$$.fragment,e),we(x.$$.fragment,e),we(k.$$.fragment,e),we(B.$$.fragment,e),we(ae.$$.fragment,e),ya=!0)},o(e){Le(j.$$.fragment,e),Le(D.$$.fragment,e),Le(x.$$.fragment,e),Le(k.$$.fragment,e),Le(B.$$.fragment,e),Le(ae.$$.fragment,e),ya=!1},d(e){r(y),e&&r(Ye),e&&r(_),Pe(j),e&&r(Ke),Pe(D,e),e&&r(Xe),e&&r(E),Pe(x),e&&r(Ze),Pe(k,e),e&&r(ea),e&&r(p),e&&r(aa),e&&r(w),Pe(B),e&&r(ra),e&&r(ue),e&&r(oa),e&&r(L),e&&r(ta),e&&r(g),e&&r(sa),e&&r(fe),e&&r(la),e&&r(h),e&&r(na),e&&r(S),e&&r(ia),e&&r(A),Pe(ae),e&&r(ca),e&&r(pe),e&&r(da),e&&r(re),e&&r(ua),e&&r(oe),e&&r(fa),e&&r(T),e&&r(pa),e&&r(se),e&&r(ma),e&&r(le),e&&r(ga),e&&r($),e&&r(ha),e&&r(N),e&&r(va),e&&r(me),e&&r(ba),e&&r(b)}}}const it={local:"introduccin",sections:[{local:"te-damos-la-bienvenida-al-curso-de",title:"\xA1Te damos la bienvenida al curso de \u{1F917}!"},{local:"qu-esperar",title:"\xBFQu\xE9 esperar?"},{local:"quines-somos",title:"\xBFQui\xE9nes somos?"}],title:"Introducci\xF3n"};function ct(ro){return tt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class mt extends Zo{constructor(y){super();et(this,y,ct,nt,at,{})}}export{mt as default,it as metadata};
