import{S as ke,i as Ne,s as je,e as t,k as d,w as fe,t as f,M as ze,c as r,d as a,m,a as l,x as ue,h as u,b as n,G as o,g as c,y as pe,L as Ue,q as he,o as _e,B as Ee,v as De}from"../../chunks/vendor-hf-doc-builder.js";import{Y as Je}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Ye}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Fe}from"../../chunks/CourseFloatingBanner-hf-doc-builder.js";function Ge(ve){let h,j,_,E,P,$,K,x,V,z,y,U,b,D,v,W,M,X,Z,J,T,ee,Y,q,ae,F,B,oe,G,i,I,g,te,re,C,w,le,se,S,L,ne,ie,k,A,ce,de,N,R,me,H;return $=new Ye({}),y=new Fe({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),b=new Je({props:{id:"MUqNwgPjJvQ"}}),{c(){h=t("meta"),j=d(),_=t("h1"),E=t("a"),P=t("span"),fe($.$$.fragment),K=d(),x=t("span"),V=f("Modelos de codificadores"),z=d(),fe(y.$$.fragment),U=d(),fe(b.$$.fragment),D=d(),v=t("p"),W=f("Los modelos de codificadores usan \xFAnicamente el codificador del Transformador. En cada etapa, las capas de atenci\xF3n pueden acceder a todas las palabras de la oraci\xF3n inicial. Estos modelos se caracterizan generalmente por tener atenci\xF3n \u201Cbidireccional\u201D y se suelen llamar modelos "),M=t("em"),X=f("auto-encoding"),Z=f("."),J=d(),T=t("p"),ee=f("El preentrenamiento de estos modelos generalmente gira en torno a corromper de alguna manera una oraci\xF3n dada (por ejemplo, ocultando aleat\xF3riamente palabras en ella) y pidi\xE9ndole al modelo que encuentre o reconstruya la oraci\xF3n inicial."),Y=d(),q=t("p"),ae=f("Los modelos de codificadores son m\xE1s adecuados para tareas que requieren un entendimiento de la oraci\xF3n completa, como la clasificaci\xF3n de oraciones, reconocimiento de entidades nombradas (y m\xE1s generalmente clasificaci\xF3n de palabras) y respuesta extractiva a preguntas."),F=d(),B=t("p"),oe=f("Los miembros de esta familia de modelos incluyen:"),G=d(),i=t("ul"),I=t("li"),g=t("a"),te=f("ALBERT"),re=d(),C=t("li"),w=t("a"),le=f("BERT"),se=d(),S=t("li"),L=t("a"),ne=f("DistilBERT"),ie=d(),k=t("li"),A=t("a"),ce=f("ELECTRA"),de=d(),N=t("li"),R=t("a"),me=f("RoBERTa"),this.h()},l(e){const s=ze('[data-svelte="svelte-1phssyn"]',document.head);h=r(s,"META",{name:!0,content:!0}),s.forEach(a),j=m(e),_=r(e,"H1",{class:!0});var O=l(_);E=r(O,"A",{id:!0,class:!0,href:!0});var $e=l(E);P=r($e,"SPAN",{});var ye=l(P);ue($.$$.fragment,ye),ye.forEach(a),$e.forEach(a),K=m(O),x=r(O,"SPAN",{});var be=l(x);V=u(be,"Modelos de codificadores"),be.forEach(a),O.forEach(a),z=m(e),ue(y.$$.fragment,e),U=m(e),ue(b.$$.fragment,e),D=m(e),v=r(e,"P",{});var Q=l(v);W=u(Q,"Los modelos de codificadores usan \xFAnicamente el codificador del Transformador. En cada etapa, las capas de atenci\xF3n pueden acceder a todas las palabras de la oraci\xF3n inicial. Estos modelos se caracterizan generalmente por tener atenci\xF3n \u201Cbidireccional\u201D y se suelen llamar modelos "),M=r(Q,"EM",{});var ge=l(M);X=u(ge,"auto-encoding"),ge.forEach(a),Z=u(Q,"."),Q.forEach(a),J=m(e),T=r(e,"P",{});var we=l(T);ee=u(we,"El preentrenamiento de estos modelos generalmente gira en torno a corromper de alguna manera una oraci\xF3n dada (por ejemplo, ocultando aleat\xF3riamente palabras en ella) y pidi\xE9ndole al modelo que encuentre o reconstruya la oraci\xF3n inicial."),we.forEach(a),Y=m(e),q=r(e,"P",{});var Le=l(q);ae=u(Le,"Los modelos de codificadores son m\xE1s adecuados para tareas que requieren un entendimiento de la oraci\xF3n completa, como la clasificaci\xF3n de oraciones, reconocimiento de entidades nombradas (y m\xE1s generalmente clasificaci\xF3n de palabras) y respuesta extractiva a preguntas."),Le.forEach(a),F=m(e),B=r(e,"P",{});var Ae=l(B);oe=u(Ae,"Los miembros de esta familia de modelos incluyen:"),Ae.forEach(a),G=m(e),i=r(e,"UL",{});var p=l(i);I=r(p,"LI",{});var Re=l(I);g=r(Re,"A",{href:!0,rel:!0});var Te=l(g);te=u(Te,"ALBERT"),Te.forEach(a),Re.forEach(a),re=m(p),C=r(p,"LI",{});var qe=l(C);w=r(qe,"A",{href:!0,rel:!0});var Be=l(w);le=u(Be,"BERT"),Be.forEach(a),qe.forEach(a),se=m(p),S=r(p,"LI",{});var Pe=l(S);L=r(Pe,"A",{href:!0,rel:!0});var xe=l(L);ne=u(xe,"DistilBERT"),xe.forEach(a),Pe.forEach(a),ie=m(p),k=r(p,"LI",{});var Me=l(k);A=r(Me,"A",{href:!0,rel:!0});var Ie=l(A);ce=u(Ie,"ELECTRA"),Ie.forEach(a),Me.forEach(a),de=m(p),N=r(p,"LI",{});var Ce=l(N);R=r(Ce,"A",{href:!0,rel:!0});var Se=l(R);me=u(Se,"RoBERTa"),Se.forEach(a),Ce.forEach(a),p.forEach(a),this.h()},h(){n(h,"name","hf:doc:metadata"),n(h,"content",JSON.stringify(He)),n(E,"id","modelos-de-codificadores"),n(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),n(E,"href","#modelos-de-codificadores"),n(_,"class","relative group"),n(g,"href","https://huggingface.co/transformers/model_doc/albert.html"),n(g,"rel","nofollow"),n(w,"href","https://huggingface.co/transformers/model_doc/bert.html"),n(w,"rel","nofollow"),n(L,"href","https://huggingface.co/transformers/model_doc/distilbert.html"),n(L,"rel","nofollow"),n(A,"href","https://huggingface.co/transformers/model_doc/electra.html"),n(A,"rel","nofollow"),n(R,"href","https://huggingface.co/transformers/model_doc/roberta.html"),n(R,"rel","nofollow")},m(e,s){o(document.head,h),c(e,j,s),c(e,_,s),o(_,E),o(E,P),pe($,P,null),o(_,K),o(_,x),o(x,V),c(e,z,s),pe(y,e,s),c(e,U,s),pe(b,e,s),c(e,D,s),c(e,v,s),o(v,W),o(v,M),o(M,X),o(v,Z),c(e,J,s),c(e,T,s),o(T,ee),c(e,Y,s),c(e,q,s),o(q,ae),c(e,F,s),c(e,B,s),o(B,oe),c(e,G,s),c(e,i,s),o(i,I),o(I,g),o(g,te),o(i,re),o(i,C),o(C,w),o(w,le),o(i,se),o(i,S),o(S,L),o(L,ne),o(i,ie),o(i,k),o(k,A),o(A,ce),o(i,de),o(i,N),o(N,R),o(R,me),H=!0},p:Ue,i(e){H||(he($.$$.fragment,e),he(y.$$.fragment,e),he(b.$$.fragment,e),H=!0)},o(e){_e($.$$.fragment,e),_e(y.$$.fragment,e),_e(b.$$.fragment,e),H=!1},d(e){a(h),e&&a(j),e&&a(_),Ee($),e&&a(z),Ee(y,e),e&&a(U),Ee(b,e),e&&a(D),e&&a(v),e&&a(J),e&&a(T),e&&a(Y),e&&a(q),e&&a(F),e&&a(B),e&&a(G),e&&a(i)}}}const He={local:"modelos-de-codificadores",title:"Modelos de codificadores"};function Oe(ve){return De(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Xe extends ke{constructor(h){super();Ne(this,h,Oe,Ge,je,{})}}export{Xe as default,He as metadata};
