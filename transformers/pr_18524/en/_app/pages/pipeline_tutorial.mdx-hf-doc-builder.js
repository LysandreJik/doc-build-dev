import{S as bn,i as An,s as qn,e as r,k as h,w as u,t,M as Pn,c as o,d as a,m as c,a as i,x as d,h as n,b as f,N as Sn,G as s,g as p,y as g,q as _,o as v,B as k,v as Tn}from"../chunks/vendor-hf-doc-builder.js";import{T as Mn}from"../chunks/Tip-hf-doc-builder.js";import{I as is}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as q}from"../chunks/CodeBlock-hf-doc-builder.js";function zn(ps){let m,D,$,w,z;return{c(){m=r("p"),D=t("Take a look at the "),$=r("a"),w=t("pipeline()"),z=t(" documentation for a complete list of supported tasks."),this.h()},l(x){m=o(x,"P",{});var P=i(m);D=n(P,"Take a look at the "),$=o(P,"A",{href:!0});var N=i($);w=n(N,"pipeline()"),N.forEach(a),z=n(P," documentation for a complete list of supported tasks."),P.forEach(a),this.h()},h(){f($,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline")},m(x,P){p(x,m,P),s(m,D),s(m,$),s($,w),s(m,z)},d(x){x&&a(m)}}}function Fn(ps){let m,D,$,w,z,x,P,N,ta,fs,E,na,ye,la,ra,Y,oa,ia,xe,pa,fa,hs,S,Z,ha,we,ca,ma,ua,Qe,da,ga,ee,_a,Ee,va,ka,cs,H,ms,F,R,Xe,se,$a,Ye,ja,us,b,ya,be,xa,wa,Ae,Ea,ba,qe,Aa,qa,ds,Pe,ae,Pa,Se,Sa,Ta,gs,te,_s,ne,le,Ma,Te,za,Fa,vs,re,ks,Me,La,$s,oe,js,y,Ca,ze,Ia,Da,Ze,Na,Ha,Fe,Ra,Oa,es,Ka,Ua,ys,ie,xs,L,O,ss,pe,Ga,as,Va,ws,j,Ba,Le,Wa,Ja,fe,Qa,Xa,ts,Ya,Za,Ce,et,st,Ie,at,tt,Es,he,bs,K,nt,De,lt,rt,As,ce,qs,U,ot,Ne,it,pt,Ps,me,Ss,C,G,ns,ue,ft,ls,ht,Ts,V,ct,He,mt,ut,Ms,Re,dt,zs,de,Fs,T,gt,ge,_t,vt,Oe,kt,$t,Ls,_e,Cs,B,jt,Ke,yt,xt,Is,ve,Ds,I,W,rs,ke,wt,os,Et,Ns,J,bt,Ue,At,qt,Hs,Ge,Pt,Rs,Ve,Be,St,Os,$e,Ks;return x=new is({}),H=new Mn({props:{$$slots:{default:[zn]},$$scope:{ctx:ps}}}),se=new is({}),te=new q({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>)`}}),re=new q({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Iron-priests at the door to the east, and thirteen for the Lord Kings at the end of the mountain&#x27;</span>}]`}}),oe=new q({props:{code:`generator(
    [
        "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
        "Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne",
    ]
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;Nine for Mortal Men, doomed to die, One for the Dark Lord on his dark throne&quot;</span>,
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),ie=new q({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone",
    num_return_sequences=2,
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>,
<span class="hljs-meta">... </span>    num_return_sequences=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`}}),pe=new is({}),he=new q({props:{code:`from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("distilgpt2")
model = AutoModelForCausalLM.from_pretrained("distilgpt2")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilgpt2&quot;</span>)`}}),ce=new q({props:{code:`from transformers import pipeline

generator = pipeline(task="text-generation", model=model, tokenizer=tokenizer)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(task=<span class="hljs-string">&quot;text-generation&quot;</span>, model=model, tokenizer=tokenizer)`}}),me=new q({props:{code:`generator(
    "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone"
)  # doctest: +SKIP`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generator(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone&quot;</span>
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, Seven for the Dragon-lords (for them to rule in a world ruled by their rulers, and all who live within the realm&#x27;</span>}]`}}),ue=new is({}),de=new q({props:{code:`from datasets import load_dataset
import torch

torch.manual_seed(42)
ds = load_dataset("hf-internal-testing/librispeech_asr_demo", "clean", split="validation")
audio_file = ds[0]["audio"]["path"]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>torch.manual_seed(<span class="hljs-number">42</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;hf-internal-testing/librispeech_asr_demo&quot;</span>, <span class="hljs-string">&quot;clean&quot;</span>, split=<span class="hljs-string">&quot;validation&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>audio_file = ds[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;path&quot;</span>]`}}),_e=new q({props:{code:`from transformers import pipeline

audio_classifier = pipeline(
    task="audio-classification", model="ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>audio_classifier = pipeline(
<span class="hljs-meta">... </span>    task=<span class="hljs-string">&quot;audio-classification&quot;</span>, model=<span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`}}),ve=new q({props:{code:`preds = audio_classifier(audio_file)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>preds = audio_classifier(audio_file)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1315</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;calm&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1307</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;neutral&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1274</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;sad&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1261</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;fearful&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.1242</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;happy&#x27;</span>}]`}}),ke=new is({}),$e=new q({props:{code:`from transformers import pipeline

vision_classifier = pipeline(task="image-classification")
preds = vision_classifier(
    images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
)
preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
preds`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>vision_classifier = pipeline(task=<span class="hljs-string">&quot;image-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = vision_classifier(
<span class="hljs-meta">... </span>    images=<span class="hljs-string">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>preds = [{<span class="hljs-string">&quot;score&quot;</span>: <span class="hljs-built_in">round</span>(pred[<span class="hljs-string">&quot;score&quot;</span>], <span class="hljs-number">4</span>), <span class="hljs-string">&quot;label&quot;</span>: pred[<span class="hljs-string">&quot;label&quot;</span>]} <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
<span class="hljs-meta">&gt;&gt;&gt; </span>preds
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.4335</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;lynx, catamount&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0348</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;cougar, puma, catamount, mountain lion, painter, panther, Felis concolor&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0324</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;snow leopard, ounce, Panthera uncia&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0239</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;Egyptian cat&#x27;</span>}, {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0229</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;tiger cat&#x27;</span>}]`}}),{c(){m=r("meta"),D=h(),$=r("h1"),w=r("a"),z=r("span"),u(x.$$.fragment),P=h(),N=r("span"),ta=t("Pipelines for inference"),fs=h(),E=r("p"),na=t("The "),ye=r("a"),la=t("pipeline()"),ra=t(" makes it simple to use any model from the "),Y=r("a"),oa=t("Model Hub"),ia=t(" for inference on a variety of tasks such as text generation, image segmentation and audio classification. Even if you don\u2019t have experience with a specific modality or understand the code powering the models, you can still use them with the "),xe=r("a"),pa=t("pipeline()"),fa=t("! This tutorial will teach you to:"),hs=h(),S=r("ul"),Z=r("li"),ha=t("Use a "),we=r("a"),ca=t("pipeline()"),ma=t(" for inference."),ua=h(),Qe=r("li"),da=t("Use a specific tokenizer or model."),ga=h(),ee=r("li"),_a=t("Use a "),Ee=r("a"),va=t("pipeline()"),ka=t(" for audio and vision tasks."),cs=h(),u(H.$$.fragment),ms=h(),F=r("h2"),R=r("a"),Xe=r("span"),u(se.$$.fragment),$a=h(),Ye=r("span"),ja=t("Pipeline usage"),us=h(),b=r("p"),ya=t("While each task has an associated "),be=r("a"),xa=t("pipeline()"),wa=t(", it is simpler to use the general "),Ae=r("a"),Ea=t("pipeline()"),ba=t(" abstraction which contains all the specific task pipelines. The "),qe=r("a"),Aa=t("pipeline()"),qa=t(" automatically loads a default model and tokenizer capable of inference for your task."),ds=h(),Pe=r("ol"),ae=r("li"),Pa=t("Start by creating a "),Se=r("a"),Sa=t("pipeline()"),Ta=t(" and specify an inference task:"),gs=h(),u(te.$$.fragment),_s=h(),ne=r("ol"),le=r("li"),Ma=t("Pass your input text to the "),Te=r("a"),za=t("pipeline()"),Fa=t(":"),vs=h(),u(re.$$.fragment),ks=h(),Me=r("p"),La=t("If you have more than one input, pass your input as a list:"),$s=h(),u(oe.$$.fragment),js=h(),y=r("p"),Ca=t("Any additional parameters for your task can also be included in the "),ze=r("a"),Ia=t("pipeline()"),Da=t(". The "),Ze=r("code"),Na=t("text-generation"),Ha=t(" task has a "),Fe=r("a"),Ra=t("generate()"),Oa=t(" method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),es=r("code"),Ka=t("num_return_sequences"),Ua=t(" parameter:"),ys=h(),u(ie.$$.fragment),xs=h(),L=r("h3"),O=r("a"),ss=r("span"),u(pe.$$.fragment),Ga=h(),as=r("span"),Va=t("Choose a model and tokenizer"),ws=h(),j=r("p"),Ba=t("The "),Le=r("a"),Wa=t("pipeline()"),Ja=t(" accepts any model from the "),fe=r("a"),Qa=t("Model Hub"),Xa=t(". There are tags on the Model Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),ts=r("code"),Ya=t("AutoModelFor"),Za=t(" and "),Ce=r("a"),et=t("AutoTokenizer"),st=t(" class. For example, load the "),Ie=r("a"),at=t("AutoModelForCausalLM"),tt=t(" class for a causal language modeling task:"),Es=h(),u(he.$$.fragment),bs=h(),K=r("p"),nt=t("Create a "),De=r("a"),lt=t("pipeline()"),rt=t(" for your task, and specify the model and tokenizer you\u2019ve loaded:"),As=h(),u(ce.$$.fragment),qs=h(),U=r("p"),ot=t("Pass your input text to the "),Ne=r("a"),it=t("pipeline()"),pt=t(" to generate some text:"),Ps=h(),u(me.$$.fragment),Ss=h(),C=r("h2"),G=r("a"),ns=r("span"),u(ue.$$.fragment),ft=h(),ls=r("span"),ht=t("Audio pipeline"),Ts=h(),V=r("p"),ct=t("The flexibility of the "),He=r("a"),mt=t("pipeline()"),ut=t(" means it can also be extended to audio tasks."),Ms=h(),Re=r("p"),dt=t("For example, let\u2019s classify the emotion in this audio clip:"),zs=h(),u(de.$$.fragment),Fs=h(),T=r("p"),gt=t("Find an "),ge=r("a"),_t=t("audio classification"),vt=t(" model on the Model Hub for emotion recognition and load it in the "),Oe=r("a"),kt=t("pipeline()"),$t=t(":"),Ls=h(),u(_e.$$.fragment),Cs=h(),B=r("p"),jt=t("Pass the audio file to the "),Ke=r("a"),yt=t("pipeline()"),xt=t(":"),Is=h(),u(ve.$$.fragment),Ds=h(),I=r("h2"),W=r("a"),rs=r("span"),u(ke.$$.fragment),wt=h(),os=r("span"),Et=t("Vision pipeline"),Ns=h(),J=r("p"),bt=t("Finally, using a "),Ue=r("a"),At=t("pipeline()"),qt=t(" for vision tasks is practically identical."),Hs=h(),Ge=r("p"),Pt=t("Specify your vision task and pass your image to the classifier. The imaage can be a link or a local path to the image. For example, what species of cat is shown below?"),Rs=h(),Ve=r("p"),Be=r("img"),Os=h(),u($e.$$.fragment),this.h()},l(e){const l=Pn('[data-svelte="svelte-1phssyn"]',document.head);m=o(l,"META",{name:!0,content:!0}),l.forEach(a),D=c(e),$=o(e,"H1",{class:!0});var je=i($);w=o(je,"A",{id:!0,class:!0,href:!0});var Tt=i(w);z=o(Tt,"SPAN",{});var Mt=i(z);d(x.$$.fragment,Mt),Mt.forEach(a),Tt.forEach(a),P=c(je),N=o(je,"SPAN",{});var zt=i(N);ta=n(zt,"Pipelines for inference"),zt.forEach(a),je.forEach(a),fs=c(e),E=o(e,"P",{});var Q=i(E);na=n(Q,"The "),ye=o(Q,"A",{href:!0});var Ft=i(ye);la=n(Ft,"pipeline()"),Ft.forEach(a),ra=n(Q," makes it simple to use any model from the "),Y=o(Q,"A",{href:!0,rel:!0});var Lt=i(Y);oa=n(Lt,"Model Hub"),Lt.forEach(a),ia=n(Q," for inference on a variety of tasks such as text generation, image segmentation and audio classification. Even if you don\u2019t have experience with a specific modality or understand the code powering the models, you can still use them with the "),xe=o(Q,"A",{href:!0});var Ct=i(xe);pa=n(Ct,"pipeline()"),Ct.forEach(a),fa=n(Q,"! This tutorial will teach you to:"),Q.forEach(a),hs=c(e),S=o(e,"UL",{});var We=i(S);Z=o(We,"LI",{});var Us=i(Z);ha=n(Us,"Use a "),we=o(Us,"A",{href:!0});var It=i(we);ca=n(It,"pipeline()"),It.forEach(a),ma=n(Us," for inference."),Us.forEach(a),ua=c(We),Qe=o(We,"LI",{});var Dt=i(Qe);da=n(Dt,"Use a specific tokenizer or model."),Dt.forEach(a),ga=c(We),ee=o(We,"LI",{});var Gs=i(ee);_a=n(Gs,"Use a "),Ee=o(Gs,"A",{href:!0});var Nt=i(Ee);va=n(Nt,"pipeline()"),Nt.forEach(a),ka=n(Gs," for audio and vision tasks."),Gs.forEach(a),We.forEach(a),cs=c(e),d(H.$$.fragment,e),ms=c(e),F=o(e,"H2",{class:!0});var Vs=i(F);R=o(Vs,"A",{id:!0,class:!0,href:!0});var Ht=i(R);Xe=o(Ht,"SPAN",{});var Rt=i(Xe);d(se.$$.fragment,Rt),Rt.forEach(a),Ht.forEach(a),$a=c(Vs),Ye=o(Vs,"SPAN",{});var Ot=i(Ye);ja=n(Ot,"Pipeline usage"),Ot.forEach(a),Vs.forEach(a),us=c(e),b=o(e,"P",{});var X=i(b);ya=n(X,"While each task has an associated "),be=o(X,"A",{href:!0});var Kt=i(be);xa=n(Kt,"pipeline()"),Kt.forEach(a),wa=n(X,", it is simpler to use the general "),Ae=o(X,"A",{href:!0});var Ut=i(Ae);Ea=n(Ut,"pipeline()"),Ut.forEach(a),ba=n(X," abstraction which contains all the specific task pipelines. The "),qe=o(X,"A",{href:!0});var Gt=i(qe);Aa=n(Gt,"pipeline()"),Gt.forEach(a),qa=n(X," automatically loads a default model and tokenizer capable of inference for your task."),X.forEach(a),ds=c(e),Pe=o(e,"OL",{});var Vt=i(Pe);ae=o(Vt,"LI",{});var Bs=i(ae);Pa=n(Bs,"Start by creating a "),Se=o(Bs,"A",{href:!0});var Bt=i(Se);Sa=n(Bt,"pipeline()"),Bt.forEach(a),Ta=n(Bs," and specify an inference task:"),Bs.forEach(a),Vt.forEach(a),gs=c(e),d(te.$$.fragment,e),_s=c(e),ne=o(e,"OL",{start:!0});var Wt=i(ne);le=o(Wt,"LI",{});var Ws=i(le);Ma=n(Ws,"Pass your input text to the "),Te=o(Ws,"A",{href:!0});var Jt=i(Te);za=n(Jt,"pipeline()"),Jt.forEach(a),Fa=n(Ws,":"),Ws.forEach(a),Wt.forEach(a),vs=c(e),d(re.$$.fragment,e),ks=c(e),Me=o(e,"P",{});var Qt=i(Me);La=n(Qt,"If you have more than one input, pass your input as a list:"),Qt.forEach(a),$s=c(e),d(oe.$$.fragment,e),js=c(e),y=o(e,"P",{});var M=i(y);Ca=n(M,"Any additional parameters for your task can also be included in the "),ze=o(M,"A",{href:!0});var Xt=i(ze);Ia=n(Xt,"pipeline()"),Xt.forEach(a),Da=n(M,". The "),Ze=o(M,"CODE",{});var Yt=i(Ze);Na=n(Yt,"text-generation"),Yt.forEach(a),Ha=n(M," task has a "),Fe=o(M,"A",{href:!0});var Zt=i(Fe);Ra=n(Zt,"generate()"),Zt.forEach(a),Oa=n(M," method with several parameters for controlling the output. For example, if you want to generate more than one output, set the "),es=o(M,"CODE",{});var en=i(es);Ka=n(en,"num_return_sequences"),en.forEach(a),Ua=n(M," parameter:"),M.forEach(a),ys=c(e),d(ie.$$.fragment,e),xs=c(e),L=o(e,"H3",{class:!0});var Js=i(L);O=o(Js,"A",{id:!0,class:!0,href:!0});var sn=i(O);ss=o(sn,"SPAN",{});var an=i(ss);d(pe.$$.fragment,an),an.forEach(a),sn.forEach(a),Ga=c(Js),as=o(Js,"SPAN",{});var tn=i(as);Va=n(tn,"Choose a model and tokenizer"),tn.forEach(a),Js.forEach(a),ws=c(e),j=o(e,"P",{});var A=i(j);Ba=n(A,"The "),Le=o(A,"A",{href:!0});var nn=i(Le);Wa=n(nn,"pipeline()"),nn.forEach(a),Ja=n(A," accepts any model from the "),fe=o(A,"A",{href:!0,rel:!0});var ln=i(fe);Qa=n(ln,"Model Hub"),ln.forEach(a),Xa=n(A,". There are tags on the Model Hub that allow you to filter for a model you\u2019d like to use for your task. Once you\u2019ve picked an appropriate model, load it with the corresponding "),ts=o(A,"CODE",{});var rn=i(ts);Ya=n(rn,"AutoModelFor"),rn.forEach(a),Za=n(A," and "),Ce=o(A,"A",{href:!0});var on=i(Ce);et=n(on,"AutoTokenizer"),on.forEach(a),st=n(A," class. For example, load the "),Ie=o(A,"A",{href:!0});var pn=i(Ie);at=n(pn,"AutoModelForCausalLM"),pn.forEach(a),tt=n(A," class for a causal language modeling task:"),A.forEach(a),Es=c(e),d(he.$$.fragment,e),bs=c(e),K=o(e,"P",{});var Qs=i(K);nt=n(Qs,"Create a "),De=o(Qs,"A",{href:!0});var fn=i(De);lt=n(fn,"pipeline()"),fn.forEach(a),rt=n(Qs," for your task, and specify the model and tokenizer you\u2019ve loaded:"),Qs.forEach(a),As=c(e),d(ce.$$.fragment,e),qs=c(e),U=o(e,"P",{});var Xs=i(U);ot=n(Xs,"Pass your input text to the "),Ne=o(Xs,"A",{href:!0});var hn=i(Ne);it=n(hn,"pipeline()"),hn.forEach(a),pt=n(Xs," to generate some text:"),Xs.forEach(a),Ps=c(e),d(me.$$.fragment,e),Ss=c(e),C=o(e,"H2",{class:!0});var Ys=i(C);G=o(Ys,"A",{id:!0,class:!0,href:!0});var cn=i(G);ns=o(cn,"SPAN",{});var mn=i(ns);d(ue.$$.fragment,mn),mn.forEach(a),cn.forEach(a),ft=c(Ys),ls=o(Ys,"SPAN",{});var un=i(ls);ht=n(un,"Audio pipeline"),un.forEach(a),Ys.forEach(a),Ts=c(e),V=o(e,"P",{});var Zs=i(V);ct=n(Zs,"The flexibility of the "),He=o(Zs,"A",{href:!0});var dn=i(He);mt=n(dn,"pipeline()"),dn.forEach(a),ut=n(Zs," means it can also be extended to audio tasks."),Zs.forEach(a),Ms=c(e),Re=o(e,"P",{});var gn=i(Re);dt=n(gn,"For example, let\u2019s classify the emotion in this audio clip:"),gn.forEach(a),zs=c(e),d(de.$$.fragment,e),Fs=c(e),T=o(e,"P",{});var Je=i(T);gt=n(Je,"Find an "),ge=o(Je,"A",{href:!0,rel:!0});var _n=i(ge);_t=n(_n,"audio classification"),_n.forEach(a),vt=n(Je," model on the Model Hub for emotion recognition and load it in the "),Oe=o(Je,"A",{href:!0});var vn=i(Oe);kt=n(vn,"pipeline()"),vn.forEach(a),$t=n(Je,":"),Je.forEach(a),Ls=c(e),d(_e.$$.fragment,e),Cs=c(e),B=o(e,"P",{});var ea=i(B);jt=n(ea,"Pass the audio file to the "),Ke=o(ea,"A",{href:!0});var kn=i(Ke);yt=n(kn,"pipeline()"),kn.forEach(a),xt=n(ea,":"),ea.forEach(a),Is=c(e),d(ve.$$.fragment,e),Ds=c(e),I=o(e,"H2",{class:!0});var sa=i(I);W=o(sa,"A",{id:!0,class:!0,href:!0});var $n=i(W);rs=o($n,"SPAN",{});var jn=i(rs);d(ke.$$.fragment,jn),jn.forEach(a),$n.forEach(a),wt=c(sa),os=o(sa,"SPAN",{});var yn=i(os);Et=n(yn,"Vision pipeline"),yn.forEach(a),sa.forEach(a),Ns=c(e),J=o(e,"P",{});var aa=i(J);bt=n(aa,"Finally, using a "),Ue=o(aa,"A",{href:!0});var xn=i(Ue);At=n(xn,"pipeline()"),xn.forEach(a),qt=n(aa," for vision tasks is practically identical."),aa.forEach(a),Hs=c(e),Ge=o(e,"P",{});var wn=i(Ge);Pt=n(wn,"Specify your vision task and pass your image to the classifier. The imaage can be a link or a local path to the image. For example, what species of cat is shown below?"),wn.forEach(a),Rs=c(e),Ve=o(e,"P",{});var En=i(Ve);Be=o(En,"IMG",{src:!0,alt:!0}),En.forEach(a),Os=c(e),d($e.$$.fragment,e),this.h()},h(){f(m,"name","hf:doc:metadata"),f(m,"content",JSON.stringify(Ln)),f(w,"id","pipelines-for-inference"),f(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(w,"href","#pipelines-for-inference"),f($,"class","relative group"),f(ye,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(Y,"href","https://huggingface.co/models"),f(Y,"rel","nofollow"),f(xe,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(we,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(Ee,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(R,"id","pipeline-usage"),f(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(R,"href","#pipeline-usage"),f(F,"class","relative group"),f(be,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(Ae,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(qe,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(Se,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(Te,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(ne,"start","2"),f(ze,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(Fe,"href","/docs/transformers/pr_18524/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate"),f(O,"id","choose-a-model-and-tokenizer"),f(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(O,"href","#choose-a-model-and-tokenizer"),f(L,"class","relative group"),f(Le,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(fe,"href","https://huggingface.co/models"),f(fe,"rel","nofollow"),f(Ce,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoTokenizer"),f(Ie,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoModelForCausalLM"),f(De,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(Ne,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(G,"id","audio-pipeline"),f(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(G,"href","#audio-pipeline"),f(C,"class","relative group"),f(He,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(ge,"href","https://huggingface.co/models?pipeline_tag=audio-classification"),f(ge,"rel","nofollow"),f(Oe,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(Ke,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),f(W,"id","vision-pipeline"),f(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(W,"href","#vision-pipeline"),f(I,"class","relative group"),f(Ue,"href","/docs/transformers/pr_18524/en/main_classes/pipelines#transformers.pipeline"),Sn(Be.src,St="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg")||f(Be,"src",St),f(Be,"alt","pipeline-cat-chonk")},m(e,l){s(document.head,m),p(e,D,l),p(e,$,l),s($,w),s(w,z),g(x,z,null),s($,P),s($,N),s(N,ta),p(e,fs,l),p(e,E,l),s(E,na),s(E,ye),s(ye,la),s(E,ra),s(E,Y),s(Y,oa),s(E,ia),s(E,xe),s(xe,pa),s(E,fa),p(e,hs,l),p(e,S,l),s(S,Z),s(Z,ha),s(Z,we),s(we,ca),s(Z,ma),s(S,ua),s(S,Qe),s(Qe,da),s(S,ga),s(S,ee),s(ee,_a),s(ee,Ee),s(Ee,va),s(ee,ka),p(e,cs,l),g(H,e,l),p(e,ms,l),p(e,F,l),s(F,R),s(R,Xe),g(se,Xe,null),s(F,$a),s(F,Ye),s(Ye,ja),p(e,us,l),p(e,b,l),s(b,ya),s(b,be),s(be,xa),s(b,wa),s(b,Ae),s(Ae,Ea),s(b,ba),s(b,qe),s(qe,Aa),s(b,qa),p(e,ds,l),p(e,Pe,l),s(Pe,ae),s(ae,Pa),s(ae,Se),s(Se,Sa),s(ae,Ta),p(e,gs,l),g(te,e,l),p(e,_s,l),p(e,ne,l),s(ne,le),s(le,Ma),s(le,Te),s(Te,za),s(le,Fa),p(e,vs,l),g(re,e,l),p(e,ks,l),p(e,Me,l),s(Me,La),p(e,$s,l),g(oe,e,l),p(e,js,l),p(e,y,l),s(y,Ca),s(y,ze),s(ze,Ia),s(y,Da),s(y,Ze),s(Ze,Na),s(y,Ha),s(y,Fe),s(Fe,Ra),s(y,Oa),s(y,es),s(es,Ka),s(y,Ua),p(e,ys,l),g(ie,e,l),p(e,xs,l),p(e,L,l),s(L,O),s(O,ss),g(pe,ss,null),s(L,Ga),s(L,as),s(as,Va),p(e,ws,l),p(e,j,l),s(j,Ba),s(j,Le),s(Le,Wa),s(j,Ja),s(j,fe),s(fe,Qa),s(j,Xa),s(j,ts),s(ts,Ya),s(j,Za),s(j,Ce),s(Ce,et),s(j,st),s(j,Ie),s(Ie,at),s(j,tt),p(e,Es,l),g(he,e,l),p(e,bs,l),p(e,K,l),s(K,nt),s(K,De),s(De,lt),s(K,rt),p(e,As,l),g(ce,e,l),p(e,qs,l),p(e,U,l),s(U,ot),s(U,Ne),s(Ne,it),s(U,pt),p(e,Ps,l),g(me,e,l),p(e,Ss,l),p(e,C,l),s(C,G),s(G,ns),g(ue,ns,null),s(C,ft),s(C,ls),s(ls,ht),p(e,Ts,l),p(e,V,l),s(V,ct),s(V,He),s(He,mt),s(V,ut),p(e,Ms,l),p(e,Re,l),s(Re,dt),p(e,zs,l),g(de,e,l),p(e,Fs,l),p(e,T,l),s(T,gt),s(T,ge),s(ge,_t),s(T,vt),s(T,Oe),s(Oe,kt),s(T,$t),p(e,Ls,l),g(_e,e,l),p(e,Cs,l),p(e,B,l),s(B,jt),s(B,Ke),s(Ke,yt),s(B,xt),p(e,Is,l),g(ve,e,l),p(e,Ds,l),p(e,I,l),s(I,W),s(W,rs),g(ke,rs,null),s(I,wt),s(I,os),s(os,Et),p(e,Ns,l),p(e,J,l),s(J,bt),s(J,Ue),s(Ue,At),s(J,qt),p(e,Hs,l),p(e,Ge,l),s(Ge,Pt),p(e,Rs,l),p(e,Ve,l),s(Ve,Be),p(e,Os,l),g($e,e,l),Ks=!0},p(e,[l]){const je={};l&2&&(je.$$scope={dirty:l,ctx:e}),H.$set(je)},i(e){Ks||(_(x.$$.fragment,e),_(H.$$.fragment,e),_(se.$$.fragment,e),_(te.$$.fragment,e),_(re.$$.fragment,e),_(oe.$$.fragment,e),_(ie.$$.fragment,e),_(pe.$$.fragment,e),_(he.$$.fragment,e),_(ce.$$.fragment,e),_(me.$$.fragment,e),_(ue.$$.fragment,e),_(de.$$.fragment,e),_(_e.$$.fragment,e),_(ve.$$.fragment,e),_(ke.$$.fragment,e),_($e.$$.fragment,e),Ks=!0)},o(e){v(x.$$.fragment,e),v(H.$$.fragment,e),v(se.$$.fragment,e),v(te.$$.fragment,e),v(re.$$.fragment,e),v(oe.$$.fragment,e),v(ie.$$.fragment,e),v(pe.$$.fragment,e),v(he.$$.fragment,e),v(ce.$$.fragment,e),v(me.$$.fragment,e),v(ue.$$.fragment,e),v(de.$$.fragment,e),v(_e.$$.fragment,e),v(ve.$$.fragment,e),v(ke.$$.fragment,e),v($e.$$.fragment,e),Ks=!1},d(e){a(m),e&&a(D),e&&a($),k(x),e&&a(fs),e&&a(E),e&&a(hs),e&&a(S),e&&a(cs),k(H,e),e&&a(ms),e&&a(F),k(se),e&&a(us),e&&a(b),e&&a(ds),e&&a(Pe),e&&a(gs),k(te,e),e&&a(_s),e&&a(ne),e&&a(vs),k(re,e),e&&a(ks),e&&a(Me),e&&a($s),k(oe,e),e&&a(js),e&&a(y),e&&a(ys),k(ie,e),e&&a(xs),e&&a(L),k(pe),e&&a(ws),e&&a(j),e&&a(Es),k(he,e),e&&a(bs),e&&a(K),e&&a(As),k(ce,e),e&&a(qs),e&&a(U),e&&a(Ps),k(me,e),e&&a(Ss),e&&a(C),k(ue),e&&a(Ts),e&&a(V),e&&a(Ms),e&&a(Re),e&&a(zs),k(de,e),e&&a(Fs),e&&a(T),e&&a(Ls),k(_e,e),e&&a(Cs),e&&a(B),e&&a(Is),k(ve,e),e&&a(Ds),e&&a(I),k(ke),e&&a(Ns),e&&a(J),e&&a(Hs),e&&a(Ge),e&&a(Rs),e&&a(Ve),e&&a(Os),k($e,e)}}}const Ln={local:"pipelines-for-inference",sections:[{local:"pipeline-usage",sections:[{local:"choose-a-model-and-tokenizer",title:"Choose a model and tokenizer"}],title:"Pipeline usage"},{local:"audio-pipeline",title:"Audio pipeline"},{local:"vision-pipeline",title:"Vision pipeline"}],title:"Pipelines for inference"};function Cn(ps){return Tn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Rn extends bn{constructor(m){super();An(this,m,Cn,Fn,qn,{})}}export{Rn as default,Ln as metadata};
