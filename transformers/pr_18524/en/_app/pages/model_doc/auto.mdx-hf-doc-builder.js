import{S as eea,i as oea,s as rea,e as a,k as l,w as F,t as o,M as tea,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as aea,L as N}from"../../chunks/vendor-hf-doc-builder.js";import{T as cdt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as I}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function nea($){let g,v,p,m,_,d,h,Ao,Ii,zf,dt,Ni,qi,VL,Wf,Oe,Qe,ji,Dn,XL,Gn,On,zL,Di,Vn,WL,Gi,Qf,Ia;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Ao=o(`, make sure its
`),Ii=a("code"),zf=o("model_type"),dt=o(" attribute is set to the same key you use when registering the config (here "),Ni=a("code"),qi=o('"new-model"'),VL=o(")."),Wf=l(),Oe=a("p"),Qe=o("Likewise, if your "),ji=a("code"),Dn=o("NewModel"),XL=o(" is a subclass of "),Gn=a("a"),On=o("PreTrainedModel"),zL=o(`, make sure its
`),Di=a("code"),Vn=o("config_class"),WL=o(` attribute is set to the same class you use when registering the model (here
`),Gi=a("code"),Qf=o("NewModelConfig"),Ia=o(")."),this.h()},l(Ue){g=n(Ue,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var kR=s(p);m=r(kR,"NewModelConfig"),kR.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Oi=s(d);h=r(Oi,"PretrainedConfig"),Oi.forEach(t),Ao=r(Ae,`, make sure its
`),Ii=n(Ae,"CODE",{});var SR=s(Ii);zf=r(SR,"model_type"),SR.forEach(t),dt=r(Ae," attribute is set to the same key you use when registering the config (here "),Ni=n(Ae,"CODE",{});var RR=s(Ni);qi=r(RR,'"new-model"'),RR.forEach(t),VL=r(Ae,")."),Ae.forEach(t),Wf=i(Ue),Oe=n(Ue,"P",{});var Lo=s(Oe);Qe=r(Lo,"Likewise, if your "),ji=n(Lo,"CODE",{});var Na=s(ji);Dn=r(Na,"NewModel"),Na.forEach(t),XL=r(Lo," is a subclass of "),Gn=n(Lo,"A",{href:!0});var PR=s(Gn);On=r(PR,"PreTrainedModel"),PR.forEach(t),zL=r(Lo,`, make sure its
`),Di=n(Lo,"CODE",{});var Uf=s(Di);Vn=r(Uf,"config_class"),Uf.forEach(t),WL=r(Lo,` attribute is set to the same class you use when registering the model (here
`),Gi=n(Lo,"CODE",{});var BR=s(Gi);Qf=r(BR,"NewModelConfig"),BR.forEach(t),Ia=r(Lo,")."),Lo.forEach(t),this.h()},h(){c(Gn,"href","/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel")},m(Ue,Ae){b(Ue,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Ao),e(g,Ii),e(Ii,zf),e(g,dt),e(g,Ni),e(Ni,qi),e(g,VL),b(Ue,Wf,Ae),b(Ue,Oe,Ae),e(Oe,Qe),e(Oe,ji),e(ji,Dn),e(Oe,XL),e(Oe,Gn),e(Gn,On),e(Oe,zL),e(Oe,Di),e(Di,Vn),e(Oe,WL),e(Oe,Gi),e(Gi,Qf),e(Oe,Ia)},d(Ue){Ue&&t(g),Ue&&t(Wf),Ue&&t(Oe)}}}function sea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iea($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Ao=s(p);m=r(Ao,"use_auth_token=True"),Ao.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function dea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cea($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Ao=s(p);m=r(Ao,"use_auth_token=True"),Ao.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function fea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _ea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Eea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Aea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $ea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Iea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Oea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ooa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function roa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function toa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function noa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function soa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function loa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ioa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function doa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function coa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function foa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function moa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function goa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function poa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _oa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function boa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function voa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Foa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Toa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Moa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Eoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Coa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function woa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Aoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Loa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $oa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function koa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Soa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Roa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Poa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Boa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ioa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Noa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function joa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Doa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Goa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ooa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Voa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Woa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Joa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Koa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function era($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ora($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ara($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sra($){let g,v,p,m,_,d,h,Ao,Ii,zf,dt,Ni,qi,VL,Wf,Oe,Qe,ji,Dn,XL,Gn,On,zL,Di,Vn,WL,Gi,Qf,Ia,Ue,Ae,kR,Oi,SR,RR,Lo,Na,PR,Uf,BR,aYe,jWe,Vi,Hf,Zne,QL,nYe,ese,sYe,DWe,Xn,lYe,ose,iYe,dYe,rse,cYe,fYe,GWe,UL,OWe,IR,mYe,VWe,Jf,XWe,Xi,Yf,tse,HL,gYe,ase,hYe,zWe,yo,JL,pYe,YL,_Ye,NR,uYe,bYe,vYe,KL,FYe,nse,TYe,MYe,EYe,$r,ZL,CYe,sse,wYe,AYe,zi,LYe,lse,yYe,xYe,ise,$Ye,kYe,SYe,A,Kf,dse,RYe,PYe,qR,BYe,IYe,NYe,Zf,cse,qYe,jYe,jR,DYe,GYe,OYe,em,fse,VYe,XYe,DR,zYe,WYe,QYe,om,mse,UYe,HYe,GR,JYe,YYe,KYe,rm,gse,ZYe,eKe,OR,oKe,rKe,tKe,tm,hse,aKe,nKe,VR,sKe,lKe,iKe,am,pse,dKe,cKe,XR,fKe,mKe,gKe,nm,_se,hKe,pKe,zR,_Ke,uKe,bKe,sm,use,vKe,FKe,WR,TKe,MKe,EKe,lm,bse,CKe,wKe,QR,AKe,LKe,yKe,im,vse,xKe,$Ke,UR,kKe,SKe,RKe,dm,Fse,PKe,BKe,HR,IKe,NKe,qKe,cm,Tse,jKe,DKe,JR,GKe,OKe,VKe,fm,Mse,XKe,zKe,YR,WKe,QKe,UKe,mm,Ese,HKe,JKe,KR,YKe,KKe,ZKe,gm,Cse,eZe,oZe,ZR,rZe,tZe,aZe,hm,wse,nZe,sZe,eP,lZe,iZe,dZe,pm,Ase,cZe,fZe,oP,mZe,gZe,hZe,_m,Lse,pZe,_Ze,rP,uZe,bZe,vZe,um,yse,FZe,TZe,tP,MZe,EZe,CZe,bm,xse,wZe,AZe,aP,LZe,yZe,xZe,vm,$se,$Ze,kZe,nP,SZe,RZe,PZe,Fm,kse,BZe,IZe,sP,NZe,qZe,jZe,Tm,Sse,DZe,GZe,lP,OZe,VZe,XZe,Mm,Rse,zZe,WZe,iP,QZe,UZe,HZe,Em,Pse,JZe,YZe,dP,KZe,ZZe,eeo,Cm,Bse,oeo,reo,cP,teo,aeo,neo,wm,Ise,seo,leo,fP,ieo,deo,ceo,Am,Nse,feo,meo,mP,geo,heo,peo,Lm,qse,_eo,ueo,gP,beo,veo,Feo,ym,jse,Teo,Meo,hP,Eeo,Ceo,weo,xm,Dse,Aeo,Leo,pP,yeo,xeo,$eo,$m,Gse,keo,Seo,_P,Reo,Peo,Beo,km,Ose,Ieo,Neo,uP,qeo,jeo,Deo,Sm,Vse,Geo,Oeo,bP,Veo,Xeo,zeo,Rm,Xse,Weo,Qeo,vP,Ueo,Heo,Jeo,Pm,zse,Yeo,Keo,FP,Zeo,eoo,ooo,Bm,Wse,roo,too,TP,aoo,noo,soo,Im,Qse,loo,ioo,MP,doo,coo,foo,Nm,Use,moo,goo,EP,hoo,poo,_oo,qm,Hse,uoo,boo,CP,voo,Foo,Too,jm,Jse,Moo,Eoo,wP,Coo,woo,Aoo,Dm,Yse,Loo,yoo,AP,xoo,$oo,koo,Gm,Kse,Soo,Roo,LP,Poo,Boo,Ioo,Om,Zse,Noo,qoo,yP,joo,Doo,Goo,Vm,ele,Ooo,Voo,xP,Xoo,zoo,Woo,Xm,ole,Qoo,Uoo,$P,Hoo,Joo,Yoo,zm,rle,Koo,Zoo,kP,ero,oro,rro,Wm,tle,tro,aro,SP,nro,sro,lro,Qm,ale,iro,dro,RP,cro,fro,mro,Um,nle,gro,hro,PP,pro,_ro,uro,Hm,sle,bro,vro,BP,Fro,Tro,Mro,Jm,lle,Ero,Cro,IP,wro,Aro,Lro,Ym,ile,yro,xro,NP,$ro,kro,Sro,Km,dle,Rro,Pro,qP,Bro,Iro,Nro,Zm,cle,qro,jro,jP,Dro,Gro,Oro,eg,fle,Vro,Xro,DP,zro,Wro,Qro,og,mle,Uro,Hro,GP,Jro,Yro,Kro,rg,gle,Zro,eto,OP,oto,rto,tto,tg,hle,ato,nto,VP,sto,lto,ito,ag,ple,dto,cto,XP,fto,mto,gto,ng,_le,hto,pto,zP,_to,uto,bto,sg,ule,vto,Fto,WP,Tto,Mto,Eto,lg,ble,Cto,wto,QP,Ato,Lto,yto,ig,vle,xto,$to,UP,kto,Sto,Rto,dg,Fle,Pto,Bto,HP,Ito,Nto,qto,cg,Tle,jto,Dto,JP,Gto,Oto,Vto,fg,Mle,Xto,zto,YP,Wto,Qto,Uto,mg,Ele,Hto,Jto,KP,Yto,Kto,Zto,gg,Cle,eao,oao,ZP,rao,tao,aao,hg,wle,nao,sao,eB,lao,iao,dao,pg,Ale,cao,fao,oB,mao,gao,hao,_g,Lle,pao,_ao,rB,uao,bao,vao,ug,yle,Fao,Tao,tB,Mao,Eao,Cao,bg,xle,wao,Aao,aB,Lao,yao,xao,vg,$le,$ao,kao,nB,Sao,Rao,Pao,Fg,kle,Bao,Iao,sB,Nao,qao,jao,Tg,Sle,Dao,Gao,lB,Oao,Vao,Xao,Mg,Rle,zao,Wao,iB,Qao,Uao,Hao,Eg,Ple,Jao,Yao,dB,Kao,Zao,eno,Cg,Ble,ono,rno,cB,tno,ano,nno,wg,Ile,sno,lno,fB,ino,dno,cno,Ag,Nle,fno,mno,mB,gno,hno,pno,Lg,qle,_no,uno,gB,bno,vno,Fno,yg,jle,Tno,Mno,hB,Eno,Cno,wno,xg,Dle,Ano,Lno,pB,yno,xno,$no,$g,Gle,kno,Sno,_B,Rno,Pno,Bno,kg,Ole,Ino,Nno,uB,qno,jno,Dno,Sg,Vle,Gno,Ono,bB,Vno,Xno,zno,Rg,Xle,Wno,Qno,vB,Uno,Hno,Jno,Pg,zle,Yno,Kno,FB,Zno,eso,oso,Bg,Wle,rso,tso,TB,aso,nso,sso,Ig,Qle,lso,iso,MB,dso,cso,fso,Ng,Ule,mso,gso,EB,hso,pso,_so,qg,Hle,uso,bso,CB,vso,Fso,Tso,jg,Jle,Mso,Eso,wB,Cso,wso,Aso,Dg,Yle,Lso,yso,AB,xso,$so,kso,Gg,Kle,Sso,Rso,LB,Pso,Bso,Iso,Og,Zle,Nso,qso,yB,jso,Dso,Gso,Vg,eie,Oso,Vso,xB,Xso,zso,Wso,Xg,oie,Qso,Uso,$B,Hso,Jso,Yso,zg,rie,Kso,Zso,kB,elo,olo,rlo,Wg,tie,tlo,alo,SB,nlo,slo,llo,Qg,aie,ilo,dlo,RB,clo,flo,mlo,Ug,nie,glo,hlo,PB,plo,_lo,ulo,Hg,sie,blo,vlo,BB,Flo,Tlo,Mlo,Jg,lie,Elo,Clo,IB,wlo,Alo,Llo,Yg,iie,ylo,xlo,NB,$lo,klo,Slo,Kg,die,Rlo,Plo,qB,Blo,Ilo,Nlo,Zg,cie,qlo,jlo,jB,Dlo,Glo,Olo,eh,fie,Vlo,Xlo,DB,zlo,Wlo,Qlo,oh,mie,Ulo,Hlo,GB,Jlo,Ylo,Klo,rh,gie,Zlo,eio,OB,oio,rio,tio,th,hie,aio,nio,VB,sio,lio,iio,ah,pie,dio,cio,XB,fio,mio,gio,nh,_ie,hio,pio,zB,_io,uio,bio,sh,uie,vio,Fio,WB,Tio,Mio,Eio,lh,bie,Cio,wio,QB,Aio,Lio,yio,ih,vie,xio,$io,UB,kio,Sio,Rio,dh,Fie,Pio,Bio,HB,Iio,Nio,qio,ch,Tie,jio,Dio,JB,Gio,Oio,Vio,fh,Xio,mh,ey,zio,Mie,Wio,WWe,Wi,gh,Eie,oy,Qio,Cie,Uio,QWe,xo,ry,Hio,ty,Jio,YB,Yio,Kio,Zio,ay,edo,wie,odo,rdo,tdo,kr,ny,ado,Aie,ndo,sdo,qa,ldo,Lie,ido,ddo,yie,cdo,fdo,xie,mdo,gdo,hdo,k,zn,$ie,pdo,_do,KB,udo,bdo,ZB,vdo,Fdo,Tdo,Wn,kie,Mdo,Edo,eI,Cdo,wdo,oI,Ado,Ldo,ydo,Qn,Sie,xdo,$do,rI,kdo,Sdo,tI,Rdo,Pdo,Bdo,hh,Rie,Ido,Ndo,aI,qdo,jdo,Ddo,Un,Pie,Gdo,Odo,nI,Vdo,Xdo,sI,zdo,Wdo,Qdo,ph,Bie,Udo,Hdo,lI,Jdo,Ydo,Kdo,_h,Iie,Zdo,eco,iI,oco,rco,tco,uh,Nie,aco,nco,dI,sco,lco,ico,Hn,qie,dco,cco,cI,fco,mco,fI,gco,hco,pco,Jn,jie,_co,uco,mI,bco,vco,gI,Fco,Tco,Mco,Yn,Die,Eco,Cco,hI,wco,Aco,pI,Lco,yco,xco,bh,Gie,$co,kco,_I,Sco,Rco,Pco,vh,Oie,Bco,Ico,uI,Nco,qco,jco,Fh,Vie,Dco,Gco,bI,Oco,Vco,Xco,Kn,Xie,zco,Wco,vI,Qco,Uco,FI,Hco,Jco,Yco,Th,zie,Kco,Zco,TI,efo,ofo,rfo,Zn,Wie,tfo,afo,MI,nfo,sfo,EI,lfo,ifo,dfo,es,Qie,cfo,ffo,CI,mfo,gfo,wI,hfo,pfo,_fo,os,Uie,ufo,bfo,AI,vfo,Ffo,LI,Tfo,Mfo,Efo,rs,Hie,Cfo,wfo,yI,Afo,Lfo,xI,yfo,xfo,$fo,Mh,Jie,kfo,Sfo,$I,Rfo,Pfo,Bfo,ts,Yie,Ifo,Nfo,kI,qfo,jfo,SI,Dfo,Gfo,Ofo,as,Kie,Vfo,Xfo,RI,zfo,Wfo,PI,Qfo,Ufo,Hfo,ns,Zie,Jfo,Yfo,BI,Kfo,Zfo,II,emo,omo,rmo,ss,ede,tmo,amo,NI,nmo,smo,qI,lmo,imo,dmo,ls,ode,cmo,fmo,jI,mmo,gmo,DI,hmo,pmo,_mo,is,rde,umo,bmo,GI,vmo,Fmo,OI,Tmo,Mmo,Emo,Eh,tde,Cmo,wmo,VI,Amo,Lmo,ymo,ds,ade,xmo,$mo,XI,kmo,Smo,zI,Rmo,Pmo,Bmo,Ch,nde,Imo,Nmo,WI,qmo,jmo,Dmo,cs,sde,Gmo,Omo,QI,Vmo,Xmo,UI,zmo,Wmo,Qmo,fs,lde,Umo,Hmo,HI,Jmo,Ymo,JI,Kmo,Zmo,ego,ms,ide,ogo,rgo,YI,tgo,ago,KI,ngo,sgo,lgo,wh,dde,igo,dgo,ZI,cgo,fgo,mgo,gs,cde,ggo,hgo,eN,pgo,_go,oN,ugo,bgo,vgo,hs,fde,Fgo,Tgo,rN,Mgo,Ego,tN,Cgo,wgo,Ago,ps,mde,Lgo,ygo,aN,xgo,$go,nN,kgo,Sgo,Rgo,Ah,gde,Pgo,Bgo,sN,Igo,Ngo,qgo,_s,hde,jgo,Dgo,lN,Ggo,Ogo,iN,Vgo,Xgo,zgo,us,pde,Wgo,Qgo,dN,Ugo,Hgo,cN,Jgo,Ygo,Kgo,bs,_de,Zgo,eho,fN,oho,rho,mN,tho,aho,nho,vs,ude,sho,lho,gN,iho,dho,hN,cho,fho,mho,Fs,bde,gho,hho,pN,pho,_ho,_N,uho,bho,vho,Ts,vde,Fho,Tho,uN,Mho,Eho,bN,Cho,who,Aho,Ms,Fde,Lho,yho,vN,xho,$ho,FN,kho,Sho,Rho,Es,Tde,Pho,Bho,TN,Iho,Nho,MN,qho,jho,Dho,Lh,Mde,Gho,Oho,EN,Vho,Xho,zho,Cs,Ede,Who,Qho,CN,Uho,Hho,wN,Jho,Yho,Kho,yh,Cde,Zho,epo,AN,opo,rpo,tpo,xh,wde,apo,npo,LN,spo,lpo,ipo,ws,Ade,dpo,cpo,yN,fpo,mpo,xN,gpo,hpo,ppo,As,Lde,_po,upo,$N,bpo,vpo,kN,Fpo,Tpo,Mpo,Ls,yde,Epo,Cpo,SN,wpo,Apo,RN,Lpo,ypo,xpo,$h,xde,$po,kpo,PN,Spo,Rpo,Ppo,ys,$de,Bpo,Ipo,BN,Npo,qpo,IN,jpo,Dpo,Gpo,xs,kde,Opo,Vpo,NN,Xpo,zpo,qN,Wpo,Qpo,Upo,$s,Sde,Hpo,Jpo,jN,Ypo,Kpo,DN,Zpo,e_o,o_o,ks,Rde,r_o,t_o,GN,a_o,n_o,ON,s_o,l_o,i_o,Ss,Pde,d_o,c_o,VN,f_o,m_o,XN,g_o,h_o,p_o,Rs,Bde,__o,u_o,zN,b_o,v_o,WN,F_o,T_o,M_o,Ps,Ide,E_o,C_o,QN,w_o,A_o,UN,L_o,y_o,x_o,Bs,Nde,$_o,k_o,HN,S_o,R_o,JN,P_o,B_o,I_o,kh,qde,N_o,q_o,YN,j_o,D_o,G_o,Is,jde,O_o,V_o,KN,X_o,z_o,ZN,W_o,Q_o,U_o,Ns,Dde,H_o,J_o,eq,Y_o,K_o,oq,Z_o,euo,ouo,Sh,Gde,ruo,tuo,rq,auo,nuo,suo,Rh,Ode,luo,iuo,tq,duo,cuo,fuo,Ph,Vde,muo,guo,aq,huo,puo,_uo,Bh,Xde,uuo,buo,nq,vuo,Fuo,Tuo,qs,zde,Muo,Euo,sq,Cuo,wuo,lq,Auo,Luo,yuo,Ih,Wde,xuo,$uo,iq,kuo,Suo,Ruo,js,Qde,Puo,Buo,dq,Iuo,Nuo,cq,quo,juo,Duo,Ds,Ude,Guo,Ouo,fq,Vuo,Xuo,mq,zuo,Wuo,Quo,Gs,Hde,Uuo,Huo,gq,Juo,Yuo,hq,Kuo,Zuo,e2o,Os,Jde,o2o,r2o,pq,t2o,a2o,_q,n2o,s2o,l2o,Vs,Yde,i2o,d2o,uq,c2o,f2o,bq,m2o,g2o,h2o,Xs,Kde,p2o,_2o,vq,u2o,b2o,Fq,v2o,F2o,T2o,Nh,Zde,M2o,E2o,Tq,C2o,w2o,A2o,qh,ece,L2o,y2o,Mq,x2o,$2o,k2o,zs,oce,S2o,R2o,Eq,P2o,B2o,Cq,I2o,N2o,q2o,Ws,rce,j2o,D2o,wq,G2o,O2o,Aq,V2o,X2o,z2o,Qs,tce,W2o,Q2o,Lq,U2o,H2o,yq,J2o,Y2o,K2o,jh,ace,Z2o,e1o,xq,o1o,r1o,t1o,Dh,nce,a1o,n1o,$q,s1o,l1o,i1o,Gh,sce,d1o,c1o,kq,f1o,m1o,g1o,Us,lce,h1o,p1o,Sq,_1o,u1o,Rq,b1o,v1o,F1o,Hs,ice,T1o,M1o,Pq,E1o,C1o,Bq,w1o,A1o,L1o,Oh,dce,y1o,x1o,Iq,$1o,k1o,S1o,Vh,cce,R1o,P1o,Nq,B1o,I1o,N1o,Xh,fce,q1o,j1o,qq,D1o,G1o,O1o,Js,mce,V1o,X1o,jq,z1o,W1o,Dq,Q1o,U1o,H1o,zh,gce,J1o,Y1o,Gq,K1o,Z1o,e4o,Wh,hce,o4o,r4o,Oq,t4o,a4o,n4o,Ys,pce,s4o,l4o,Vq,i4o,d4o,Xq,c4o,f4o,m4o,Ks,_ce,g4o,h4o,zq,p4o,_4o,Wq,u4o,b4o,v4o,Zs,uce,F4o,T4o,Qq,M4o,E4o,Uq,C4o,w4o,A4o,el,bce,L4o,y4o,Hq,x4o,$4o,Jq,k4o,S4o,R4o,Qh,P4o,Uh,sy,B4o,vce,I4o,UWe,Qi,Hh,Fce,ly,N4o,Tce,q4o,HWe,$o,iy,j4o,dy,D4o,Yq,G4o,O4o,V4o,cy,X4o,Mce,z4o,W4o,Q4o,He,fy,U4o,Ece,H4o,J4o,ja,Y4o,Cce,K4o,Z4o,wce,ebo,obo,Ace,rbo,tbo,abo,Q,Jh,Lce,nbo,sbo,Kq,lbo,ibo,dbo,Yh,yce,cbo,fbo,Zq,mbo,gbo,hbo,Kh,xce,pbo,_bo,ej,ubo,bbo,vbo,Zh,$ce,Fbo,Tbo,oj,Mbo,Ebo,Cbo,ep,kce,wbo,Abo,rj,Lbo,ybo,xbo,op,Sce,$bo,kbo,tj,Sbo,Rbo,Pbo,rp,Rce,Bbo,Ibo,aj,Nbo,qbo,jbo,tp,Pce,Dbo,Gbo,nj,Obo,Vbo,Xbo,ap,Bce,zbo,Wbo,sj,Qbo,Ubo,Hbo,np,Ice,Jbo,Ybo,lj,Kbo,Zbo,evo,sp,Nce,ovo,rvo,ij,tvo,avo,nvo,lp,qce,svo,lvo,dj,ivo,dvo,cvo,ip,jce,fvo,mvo,cj,gvo,hvo,pvo,dp,Dce,_vo,uvo,fj,bvo,vvo,Fvo,cp,Gce,Tvo,Mvo,mj,Evo,Cvo,wvo,fp,Oce,Avo,Lvo,gj,yvo,xvo,$vo,mp,Vce,kvo,Svo,hj,Rvo,Pvo,Bvo,gp,Xce,Ivo,Nvo,zce,qvo,jvo,Dvo,hp,Wce,Gvo,Ovo,pj,Vvo,Xvo,zvo,pp,Qce,Wvo,Qvo,_j,Uvo,Hvo,Jvo,_p,Uce,Yvo,Kvo,uj,Zvo,e5o,o5o,up,Hce,r5o,t5o,bj,a5o,n5o,s5o,bp,Jce,l5o,i5o,vj,d5o,c5o,f5o,vp,Yce,m5o,g5o,Fj,h5o,p5o,_5o,Fp,Kce,u5o,b5o,Tj,v5o,F5o,T5o,Tp,Zce,M5o,E5o,Mj,C5o,w5o,A5o,Mp,efe,L5o,y5o,Ej,x5o,$5o,k5o,Ep,ofe,S5o,R5o,Cj,P5o,B5o,I5o,Cp,rfe,N5o,q5o,wj,j5o,D5o,G5o,wp,tfe,O5o,V5o,Aj,X5o,z5o,W5o,Ap,afe,Q5o,U5o,Lj,H5o,J5o,Y5o,Lp,nfe,K5o,Z5o,yj,eFo,oFo,rFo,yp,sfe,tFo,aFo,xj,nFo,sFo,lFo,xp,lfe,iFo,dFo,$j,cFo,fFo,mFo,$p,ife,gFo,hFo,kj,pFo,_Fo,uFo,kp,dfe,bFo,vFo,Sj,FFo,TFo,MFo,Sp,cfe,EFo,CFo,Rj,wFo,AFo,LFo,Rp,ffe,yFo,xFo,Pj,$Fo,kFo,SFo,Pp,RFo,Bp,PFo,Ip,my,BFo,mfe,IFo,JWe,Ui,Np,gfe,gy,NFo,hfe,qFo,YWe,ko,hy,jFo,py,DFo,Bj,GFo,OFo,VFo,_y,XFo,pfe,zFo,WFo,QFo,Je,uy,UFo,_fe,HFo,JFo,Hi,YFo,ufe,KFo,ZFo,bfe,eTo,oTo,rTo,fe,qp,vfe,tTo,aTo,Ij,nTo,sTo,lTo,jp,Ffe,iTo,dTo,Nj,cTo,fTo,mTo,Dp,Tfe,gTo,hTo,qj,pTo,_To,uTo,Gp,Mfe,bTo,vTo,jj,FTo,TTo,MTo,Op,Efe,ETo,CTo,Dj,wTo,ATo,LTo,Vp,Cfe,yTo,xTo,Gj,$To,kTo,STo,Xp,wfe,RTo,PTo,Oj,BTo,ITo,NTo,zp,Afe,qTo,jTo,Vj,DTo,GTo,OTo,Wp,Lfe,VTo,XTo,Xj,zTo,WTo,QTo,Qp,yfe,UTo,HTo,zj,JTo,YTo,KTo,Up,xfe,ZTo,e8o,Wj,o8o,r8o,t8o,Hp,$fe,a8o,n8o,Qj,s8o,l8o,i8o,Jp,kfe,d8o,c8o,Uj,f8o,m8o,g8o,Yp,Sfe,h8o,p8o,Hj,_8o,u8o,b8o,Kp,Rfe,v8o,F8o,Jj,T8o,M8o,E8o,Zp,Pfe,C8o,w8o,Yj,A8o,L8o,y8o,e_,Bfe,x8o,$8o,Kj,k8o,S8o,R8o,o_,Ife,P8o,B8o,Zj,I8o,N8o,q8o,r_,Nfe,j8o,D8o,eD,G8o,O8o,V8o,t_,X8o,a_,z8o,n_,by,W8o,qfe,Q8o,KWe,Ji,s_,jfe,vy,U8o,Dfe,H8o,ZWe,So,Fy,J8o,Yi,Y8o,oD,K8o,Z8o,rD,eMo,oMo,rMo,Ty,tMo,Gfe,aMo,nMo,sMo,ct,My,lMo,Ofe,iMo,dMo,Ki,cMo,Vfe,fMo,mMo,tD,gMo,hMo,pMo,l_,_Mo,Ye,Ey,uMo,Xfe,bMo,vMo,Da,FMo,zfe,TMo,MMo,Wfe,EMo,CMo,Qfe,wMo,AMo,LMo,y,i_,Ufe,yMo,xMo,aD,$Mo,kMo,SMo,d_,Hfe,RMo,PMo,nD,BMo,IMo,NMo,c_,Jfe,qMo,jMo,sD,DMo,GMo,OMo,f_,Yfe,VMo,XMo,lD,zMo,WMo,QMo,m_,Kfe,UMo,HMo,iD,JMo,YMo,KMo,g_,Zfe,ZMo,eEo,dD,oEo,rEo,tEo,h_,eme,aEo,nEo,cD,sEo,lEo,iEo,p_,ome,dEo,cEo,fD,fEo,mEo,gEo,__,rme,hEo,pEo,mD,_Eo,uEo,bEo,u_,tme,vEo,FEo,gD,TEo,MEo,EEo,b_,ame,CEo,wEo,hD,AEo,LEo,yEo,v_,nme,xEo,$Eo,pD,kEo,SEo,REo,F_,sme,PEo,BEo,_D,IEo,NEo,qEo,T_,lme,jEo,DEo,uD,GEo,OEo,VEo,M_,ime,XEo,zEo,bD,WEo,QEo,UEo,E_,dme,HEo,JEo,vD,YEo,KEo,ZEo,C_,cme,eCo,oCo,FD,rCo,tCo,aCo,w_,fme,nCo,sCo,TD,lCo,iCo,dCo,A_,mme,cCo,fCo,MD,mCo,gCo,hCo,L_,gme,pCo,_Co,ED,uCo,bCo,vCo,y_,hme,FCo,TCo,CD,MCo,ECo,CCo,x_,pme,wCo,ACo,wD,LCo,yCo,xCo,$_,_me,$Co,kCo,AD,SCo,RCo,PCo,k_,ume,BCo,ICo,LD,NCo,qCo,jCo,S_,bme,DCo,GCo,yD,OCo,VCo,XCo,R_,vme,zCo,WCo,xD,QCo,UCo,HCo,P_,Fme,JCo,YCo,$D,KCo,ZCo,e3o,B_,Tme,o3o,r3o,kD,t3o,a3o,n3o,I_,Mme,s3o,l3o,SD,i3o,d3o,c3o,N_,Eme,f3o,m3o,RD,g3o,h3o,p3o,q_,Cme,_3o,u3o,PD,b3o,v3o,F3o,j_,wme,T3o,M3o,BD,E3o,C3o,w3o,D_,Ame,A3o,L3o,ID,y3o,x3o,$3o,G_,Lme,k3o,S3o,ND,R3o,P3o,B3o,ol,yme,I3o,N3o,qD,q3o,j3o,jD,D3o,G3o,O3o,O_,xme,V3o,X3o,DD,z3o,W3o,Q3o,V_,$me,U3o,H3o,GD,J3o,Y3o,K3o,X_,kme,Z3o,e0o,OD,o0o,r0o,t0o,z_,Sme,a0o,n0o,VD,s0o,l0o,i0o,W_,Rme,d0o,c0o,XD,f0o,m0o,g0o,Q_,Pme,h0o,p0o,zD,_0o,u0o,b0o,U_,Bme,v0o,F0o,WD,T0o,M0o,E0o,H_,Ime,C0o,w0o,QD,A0o,L0o,y0o,J_,Nme,x0o,$0o,UD,k0o,S0o,R0o,Y_,qme,P0o,B0o,HD,I0o,N0o,q0o,K_,jme,j0o,D0o,JD,G0o,O0o,V0o,Z_,Dme,X0o,z0o,YD,W0o,Q0o,U0o,eu,Gme,H0o,J0o,KD,Y0o,K0o,Z0o,ou,Ome,ewo,owo,ZD,rwo,two,awo,ru,Vme,nwo,swo,eG,lwo,iwo,dwo,tu,Xme,cwo,fwo,oG,mwo,gwo,hwo,au,zme,pwo,_wo,rG,uwo,bwo,vwo,nu,Wme,Fwo,Two,tG,Mwo,Ewo,Cwo,su,Qme,wwo,Awo,aG,Lwo,ywo,xwo,lu,Ume,$wo,kwo,nG,Swo,Rwo,Pwo,iu,Hme,Bwo,Iwo,sG,Nwo,qwo,jwo,du,Jme,Dwo,Gwo,lG,Owo,Vwo,Xwo,cu,Yme,zwo,Wwo,iG,Qwo,Uwo,Hwo,fu,Kme,Jwo,Ywo,dG,Kwo,Zwo,e6o,mu,Zme,o6o,r6o,cG,t6o,a6o,n6o,gu,ege,s6o,l6o,fG,i6o,d6o,c6o,hu,oge,f6o,m6o,mG,g6o,h6o,p6o,pu,rge,_6o,u6o,gG,b6o,v6o,F6o,_u,tge,T6o,M6o,hG,E6o,C6o,w6o,uu,age,A6o,L6o,pG,y6o,x6o,$6o,bu,nge,k6o,S6o,_G,R6o,P6o,B6o,vu,sge,I6o,N6o,uG,q6o,j6o,D6o,Fu,lge,G6o,O6o,bG,V6o,X6o,z6o,Tu,ige,W6o,Q6o,vG,U6o,H6o,J6o,Mu,dge,Y6o,K6o,FG,Z6o,eAo,oAo,Eu,cge,rAo,tAo,TG,aAo,nAo,sAo,Cu,fge,lAo,iAo,MG,dAo,cAo,fAo,wu,mge,mAo,gAo,EG,hAo,pAo,_Ao,Au,gge,uAo,bAo,CG,vAo,FAo,TAo,Lu,hge,MAo,EAo,wG,CAo,wAo,AAo,yu,pge,LAo,yAo,AG,xAo,$Ao,kAo,xu,_ge,SAo,RAo,LG,PAo,BAo,IAo,$u,uge,NAo,qAo,yG,jAo,DAo,GAo,ku,bge,OAo,VAo,xG,XAo,zAo,WAo,Su,vge,QAo,UAo,$G,HAo,JAo,YAo,Ru,Fge,KAo,ZAo,kG,e7o,o7o,r7o,Pu,Tge,t7o,a7o,SG,n7o,s7o,l7o,Bu,Mge,i7o,d7o,RG,c7o,f7o,m7o,Iu,Ege,g7o,h7o,PG,p7o,_7o,u7o,Nu,Cge,b7o,v7o,BG,F7o,T7o,M7o,qu,wge,E7o,C7o,IG,w7o,A7o,L7o,ju,Age,y7o,x7o,NG,$7o,k7o,S7o,Du,Lge,R7o,P7o,qG,B7o,I7o,N7o,Gu,yge,q7o,j7o,jG,D7o,G7o,O7o,Ou,xge,V7o,X7o,DG,z7o,W7o,Q7o,Vu,$ge,U7o,H7o,GG,J7o,Y7o,K7o,Xu,kge,Z7o,eLo,OG,oLo,rLo,tLo,zu,Sge,aLo,nLo,VG,sLo,lLo,iLo,Wu,Rge,dLo,cLo,XG,fLo,mLo,gLo,Qu,Pge,hLo,pLo,zG,_Lo,uLo,bLo,Uu,Bge,vLo,FLo,WG,TLo,MLo,ELo,Hu,Ige,CLo,wLo,QG,ALo,LLo,yLo,Ju,Nge,xLo,$Lo,UG,kLo,SLo,RLo,Yu,qge,PLo,BLo,HG,ILo,NLo,qLo,Ku,jge,jLo,DLo,JG,GLo,OLo,VLo,Zu,Dge,XLo,zLo,YG,WLo,QLo,ULo,e2,Gge,HLo,JLo,KG,YLo,KLo,ZLo,o2,Oge,eyo,oyo,ZG,ryo,tyo,ayo,r2,Vge,nyo,syo,eO,lyo,iyo,dyo,t2,Xge,cyo,fyo,oO,myo,gyo,hyo,a2,zge,pyo,_yo,rO,uyo,byo,vyo,n2,Wge,Fyo,Tyo,tO,Myo,Eyo,Cyo,s2,Qge,wyo,Ayo,aO,Lyo,yyo,xyo,l2,Uge,$yo,kyo,nO,Syo,Ryo,Pyo,i2,Hge,Byo,Iyo,sO,Nyo,qyo,jyo,d2,Jge,Dyo,Gyo,lO,Oyo,Vyo,Xyo,c2,Yge,zyo,Wyo,iO,Qyo,Uyo,Hyo,f2,Kge,Jyo,Yyo,dO,Kyo,Zyo,e9o,m2,Zge,o9o,r9o,cO,t9o,a9o,n9o,g2,ehe,s9o,l9o,fO,i9o,d9o,c9o,h2,f9o,ohe,m9o,g9o,rhe,h9o,p9o,p2,eQe,Zi,_2,the,Cy,_9o,ahe,u9o,oQe,Ro,wy,b9o,ed,v9o,mO,F9o,T9o,gO,M9o,E9o,C9o,Ay,w9o,nhe,A9o,L9o,y9o,ft,Ly,x9o,she,$9o,k9o,od,S9o,lhe,R9o,P9o,hO,B9o,I9o,N9o,u2,q9o,Ke,yy,j9o,ihe,D9o,G9o,Ga,O9o,dhe,V9o,X9o,che,z9o,W9o,fhe,Q9o,U9o,H9o,G,b2,mhe,J9o,Y9o,pO,K9o,Z9o,exo,v2,ghe,oxo,rxo,_O,txo,axo,nxo,F2,hhe,sxo,lxo,uO,ixo,dxo,cxo,T2,phe,fxo,mxo,bO,gxo,hxo,pxo,M2,_he,_xo,uxo,vO,bxo,vxo,Fxo,E2,uhe,Txo,Mxo,FO,Exo,Cxo,wxo,C2,bhe,Axo,Lxo,TO,yxo,xxo,$xo,w2,vhe,kxo,Sxo,MO,Rxo,Pxo,Bxo,A2,Fhe,Ixo,Nxo,EO,qxo,jxo,Dxo,L2,The,Gxo,Oxo,CO,Vxo,Xxo,zxo,y2,Mhe,Wxo,Qxo,wO,Uxo,Hxo,Jxo,x2,Ehe,Yxo,Kxo,AO,Zxo,e$o,o$o,$2,Che,r$o,t$o,LO,a$o,n$o,s$o,k2,whe,l$o,i$o,yO,d$o,c$o,f$o,S2,Ahe,m$o,g$o,xO,h$o,p$o,_$o,R2,Lhe,u$o,b$o,$O,v$o,F$o,T$o,P2,yhe,M$o,E$o,kO,C$o,w$o,A$o,B2,xhe,L$o,y$o,SO,x$o,$$o,k$o,I2,$he,S$o,R$o,RO,P$o,B$o,I$o,N2,khe,N$o,q$o,PO,j$o,D$o,G$o,q2,She,O$o,V$o,BO,X$o,z$o,W$o,j2,Rhe,Q$o,U$o,IO,H$o,J$o,Y$o,D2,Phe,K$o,Z$o,NO,eko,oko,rko,G2,Bhe,tko,ako,qO,nko,sko,lko,O2,Ihe,iko,dko,jO,cko,fko,mko,V2,Nhe,gko,hko,DO,pko,_ko,uko,X2,qhe,bko,vko,GO,Fko,Tko,Mko,z2,jhe,Eko,Cko,OO,wko,Ako,Lko,W2,Dhe,yko,xko,VO,$ko,kko,Sko,Q2,Ghe,Rko,Pko,XO,Bko,Iko,Nko,U2,Ohe,qko,jko,zO,Dko,Gko,Oko,H2,Vhe,Vko,Xko,WO,zko,Wko,Qko,J2,Xhe,Uko,Hko,QO,Jko,Yko,Kko,Y2,zhe,Zko,eSo,UO,oSo,rSo,tSo,K2,Whe,aSo,nSo,HO,sSo,lSo,iSo,Z2,Qhe,dSo,cSo,JO,fSo,mSo,gSo,e1,Uhe,hSo,pSo,YO,_So,uSo,bSo,o1,Hhe,vSo,FSo,KO,TSo,MSo,ESo,r1,Jhe,CSo,wSo,ZO,ASo,LSo,ySo,t1,Yhe,xSo,$So,eV,kSo,SSo,RSo,a1,Khe,PSo,BSo,oV,ISo,NSo,qSo,n1,Zhe,jSo,DSo,rV,GSo,OSo,VSo,s1,epe,XSo,zSo,tV,WSo,QSo,USo,l1,ope,HSo,JSo,aV,YSo,KSo,ZSo,i1,rpe,eRo,oRo,nV,rRo,tRo,aRo,d1,tpe,nRo,sRo,sV,lRo,iRo,dRo,c1,ape,cRo,fRo,lV,mRo,gRo,hRo,f1,pRo,npe,_Ro,uRo,spe,bRo,vRo,m1,rQe,rd,g1,lpe,xy,FRo,ipe,TRo,tQe,Po,$y,MRo,td,ERo,iV,CRo,wRo,dV,ARo,LRo,yRo,ky,xRo,dpe,$Ro,kRo,SRo,mt,Sy,RRo,cpe,PRo,BRo,ad,IRo,fpe,NRo,qRo,cV,jRo,DRo,GRo,h1,ORo,Ze,Ry,VRo,mpe,XRo,zRo,Oa,WRo,gpe,QRo,URo,hpe,HRo,JRo,ppe,YRo,KRo,ZRo,z,p1,_pe,ePo,oPo,fV,rPo,tPo,aPo,_1,upe,nPo,sPo,mV,lPo,iPo,dPo,u1,bpe,cPo,fPo,gV,mPo,gPo,hPo,b1,vpe,pPo,_Po,hV,uPo,bPo,vPo,v1,Fpe,FPo,TPo,pV,MPo,EPo,CPo,F1,Tpe,wPo,APo,_V,LPo,yPo,xPo,T1,Mpe,$Po,kPo,uV,SPo,RPo,PPo,M1,Epe,BPo,IPo,bV,NPo,qPo,jPo,E1,Cpe,DPo,GPo,vV,OPo,VPo,XPo,C1,wpe,zPo,WPo,FV,QPo,UPo,HPo,w1,Ape,JPo,YPo,TV,KPo,ZPo,eBo,A1,Lpe,oBo,rBo,MV,tBo,aBo,nBo,L1,ype,sBo,lBo,EV,iBo,dBo,cBo,y1,xpe,fBo,mBo,CV,gBo,hBo,pBo,x1,$pe,_Bo,uBo,wV,bBo,vBo,FBo,$1,kpe,TBo,MBo,AV,EBo,CBo,wBo,k1,Spe,ABo,LBo,LV,yBo,xBo,$Bo,S1,Rpe,kBo,SBo,yV,RBo,PBo,BBo,R1,Ppe,IBo,NBo,xV,qBo,jBo,DBo,P1,Bpe,GBo,OBo,$V,VBo,XBo,zBo,B1,Ipe,WBo,QBo,kV,UBo,HBo,JBo,I1,Npe,YBo,KBo,SV,ZBo,eIo,oIo,N1,qpe,rIo,tIo,RV,aIo,nIo,sIo,q1,jpe,lIo,iIo,PV,dIo,cIo,fIo,j1,Dpe,mIo,gIo,BV,hIo,pIo,_Io,D1,Gpe,uIo,bIo,IV,vIo,FIo,TIo,G1,Ope,MIo,EIo,NV,CIo,wIo,AIo,O1,Vpe,LIo,yIo,qV,xIo,$Io,kIo,V1,Xpe,SIo,RIo,jV,PIo,BIo,IIo,X1,zpe,NIo,qIo,DV,jIo,DIo,GIo,z1,Wpe,OIo,VIo,GV,XIo,zIo,WIo,W1,Qpe,QIo,UIo,OV,HIo,JIo,YIo,Q1,Upe,KIo,ZIo,VV,eNo,oNo,rNo,U1,Hpe,tNo,aNo,XV,nNo,sNo,lNo,H1,Jpe,iNo,dNo,zV,cNo,fNo,mNo,J1,Ype,gNo,hNo,WV,pNo,_No,uNo,Y1,Kpe,bNo,vNo,QV,FNo,TNo,MNo,K1,Zpe,ENo,CNo,UV,wNo,ANo,LNo,Z1,e_e,yNo,xNo,HV,$No,kNo,SNo,e4,o_e,RNo,PNo,JV,BNo,INo,NNo,o4,qNo,r_e,jNo,DNo,t_e,GNo,ONo,r4,aQe,nd,t4,a_e,Py,VNo,n_e,XNo,nQe,Bo,By,zNo,sd,WNo,YV,QNo,UNo,KV,HNo,JNo,YNo,Iy,KNo,s_e,ZNo,eqo,oqo,gt,Ny,rqo,l_e,tqo,aqo,ld,nqo,i_e,sqo,lqo,ZV,iqo,dqo,cqo,a4,fqo,eo,qy,mqo,d_e,gqo,hqo,Va,pqo,c_e,_qo,uqo,f_e,bqo,vqo,m_e,Fqo,Tqo,Mqo,U,n4,g_e,Eqo,Cqo,eX,wqo,Aqo,Lqo,s4,h_e,yqo,xqo,oX,$qo,kqo,Sqo,l4,p_e,Rqo,Pqo,rX,Bqo,Iqo,Nqo,i4,__e,qqo,jqo,tX,Dqo,Gqo,Oqo,d4,u_e,Vqo,Xqo,aX,zqo,Wqo,Qqo,c4,b_e,Uqo,Hqo,nX,Jqo,Yqo,Kqo,f4,v_e,Zqo,ejo,sX,ojo,rjo,tjo,m4,F_e,ajo,njo,lX,sjo,ljo,ijo,g4,T_e,djo,cjo,iX,fjo,mjo,gjo,h4,M_e,hjo,pjo,dX,_jo,ujo,bjo,p4,E_e,vjo,Fjo,cX,Tjo,Mjo,Ejo,_4,C_e,Cjo,wjo,fX,Ajo,Ljo,yjo,u4,w_e,xjo,$jo,mX,kjo,Sjo,Rjo,b4,A_e,Pjo,Bjo,gX,Ijo,Njo,qjo,v4,L_e,jjo,Djo,hX,Gjo,Ojo,Vjo,F4,y_e,Xjo,zjo,pX,Wjo,Qjo,Ujo,T4,x_e,Hjo,Jjo,_X,Yjo,Kjo,Zjo,M4,$_e,eDo,oDo,uX,rDo,tDo,aDo,E4,k_e,nDo,sDo,bX,lDo,iDo,dDo,C4,S_e,cDo,fDo,vX,mDo,gDo,hDo,w4,R_e,pDo,_Do,FX,uDo,bDo,vDo,A4,P_e,FDo,TDo,TX,MDo,EDo,CDo,L4,B_e,wDo,ADo,MX,LDo,yDo,xDo,y4,I_e,$Do,kDo,EX,SDo,RDo,PDo,x4,N_e,BDo,IDo,CX,NDo,qDo,jDo,$4,q_e,DDo,GDo,wX,ODo,VDo,XDo,k4,j_e,zDo,WDo,AX,QDo,UDo,HDo,S4,D_e,JDo,YDo,LX,KDo,ZDo,eGo,R4,G_e,oGo,rGo,yX,tGo,aGo,nGo,P4,O_e,sGo,lGo,xX,iGo,dGo,cGo,B4,V_e,fGo,mGo,$X,gGo,hGo,pGo,I4,X_e,_Go,uGo,kX,bGo,vGo,FGo,N4,z_e,TGo,MGo,SX,EGo,CGo,wGo,q4,W_e,AGo,LGo,Q_e,yGo,xGo,$Go,j4,U_e,kGo,SGo,RX,RGo,PGo,BGo,D4,H_e,IGo,NGo,PX,qGo,jGo,DGo,G4,J_e,GGo,OGo,BX,VGo,XGo,zGo,O4,Y_e,WGo,QGo,IX,UGo,HGo,JGo,V4,YGo,K_e,KGo,ZGo,Z_e,eOo,oOo,X4,sQe,id,z4,eue,jy,rOo,oue,tOo,lQe,Io,Dy,aOo,dd,nOo,NX,sOo,lOo,qX,iOo,dOo,cOo,Gy,fOo,rue,mOo,gOo,hOo,ht,Oy,pOo,tue,_Oo,uOo,cd,bOo,aue,vOo,FOo,jX,TOo,MOo,EOo,W4,COo,oo,Vy,wOo,nue,AOo,LOo,Xa,yOo,sue,xOo,$Oo,lue,kOo,SOo,iue,ROo,POo,BOo,me,Q4,due,IOo,NOo,DX,qOo,jOo,DOo,U4,cue,GOo,OOo,GX,VOo,XOo,zOo,H4,fue,WOo,QOo,OX,UOo,HOo,JOo,J4,mue,YOo,KOo,VX,ZOo,eVo,oVo,Y4,gue,rVo,tVo,XX,aVo,nVo,sVo,K4,hue,lVo,iVo,zX,dVo,cVo,fVo,Z4,pue,mVo,gVo,WX,hVo,pVo,_Vo,eb,_ue,uVo,bVo,QX,vVo,FVo,TVo,ob,uue,MVo,EVo,UX,CVo,wVo,AVo,rb,bue,LVo,yVo,HX,xVo,$Vo,kVo,tb,vue,SVo,RVo,JX,PVo,BVo,IVo,ab,Fue,NVo,qVo,YX,jVo,DVo,GVo,nb,Tue,OVo,VVo,KX,XVo,zVo,WVo,sb,Mue,QVo,UVo,ZX,HVo,JVo,YVo,lb,Eue,KVo,ZVo,ez,eXo,oXo,rXo,ib,Cue,tXo,aXo,oz,nXo,sXo,lXo,db,wue,iXo,dXo,rz,cXo,fXo,mXo,cb,Aue,gXo,hXo,tz,pXo,_Xo,uXo,fb,Lue,bXo,vXo,az,FXo,TXo,MXo,mb,EXo,yue,CXo,wXo,xue,AXo,LXo,gb,iQe,fd,hb,$ue,Xy,yXo,kue,xXo,dQe,No,zy,$Xo,md,kXo,nz,SXo,RXo,sz,PXo,BXo,IXo,Wy,NXo,Sue,qXo,jXo,DXo,pt,Qy,GXo,Rue,OXo,VXo,gd,XXo,Pue,zXo,WXo,lz,QXo,UXo,HXo,pb,JXo,ro,Uy,YXo,Bue,KXo,ZXo,za,ezo,Iue,ozo,rzo,Nue,tzo,azo,que,nzo,szo,lzo,B,_b,jue,izo,dzo,iz,czo,fzo,mzo,ub,Due,gzo,hzo,dz,pzo,_zo,uzo,bb,Gue,bzo,vzo,cz,Fzo,Tzo,Mzo,vb,Oue,Ezo,Czo,fz,wzo,Azo,Lzo,Fb,Vue,yzo,xzo,mz,$zo,kzo,Szo,Tb,Xue,Rzo,Pzo,gz,Bzo,Izo,Nzo,Mb,zue,qzo,jzo,hz,Dzo,Gzo,Ozo,Eb,Wue,Vzo,Xzo,pz,zzo,Wzo,Qzo,Cb,Que,Uzo,Hzo,_z,Jzo,Yzo,Kzo,wb,Uue,Zzo,eWo,uz,oWo,rWo,tWo,Ab,Hue,aWo,nWo,bz,sWo,lWo,iWo,Lb,Jue,dWo,cWo,vz,fWo,mWo,gWo,yb,Yue,hWo,pWo,Fz,_Wo,uWo,bWo,xb,Kue,vWo,FWo,Tz,TWo,MWo,EWo,$b,Zue,CWo,wWo,Mz,AWo,LWo,yWo,kb,e2e,xWo,$Wo,Ez,kWo,SWo,RWo,Sb,o2e,PWo,BWo,Cz,IWo,NWo,qWo,Rb,r2e,jWo,DWo,wz,GWo,OWo,VWo,Pb,t2e,XWo,zWo,Az,WWo,QWo,UWo,Bb,a2e,HWo,JWo,Lz,YWo,KWo,ZWo,Ib,n2e,eQo,oQo,yz,rQo,tQo,aQo,Nb,s2e,nQo,sQo,xz,lQo,iQo,dQo,qb,l2e,cQo,fQo,$z,mQo,gQo,hQo,jb,i2e,pQo,_Qo,kz,uQo,bQo,vQo,Db,d2e,FQo,TQo,Sz,MQo,EQo,CQo,Gb,c2e,wQo,AQo,Rz,LQo,yQo,xQo,Ob,f2e,$Qo,kQo,Pz,SQo,RQo,PQo,Vb,m2e,BQo,IQo,Bz,NQo,qQo,jQo,Xb,g2e,DQo,GQo,Iz,OQo,VQo,XQo,zb,h2e,zQo,WQo,Nz,QQo,UQo,HQo,Wb,p2e,JQo,YQo,qz,KQo,ZQo,eUo,Qb,_2e,oUo,rUo,jz,tUo,aUo,nUo,Ub,u2e,sUo,lUo,Dz,iUo,dUo,cUo,Hb,b2e,fUo,mUo,Gz,gUo,hUo,pUo,Jb,v2e,_Uo,uUo,Oz,bUo,vUo,FUo,Yb,F2e,TUo,MUo,Vz,EUo,CUo,wUo,Kb,T2e,AUo,LUo,Xz,yUo,xUo,$Uo,Zb,M2e,kUo,SUo,zz,RUo,PUo,BUo,ev,E2e,IUo,NUo,Wz,qUo,jUo,DUo,ov,C2e,GUo,OUo,Qz,VUo,XUo,zUo,rv,w2e,WUo,QUo,Uz,UUo,HUo,JUo,tv,A2e,YUo,KUo,Hz,ZUo,eHo,oHo,av,L2e,rHo,tHo,Jz,aHo,nHo,sHo,nv,y2e,lHo,iHo,Yz,dHo,cHo,fHo,sv,x2e,mHo,gHo,Kz,hHo,pHo,_Ho,lv,$2e,uHo,bHo,Zz,vHo,FHo,THo,iv,k2e,MHo,EHo,eW,CHo,wHo,AHo,dv,S2e,LHo,yHo,oW,xHo,$Ho,kHo,cv,R2e,SHo,RHo,rW,PHo,BHo,IHo,fv,P2e,NHo,qHo,tW,jHo,DHo,GHo,mv,B2e,OHo,VHo,aW,XHo,zHo,WHo,gv,I2e,QHo,UHo,nW,HHo,JHo,YHo,hv,KHo,N2e,ZHo,eJo,q2e,oJo,rJo,pv,cQe,hd,_v,j2e,Hy,tJo,D2e,aJo,fQe,qo,Jy,nJo,pd,sJo,sW,lJo,iJo,lW,dJo,cJo,fJo,Yy,mJo,G2e,gJo,hJo,pJo,_t,Ky,_Jo,O2e,uJo,bJo,_d,vJo,V2e,FJo,TJo,iW,MJo,EJo,CJo,uv,wJo,to,Zy,AJo,X2e,LJo,yJo,Wa,xJo,z2e,$Jo,kJo,W2e,SJo,RJo,Q2e,PJo,BJo,IJo,Z,bv,U2e,NJo,qJo,dW,jJo,DJo,GJo,vv,H2e,OJo,VJo,cW,XJo,zJo,WJo,Fv,J2e,QJo,UJo,fW,HJo,JJo,YJo,Tv,Y2e,KJo,ZJo,mW,eYo,oYo,rYo,Mv,K2e,tYo,aYo,gW,nYo,sYo,lYo,Ev,Z2e,iYo,dYo,hW,cYo,fYo,mYo,Cv,e1e,gYo,hYo,pW,pYo,_Yo,uYo,wv,o1e,bYo,vYo,_W,FYo,TYo,MYo,Av,r1e,EYo,CYo,uW,wYo,AYo,LYo,Lv,t1e,yYo,xYo,bW,$Yo,kYo,SYo,yv,a1e,RYo,PYo,vW,BYo,IYo,NYo,xv,n1e,qYo,jYo,FW,DYo,GYo,OYo,$v,s1e,VYo,XYo,TW,zYo,WYo,QYo,kv,l1e,UYo,HYo,MW,JYo,YYo,KYo,Sv,i1e,ZYo,eKo,EW,oKo,rKo,tKo,Rv,d1e,aKo,nKo,CW,sKo,lKo,iKo,Pv,c1e,dKo,cKo,wW,fKo,mKo,gKo,Bv,f1e,hKo,pKo,AW,_Ko,uKo,bKo,Iv,m1e,vKo,FKo,LW,TKo,MKo,EKo,Nv,g1e,CKo,wKo,yW,AKo,LKo,yKo,qv,h1e,xKo,$Ko,xW,kKo,SKo,RKo,jv,p1e,PKo,BKo,$W,IKo,NKo,qKo,Dv,_1e,jKo,DKo,kW,GKo,OKo,VKo,Gv,u1e,XKo,zKo,SW,WKo,QKo,UKo,Ov,b1e,HKo,JKo,RW,YKo,KKo,ZKo,Vv,v1e,eZo,oZo,PW,rZo,tZo,aZo,Xv,F1e,nZo,sZo,BW,lZo,iZo,dZo,zv,T1e,cZo,fZo,IW,mZo,gZo,hZo,Wv,M1e,pZo,_Zo,NW,uZo,bZo,vZo,Qv,E1e,FZo,TZo,qW,MZo,EZo,CZo,Uv,C1e,wZo,AZo,jW,LZo,yZo,xZo,Hv,$Zo,w1e,kZo,SZo,A1e,RZo,PZo,Jv,mQe,ud,Yv,L1e,e9,BZo,y1e,IZo,gQe,jo,o9,NZo,bd,qZo,DW,jZo,DZo,GW,GZo,OZo,VZo,r9,XZo,x1e,zZo,WZo,QZo,ut,t9,UZo,$1e,HZo,JZo,vd,YZo,k1e,KZo,ZZo,OW,eer,oer,rer,Kv,ter,ao,a9,aer,S1e,ner,ser,Qa,ler,R1e,ier,der,P1e,cer,fer,B1e,mer,ger,her,Do,Zv,I1e,per,_er,VW,uer,ber,ver,e5,N1e,Fer,Ter,XW,Mer,Eer,Cer,o5,q1e,wer,Aer,zW,Ler,yer,xer,r5,j1e,$er,ker,WW,Ser,Rer,Per,t5,D1e,Ber,Ier,QW,Ner,qer,jer,a5,G1e,Der,Ger,UW,Oer,Ver,Xer,n5,zer,O1e,Wer,Qer,V1e,Uer,Her,s5,hQe,Fd,l5,X1e,n9,Jer,z1e,Yer,pQe,Go,s9,Ker,Td,Zer,HW,eor,oor,JW,ror,tor,aor,l9,nor,W1e,sor,lor,ior,bt,i9,dor,Q1e,cor,mor,Md,gor,U1e,hor,por,YW,_or,uor,bor,i5,vor,no,d9,For,H1e,Tor,Mor,Ua,Eor,J1e,Cor,wor,Y1e,Aor,Lor,K1e,yor,xor,$or,H,d5,Z1e,kor,Sor,KW,Ror,Por,Bor,c5,e4e,Ior,Nor,ZW,qor,jor,Dor,f5,o4e,Gor,Oor,eQ,Vor,Xor,zor,m5,r4e,Wor,Qor,oQ,Uor,Hor,Jor,g5,t4e,Yor,Kor,rQ,Zor,err,orr,h5,a4e,rrr,trr,tQ,arr,nrr,srr,p5,n4e,lrr,irr,aQ,drr,crr,frr,_5,s4e,mrr,grr,nQ,hrr,prr,_rr,u5,l4e,urr,brr,sQ,vrr,Frr,Trr,b5,i4e,Mrr,Err,lQ,Crr,wrr,Arr,v5,d4e,Lrr,yrr,iQ,xrr,$rr,krr,F5,c4e,Srr,Rrr,dQ,Prr,Brr,Irr,T5,f4e,Nrr,qrr,cQ,jrr,Drr,Grr,M5,m4e,Orr,Vrr,fQ,Xrr,zrr,Wrr,E5,g4e,Qrr,Urr,mQ,Hrr,Jrr,Yrr,C5,h4e,Krr,Zrr,gQ,etr,otr,rtr,w5,p4e,ttr,atr,hQ,ntr,str,ltr,A5,_4e,itr,dtr,pQ,ctr,ftr,mtr,L5,u4e,gtr,htr,_Q,ptr,_tr,utr,y5,b4e,btr,vtr,uQ,Ftr,Ttr,Mtr,x5,v4e,Etr,Ctr,bQ,wtr,Atr,Ltr,$5,F4e,ytr,xtr,vQ,$tr,ktr,Str,k5,T4e,Rtr,Ptr,FQ,Btr,Itr,Ntr,S5,M4e,qtr,jtr,TQ,Dtr,Gtr,Otr,R5,E4e,Vtr,Xtr,MQ,ztr,Wtr,Qtr,P5,C4e,Utr,Htr,EQ,Jtr,Ytr,Ktr,B5,w4e,Ztr,ear,CQ,oar,rar,tar,I5,A4e,aar,nar,wQ,sar,lar,iar,N5,L4e,dar,car,AQ,far,mar,gar,q5,y4e,har,par,LQ,_ar,uar,bar,j5,x4e,Far,Tar,yQ,Mar,Ear,Car,D5,$4e,war,Aar,xQ,Lar,yar,xar,G5,k4e,$ar,kar,$Q,Sar,Rar,Par,O5,S4e,Bar,Iar,kQ,Nar,qar,jar,V5,R4e,Dar,Gar,SQ,Oar,Var,Xar,X5,P4e,zar,War,RQ,Qar,Uar,Har,z5,B4e,Jar,Yar,PQ,Kar,Zar,enr,W5,onr,I4e,rnr,tnr,N4e,anr,nnr,Q5,_Qe,Ed,U5,q4e,c9,snr,j4e,lnr,uQe,Oo,f9,inr,Cd,dnr,BQ,cnr,fnr,IQ,mnr,gnr,hnr,m9,pnr,D4e,_nr,unr,bnr,vt,g9,vnr,G4e,Fnr,Tnr,wd,Mnr,O4e,Enr,Cnr,NQ,wnr,Anr,Lnr,H5,ynr,so,h9,xnr,V4e,$nr,knr,Ha,Snr,X4e,Rnr,Pnr,z4e,Bnr,Inr,W4e,Nnr,qnr,jnr,V,J5,Q4e,Dnr,Gnr,qQ,Onr,Vnr,Xnr,Y5,U4e,znr,Wnr,jQ,Qnr,Unr,Hnr,K5,H4e,Jnr,Ynr,DQ,Knr,Znr,esr,Z5,J4e,osr,rsr,GQ,tsr,asr,nsr,eF,Y4e,ssr,lsr,OQ,isr,dsr,csr,oF,K4e,fsr,msr,VQ,gsr,hsr,psr,rF,Z4e,_sr,usr,XQ,bsr,vsr,Fsr,tF,ebe,Tsr,Msr,zQ,Esr,Csr,wsr,aF,obe,Asr,Lsr,WQ,ysr,xsr,$sr,nF,rbe,ksr,Ssr,QQ,Rsr,Psr,Bsr,sF,tbe,Isr,Nsr,UQ,qsr,jsr,Dsr,lF,abe,Gsr,Osr,HQ,Vsr,Xsr,zsr,iF,nbe,Wsr,Qsr,JQ,Usr,Hsr,Jsr,dF,sbe,Ysr,Ksr,YQ,Zsr,elr,olr,cF,lbe,rlr,tlr,KQ,alr,nlr,slr,fF,ibe,llr,ilr,ZQ,dlr,clr,flr,mF,dbe,mlr,glr,eU,hlr,plr,_lr,gF,cbe,ulr,blr,oU,vlr,Flr,Tlr,hF,fbe,Mlr,Elr,rU,Clr,wlr,Alr,pF,mbe,Llr,ylr,tU,xlr,$lr,klr,_F,gbe,Slr,Rlr,aU,Plr,Blr,Ilr,uF,hbe,Nlr,qlr,nU,jlr,Dlr,Glr,bF,pbe,Olr,Vlr,sU,Xlr,zlr,Wlr,vF,_be,Qlr,Ulr,lU,Hlr,Jlr,Ylr,FF,ube,Klr,Zlr,iU,eir,oir,rir,TF,bbe,tir,air,dU,nir,sir,lir,MF,vbe,iir,dir,cU,cir,fir,mir,EF,Fbe,gir,hir,fU,pir,_ir,uir,CF,Tbe,bir,vir,mU,Fir,Tir,Mir,wF,Mbe,Eir,Cir,gU,wir,Air,Lir,AF,Ebe,yir,xir,hU,$ir,kir,Sir,LF,Cbe,Rir,Pir,pU,Bir,Iir,Nir,yF,wbe,qir,jir,_U,Dir,Gir,Oir,xF,Abe,Vir,Xir,uU,zir,Wir,Qir,$F,Lbe,Uir,Hir,bU,Jir,Yir,Kir,kF,ybe,Zir,edr,vU,odr,rdr,tdr,SF,xbe,adr,ndr,FU,sdr,ldr,idr,RF,$be,ddr,cdr,TU,fdr,mdr,gdr,PF,kbe,hdr,pdr,MU,_dr,udr,bdr,BF,Sbe,vdr,Fdr,EU,Tdr,Mdr,Edr,IF,Rbe,Cdr,wdr,CU,Adr,Ldr,ydr,NF,Pbe,xdr,$dr,wU,kdr,Sdr,Rdr,qF,Bbe,Pdr,Bdr,AU,Idr,Ndr,qdr,jF,jdr,Ibe,Ddr,Gdr,Nbe,Odr,Vdr,DF,bQe,Ad,GF,qbe,p9,Xdr,jbe,zdr,vQe,Vo,_9,Wdr,Ld,Qdr,LU,Udr,Hdr,yU,Jdr,Ydr,Kdr,u9,Zdr,Dbe,ecr,ocr,rcr,Ft,b9,tcr,Gbe,acr,ncr,yd,scr,Obe,lcr,icr,xU,dcr,ccr,fcr,OF,mcr,lo,v9,gcr,Vbe,hcr,pcr,Ja,_cr,Xbe,ucr,bcr,zbe,vcr,Fcr,Wbe,Tcr,Mcr,Ecr,Qbe,VF,Ube,Ccr,wcr,$U,Acr,Lcr,ycr,XF,xcr,Hbe,$cr,kcr,Jbe,Scr,Rcr,zF,FQe,xd,WF,Ybe,F9,Pcr,Kbe,Bcr,TQe,Xo,T9,Icr,$d,Ncr,kU,qcr,jcr,SU,Dcr,Gcr,Ocr,M9,Vcr,Zbe,Xcr,zcr,Wcr,Tt,E9,Qcr,eve,Ucr,Hcr,kd,Jcr,ove,Ycr,Kcr,RU,Zcr,efr,ofr,QF,rfr,io,C9,tfr,rve,afr,nfr,Ya,sfr,tve,lfr,ifr,ave,dfr,cfr,nve,ffr,mfr,gfr,be,UF,sve,hfr,pfr,PU,_fr,ufr,bfr,HF,lve,vfr,Ffr,BU,Tfr,Mfr,Efr,JF,ive,Cfr,wfr,IU,Afr,Lfr,yfr,YF,dve,xfr,$fr,NU,kfr,Sfr,Rfr,rl,cve,Pfr,Bfr,qU,Ifr,Nfr,jU,qfr,jfr,Dfr,KF,fve,Gfr,Ofr,DU,Vfr,Xfr,zfr,tl,mve,Wfr,Qfr,GU,Ufr,Hfr,OU,Jfr,Yfr,Kfr,ZF,gve,Zfr,emr,VU,omr,rmr,tmr,Mt,hve,amr,nmr,XU,smr,lmr,zU,imr,dmr,WU,cmr,fmr,mmr,eT,pve,gmr,hmr,QU,pmr,_mr,umr,oT,_ve,bmr,vmr,UU,Fmr,Tmr,Mmr,rT,uve,Emr,Cmr,HU,wmr,Amr,Lmr,tT,bve,ymr,xmr,JU,$mr,kmr,Smr,aT,vve,Rmr,Pmr,YU,Bmr,Imr,Nmr,nT,Fve,qmr,jmr,KU,Dmr,Gmr,Omr,sT,Tve,Vmr,Xmr,ZU,zmr,Wmr,Qmr,lT,Mve,Umr,Hmr,eH,Jmr,Ymr,Kmr,iT,Zmr,Eve,egr,ogr,Cve,rgr,tgr,dT,MQe,Sd,cT,wve,w9,agr,Ave,ngr,EQe,zo,A9,sgr,Rd,lgr,oH,igr,dgr,rH,cgr,fgr,mgr,L9,ggr,Lve,hgr,pgr,_gr,Et,y9,ugr,yve,bgr,vgr,Pd,Fgr,xve,Tgr,Mgr,tH,Egr,Cgr,wgr,fT,Agr,co,x9,Lgr,$ve,ygr,xgr,Ka,$gr,kve,kgr,Sgr,Sve,Rgr,Pgr,Rve,Bgr,Igr,Ngr,Pve,mT,Bve,qgr,jgr,aH,Dgr,Ggr,Ogr,gT,Vgr,Ive,Xgr,zgr,Nve,Wgr,Qgr,hT,CQe,Bd,pT,qve,$9,Ugr,jve,Hgr,wQe,Wo,k9,Jgr,Id,Ygr,nH,Kgr,Zgr,sH,ehr,ohr,rhr,S9,thr,Dve,ahr,nhr,shr,Ct,R9,lhr,Gve,ihr,dhr,Nd,chr,Ove,fhr,mhr,lH,ghr,hhr,phr,_T,_hr,fo,P9,uhr,Vve,bhr,vhr,Za,Fhr,Xve,Thr,Mhr,zve,Ehr,Chr,Wve,whr,Ahr,Lhr,Qve,uT,Uve,yhr,xhr,iH,$hr,khr,Shr,bT,Rhr,Hve,Phr,Bhr,Jve,Ihr,Nhr,vT,AQe,qd,FT,Yve,B9,qhr,Kve,jhr,LQe,Qo,I9,Dhr,jd,Ghr,dH,Ohr,Vhr,cH,Xhr,zhr,Whr,N9,Qhr,Zve,Uhr,Hhr,Jhr,wt,q9,Yhr,e5e,Khr,Zhr,Dd,epr,o5e,opr,rpr,fH,tpr,apr,npr,TT,spr,mo,j9,lpr,r5e,ipr,dpr,en,cpr,t5e,fpr,mpr,a5e,gpr,hpr,n5e,ppr,_pr,upr,s5e,MT,l5e,bpr,vpr,mH,Fpr,Tpr,Mpr,ET,Epr,i5e,Cpr,wpr,d5e,Apr,Lpr,CT,yQe,Gd,wT,c5e,D9,ypr,f5e,xpr,xQe,Uo,G9,$pr,Od,kpr,gH,Spr,Rpr,hH,Ppr,Bpr,Ipr,O9,Npr,m5e,qpr,jpr,Dpr,At,V9,Gpr,g5e,Opr,Vpr,Vd,Xpr,h5e,zpr,Wpr,pH,Qpr,Upr,Hpr,AT,Jpr,go,X9,Ypr,p5e,Kpr,Zpr,on,e_r,_5e,o_r,r_r,u5e,t_r,a_r,b5e,n_r,s_r,l_r,Pe,LT,v5e,i_r,d_r,_H,c_r,f_r,m_r,yT,F5e,g_r,h_r,uH,p_r,__r,u_r,xT,T5e,b_r,v_r,bH,F_r,T_r,M_r,$T,M5e,E_r,C_r,vH,w_r,A_r,L_r,kT,E5e,y_r,x_r,FH,$_r,k_r,S_r,ST,C5e,R_r,P_r,TH,B_r,I_r,N_r,RT,w5e,q_r,j_r,MH,D_r,G_r,O_r,PT,A5e,V_r,X_r,EH,z_r,W_r,Q_r,BT,L5e,U_r,H_r,CH,J_r,Y_r,K_r,IT,Z_r,y5e,eur,our,x5e,rur,tur,NT,$Qe,Xd,qT,$5e,z9,aur,k5e,nur,kQe,Ho,W9,sur,zd,lur,wH,iur,dur,AH,cur,fur,mur,Q9,gur,S5e,hur,pur,_ur,Lt,U9,uur,R5e,bur,vur,Wd,Fur,P5e,Tur,Mur,LH,Eur,Cur,wur,jT,Aur,ho,H9,Lur,B5e,yur,xur,rn,$ur,I5e,kur,Sur,N5e,Rur,Pur,q5e,Bur,Iur,Nur,at,DT,j5e,qur,jur,yH,Dur,Gur,Our,GT,D5e,Vur,Xur,xH,zur,Wur,Qur,OT,G5e,Uur,Hur,$H,Jur,Yur,Kur,VT,O5e,Zur,e2r,kH,o2r,r2r,t2r,XT,V5e,a2r,n2r,SH,s2r,l2r,i2r,zT,d2r,X5e,c2r,f2r,z5e,m2r,g2r,WT,SQe,Qd,QT,W5e,J9,h2r,Q5e,p2r,RQe,Jo,Y9,_2r,Ud,u2r,RH,b2r,v2r,PH,F2r,T2r,M2r,K9,E2r,U5e,C2r,w2r,A2r,yt,Z9,L2r,H5e,y2r,x2r,Hd,$2r,J5e,k2r,S2r,BH,R2r,P2r,B2r,UT,I2r,po,ex,N2r,Y5e,q2r,j2r,tn,D2r,K5e,G2r,O2r,Z5e,V2r,X2r,eFe,z2r,W2r,Q2r,Le,HT,oFe,U2r,H2r,IH,J2r,Y2r,K2r,JT,rFe,Z2r,e1r,NH,o1r,r1r,t1r,YT,tFe,a1r,n1r,qH,s1r,l1r,i1r,KT,aFe,d1r,c1r,jH,f1r,m1r,g1r,ZT,nFe,h1r,p1r,DH,_1r,u1r,b1r,e8,sFe,v1r,F1r,GH,T1r,M1r,E1r,o8,lFe,C1r,w1r,OH,A1r,L1r,y1r,r8,iFe,x1r,$1r,VH,k1r,S1r,R1r,t8,dFe,P1r,B1r,XH,I1r,N1r,q1r,a8,cFe,j1r,D1r,zH,G1r,O1r,V1r,n8,X1r,fFe,z1r,W1r,mFe,Q1r,U1r,s8,PQe,Jd,l8,gFe,ox,H1r,hFe,J1r,BQe,Yo,rx,Y1r,Yd,K1r,WH,Z1r,e4r,QH,o4r,r4r,t4r,tx,a4r,pFe,n4r,s4r,l4r,xt,ax,i4r,_Fe,d4r,c4r,Kd,f4r,uFe,m4r,g4r,UH,h4r,p4r,_4r,i8,u4r,_o,nx,b4r,bFe,v4r,F4r,an,T4r,vFe,M4r,E4r,FFe,C4r,w4r,TFe,A4r,L4r,y4r,sx,d8,MFe,x4r,$4r,HH,k4r,S4r,R4r,c8,EFe,P4r,B4r,JH,I4r,N4r,q4r,f8,j4r,CFe,D4r,G4r,wFe,O4r,V4r,m8,IQe,Zd,g8,AFe,lx,X4r,LFe,z4r,NQe,Ko,ix,W4r,ec,Q4r,YH,U4r,H4r,KH,J4r,Y4r,K4r,dx,Z4r,yFe,ebr,obr,rbr,$t,cx,tbr,xFe,abr,nbr,oc,sbr,$Fe,lbr,ibr,ZH,dbr,cbr,fbr,h8,mbr,uo,fx,gbr,kFe,hbr,pbr,nn,_br,SFe,ubr,bbr,RFe,vbr,Fbr,PFe,Tbr,Mbr,Ebr,nt,p8,BFe,Cbr,wbr,eJ,Abr,Lbr,ybr,_8,IFe,xbr,$br,oJ,kbr,Sbr,Rbr,u8,NFe,Pbr,Bbr,rJ,Ibr,Nbr,qbr,b8,qFe,jbr,Dbr,tJ,Gbr,Obr,Vbr,v8,jFe,Xbr,zbr,aJ,Wbr,Qbr,Ubr,F8,Hbr,DFe,Jbr,Ybr,GFe,Kbr,Zbr,T8,qQe,rc,M8,OFe,mx,evr,VFe,ovr,jQe,Zo,gx,rvr,tc,tvr,nJ,avr,nvr,sJ,svr,lvr,ivr,hx,dvr,XFe,cvr,fvr,mvr,kt,px,gvr,zFe,hvr,pvr,ac,_vr,WFe,uvr,bvr,lJ,vvr,Fvr,Tvr,E8,Mvr,bo,_x,Evr,QFe,Cvr,wvr,sn,Avr,UFe,Lvr,yvr,HFe,xvr,$vr,JFe,kvr,Svr,Rvr,ln,C8,YFe,Pvr,Bvr,iJ,Ivr,Nvr,qvr,w8,KFe,jvr,Dvr,dJ,Gvr,Ovr,Vvr,A8,ZFe,Xvr,zvr,cJ,Wvr,Qvr,Uvr,L8,eTe,Hvr,Jvr,fJ,Yvr,Kvr,Zvr,y8,e5r,oTe,o5r,r5r,rTe,t5r,a5r,x8,DQe,nc,$8,tTe,ux,n5r,aTe,s5r,GQe,er,bx,l5r,sc,i5r,mJ,d5r,c5r,gJ,f5r,m5r,g5r,vx,h5r,nTe,p5r,_5r,u5r,St,Fx,b5r,sTe,v5r,F5r,lc,T5r,lTe,M5r,E5r,hJ,C5r,w5r,A5r,k8,L5r,vo,Tx,y5r,iTe,x5r,$5r,dn,k5r,dTe,S5r,R5r,cTe,P5r,B5r,fTe,I5r,N5r,q5r,Mx,S8,mTe,j5r,D5r,pJ,G5r,O5r,V5r,R8,gTe,X5r,z5r,_J,W5r,Q5r,U5r,P8,H5r,hTe,J5r,Y5r,pTe,K5r,Z5r,B8,OQe,ic,I8,_Te,Ex,eFr,uTe,oFr,VQe,or,Cx,rFr,dc,tFr,uJ,aFr,nFr,bJ,sFr,lFr,iFr,wx,dFr,bTe,cFr,fFr,mFr,Rt,Ax,gFr,vTe,hFr,pFr,cc,_Fr,FTe,uFr,bFr,vJ,vFr,FFr,TFr,N8,MFr,Fo,Lx,EFr,TTe,CFr,wFr,cn,AFr,MTe,LFr,yFr,ETe,xFr,$Fr,CTe,kFr,SFr,RFr,wTe,q8,ATe,PFr,BFr,FJ,IFr,NFr,qFr,j8,jFr,LTe,DFr,GFr,yTe,OFr,VFr,D8,XQe,fc,G8,xTe,yx,XFr,$Te,zFr,zQe,rr,xx,WFr,mc,QFr,TJ,UFr,HFr,MJ,JFr,YFr,KFr,$x,ZFr,kTe,eTr,oTr,rTr,Pt,kx,tTr,STe,aTr,nTr,gc,sTr,RTe,lTr,iTr,EJ,dTr,cTr,fTr,O8,mTr,To,Sx,gTr,PTe,hTr,pTr,fn,_Tr,BTe,uTr,bTr,ITe,vTr,FTr,NTe,TTr,MTr,ETr,st,V8,qTe,CTr,wTr,CJ,ATr,LTr,yTr,X8,jTe,xTr,$Tr,wJ,kTr,STr,RTr,z8,DTe,PTr,BTr,AJ,ITr,NTr,qTr,W8,GTe,jTr,DTr,LJ,GTr,OTr,VTr,Q8,OTe,XTr,zTr,yJ,WTr,QTr,UTr,U8,HTr,VTe,JTr,YTr,XTe,KTr,ZTr,H8,WQe,hc,J8,zTe,Rx,e8r,WTe,o8r,QQe,tr,Px,r8r,pc,t8r,xJ,a8r,n8r,$J,s8r,l8r,i8r,Bx,d8r,QTe,c8r,f8r,m8r,Bt,Ix,g8r,UTe,h8r,p8r,_c,_8r,HTe,u8r,b8r,kJ,v8r,F8r,T8r,Y8,M8r,Mo,Nx,E8r,JTe,C8r,w8r,mn,A8r,YTe,L8r,y8r,KTe,x8r,$8r,ZTe,k8r,S8r,R8r,e8e,K8,o8e,P8r,B8r,SJ,I8r,N8r,q8r,Z8,j8r,r8e,D8r,G8r,t8e,O8r,V8r,eM,UQe,uc,oM,a8e,qx,X8r,n8e,z8r,HQe,ar,jx,W8r,bc,Q8r,RJ,U8r,H8r,PJ,J8r,Y8r,K8r,Dx,Z8r,s8e,eMr,oMr,rMr,It,Gx,tMr,l8e,aMr,nMr,vc,sMr,i8e,lMr,iMr,BJ,dMr,cMr,fMr,rM,mMr,Sr,Ox,gMr,d8e,hMr,pMr,gn,_Mr,c8e,uMr,bMr,f8e,vMr,FMr,m8e,TMr,MMr,EMr,q,tM,g8e,CMr,wMr,IJ,AMr,LMr,yMr,aM,h8e,xMr,$Mr,NJ,kMr,SMr,RMr,nM,p8e,PMr,BMr,qJ,IMr,NMr,qMr,sM,_8e,jMr,DMr,jJ,GMr,OMr,VMr,lM,u8e,XMr,zMr,DJ,WMr,QMr,UMr,iM,b8e,HMr,JMr,GJ,YMr,KMr,ZMr,dM,v8e,eEr,oEr,OJ,rEr,tEr,aEr,cM,F8e,nEr,sEr,VJ,lEr,iEr,dEr,fM,T8e,cEr,fEr,XJ,mEr,gEr,hEr,mM,M8e,pEr,_Er,zJ,uEr,bEr,vEr,gM,E8e,FEr,TEr,WJ,MEr,EEr,CEr,hM,C8e,wEr,AEr,QJ,LEr,yEr,xEr,pM,w8e,$Er,kEr,UJ,SEr,REr,PEr,_M,A8e,BEr,IEr,HJ,NEr,qEr,jEr,uM,L8e,DEr,GEr,JJ,OEr,VEr,XEr,bM,y8e,zEr,WEr,YJ,QEr,UEr,HEr,vM,x8e,JEr,YEr,KJ,KEr,ZEr,eCr,FM,$8e,oCr,rCr,ZJ,tCr,aCr,nCr,al,k8e,sCr,lCr,eY,iCr,dCr,oY,cCr,fCr,mCr,TM,S8e,gCr,hCr,rY,pCr,_Cr,uCr,MM,R8e,bCr,vCr,tY,FCr,TCr,MCr,EM,P8e,ECr,CCr,aY,wCr,ACr,LCr,CM,B8e,yCr,xCr,nY,$Cr,kCr,SCr,wM,I8e,RCr,PCr,sY,BCr,ICr,NCr,AM,N8e,qCr,jCr,lY,DCr,GCr,OCr,LM,q8e,VCr,XCr,iY,zCr,WCr,QCr,yM,j8e,UCr,HCr,dY,JCr,YCr,KCr,xM,D8e,ZCr,e3r,cY,o3r,r3r,t3r,$M,G8e,a3r,n3r,fY,s3r,l3r,i3r,kM,O8e,d3r,c3r,mY,f3r,m3r,g3r,SM,V8e,h3r,p3r,gY,_3r,u3r,b3r,RM,X8e,v3r,F3r,hY,T3r,M3r,E3r,PM,z8e,C3r,w3r,pY,A3r,L3r,y3r,BM,W8e,x3r,$3r,_Y,k3r,S3r,R3r,IM,Q8e,P3r,B3r,uY,I3r,N3r,q3r,NM,U8e,j3r,D3r,bY,G3r,O3r,V3r,qM,H8e,X3r,z3r,vY,W3r,Q3r,U3r,jM,J8e,H3r,J3r,FY,Y3r,K3r,Z3r,DM,Y8e,e0r,o0r,TY,r0r,t0r,a0r,GM,K8e,n0r,s0r,MY,l0r,i0r,d0r,OM,Z8e,c0r,f0r,EY,m0r,g0r,h0r,VM,eMe,p0r,_0r,CY,u0r,b0r,v0r,XM,oMe,F0r,T0r,wY,M0r,E0r,C0r,zM,rMe,w0r,A0r,AY,L0r,y0r,x0r,WM,tMe,$0r,k0r,LY,S0r,R0r,P0r,QM,aMe,B0r,I0r,yY,N0r,q0r,j0r,UM,nMe,D0r,G0r,xY,O0r,V0r,X0r,HM,sMe,z0r,W0r,$Y,Q0r,U0r,H0r,JM,lMe,J0r,Y0r,kY,K0r,Z0r,ewr,YM,iMe,owr,rwr,SY,twr,awr,nwr,KM,dMe,swr,lwr,RY,iwr,dwr,cwr,ZM,JQe,Fc,eE,cMe,Vx,fwr,fMe,mwr,YQe,nr,Xx,gwr,Tc,hwr,PY,pwr,_wr,BY,uwr,bwr,vwr,zx,Fwr,mMe,Twr,Mwr,Ewr,Nt,Wx,Cwr,gMe,wwr,Awr,Mc,Lwr,hMe,ywr,xwr,IY,$wr,kwr,Swr,oE,Rwr,Rr,Qx,Pwr,pMe,Bwr,Iwr,hn,Nwr,_Me,qwr,jwr,uMe,Dwr,Gwr,bMe,Owr,Vwr,Xwr,se,rE,vMe,zwr,Wwr,NY,Qwr,Uwr,Hwr,tE,FMe,Jwr,Ywr,qY,Kwr,Zwr,e6r,aE,TMe,o6r,r6r,jY,t6r,a6r,n6r,nE,MMe,s6r,l6r,DY,i6r,d6r,c6r,sE,EMe,f6r,m6r,GY,g6r,h6r,p6r,lE,CMe,_6r,u6r,OY,b6r,v6r,F6r,iE,wMe,T6r,M6r,VY,E6r,C6r,w6r,dE,AMe,A6r,L6r,XY,y6r,x6r,$6r,cE,LMe,k6r,S6r,zY,R6r,P6r,B6r,fE,yMe,I6r,N6r,WY,q6r,j6r,D6r,mE,xMe,G6r,O6r,QY,V6r,X6r,z6r,gE,$Me,W6r,Q6r,UY,U6r,H6r,J6r,hE,kMe,Y6r,K6r,HY,Z6r,eAr,oAr,pE,SMe,rAr,tAr,JY,aAr,nAr,sAr,_E,RMe,lAr,iAr,YY,dAr,cAr,fAr,uE,PMe,mAr,gAr,KY,hAr,pAr,_Ar,bE,BMe,uAr,bAr,ZY,vAr,FAr,TAr,vE,IMe,MAr,EAr,eK,CAr,wAr,AAr,FE,NMe,LAr,yAr,oK,xAr,$Ar,kAr,TE,qMe,SAr,RAr,rK,PAr,BAr,IAr,ME,jMe,NAr,qAr,tK,jAr,DAr,GAr,EE,DMe,OAr,VAr,aK,XAr,zAr,WAr,CE,GMe,QAr,UAr,nK,HAr,JAr,YAr,wE,KQe,Ec,AE,OMe,Ux,KAr,VMe,ZAr,ZQe,sr,Hx,e7r,Cc,o7r,sK,r7r,t7r,lK,a7r,n7r,s7r,Jx,l7r,XMe,i7r,d7r,c7r,qt,Yx,f7r,zMe,m7r,g7r,wc,h7r,WMe,p7r,_7r,iK,u7r,b7r,v7r,LE,F7r,Pr,Kx,T7r,QMe,M7r,E7r,pn,C7r,UMe,w7r,A7r,HMe,L7r,y7r,JMe,x7r,$7r,k7r,Me,yE,YMe,S7r,R7r,dK,P7r,B7r,I7r,xE,KMe,N7r,q7r,cK,j7r,D7r,G7r,$E,ZMe,O7r,V7r,fK,X7r,z7r,W7r,kE,eEe,Q7r,U7r,mK,H7r,J7r,Y7r,SE,oEe,K7r,Z7r,gK,eLr,oLr,rLr,RE,rEe,tLr,aLr,hK,nLr,sLr,lLr,PE,tEe,iLr,dLr,pK,cLr,fLr,mLr,BE,aEe,gLr,hLr,_K,pLr,_Lr,uLr,IE,nEe,bLr,vLr,uK,FLr,TLr,MLr,NE,sEe,ELr,CLr,bK,wLr,ALr,LLr,qE,lEe,yLr,xLr,vK,$Lr,kLr,SLr,jE,iEe,RLr,PLr,FK,BLr,ILr,NLr,DE,dEe,qLr,jLr,TK,DLr,GLr,OLr,GE,eUe,Ac,OE,cEe,Zx,VLr,fEe,XLr,oUe,lr,e$,zLr,Lc,WLr,MK,QLr,ULr,EK,HLr,JLr,YLr,o$,KLr,mEe,ZLr,eyr,oyr,jt,r$,ryr,gEe,tyr,ayr,yc,nyr,hEe,syr,lyr,CK,iyr,dyr,cyr,VE,fyr,Br,t$,myr,pEe,gyr,hyr,_n,pyr,_Ee,_yr,uyr,uEe,byr,vyr,bEe,Fyr,Tyr,Myr,Ve,XE,vEe,Eyr,Cyr,wK,wyr,Ayr,Lyr,zE,FEe,yyr,xyr,AK,$yr,kyr,Syr,nl,TEe,Ryr,Pyr,LK,Byr,Iyr,yK,Nyr,qyr,jyr,WE,MEe,Dyr,Gyr,xK,Oyr,Vyr,Xyr,QE,EEe,zyr,Wyr,$K,Qyr,Uyr,Hyr,UE,CEe,Jyr,Yyr,kK,Kyr,Zyr,e9r,HE,wEe,o9r,r9r,SK,t9r,a9r,n9r,JE,AEe,s9r,l9r,RK,i9r,d9r,c9r,YE,rUe,xc,KE,LEe,a$,f9r,yEe,m9r,tUe,ir,n$,g9r,$c,h9r,PK,p9r,_9r,BK,u9r,b9r,v9r,s$,F9r,xEe,T9r,M9r,E9r,Dt,l$,C9r,$Ee,w9r,A9r,kc,L9r,kEe,y9r,x9r,IK,$9r,k9r,S9r,ZE,R9r,Ir,i$,P9r,SEe,B9r,I9r,un,N9r,REe,q9r,j9r,PEe,D9r,G9r,BEe,O9r,V9r,X9r,ie,eC,IEe,z9r,W9r,NK,Q9r,U9r,H9r,oC,NEe,J9r,Y9r,qK,K9r,Z9r,exr,rC,qEe,oxr,rxr,jK,txr,axr,nxr,tC,jEe,sxr,lxr,DK,ixr,dxr,cxr,aC,DEe,fxr,mxr,GK,gxr,hxr,pxr,nC,GEe,_xr,uxr,OK,bxr,vxr,Fxr,sC,OEe,Txr,Mxr,VK,Exr,Cxr,wxr,lC,VEe,Axr,Lxr,XK,yxr,xxr,$xr,iC,XEe,kxr,Sxr,zK,Rxr,Pxr,Bxr,dC,zEe,Ixr,Nxr,WK,qxr,jxr,Dxr,cC,WEe,Gxr,Oxr,QK,Vxr,Xxr,zxr,fC,QEe,Wxr,Qxr,UK,Uxr,Hxr,Jxr,mC,UEe,Yxr,Kxr,HK,Zxr,e$r,o$r,gC,HEe,r$r,t$r,JK,a$r,n$r,s$r,hC,JEe,l$r,i$r,YK,d$r,c$r,f$r,pC,YEe,m$r,g$r,KK,h$r,p$r,_$r,_C,KEe,u$r,b$r,ZK,v$r,F$r,T$r,uC,ZEe,M$r,E$r,eZ,C$r,w$r,A$r,bC,eCe,L$r,y$r,oZ,x$r,$$r,k$r,vC,oCe,S$r,R$r,rZ,P$r,B$r,I$r,FC,aUe,Sc,TC,rCe,d$,N$r,tCe,q$r,nUe,dr,c$,j$r,Rc,D$r,tZ,G$r,O$r,aZ,V$r,X$r,z$r,f$,W$r,aCe,Q$r,U$r,H$r,Gt,m$,J$r,nCe,Y$r,K$r,Pc,Z$r,sCe,ekr,okr,nZ,rkr,tkr,akr,MC,nkr,Nr,g$,skr,lCe,lkr,ikr,bn,dkr,iCe,ckr,fkr,dCe,mkr,gkr,cCe,hkr,pkr,_kr,ye,EC,fCe,ukr,bkr,sZ,vkr,Fkr,Tkr,CC,mCe,Mkr,Ekr,lZ,Ckr,wkr,Akr,wC,gCe,Lkr,ykr,iZ,xkr,$kr,kkr,AC,hCe,Skr,Rkr,dZ,Pkr,Bkr,Ikr,LC,pCe,Nkr,qkr,cZ,jkr,Dkr,Gkr,yC,_Ce,Okr,Vkr,fZ,Xkr,zkr,Wkr,xC,uCe,Qkr,Ukr,mZ,Hkr,Jkr,Ykr,$C,bCe,Kkr,Zkr,gZ,eSr,oSr,rSr,kC,vCe,tSr,aSr,hZ,nSr,sSr,lSr,SC,FCe,iSr,dSr,pZ,cSr,fSr,mSr,RC,sUe,Bc,PC,TCe,h$,gSr,MCe,hSr,lUe,cr,p$,pSr,Ic,_Sr,_Z,uSr,bSr,uZ,vSr,FSr,TSr,_$,MSr,ECe,ESr,CSr,wSr,Ot,u$,ASr,CCe,LSr,ySr,Nc,xSr,wCe,$Sr,kSr,bZ,SSr,RSr,PSr,BC,BSr,qr,b$,ISr,ACe,NSr,qSr,vn,jSr,LCe,DSr,GSr,yCe,OSr,VSr,xCe,XSr,zSr,WSr,te,IC,$Ce,QSr,USr,vZ,HSr,JSr,YSr,NC,kCe,KSr,ZSr,FZ,eRr,oRr,rRr,qC,SCe,tRr,aRr,TZ,nRr,sRr,lRr,jC,RCe,iRr,dRr,MZ,cRr,fRr,mRr,DC,PCe,gRr,hRr,EZ,pRr,_Rr,uRr,GC,BCe,bRr,vRr,CZ,FRr,TRr,MRr,OC,ICe,ERr,CRr,wZ,wRr,ARr,LRr,VC,NCe,yRr,xRr,AZ,$Rr,kRr,SRr,XC,qCe,RRr,PRr,LZ,BRr,IRr,NRr,zC,jCe,qRr,jRr,yZ,DRr,GRr,ORr,WC,DCe,VRr,XRr,xZ,zRr,WRr,QRr,QC,GCe,URr,HRr,$Z,JRr,YRr,KRr,UC,OCe,ZRr,ePr,kZ,oPr,rPr,tPr,HC,VCe,aPr,nPr,SZ,sPr,lPr,iPr,JC,XCe,dPr,cPr,RZ,fPr,mPr,gPr,YC,zCe,hPr,pPr,PZ,_Pr,uPr,bPr,KC,WCe,vPr,FPr,BZ,TPr,MPr,EPr,ZC,QCe,CPr,wPr,IZ,APr,LPr,yPr,e3,UCe,xPr,$Pr,NZ,kPr,SPr,RPr,o3,HCe,PPr,BPr,qZ,IPr,NPr,qPr,r3,JCe,jPr,DPr,jZ,GPr,OPr,VPr,t3,YCe,XPr,zPr,DZ,WPr,QPr,UPr,a3,KCe,HPr,JPr,GZ,YPr,KPr,ZPr,n3,ZCe,eBr,oBr,OZ,rBr,tBr,aBr,s3,e3e,nBr,sBr,VZ,lBr,iBr,dBr,l3,o3e,cBr,fBr,XZ,mBr,gBr,hBr,i3,iUe,qc,d3,r3e,v$,pBr,t3e,_Br,dUe,fr,F$,uBr,jc,bBr,zZ,vBr,FBr,WZ,TBr,MBr,EBr,T$,CBr,a3e,wBr,ABr,LBr,Vt,M$,yBr,n3e,xBr,$Br,Dc,kBr,s3e,SBr,RBr,QZ,PBr,BBr,IBr,c3,NBr,jr,E$,qBr,l3e,jBr,DBr,Fn,GBr,i3e,OBr,VBr,d3e,XBr,zBr,c3e,WBr,QBr,UBr,ve,f3,f3e,HBr,JBr,UZ,YBr,KBr,ZBr,m3,m3e,eIr,oIr,HZ,rIr,tIr,aIr,g3,g3e,nIr,sIr,JZ,lIr,iIr,dIr,h3,h3e,cIr,fIr,YZ,mIr,gIr,hIr,p3,p3e,pIr,_Ir,KZ,uIr,bIr,vIr,_3,_3e,FIr,TIr,ZZ,MIr,EIr,CIr,u3,u3e,wIr,AIr,eee,LIr,yIr,xIr,b3,b3e,$Ir,kIr,oee,SIr,RIr,PIr,v3,v3e,BIr,IIr,ree,NIr,qIr,jIr,F3,F3e,DIr,GIr,tee,OIr,VIr,XIr,T3,T3e,zIr,WIr,aee,QIr,UIr,HIr,M3,M3e,JIr,YIr,nee,KIr,ZIr,eNr,E3,E3e,oNr,rNr,see,tNr,aNr,nNr,C3,C3e,sNr,lNr,lee,iNr,dNr,cNr,w3,w3e,fNr,mNr,iee,gNr,hNr,pNr,A3,A3e,_Nr,uNr,dee,bNr,vNr,FNr,L3,L3e,TNr,MNr,cee,ENr,CNr,wNr,y3,cUe,Gc,x3,y3e,C$,ANr,x3e,LNr,fUe,mr,w$,yNr,Oc,xNr,fee,$Nr,kNr,mee,SNr,RNr,PNr,A$,BNr,$3e,INr,NNr,qNr,Xt,L$,jNr,k3e,DNr,GNr,Vc,ONr,S3e,VNr,XNr,gee,zNr,WNr,QNr,$3,UNr,Dr,y$,HNr,R3e,JNr,YNr,Tn,KNr,P3e,ZNr,eqr,B3e,oqr,rqr,I3e,tqr,aqr,nqr,x$,k3,N3e,sqr,lqr,hee,iqr,dqr,cqr,S3,q3e,fqr,mqr,pee,gqr,hqr,pqr,R3,mUe,Xc,P3,j3e,$$,_qr,D3e,uqr,gUe,gr,k$,bqr,zc,vqr,_ee,Fqr,Tqr,uee,Mqr,Eqr,Cqr,S$,wqr,G3e,Aqr,Lqr,yqr,zt,R$,xqr,O3e,$qr,kqr,Wc,Sqr,V3e,Rqr,Pqr,bee,Bqr,Iqr,Nqr,B3,qqr,Gr,P$,jqr,X3e,Dqr,Gqr,Mn,Oqr,z3e,Vqr,Xqr,W3e,zqr,Wqr,Q3e,Qqr,Uqr,Hqr,U3e,I3,H3e,Jqr,Yqr,vee,Kqr,Zqr,ejr,N3,hUe,Qc,q3,J3e,B$,ojr,Y3e,rjr,pUe,hr,I$,tjr,Uc,ajr,Fee,njr,sjr,Tee,ljr,ijr,djr,N$,cjr,K3e,fjr,mjr,gjr,Wt,q$,hjr,Z3e,pjr,_jr,Hc,ujr,e0e,bjr,vjr,Mee,Fjr,Tjr,Mjr,j3,Ejr,Or,j$,Cjr,o0e,wjr,Ajr,En,Ljr,r0e,yjr,xjr,t0e,$jr,kjr,a0e,Sjr,Rjr,Pjr,de,D3,n0e,Bjr,Ijr,Eee,Njr,qjr,jjr,G3,s0e,Djr,Gjr,Cee,Ojr,Vjr,Xjr,O3,l0e,zjr,Wjr,wee,Qjr,Ujr,Hjr,V3,i0e,Jjr,Yjr,Aee,Kjr,Zjr,eDr,X3,d0e,oDr,rDr,Lee,tDr,aDr,nDr,z3,c0e,sDr,lDr,yee,iDr,dDr,cDr,W3,f0e,fDr,mDr,xee,gDr,hDr,pDr,Q3,m0e,_Dr,uDr,$ee,bDr,vDr,FDr,U3,g0e,TDr,MDr,kee,EDr,CDr,wDr,H3,h0e,ADr,LDr,See,yDr,xDr,$Dr,J3,p0e,kDr,SDr,Ree,RDr,PDr,BDr,Y3,_0e,IDr,NDr,Pee,qDr,jDr,DDr,K3,u0e,GDr,ODr,Bee,VDr,XDr,zDr,Z3,b0e,WDr,QDr,Iee,UDr,HDr,JDr,e0,v0e,YDr,KDr,Nee,ZDr,eGr,oGr,o0,F0e,rGr,tGr,qee,aGr,nGr,sGr,r0,T0e,lGr,iGr,jee,dGr,cGr,fGr,t0,M0e,mGr,gGr,Dee,hGr,pGr,_Gr,a0,E0e,uGr,bGr,Gee,vGr,FGr,TGr,n0,C0e,MGr,EGr,Oee,CGr,wGr,AGr,s0,_Ue,Jc,l0,w0e,D$,LGr,A0e,yGr,uUe,pr,G$,xGr,Yc,$Gr,Vee,kGr,SGr,Xee,RGr,PGr,BGr,O$,IGr,L0e,NGr,qGr,jGr,Qt,V$,DGr,y0e,GGr,OGr,Kc,VGr,x0e,XGr,zGr,zee,WGr,QGr,UGr,i0,HGr,Vr,X$,JGr,$0e,YGr,KGr,Cn,ZGr,k0e,eOr,oOr,S0e,rOr,tOr,R0e,aOr,nOr,sOr,ce,d0,P0e,lOr,iOr,Wee,dOr,cOr,fOr,c0,B0e,mOr,gOr,Qee,hOr,pOr,_Or,f0,I0e,uOr,bOr,Uee,vOr,FOr,TOr,m0,N0e,MOr,EOr,Hee,COr,wOr,AOr,g0,q0e,LOr,yOr,Jee,xOr,$Or,kOr,h0,j0e,SOr,ROr,Yee,POr,BOr,IOr,p0,D0e,NOr,qOr,Kee,jOr,DOr,GOr,_0,G0e,OOr,VOr,Zee,XOr,zOr,WOr,u0,O0e,QOr,UOr,eoe,HOr,JOr,YOr,b0,V0e,KOr,ZOr,ooe,eVr,oVr,rVr,v0,X0e,tVr,aVr,roe,nVr,sVr,lVr,F0,z0e,iVr,dVr,toe,cVr,fVr,mVr,T0,W0e,gVr,hVr,aoe,pVr,_Vr,uVr,M0,Q0e,bVr,vVr,noe,FVr,TVr,MVr,E0,U0e,EVr,CVr,soe,wVr,AVr,LVr,C0,H0e,yVr,xVr,loe,$Vr,kVr,SVr,w0,J0e,RVr,PVr,ioe,BVr,IVr,NVr,A0,Y0e,qVr,jVr,doe,DVr,GVr,OVr,L0,K0e,VVr,XVr,coe,zVr,WVr,QVr,y0,Z0e,UVr,HVr,foe,JVr,YVr,KVr,x0,bUe,Zc,$0,ewe,z$,ZVr,owe,eXr,vUe,_r,W$,oXr,ef,rXr,moe,tXr,aXr,goe,nXr,sXr,lXr,Q$,iXr,rwe,dXr,cXr,fXr,Ut,U$,mXr,twe,gXr,hXr,of,pXr,awe,_Xr,uXr,hoe,bXr,vXr,FXr,k0,TXr,Xr,H$,MXr,nwe,EXr,CXr,wn,wXr,swe,AXr,LXr,lwe,yXr,xXr,iwe,$Xr,kXr,SXr,dwe,S0,cwe,RXr,PXr,poe,BXr,IXr,NXr,R0,FUe,rf,P0,fwe,J$,qXr,mwe,jXr,TUe,ur,Y$,DXr,tf,GXr,_oe,OXr,VXr,uoe,XXr,zXr,WXr,K$,QXr,gwe,UXr,HXr,JXr,Ht,Z$,YXr,hwe,KXr,ZXr,af,ezr,pwe,ozr,rzr,boe,tzr,azr,nzr,B0,szr,zr,ek,lzr,_we,izr,dzr,An,czr,uwe,fzr,mzr,bwe,gzr,hzr,vwe,pzr,_zr,uzr,Fwe,I0,Twe,bzr,vzr,voe,Fzr,Tzr,Mzr,N0,MUe,nf,q0,Mwe,ok,Ezr,Ewe,Czr,EUe,br,rk,wzr,sf,Azr,Foe,Lzr,yzr,Toe,xzr,$zr,kzr,tk,Szr,Cwe,Rzr,Pzr,Bzr,Jt,ak,Izr,wwe,Nzr,qzr,lf,jzr,Awe,Dzr,Gzr,Moe,Ozr,Vzr,Xzr,j0,zzr,Wr,nk,Wzr,Lwe,Qzr,Uzr,Ln,Hzr,ywe,Jzr,Yzr,xwe,Kzr,Zzr,$we,eWr,oWr,rWr,oe,D0,kwe,tWr,aWr,Eoe,nWr,sWr,lWr,G0,Swe,iWr,dWr,Coe,cWr,fWr,mWr,O0,Rwe,gWr,hWr,woe,pWr,_Wr,uWr,V0,Pwe,bWr,vWr,Aoe,FWr,TWr,MWr,X0,Bwe,EWr,CWr,Loe,wWr,AWr,LWr,z0,Iwe,yWr,xWr,yoe,$Wr,kWr,SWr,W0,Nwe,RWr,PWr,xoe,BWr,IWr,NWr,Q0,qwe,qWr,jWr,$oe,DWr,GWr,OWr,U0,jwe,VWr,XWr,koe,zWr,WWr,QWr,H0,Dwe,UWr,HWr,Soe,JWr,YWr,KWr,J0,Gwe,ZWr,eQr,Roe,oQr,rQr,tQr,Y0,Owe,aQr,nQr,Poe,sQr,lQr,iQr,K0,Vwe,dQr,cQr,Boe,fQr,mQr,gQr,Z0,Xwe,hQr,pQr,Ioe,_Qr,uQr,bQr,ew,zwe,vQr,FQr,Noe,TQr,MQr,EQr,ow,Wwe,CQr,wQr,qoe,AQr,LQr,yQr,rw,Qwe,xQr,$Qr,joe,kQr,SQr,RQr,tw,Uwe,PQr,BQr,Doe,IQr,NQr,qQr,aw,Hwe,jQr,DQr,Goe,GQr,OQr,VQr,nw,Jwe,XQr,zQr,Ooe,WQr,QQr,UQr,sw,Ywe,HQr,JQr,Voe,YQr,KQr,ZQr,lw,Kwe,eUr,oUr,Xoe,rUr,tUr,aUr,iw,Zwe,nUr,sUr,zoe,lUr,iUr,dUr,dw,e6e,cUr,fUr,Woe,mUr,gUr,hUr,cw,o6e,pUr,_Ur,Qoe,uUr,bUr,vUr,fw,r6e,FUr,TUr,Uoe,MUr,EUr,CUr,mw,t6e,wUr,AUr,Hoe,LUr,yUr,xUr,gw,CUe,df,hw,a6e,sk,$Ur,n6e,kUr,wUe,vr,lk,SUr,cf,RUr,Joe,PUr,BUr,Yoe,IUr,NUr,qUr,ik,jUr,s6e,DUr,GUr,OUr,Yt,dk,VUr,l6e,XUr,zUr,ff,WUr,i6e,QUr,UUr,Koe,HUr,JUr,YUr,pw,KUr,Qr,ck,ZUr,d6e,eHr,oHr,yn,rHr,c6e,tHr,aHr,f6e,nHr,sHr,m6e,lHr,iHr,dHr,xe,_w,g6e,cHr,fHr,Zoe,mHr,gHr,hHr,uw,h6e,pHr,_Hr,ere,uHr,bHr,vHr,bw,p6e,FHr,THr,ore,MHr,EHr,CHr,vw,_6e,wHr,AHr,rre,LHr,yHr,xHr,Fw,u6e,$Hr,kHr,tre,SHr,RHr,PHr,Tw,b6e,BHr,IHr,are,NHr,qHr,jHr,Mw,v6e,DHr,GHr,nre,OHr,VHr,XHr,Ew,F6e,zHr,WHr,sre,QHr,UHr,HHr,Cw,T6e,JHr,YHr,lre,KHr,ZHr,eJr,ww,M6e,oJr,rJr,ire,tJr,aJr,nJr,Aw,AUe,mf,Lw,E6e,fk,sJr,C6e,lJr,LUe,Fr,mk,iJr,gf,dJr,dre,cJr,fJr,cre,mJr,gJr,hJr,gk,pJr,w6e,_Jr,uJr,bJr,Kt,hk,vJr,A6e,FJr,TJr,hf,MJr,L6e,EJr,CJr,fre,wJr,AJr,LJr,yw,yJr,Ur,pk,xJr,y6e,$Jr,kJr,xn,SJr,x6e,RJr,PJr,$6e,BJr,IJr,k6e,NJr,qJr,jJr,Ee,xw,S6e,DJr,GJr,mre,OJr,VJr,XJr,$w,R6e,zJr,WJr,gre,QJr,UJr,HJr,kw,P6e,JJr,YJr,hre,KJr,ZJr,eYr,Sw,B6e,oYr,rYr,pre,tYr,aYr,nYr,Rw,I6e,sYr,lYr,_re,iYr,dYr,cYr,Pw,N6e,fYr,mYr,ure,gYr,hYr,pYr,Bw,q6e,_Yr,uYr,bre,bYr,vYr,FYr,Iw,j6e,TYr,MYr,vre,EYr,CYr,wYr,Nw,D6e,AYr,LYr,Fre,yYr,xYr,$Yr,qw,G6e,kYr,SYr,Tre,RYr,PYr,BYr,jw,O6e,IYr,NYr,Mre,qYr,jYr,DYr,Dw,V6e,GYr,OYr,Ere,VYr,XYr,zYr,Gw,X6e,WYr,QYr,Cre,UYr,HYr,JYr,Ow,yUe,pf,Vw,z6e,_k,YYr,W6e,KYr,xUe,Tr,uk,ZYr,_f,eKr,wre,oKr,rKr,Are,tKr,aKr,nKr,bk,sKr,Q6e,lKr,iKr,dKr,Zt,vk,cKr,U6e,fKr,mKr,uf,gKr,H6e,hKr,pKr,Lre,_Kr,uKr,bKr,Xw,vKr,Hr,Fk,FKr,J6e,TKr,MKr,$n,EKr,Y6e,CKr,wKr,K6e,AKr,LKr,Z6e,yKr,xKr,$Kr,$e,zw,eAe,kKr,SKr,yre,RKr,PKr,BKr,Ww,oAe,IKr,NKr,xre,qKr,jKr,DKr,Qw,rAe,GKr,OKr,$re,VKr,XKr,zKr,Uw,tAe,WKr,QKr,kre,UKr,HKr,JKr,Hw,aAe,YKr,KKr,Sre,ZKr,eZr,oZr,Jw,nAe,rZr,tZr,Rre,aZr,nZr,sZr,Yw,sAe,lZr,iZr,Pre,dZr,cZr,fZr,Kw,lAe,mZr,gZr,Bre,hZr,pZr,_Zr,Zw,iAe,uZr,bZr,Ire,vZr,FZr,TZr,e6,dAe,MZr,EZr,Nre,CZr,wZr,AZr,o6,$Ue,bf,r6,cAe,Tk,LZr,fAe,yZr,kUe,Mr,Mk,xZr,vf,$Zr,qre,kZr,SZr,jre,RZr,PZr,BZr,Ek,IZr,mAe,NZr,qZr,jZr,ea,Ck,DZr,gAe,GZr,OZr,Ff,VZr,hAe,XZr,zZr,Dre,WZr,QZr,UZr,t6,HZr,Jr,wk,JZr,pAe,YZr,KZr,kn,ZZr,_Ae,eet,oet,uAe,ret,tet,bAe,aet,net,set,ke,a6,vAe,iet,det,Gre,cet,fet,met,n6,FAe,get,het,Ore,pet,_et,uet,s6,TAe,bet,vet,Vre,Fet,Tet,Met,l6,MAe,Eet,Cet,Xre,wet,Aet,Let,i6,EAe,yet,xet,zre,$et,ket,Set,d6,CAe,Ret,Pet,Wre,Bet,Iet,Net,c6,wAe,qet,jet,Qre,Det,Get,Oet,f6,AAe,Vet,Xet,Ure,zet,Wet,Qet,m6,LAe,Uet,Het,Hre,Jet,Yet,Ket,g6,yAe,Zet,eot,Jre,oot,rot,tot,h6,SUe,Tf,p6,xAe,Ak,aot,$Ae,not,RUe,Er,Lk,sot,Mf,lot,Yre,iot,dot,Kre,cot,fot,mot,yk,got,kAe,hot,pot,_ot,oa,xk,uot,SAe,bot,vot,Ef,Fot,RAe,Tot,Mot,Zre,Eot,Cot,wot,_6,Aot,Yr,$k,Lot,PAe,yot,xot,Sn,$ot,BAe,kot,Sot,IAe,Rot,Pot,NAe,Bot,Iot,Not,Se,u6,qAe,qot,jot,ete,Dot,Got,Oot,b6,jAe,Vot,Xot,ote,zot,Wot,Qot,v6,DAe,Uot,Hot,rte,Jot,Yot,Kot,F6,GAe,Zot,ert,tte,ort,rrt,trt,T6,OAe,art,nrt,ate,srt,lrt,irt,M6,VAe,drt,crt,nte,frt,mrt,grt,E6,XAe,hrt,prt,ste,_rt,urt,brt,C6,zAe,vrt,Frt,lte,Trt,Mrt,Ert,w6,WAe,Crt,wrt,ite,Art,Lrt,yrt,A6,QAe,xrt,$rt,dte,krt,Srt,Rrt,L6,PUe,Cf,y6,UAe,kk,Prt,HAe,Brt,BUe,Cr,Sk,Irt,wf,Nrt,cte,qrt,jrt,fte,Drt,Grt,Ort,Rk,Vrt,JAe,Xrt,zrt,Wrt,ra,Pk,Qrt,YAe,Urt,Hrt,Af,Jrt,KAe,Yrt,Krt,mte,Zrt,ett,ott,x6,rtt,Kr,Bk,ttt,ZAe,att,ntt,Rn,stt,e7e,ltt,itt,o7e,dtt,ctt,r7e,ftt,mtt,gtt,Re,$6,t7e,htt,ptt,gte,_tt,utt,btt,k6,a7e,vtt,Ftt,hte,Ttt,Mtt,Ett,S6,n7e,Ctt,wtt,pte,Att,Ltt,ytt,R6,s7e,xtt,$tt,_te,ktt,Stt,Rtt,P6,l7e,Ptt,Btt,ute,Itt,Ntt,qtt,B6,i7e,jtt,Dtt,bte,Gtt,Ott,Vtt,I6,d7e,Xtt,ztt,vte,Wtt,Qtt,Utt,N6,c7e,Htt,Jtt,Fte,Ytt,Ktt,Ztt,q6,f7e,eat,oat,Tte,rat,tat,aat,j6,m7e,nat,sat,Mte,lat,iat,dat,D6,IUe,Lf,G6,g7e,Ik,cat,h7e,fat,NUe,wr,Nk,mat,yf,gat,Ete,hat,pat,Cte,_at,uat,bat,qk,vat,p7e,Fat,Tat,Mat,ta,jk,Eat,_7e,Cat,wat,xf,Aat,u7e,Lat,yat,wte,xat,$at,kat,O6,Sat,Zr,Dk,Rat,b7e,Pat,Bat,Pn,Iat,v7e,Nat,qat,F7e,jat,Dat,T7e,Gat,Oat,Vat,Xe,V6,M7e,Xat,zat,Ate,Wat,Qat,Uat,X6,E7e,Hat,Jat,Lte,Yat,Kat,Zat,z6,C7e,ent,ont,yte,rnt,tnt,ant,W6,w7e,nnt,snt,xte,lnt,int,dnt,Q6,A7e,cnt,fnt,$te,mnt,gnt,hnt,U6,L7e,pnt,_nt,kte,unt,bnt,vnt,H6,y7e,Fnt,Tnt,Ste,Mnt,Ent,Cnt,J6,x7e,wnt,Ant,Rte,Lnt,ynt,xnt,Y6,qUe,$f,K6,$7e,Gk,$nt,k7e,knt,jUe,Ar,Ok,Snt,kf,Rnt,Pte,Pnt,Bnt,Bte,Int,Nnt,qnt,Vk,jnt,S7e,Dnt,Gnt,Ont,aa,Xk,Vnt,R7e,Xnt,znt,Sf,Wnt,P7e,Qnt,Unt,Ite,Hnt,Jnt,Ynt,Z6,Knt,et,zk,Znt,B7e,est,ost,Bn,rst,I7e,tst,ast,N7e,nst,sst,q7e,lst,ist,dst,ze,eA,j7e,cst,fst,Nte,mst,gst,hst,oA,D7e,pst,_st,qte,ust,bst,vst,rA,G7e,Fst,Tst,jte,Mst,Est,Cst,tA,O7e,wst,Ast,Dte,Lst,yst,xst,aA,V7e,$st,kst,Gte,Sst,Rst,Pst,nA,X7e,Bst,Ist,Ote,Nst,qst,jst,sA,z7e,Dst,Gst,Vte,Ost,Vst,Xst,lA,W7e,zst,Wst,Xte,Qst,Ust,Hst,iA,DUe,Rf,dA,Q7e,Wk,Jst,U7e,Yst,GUe,Lr,Qk,Kst,Pf,Zst,zte,elt,olt,Wte,rlt,tlt,alt,Uk,nlt,H7e,slt,llt,ilt,na,Hk,dlt,J7e,clt,flt,Bf,mlt,Y7e,glt,hlt,Qte,plt,_lt,ult,cA,blt,ot,Jk,vlt,K7e,Flt,Tlt,In,Mlt,Z7e,Elt,Clt,eLe,wlt,Alt,oLe,Llt,ylt,xlt,rLe,fA,tLe,$lt,klt,Ute,Slt,Rlt,Plt,mA,OUe,If,gA,aLe,Yk,Blt,nLe,Ilt,VUe,yr,Kk,Nlt,Nf,qlt,Hte,jlt,Dlt,Jte,Glt,Olt,Vlt,Zk,Xlt,sLe,zlt,Wlt,Qlt,sa,eS,Ult,lLe,Hlt,Jlt,qf,Ylt,iLe,Klt,Zlt,Yte,eit,oit,rit,hA,tit,rt,oS,ait,dLe,nit,sit,Nn,lit,cLe,iit,dit,fLe,cit,fit,mLe,mit,git,hit,rS,pA,gLe,pit,_it,Kte,uit,bit,vit,_A,hLe,Fit,Tit,Zte,Mit,Eit,Cit,uA,XUe,jf,bA,pLe,tS,wit,_Le,Ait,zUe,xr,aS,Lit,Df,yit,eae,xit,$it,oae,kit,Sit,Rit,nS,Pit,uLe,Bit,Iit,Nit,la,sS,qit,bLe,jit,Dit,Gf,Git,vLe,Oit,Vit,rae,Xit,zit,Wit,vA,Qit,tt,lS,Uit,FLe,Hit,Jit,qn,Yit,TLe,Kit,Zit,MLe,edt,odt,ELe,rdt,tdt,adt,CLe,FA,wLe,ndt,sdt,tae,ldt,idt,ddt,TA,WUe;return d=new re({}),Ia=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),QL=new re({}),UL=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Jf=new cdt({props:{warning:!0,$$slots:{default:[nea]},$$scope:{ctx:$}}}),HL=new re({}),JL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/configuration_auto.py#L620"}}),ZL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/configuration_auto.py#L643"}}),fh=new I({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[sea]},$$scope:{ctx:$}}}),ey=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/configuration_auto.py#L766"}}),oy=new re({}),ry=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/tokenization_auto.py#L411"}}),ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_18524/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/tokenization_auto.py#L425"}}),Qh=new I({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[lea]},$$scope:{ctx:$}}}),sy=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/tokenization_auto.py#L624"}}),ly=new re({}),iy=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/feature_extraction_auto.py#L199"}}),fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_18524/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/feature_extraction_auto.py#L213"}}),Pp=new cdt({props:{$$slots:{default:[iea]},$$scope:{ctx:$}}}),Bp=new I({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[dea]},$$scope:{ctx:$}}}),my=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/feature_extraction_auto.py#L340"}}),gy=new re({}),hy=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/processing_auto.py#L90"}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/processing_auto.py#L104"}}),t_=new cdt({props:{$$slots:{default:[cea]},$$scope:{ctx:$}}}),a_=new I({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[fea]},$$scope:{ctx:$}}}),by=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/processing_auto.py#L257"}}),vy=new re({}),Fy=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L818"}}),My=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),l_=new I({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[mea]},$$scope:{ctx:$}}}),Ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),p2=new I({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[gea]},$$scope:{ctx:$}}}),Cy=new re({}),wy=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L825"}}),Ly=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),u2=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[hea]},$$scope:{ctx:$}}}),yy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),m1=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[pea]},$$scope:{ctx:$}}}),xy=new re({}),$y=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L840"}}),Sy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),h1=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[_ea]},$$scope:{ctx:$}}}),Ry=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),r4=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[uea]},$$scope:{ctx:$}}}),Py=new re({}),By=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L847"}}),Ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),a4=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[bea]},$$scope:{ctx:$}}}),qy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),X4=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[vea]},$$scope:{ctx:$}}}),jy=new re({}),Dy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L854"}}),Oy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),W4=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Fea]},$$scope:{ctx:$}}}),Vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),gb=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Tea]},$$scope:{ctx:$}}}),Xy=new re({}),zy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L863"}}),Qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),pb=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Mea]},$$scope:{ctx:$}}}),Uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),pv=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Eea]},$$scope:{ctx:$}}}),Hy=new re({}),Jy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L919"}}),Ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),uv=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Cea]},$$scope:{ctx:$}}}),Zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),Jv=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[wea]},$$scope:{ctx:$}}}),e9=new re({}),o9=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L926"}}),t9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),Kv=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Aea]},$$scope:{ctx:$}}}),a9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),s5=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Lea]},$$scope:{ctx:$}}}),n9=new re({}),s9=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L912"}}),i9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),i5=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[yea]},$$scope:{ctx:$}}}),d9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),Q5=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xea]},$$scope:{ctx:$}}}),c9=new re({}),f9=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L883"}}),g9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),H5=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[$ea]},$$scope:{ctx:$}}}),h9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),DF=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[kea]},$$scope:{ctx:$}}}),p9=new re({}),_9=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L890"}}),b9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),OF=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Sea]},$$scope:{ctx:$}}}),v9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),zF=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Rea]},$$scope:{ctx:$}}}),F9=new re({}),T9=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L935"}}),E9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),QF=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Pea]},$$scope:{ctx:$}}}),C9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),dT=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Bea]},$$scope:{ctx:$}}}),w9=new re({}),A9=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L974"}}),y9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),fT=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[Iea]},$$scope:{ctx:$}}}),x9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),hT=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[Nea]},$$scope:{ctx:$}}}),$9=new re({}),k9=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L981"}}),R9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),_T=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[qea]},$$scope:{ctx:$}}}),P9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),vT=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[jea]},$$scope:{ctx:$}}}),B9=new re({}),I9=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L901"}}),q9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),TT=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Dea]},$$scope:{ctx:$}}}),j9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),CT=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[Gea]},$$scope:{ctx:$}}}),D9=new re({}),G9=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L988"}}),V9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),AT=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Oea]},$$scope:{ctx:$}}}),X9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),NT=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Vea]},$$scope:{ctx:$}}}),z9=new re({}),W9=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L1011"}}),U9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),jT=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[Xea]},$$scope:{ctx:$}}}),H9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),WT=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[zea]},$$scope:{ctx:$}}}),J9=new re({}),Y9=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L995"}}),Z9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),UT=new I({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Wea]},$$scope:{ctx:$}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),s8=new I({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Qea]},$$scope:{ctx:$}}}),ox=new re({}),rx=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L1002"}}),ax=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),i8=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Uea]},$$scope:{ctx:$}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),m8=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Hea]},$$scope:{ctx:$}}}),lx=new re({}),ix=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L1020"}}),cx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),h8=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Jea]},$$scope:{ctx:$}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),T8=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Yea]},$$scope:{ctx:$}}}),mx=new re({}),gx=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L1027"}}),px=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),E8=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Kea]},$$scope:{ctx:$}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),x8=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Zea]},$$scope:{ctx:$}}}),ux=new re({}),bx=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L967"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),k8=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[eoa]},$$scope:{ctx:$}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),B8=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[ooa]},$$scope:{ctx:$}}}),Ex=new re({}),Cx=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L942"}}),Ax=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),N8=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[roa]},$$scope:{ctx:$}}}),Lx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),D8=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[toa]},$$scope:{ctx:$}}}),yx=new re({}),xx=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L949"}}),kx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),O8=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[aoa]},$$scope:{ctx:$}}}),Sx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),H8=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[noa]},$$scope:{ctx:$}}}),Rx=new re({}),Px=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_auto.py#L958"}}),Ix=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),Y8=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[soa]},$$scope:{ctx:$}}}),Nx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),eM=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[loa]},$$scope:{ctx:$}}}),qx=new re({}),jx=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),Gx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),rM=new I({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[ioa]},$$scope:{ctx:$}}}),Ox=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),ZM=new I({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[doa]},$$scope:{ctx:$}}}),Vx=new re({}),Xx=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L423"}}),Wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),oE=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[coa]},$$scope:{ctx:$}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),wE=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[foa]},$$scope:{ctx:$}}}),Ux=new re({}),Hx=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L438"}}),Yx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),LE=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[moa]},$$scope:{ctx:$}}}),Kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),GE=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[goa]},$$scope:{ctx:$}}}),Zx=new re({}),e$=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L454"}}),r$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/pr_18524/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),VE=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[hoa]},$$scope:{ctx:$}}}),t$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),YE=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[poa]},$$scope:{ctx:$}}}),a$=new re({}),n$=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L479"}}),l$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),ZE=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[_oa]},$$scope:{ctx:$}}}),i$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),FC=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[uoa]},$$scope:{ctx:$}}}),d$=new re({}),c$=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L486"}}),m$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),MC=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[boa]},$$scope:{ctx:$}}}),g$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),RC=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[voa]},$$scope:{ctx:$}}}),h$=new re({}),p$=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L495"}}),u$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),BC=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Foa]},$$scope:{ctx:$}}}),b$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),i3=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Toa]},$$scope:{ctx:$}}}),v$=new re({}),F$=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L531"}}),M$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),c3=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Moa]},$$scope:{ctx:$}}}),E$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),y3=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Eoa]},$$scope:{ctx:$}}}),C$=new re({}),w$=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L538"}}),L$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),$3=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Coa]},$$scope:{ctx:$}}}),y$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),R3=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[woa]},$$scope:{ctx:$}}}),$$=new re({}),k$=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L511"}}),R$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),B3=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Aoa]},$$scope:{ctx:$}}}),P$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),N3=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Loa]},$$scope:{ctx:$}}}),B$=new re({}),I$=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L522"}}),q$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),j3=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[yoa]},$$scope:{ctx:$}}}),j$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),s0=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xoa]},$$scope:{ctx:$}}}),D$=new re({}),G$=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L504"}}),V$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),i0=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[$oa]},$$scope:{ctx:$}}}),X$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),x0=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[koa]},$$scope:{ctx:$}}}),z$=new re({}),W$=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L472"}}),U$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),k0=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[Soa]},$$scope:{ctx:$}}}),H$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),R0=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Roa]},$$scope:{ctx:$}}}),J$=new re({}),Y$=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_tf_auto.py#L547"}}),Z$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),B0=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Poa]},$$scope:{ctx:$}}}),ek=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),N0=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Boa]},$$scope:{ctx:$}}}),ok=new re({}),rk=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),ak=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),j0=new I({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Ioa]},$$scope:{ctx:$}}}),nk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),gw=new I({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Noa]},$$scope:{ctx:$}}}),sk=new re({}),lk=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),dk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),pw=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[qoa]},$$scope:{ctx:$}}}),ck=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),Aw=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[joa]},$$scope:{ctx:$}}}),fk=new re({}),mk=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),hk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),yw=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[Doa]},$$scope:{ctx:$}}}),pk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),Ow=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Goa]},$$scope:{ctx:$}}}),_k=new re({}),uk=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),vk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),Xw=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Ooa]},$$scope:{ctx:$}}}),Fk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),o6=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Voa]},$$scope:{ctx:$}}}),Tk=new re({}),Mk=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),Ck=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),t6=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Xoa]},$$scope:{ctx:$}}}),wk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),h6=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[zoa]},$$scope:{ctx:$}}}),Ak=new re({}),Lk=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),xk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),_6=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Woa]},$$scope:{ctx:$}}}),$k=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),L6=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Qoa]},$$scope:{ctx:$}}}),kk=new re({}),Sk=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),Pk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),x6=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Uoa]},$$scope:{ctx:$}}}),Bk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),D6=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Hoa]},$$scope:{ctx:$}}}),Ik=new re({}),Nk=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),jk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),O6=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[Joa]},$$scope:{ctx:$}}}),Dk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),Y6=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Yoa]},$$scope:{ctx:$}}}),Gk=new re({}),Ok=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),Xk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),Z6=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Koa]},$$scope:{ctx:$}}}),zk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),iA=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Zoa]},$$scope:{ctx:$}}}),Wk=new re({}),Qk=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),Hk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),cA=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[era]},$$scope:{ctx:$}}}),Jk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),mA=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[ora]},$$scope:{ctx:$}}}),Yk=new re({}),Kk=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),eS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),hA=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[rra]},$$scope:{ctx:$}}}),oS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),uA=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[tra]},$$scope:{ctx:$}}}),tS=new re({}),aS=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),sS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L389"}}),vA=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[ara]},$$scope:{ctx:$}}}),lS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18524/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18524/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18524/src/transformers/models/auto/auto_factory.py#L417"}}),TA=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[nra]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Ao=a("span"),Ii=o("Auto Classes"),zf=l(),dt=a("p"),Ni=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),qi=a("code"),VL=o("from_pretrained()"),Wf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),ji=o("Instantiating one of "),Dn=a("a"),XL=o("AutoConfig"),Gn=o(", "),On=a("a"),zL=o("AutoModel"),Di=o(`, and
`),Vn=a("a"),WL=o("AutoTokenizer"),Gi=o(" will directly create a class of the relevant architecture. For instance"),Qf=l(),F(Ia.$$.fragment),Ue=l(),Ae=a("p"),kR=o("will create a model that is an instance of "),Oi=a("a"),SR=o("BertModel"),RR=o("."),Lo=l(),Na=a("p"),PR=o("There is one class of "),Uf=a("code"),BR=o("AutoModel"),aYe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jWe=l(),Vi=a("h2"),Hf=a("a"),Zne=a("span"),F(QL.$$.fragment),nYe=l(),ese=a("span"),sYe=o("Extending the Auto Classes"),DWe=l(),Xn=a("p"),lYe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ose=a("code"),iYe=o("NewModel"),dYe=o(", make sure you have a "),rse=a("code"),cYe=o("NewModelConfig"),fYe=o(` then you can add those to the auto
classes like this:`),GWe=l(),F(UL.$$.fragment),OWe=l(),IR=a("p"),mYe=o("You will then be able to use the auto classes like you would usually do!"),VWe=l(),F(Jf.$$.fragment),XWe=l(),Xi=a("h2"),Yf=a("a"),tse=a("span"),F(HL.$$.fragment),gYe=l(),ase=a("span"),hYe=o("AutoConfig"),zWe=l(),yo=a("div"),F(JL.$$.fragment),pYe=l(),YL=a("p"),_Ye=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),NR=a("a"),uYe=o("from_pretrained()"),bYe=o(" class method."),vYe=l(),KL=a("p"),FYe=o("This class cannot be instantiated directly using "),nse=a("code"),TYe=o("__init__()"),MYe=o(" (throws an error)."),EYe=l(),$r=a("div"),F(ZL.$$.fragment),CYe=l(),sse=a("p"),wYe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),AYe=l(),zi=a("p"),LYe=o("The configuration class to instantiate is selected based on the "),lse=a("code"),yYe=o("model_type"),xYe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ise=a("code"),$Ye=o("pretrained_model_name_or_path"),kYe=o(":"),SYe=l(),A=a("ul"),Kf=a("li"),dse=a("strong"),RYe=o("albert"),PYe=o(" \u2014 "),qR=a("a"),BYe=o("AlbertConfig"),IYe=o(" (ALBERT model)"),NYe=l(),Zf=a("li"),cse=a("strong"),qYe=o("bart"),jYe=o(" \u2014 "),jR=a("a"),DYe=o("BartConfig"),GYe=o(" (BART model)"),OYe=l(),em=a("li"),fse=a("strong"),VYe=o("beit"),XYe=o(" \u2014 "),DR=a("a"),zYe=o("BeitConfig"),WYe=o(" (BEiT model)"),QYe=l(),om=a("li"),mse=a("strong"),UYe=o("bert"),HYe=o(" \u2014 "),GR=a("a"),JYe=o("BertConfig"),YYe=o(" (BERT model)"),KYe=l(),rm=a("li"),gse=a("strong"),ZYe=o("bert-generation"),eKe=o(" \u2014 "),OR=a("a"),oKe=o("BertGenerationConfig"),rKe=o(" (Bert Generation model)"),tKe=l(),tm=a("li"),hse=a("strong"),aKe=o("big_bird"),nKe=o(" \u2014 "),VR=a("a"),sKe=o("BigBirdConfig"),lKe=o(" (BigBird model)"),iKe=l(),am=a("li"),pse=a("strong"),dKe=o("bigbird_pegasus"),cKe=o(" \u2014 "),XR=a("a"),fKe=o("BigBirdPegasusConfig"),mKe=o(" (BigBird-Pegasus model)"),gKe=l(),nm=a("li"),_se=a("strong"),hKe=o("blenderbot"),pKe=o(" \u2014 "),zR=a("a"),_Ke=o("BlenderbotConfig"),uKe=o(" (Blenderbot model)"),bKe=l(),sm=a("li"),use=a("strong"),vKe=o("blenderbot-small"),FKe=o(" \u2014 "),WR=a("a"),TKe=o("BlenderbotSmallConfig"),MKe=o(" (BlenderbotSmall model)"),EKe=l(),lm=a("li"),bse=a("strong"),CKe=o("bloom"),wKe=o(" \u2014 "),QR=a("a"),AKe=o("BloomConfig"),LKe=o(" (BLOOM model)"),yKe=l(),im=a("li"),vse=a("strong"),xKe=o("camembert"),$Ke=o(" \u2014 "),UR=a("a"),kKe=o("CamembertConfig"),SKe=o(" (CamemBERT model)"),RKe=l(),dm=a("li"),Fse=a("strong"),PKe=o("canine"),BKe=o(" \u2014 "),HR=a("a"),IKe=o("CanineConfig"),NKe=o(" (CANINE model)"),qKe=l(),cm=a("li"),Tse=a("strong"),jKe=o("clip"),DKe=o(" \u2014 "),JR=a("a"),GKe=o("CLIPConfig"),OKe=o(" (CLIP model)"),VKe=l(),fm=a("li"),Mse=a("strong"),XKe=o("codegen"),zKe=o(" \u2014 "),YR=a("a"),WKe=o("CodeGenConfig"),QKe=o(" (CodeGen model)"),UKe=l(),mm=a("li"),Ese=a("strong"),HKe=o("convbert"),JKe=o(" \u2014 "),KR=a("a"),YKe=o("ConvBertConfig"),KKe=o(" (ConvBERT model)"),ZKe=l(),gm=a("li"),Cse=a("strong"),eZe=o("convnext"),oZe=o(" \u2014 "),ZR=a("a"),rZe=o("ConvNextConfig"),tZe=o(" (ConvNeXT model)"),aZe=l(),hm=a("li"),wse=a("strong"),nZe=o("ctrl"),sZe=o(" \u2014 "),eP=a("a"),lZe=o("CTRLConfig"),iZe=o(" (CTRL model)"),dZe=l(),pm=a("li"),Ase=a("strong"),cZe=o("cvt"),fZe=o(" \u2014 "),oP=a("a"),mZe=o("CvtConfig"),gZe=o(" (CvT model)"),hZe=l(),_m=a("li"),Lse=a("strong"),pZe=o("data2vec-audio"),_Ze=o(" \u2014 "),rP=a("a"),uZe=o("Data2VecAudioConfig"),bZe=o(" (Data2VecAudio model)"),vZe=l(),um=a("li"),yse=a("strong"),FZe=o("data2vec-text"),TZe=o(" \u2014 "),tP=a("a"),MZe=o("Data2VecTextConfig"),EZe=o(" (Data2VecText model)"),CZe=l(),bm=a("li"),xse=a("strong"),wZe=o("data2vec-vision"),AZe=o(" \u2014 "),aP=a("a"),LZe=o("Data2VecVisionConfig"),yZe=o(" (Data2VecVision model)"),xZe=l(),vm=a("li"),$se=a("strong"),$Ze=o("deberta"),kZe=o(" \u2014 "),nP=a("a"),SZe=o("DebertaConfig"),RZe=o(" (DeBERTa model)"),PZe=l(),Fm=a("li"),kse=a("strong"),BZe=o("deberta-v2"),IZe=o(" \u2014 "),sP=a("a"),NZe=o("DebertaV2Config"),qZe=o(" (DeBERTa-v2 model)"),jZe=l(),Tm=a("li"),Sse=a("strong"),DZe=o("decision_transformer"),GZe=o(" \u2014 "),lP=a("a"),OZe=o("DecisionTransformerConfig"),VZe=o(" (Decision Transformer model)"),XZe=l(),Mm=a("li"),Rse=a("strong"),zZe=o("deit"),WZe=o(" \u2014 "),iP=a("a"),QZe=o("DeiTConfig"),UZe=o(" (DeiT model)"),HZe=l(),Em=a("li"),Pse=a("strong"),JZe=o("detr"),YZe=o(" \u2014 "),dP=a("a"),KZe=o("DetrConfig"),ZZe=o(" (DETR model)"),eeo=l(),Cm=a("li"),Bse=a("strong"),oeo=o("distilbert"),reo=o(" \u2014 "),cP=a("a"),teo=o("DistilBertConfig"),aeo=o(" (DistilBERT model)"),neo=l(),wm=a("li"),Ise=a("strong"),seo=o("dpr"),leo=o(" \u2014 "),fP=a("a"),ieo=o("DPRConfig"),deo=o(" (DPR model)"),ceo=l(),Am=a("li"),Nse=a("strong"),feo=o("dpt"),meo=o(" \u2014 "),mP=a("a"),geo=o("DPTConfig"),heo=o(" (DPT model)"),peo=l(),Lm=a("li"),qse=a("strong"),_eo=o("electra"),ueo=o(" \u2014 "),gP=a("a"),beo=o("ElectraConfig"),veo=o(" (ELECTRA model)"),Feo=l(),ym=a("li"),jse=a("strong"),Teo=o("encoder-decoder"),Meo=o(" \u2014 "),hP=a("a"),Eeo=o("EncoderDecoderConfig"),Ceo=o(" (Encoder decoder model)"),weo=l(),xm=a("li"),Dse=a("strong"),Aeo=o("flaubert"),Leo=o(" \u2014 "),pP=a("a"),yeo=o("FlaubertConfig"),xeo=o(" (FlauBERT model)"),$eo=l(),$m=a("li"),Gse=a("strong"),keo=o("flava"),Seo=o(" \u2014 "),_P=a("a"),Reo=o("FlavaConfig"),Peo=o(" (FLAVA model)"),Beo=l(),km=a("li"),Ose=a("strong"),Ieo=o("fnet"),Neo=o(" \u2014 "),uP=a("a"),qeo=o("FNetConfig"),jeo=o(" (FNet model)"),Deo=l(),Sm=a("li"),Vse=a("strong"),Geo=o("fsmt"),Oeo=o(" \u2014 "),bP=a("a"),Veo=o("FSMTConfig"),Xeo=o(" (FairSeq Machine-Translation model)"),zeo=l(),Rm=a("li"),Xse=a("strong"),Weo=o("funnel"),Qeo=o(" \u2014 "),vP=a("a"),Ueo=o("FunnelConfig"),Heo=o(" (Funnel Transformer model)"),Jeo=l(),Pm=a("li"),zse=a("strong"),Yeo=o("glpn"),Keo=o(" \u2014 "),FP=a("a"),Zeo=o("GLPNConfig"),eoo=o(" (GLPN model)"),ooo=l(),Bm=a("li"),Wse=a("strong"),roo=o("gpt2"),too=o(" \u2014 "),TP=a("a"),aoo=o("GPT2Config"),noo=o(" (OpenAI GPT-2 model)"),soo=l(),Im=a("li"),Qse=a("strong"),loo=o("gpt_neo"),ioo=o(" \u2014 "),MP=a("a"),doo=o("GPTNeoConfig"),coo=o(" (GPT Neo model)"),foo=l(),Nm=a("li"),Use=a("strong"),moo=o("gpt_neox"),goo=o(" \u2014 "),EP=a("a"),hoo=o("GPTNeoXConfig"),poo=o(" (GPT NeoX model)"),_oo=l(),qm=a("li"),Hse=a("strong"),uoo=o("gptj"),boo=o(" \u2014 "),CP=a("a"),voo=o("GPTJConfig"),Foo=o(" (GPT-J model)"),Too=l(),jm=a("li"),Jse=a("strong"),Moo=o("groupvit"),Eoo=o(" \u2014 "),wP=a("a"),Coo=o("GroupViTConfig"),woo=o(" (GroupViT model)"),Aoo=l(),Dm=a("li"),Yse=a("strong"),Loo=o("hubert"),yoo=o(" \u2014 "),AP=a("a"),xoo=o("HubertConfig"),$oo=o(" (Hubert model)"),koo=l(),Gm=a("li"),Kse=a("strong"),Soo=o("ibert"),Roo=o(" \u2014 "),LP=a("a"),Poo=o("IBertConfig"),Boo=o(" (I-BERT model)"),Ioo=l(),Om=a("li"),Zse=a("strong"),Noo=o("imagegpt"),qoo=o(" \u2014 "),yP=a("a"),joo=o("ImageGPTConfig"),Doo=o(" (ImageGPT model)"),Goo=l(),Vm=a("li"),ele=a("strong"),Ooo=o("layoutlm"),Voo=o(" \u2014 "),xP=a("a"),Xoo=o("LayoutLMConfig"),zoo=o(" (LayoutLM model)"),Woo=l(),Xm=a("li"),ole=a("strong"),Qoo=o("layoutlmv2"),Uoo=o(" \u2014 "),$P=a("a"),Hoo=o("LayoutLMv2Config"),Joo=o(" (LayoutLMv2 model)"),Yoo=l(),zm=a("li"),rle=a("strong"),Koo=o("layoutlmv3"),Zoo=o(" \u2014 "),kP=a("a"),ero=o("LayoutLMv3Config"),oro=o(" (LayoutLMv3 model)"),rro=l(),Wm=a("li"),tle=a("strong"),tro=o("led"),aro=o(" \u2014 "),SP=a("a"),nro=o("LEDConfig"),sro=o(" (LED model)"),lro=l(),Qm=a("li"),ale=a("strong"),iro=o("levit"),dro=o(" \u2014 "),RP=a("a"),cro=o("LevitConfig"),fro=o(" (LeViT model)"),mro=l(),Um=a("li"),nle=a("strong"),gro=o("longformer"),hro=o(" \u2014 "),PP=a("a"),pro=o("LongformerConfig"),_ro=o(" (Longformer model)"),uro=l(),Hm=a("li"),sle=a("strong"),bro=o("longt5"),vro=o(" \u2014 "),BP=a("a"),Fro=o("LongT5Config"),Tro=o(" (LongT5 model)"),Mro=l(),Jm=a("li"),lle=a("strong"),Ero=o("luke"),Cro=o(" \u2014 "),IP=a("a"),wro=o("LukeConfig"),Aro=o(" (LUKE model)"),Lro=l(),Ym=a("li"),ile=a("strong"),yro=o("lxmert"),xro=o(" \u2014 "),NP=a("a"),$ro=o("LxmertConfig"),kro=o(" (LXMERT model)"),Sro=l(),Km=a("li"),dle=a("strong"),Rro=o("m2m_100"),Pro=o(" \u2014 "),qP=a("a"),Bro=o("M2M100Config"),Iro=o(" (M2M100 model)"),Nro=l(),Zm=a("li"),cle=a("strong"),qro=o("marian"),jro=o(" \u2014 "),jP=a("a"),Dro=o("MarianConfig"),Gro=o(" (Marian model)"),Oro=l(),eg=a("li"),fle=a("strong"),Vro=o("maskformer"),Xro=o(" \u2014 "),DP=a("a"),zro=o("MaskFormerConfig"),Wro=o(" (MaskFormer model)"),Qro=l(),og=a("li"),mle=a("strong"),Uro=o("mbart"),Hro=o(" \u2014 "),GP=a("a"),Jro=o("MBartConfig"),Yro=o(" (mBART model)"),Kro=l(),rg=a("li"),gle=a("strong"),Zro=o("mctct"),eto=o(" \u2014 "),OP=a("a"),oto=o("MCTCTConfig"),rto=o(" (M-CTC-T model)"),tto=l(),tg=a("li"),hle=a("strong"),ato=o("megatron-bert"),nto=o(" \u2014 "),VP=a("a"),sto=o("MegatronBertConfig"),lto=o(" (Megatron-BERT model)"),ito=l(),ag=a("li"),ple=a("strong"),dto=o("mobilebert"),cto=o(" \u2014 "),XP=a("a"),fto=o("MobileBertConfig"),mto=o(" (MobileBERT model)"),gto=l(),ng=a("li"),_le=a("strong"),hto=o("mobilevit"),pto=o(" \u2014 "),zP=a("a"),_to=o("MobileViTConfig"),uto=o(" (MobileViT model)"),bto=l(),sg=a("li"),ule=a("strong"),vto=o("mpnet"),Fto=o(" \u2014 "),WP=a("a"),Tto=o("MPNetConfig"),Mto=o(" (MPNet model)"),Eto=l(),lg=a("li"),ble=a("strong"),Cto=o("mt5"),wto=o(" \u2014 "),QP=a("a"),Ato=o("MT5Config"),Lto=o(" (MT5 model)"),yto=l(),ig=a("li"),vle=a("strong"),xto=o("mvp"),$to=o(" \u2014 "),UP=a("a"),kto=o("MvpConfig"),Sto=o(" (MVP model)"),Rto=l(),dg=a("li"),Fle=a("strong"),Pto=o("nezha"),Bto=o(" \u2014 "),HP=a("a"),Ito=o("NezhaConfig"),Nto=o(" (Nezha model)"),qto=l(),cg=a("li"),Tle=a("strong"),jto=o("nystromformer"),Dto=o(" \u2014 "),JP=a("a"),Gto=o("NystromformerConfig"),Oto=o(" (Nystr\xF6mformer model)"),Vto=l(),fg=a("li"),Mle=a("strong"),Xto=o("openai-gpt"),zto=o(" \u2014 "),YP=a("a"),Wto=o("OpenAIGPTConfig"),Qto=o(" (OpenAI GPT model)"),Uto=l(),mg=a("li"),Ele=a("strong"),Hto=o("opt"),Jto=o(" \u2014 "),KP=a("a"),Yto=o("OPTConfig"),Kto=o(" (OPT model)"),Zto=l(),gg=a("li"),Cle=a("strong"),eao=o("owlvit"),oao=o(" \u2014 "),ZP=a("a"),rao=o("OwlViTConfig"),tao=o(" (OWL-ViT model)"),aao=l(),hg=a("li"),wle=a("strong"),nao=o("pegasus"),sao=o(" \u2014 "),eB=a("a"),lao=o("PegasusConfig"),iao=o(" (Pegasus model)"),dao=l(),pg=a("li"),Ale=a("strong"),cao=o("perceiver"),fao=o(" \u2014 "),oB=a("a"),mao=o("PerceiverConfig"),gao=o(" (Perceiver model)"),hao=l(),_g=a("li"),Lle=a("strong"),pao=o("plbart"),_ao=o(" \u2014 "),rB=a("a"),uao=o("PLBartConfig"),bao=o(" (PLBart model)"),vao=l(),ug=a("li"),yle=a("strong"),Fao=o("poolformer"),Tao=o(" \u2014 "),tB=a("a"),Mao=o("PoolFormerConfig"),Eao=o(" (PoolFormer model)"),Cao=l(),bg=a("li"),xle=a("strong"),wao=o("prophetnet"),Aao=o(" \u2014 "),aB=a("a"),Lao=o("ProphetNetConfig"),yao=o(" (ProphetNet model)"),xao=l(),vg=a("li"),$le=a("strong"),$ao=o("qdqbert"),kao=o(" \u2014 "),nB=a("a"),Sao=o("QDQBertConfig"),Rao=o(" (QDQBert model)"),Pao=l(),Fg=a("li"),kle=a("strong"),Bao=o("rag"),Iao=o(" \u2014 "),sB=a("a"),Nao=o("RagConfig"),qao=o(" (RAG model)"),jao=l(),Tg=a("li"),Sle=a("strong"),Dao=o("realm"),Gao=o(" \u2014 "),lB=a("a"),Oao=o("RealmConfig"),Vao=o(" (REALM model)"),Xao=l(),Mg=a("li"),Rle=a("strong"),zao=o("reformer"),Wao=o(" \u2014 "),iB=a("a"),Qao=o("ReformerConfig"),Uao=o(" (Reformer model)"),Hao=l(),Eg=a("li"),Ple=a("strong"),Jao=o("regnet"),Yao=o(" \u2014 "),dB=a("a"),Kao=o("RegNetConfig"),Zao=o(" (RegNet model)"),eno=l(),Cg=a("li"),Ble=a("strong"),ono=o("rembert"),rno=o(" \u2014 "),cB=a("a"),tno=o("RemBertConfig"),ano=o(" (RemBERT model)"),nno=l(),wg=a("li"),Ile=a("strong"),sno=o("resnet"),lno=o(" \u2014 "),fB=a("a"),ino=o("ResNetConfig"),dno=o(" (ResNet model)"),cno=l(),Ag=a("li"),Nle=a("strong"),fno=o("retribert"),mno=o(" \u2014 "),mB=a("a"),gno=o("RetriBertConfig"),hno=o(" (RetriBERT model)"),pno=l(),Lg=a("li"),qle=a("strong"),_no=o("roberta"),uno=o(" \u2014 "),gB=a("a"),bno=o("RobertaConfig"),vno=o(" (RoBERTa model)"),Fno=l(),yg=a("li"),jle=a("strong"),Tno=o("roformer"),Mno=o(" \u2014 "),hB=a("a"),Eno=o("RoFormerConfig"),Cno=o(" (RoFormer model)"),wno=l(),xg=a("li"),Dle=a("strong"),Ano=o("segformer"),Lno=o(" \u2014 "),pB=a("a"),yno=o("SegformerConfig"),xno=o(" (SegFormer model)"),$no=l(),$g=a("li"),Gle=a("strong"),kno=o("sew"),Sno=o(" \u2014 "),_B=a("a"),Rno=o("SEWConfig"),Pno=o(" (SEW model)"),Bno=l(),kg=a("li"),Ole=a("strong"),Ino=o("sew-d"),Nno=o(" \u2014 "),uB=a("a"),qno=o("SEWDConfig"),jno=o(" (SEW-D model)"),Dno=l(),Sg=a("li"),Vle=a("strong"),Gno=o("speech-encoder-decoder"),Ono=o(" \u2014 "),bB=a("a"),Vno=o("SpeechEncoderDecoderConfig"),Xno=o(" (Speech Encoder decoder model)"),zno=l(),Rg=a("li"),Xle=a("strong"),Wno=o("speech_to_text"),Qno=o(" \u2014 "),vB=a("a"),Uno=o("Speech2TextConfig"),Hno=o(" (Speech2Text model)"),Jno=l(),Pg=a("li"),zle=a("strong"),Yno=o("speech_to_text_2"),Kno=o(" \u2014 "),FB=a("a"),Zno=o("Speech2Text2Config"),eso=o(" (Speech2Text2 model)"),oso=l(),Bg=a("li"),Wle=a("strong"),rso=o("splinter"),tso=o(" \u2014 "),TB=a("a"),aso=o("SplinterConfig"),nso=o(" (Splinter model)"),sso=l(),Ig=a("li"),Qle=a("strong"),lso=o("squeezebert"),iso=o(" \u2014 "),MB=a("a"),dso=o("SqueezeBertConfig"),cso=o(" (SqueezeBERT model)"),fso=l(),Ng=a("li"),Ule=a("strong"),mso=o("swin"),gso=o(" \u2014 "),EB=a("a"),hso=o("SwinConfig"),pso=o(" (Swin Transformer model)"),_so=l(),qg=a("li"),Hle=a("strong"),uso=o("swinv2"),bso=o(" \u2014 "),CB=a("a"),vso=o("Swinv2Config"),Fso=o(" (Swin Transformer V2 model)"),Tso=l(),jg=a("li"),Jle=a("strong"),Mso=o("t5"),Eso=o(" \u2014 "),wB=a("a"),Cso=o("T5Config"),wso=o(" (T5 model)"),Aso=l(),Dg=a("li"),Yle=a("strong"),Lso=o("tapas"),yso=o(" \u2014 "),AB=a("a"),xso=o("TapasConfig"),$so=o(" (TAPAS model)"),kso=l(),Gg=a("li"),Kle=a("strong"),Sso=o("trajectory_transformer"),Rso=o(" \u2014 "),LB=a("a"),Pso=o("TrajectoryTransformerConfig"),Bso=o(" (Trajectory Transformer model)"),Iso=l(),Og=a("li"),Zle=a("strong"),Nso=o("transfo-xl"),qso=o(" \u2014 "),yB=a("a"),jso=o("TransfoXLConfig"),Dso=o(" (Transformer-XL model)"),Gso=l(),Vg=a("li"),eie=a("strong"),Oso=o("trocr"),Vso=o(" \u2014 "),xB=a("a"),Xso=o("TrOCRConfig"),zso=o(" (TrOCR model)"),Wso=l(),Xg=a("li"),oie=a("strong"),Qso=o("unispeech"),Uso=o(" \u2014 "),$B=a("a"),Hso=o("UniSpeechConfig"),Jso=o(" (UniSpeech model)"),Yso=l(),zg=a("li"),rie=a("strong"),Kso=o("unispeech-sat"),Zso=o(" \u2014 "),kB=a("a"),elo=o("UniSpeechSatConfig"),olo=o(" (UniSpeechSat model)"),rlo=l(),Wg=a("li"),tie=a("strong"),tlo=o("van"),alo=o(" \u2014 "),SB=a("a"),nlo=o("VanConfig"),slo=o(" (VAN model)"),llo=l(),Qg=a("li"),aie=a("strong"),ilo=o("videomae"),dlo=o(" \u2014 "),RB=a("a"),clo=o("VideoMAEConfig"),flo=o(" (VideoMAE model)"),mlo=l(),Ug=a("li"),nie=a("strong"),glo=o("vilt"),hlo=o(" \u2014 "),PB=a("a"),plo=o("ViltConfig"),_lo=o(" (ViLT model)"),ulo=l(),Hg=a("li"),sie=a("strong"),blo=o("vision-encoder-decoder"),vlo=o(" \u2014 "),BB=a("a"),Flo=o("VisionEncoderDecoderConfig"),Tlo=o(" (Vision Encoder decoder model)"),Mlo=l(),Jg=a("li"),lie=a("strong"),Elo=o("vision-text-dual-encoder"),Clo=o(" \u2014 "),IB=a("a"),wlo=o("VisionTextDualEncoderConfig"),Alo=o(" (VisionTextDualEncoder model)"),Llo=l(),Yg=a("li"),iie=a("strong"),ylo=o("visual_bert"),xlo=o(" \u2014 "),NB=a("a"),$lo=o("VisualBertConfig"),klo=o(" (VisualBERT model)"),Slo=l(),Kg=a("li"),die=a("strong"),Rlo=o("vit"),Plo=o(" \u2014 "),qB=a("a"),Blo=o("ViTConfig"),Ilo=o(" (ViT model)"),Nlo=l(),Zg=a("li"),cie=a("strong"),qlo=o("vit_mae"),jlo=o(" \u2014 "),jB=a("a"),Dlo=o("ViTMAEConfig"),Glo=o(" (ViTMAE model)"),Olo=l(),eh=a("li"),fie=a("strong"),Vlo=o("wav2vec2"),Xlo=o(" \u2014 "),DB=a("a"),zlo=o("Wav2Vec2Config"),Wlo=o(" (Wav2Vec2 model)"),Qlo=l(),oh=a("li"),mie=a("strong"),Ulo=o("wav2vec2-conformer"),Hlo=o(" \u2014 "),GB=a("a"),Jlo=o("Wav2Vec2ConformerConfig"),Ylo=o(" (Wav2Vec2-Conformer model)"),Klo=l(),rh=a("li"),gie=a("strong"),Zlo=o("wavlm"),eio=o(" \u2014 "),OB=a("a"),oio=o("WavLMConfig"),rio=o(" (WavLM model)"),tio=l(),th=a("li"),hie=a("strong"),aio=o("xglm"),nio=o(" \u2014 "),VB=a("a"),sio=o("XGLMConfig"),lio=o(" (XGLM model)"),iio=l(),ah=a("li"),pie=a("strong"),dio=o("xlm"),cio=o(" \u2014 "),XB=a("a"),fio=o("XLMConfig"),mio=o(" (XLM model)"),gio=l(),nh=a("li"),_ie=a("strong"),hio=o("xlm-prophetnet"),pio=o(" \u2014 "),zB=a("a"),_io=o("XLMProphetNetConfig"),uio=o(" (XLM-ProphetNet model)"),bio=l(),sh=a("li"),uie=a("strong"),vio=o("xlm-roberta"),Fio=o(" \u2014 "),WB=a("a"),Tio=o("XLMRobertaConfig"),Mio=o(" (XLM-RoBERTa model)"),Eio=l(),lh=a("li"),bie=a("strong"),Cio=o("xlm-roberta-xl"),wio=o(" \u2014 "),QB=a("a"),Aio=o("XLMRobertaXLConfig"),Lio=o(" (XLM-RoBERTa-XL model)"),yio=l(),ih=a("li"),vie=a("strong"),xio=o("xlnet"),$io=o(" \u2014 "),UB=a("a"),kio=o("XLNetConfig"),Sio=o(" (XLNet model)"),Rio=l(),dh=a("li"),Fie=a("strong"),Pio=o("yolos"),Bio=o(" \u2014 "),HB=a("a"),Iio=o("YolosConfig"),Nio=o(" (YOLOS model)"),qio=l(),ch=a("li"),Tie=a("strong"),jio=o("yoso"),Dio=o(" \u2014 "),JB=a("a"),Gio=o("YosoConfig"),Oio=o(" (YOSO model)"),Vio=l(),F(fh.$$.fragment),Xio=l(),mh=a("div"),F(ey.$$.fragment),zio=l(),Mie=a("p"),Wio=o("Register a new configuration for this class."),WWe=l(),Wi=a("h2"),gh=a("a"),Eie=a("span"),F(oy.$$.fragment),Qio=l(),Cie=a("span"),Uio=o("AutoTokenizer"),QWe=l(),xo=a("div"),F(ry.$$.fragment),Hio=l(),ty=a("p"),Jio=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),YB=a("a"),Yio=o("AutoTokenizer.from_pretrained()"),Kio=o(" class method."),Zio=l(),ay=a("p"),edo=o("This class cannot be instantiated directly using "),wie=a("code"),odo=o("__init__()"),rdo=o(" (throws an error)."),tdo=l(),kr=a("div"),F(ny.$$.fragment),ado=l(),Aie=a("p"),ndo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),sdo=l(),qa=a("p"),ldo=o("The tokenizer class to instantiate is selected based on the "),Lie=a("code"),ido=o("model_type"),ddo=o(` property of the config object (either
passed as an argument or loaded from `),yie=a("code"),cdo=o("pretrained_model_name_or_path"),fdo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xie=a("code"),mdo=o("pretrained_model_name_or_path"),gdo=o(":"),hdo=l(),k=a("ul"),zn=a("li"),$ie=a("strong"),pdo=o("albert"),_do=o(" \u2014 "),KB=a("a"),udo=o("AlbertTokenizer"),bdo=o(" or "),ZB=a("a"),vdo=o("AlbertTokenizerFast"),Fdo=o(" (ALBERT model)"),Tdo=l(),Wn=a("li"),kie=a("strong"),Mdo=o("bart"),Edo=o(" \u2014 "),eI=a("a"),Cdo=o("BartTokenizer"),wdo=o(" or "),oI=a("a"),Ado=o("BartTokenizerFast"),Ldo=o(" (BART model)"),ydo=l(),Qn=a("li"),Sie=a("strong"),xdo=o("barthez"),$do=o(" \u2014 "),rI=a("a"),kdo=o("BarthezTokenizer"),Sdo=o(" or "),tI=a("a"),Rdo=o("BarthezTokenizerFast"),Pdo=o(" (BARThez model)"),Bdo=l(),hh=a("li"),Rie=a("strong"),Ido=o("bartpho"),Ndo=o(" \u2014 "),aI=a("a"),qdo=o("BartphoTokenizer"),jdo=o(" (BARTpho model)"),Ddo=l(),Un=a("li"),Pie=a("strong"),Gdo=o("bert"),Odo=o(" \u2014 "),nI=a("a"),Vdo=o("BertTokenizer"),Xdo=o(" or "),sI=a("a"),zdo=o("BertTokenizerFast"),Wdo=o(" (BERT model)"),Qdo=l(),ph=a("li"),Bie=a("strong"),Udo=o("bert-generation"),Hdo=o(" \u2014 "),lI=a("a"),Jdo=o("BertGenerationTokenizer"),Ydo=o(" (Bert Generation model)"),Kdo=l(),_h=a("li"),Iie=a("strong"),Zdo=o("bert-japanese"),eco=o(" \u2014 "),iI=a("a"),oco=o("BertJapaneseTokenizer"),rco=o(" (BertJapanese model)"),tco=l(),uh=a("li"),Nie=a("strong"),aco=o("bertweet"),nco=o(" \u2014 "),dI=a("a"),sco=o("BertweetTokenizer"),lco=o(" (BERTweet model)"),ico=l(),Hn=a("li"),qie=a("strong"),dco=o("big_bird"),cco=o(" \u2014 "),cI=a("a"),fco=o("BigBirdTokenizer"),mco=o(" or "),fI=a("a"),gco=o("BigBirdTokenizerFast"),hco=o(" (BigBird model)"),pco=l(),Jn=a("li"),jie=a("strong"),_co=o("bigbird_pegasus"),uco=o(" \u2014 "),mI=a("a"),bco=o("PegasusTokenizer"),vco=o(" or "),gI=a("a"),Fco=o("PegasusTokenizerFast"),Tco=o(" (BigBird-Pegasus model)"),Mco=l(),Yn=a("li"),Die=a("strong"),Eco=o("blenderbot"),Cco=o(" \u2014 "),hI=a("a"),wco=o("BlenderbotTokenizer"),Aco=o(" or "),pI=a("a"),Lco=o("BlenderbotTokenizerFast"),yco=o(" (Blenderbot model)"),xco=l(),bh=a("li"),Gie=a("strong"),$co=o("blenderbot-small"),kco=o(" \u2014 "),_I=a("a"),Sco=o("BlenderbotSmallTokenizer"),Rco=o(" (BlenderbotSmall model)"),Pco=l(),vh=a("li"),Oie=a("strong"),Bco=o("bloom"),Ico=o(" \u2014 "),uI=a("a"),Nco=o("BloomTokenizerFast"),qco=o(" (BLOOM model)"),jco=l(),Fh=a("li"),Vie=a("strong"),Dco=o("byt5"),Gco=o(" \u2014 "),bI=a("a"),Oco=o("ByT5Tokenizer"),Vco=o(" (ByT5 model)"),Xco=l(),Kn=a("li"),Xie=a("strong"),zco=o("camembert"),Wco=o(" \u2014 "),vI=a("a"),Qco=o("CamembertTokenizer"),Uco=o(" or "),FI=a("a"),Hco=o("CamembertTokenizerFast"),Jco=o(" (CamemBERT model)"),Yco=l(),Th=a("li"),zie=a("strong"),Kco=o("canine"),Zco=o(" \u2014 "),TI=a("a"),efo=o("CanineTokenizer"),ofo=o(" (CANINE model)"),rfo=l(),Zn=a("li"),Wie=a("strong"),tfo=o("clip"),afo=o(" \u2014 "),MI=a("a"),nfo=o("CLIPTokenizer"),sfo=o(" or "),EI=a("a"),lfo=o("CLIPTokenizerFast"),ifo=o(" (CLIP model)"),dfo=l(),es=a("li"),Qie=a("strong"),cfo=o("codegen"),ffo=o(" \u2014 "),CI=a("a"),mfo=o("CodeGenTokenizer"),gfo=o(" or "),wI=a("a"),hfo=o("CodeGenTokenizerFast"),pfo=o(" (CodeGen model)"),_fo=l(),os=a("li"),Uie=a("strong"),ufo=o("convbert"),bfo=o(" \u2014 "),AI=a("a"),vfo=o("ConvBertTokenizer"),Ffo=o(" or "),LI=a("a"),Tfo=o("ConvBertTokenizerFast"),Mfo=o(" (ConvBERT model)"),Efo=l(),rs=a("li"),Hie=a("strong"),Cfo=o("cpm"),wfo=o(" \u2014 "),yI=a("a"),Afo=o("CpmTokenizer"),Lfo=o(" or "),xI=a("a"),yfo=o("CpmTokenizerFast"),xfo=o(" (CPM model)"),$fo=l(),Mh=a("li"),Jie=a("strong"),kfo=o("ctrl"),Sfo=o(" \u2014 "),$I=a("a"),Rfo=o("CTRLTokenizer"),Pfo=o(" (CTRL model)"),Bfo=l(),ts=a("li"),Yie=a("strong"),Ifo=o("data2vec-text"),Nfo=o(" \u2014 "),kI=a("a"),qfo=o("RobertaTokenizer"),jfo=o(" or "),SI=a("a"),Dfo=o("RobertaTokenizerFast"),Gfo=o(" (Data2VecText model)"),Ofo=l(),as=a("li"),Kie=a("strong"),Vfo=o("deberta"),Xfo=o(" \u2014 "),RI=a("a"),zfo=o("DebertaTokenizer"),Wfo=o(" or "),PI=a("a"),Qfo=o("DebertaTokenizerFast"),Ufo=o(" (DeBERTa model)"),Hfo=l(),ns=a("li"),Zie=a("strong"),Jfo=o("deberta-v2"),Yfo=o(" \u2014 "),BI=a("a"),Kfo=o("DebertaV2Tokenizer"),Zfo=o(" or "),II=a("a"),emo=o("DebertaV2TokenizerFast"),omo=o(" (DeBERTa-v2 model)"),rmo=l(),ss=a("li"),ede=a("strong"),tmo=o("distilbert"),amo=o(" \u2014 "),NI=a("a"),nmo=o("DistilBertTokenizer"),smo=o(" or "),qI=a("a"),lmo=o("DistilBertTokenizerFast"),imo=o(" (DistilBERT model)"),dmo=l(),ls=a("li"),ode=a("strong"),cmo=o("dpr"),fmo=o(" \u2014 "),jI=a("a"),mmo=o("DPRQuestionEncoderTokenizer"),gmo=o(" or "),DI=a("a"),hmo=o("DPRQuestionEncoderTokenizerFast"),pmo=o(" (DPR model)"),_mo=l(),is=a("li"),rde=a("strong"),umo=o("electra"),bmo=o(" \u2014 "),GI=a("a"),vmo=o("ElectraTokenizer"),Fmo=o(" or "),OI=a("a"),Tmo=o("ElectraTokenizerFast"),Mmo=o(" (ELECTRA model)"),Emo=l(),Eh=a("li"),tde=a("strong"),Cmo=o("flaubert"),wmo=o(" \u2014 "),VI=a("a"),Amo=o("FlaubertTokenizer"),Lmo=o(" (FlauBERT model)"),ymo=l(),ds=a("li"),ade=a("strong"),xmo=o("fnet"),$mo=o(" \u2014 "),XI=a("a"),kmo=o("FNetTokenizer"),Smo=o(" or "),zI=a("a"),Rmo=o("FNetTokenizerFast"),Pmo=o(" (FNet model)"),Bmo=l(),Ch=a("li"),nde=a("strong"),Imo=o("fsmt"),Nmo=o(" \u2014 "),WI=a("a"),qmo=o("FSMTTokenizer"),jmo=o(" (FairSeq Machine-Translation model)"),Dmo=l(),cs=a("li"),sde=a("strong"),Gmo=o("funnel"),Omo=o(" \u2014 "),QI=a("a"),Vmo=o("FunnelTokenizer"),Xmo=o(" or "),UI=a("a"),zmo=o("FunnelTokenizerFast"),Wmo=o(" (Funnel Transformer model)"),Qmo=l(),fs=a("li"),lde=a("strong"),Umo=o("gpt2"),Hmo=o(" \u2014 "),HI=a("a"),Jmo=o("GPT2Tokenizer"),Ymo=o(" or "),JI=a("a"),Kmo=o("GPT2TokenizerFast"),Zmo=o(" (OpenAI GPT-2 model)"),ego=l(),ms=a("li"),ide=a("strong"),ogo=o("gpt_neo"),rgo=o(" \u2014 "),YI=a("a"),tgo=o("GPT2Tokenizer"),ago=o(" or "),KI=a("a"),ngo=o("GPT2TokenizerFast"),sgo=o(" (GPT Neo model)"),lgo=l(),wh=a("li"),dde=a("strong"),igo=o("gpt_neox"),dgo=o(" \u2014 "),ZI=a("a"),cgo=o("GPTNeoXTokenizerFast"),fgo=o(" (GPT NeoX model)"),mgo=l(),gs=a("li"),cde=a("strong"),ggo=o("gptj"),hgo=o(" \u2014 "),eN=a("a"),pgo=o("GPT2Tokenizer"),_go=o(" or "),oN=a("a"),ugo=o("GPT2TokenizerFast"),bgo=o(" (GPT-J model)"),vgo=l(),hs=a("li"),fde=a("strong"),Fgo=o("groupvit"),Tgo=o(" \u2014 "),rN=a("a"),Mgo=o("CLIPTokenizer"),Ego=o(" or "),tN=a("a"),Cgo=o("CLIPTokenizerFast"),wgo=o(" (GroupViT model)"),Ago=l(),ps=a("li"),mde=a("strong"),Lgo=o("herbert"),ygo=o(" \u2014 "),aN=a("a"),xgo=o("HerbertTokenizer"),$go=o(" or "),nN=a("a"),kgo=o("HerbertTokenizerFast"),Sgo=o(" (HerBERT model)"),Rgo=l(),Ah=a("li"),gde=a("strong"),Pgo=o("hubert"),Bgo=o(" \u2014 "),sN=a("a"),Igo=o("Wav2Vec2CTCTokenizer"),Ngo=o(" (Hubert model)"),qgo=l(),_s=a("li"),hde=a("strong"),jgo=o("ibert"),Dgo=o(" \u2014 "),lN=a("a"),Ggo=o("RobertaTokenizer"),Ogo=o(" or "),iN=a("a"),Vgo=o("RobertaTokenizerFast"),Xgo=o(" (I-BERT model)"),zgo=l(),us=a("li"),pde=a("strong"),Wgo=o("layoutlm"),Qgo=o(" \u2014 "),dN=a("a"),Ugo=o("LayoutLMTokenizer"),Hgo=o(" or "),cN=a("a"),Jgo=o("LayoutLMTokenizerFast"),Ygo=o(" (LayoutLM model)"),Kgo=l(),bs=a("li"),_de=a("strong"),Zgo=o("layoutlmv2"),eho=o(" \u2014 "),fN=a("a"),oho=o("LayoutLMv2Tokenizer"),rho=o(" or "),mN=a("a"),tho=o("LayoutLMv2TokenizerFast"),aho=o(" (LayoutLMv2 model)"),nho=l(),vs=a("li"),ude=a("strong"),sho=o("layoutlmv3"),lho=o(" \u2014 "),gN=a("a"),iho=o("LayoutLMv3Tokenizer"),dho=o(" or "),hN=a("a"),cho=o("LayoutLMv3TokenizerFast"),fho=o(" (LayoutLMv3 model)"),mho=l(),Fs=a("li"),bde=a("strong"),gho=o("layoutxlm"),hho=o(" \u2014 "),pN=a("a"),pho=o("LayoutXLMTokenizer"),_ho=o(" or "),_N=a("a"),uho=o("LayoutXLMTokenizerFast"),bho=o(" (LayoutXLM model)"),vho=l(),Ts=a("li"),vde=a("strong"),Fho=o("led"),Tho=o(" \u2014 "),uN=a("a"),Mho=o("LEDTokenizer"),Eho=o(" or "),bN=a("a"),Cho=o("LEDTokenizerFast"),who=o(" (LED model)"),Aho=l(),Ms=a("li"),Fde=a("strong"),Lho=o("longformer"),yho=o(" \u2014 "),vN=a("a"),xho=o("LongformerTokenizer"),$ho=o(" or "),FN=a("a"),kho=o("LongformerTokenizerFast"),Sho=o(" (Longformer model)"),Rho=l(),Es=a("li"),Tde=a("strong"),Pho=o("longt5"),Bho=o(" \u2014 "),TN=a("a"),Iho=o("T5Tokenizer"),Nho=o(" or "),MN=a("a"),qho=o("T5TokenizerFast"),jho=o(" (LongT5 model)"),Dho=l(),Lh=a("li"),Mde=a("strong"),Gho=o("luke"),Oho=o(" \u2014 "),EN=a("a"),Vho=o("LukeTokenizer"),Xho=o(" (LUKE model)"),zho=l(),Cs=a("li"),Ede=a("strong"),Who=o("lxmert"),Qho=o(" \u2014 "),CN=a("a"),Uho=o("LxmertTokenizer"),Hho=o(" or "),wN=a("a"),Jho=o("LxmertTokenizerFast"),Yho=o(" (LXMERT model)"),Kho=l(),yh=a("li"),Cde=a("strong"),Zho=o("m2m_100"),epo=o(" \u2014 "),AN=a("a"),opo=o("M2M100Tokenizer"),rpo=o(" (M2M100 model)"),tpo=l(),xh=a("li"),wde=a("strong"),apo=o("marian"),npo=o(" \u2014 "),LN=a("a"),spo=o("MarianTokenizer"),lpo=o(" (Marian model)"),ipo=l(),ws=a("li"),Ade=a("strong"),dpo=o("mbart"),cpo=o(" \u2014 "),yN=a("a"),fpo=o("MBartTokenizer"),mpo=o(" or "),xN=a("a"),gpo=o("MBartTokenizerFast"),hpo=o(" (mBART model)"),ppo=l(),As=a("li"),Lde=a("strong"),_po=o("mbart50"),upo=o(" \u2014 "),$N=a("a"),bpo=o("MBart50Tokenizer"),vpo=o(" or "),kN=a("a"),Fpo=o("MBart50TokenizerFast"),Tpo=o(" (mBART-50 model)"),Mpo=l(),Ls=a("li"),yde=a("strong"),Epo=o("megatron-bert"),Cpo=o(" \u2014 "),SN=a("a"),wpo=o("BertTokenizer"),Apo=o(" or "),RN=a("a"),Lpo=o("BertTokenizerFast"),ypo=o(" (Megatron-BERT model)"),xpo=l(),$h=a("li"),xde=a("strong"),$po=o("mluke"),kpo=o(" \u2014 "),PN=a("a"),Spo=o("MLukeTokenizer"),Rpo=o(" (mLUKE model)"),Ppo=l(),ys=a("li"),$de=a("strong"),Bpo=o("mobilebert"),Ipo=o(" \u2014 "),BN=a("a"),Npo=o("MobileBertTokenizer"),qpo=o(" or "),IN=a("a"),jpo=o("MobileBertTokenizerFast"),Dpo=o(" (MobileBERT model)"),Gpo=l(),xs=a("li"),kde=a("strong"),Opo=o("mpnet"),Vpo=o(" \u2014 "),NN=a("a"),Xpo=o("MPNetTokenizer"),zpo=o(" or "),qN=a("a"),Wpo=o("MPNetTokenizerFast"),Qpo=o(" (MPNet model)"),Upo=l(),$s=a("li"),Sde=a("strong"),Hpo=o("mt5"),Jpo=o(" \u2014 "),jN=a("a"),Ypo=o("MT5Tokenizer"),Kpo=o(" or "),DN=a("a"),Zpo=o("MT5TokenizerFast"),e_o=o(" (MT5 model)"),o_o=l(),ks=a("li"),Rde=a("strong"),r_o=o("mvp"),t_o=o(" \u2014 "),GN=a("a"),a_o=o("MvpTokenizer"),n_o=o(" or "),ON=a("a"),s_o=o("MvpTokenizerFast"),l_o=o(" (MVP model)"),i_o=l(),Ss=a("li"),Pde=a("strong"),d_o=o("nezha"),c_o=o(" \u2014 "),VN=a("a"),f_o=o("BertTokenizer"),m_o=o(" or "),XN=a("a"),g_o=o("BertTokenizerFast"),h_o=o(" (Nezha model)"),p_o=l(),Rs=a("li"),Bde=a("strong"),__o=o("nllb"),u_o=o(" \u2014 "),zN=a("a"),b_o=o("NllbTokenizer"),v_o=o(" or "),WN=a("a"),F_o=o("NllbTokenizerFast"),T_o=o(" (NLLB model)"),M_o=l(),Ps=a("li"),Ide=a("strong"),E_o=o("nystromformer"),C_o=o(" \u2014 "),QN=a("a"),w_o=o("AlbertTokenizer"),A_o=o(" or "),UN=a("a"),L_o=o("AlbertTokenizerFast"),y_o=o(" (Nystr\xF6mformer model)"),x_o=l(),Bs=a("li"),Nde=a("strong"),$_o=o("openai-gpt"),k_o=o(" \u2014 "),HN=a("a"),S_o=o("OpenAIGPTTokenizer"),R_o=o(" or "),JN=a("a"),P_o=o("OpenAIGPTTokenizerFast"),B_o=o(" (OpenAI GPT model)"),I_o=l(),kh=a("li"),qde=a("strong"),N_o=o("opt"),q_o=o(" \u2014 "),YN=a("a"),j_o=o("GPT2Tokenizer"),D_o=o(" (OPT model)"),G_o=l(),Is=a("li"),jde=a("strong"),O_o=o("owlvit"),V_o=o(" \u2014 "),KN=a("a"),X_o=o("CLIPTokenizer"),z_o=o(" or "),ZN=a("a"),W_o=o("CLIPTokenizerFast"),Q_o=o(" (OWL-ViT model)"),U_o=l(),Ns=a("li"),Dde=a("strong"),H_o=o("pegasus"),J_o=o(" \u2014 "),eq=a("a"),Y_o=o("PegasusTokenizer"),K_o=o(" or "),oq=a("a"),Z_o=o("PegasusTokenizerFast"),euo=o(" (Pegasus model)"),ouo=l(),Sh=a("li"),Gde=a("strong"),ruo=o("perceiver"),tuo=o(" \u2014 "),rq=a("a"),auo=o("PerceiverTokenizer"),nuo=o(" (Perceiver model)"),suo=l(),Rh=a("li"),Ode=a("strong"),luo=o("phobert"),iuo=o(" \u2014 "),tq=a("a"),duo=o("PhobertTokenizer"),cuo=o(" (PhoBERT model)"),fuo=l(),Ph=a("li"),Vde=a("strong"),muo=o("plbart"),guo=o(" \u2014 "),aq=a("a"),huo=o("PLBartTokenizer"),puo=o(" (PLBart model)"),_uo=l(),Bh=a("li"),Xde=a("strong"),uuo=o("prophetnet"),buo=o(" \u2014 "),nq=a("a"),vuo=o("ProphetNetTokenizer"),Fuo=o(" (ProphetNet model)"),Tuo=l(),qs=a("li"),zde=a("strong"),Muo=o("qdqbert"),Euo=o(" \u2014 "),sq=a("a"),Cuo=o("BertTokenizer"),wuo=o(" or "),lq=a("a"),Auo=o("BertTokenizerFast"),Luo=o(" (QDQBert model)"),yuo=l(),Ih=a("li"),Wde=a("strong"),xuo=o("rag"),$uo=o(" \u2014 "),iq=a("a"),kuo=o("RagTokenizer"),Suo=o(" (RAG model)"),Ruo=l(),js=a("li"),Qde=a("strong"),Puo=o("realm"),Buo=o(" \u2014 "),dq=a("a"),Iuo=o("RealmTokenizer"),Nuo=o(" or "),cq=a("a"),quo=o("RealmTokenizerFast"),juo=o(" (REALM model)"),Duo=l(),Ds=a("li"),Ude=a("strong"),Guo=o("reformer"),Ouo=o(" \u2014 "),fq=a("a"),Vuo=o("ReformerTokenizer"),Xuo=o(" or "),mq=a("a"),zuo=o("ReformerTokenizerFast"),Wuo=o(" (Reformer model)"),Quo=l(),Gs=a("li"),Hde=a("strong"),Uuo=o("rembert"),Huo=o(" \u2014 "),gq=a("a"),Juo=o("RemBertTokenizer"),Yuo=o(" or "),hq=a("a"),Kuo=o("RemBertTokenizerFast"),Zuo=o(" (RemBERT model)"),e2o=l(),Os=a("li"),Jde=a("strong"),o2o=o("retribert"),r2o=o(" \u2014 "),pq=a("a"),t2o=o("RetriBertTokenizer"),a2o=o(" or "),_q=a("a"),n2o=o("RetriBertTokenizerFast"),s2o=o(" (RetriBERT model)"),l2o=l(),Vs=a("li"),Yde=a("strong"),i2o=o("roberta"),d2o=o(" \u2014 "),uq=a("a"),c2o=o("RobertaTokenizer"),f2o=o(" or "),bq=a("a"),m2o=o("RobertaTokenizerFast"),g2o=o(" (RoBERTa model)"),h2o=l(),Xs=a("li"),Kde=a("strong"),p2o=o("roformer"),_2o=o(" \u2014 "),vq=a("a"),u2o=o("RoFormerTokenizer"),b2o=o(" or "),Fq=a("a"),v2o=o("RoFormerTokenizerFast"),F2o=o(" (RoFormer model)"),T2o=l(),Nh=a("li"),Zde=a("strong"),M2o=o("speech_to_text"),E2o=o(" \u2014 "),Tq=a("a"),C2o=o("Speech2TextTokenizer"),w2o=o(" (Speech2Text model)"),A2o=l(),qh=a("li"),ece=a("strong"),L2o=o("speech_to_text_2"),y2o=o(" \u2014 "),Mq=a("a"),x2o=o("Speech2Text2Tokenizer"),$2o=o(" (Speech2Text2 model)"),k2o=l(),zs=a("li"),oce=a("strong"),S2o=o("splinter"),R2o=o(" \u2014 "),Eq=a("a"),P2o=o("SplinterTokenizer"),B2o=o(" or "),Cq=a("a"),I2o=o("SplinterTokenizerFast"),N2o=o(" (Splinter model)"),q2o=l(),Ws=a("li"),rce=a("strong"),j2o=o("squeezebert"),D2o=o(" \u2014 "),wq=a("a"),G2o=o("SqueezeBertTokenizer"),O2o=o(" or "),Aq=a("a"),V2o=o("SqueezeBertTokenizerFast"),X2o=o(" (SqueezeBERT model)"),z2o=l(),Qs=a("li"),tce=a("strong"),W2o=o("t5"),Q2o=o(" \u2014 "),Lq=a("a"),U2o=o("T5Tokenizer"),H2o=o(" or "),yq=a("a"),J2o=o("T5TokenizerFast"),Y2o=o(" (T5 model)"),K2o=l(),jh=a("li"),ace=a("strong"),Z2o=o("tapas"),e1o=o(" \u2014 "),xq=a("a"),o1o=o("TapasTokenizer"),r1o=o(" (TAPAS model)"),t1o=l(),Dh=a("li"),nce=a("strong"),a1o=o("tapex"),n1o=o(" \u2014 "),$q=a("a"),s1o=o("TapexTokenizer"),l1o=o(" (TAPEX model)"),i1o=l(),Gh=a("li"),sce=a("strong"),d1o=o("transfo-xl"),c1o=o(" \u2014 "),kq=a("a"),f1o=o("TransfoXLTokenizer"),m1o=o(" (Transformer-XL model)"),g1o=l(),Us=a("li"),lce=a("strong"),h1o=o("vilt"),p1o=o(" \u2014 "),Sq=a("a"),_1o=o("BertTokenizer"),u1o=o(" or "),Rq=a("a"),b1o=o("BertTokenizerFast"),v1o=o(" (ViLT model)"),F1o=l(),Hs=a("li"),ice=a("strong"),T1o=o("visual_bert"),M1o=o(" \u2014 "),Pq=a("a"),E1o=o("BertTokenizer"),C1o=o(" or "),Bq=a("a"),w1o=o("BertTokenizerFast"),A1o=o(" (VisualBERT model)"),L1o=l(),Oh=a("li"),dce=a("strong"),y1o=o("wav2vec2"),x1o=o(" \u2014 "),Iq=a("a"),$1o=o("Wav2Vec2CTCTokenizer"),k1o=o(" (Wav2Vec2 model)"),S1o=l(),Vh=a("li"),cce=a("strong"),R1o=o("wav2vec2-conformer"),P1o=o(" \u2014 "),Nq=a("a"),B1o=o("Wav2Vec2CTCTokenizer"),I1o=o(" (Wav2Vec2-Conformer model)"),N1o=l(),Xh=a("li"),fce=a("strong"),q1o=o("wav2vec2_phoneme"),j1o=o(" \u2014 "),qq=a("a"),D1o=o("Wav2Vec2PhonemeCTCTokenizer"),G1o=o(" (Wav2Vec2Phoneme model)"),O1o=l(),Js=a("li"),mce=a("strong"),V1o=o("xglm"),X1o=o(" \u2014 "),jq=a("a"),z1o=o("XGLMTokenizer"),W1o=o(" or "),Dq=a("a"),Q1o=o("XGLMTokenizerFast"),U1o=o(" (XGLM model)"),H1o=l(),zh=a("li"),gce=a("strong"),J1o=o("xlm"),Y1o=o(" \u2014 "),Gq=a("a"),K1o=o("XLMTokenizer"),Z1o=o(" (XLM model)"),e4o=l(),Wh=a("li"),hce=a("strong"),o4o=o("xlm-prophetnet"),r4o=o(" \u2014 "),Oq=a("a"),t4o=o("XLMProphetNetTokenizer"),a4o=o(" (XLM-ProphetNet model)"),n4o=l(),Ys=a("li"),pce=a("strong"),s4o=o("xlm-roberta"),l4o=o(" \u2014 "),Vq=a("a"),i4o=o("XLMRobertaTokenizer"),d4o=o(" or "),Xq=a("a"),c4o=o("XLMRobertaTokenizerFast"),f4o=o(" (XLM-RoBERTa model)"),m4o=l(),Ks=a("li"),_ce=a("strong"),g4o=o("xlm-roberta-xl"),h4o=o(" \u2014 "),zq=a("a"),p4o=o("RobertaTokenizer"),_4o=o(" or "),Wq=a("a"),u4o=o("RobertaTokenizerFast"),b4o=o(" (XLM-RoBERTa-XL model)"),v4o=l(),Zs=a("li"),uce=a("strong"),F4o=o("xlnet"),T4o=o(" \u2014 "),Qq=a("a"),M4o=o("XLNetTokenizer"),E4o=o(" or "),Uq=a("a"),C4o=o("XLNetTokenizerFast"),w4o=o(" (XLNet model)"),A4o=l(),el=a("li"),bce=a("strong"),L4o=o("yoso"),y4o=o(" \u2014 "),Hq=a("a"),x4o=o("AlbertTokenizer"),$4o=o(" or "),Jq=a("a"),k4o=o("AlbertTokenizerFast"),S4o=o(" (YOSO model)"),R4o=l(),F(Qh.$$.fragment),P4o=l(),Uh=a("div"),F(sy.$$.fragment),B4o=l(),vce=a("p"),I4o=o("Register a new tokenizer in this mapping."),UWe=l(),Qi=a("h2"),Hh=a("a"),Fce=a("span"),F(ly.$$.fragment),N4o=l(),Tce=a("span"),q4o=o("AutoFeatureExtractor"),HWe=l(),$o=a("div"),F(iy.$$.fragment),j4o=l(),dy=a("p"),D4o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),Yq=a("a"),G4o=o("AutoFeatureExtractor.from_pretrained()"),O4o=o(" class method."),V4o=l(),cy=a("p"),X4o=o("This class cannot be instantiated directly using "),Mce=a("code"),z4o=o("__init__()"),W4o=o(" (throws an error)."),Q4o=l(),He=a("div"),F(fy.$$.fragment),U4o=l(),Ece=a("p"),H4o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),J4o=l(),ja=a("p"),Y4o=o("The feature extractor class to instantiate is selected based on the "),Cce=a("code"),K4o=o("model_type"),Z4o=o(` property of the config object
(either passed as an argument or loaded from `),wce=a("code"),ebo=o("pretrained_model_name_or_path"),obo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ace=a("code"),rbo=o("pretrained_model_name_or_path"),tbo=o(":"),abo=l(),Q=a("ul"),Jh=a("li"),Lce=a("strong"),nbo=o("beit"),sbo=o(" \u2014 "),Kq=a("a"),lbo=o("BeitFeatureExtractor"),ibo=o(" (BEiT model)"),dbo=l(),Yh=a("li"),yce=a("strong"),cbo=o("clip"),fbo=o(" \u2014 "),Zq=a("a"),mbo=o("CLIPFeatureExtractor"),gbo=o(" (CLIP model)"),hbo=l(),Kh=a("li"),xce=a("strong"),pbo=o("convnext"),_bo=o(" \u2014 "),ej=a("a"),ubo=o("ConvNextFeatureExtractor"),bbo=o(" (ConvNeXT model)"),vbo=l(),Zh=a("li"),$ce=a("strong"),Fbo=o("cvt"),Tbo=o(" \u2014 "),oj=a("a"),Mbo=o("ConvNextFeatureExtractor"),Ebo=o(" (CvT model)"),Cbo=l(),ep=a("li"),kce=a("strong"),wbo=o("data2vec-audio"),Abo=o(" \u2014 "),rj=a("a"),Lbo=o("Wav2Vec2FeatureExtractor"),ybo=o(" (Data2VecAudio model)"),xbo=l(),op=a("li"),Sce=a("strong"),$bo=o("data2vec-vision"),kbo=o(" \u2014 "),tj=a("a"),Sbo=o("BeitFeatureExtractor"),Rbo=o(" (Data2VecVision model)"),Pbo=l(),rp=a("li"),Rce=a("strong"),Bbo=o("deit"),Ibo=o(" \u2014 "),aj=a("a"),Nbo=o("DeiTFeatureExtractor"),qbo=o(" (DeiT model)"),jbo=l(),tp=a("li"),Pce=a("strong"),Dbo=o("detr"),Gbo=o(" \u2014 "),nj=a("a"),Obo=o("DetrFeatureExtractor"),Vbo=o(" (DETR model)"),Xbo=l(),ap=a("li"),Bce=a("strong"),zbo=o("dpt"),Wbo=o(" \u2014 "),sj=a("a"),Qbo=o("DPTFeatureExtractor"),Ubo=o(" (DPT model)"),Hbo=l(),np=a("li"),Ice=a("strong"),Jbo=o("flava"),Ybo=o(" \u2014 "),lj=a("a"),Kbo=o("FlavaFeatureExtractor"),Zbo=o(" (FLAVA model)"),evo=l(),sp=a("li"),Nce=a("strong"),ovo=o("glpn"),rvo=o(" \u2014 "),ij=a("a"),tvo=o("GLPNFeatureExtractor"),avo=o(" (GLPN model)"),nvo=l(),lp=a("li"),qce=a("strong"),svo=o("groupvit"),lvo=o(" \u2014 "),dj=a("a"),ivo=o("CLIPFeatureExtractor"),dvo=o(" (GroupViT model)"),cvo=l(),ip=a("li"),jce=a("strong"),fvo=o("hubert"),mvo=o(" \u2014 "),cj=a("a"),gvo=o("Wav2Vec2FeatureExtractor"),hvo=o(" (Hubert model)"),pvo=l(),dp=a("li"),Dce=a("strong"),_vo=o("imagegpt"),uvo=o(" \u2014 "),fj=a("a"),bvo=o("ImageGPTFeatureExtractor"),vvo=o(" (ImageGPT model)"),Fvo=l(),cp=a("li"),Gce=a("strong"),Tvo=o("layoutlmv2"),Mvo=o(" \u2014 "),mj=a("a"),Evo=o("LayoutLMv2FeatureExtractor"),Cvo=o(" (LayoutLMv2 model)"),wvo=l(),fp=a("li"),Oce=a("strong"),Avo=o("layoutlmv3"),Lvo=o(" \u2014 "),gj=a("a"),yvo=o("LayoutLMv3FeatureExtractor"),xvo=o(" (LayoutLMv3 model)"),$vo=l(),mp=a("li"),Vce=a("strong"),kvo=o("levit"),Svo=o(" \u2014 "),hj=a("a"),Rvo=o("LevitFeatureExtractor"),Pvo=o(" (LeViT model)"),Bvo=l(),gp=a("li"),Xce=a("strong"),Ivo=o("luke"),Nvo=o(" \u2014 "),zce=a("code"),qvo=o("LukeFeatureExtractor"),jvo=o(" (LUKE model)"),Dvo=l(),hp=a("li"),Wce=a("strong"),Gvo=o("maskformer"),Ovo=o(" \u2014 "),pj=a("a"),Vvo=o("MaskFormerFeatureExtractor"),Xvo=o(" (MaskFormer model)"),zvo=l(),pp=a("li"),Qce=a("strong"),Wvo=o("mctct"),Qvo=o(" \u2014 "),_j=a("a"),Uvo=o("MCTCTFeatureExtractor"),Hvo=o(" (M-CTC-T model)"),Jvo=l(),_p=a("li"),Uce=a("strong"),Yvo=o("mobilevit"),Kvo=o(" \u2014 "),uj=a("a"),Zvo=o("MobileViTFeatureExtractor"),e5o=o(" (MobileViT model)"),o5o=l(),up=a("li"),Hce=a("strong"),r5o=o("owlvit"),t5o=o(" \u2014 "),bj=a("a"),a5o=o("OwlViTFeatureExtractor"),n5o=o(" (OWL-ViT model)"),s5o=l(),bp=a("li"),Jce=a("strong"),l5o=o("perceiver"),i5o=o(" \u2014 "),vj=a("a"),d5o=o("PerceiverFeatureExtractor"),c5o=o(" (Perceiver model)"),f5o=l(),vp=a("li"),Yce=a("strong"),m5o=o("poolformer"),g5o=o(" \u2014 "),Fj=a("a"),h5o=o("PoolFormerFeatureExtractor"),p5o=o(" (PoolFormer model)"),_5o=l(),Fp=a("li"),Kce=a("strong"),u5o=o("regnet"),b5o=o(" \u2014 "),Tj=a("a"),v5o=o("ConvNextFeatureExtractor"),F5o=o(" (RegNet model)"),T5o=l(),Tp=a("li"),Zce=a("strong"),M5o=o("resnet"),E5o=o(" \u2014 "),Mj=a("a"),C5o=o("ConvNextFeatureExtractor"),w5o=o(" (ResNet model)"),A5o=l(),Mp=a("li"),efe=a("strong"),L5o=o("segformer"),y5o=o(" \u2014 "),Ej=a("a"),x5o=o("SegformerFeatureExtractor"),$5o=o(" (SegFormer model)"),k5o=l(),Ep=a("li"),ofe=a("strong"),S5o=o("speech_to_text"),R5o=o(" \u2014 "),Cj=a("a"),P5o=o("Speech2TextFeatureExtractor"),B5o=o(" (Speech2Text model)"),I5o=l(),Cp=a("li"),rfe=a("strong"),N5o=o("swin"),q5o=o(" \u2014 "),wj=a("a"),j5o=o("ViTFeatureExtractor"),D5o=o(" (Swin Transformer model)"),G5o=l(),wp=a("li"),tfe=a("strong"),O5o=o("swinv2"),V5o=o(" \u2014 "),Aj=a("a"),X5o=o("ViTFeatureExtractor"),z5o=o(" (Swin Transformer V2 model)"),W5o=l(),Ap=a("li"),afe=a("strong"),Q5o=o("van"),U5o=o(" \u2014 "),Lj=a("a"),H5o=o("ConvNextFeatureExtractor"),J5o=o(" (VAN model)"),Y5o=l(),Lp=a("li"),nfe=a("strong"),K5o=o("videomae"),Z5o=o(" \u2014 "),yj=a("a"),eFo=o("ViTFeatureExtractor"),oFo=o(" (VideoMAE model)"),rFo=l(),yp=a("li"),sfe=a("strong"),tFo=o("vilt"),aFo=o(" \u2014 "),xj=a("a"),nFo=o("ViltFeatureExtractor"),sFo=o(" (ViLT model)"),lFo=l(),xp=a("li"),lfe=a("strong"),iFo=o("vit"),dFo=o(" \u2014 "),$j=a("a"),cFo=o("ViTFeatureExtractor"),fFo=o(" (ViT model)"),mFo=l(),$p=a("li"),ife=a("strong"),gFo=o("vit_mae"),hFo=o(" \u2014 "),kj=a("a"),pFo=o("ViTFeatureExtractor"),_Fo=o(" (ViTMAE model)"),uFo=l(),kp=a("li"),dfe=a("strong"),bFo=o("wav2vec2"),vFo=o(" \u2014 "),Sj=a("a"),FFo=o("Wav2Vec2FeatureExtractor"),TFo=o(" (Wav2Vec2 model)"),MFo=l(),Sp=a("li"),cfe=a("strong"),EFo=o("wav2vec2-conformer"),CFo=o(" \u2014 "),Rj=a("a"),wFo=o("Wav2Vec2FeatureExtractor"),AFo=o(" (Wav2Vec2-Conformer model)"),LFo=l(),Rp=a("li"),ffe=a("strong"),yFo=o("yolos"),xFo=o(" \u2014 "),Pj=a("a"),$Fo=o("YolosFeatureExtractor"),kFo=o(" (YOLOS model)"),SFo=l(),F(Pp.$$.fragment),RFo=l(),F(Bp.$$.fragment),PFo=l(),Ip=a("div"),F(my.$$.fragment),BFo=l(),mfe=a("p"),IFo=o("Register a new feature extractor for this class."),JWe=l(),Ui=a("h2"),Np=a("a"),gfe=a("span"),F(gy.$$.fragment),NFo=l(),hfe=a("span"),qFo=o("AutoProcessor"),YWe=l(),ko=a("div"),F(hy.$$.fragment),jFo=l(),py=a("p"),DFo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Bj=a("a"),GFo=o("AutoProcessor.from_pretrained()"),OFo=o(" class method."),VFo=l(),_y=a("p"),XFo=o("This class cannot be instantiated directly using "),pfe=a("code"),zFo=o("__init__()"),WFo=o(" (throws an error)."),QFo=l(),Je=a("div"),F(uy.$$.fragment),UFo=l(),_fe=a("p"),HFo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),JFo=l(),Hi=a("p"),YFo=o("The processor class to instantiate is selected based on the "),ufe=a("code"),KFo=o("model_type"),ZFo=o(` property of the config object (either
passed as an argument or loaded from `),bfe=a("code"),eTo=o("pretrained_model_name_or_path"),oTo=o(" if possible):"),rTo=l(),fe=a("ul"),qp=a("li"),vfe=a("strong"),tTo=o("clip"),aTo=o(" \u2014 "),Ij=a("a"),nTo=o("CLIPProcessor"),sTo=o(" (CLIP model)"),lTo=l(),jp=a("li"),Ffe=a("strong"),iTo=o("flava"),dTo=o(" \u2014 "),Nj=a("a"),cTo=o("FlavaProcessor"),fTo=o(" (FLAVA model)"),mTo=l(),Dp=a("li"),Tfe=a("strong"),gTo=o("groupvit"),hTo=o(" \u2014 "),qj=a("a"),pTo=o("CLIPProcessor"),_To=o(" (GroupViT model)"),uTo=l(),Gp=a("li"),Mfe=a("strong"),bTo=o("layoutlmv2"),vTo=o(" \u2014 "),jj=a("a"),FTo=o("LayoutLMv2Processor"),TTo=o(" (LayoutLMv2 model)"),MTo=l(),Op=a("li"),Efe=a("strong"),ETo=o("layoutlmv3"),CTo=o(" \u2014 "),Dj=a("a"),wTo=o("LayoutLMv3Processor"),ATo=o(" (LayoutLMv3 model)"),LTo=l(),Vp=a("li"),Cfe=a("strong"),yTo=o("layoutxlm"),xTo=o(" \u2014 "),Gj=a("a"),$To=o("LayoutXLMProcessor"),kTo=o(" (LayoutXLM model)"),STo=l(),Xp=a("li"),wfe=a("strong"),RTo=o("owlvit"),PTo=o(" \u2014 "),Oj=a("a"),BTo=o("OwlViTProcessor"),ITo=o(" (OWL-ViT model)"),NTo=l(),zp=a("li"),Afe=a("strong"),qTo=o("sew"),jTo=o(" \u2014 "),Vj=a("a"),DTo=o("Wav2Vec2Processor"),GTo=o(" (SEW model)"),OTo=l(),Wp=a("li"),Lfe=a("strong"),VTo=o("sew-d"),XTo=o(" \u2014 "),Xj=a("a"),zTo=o("Wav2Vec2Processor"),WTo=o(" (SEW-D model)"),QTo=l(),Qp=a("li"),yfe=a("strong"),UTo=o("speech_to_text"),HTo=o(" \u2014 "),zj=a("a"),JTo=o("Speech2TextProcessor"),YTo=o(" (Speech2Text model)"),KTo=l(),Up=a("li"),xfe=a("strong"),ZTo=o("speech_to_text_2"),e8o=o(" \u2014 "),Wj=a("a"),o8o=o("Speech2Text2Processor"),r8o=o(" (Speech2Text2 model)"),t8o=l(),Hp=a("li"),$fe=a("strong"),a8o=o("trocr"),n8o=o(" \u2014 "),Qj=a("a"),s8o=o("TrOCRProcessor"),l8o=o(" (TrOCR model)"),i8o=l(),Jp=a("li"),kfe=a("strong"),d8o=o("unispeech"),c8o=o(" \u2014 "),Uj=a("a"),f8o=o("Wav2Vec2Processor"),m8o=o(" (UniSpeech model)"),g8o=l(),Yp=a("li"),Sfe=a("strong"),h8o=o("unispeech-sat"),p8o=o(" \u2014 "),Hj=a("a"),_8o=o("Wav2Vec2Processor"),u8o=o(" (UniSpeechSat model)"),b8o=l(),Kp=a("li"),Rfe=a("strong"),v8o=o("vilt"),F8o=o(" \u2014 "),Jj=a("a"),T8o=o("ViltProcessor"),M8o=o(" (ViLT model)"),E8o=l(),Zp=a("li"),Pfe=a("strong"),C8o=o("vision-text-dual-encoder"),w8o=o(" \u2014 "),Yj=a("a"),A8o=o("VisionTextDualEncoderProcessor"),L8o=o(" (VisionTextDualEncoder model)"),y8o=l(),e_=a("li"),Bfe=a("strong"),x8o=o("wav2vec2"),$8o=o(" \u2014 "),Kj=a("a"),k8o=o("Wav2Vec2Processor"),S8o=o(" (Wav2Vec2 model)"),R8o=l(),o_=a("li"),Ife=a("strong"),P8o=o("wav2vec2-conformer"),B8o=o(" \u2014 "),Zj=a("a"),I8o=o("Wav2Vec2Processor"),N8o=o(" (Wav2Vec2-Conformer model)"),q8o=l(),r_=a("li"),Nfe=a("strong"),j8o=o("wavlm"),D8o=o(" \u2014 "),eD=a("a"),G8o=o("Wav2Vec2Processor"),O8o=o(" (WavLM model)"),V8o=l(),F(t_.$$.fragment),X8o=l(),F(a_.$$.fragment),z8o=l(),n_=a("div"),F(by.$$.fragment),W8o=l(),qfe=a("p"),Q8o=o("Register a new processor for this class."),KWe=l(),Ji=a("h2"),s_=a("a"),jfe=a("span"),F(vy.$$.fragment),U8o=l(),Dfe=a("span"),H8o=o("AutoModel"),ZWe=l(),So=a("div"),F(Fy.$$.fragment),J8o=l(),Yi=a("p"),Y8o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oD=a("a"),K8o=o("from_pretrained()"),Z8o=o(" class method or the "),rD=a("a"),eMo=o("from_config()"),oMo=o(` class
method.`),rMo=l(),Ty=a("p"),tMo=o("This class cannot be instantiated directly using "),Gfe=a("code"),aMo=o("__init__()"),nMo=o(" (throws an error)."),sMo=l(),ct=a("div"),F(My.$$.fragment),lMo=l(),Ofe=a("p"),iMo=o("Instantiates one of the base model classes of the library from a configuration."),dMo=l(),Ki=a("p"),cMo=o(`Note:
Loading a model from its configuration file does `),Vfe=a("strong"),fMo=o("not"),mMo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tD=a("a"),gMo=o("from_pretrained()"),hMo=o(" to load the model weights."),pMo=l(),F(l_.$$.fragment),_Mo=l(),Ye=a("div"),F(Ey.$$.fragment),uMo=l(),Xfe=a("p"),bMo=o("Instantiate one of the base model classes of the library from a pretrained model."),vMo=l(),Da=a("p"),FMo=o("The model class to instantiate is selected based on the "),zfe=a("code"),TMo=o("model_type"),MMo=o(` property of the config object (either
passed as an argument or loaded from `),Wfe=a("code"),EMo=o("pretrained_model_name_or_path"),CMo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qfe=a("code"),wMo=o("pretrained_model_name_or_path"),AMo=o(":"),LMo=l(),y=a("ul"),i_=a("li"),Ufe=a("strong"),yMo=o("albert"),xMo=o(" \u2014 "),aD=a("a"),$Mo=o("AlbertModel"),kMo=o(" (ALBERT model)"),SMo=l(),d_=a("li"),Hfe=a("strong"),RMo=o("bart"),PMo=o(" \u2014 "),nD=a("a"),BMo=o("BartModel"),IMo=o(" (BART model)"),NMo=l(),c_=a("li"),Jfe=a("strong"),qMo=o("beit"),jMo=o(" \u2014 "),sD=a("a"),DMo=o("BeitModel"),GMo=o(" (BEiT model)"),OMo=l(),f_=a("li"),Yfe=a("strong"),VMo=o("bert"),XMo=o(" \u2014 "),lD=a("a"),zMo=o("BertModel"),WMo=o(" (BERT model)"),QMo=l(),m_=a("li"),Kfe=a("strong"),UMo=o("bert-generation"),HMo=o(" \u2014 "),iD=a("a"),JMo=o("BertGenerationEncoder"),YMo=o(" (Bert Generation model)"),KMo=l(),g_=a("li"),Zfe=a("strong"),ZMo=o("big_bird"),eEo=o(" \u2014 "),dD=a("a"),oEo=o("BigBirdModel"),rEo=o(" (BigBird model)"),tEo=l(),h_=a("li"),eme=a("strong"),aEo=o("bigbird_pegasus"),nEo=o(" \u2014 "),cD=a("a"),sEo=o("BigBirdPegasusModel"),lEo=o(" (BigBird-Pegasus model)"),iEo=l(),p_=a("li"),ome=a("strong"),dEo=o("blenderbot"),cEo=o(" \u2014 "),fD=a("a"),fEo=o("BlenderbotModel"),mEo=o(" (Blenderbot model)"),gEo=l(),__=a("li"),rme=a("strong"),hEo=o("blenderbot-small"),pEo=o(" \u2014 "),mD=a("a"),_Eo=o("BlenderbotSmallModel"),uEo=o(" (BlenderbotSmall model)"),bEo=l(),u_=a("li"),tme=a("strong"),vEo=o("bloom"),FEo=o(" \u2014 "),gD=a("a"),TEo=o("BloomModel"),MEo=o(" (BLOOM model)"),EEo=l(),b_=a("li"),ame=a("strong"),CEo=o("camembert"),wEo=o(" \u2014 "),hD=a("a"),AEo=o("CamembertModel"),LEo=o(" (CamemBERT model)"),yEo=l(),v_=a("li"),nme=a("strong"),xEo=o("canine"),$Eo=o(" \u2014 "),pD=a("a"),kEo=o("CanineModel"),SEo=o(" (CANINE model)"),REo=l(),F_=a("li"),sme=a("strong"),PEo=o("clip"),BEo=o(" \u2014 "),_D=a("a"),IEo=o("CLIPModel"),NEo=o(" (CLIP model)"),qEo=l(),T_=a("li"),lme=a("strong"),jEo=o("codegen"),DEo=o(" \u2014 "),uD=a("a"),GEo=o("CodeGenModel"),OEo=o(" (CodeGen model)"),VEo=l(),M_=a("li"),ime=a("strong"),XEo=o("convbert"),zEo=o(" \u2014 "),bD=a("a"),WEo=o("ConvBertModel"),QEo=o(" (ConvBERT model)"),UEo=l(),E_=a("li"),dme=a("strong"),HEo=o("convnext"),JEo=o(" \u2014 "),vD=a("a"),YEo=o("ConvNextModel"),KEo=o(" (ConvNeXT model)"),ZEo=l(),C_=a("li"),cme=a("strong"),eCo=o("ctrl"),oCo=o(" \u2014 "),FD=a("a"),rCo=o("CTRLModel"),tCo=o(" (CTRL model)"),aCo=l(),w_=a("li"),fme=a("strong"),nCo=o("cvt"),sCo=o(" \u2014 "),TD=a("a"),lCo=o("CvtModel"),iCo=o(" (CvT model)"),dCo=l(),A_=a("li"),mme=a("strong"),cCo=o("data2vec-audio"),fCo=o(" \u2014 "),MD=a("a"),mCo=o("Data2VecAudioModel"),gCo=o(" (Data2VecAudio model)"),hCo=l(),L_=a("li"),gme=a("strong"),pCo=o("data2vec-text"),_Co=o(" \u2014 "),ED=a("a"),uCo=o("Data2VecTextModel"),bCo=o(" (Data2VecText model)"),vCo=l(),y_=a("li"),hme=a("strong"),FCo=o("data2vec-vision"),TCo=o(" \u2014 "),CD=a("a"),MCo=o("Data2VecVisionModel"),ECo=o(" (Data2VecVision model)"),CCo=l(),x_=a("li"),pme=a("strong"),wCo=o("deberta"),ACo=o(" \u2014 "),wD=a("a"),LCo=o("DebertaModel"),yCo=o(" (DeBERTa model)"),xCo=l(),$_=a("li"),_me=a("strong"),$Co=o("deberta-v2"),kCo=o(" \u2014 "),AD=a("a"),SCo=o("DebertaV2Model"),RCo=o(" (DeBERTa-v2 model)"),PCo=l(),k_=a("li"),ume=a("strong"),BCo=o("decision_transformer"),ICo=o(" \u2014 "),LD=a("a"),NCo=o("DecisionTransformerModel"),qCo=o(" (Decision Transformer model)"),jCo=l(),S_=a("li"),bme=a("strong"),DCo=o("deit"),GCo=o(" \u2014 "),yD=a("a"),OCo=o("DeiTModel"),VCo=o(" (DeiT model)"),XCo=l(),R_=a("li"),vme=a("strong"),zCo=o("detr"),WCo=o(" \u2014 "),xD=a("a"),QCo=o("DetrModel"),UCo=o(" (DETR model)"),HCo=l(),P_=a("li"),Fme=a("strong"),JCo=o("distilbert"),YCo=o(" \u2014 "),$D=a("a"),KCo=o("DistilBertModel"),ZCo=o(" (DistilBERT model)"),e3o=l(),B_=a("li"),Tme=a("strong"),o3o=o("dpr"),r3o=o(" \u2014 "),kD=a("a"),t3o=o("DPRQuestionEncoder"),a3o=o(" (DPR model)"),n3o=l(),I_=a("li"),Mme=a("strong"),s3o=o("dpt"),l3o=o(" \u2014 "),SD=a("a"),i3o=o("DPTModel"),d3o=o(" (DPT model)"),c3o=l(),N_=a("li"),Eme=a("strong"),f3o=o("electra"),m3o=o(" \u2014 "),RD=a("a"),g3o=o("ElectraModel"),h3o=o(" (ELECTRA model)"),p3o=l(),q_=a("li"),Cme=a("strong"),_3o=o("flaubert"),u3o=o(" \u2014 "),PD=a("a"),b3o=o("FlaubertModel"),v3o=o(" (FlauBERT model)"),F3o=l(),j_=a("li"),wme=a("strong"),T3o=o("flava"),M3o=o(" \u2014 "),BD=a("a"),E3o=o("FlavaModel"),C3o=o(" (FLAVA model)"),w3o=l(),D_=a("li"),Ame=a("strong"),A3o=o("fnet"),L3o=o(" \u2014 "),ID=a("a"),y3o=o("FNetModel"),x3o=o(" (FNet model)"),$3o=l(),G_=a("li"),Lme=a("strong"),k3o=o("fsmt"),S3o=o(" \u2014 "),ND=a("a"),R3o=o("FSMTModel"),P3o=o(" (FairSeq Machine-Translation model)"),B3o=l(),ol=a("li"),yme=a("strong"),I3o=o("funnel"),N3o=o(" \u2014 "),qD=a("a"),q3o=o("FunnelModel"),j3o=o(" or "),jD=a("a"),D3o=o("FunnelBaseModel"),G3o=o(" (Funnel Transformer model)"),O3o=l(),O_=a("li"),xme=a("strong"),V3o=o("glpn"),X3o=o(" \u2014 "),DD=a("a"),z3o=o("GLPNModel"),W3o=o(" (GLPN model)"),Q3o=l(),V_=a("li"),$me=a("strong"),U3o=o("gpt2"),H3o=o(" \u2014 "),GD=a("a"),J3o=o("GPT2Model"),Y3o=o(" (OpenAI GPT-2 model)"),K3o=l(),X_=a("li"),kme=a("strong"),Z3o=o("gpt_neo"),e0o=o(" \u2014 "),OD=a("a"),o0o=o("GPTNeoModel"),r0o=o(" (GPT Neo model)"),t0o=l(),z_=a("li"),Sme=a("strong"),a0o=o("gpt_neox"),n0o=o(" \u2014 "),VD=a("a"),s0o=o("GPTNeoXModel"),l0o=o(" (GPT NeoX model)"),i0o=l(),W_=a("li"),Rme=a("strong"),d0o=o("gptj"),c0o=o(" \u2014 "),XD=a("a"),f0o=o("GPTJModel"),m0o=o(" (GPT-J model)"),g0o=l(),Q_=a("li"),Pme=a("strong"),h0o=o("groupvit"),p0o=o(" \u2014 "),zD=a("a"),_0o=o("GroupViTModel"),u0o=o(" (GroupViT model)"),b0o=l(),U_=a("li"),Bme=a("strong"),v0o=o("hubert"),F0o=o(" \u2014 "),WD=a("a"),T0o=o("HubertModel"),M0o=o(" (Hubert model)"),E0o=l(),H_=a("li"),Ime=a("strong"),C0o=o("ibert"),w0o=o(" \u2014 "),QD=a("a"),A0o=o("IBertModel"),L0o=o(" (I-BERT model)"),y0o=l(),J_=a("li"),Nme=a("strong"),x0o=o("imagegpt"),$0o=o(" \u2014 "),UD=a("a"),k0o=o("ImageGPTModel"),S0o=o(" (ImageGPT model)"),R0o=l(),Y_=a("li"),qme=a("strong"),P0o=o("layoutlm"),B0o=o(" \u2014 "),HD=a("a"),I0o=o("LayoutLMModel"),N0o=o(" (LayoutLM model)"),q0o=l(),K_=a("li"),jme=a("strong"),j0o=o("layoutlmv2"),D0o=o(" \u2014 "),JD=a("a"),G0o=o("LayoutLMv2Model"),O0o=o(" (LayoutLMv2 model)"),V0o=l(),Z_=a("li"),Dme=a("strong"),X0o=o("layoutlmv3"),z0o=o(" \u2014 "),YD=a("a"),W0o=o("LayoutLMv3Model"),Q0o=o(" (LayoutLMv3 model)"),U0o=l(),eu=a("li"),Gme=a("strong"),H0o=o("led"),J0o=o(" \u2014 "),KD=a("a"),Y0o=o("LEDModel"),K0o=o(" (LED model)"),Z0o=l(),ou=a("li"),Ome=a("strong"),ewo=o("levit"),owo=o(" \u2014 "),ZD=a("a"),rwo=o("LevitModel"),two=o(" (LeViT model)"),awo=l(),ru=a("li"),Vme=a("strong"),nwo=o("longformer"),swo=o(" \u2014 "),eG=a("a"),lwo=o("LongformerModel"),iwo=o(" (Longformer model)"),dwo=l(),tu=a("li"),Xme=a("strong"),cwo=o("longt5"),fwo=o(" \u2014 "),oG=a("a"),mwo=o("LongT5Model"),gwo=o(" (LongT5 model)"),hwo=l(),au=a("li"),zme=a("strong"),pwo=o("luke"),_wo=o(" \u2014 "),rG=a("a"),uwo=o("LukeModel"),bwo=o(" (LUKE model)"),vwo=l(),nu=a("li"),Wme=a("strong"),Fwo=o("lxmert"),Two=o(" \u2014 "),tG=a("a"),Mwo=o("LxmertModel"),Ewo=o(" (LXMERT model)"),Cwo=l(),su=a("li"),Qme=a("strong"),wwo=o("m2m_100"),Awo=o(" \u2014 "),aG=a("a"),Lwo=o("M2M100Model"),ywo=o(" (M2M100 model)"),xwo=l(),lu=a("li"),Ume=a("strong"),$wo=o("marian"),kwo=o(" \u2014 "),nG=a("a"),Swo=o("MarianModel"),Rwo=o(" (Marian model)"),Pwo=l(),iu=a("li"),Hme=a("strong"),Bwo=o("maskformer"),Iwo=o(" \u2014 "),sG=a("a"),Nwo=o("MaskFormerModel"),qwo=o(" (MaskFormer model)"),jwo=l(),du=a("li"),Jme=a("strong"),Dwo=o("mbart"),Gwo=o(" \u2014 "),lG=a("a"),Owo=o("MBartModel"),Vwo=o(" (mBART model)"),Xwo=l(),cu=a("li"),Yme=a("strong"),zwo=o("mctct"),Wwo=o(" \u2014 "),iG=a("a"),Qwo=o("MCTCTModel"),Uwo=o(" (M-CTC-T model)"),Hwo=l(),fu=a("li"),Kme=a("strong"),Jwo=o("megatron-bert"),Ywo=o(" \u2014 "),dG=a("a"),Kwo=o("MegatronBertModel"),Zwo=o(" (Megatron-BERT model)"),e6o=l(),mu=a("li"),Zme=a("strong"),o6o=o("mobilebert"),r6o=o(" \u2014 "),cG=a("a"),t6o=o("MobileBertModel"),a6o=o(" (MobileBERT model)"),n6o=l(),gu=a("li"),ege=a("strong"),s6o=o("mobilevit"),l6o=o(" \u2014 "),fG=a("a"),i6o=o("MobileViTModel"),d6o=o(" (MobileViT model)"),c6o=l(),hu=a("li"),oge=a("strong"),f6o=o("mpnet"),m6o=o(" \u2014 "),mG=a("a"),g6o=o("MPNetModel"),h6o=o(" (MPNet model)"),p6o=l(),pu=a("li"),rge=a("strong"),_6o=o("mt5"),u6o=o(" \u2014 "),gG=a("a"),b6o=o("MT5Model"),v6o=o(" (MT5 model)"),F6o=l(),_u=a("li"),tge=a("strong"),T6o=o("mvp"),M6o=o(" \u2014 "),hG=a("a"),E6o=o("MvpModel"),C6o=o(" (MVP model)"),w6o=l(),uu=a("li"),age=a("strong"),A6o=o("nezha"),L6o=o(" \u2014 "),pG=a("a"),y6o=o("NezhaModel"),x6o=o(" (Nezha model)"),$6o=l(),bu=a("li"),nge=a("strong"),k6o=o("nllb"),S6o=o(" \u2014 "),_G=a("a"),R6o=o("M2M100Model"),P6o=o(" (NLLB model)"),B6o=l(),vu=a("li"),sge=a("strong"),I6o=o("nystromformer"),N6o=o(" \u2014 "),uG=a("a"),q6o=o("NystromformerModel"),j6o=o(" (Nystr\xF6mformer model)"),D6o=l(),Fu=a("li"),lge=a("strong"),G6o=o("openai-gpt"),O6o=o(" \u2014 "),bG=a("a"),V6o=o("OpenAIGPTModel"),X6o=o(" (OpenAI GPT model)"),z6o=l(),Tu=a("li"),ige=a("strong"),W6o=o("opt"),Q6o=o(" \u2014 "),vG=a("a"),U6o=o("OPTModel"),H6o=o(" (OPT model)"),J6o=l(),Mu=a("li"),dge=a("strong"),Y6o=o("owlvit"),K6o=o(" \u2014 "),FG=a("a"),Z6o=o("OwlViTModel"),eAo=o(" (OWL-ViT model)"),oAo=l(),Eu=a("li"),cge=a("strong"),rAo=o("pegasus"),tAo=o(" \u2014 "),TG=a("a"),aAo=o("PegasusModel"),nAo=o(" (Pegasus model)"),sAo=l(),Cu=a("li"),fge=a("strong"),lAo=o("perceiver"),iAo=o(" \u2014 "),MG=a("a"),dAo=o("PerceiverModel"),cAo=o(" (Perceiver model)"),fAo=l(),wu=a("li"),mge=a("strong"),mAo=o("plbart"),gAo=o(" \u2014 "),EG=a("a"),hAo=o("PLBartModel"),pAo=o(" (PLBart model)"),_Ao=l(),Au=a("li"),gge=a("strong"),uAo=o("poolformer"),bAo=o(" \u2014 "),CG=a("a"),vAo=o("PoolFormerModel"),FAo=o(" (PoolFormer model)"),TAo=l(),Lu=a("li"),hge=a("strong"),MAo=o("prophetnet"),EAo=o(" \u2014 "),wG=a("a"),CAo=o("ProphetNetModel"),wAo=o(" (ProphetNet model)"),AAo=l(),yu=a("li"),pge=a("strong"),LAo=o("qdqbert"),yAo=o(" \u2014 "),AG=a("a"),xAo=o("QDQBertModel"),$Ao=o(" (QDQBert model)"),kAo=l(),xu=a("li"),_ge=a("strong"),SAo=o("reformer"),RAo=o(" \u2014 "),LG=a("a"),PAo=o("ReformerModel"),BAo=o(" (Reformer model)"),IAo=l(),$u=a("li"),uge=a("strong"),NAo=o("regnet"),qAo=o(" \u2014 "),yG=a("a"),jAo=o("RegNetModel"),DAo=o(" (RegNet model)"),GAo=l(),ku=a("li"),bge=a("strong"),OAo=o("rembert"),VAo=o(" \u2014 "),xG=a("a"),XAo=o("RemBertModel"),zAo=o(" (RemBERT model)"),WAo=l(),Su=a("li"),vge=a("strong"),QAo=o("resnet"),UAo=o(" \u2014 "),$G=a("a"),HAo=o("ResNetModel"),JAo=o(" (ResNet model)"),YAo=l(),Ru=a("li"),Fge=a("strong"),KAo=o("retribert"),ZAo=o(" \u2014 "),kG=a("a"),e7o=o("RetriBertModel"),o7o=o(" (RetriBERT model)"),r7o=l(),Pu=a("li"),Tge=a("strong"),t7o=o("roberta"),a7o=o(" \u2014 "),SG=a("a"),n7o=o("RobertaModel"),s7o=o(" (RoBERTa model)"),l7o=l(),Bu=a("li"),Mge=a("strong"),i7o=o("roformer"),d7o=o(" \u2014 "),RG=a("a"),c7o=o("RoFormerModel"),f7o=o(" (RoFormer model)"),m7o=l(),Iu=a("li"),Ege=a("strong"),g7o=o("segformer"),h7o=o(" \u2014 "),PG=a("a"),p7o=o("SegformerModel"),_7o=o(" (SegFormer model)"),u7o=l(),Nu=a("li"),Cge=a("strong"),b7o=o("sew"),v7o=o(" \u2014 "),BG=a("a"),F7o=o("SEWModel"),T7o=o(" (SEW model)"),M7o=l(),qu=a("li"),wge=a("strong"),E7o=o("sew-d"),C7o=o(" \u2014 "),IG=a("a"),w7o=o("SEWDModel"),A7o=o(" (SEW-D model)"),L7o=l(),ju=a("li"),Age=a("strong"),y7o=o("speech_to_text"),x7o=o(" \u2014 "),NG=a("a"),$7o=o("Speech2TextModel"),k7o=o(" (Speech2Text model)"),S7o=l(),Du=a("li"),Lge=a("strong"),R7o=o("splinter"),P7o=o(" \u2014 "),qG=a("a"),B7o=o("SplinterModel"),I7o=o(" (Splinter model)"),N7o=l(),Gu=a("li"),yge=a("strong"),q7o=o("squeezebert"),j7o=o(" \u2014 "),jG=a("a"),D7o=o("SqueezeBertModel"),G7o=o(" (SqueezeBERT model)"),O7o=l(),Ou=a("li"),xge=a("strong"),V7o=o("swin"),X7o=o(" \u2014 "),DG=a("a"),z7o=o("SwinModel"),W7o=o(" (Swin Transformer model)"),Q7o=l(),Vu=a("li"),$ge=a("strong"),U7o=o("swinv2"),H7o=o(" \u2014 "),GG=a("a"),J7o=o("Swinv2Model"),Y7o=o(" (Swin Transformer V2 model)"),K7o=l(),Xu=a("li"),kge=a("strong"),Z7o=o("t5"),eLo=o(" \u2014 "),OG=a("a"),oLo=o("T5Model"),rLo=o(" (T5 model)"),tLo=l(),zu=a("li"),Sge=a("strong"),aLo=o("tapas"),nLo=o(" \u2014 "),VG=a("a"),sLo=o("TapasModel"),lLo=o(" (TAPAS model)"),iLo=l(),Wu=a("li"),Rge=a("strong"),dLo=o("trajectory_transformer"),cLo=o(" \u2014 "),XG=a("a"),fLo=o("TrajectoryTransformerModel"),mLo=o(" (Trajectory Transformer model)"),gLo=l(),Qu=a("li"),Pge=a("strong"),hLo=o("transfo-xl"),pLo=o(" \u2014 "),zG=a("a"),_Lo=o("TransfoXLModel"),uLo=o(" (Transformer-XL model)"),bLo=l(),Uu=a("li"),Bge=a("strong"),vLo=o("unispeech"),FLo=o(" \u2014 "),WG=a("a"),TLo=o("UniSpeechModel"),MLo=o(" (UniSpeech model)"),ELo=l(),Hu=a("li"),Ige=a("strong"),CLo=o("unispeech-sat"),wLo=o(" \u2014 "),QG=a("a"),ALo=o("UniSpeechSatModel"),LLo=o(" (UniSpeechSat model)"),yLo=l(),Ju=a("li"),Nge=a("strong"),xLo=o("van"),$Lo=o(" \u2014 "),UG=a("a"),kLo=o("VanModel"),SLo=o(" (VAN model)"),RLo=l(),Yu=a("li"),qge=a("strong"),PLo=o("videomae"),BLo=o(" \u2014 "),HG=a("a"),ILo=o("VideoMAEModel"),NLo=o(" (VideoMAE model)"),qLo=l(),Ku=a("li"),jge=a("strong"),jLo=o("vilt"),DLo=o(" \u2014 "),JG=a("a"),GLo=o("ViltModel"),OLo=o(" (ViLT model)"),VLo=l(),Zu=a("li"),Dge=a("strong"),XLo=o("vision-text-dual-encoder"),zLo=o(" \u2014 "),YG=a("a"),WLo=o("VisionTextDualEncoderModel"),QLo=o(" (VisionTextDualEncoder model)"),ULo=l(),e2=a("li"),Gge=a("strong"),HLo=o("visual_bert"),JLo=o(" \u2014 "),KG=a("a"),YLo=o("VisualBertModel"),KLo=o(" (VisualBERT model)"),ZLo=l(),o2=a("li"),Oge=a("strong"),eyo=o("vit"),oyo=o(" \u2014 "),ZG=a("a"),ryo=o("ViTModel"),tyo=o(" (ViT model)"),ayo=l(),r2=a("li"),Vge=a("strong"),nyo=o("vit_mae"),syo=o(" \u2014 "),eO=a("a"),lyo=o("ViTMAEModel"),iyo=o(" (ViTMAE model)"),dyo=l(),t2=a("li"),Xge=a("strong"),cyo=o("wav2vec2"),fyo=o(" \u2014 "),oO=a("a"),myo=o("Wav2Vec2Model"),gyo=o(" (Wav2Vec2 model)"),hyo=l(),a2=a("li"),zge=a("strong"),pyo=o("wav2vec2-conformer"),_yo=o(" \u2014 "),rO=a("a"),uyo=o("Wav2Vec2ConformerModel"),byo=o(" (Wav2Vec2-Conformer model)"),vyo=l(),n2=a("li"),Wge=a("strong"),Fyo=o("wavlm"),Tyo=o(" \u2014 "),tO=a("a"),Myo=o("WavLMModel"),Eyo=o(" (WavLM model)"),Cyo=l(),s2=a("li"),Qge=a("strong"),wyo=o("xglm"),Ayo=o(" \u2014 "),aO=a("a"),Lyo=o("XGLMModel"),yyo=o(" (XGLM model)"),xyo=l(),l2=a("li"),Uge=a("strong"),$yo=o("xlm"),kyo=o(" \u2014 "),nO=a("a"),Syo=o("XLMModel"),Ryo=o(" (XLM model)"),Pyo=l(),i2=a("li"),Hge=a("strong"),Byo=o("xlm-prophetnet"),Iyo=o(" \u2014 "),sO=a("a"),Nyo=o("XLMProphetNetModel"),qyo=o(" (XLM-ProphetNet model)"),jyo=l(),d2=a("li"),Jge=a("strong"),Dyo=o("xlm-roberta"),Gyo=o(" \u2014 "),lO=a("a"),Oyo=o("XLMRobertaModel"),Vyo=o(" (XLM-RoBERTa model)"),Xyo=l(),c2=a("li"),Yge=a("strong"),zyo=o("xlm-roberta-xl"),Wyo=o(" \u2014 "),iO=a("a"),Qyo=o("XLMRobertaXLModel"),Uyo=o(" (XLM-RoBERTa-XL model)"),Hyo=l(),f2=a("li"),Kge=a("strong"),Jyo=o("xlnet"),Yyo=o(" \u2014 "),dO=a("a"),Kyo=o("XLNetModel"),Zyo=o(" (XLNet model)"),e9o=l(),m2=a("li"),Zge=a("strong"),o9o=o("yolos"),r9o=o(" \u2014 "),cO=a("a"),t9o=o("YolosModel"),a9o=o(" (YOLOS model)"),n9o=l(),g2=a("li"),ehe=a("strong"),s9o=o("yoso"),l9o=o(" \u2014 "),fO=a("a"),i9o=o("YosoModel"),d9o=o(" (YOSO model)"),c9o=l(),h2=a("p"),f9o=o("The model is set in evaluation mode by default using "),ohe=a("code"),m9o=o("model.eval()"),g9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rhe=a("code"),h9o=o("model.train()"),p9o=l(),F(p2.$$.fragment),eQe=l(),Zi=a("h2"),_2=a("a"),the=a("span"),F(Cy.$$.fragment),_9o=l(),ahe=a("span"),u9o=o("AutoModelForPreTraining"),oQe=l(),Ro=a("div"),F(wy.$$.fragment),b9o=l(),ed=a("p"),v9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mO=a("a"),F9o=o("from_pretrained()"),T9o=o(" class method or the "),gO=a("a"),M9o=o("from_config()"),E9o=o(` class
method.`),C9o=l(),Ay=a("p"),w9o=o("This class cannot be instantiated directly using "),nhe=a("code"),A9o=o("__init__()"),L9o=o(" (throws an error)."),y9o=l(),ft=a("div"),F(Ly.$$.fragment),x9o=l(),she=a("p"),$9o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),k9o=l(),od=a("p"),S9o=o(`Note:
Loading a model from its configuration file does `),lhe=a("strong"),R9o=o("not"),P9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=a("a"),B9o=o("from_pretrained()"),I9o=o(" to load the model weights."),N9o=l(),F(u2.$$.fragment),q9o=l(),Ke=a("div"),F(yy.$$.fragment),j9o=l(),ihe=a("p"),D9o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),G9o=l(),Ga=a("p"),O9o=o("The model class to instantiate is selected based on the "),dhe=a("code"),V9o=o("model_type"),X9o=o(` property of the config object (either
passed as an argument or loaded from `),che=a("code"),z9o=o("pretrained_model_name_or_path"),W9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fhe=a("code"),Q9o=o("pretrained_model_name_or_path"),U9o=o(":"),H9o=l(),G=a("ul"),b2=a("li"),mhe=a("strong"),J9o=o("albert"),Y9o=o(" \u2014 "),pO=a("a"),K9o=o("AlbertForPreTraining"),Z9o=o(" (ALBERT model)"),exo=l(),v2=a("li"),ghe=a("strong"),oxo=o("bart"),rxo=o(" \u2014 "),_O=a("a"),txo=o("BartForConditionalGeneration"),axo=o(" (BART model)"),nxo=l(),F2=a("li"),hhe=a("strong"),sxo=o("bert"),lxo=o(" \u2014 "),uO=a("a"),ixo=o("BertForPreTraining"),dxo=o(" (BERT model)"),cxo=l(),T2=a("li"),phe=a("strong"),fxo=o("big_bird"),mxo=o(" \u2014 "),bO=a("a"),gxo=o("BigBirdForPreTraining"),hxo=o(" (BigBird model)"),pxo=l(),M2=a("li"),_he=a("strong"),_xo=o("bloom"),uxo=o(" \u2014 "),vO=a("a"),bxo=o("BloomForCausalLM"),vxo=o(" (BLOOM model)"),Fxo=l(),E2=a("li"),uhe=a("strong"),Txo=o("camembert"),Mxo=o(" \u2014 "),FO=a("a"),Exo=o("CamembertForMaskedLM"),Cxo=o(" (CamemBERT model)"),wxo=l(),C2=a("li"),bhe=a("strong"),Axo=o("ctrl"),Lxo=o(" \u2014 "),TO=a("a"),yxo=o("CTRLLMHeadModel"),xxo=o(" (CTRL model)"),$xo=l(),w2=a("li"),vhe=a("strong"),kxo=o("data2vec-text"),Sxo=o(" \u2014 "),MO=a("a"),Rxo=o("Data2VecTextForMaskedLM"),Pxo=o(" (Data2VecText model)"),Bxo=l(),A2=a("li"),Fhe=a("strong"),Ixo=o("deberta"),Nxo=o(" \u2014 "),EO=a("a"),qxo=o("DebertaForMaskedLM"),jxo=o(" (DeBERTa model)"),Dxo=l(),L2=a("li"),The=a("strong"),Gxo=o("deberta-v2"),Oxo=o(" \u2014 "),CO=a("a"),Vxo=o("DebertaV2ForMaskedLM"),Xxo=o(" (DeBERTa-v2 model)"),zxo=l(),y2=a("li"),Mhe=a("strong"),Wxo=o("distilbert"),Qxo=o(" \u2014 "),wO=a("a"),Uxo=o("DistilBertForMaskedLM"),Hxo=o(" (DistilBERT model)"),Jxo=l(),x2=a("li"),Ehe=a("strong"),Yxo=o("electra"),Kxo=o(" \u2014 "),AO=a("a"),Zxo=o("ElectraForPreTraining"),e$o=o(" (ELECTRA model)"),o$o=l(),$2=a("li"),Che=a("strong"),r$o=o("flaubert"),t$o=o(" \u2014 "),LO=a("a"),a$o=o("FlaubertWithLMHeadModel"),n$o=o(" (FlauBERT model)"),s$o=l(),k2=a("li"),whe=a("strong"),l$o=o("flava"),i$o=o(" \u2014 "),yO=a("a"),d$o=o("FlavaForPreTraining"),c$o=o(" (FLAVA model)"),f$o=l(),S2=a("li"),Ahe=a("strong"),m$o=o("fnet"),g$o=o(" \u2014 "),xO=a("a"),h$o=o("FNetForPreTraining"),p$o=o(" (FNet model)"),_$o=l(),R2=a("li"),Lhe=a("strong"),u$o=o("fsmt"),b$o=o(" \u2014 "),$O=a("a"),v$o=o("FSMTForConditionalGeneration"),F$o=o(" (FairSeq Machine-Translation model)"),T$o=l(),P2=a("li"),yhe=a("strong"),M$o=o("funnel"),E$o=o(" \u2014 "),kO=a("a"),C$o=o("FunnelForPreTraining"),w$o=o(" (Funnel Transformer model)"),A$o=l(),B2=a("li"),xhe=a("strong"),L$o=o("gpt2"),y$o=o(" \u2014 "),SO=a("a"),x$o=o("GPT2LMHeadModel"),$$o=o(" (OpenAI GPT-2 model)"),k$o=l(),I2=a("li"),$he=a("strong"),S$o=o("ibert"),R$o=o(" \u2014 "),RO=a("a"),P$o=o("IBertForMaskedLM"),B$o=o(" (I-BERT model)"),I$o=l(),N2=a("li"),khe=a("strong"),N$o=o("layoutlm"),q$o=o(" \u2014 "),PO=a("a"),j$o=o("LayoutLMForMaskedLM"),D$o=o(" (LayoutLM model)"),G$o=l(),q2=a("li"),She=a("strong"),O$o=o("longformer"),V$o=o(" \u2014 "),BO=a("a"),X$o=o("LongformerForMaskedLM"),z$o=o(" (Longformer model)"),W$o=l(),j2=a("li"),Rhe=a("strong"),Q$o=o("luke"),U$o=o(" \u2014 "),IO=a("a"),H$o=o("LukeForMaskedLM"),J$o=o(" (LUKE model)"),Y$o=l(),D2=a("li"),Phe=a("strong"),K$o=o("lxmert"),Z$o=o(" \u2014 "),NO=a("a"),eko=o("LxmertForPreTraining"),oko=o(" (LXMERT model)"),rko=l(),G2=a("li"),Bhe=a("strong"),tko=o("megatron-bert"),ako=o(" \u2014 "),qO=a("a"),nko=o("MegatronBertForPreTraining"),sko=o(" (Megatron-BERT model)"),lko=l(),O2=a("li"),Ihe=a("strong"),iko=o("mobilebert"),dko=o(" \u2014 "),jO=a("a"),cko=o("MobileBertForPreTraining"),fko=o(" (MobileBERT model)"),mko=l(),V2=a("li"),Nhe=a("strong"),gko=o("mpnet"),hko=o(" \u2014 "),DO=a("a"),pko=o("MPNetForMaskedLM"),_ko=o(" (MPNet model)"),uko=l(),X2=a("li"),qhe=a("strong"),bko=o("mvp"),vko=o(" \u2014 "),GO=a("a"),Fko=o("MvpForConditionalGeneration"),Tko=o(" (MVP model)"),Mko=l(),z2=a("li"),jhe=a("strong"),Eko=o("nezha"),Cko=o(" \u2014 "),OO=a("a"),wko=o("NezhaForPreTraining"),Ako=o(" (Nezha model)"),Lko=l(),W2=a("li"),Dhe=a("strong"),yko=o("openai-gpt"),xko=o(" \u2014 "),VO=a("a"),$ko=o("OpenAIGPTLMHeadModel"),kko=o(" (OpenAI GPT model)"),Sko=l(),Q2=a("li"),Ghe=a("strong"),Rko=o("retribert"),Pko=o(" \u2014 "),XO=a("a"),Bko=o("RetriBertModel"),Iko=o(" (RetriBERT model)"),Nko=l(),U2=a("li"),Ohe=a("strong"),qko=o("roberta"),jko=o(" \u2014 "),zO=a("a"),Dko=o("RobertaForMaskedLM"),Gko=o(" (RoBERTa model)"),Oko=l(),H2=a("li"),Vhe=a("strong"),Vko=o("splinter"),Xko=o(" \u2014 "),WO=a("a"),zko=o("SplinterForPreTraining"),Wko=o(" (Splinter model)"),Qko=l(),J2=a("li"),Xhe=a("strong"),Uko=o("squeezebert"),Hko=o(" \u2014 "),QO=a("a"),Jko=o("SqueezeBertForMaskedLM"),Yko=o(" (SqueezeBERT model)"),Kko=l(),Y2=a("li"),zhe=a("strong"),Zko=o("t5"),eSo=o(" \u2014 "),UO=a("a"),oSo=o("T5ForConditionalGeneration"),rSo=o(" (T5 model)"),tSo=l(),K2=a("li"),Whe=a("strong"),aSo=o("tapas"),nSo=o(" \u2014 "),HO=a("a"),sSo=o("TapasForMaskedLM"),lSo=o(" (TAPAS model)"),iSo=l(),Z2=a("li"),Qhe=a("strong"),dSo=o("transfo-xl"),cSo=o(" \u2014 "),JO=a("a"),fSo=o("TransfoXLLMHeadModel"),mSo=o(" (Transformer-XL model)"),gSo=l(),e1=a("li"),Uhe=a("strong"),hSo=o("unispeech"),pSo=o(" \u2014 "),YO=a("a"),_So=o("UniSpeechForPreTraining"),uSo=o(" (UniSpeech model)"),bSo=l(),o1=a("li"),Hhe=a("strong"),vSo=o("unispeech-sat"),FSo=o(" \u2014 "),KO=a("a"),TSo=o("UniSpeechSatForPreTraining"),MSo=o(" (UniSpeechSat model)"),ESo=l(),r1=a("li"),Jhe=a("strong"),CSo=o("videomae"),wSo=o(" \u2014 "),ZO=a("a"),ASo=o("VideoMAEForPreTraining"),LSo=o(" (VideoMAE model)"),ySo=l(),t1=a("li"),Yhe=a("strong"),xSo=o("visual_bert"),$So=o(" \u2014 "),eV=a("a"),kSo=o("VisualBertForPreTraining"),SSo=o(" (VisualBERT model)"),RSo=l(),a1=a("li"),Khe=a("strong"),PSo=o("vit_mae"),BSo=o(" \u2014 "),oV=a("a"),ISo=o("ViTMAEForPreTraining"),NSo=o(" (ViTMAE model)"),qSo=l(),n1=a("li"),Zhe=a("strong"),jSo=o("wav2vec2"),DSo=o(" \u2014 "),rV=a("a"),GSo=o("Wav2Vec2ForPreTraining"),OSo=o(" (Wav2Vec2 model)"),VSo=l(),s1=a("li"),epe=a("strong"),XSo=o("wav2vec2-conformer"),zSo=o(" \u2014 "),tV=a("a"),WSo=o("Wav2Vec2ConformerForPreTraining"),QSo=o(" (Wav2Vec2-Conformer model)"),USo=l(),l1=a("li"),ope=a("strong"),HSo=o("xlm"),JSo=o(" \u2014 "),aV=a("a"),YSo=o("XLMWithLMHeadModel"),KSo=o(" (XLM model)"),ZSo=l(),i1=a("li"),rpe=a("strong"),eRo=o("xlm-roberta"),oRo=o(" \u2014 "),nV=a("a"),rRo=o("XLMRobertaForMaskedLM"),tRo=o(" (XLM-RoBERTa model)"),aRo=l(),d1=a("li"),tpe=a("strong"),nRo=o("xlm-roberta-xl"),sRo=o(" \u2014 "),sV=a("a"),lRo=o("XLMRobertaXLForMaskedLM"),iRo=o(" (XLM-RoBERTa-XL model)"),dRo=l(),c1=a("li"),ape=a("strong"),cRo=o("xlnet"),fRo=o(" \u2014 "),lV=a("a"),mRo=o("XLNetLMHeadModel"),gRo=o(" (XLNet model)"),hRo=l(),f1=a("p"),pRo=o("The model is set in evaluation mode by default using "),npe=a("code"),_Ro=o("model.eval()"),uRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),spe=a("code"),bRo=o("model.train()"),vRo=l(),F(m1.$$.fragment),rQe=l(),rd=a("h2"),g1=a("a"),lpe=a("span"),F(xy.$$.fragment),FRo=l(),ipe=a("span"),TRo=o("AutoModelForCausalLM"),tQe=l(),Po=a("div"),F($y.$$.fragment),MRo=l(),td=a("p"),ERo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),iV=a("a"),CRo=o("from_pretrained()"),wRo=o(" class method or the "),dV=a("a"),ARo=o("from_config()"),LRo=o(` class
method.`),yRo=l(),ky=a("p"),xRo=o("This class cannot be instantiated directly using "),dpe=a("code"),$Ro=o("__init__()"),kRo=o(" (throws an error)."),SRo=l(),mt=a("div"),F(Sy.$$.fragment),RRo=l(),cpe=a("p"),PRo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),BRo=l(),ad=a("p"),IRo=o(`Note:
Loading a model from its configuration file does `),fpe=a("strong"),NRo=o("not"),qRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cV=a("a"),jRo=o("from_pretrained()"),DRo=o(" to load the model weights."),GRo=l(),F(h1.$$.fragment),ORo=l(),Ze=a("div"),F(Ry.$$.fragment),VRo=l(),mpe=a("p"),XRo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),zRo=l(),Oa=a("p"),WRo=o("The model class to instantiate is selected based on the "),gpe=a("code"),QRo=o("model_type"),URo=o(` property of the config object (either
passed as an argument or loaded from `),hpe=a("code"),HRo=o("pretrained_model_name_or_path"),JRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ppe=a("code"),YRo=o("pretrained_model_name_or_path"),KRo=o(":"),ZRo=l(),z=a("ul"),p1=a("li"),_pe=a("strong"),ePo=o("bart"),oPo=o(" \u2014 "),fV=a("a"),rPo=o("BartForCausalLM"),tPo=o(" (BART model)"),aPo=l(),_1=a("li"),upe=a("strong"),nPo=o("bert"),sPo=o(" \u2014 "),mV=a("a"),lPo=o("BertLMHeadModel"),iPo=o(" (BERT model)"),dPo=l(),u1=a("li"),bpe=a("strong"),cPo=o("bert-generation"),fPo=o(" \u2014 "),gV=a("a"),mPo=o("BertGenerationDecoder"),gPo=o(" (Bert Generation model)"),hPo=l(),b1=a("li"),vpe=a("strong"),pPo=o("big_bird"),_Po=o(" \u2014 "),hV=a("a"),uPo=o("BigBirdForCausalLM"),bPo=o(" (BigBird model)"),vPo=l(),v1=a("li"),Fpe=a("strong"),FPo=o("bigbird_pegasus"),TPo=o(" \u2014 "),pV=a("a"),MPo=o("BigBirdPegasusForCausalLM"),EPo=o(" (BigBird-Pegasus model)"),CPo=l(),F1=a("li"),Tpe=a("strong"),wPo=o("blenderbot"),APo=o(" \u2014 "),_V=a("a"),LPo=o("BlenderbotForCausalLM"),yPo=o(" (Blenderbot model)"),xPo=l(),T1=a("li"),Mpe=a("strong"),$Po=o("blenderbot-small"),kPo=o(" \u2014 "),uV=a("a"),SPo=o("BlenderbotSmallForCausalLM"),RPo=o(" (BlenderbotSmall model)"),PPo=l(),M1=a("li"),Epe=a("strong"),BPo=o("bloom"),IPo=o(" \u2014 "),bV=a("a"),NPo=o("BloomForCausalLM"),qPo=o(" (BLOOM model)"),jPo=l(),E1=a("li"),Cpe=a("strong"),DPo=o("camembert"),GPo=o(" \u2014 "),vV=a("a"),OPo=o("CamembertForCausalLM"),VPo=o(" (CamemBERT model)"),XPo=l(),C1=a("li"),wpe=a("strong"),zPo=o("codegen"),WPo=o(" \u2014 "),FV=a("a"),QPo=o("CodeGenForCausalLM"),UPo=o(" (CodeGen model)"),HPo=l(),w1=a("li"),Ape=a("strong"),JPo=o("ctrl"),YPo=o(" \u2014 "),TV=a("a"),KPo=o("CTRLLMHeadModel"),ZPo=o(" (CTRL model)"),eBo=l(),A1=a("li"),Lpe=a("strong"),oBo=o("data2vec-text"),rBo=o(" \u2014 "),MV=a("a"),tBo=o("Data2VecTextForCausalLM"),aBo=o(" (Data2VecText model)"),nBo=l(),L1=a("li"),ype=a("strong"),sBo=o("electra"),lBo=o(" \u2014 "),EV=a("a"),iBo=o("ElectraForCausalLM"),dBo=o(" (ELECTRA model)"),cBo=l(),y1=a("li"),xpe=a("strong"),fBo=o("gpt2"),mBo=o(" \u2014 "),CV=a("a"),gBo=o("GPT2LMHeadModel"),hBo=o(" (OpenAI GPT-2 model)"),pBo=l(),x1=a("li"),$pe=a("strong"),_Bo=o("gpt_neo"),uBo=o(" \u2014 "),wV=a("a"),bBo=o("GPTNeoForCausalLM"),vBo=o(" (GPT Neo model)"),FBo=l(),$1=a("li"),kpe=a("strong"),TBo=o("gpt_neox"),MBo=o(" \u2014 "),AV=a("a"),EBo=o("GPTNeoXForCausalLM"),CBo=o(" (GPT NeoX model)"),wBo=l(),k1=a("li"),Spe=a("strong"),ABo=o("gptj"),LBo=o(" \u2014 "),LV=a("a"),yBo=o("GPTJForCausalLM"),xBo=o(" (GPT-J model)"),$Bo=l(),S1=a("li"),Rpe=a("strong"),kBo=o("marian"),SBo=o(" \u2014 "),yV=a("a"),RBo=o("MarianForCausalLM"),PBo=o(" (Marian model)"),BBo=l(),R1=a("li"),Ppe=a("strong"),IBo=o("mbart"),NBo=o(" \u2014 "),xV=a("a"),qBo=o("MBartForCausalLM"),jBo=o(" (mBART model)"),DBo=l(),P1=a("li"),Bpe=a("strong"),GBo=o("megatron-bert"),OBo=o(" \u2014 "),$V=a("a"),VBo=o("MegatronBertForCausalLM"),XBo=o(" (Megatron-BERT model)"),zBo=l(),B1=a("li"),Ipe=a("strong"),WBo=o("mvp"),QBo=o(" \u2014 "),kV=a("a"),UBo=o("MvpForCausalLM"),HBo=o(" (MVP model)"),JBo=l(),I1=a("li"),Npe=a("strong"),YBo=o("openai-gpt"),KBo=o(" \u2014 "),SV=a("a"),ZBo=o("OpenAIGPTLMHeadModel"),eIo=o(" (OpenAI GPT model)"),oIo=l(),N1=a("li"),qpe=a("strong"),rIo=o("opt"),tIo=o(" \u2014 "),RV=a("a"),aIo=o("OPTForCausalLM"),nIo=o(" (OPT model)"),sIo=l(),q1=a("li"),jpe=a("strong"),lIo=o("pegasus"),iIo=o(" \u2014 "),PV=a("a"),dIo=o("PegasusForCausalLM"),cIo=o(" (Pegasus model)"),fIo=l(),j1=a("li"),Dpe=a("strong"),mIo=o("plbart"),gIo=o(" \u2014 "),BV=a("a"),hIo=o("PLBartForCausalLM"),pIo=o(" (PLBart model)"),_Io=l(),D1=a("li"),Gpe=a("strong"),uIo=o("prophetnet"),bIo=o(" \u2014 "),IV=a("a"),vIo=o("ProphetNetForCausalLM"),FIo=o(" (ProphetNet model)"),TIo=l(),G1=a("li"),Ope=a("strong"),MIo=o("qdqbert"),EIo=o(" \u2014 "),NV=a("a"),CIo=o("QDQBertLMHeadModel"),wIo=o(" (QDQBert model)"),AIo=l(),O1=a("li"),Vpe=a("strong"),LIo=o("reformer"),yIo=o(" \u2014 "),qV=a("a"),xIo=o("ReformerModelWithLMHead"),$Io=o(" (Reformer model)"),kIo=l(),V1=a("li"),Xpe=a("strong"),SIo=o("rembert"),RIo=o(" \u2014 "),jV=a("a"),PIo=o("RemBertForCausalLM"),BIo=o(" (RemBERT model)"),IIo=l(),X1=a("li"),zpe=a("strong"),NIo=o("roberta"),qIo=o(" \u2014 "),DV=a("a"),jIo=o("RobertaForCausalLM"),DIo=o(" (RoBERTa model)"),GIo=l(),z1=a("li"),Wpe=a("strong"),OIo=o("roformer"),VIo=o(" \u2014 "),GV=a("a"),XIo=o("RoFormerForCausalLM"),zIo=o(" (RoFormer model)"),WIo=l(),W1=a("li"),Qpe=a("strong"),QIo=o("speech_to_text_2"),UIo=o(" \u2014 "),OV=a("a"),HIo=o("Speech2Text2ForCausalLM"),JIo=o(" (Speech2Text2 model)"),YIo=l(),Q1=a("li"),Upe=a("strong"),KIo=o("transfo-xl"),ZIo=o(" \u2014 "),VV=a("a"),eNo=o("TransfoXLLMHeadModel"),oNo=o(" (Transformer-XL model)"),rNo=l(),U1=a("li"),Hpe=a("strong"),tNo=o("trocr"),aNo=o(" \u2014 "),XV=a("a"),nNo=o("TrOCRForCausalLM"),sNo=o(" (TrOCR model)"),lNo=l(),H1=a("li"),Jpe=a("strong"),iNo=o("xglm"),dNo=o(" \u2014 "),zV=a("a"),cNo=o("XGLMForCausalLM"),fNo=o(" (XGLM model)"),mNo=l(),J1=a("li"),Ype=a("strong"),gNo=o("xlm"),hNo=o(" \u2014 "),WV=a("a"),pNo=o("XLMWithLMHeadModel"),_No=o(" (XLM model)"),uNo=l(),Y1=a("li"),Kpe=a("strong"),bNo=o("xlm-prophetnet"),vNo=o(" \u2014 "),QV=a("a"),FNo=o("XLMProphetNetForCausalLM"),TNo=o(" (XLM-ProphetNet model)"),MNo=l(),K1=a("li"),Zpe=a("strong"),ENo=o("xlm-roberta"),CNo=o(" \u2014 "),UV=a("a"),wNo=o("XLMRobertaForCausalLM"),ANo=o(" (XLM-RoBERTa model)"),LNo=l(),Z1=a("li"),e_e=a("strong"),yNo=o("xlm-roberta-xl"),xNo=o(" \u2014 "),HV=a("a"),$No=o("XLMRobertaXLForCausalLM"),kNo=o(" (XLM-RoBERTa-XL model)"),SNo=l(),e4=a("li"),o_e=a("strong"),RNo=o("xlnet"),PNo=o(" \u2014 "),JV=a("a"),BNo=o("XLNetLMHeadModel"),INo=o(" (XLNet model)"),NNo=l(),o4=a("p"),qNo=o("The model is set in evaluation mode by default using "),r_e=a("code"),jNo=o("model.eval()"),DNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t_e=a("code"),GNo=o("model.train()"),ONo=l(),F(r4.$$.fragment),aQe=l(),nd=a("h2"),t4=a("a"),a_e=a("span"),F(Py.$$.fragment),VNo=l(),n_e=a("span"),XNo=o("AutoModelForMaskedLM"),nQe=l(),Bo=a("div"),F(By.$$.fragment),zNo=l(),sd=a("p"),WNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),YV=a("a"),QNo=o("from_pretrained()"),UNo=o(" class method or the "),KV=a("a"),HNo=o("from_config()"),JNo=o(` class
method.`),YNo=l(),Iy=a("p"),KNo=o("This class cannot be instantiated directly using "),s_e=a("code"),ZNo=o("__init__()"),eqo=o(" (throws an error)."),oqo=l(),gt=a("div"),F(Ny.$$.fragment),rqo=l(),l_e=a("p"),tqo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),aqo=l(),ld=a("p"),nqo=o(`Note:
Loading a model from its configuration file does `),i_e=a("strong"),sqo=o("not"),lqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZV=a("a"),iqo=o("from_pretrained()"),dqo=o(" to load the model weights."),cqo=l(),F(a4.$$.fragment),fqo=l(),eo=a("div"),F(qy.$$.fragment),mqo=l(),d_e=a("p"),gqo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),hqo=l(),Va=a("p"),pqo=o("The model class to instantiate is selected based on the "),c_e=a("code"),_qo=o("model_type"),uqo=o(` property of the config object (either
passed as an argument or loaded from `),f_e=a("code"),bqo=o("pretrained_model_name_or_path"),vqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m_e=a("code"),Fqo=o("pretrained_model_name_or_path"),Tqo=o(":"),Mqo=l(),U=a("ul"),n4=a("li"),g_e=a("strong"),Eqo=o("albert"),Cqo=o(" \u2014 "),eX=a("a"),wqo=o("AlbertForMaskedLM"),Aqo=o(" (ALBERT model)"),Lqo=l(),s4=a("li"),h_e=a("strong"),yqo=o("bart"),xqo=o(" \u2014 "),oX=a("a"),$qo=o("BartForConditionalGeneration"),kqo=o(" (BART model)"),Sqo=l(),l4=a("li"),p_e=a("strong"),Rqo=o("bert"),Pqo=o(" \u2014 "),rX=a("a"),Bqo=o("BertForMaskedLM"),Iqo=o(" (BERT model)"),Nqo=l(),i4=a("li"),__e=a("strong"),qqo=o("big_bird"),jqo=o(" \u2014 "),tX=a("a"),Dqo=o("BigBirdForMaskedLM"),Gqo=o(" (BigBird model)"),Oqo=l(),d4=a("li"),u_e=a("strong"),Vqo=o("camembert"),Xqo=o(" \u2014 "),aX=a("a"),zqo=o("CamembertForMaskedLM"),Wqo=o(" (CamemBERT model)"),Qqo=l(),c4=a("li"),b_e=a("strong"),Uqo=o("convbert"),Hqo=o(" \u2014 "),nX=a("a"),Jqo=o("ConvBertForMaskedLM"),Yqo=o(" (ConvBERT model)"),Kqo=l(),f4=a("li"),v_e=a("strong"),Zqo=o("data2vec-text"),ejo=o(" \u2014 "),sX=a("a"),ojo=o("Data2VecTextForMaskedLM"),rjo=o(" (Data2VecText model)"),tjo=l(),m4=a("li"),F_e=a("strong"),ajo=o("deberta"),njo=o(" \u2014 "),lX=a("a"),sjo=o("DebertaForMaskedLM"),ljo=o(" (DeBERTa model)"),ijo=l(),g4=a("li"),T_e=a("strong"),djo=o("deberta-v2"),cjo=o(" \u2014 "),iX=a("a"),fjo=o("DebertaV2ForMaskedLM"),mjo=o(" (DeBERTa-v2 model)"),gjo=l(),h4=a("li"),M_e=a("strong"),hjo=o("distilbert"),pjo=o(" \u2014 "),dX=a("a"),_jo=o("DistilBertForMaskedLM"),ujo=o(" (DistilBERT model)"),bjo=l(),p4=a("li"),E_e=a("strong"),vjo=o("electra"),Fjo=o(" \u2014 "),cX=a("a"),Tjo=o("ElectraForMaskedLM"),Mjo=o(" (ELECTRA model)"),Ejo=l(),_4=a("li"),C_e=a("strong"),Cjo=o("flaubert"),wjo=o(" \u2014 "),fX=a("a"),Ajo=o("FlaubertWithLMHeadModel"),Ljo=o(" (FlauBERT model)"),yjo=l(),u4=a("li"),w_e=a("strong"),xjo=o("fnet"),$jo=o(" \u2014 "),mX=a("a"),kjo=o("FNetForMaskedLM"),Sjo=o(" (FNet model)"),Rjo=l(),b4=a("li"),A_e=a("strong"),Pjo=o("funnel"),Bjo=o(" \u2014 "),gX=a("a"),Ijo=o("FunnelForMaskedLM"),Njo=o(" (Funnel Transformer model)"),qjo=l(),v4=a("li"),L_e=a("strong"),jjo=o("ibert"),Djo=o(" \u2014 "),hX=a("a"),Gjo=o("IBertForMaskedLM"),Ojo=o(" (I-BERT model)"),Vjo=l(),F4=a("li"),y_e=a("strong"),Xjo=o("layoutlm"),zjo=o(" \u2014 "),pX=a("a"),Wjo=o("LayoutLMForMaskedLM"),Qjo=o(" (LayoutLM model)"),Ujo=l(),T4=a("li"),x_e=a("strong"),Hjo=o("longformer"),Jjo=o(" \u2014 "),_X=a("a"),Yjo=o("LongformerForMaskedLM"),Kjo=o(" (Longformer model)"),Zjo=l(),M4=a("li"),$_e=a("strong"),eDo=o("luke"),oDo=o(" \u2014 "),uX=a("a"),rDo=o("LukeForMaskedLM"),tDo=o(" (LUKE model)"),aDo=l(),E4=a("li"),k_e=a("strong"),nDo=o("mbart"),sDo=o(" \u2014 "),bX=a("a"),lDo=o("MBartForConditionalGeneration"),iDo=o(" (mBART model)"),dDo=l(),C4=a("li"),S_e=a("strong"),cDo=o("megatron-bert"),fDo=o(" \u2014 "),vX=a("a"),mDo=o("MegatronBertForMaskedLM"),gDo=o(" (Megatron-BERT model)"),hDo=l(),w4=a("li"),R_e=a("strong"),pDo=o("mobilebert"),_Do=o(" \u2014 "),FX=a("a"),uDo=o("MobileBertForMaskedLM"),bDo=o(" (MobileBERT model)"),vDo=l(),A4=a("li"),P_e=a("strong"),FDo=o("mpnet"),TDo=o(" \u2014 "),TX=a("a"),MDo=o("MPNetForMaskedLM"),EDo=o(" (MPNet model)"),CDo=l(),L4=a("li"),B_e=a("strong"),wDo=o("mvp"),ADo=o(" \u2014 "),MX=a("a"),LDo=o("MvpForConditionalGeneration"),yDo=o(" (MVP model)"),xDo=l(),y4=a("li"),I_e=a("strong"),$Do=o("nezha"),kDo=o(" \u2014 "),EX=a("a"),SDo=o("NezhaForMaskedLM"),RDo=o(" (Nezha model)"),PDo=l(),x4=a("li"),N_e=a("strong"),BDo=o("nystromformer"),IDo=o(" \u2014 "),CX=a("a"),NDo=o("NystromformerForMaskedLM"),qDo=o(" (Nystr\xF6mformer model)"),jDo=l(),$4=a("li"),q_e=a("strong"),DDo=o("perceiver"),GDo=o(" \u2014 "),wX=a("a"),ODo=o("PerceiverForMaskedLM"),VDo=o(" (Perceiver model)"),XDo=l(),k4=a("li"),j_e=a("strong"),zDo=o("qdqbert"),WDo=o(" \u2014 "),AX=a("a"),QDo=o("QDQBertForMaskedLM"),UDo=o(" (QDQBert model)"),HDo=l(),S4=a("li"),D_e=a("strong"),JDo=o("reformer"),YDo=o(" \u2014 "),LX=a("a"),KDo=o("ReformerForMaskedLM"),ZDo=o(" (Reformer model)"),eGo=l(),R4=a("li"),G_e=a("strong"),oGo=o("rembert"),rGo=o(" \u2014 "),yX=a("a"),tGo=o("RemBertForMaskedLM"),aGo=o(" (RemBERT model)"),nGo=l(),P4=a("li"),O_e=a("strong"),sGo=o("roberta"),lGo=o(" \u2014 "),xX=a("a"),iGo=o("RobertaForMaskedLM"),dGo=o(" (RoBERTa model)"),cGo=l(),B4=a("li"),V_e=a("strong"),fGo=o("roformer"),mGo=o(" \u2014 "),$X=a("a"),gGo=o("RoFormerForMaskedLM"),hGo=o(" (RoFormer model)"),pGo=l(),I4=a("li"),X_e=a("strong"),_Go=o("squeezebert"),uGo=o(" \u2014 "),kX=a("a"),bGo=o("SqueezeBertForMaskedLM"),vGo=o(" (SqueezeBERT model)"),FGo=l(),N4=a("li"),z_e=a("strong"),TGo=o("tapas"),MGo=o(" \u2014 "),SX=a("a"),EGo=o("TapasForMaskedLM"),CGo=o(" (TAPAS model)"),wGo=l(),q4=a("li"),W_e=a("strong"),AGo=o("wav2vec2"),LGo=o(" \u2014 "),Q_e=a("code"),yGo=o("Wav2Vec2ForMaskedLM"),xGo=o(" (Wav2Vec2 model)"),$Go=l(),j4=a("li"),U_e=a("strong"),kGo=o("xlm"),SGo=o(" \u2014 "),RX=a("a"),RGo=o("XLMWithLMHeadModel"),PGo=o(" (XLM model)"),BGo=l(),D4=a("li"),H_e=a("strong"),IGo=o("xlm-roberta"),NGo=o(" \u2014 "),PX=a("a"),qGo=o("XLMRobertaForMaskedLM"),jGo=o(" (XLM-RoBERTa model)"),DGo=l(),G4=a("li"),J_e=a("strong"),GGo=o("xlm-roberta-xl"),OGo=o(" \u2014 "),BX=a("a"),VGo=o("XLMRobertaXLForMaskedLM"),XGo=o(" (XLM-RoBERTa-XL model)"),zGo=l(),O4=a("li"),Y_e=a("strong"),WGo=o("yoso"),QGo=o(" \u2014 "),IX=a("a"),UGo=o("YosoForMaskedLM"),HGo=o(" (YOSO model)"),JGo=l(),V4=a("p"),YGo=o("The model is set in evaluation mode by default using "),K_e=a("code"),KGo=o("model.eval()"),ZGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z_e=a("code"),eOo=o("model.train()"),oOo=l(),F(X4.$$.fragment),sQe=l(),id=a("h2"),z4=a("a"),eue=a("span"),F(jy.$$.fragment),rOo=l(),oue=a("span"),tOo=o("AutoModelForSeq2SeqLM"),lQe=l(),Io=a("div"),F(Dy.$$.fragment),aOo=l(),dd=a("p"),nOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),NX=a("a"),sOo=o("from_pretrained()"),lOo=o(" class method or the "),qX=a("a"),iOo=o("from_config()"),dOo=o(` class
method.`),cOo=l(),Gy=a("p"),fOo=o("This class cannot be instantiated directly using "),rue=a("code"),mOo=o("__init__()"),gOo=o(" (throws an error)."),hOo=l(),ht=a("div"),F(Oy.$$.fragment),pOo=l(),tue=a("p"),_Oo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),uOo=l(),cd=a("p"),bOo=o(`Note:
Loading a model from its configuration file does `),aue=a("strong"),vOo=o("not"),FOo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jX=a("a"),TOo=o("from_pretrained()"),MOo=o(" to load the model weights."),EOo=l(),F(W4.$$.fragment),COo=l(),oo=a("div"),F(Vy.$$.fragment),wOo=l(),nue=a("p"),AOo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),LOo=l(),Xa=a("p"),yOo=o("The model class to instantiate is selected based on the "),sue=a("code"),xOo=o("model_type"),$Oo=o(` property of the config object (either
passed as an argument or loaded from `),lue=a("code"),kOo=o("pretrained_model_name_or_path"),SOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iue=a("code"),ROo=o("pretrained_model_name_or_path"),POo=o(":"),BOo=l(),me=a("ul"),Q4=a("li"),due=a("strong"),IOo=o("bart"),NOo=o(" \u2014 "),DX=a("a"),qOo=o("BartForConditionalGeneration"),jOo=o(" (BART model)"),DOo=l(),U4=a("li"),cue=a("strong"),GOo=o("bigbird_pegasus"),OOo=o(" \u2014 "),GX=a("a"),VOo=o("BigBirdPegasusForConditionalGeneration"),XOo=o(" (BigBird-Pegasus model)"),zOo=l(),H4=a("li"),fue=a("strong"),WOo=o("blenderbot"),QOo=o(" \u2014 "),OX=a("a"),UOo=o("BlenderbotForConditionalGeneration"),HOo=o(" (Blenderbot model)"),JOo=l(),J4=a("li"),mue=a("strong"),YOo=o("blenderbot-small"),KOo=o(" \u2014 "),VX=a("a"),ZOo=o("BlenderbotSmallForConditionalGeneration"),eVo=o(" (BlenderbotSmall model)"),oVo=l(),Y4=a("li"),gue=a("strong"),rVo=o("encoder-decoder"),tVo=o(" \u2014 "),XX=a("a"),aVo=o("EncoderDecoderModel"),nVo=o(" (Encoder decoder model)"),sVo=l(),K4=a("li"),hue=a("strong"),lVo=o("fsmt"),iVo=o(" \u2014 "),zX=a("a"),dVo=o("FSMTForConditionalGeneration"),cVo=o(" (FairSeq Machine-Translation model)"),fVo=l(),Z4=a("li"),pue=a("strong"),mVo=o("led"),gVo=o(" \u2014 "),WX=a("a"),hVo=o("LEDForConditionalGeneration"),pVo=o(" (LED model)"),_Vo=l(),eb=a("li"),_ue=a("strong"),uVo=o("longt5"),bVo=o(" \u2014 "),QX=a("a"),vVo=o("LongT5ForConditionalGeneration"),FVo=o(" (LongT5 model)"),TVo=l(),ob=a("li"),uue=a("strong"),MVo=o("m2m_100"),EVo=o(" \u2014 "),UX=a("a"),CVo=o("M2M100ForConditionalGeneration"),wVo=o(" (M2M100 model)"),AVo=l(),rb=a("li"),bue=a("strong"),LVo=o("marian"),yVo=o(" \u2014 "),HX=a("a"),xVo=o("MarianMTModel"),$Vo=o(" (Marian model)"),kVo=l(),tb=a("li"),vue=a("strong"),SVo=o("mbart"),RVo=o(" \u2014 "),JX=a("a"),PVo=o("MBartForConditionalGeneration"),BVo=o(" (mBART model)"),IVo=l(),ab=a("li"),Fue=a("strong"),NVo=o("mt5"),qVo=o(" \u2014 "),YX=a("a"),jVo=o("MT5ForConditionalGeneration"),DVo=o(" (MT5 model)"),GVo=l(),nb=a("li"),Tue=a("strong"),OVo=o("mvp"),VVo=o(" \u2014 "),KX=a("a"),XVo=o("MvpForConditionalGeneration"),zVo=o(" (MVP model)"),WVo=l(),sb=a("li"),Mue=a("strong"),QVo=o("nllb"),UVo=o(" \u2014 "),ZX=a("a"),HVo=o("M2M100ForConditionalGeneration"),JVo=o(" (NLLB model)"),YVo=l(),lb=a("li"),Eue=a("strong"),KVo=o("pegasus"),ZVo=o(" \u2014 "),ez=a("a"),eXo=o("PegasusForConditionalGeneration"),oXo=o(" (Pegasus model)"),rXo=l(),ib=a("li"),Cue=a("strong"),tXo=o("plbart"),aXo=o(" \u2014 "),oz=a("a"),nXo=o("PLBartForConditionalGeneration"),sXo=o(" (PLBart model)"),lXo=l(),db=a("li"),wue=a("strong"),iXo=o("prophetnet"),dXo=o(" \u2014 "),rz=a("a"),cXo=o("ProphetNetForConditionalGeneration"),fXo=o(" (ProphetNet model)"),mXo=l(),cb=a("li"),Aue=a("strong"),gXo=o("t5"),hXo=o(" \u2014 "),tz=a("a"),pXo=o("T5ForConditionalGeneration"),_Xo=o(" (T5 model)"),uXo=l(),fb=a("li"),Lue=a("strong"),bXo=o("xlm-prophetnet"),vXo=o(" \u2014 "),az=a("a"),FXo=o("XLMProphetNetForConditionalGeneration"),TXo=o(" (XLM-ProphetNet model)"),MXo=l(),mb=a("p"),EXo=o("The model is set in evaluation mode by default using "),yue=a("code"),CXo=o("model.eval()"),wXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xue=a("code"),AXo=o("model.train()"),LXo=l(),F(gb.$$.fragment),iQe=l(),fd=a("h2"),hb=a("a"),$ue=a("span"),F(Xy.$$.fragment),yXo=l(),kue=a("span"),xXo=o("AutoModelForSequenceClassification"),dQe=l(),No=a("div"),F(zy.$$.fragment),$Xo=l(),md=a("p"),kXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nz=a("a"),SXo=o("from_pretrained()"),RXo=o(" class method or the "),sz=a("a"),PXo=o("from_config()"),BXo=o(` class
method.`),IXo=l(),Wy=a("p"),NXo=o("This class cannot be instantiated directly using "),Sue=a("code"),qXo=o("__init__()"),jXo=o(" (throws an error)."),DXo=l(),pt=a("div"),F(Qy.$$.fragment),GXo=l(),Rue=a("p"),OXo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),VXo=l(),gd=a("p"),XXo=o(`Note:
Loading a model from its configuration file does `),Pue=a("strong"),zXo=o("not"),WXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lz=a("a"),QXo=o("from_pretrained()"),UXo=o(" to load the model weights."),HXo=l(),F(pb.$$.fragment),JXo=l(),ro=a("div"),F(Uy.$$.fragment),YXo=l(),Bue=a("p"),KXo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),ZXo=l(),za=a("p"),ezo=o("The model class to instantiate is selected based on the "),Iue=a("code"),ozo=o("model_type"),rzo=o(` property of the config object (either
passed as an argument or loaded from `),Nue=a("code"),tzo=o("pretrained_model_name_or_path"),azo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),que=a("code"),nzo=o("pretrained_model_name_or_path"),szo=o(":"),lzo=l(),B=a("ul"),_b=a("li"),jue=a("strong"),izo=o("albert"),dzo=o(" \u2014 "),iz=a("a"),czo=o("AlbertForSequenceClassification"),fzo=o(" (ALBERT model)"),mzo=l(),ub=a("li"),Due=a("strong"),gzo=o("bart"),hzo=o(" \u2014 "),dz=a("a"),pzo=o("BartForSequenceClassification"),_zo=o(" (BART model)"),uzo=l(),bb=a("li"),Gue=a("strong"),bzo=o("bert"),vzo=o(" \u2014 "),cz=a("a"),Fzo=o("BertForSequenceClassification"),Tzo=o(" (BERT model)"),Mzo=l(),vb=a("li"),Oue=a("strong"),Ezo=o("big_bird"),Czo=o(" \u2014 "),fz=a("a"),wzo=o("BigBirdForSequenceClassification"),Azo=o(" (BigBird model)"),Lzo=l(),Fb=a("li"),Vue=a("strong"),yzo=o("bigbird_pegasus"),xzo=o(" \u2014 "),mz=a("a"),$zo=o("BigBirdPegasusForSequenceClassification"),kzo=o(" (BigBird-Pegasus model)"),Szo=l(),Tb=a("li"),Xue=a("strong"),Rzo=o("bloom"),Pzo=o(" \u2014 "),gz=a("a"),Bzo=o("BloomForSequenceClassification"),Izo=o(" (BLOOM model)"),Nzo=l(),Mb=a("li"),zue=a("strong"),qzo=o("camembert"),jzo=o(" \u2014 "),hz=a("a"),Dzo=o("CamembertForSequenceClassification"),Gzo=o(" (CamemBERT model)"),Ozo=l(),Eb=a("li"),Wue=a("strong"),Vzo=o("canine"),Xzo=o(" \u2014 "),pz=a("a"),zzo=o("CanineForSequenceClassification"),Wzo=o(" (CANINE model)"),Qzo=l(),Cb=a("li"),Que=a("strong"),Uzo=o("convbert"),Hzo=o(" \u2014 "),_z=a("a"),Jzo=o("ConvBertForSequenceClassification"),Yzo=o(" (ConvBERT model)"),Kzo=l(),wb=a("li"),Uue=a("strong"),Zzo=o("ctrl"),eWo=o(" \u2014 "),uz=a("a"),oWo=o("CTRLForSequenceClassification"),rWo=o(" (CTRL model)"),tWo=l(),Ab=a("li"),Hue=a("strong"),aWo=o("data2vec-text"),nWo=o(" \u2014 "),bz=a("a"),sWo=o("Data2VecTextForSequenceClassification"),lWo=o(" (Data2VecText model)"),iWo=l(),Lb=a("li"),Jue=a("strong"),dWo=o("deberta"),cWo=o(" \u2014 "),vz=a("a"),fWo=o("DebertaForSequenceClassification"),mWo=o(" (DeBERTa model)"),gWo=l(),yb=a("li"),Yue=a("strong"),hWo=o("deberta-v2"),pWo=o(" \u2014 "),Fz=a("a"),_Wo=o("DebertaV2ForSequenceClassification"),uWo=o(" (DeBERTa-v2 model)"),bWo=l(),xb=a("li"),Kue=a("strong"),vWo=o("distilbert"),FWo=o(" \u2014 "),Tz=a("a"),TWo=o("DistilBertForSequenceClassification"),MWo=o(" (DistilBERT model)"),EWo=l(),$b=a("li"),Zue=a("strong"),CWo=o("electra"),wWo=o(" \u2014 "),Mz=a("a"),AWo=o("ElectraForSequenceClassification"),LWo=o(" (ELECTRA model)"),yWo=l(),kb=a("li"),e2e=a("strong"),xWo=o("flaubert"),$Wo=o(" \u2014 "),Ez=a("a"),kWo=o("FlaubertForSequenceClassification"),SWo=o(" (FlauBERT model)"),RWo=l(),Sb=a("li"),o2e=a("strong"),PWo=o("fnet"),BWo=o(" \u2014 "),Cz=a("a"),IWo=o("FNetForSequenceClassification"),NWo=o(" (FNet model)"),qWo=l(),Rb=a("li"),r2e=a("strong"),jWo=o("funnel"),DWo=o(" \u2014 "),wz=a("a"),GWo=o("FunnelForSequenceClassification"),OWo=o(" (Funnel Transformer model)"),VWo=l(),Pb=a("li"),t2e=a("strong"),XWo=o("gpt2"),zWo=o(" \u2014 "),Az=a("a"),WWo=o("GPT2ForSequenceClassification"),QWo=o(" (OpenAI GPT-2 model)"),UWo=l(),Bb=a("li"),a2e=a("strong"),HWo=o("gpt_neo"),JWo=o(" \u2014 "),Lz=a("a"),YWo=o("GPTNeoForSequenceClassification"),KWo=o(" (GPT Neo model)"),ZWo=l(),Ib=a("li"),n2e=a("strong"),eQo=o("gptj"),oQo=o(" \u2014 "),yz=a("a"),rQo=o("GPTJForSequenceClassification"),tQo=o(" (GPT-J model)"),aQo=l(),Nb=a("li"),s2e=a("strong"),nQo=o("ibert"),sQo=o(" \u2014 "),xz=a("a"),lQo=o("IBertForSequenceClassification"),iQo=o(" (I-BERT model)"),dQo=l(),qb=a("li"),l2e=a("strong"),cQo=o("layoutlm"),fQo=o(" \u2014 "),$z=a("a"),mQo=o("LayoutLMForSequenceClassification"),gQo=o(" (LayoutLM model)"),hQo=l(),jb=a("li"),i2e=a("strong"),pQo=o("layoutlmv2"),_Qo=o(" \u2014 "),kz=a("a"),uQo=o("LayoutLMv2ForSequenceClassification"),bQo=o(" (LayoutLMv2 model)"),vQo=l(),Db=a("li"),d2e=a("strong"),FQo=o("layoutlmv3"),TQo=o(" \u2014 "),Sz=a("a"),MQo=o("LayoutLMv3ForSequenceClassification"),EQo=o(" (LayoutLMv3 model)"),CQo=l(),Gb=a("li"),c2e=a("strong"),wQo=o("led"),AQo=o(" \u2014 "),Rz=a("a"),LQo=o("LEDForSequenceClassification"),yQo=o(" (LED model)"),xQo=l(),Ob=a("li"),f2e=a("strong"),$Qo=o("longformer"),kQo=o(" \u2014 "),Pz=a("a"),SQo=o("LongformerForSequenceClassification"),RQo=o(" (Longformer model)"),PQo=l(),Vb=a("li"),m2e=a("strong"),BQo=o("luke"),IQo=o(" \u2014 "),Bz=a("a"),NQo=o("LukeForSequenceClassification"),qQo=o(" (LUKE model)"),jQo=l(),Xb=a("li"),g2e=a("strong"),DQo=o("mbart"),GQo=o(" \u2014 "),Iz=a("a"),OQo=o("MBartForSequenceClassification"),VQo=o(" (mBART model)"),XQo=l(),zb=a("li"),h2e=a("strong"),zQo=o("megatron-bert"),WQo=o(" \u2014 "),Nz=a("a"),QQo=o("MegatronBertForSequenceClassification"),UQo=o(" (Megatron-BERT model)"),HQo=l(),Wb=a("li"),p2e=a("strong"),JQo=o("mobilebert"),YQo=o(" \u2014 "),qz=a("a"),KQo=o("MobileBertForSequenceClassification"),ZQo=o(" (MobileBERT model)"),eUo=l(),Qb=a("li"),_2e=a("strong"),oUo=o("mpnet"),rUo=o(" \u2014 "),jz=a("a"),tUo=o("MPNetForSequenceClassification"),aUo=o(" (MPNet model)"),nUo=l(),Ub=a("li"),u2e=a("strong"),sUo=o("mvp"),lUo=o(" \u2014 "),Dz=a("a"),iUo=o("MvpForSequenceClassification"),dUo=o(" (MVP model)"),cUo=l(),Hb=a("li"),b2e=a("strong"),fUo=o("nezha"),mUo=o(" \u2014 "),Gz=a("a"),gUo=o("NezhaForSequenceClassification"),hUo=o(" (Nezha model)"),pUo=l(),Jb=a("li"),v2e=a("strong"),_Uo=o("nystromformer"),uUo=o(" \u2014 "),Oz=a("a"),bUo=o("NystromformerForSequenceClassification"),vUo=o(" (Nystr\xF6mformer model)"),FUo=l(),Yb=a("li"),F2e=a("strong"),TUo=o("openai-gpt"),MUo=o(" \u2014 "),Vz=a("a"),EUo=o("OpenAIGPTForSequenceClassification"),CUo=o(" (OpenAI GPT model)"),wUo=l(),Kb=a("li"),T2e=a("strong"),AUo=o("opt"),LUo=o(" \u2014 "),Xz=a("a"),yUo=o("OPTForSequenceClassification"),xUo=o(" (OPT model)"),$Uo=l(),Zb=a("li"),M2e=a("strong"),kUo=o("perceiver"),SUo=o(" \u2014 "),zz=a("a"),RUo=o("PerceiverForSequenceClassification"),PUo=o(" (Perceiver model)"),BUo=l(),ev=a("li"),E2e=a("strong"),IUo=o("plbart"),NUo=o(" \u2014 "),Wz=a("a"),qUo=o("PLBartForSequenceClassification"),jUo=o(" (PLBart model)"),DUo=l(),ov=a("li"),C2e=a("strong"),GUo=o("qdqbert"),OUo=o(" \u2014 "),Qz=a("a"),VUo=o("QDQBertForSequenceClassification"),XUo=o(" (QDQBert model)"),zUo=l(),rv=a("li"),w2e=a("strong"),WUo=o("reformer"),QUo=o(" \u2014 "),Uz=a("a"),UUo=o("ReformerForSequenceClassification"),HUo=o(" (Reformer model)"),JUo=l(),tv=a("li"),A2e=a("strong"),YUo=o("rembert"),KUo=o(" \u2014 "),Hz=a("a"),ZUo=o("RemBertForSequenceClassification"),eHo=o(" (RemBERT model)"),oHo=l(),av=a("li"),L2e=a("strong"),rHo=o("roberta"),tHo=o(" \u2014 "),Jz=a("a"),aHo=o("RobertaForSequenceClassification"),nHo=o(" (RoBERTa model)"),sHo=l(),nv=a("li"),y2e=a("strong"),lHo=o("roformer"),iHo=o(" \u2014 "),Yz=a("a"),dHo=o("RoFormerForSequenceClassification"),cHo=o(" (RoFormer model)"),fHo=l(),sv=a("li"),x2e=a("strong"),mHo=o("squeezebert"),gHo=o(" \u2014 "),Kz=a("a"),hHo=o("SqueezeBertForSequenceClassification"),pHo=o(" (SqueezeBERT model)"),_Ho=l(),lv=a("li"),$2e=a("strong"),uHo=o("tapas"),bHo=o(" \u2014 "),Zz=a("a"),vHo=o("TapasForSequenceClassification"),FHo=o(" (TAPAS model)"),THo=l(),iv=a("li"),k2e=a("strong"),MHo=o("transfo-xl"),EHo=o(" \u2014 "),eW=a("a"),CHo=o("TransfoXLForSequenceClassification"),wHo=o(" (Transformer-XL model)"),AHo=l(),dv=a("li"),S2e=a("strong"),LHo=o("xlm"),yHo=o(" \u2014 "),oW=a("a"),xHo=o("XLMForSequenceClassification"),$Ho=o(" (XLM model)"),kHo=l(),cv=a("li"),R2e=a("strong"),SHo=o("xlm-roberta"),RHo=o(" \u2014 "),rW=a("a"),PHo=o("XLMRobertaForSequenceClassification"),BHo=o(" (XLM-RoBERTa model)"),IHo=l(),fv=a("li"),P2e=a("strong"),NHo=o("xlm-roberta-xl"),qHo=o(" \u2014 "),tW=a("a"),jHo=o("XLMRobertaXLForSequenceClassification"),DHo=o(" (XLM-RoBERTa-XL model)"),GHo=l(),mv=a("li"),B2e=a("strong"),OHo=o("xlnet"),VHo=o(" \u2014 "),aW=a("a"),XHo=o("XLNetForSequenceClassification"),zHo=o(" (XLNet model)"),WHo=l(),gv=a("li"),I2e=a("strong"),QHo=o("yoso"),UHo=o(" \u2014 "),nW=a("a"),HHo=o("YosoForSequenceClassification"),JHo=o(" (YOSO model)"),YHo=l(),hv=a("p"),KHo=o("The model is set in evaluation mode by default using "),N2e=a("code"),ZHo=o("model.eval()"),eJo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q2e=a("code"),oJo=o("model.train()"),rJo=l(),F(pv.$$.fragment),cQe=l(),hd=a("h2"),_v=a("a"),j2e=a("span"),F(Hy.$$.fragment),tJo=l(),D2e=a("span"),aJo=o("AutoModelForMultipleChoice"),fQe=l(),qo=a("div"),F(Jy.$$.fragment),nJo=l(),pd=a("p"),sJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),sW=a("a"),lJo=o("from_pretrained()"),iJo=o(" class method or the "),lW=a("a"),dJo=o("from_config()"),cJo=o(` class
method.`),fJo=l(),Yy=a("p"),mJo=o("This class cannot be instantiated directly using "),G2e=a("code"),gJo=o("__init__()"),hJo=o(" (throws an error)."),pJo=l(),_t=a("div"),F(Ky.$$.fragment),_Jo=l(),O2e=a("p"),uJo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),bJo=l(),_d=a("p"),vJo=o(`Note:
Loading a model from its configuration file does `),V2e=a("strong"),FJo=o("not"),TJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iW=a("a"),MJo=o("from_pretrained()"),EJo=o(" to load the model weights."),CJo=l(),F(uv.$$.fragment),wJo=l(),to=a("div"),F(Zy.$$.fragment),AJo=l(),X2e=a("p"),LJo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),yJo=l(),Wa=a("p"),xJo=o("The model class to instantiate is selected based on the "),z2e=a("code"),$Jo=o("model_type"),kJo=o(` property of the config object (either
passed as an argument or loaded from `),W2e=a("code"),SJo=o("pretrained_model_name_or_path"),RJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q2e=a("code"),PJo=o("pretrained_model_name_or_path"),BJo=o(":"),IJo=l(),Z=a("ul"),bv=a("li"),U2e=a("strong"),NJo=o("albert"),qJo=o(" \u2014 "),dW=a("a"),jJo=o("AlbertForMultipleChoice"),DJo=o(" (ALBERT model)"),GJo=l(),vv=a("li"),H2e=a("strong"),OJo=o("bert"),VJo=o(" \u2014 "),cW=a("a"),XJo=o("BertForMultipleChoice"),zJo=o(" (BERT model)"),WJo=l(),Fv=a("li"),J2e=a("strong"),QJo=o("big_bird"),UJo=o(" \u2014 "),fW=a("a"),HJo=o("BigBirdForMultipleChoice"),JJo=o(" (BigBird model)"),YJo=l(),Tv=a("li"),Y2e=a("strong"),KJo=o("camembert"),ZJo=o(" \u2014 "),mW=a("a"),eYo=o("CamembertForMultipleChoice"),oYo=o(" (CamemBERT model)"),rYo=l(),Mv=a("li"),K2e=a("strong"),tYo=o("canine"),aYo=o(" \u2014 "),gW=a("a"),nYo=o("CanineForMultipleChoice"),sYo=o(" (CANINE model)"),lYo=l(),Ev=a("li"),Z2e=a("strong"),iYo=o("convbert"),dYo=o(" \u2014 "),hW=a("a"),cYo=o("ConvBertForMultipleChoice"),fYo=o(" (ConvBERT model)"),mYo=l(),Cv=a("li"),e1e=a("strong"),gYo=o("data2vec-text"),hYo=o(" \u2014 "),pW=a("a"),pYo=o("Data2VecTextForMultipleChoice"),_Yo=o(" (Data2VecText model)"),uYo=l(),wv=a("li"),o1e=a("strong"),bYo=o("deberta-v2"),vYo=o(" \u2014 "),_W=a("a"),FYo=o("DebertaV2ForMultipleChoice"),TYo=o(" (DeBERTa-v2 model)"),MYo=l(),Av=a("li"),r1e=a("strong"),EYo=o("distilbert"),CYo=o(" \u2014 "),uW=a("a"),wYo=o("DistilBertForMultipleChoice"),AYo=o(" (DistilBERT model)"),LYo=l(),Lv=a("li"),t1e=a("strong"),yYo=o("electra"),xYo=o(" \u2014 "),bW=a("a"),$Yo=o("ElectraForMultipleChoice"),kYo=o(" (ELECTRA model)"),SYo=l(),yv=a("li"),a1e=a("strong"),RYo=o("flaubert"),PYo=o(" \u2014 "),vW=a("a"),BYo=o("FlaubertForMultipleChoice"),IYo=o(" (FlauBERT model)"),NYo=l(),xv=a("li"),n1e=a("strong"),qYo=o("fnet"),jYo=o(" \u2014 "),FW=a("a"),DYo=o("FNetForMultipleChoice"),GYo=o(" (FNet model)"),OYo=l(),$v=a("li"),s1e=a("strong"),VYo=o("funnel"),XYo=o(" \u2014 "),TW=a("a"),zYo=o("FunnelForMultipleChoice"),WYo=o(" (Funnel Transformer model)"),QYo=l(),kv=a("li"),l1e=a("strong"),UYo=o("ibert"),HYo=o(" \u2014 "),MW=a("a"),JYo=o("IBertForMultipleChoice"),YYo=o(" (I-BERT model)"),KYo=l(),Sv=a("li"),i1e=a("strong"),ZYo=o("longformer"),eKo=o(" \u2014 "),EW=a("a"),oKo=o("LongformerForMultipleChoice"),rKo=o(" (Longformer model)"),tKo=l(),Rv=a("li"),d1e=a("strong"),aKo=o("luke"),nKo=o(" \u2014 "),CW=a("a"),sKo=o("LukeForMultipleChoice"),lKo=o(" (LUKE model)"),iKo=l(),Pv=a("li"),c1e=a("strong"),dKo=o("megatron-bert"),cKo=o(" \u2014 "),wW=a("a"),fKo=o("MegatronBertForMultipleChoice"),mKo=o(" (Megatron-BERT model)"),gKo=l(),Bv=a("li"),f1e=a("strong"),hKo=o("mobilebert"),pKo=o(" \u2014 "),AW=a("a"),_Ko=o("MobileBertForMultipleChoice"),uKo=o(" (MobileBERT model)"),bKo=l(),Iv=a("li"),m1e=a("strong"),vKo=o("mpnet"),FKo=o(" \u2014 "),LW=a("a"),TKo=o("MPNetForMultipleChoice"),MKo=o(" (MPNet model)"),EKo=l(),Nv=a("li"),g1e=a("strong"),CKo=o("nezha"),wKo=o(" \u2014 "),yW=a("a"),AKo=o("NezhaForMultipleChoice"),LKo=o(" (Nezha model)"),yKo=l(),qv=a("li"),h1e=a("strong"),xKo=o("nystromformer"),$Ko=o(" \u2014 "),xW=a("a"),kKo=o("NystromformerForMultipleChoice"),SKo=o(" (Nystr\xF6mformer model)"),RKo=l(),jv=a("li"),p1e=a("strong"),PKo=o("qdqbert"),BKo=o(" \u2014 "),$W=a("a"),IKo=o("QDQBertForMultipleChoice"),NKo=o(" (QDQBert model)"),qKo=l(),Dv=a("li"),_1e=a("strong"),jKo=o("rembert"),DKo=o(" \u2014 "),kW=a("a"),GKo=o("RemBertForMultipleChoice"),OKo=o(" (RemBERT model)"),VKo=l(),Gv=a("li"),u1e=a("strong"),XKo=o("roberta"),zKo=o(" \u2014 "),SW=a("a"),WKo=o("RobertaForMultipleChoice"),QKo=o(" (RoBERTa model)"),UKo=l(),Ov=a("li"),b1e=a("strong"),HKo=o("roformer"),JKo=o(" \u2014 "),RW=a("a"),YKo=o("RoFormerForMultipleChoice"),KKo=o(" (RoFormer model)"),ZKo=l(),Vv=a("li"),v1e=a("strong"),eZo=o("squeezebert"),oZo=o(" \u2014 "),PW=a("a"),rZo=o("SqueezeBertForMultipleChoice"),tZo=o(" (SqueezeBERT model)"),aZo=l(),Xv=a("li"),F1e=a("strong"),nZo=o("xlm"),sZo=o(" \u2014 "),BW=a("a"),lZo=o("XLMForMultipleChoice"),iZo=o(" (XLM model)"),dZo=l(),zv=a("li"),T1e=a("strong"),cZo=o("xlm-roberta"),fZo=o(" \u2014 "),IW=a("a"),mZo=o("XLMRobertaForMultipleChoice"),gZo=o(" (XLM-RoBERTa model)"),hZo=l(),Wv=a("li"),M1e=a("strong"),pZo=o("xlm-roberta-xl"),_Zo=o(" \u2014 "),NW=a("a"),uZo=o("XLMRobertaXLForMultipleChoice"),bZo=o(" (XLM-RoBERTa-XL model)"),vZo=l(),Qv=a("li"),E1e=a("strong"),FZo=o("xlnet"),TZo=o(" \u2014 "),qW=a("a"),MZo=o("XLNetForMultipleChoice"),EZo=o(" (XLNet model)"),CZo=l(),Uv=a("li"),C1e=a("strong"),wZo=o("yoso"),AZo=o(" \u2014 "),jW=a("a"),LZo=o("YosoForMultipleChoice"),yZo=o(" (YOSO model)"),xZo=l(),Hv=a("p"),$Zo=o("The model is set in evaluation mode by default using "),w1e=a("code"),kZo=o("model.eval()"),SZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A1e=a("code"),RZo=o("model.train()"),PZo=l(),F(Jv.$$.fragment),mQe=l(),ud=a("h2"),Yv=a("a"),L1e=a("span"),F(e9.$$.fragment),BZo=l(),y1e=a("span"),IZo=o("AutoModelForNextSentencePrediction"),gQe=l(),jo=a("div"),F(o9.$$.fragment),NZo=l(),bd=a("p"),qZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DW=a("a"),jZo=o("from_pretrained()"),DZo=o(" class method or the "),GW=a("a"),GZo=o("from_config()"),OZo=o(` class
method.`),VZo=l(),r9=a("p"),XZo=o("This class cannot be instantiated directly using "),x1e=a("code"),zZo=o("__init__()"),WZo=o(" (throws an error)."),QZo=l(),ut=a("div"),F(t9.$$.fragment),UZo=l(),$1e=a("p"),HZo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),JZo=l(),vd=a("p"),YZo=o(`Note:
Loading a model from its configuration file does `),k1e=a("strong"),KZo=o("not"),ZZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=a("a"),eer=o("from_pretrained()"),oer=o(" to load the model weights."),rer=l(),F(Kv.$$.fragment),ter=l(),ao=a("div"),F(a9.$$.fragment),aer=l(),S1e=a("p"),ner=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),ser=l(),Qa=a("p"),ler=o("The model class to instantiate is selected based on the "),R1e=a("code"),ier=o("model_type"),der=o(` property of the config object (either
passed as an argument or loaded from `),P1e=a("code"),cer=o("pretrained_model_name_or_path"),fer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B1e=a("code"),mer=o("pretrained_model_name_or_path"),ger=o(":"),her=l(),Do=a("ul"),Zv=a("li"),I1e=a("strong"),per=o("bert"),_er=o(" \u2014 "),VW=a("a"),uer=o("BertForNextSentencePrediction"),ber=o(" (BERT model)"),ver=l(),e5=a("li"),N1e=a("strong"),Fer=o("fnet"),Ter=o(" \u2014 "),XW=a("a"),Mer=o("FNetForNextSentencePrediction"),Eer=o(" (FNet model)"),Cer=l(),o5=a("li"),q1e=a("strong"),wer=o("megatron-bert"),Aer=o(" \u2014 "),zW=a("a"),Ler=o("MegatronBertForNextSentencePrediction"),yer=o(" (Megatron-BERT model)"),xer=l(),r5=a("li"),j1e=a("strong"),$er=o("mobilebert"),ker=o(" \u2014 "),WW=a("a"),Ser=o("MobileBertForNextSentencePrediction"),Rer=o(" (MobileBERT model)"),Per=l(),t5=a("li"),D1e=a("strong"),Ber=o("nezha"),Ier=o(" \u2014 "),QW=a("a"),Ner=o("NezhaForNextSentencePrediction"),qer=o(" (Nezha model)"),jer=l(),a5=a("li"),G1e=a("strong"),Der=o("qdqbert"),Ger=o(" \u2014 "),UW=a("a"),Oer=o("QDQBertForNextSentencePrediction"),Ver=o(" (QDQBert model)"),Xer=l(),n5=a("p"),zer=o("The model is set in evaluation mode by default using "),O1e=a("code"),Wer=o("model.eval()"),Qer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V1e=a("code"),Uer=o("model.train()"),Her=l(),F(s5.$$.fragment),hQe=l(),Fd=a("h2"),l5=a("a"),X1e=a("span"),F(n9.$$.fragment),Jer=l(),z1e=a("span"),Yer=o("AutoModelForTokenClassification"),pQe=l(),Go=a("div"),F(s9.$$.fragment),Ker=l(),Td=a("p"),Zer=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HW=a("a"),eor=o("from_pretrained()"),oor=o(" class method or the "),JW=a("a"),ror=o("from_config()"),tor=o(` class
method.`),aor=l(),l9=a("p"),nor=o("This class cannot be instantiated directly using "),W1e=a("code"),sor=o("__init__()"),lor=o(" (throws an error)."),ior=l(),bt=a("div"),F(i9.$$.fragment),dor=l(),Q1e=a("p"),cor=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),mor=l(),Md=a("p"),gor=o(`Note:
Loading a model from its configuration file does `),U1e=a("strong"),hor=o("not"),por=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=a("a"),_or=o("from_pretrained()"),uor=o(" to load the model weights."),bor=l(),F(i5.$$.fragment),vor=l(),no=a("div"),F(d9.$$.fragment),For=l(),H1e=a("p"),Tor=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Mor=l(),Ua=a("p"),Eor=o("The model class to instantiate is selected based on the "),J1e=a("code"),Cor=o("model_type"),wor=o(` property of the config object (either
passed as an argument or loaded from `),Y1e=a("code"),Aor=o("pretrained_model_name_or_path"),Lor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K1e=a("code"),yor=o("pretrained_model_name_or_path"),xor=o(":"),$or=l(),H=a("ul"),d5=a("li"),Z1e=a("strong"),kor=o("albert"),Sor=o(" \u2014 "),KW=a("a"),Ror=o("AlbertForTokenClassification"),Por=o(" (ALBERT model)"),Bor=l(),c5=a("li"),e4e=a("strong"),Ior=o("bert"),Nor=o(" \u2014 "),ZW=a("a"),qor=o("BertForTokenClassification"),jor=o(" (BERT model)"),Dor=l(),f5=a("li"),o4e=a("strong"),Gor=o("big_bird"),Oor=o(" \u2014 "),eQ=a("a"),Vor=o("BigBirdForTokenClassification"),Xor=o(" (BigBird model)"),zor=l(),m5=a("li"),r4e=a("strong"),Wor=o("bloom"),Qor=o(" \u2014 "),oQ=a("a"),Uor=o("BloomForTokenClassification"),Hor=o(" (BLOOM model)"),Jor=l(),g5=a("li"),t4e=a("strong"),Yor=o("camembert"),Kor=o(" \u2014 "),rQ=a("a"),Zor=o("CamembertForTokenClassification"),err=o(" (CamemBERT model)"),orr=l(),h5=a("li"),a4e=a("strong"),rrr=o("canine"),trr=o(" \u2014 "),tQ=a("a"),arr=o("CanineForTokenClassification"),nrr=o(" (CANINE model)"),srr=l(),p5=a("li"),n4e=a("strong"),lrr=o("convbert"),irr=o(" \u2014 "),aQ=a("a"),drr=o("ConvBertForTokenClassification"),crr=o(" (ConvBERT model)"),frr=l(),_5=a("li"),s4e=a("strong"),mrr=o("data2vec-text"),grr=o(" \u2014 "),nQ=a("a"),hrr=o("Data2VecTextForTokenClassification"),prr=o(" (Data2VecText model)"),_rr=l(),u5=a("li"),l4e=a("strong"),urr=o("deberta"),brr=o(" \u2014 "),sQ=a("a"),vrr=o("DebertaForTokenClassification"),Frr=o(" (DeBERTa model)"),Trr=l(),b5=a("li"),i4e=a("strong"),Mrr=o("deberta-v2"),Err=o(" \u2014 "),lQ=a("a"),Crr=o("DebertaV2ForTokenClassification"),wrr=o(" (DeBERTa-v2 model)"),Arr=l(),v5=a("li"),d4e=a("strong"),Lrr=o("distilbert"),yrr=o(" \u2014 "),iQ=a("a"),xrr=o("DistilBertForTokenClassification"),$rr=o(" (DistilBERT model)"),krr=l(),F5=a("li"),c4e=a("strong"),Srr=o("electra"),Rrr=o(" \u2014 "),dQ=a("a"),Prr=o("ElectraForTokenClassification"),Brr=o(" (ELECTRA model)"),Irr=l(),T5=a("li"),f4e=a("strong"),Nrr=o("flaubert"),qrr=o(" \u2014 "),cQ=a("a"),jrr=o("FlaubertForTokenClassification"),Drr=o(" (FlauBERT model)"),Grr=l(),M5=a("li"),m4e=a("strong"),Orr=o("fnet"),Vrr=o(" \u2014 "),fQ=a("a"),Xrr=o("FNetForTokenClassification"),zrr=o(" (FNet model)"),Wrr=l(),E5=a("li"),g4e=a("strong"),Qrr=o("funnel"),Urr=o(" \u2014 "),mQ=a("a"),Hrr=o("FunnelForTokenClassification"),Jrr=o(" (Funnel Transformer model)"),Yrr=l(),C5=a("li"),h4e=a("strong"),Krr=o("gpt2"),Zrr=o(" \u2014 "),gQ=a("a"),etr=o("GPT2ForTokenClassification"),otr=o(" (OpenAI GPT-2 model)"),rtr=l(),w5=a("li"),p4e=a("strong"),ttr=o("ibert"),atr=o(" \u2014 "),hQ=a("a"),ntr=o("IBertForTokenClassification"),str=o(" (I-BERT model)"),ltr=l(),A5=a("li"),_4e=a("strong"),itr=o("layoutlm"),dtr=o(" \u2014 "),pQ=a("a"),ctr=o("LayoutLMForTokenClassification"),ftr=o(" (LayoutLM model)"),mtr=l(),L5=a("li"),u4e=a("strong"),gtr=o("layoutlmv2"),htr=o(" \u2014 "),_Q=a("a"),ptr=o("LayoutLMv2ForTokenClassification"),_tr=o(" (LayoutLMv2 model)"),utr=l(),y5=a("li"),b4e=a("strong"),btr=o("layoutlmv3"),vtr=o(" \u2014 "),uQ=a("a"),Ftr=o("LayoutLMv3ForTokenClassification"),Ttr=o(" (LayoutLMv3 model)"),Mtr=l(),x5=a("li"),v4e=a("strong"),Etr=o("longformer"),Ctr=o(" \u2014 "),bQ=a("a"),wtr=o("LongformerForTokenClassification"),Atr=o(" (Longformer model)"),Ltr=l(),$5=a("li"),F4e=a("strong"),ytr=o("luke"),xtr=o(" \u2014 "),vQ=a("a"),$tr=o("LukeForTokenClassification"),ktr=o(" (LUKE model)"),Str=l(),k5=a("li"),T4e=a("strong"),Rtr=o("megatron-bert"),Ptr=o(" \u2014 "),FQ=a("a"),Btr=o("MegatronBertForTokenClassification"),Itr=o(" (Megatron-BERT model)"),Ntr=l(),S5=a("li"),M4e=a("strong"),qtr=o("mobilebert"),jtr=o(" \u2014 "),TQ=a("a"),Dtr=o("MobileBertForTokenClassification"),Gtr=o(" (MobileBERT model)"),Otr=l(),R5=a("li"),E4e=a("strong"),Vtr=o("mpnet"),Xtr=o(" \u2014 "),MQ=a("a"),ztr=o("MPNetForTokenClassification"),Wtr=o(" (MPNet model)"),Qtr=l(),P5=a("li"),C4e=a("strong"),Utr=o("nezha"),Htr=o(" \u2014 "),EQ=a("a"),Jtr=o("NezhaForTokenClassification"),Ytr=o(" (Nezha model)"),Ktr=l(),B5=a("li"),w4e=a("strong"),Ztr=o("nystromformer"),ear=o(" \u2014 "),CQ=a("a"),oar=o("NystromformerForTokenClassification"),rar=o(" (Nystr\xF6mformer model)"),tar=l(),I5=a("li"),A4e=a("strong"),aar=o("qdqbert"),nar=o(" \u2014 "),wQ=a("a"),sar=o("QDQBertForTokenClassification"),lar=o(" (QDQBert model)"),iar=l(),N5=a("li"),L4e=a("strong"),dar=o("rembert"),car=o(" \u2014 "),AQ=a("a"),far=o("RemBertForTokenClassification"),mar=o(" (RemBERT model)"),gar=l(),q5=a("li"),y4e=a("strong"),har=o("roberta"),par=o(" \u2014 "),LQ=a("a"),_ar=o("RobertaForTokenClassification"),uar=o(" (RoBERTa model)"),bar=l(),j5=a("li"),x4e=a("strong"),Far=o("roformer"),Tar=o(" \u2014 "),yQ=a("a"),Mar=o("RoFormerForTokenClassification"),Ear=o(" (RoFormer model)"),Car=l(),D5=a("li"),$4e=a("strong"),war=o("squeezebert"),Aar=o(" \u2014 "),xQ=a("a"),Lar=o("SqueezeBertForTokenClassification"),yar=o(" (SqueezeBERT model)"),xar=l(),G5=a("li"),k4e=a("strong"),$ar=o("xlm"),kar=o(" \u2014 "),$Q=a("a"),Sar=o("XLMForTokenClassification"),Rar=o(" (XLM model)"),Par=l(),O5=a("li"),S4e=a("strong"),Bar=o("xlm-roberta"),Iar=o(" \u2014 "),kQ=a("a"),Nar=o("XLMRobertaForTokenClassification"),qar=o(" (XLM-RoBERTa model)"),jar=l(),V5=a("li"),R4e=a("strong"),Dar=o("xlm-roberta-xl"),Gar=o(" \u2014 "),SQ=a("a"),Oar=o("XLMRobertaXLForTokenClassification"),Var=o(" (XLM-RoBERTa-XL model)"),Xar=l(),X5=a("li"),P4e=a("strong"),zar=o("xlnet"),War=o(" \u2014 "),RQ=a("a"),Qar=o("XLNetForTokenClassification"),Uar=o(" (XLNet model)"),Har=l(),z5=a("li"),B4e=a("strong"),Jar=o("yoso"),Yar=o(" \u2014 "),PQ=a("a"),Kar=o("YosoForTokenClassification"),Zar=o(" (YOSO model)"),enr=l(),W5=a("p"),onr=o("The model is set in evaluation mode by default using "),I4e=a("code"),rnr=o("model.eval()"),tnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N4e=a("code"),anr=o("model.train()"),nnr=l(),F(Q5.$$.fragment),_Qe=l(),Ed=a("h2"),U5=a("a"),q4e=a("span"),F(c9.$$.fragment),snr=l(),j4e=a("span"),lnr=o("AutoModelForQuestionAnswering"),uQe=l(),Oo=a("div"),F(f9.$$.fragment),inr=l(),Cd=a("p"),dnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),BQ=a("a"),cnr=o("from_pretrained()"),fnr=o(" class method or the "),IQ=a("a"),mnr=o("from_config()"),gnr=o(` class
method.`),hnr=l(),m9=a("p"),pnr=o("This class cannot be instantiated directly using "),D4e=a("code"),_nr=o("__init__()"),unr=o(" (throws an error)."),bnr=l(),vt=a("div"),F(g9.$$.fragment),vnr=l(),G4e=a("p"),Fnr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Tnr=l(),wd=a("p"),Mnr=o(`Note:
Loading a model from its configuration file does `),O4e=a("strong"),Enr=o("not"),Cnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NQ=a("a"),wnr=o("from_pretrained()"),Anr=o(" to load the model weights."),Lnr=l(),F(H5.$$.fragment),ynr=l(),so=a("div"),F(h9.$$.fragment),xnr=l(),V4e=a("p"),$nr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),knr=l(),Ha=a("p"),Snr=o("The model class to instantiate is selected based on the "),X4e=a("code"),Rnr=o("model_type"),Pnr=o(` property of the config object (either
passed as an argument or loaded from `),z4e=a("code"),Bnr=o("pretrained_model_name_or_path"),Inr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W4e=a("code"),Nnr=o("pretrained_model_name_or_path"),qnr=o(":"),jnr=l(),V=a("ul"),J5=a("li"),Q4e=a("strong"),Dnr=o("albert"),Gnr=o(" \u2014 "),qQ=a("a"),Onr=o("AlbertForQuestionAnswering"),Vnr=o(" (ALBERT model)"),Xnr=l(),Y5=a("li"),U4e=a("strong"),znr=o("bart"),Wnr=o(" \u2014 "),jQ=a("a"),Qnr=o("BartForQuestionAnswering"),Unr=o(" (BART model)"),Hnr=l(),K5=a("li"),H4e=a("strong"),Jnr=o("bert"),Ynr=o(" \u2014 "),DQ=a("a"),Knr=o("BertForQuestionAnswering"),Znr=o(" (BERT model)"),esr=l(),Z5=a("li"),J4e=a("strong"),osr=o("big_bird"),rsr=o(" \u2014 "),GQ=a("a"),tsr=o("BigBirdForQuestionAnswering"),asr=o(" (BigBird model)"),nsr=l(),eF=a("li"),Y4e=a("strong"),ssr=o("bigbird_pegasus"),lsr=o(" \u2014 "),OQ=a("a"),isr=o("BigBirdPegasusForQuestionAnswering"),dsr=o(" (BigBird-Pegasus model)"),csr=l(),oF=a("li"),K4e=a("strong"),fsr=o("camembert"),msr=o(" \u2014 "),VQ=a("a"),gsr=o("CamembertForQuestionAnswering"),hsr=o(" (CamemBERT model)"),psr=l(),rF=a("li"),Z4e=a("strong"),_sr=o("canine"),usr=o(" \u2014 "),XQ=a("a"),bsr=o("CanineForQuestionAnswering"),vsr=o(" (CANINE model)"),Fsr=l(),tF=a("li"),ebe=a("strong"),Tsr=o("convbert"),Msr=o(" \u2014 "),zQ=a("a"),Esr=o("ConvBertForQuestionAnswering"),Csr=o(" (ConvBERT model)"),wsr=l(),aF=a("li"),obe=a("strong"),Asr=o("data2vec-text"),Lsr=o(" \u2014 "),WQ=a("a"),ysr=o("Data2VecTextForQuestionAnswering"),xsr=o(" (Data2VecText model)"),$sr=l(),nF=a("li"),rbe=a("strong"),ksr=o("deberta"),Ssr=o(" \u2014 "),QQ=a("a"),Rsr=o("DebertaForQuestionAnswering"),Psr=o(" (DeBERTa model)"),Bsr=l(),sF=a("li"),tbe=a("strong"),Isr=o("deberta-v2"),Nsr=o(" \u2014 "),UQ=a("a"),qsr=o("DebertaV2ForQuestionAnswering"),jsr=o(" (DeBERTa-v2 model)"),Dsr=l(),lF=a("li"),abe=a("strong"),Gsr=o("distilbert"),Osr=o(" \u2014 "),HQ=a("a"),Vsr=o("DistilBertForQuestionAnswering"),Xsr=o(" (DistilBERT model)"),zsr=l(),iF=a("li"),nbe=a("strong"),Wsr=o("electra"),Qsr=o(" \u2014 "),JQ=a("a"),Usr=o("ElectraForQuestionAnswering"),Hsr=o(" (ELECTRA model)"),Jsr=l(),dF=a("li"),sbe=a("strong"),Ysr=o("flaubert"),Ksr=o(" \u2014 "),YQ=a("a"),Zsr=o("FlaubertForQuestionAnsweringSimple"),elr=o(" (FlauBERT model)"),olr=l(),cF=a("li"),lbe=a("strong"),rlr=o("fnet"),tlr=o(" \u2014 "),KQ=a("a"),alr=o("FNetForQuestionAnswering"),nlr=o(" (FNet model)"),slr=l(),fF=a("li"),ibe=a("strong"),llr=o("funnel"),ilr=o(" \u2014 "),ZQ=a("a"),dlr=o("FunnelForQuestionAnswering"),clr=o(" (Funnel Transformer model)"),flr=l(),mF=a("li"),dbe=a("strong"),mlr=o("gptj"),glr=o(" \u2014 "),eU=a("a"),hlr=o("GPTJForQuestionAnswering"),plr=o(" (GPT-J model)"),_lr=l(),gF=a("li"),cbe=a("strong"),ulr=o("ibert"),blr=o(" \u2014 "),oU=a("a"),vlr=o("IBertForQuestionAnswering"),Flr=o(" (I-BERT model)"),Tlr=l(),hF=a("li"),fbe=a("strong"),Mlr=o("layoutlmv2"),Elr=o(" \u2014 "),rU=a("a"),Clr=o("LayoutLMv2ForQuestionAnswering"),wlr=o(" (LayoutLMv2 model)"),Alr=l(),pF=a("li"),mbe=a("strong"),Llr=o("layoutlmv3"),ylr=o(" \u2014 "),tU=a("a"),xlr=o("LayoutLMv3ForQuestionAnswering"),$lr=o(" (LayoutLMv3 model)"),klr=l(),_F=a("li"),gbe=a("strong"),Slr=o("led"),Rlr=o(" \u2014 "),aU=a("a"),Plr=o("LEDForQuestionAnswering"),Blr=o(" (LED model)"),Ilr=l(),uF=a("li"),hbe=a("strong"),Nlr=o("longformer"),qlr=o(" \u2014 "),nU=a("a"),jlr=o("LongformerForQuestionAnswering"),Dlr=o(" (Longformer model)"),Glr=l(),bF=a("li"),pbe=a("strong"),Olr=o("luke"),Vlr=o(" \u2014 "),sU=a("a"),Xlr=o("LukeForQuestionAnswering"),zlr=o(" (LUKE model)"),Wlr=l(),vF=a("li"),_be=a("strong"),Qlr=o("lxmert"),Ulr=o(" \u2014 "),lU=a("a"),Hlr=o("LxmertForQuestionAnswering"),Jlr=o(" (LXMERT model)"),Ylr=l(),FF=a("li"),ube=a("strong"),Klr=o("mbart"),Zlr=o(" \u2014 "),iU=a("a"),eir=o("MBartForQuestionAnswering"),oir=o(" (mBART model)"),rir=l(),TF=a("li"),bbe=a("strong"),tir=o("megatron-bert"),air=o(" \u2014 "),dU=a("a"),nir=o("MegatronBertForQuestionAnswering"),sir=o(" (Megatron-BERT model)"),lir=l(),MF=a("li"),vbe=a("strong"),iir=o("mobilebert"),dir=o(" \u2014 "),cU=a("a"),cir=o("MobileBertForQuestionAnswering"),fir=o(" (MobileBERT model)"),mir=l(),EF=a("li"),Fbe=a("strong"),gir=o("mpnet"),hir=o(" \u2014 "),fU=a("a"),pir=o("MPNetForQuestionAnswering"),_ir=o(" (MPNet model)"),uir=l(),CF=a("li"),Tbe=a("strong"),bir=o("mvp"),vir=o(" \u2014 "),mU=a("a"),Fir=o("MvpForQuestionAnswering"),Tir=o(" (MVP model)"),Mir=l(),wF=a("li"),Mbe=a("strong"),Eir=o("nezha"),Cir=o(" \u2014 "),gU=a("a"),wir=o("NezhaForQuestionAnswering"),Air=o(" (Nezha model)"),Lir=l(),AF=a("li"),Ebe=a("strong"),yir=o("nystromformer"),xir=o(" \u2014 "),hU=a("a"),$ir=o("NystromformerForQuestionAnswering"),kir=o(" (Nystr\xF6mformer model)"),Sir=l(),LF=a("li"),Cbe=a("strong"),Rir=o("qdqbert"),Pir=o(" \u2014 "),pU=a("a"),Bir=o("QDQBertForQuestionAnswering"),Iir=o(" (QDQBert model)"),Nir=l(),yF=a("li"),wbe=a("strong"),qir=o("reformer"),jir=o(" \u2014 "),_U=a("a"),Dir=o("ReformerForQuestionAnswering"),Gir=o(" (Reformer model)"),Oir=l(),xF=a("li"),Abe=a("strong"),Vir=o("rembert"),Xir=o(" \u2014 "),uU=a("a"),zir=o("RemBertForQuestionAnswering"),Wir=o(" (RemBERT model)"),Qir=l(),$F=a("li"),Lbe=a("strong"),Uir=o("roberta"),Hir=o(" \u2014 "),bU=a("a"),Jir=o("RobertaForQuestionAnswering"),Yir=o(" (RoBERTa model)"),Kir=l(),kF=a("li"),ybe=a("strong"),Zir=o("roformer"),edr=o(" \u2014 "),vU=a("a"),odr=o("RoFormerForQuestionAnswering"),rdr=o(" (RoFormer model)"),tdr=l(),SF=a("li"),xbe=a("strong"),adr=o("splinter"),ndr=o(" \u2014 "),FU=a("a"),sdr=o("SplinterForQuestionAnswering"),ldr=o(" (Splinter model)"),idr=l(),RF=a("li"),$be=a("strong"),ddr=o("squeezebert"),cdr=o(" \u2014 "),TU=a("a"),fdr=o("SqueezeBertForQuestionAnswering"),mdr=o(" (SqueezeBERT model)"),gdr=l(),PF=a("li"),kbe=a("strong"),hdr=o("xlm"),pdr=o(" \u2014 "),MU=a("a"),_dr=o("XLMForQuestionAnsweringSimple"),udr=o(" (XLM model)"),bdr=l(),BF=a("li"),Sbe=a("strong"),vdr=o("xlm-roberta"),Fdr=o(" \u2014 "),EU=a("a"),Tdr=o("XLMRobertaForQuestionAnswering"),Mdr=o(" (XLM-RoBERTa model)"),Edr=l(),IF=a("li"),Rbe=a("strong"),Cdr=o("xlm-roberta-xl"),wdr=o(" \u2014 "),CU=a("a"),Adr=o("XLMRobertaXLForQuestionAnswering"),Ldr=o(" (XLM-RoBERTa-XL model)"),ydr=l(),NF=a("li"),Pbe=a("strong"),xdr=o("xlnet"),$dr=o(" \u2014 "),wU=a("a"),kdr=o("XLNetForQuestionAnsweringSimple"),Sdr=o(" (XLNet model)"),Rdr=l(),qF=a("li"),Bbe=a("strong"),Pdr=o("yoso"),Bdr=o(" \u2014 "),AU=a("a"),Idr=o("YosoForQuestionAnswering"),Ndr=o(" (YOSO model)"),qdr=l(),jF=a("p"),jdr=o("The model is set in evaluation mode by default using "),Ibe=a("code"),Ddr=o("model.eval()"),Gdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nbe=a("code"),Odr=o("model.train()"),Vdr=l(),F(DF.$$.fragment),bQe=l(),Ad=a("h2"),GF=a("a"),qbe=a("span"),F(p9.$$.fragment),Xdr=l(),jbe=a("span"),zdr=o("AutoModelForTableQuestionAnswering"),vQe=l(),Vo=a("div"),F(_9.$$.fragment),Wdr=l(),Ld=a("p"),Qdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),LU=a("a"),Udr=o("from_pretrained()"),Hdr=o(" class method or the "),yU=a("a"),Jdr=o("from_config()"),Ydr=o(` class
method.`),Kdr=l(),u9=a("p"),Zdr=o("This class cannot be instantiated directly using "),Dbe=a("code"),ecr=o("__init__()"),ocr=o(" (throws an error)."),rcr=l(),Ft=a("div"),F(b9.$$.fragment),tcr=l(),Gbe=a("p"),acr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),ncr=l(),yd=a("p"),scr=o(`Note:
Loading a model from its configuration file does `),Obe=a("strong"),lcr=o("not"),icr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=a("a"),dcr=o("from_pretrained()"),ccr=o(" to load the model weights."),fcr=l(),F(OF.$$.fragment),mcr=l(),lo=a("div"),F(v9.$$.fragment),gcr=l(),Vbe=a("p"),hcr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),pcr=l(),Ja=a("p"),_cr=o("The model class to instantiate is selected based on the "),Xbe=a("code"),ucr=o("model_type"),bcr=o(` property of the config object (either
passed as an argument or loaded from `),zbe=a("code"),vcr=o("pretrained_model_name_or_path"),Fcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wbe=a("code"),Tcr=o("pretrained_model_name_or_path"),Mcr=o(":"),Ecr=l(),Qbe=a("ul"),VF=a("li"),Ube=a("strong"),Ccr=o("tapas"),wcr=o(" \u2014 "),$U=a("a"),Acr=o("TapasForQuestionAnswering"),Lcr=o(" (TAPAS model)"),ycr=l(),XF=a("p"),xcr=o("The model is set in evaluation mode by default using "),Hbe=a("code"),$cr=o("model.eval()"),kcr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=a("code"),Scr=o("model.train()"),Rcr=l(),F(zF.$$.fragment),FQe=l(),xd=a("h2"),WF=a("a"),Ybe=a("span"),F(F9.$$.fragment),Pcr=l(),Kbe=a("span"),Bcr=o("AutoModelForImageClassification"),TQe=l(),Xo=a("div"),F(T9.$$.fragment),Icr=l(),$d=a("p"),Ncr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),kU=a("a"),qcr=o("from_pretrained()"),jcr=o(" class method or the "),SU=a("a"),Dcr=o("from_config()"),Gcr=o(` class
method.`),Ocr=l(),M9=a("p"),Vcr=o("This class cannot be instantiated directly using "),Zbe=a("code"),Xcr=o("__init__()"),zcr=o(" (throws an error)."),Wcr=l(),Tt=a("div"),F(E9.$$.fragment),Qcr=l(),eve=a("p"),Ucr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Hcr=l(),kd=a("p"),Jcr=o(`Note:
Loading a model from its configuration file does `),ove=a("strong"),Ycr=o("not"),Kcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=a("a"),Zcr=o("from_pretrained()"),efr=o(" to load the model weights."),ofr=l(),F(QF.$$.fragment),rfr=l(),io=a("div"),F(C9.$$.fragment),tfr=l(),rve=a("p"),afr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),nfr=l(),Ya=a("p"),sfr=o("The model class to instantiate is selected based on the "),tve=a("code"),lfr=o("model_type"),ifr=o(` property of the config object (either
passed as an argument or loaded from `),ave=a("code"),dfr=o("pretrained_model_name_or_path"),cfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=a("code"),ffr=o("pretrained_model_name_or_path"),mfr=o(":"),gfr=l(),be=a("ul"),UF=a("li"),sve=a("strong"),hfr=o("beit"),pfr=o(" \u2014 "),PU=a("a"),_fr=o("BeitForImageClassification"),ufr=o(" (BEiT model)"),bfr=l(),HF=a("li"),lve=a("strong"),vfr=o("convnext"),Ffr=o(" \u2014 "),BU=a("a"),Tfr=o("ConvNextForImageClassification"),Mfr=o(" (ConvNeXT model)"),Efr=l(),JF=a("li"),ive=a("strong"),Cfr=o("cvt"),wfr=o(" \u2014 "),IU=a("a"),Afr=o("CvtForImageClassification"),Lfr=o(" (CvT model)"),yfr=l(),YF=a("li"),dve=a("strong"),xfr=o("data2vec-vision"),$fr=o(" \u2014 "),NU=a("a"),kfr=o("Data2VecVisionForImageClassification"),Sfr=o(" (Data2VecVision model)"),Rfr=l(),rl=a("li"),cve=a("strong"),Pfr=o("deit"),Bfr=o(" \u2014 "),qU=a("a"),Ifr=o("DeiTForImageClassification"),Nfr=o(" or "),jU=a("a"),qfr=o("DeiTForImageClassificationWithTeacher"),jfr=o(" (DeiT model)"),Dfr=l(),KF=a("li"),fve=a("strong"),Gfr=o("imagegpt"),Ofr=o(" \u2014 "),DU=a("a"),Vfr=o("ImageGPTForImageClassification"),Xfr=o(" (ImageGPT model)"),zfr=l(),tl=a("li"),mve=a("strong"),Wfr=o("levit"),Qfr=o(" \u2014 "),GU=a("a"),Ufr=o("LevitForImageClassification"),Hfr=o(" or "),OU=a("a"),Jfr=o("LevitForImageClassificationWithTeacher"),Yfr=o(" (LeViT model)"),Kfr=l(),ZF=a("li"),gve=a("strong"),Zfr=o("mobilevit"),emr=o(" \u2014 "),VU=a("a"),omr=o("MobileViTForImageClassification"),rmr=o(" (MobileViT model)"),tmr=l(),Mt=a("li"),hve=a("strong"),amr=o("perceiver"),nmr=o(" \u2014 "),XU=a("a"),smr=o("PerceiverForImageClassificationLearned"),lmr=o(" or "),zU=a("a"),imr=o("PerceiverForImageClassificationFourier"),dmr=o(" or "),WU=a("a"),cmr=o("PerceiverForImageClassificationConvProcessing"),fmr=o(" (Perceiver model)"),mmr=l(),eT=a("li"),pve=a("strong"),gmr=o("poolformer"),hmr=o(" \u2014 "),QU=a("a"),pmr=o("PoolFormerForImageClassification"),_mr=o(" (PoolFormer model)"),umr=l(),oT=a("li"),_ve=a("strong"),bmr=o("regnet"),vmr=o(" \u2014 "),UU=a("a"),Fmr=o("RegNetForImageClassification"),Tmr=o(" (RegNet model)"),Mmr=l(),rT=a("li"),uve=a("strong"),Emr=o("resnet"),Cmr=o(" \u2014 "),HU=a("a"),wmr=o("ResNetForImageClassification"),Amr=o(" (ResNet model)"),Lmr=l(),tT=a("li"),bve=a("strong"),ymr=o("segformer"),xmr=o(" \u2014 "),JU=a("a"),$mr=o("SegformerForImageClassification"),kmr=o(" (SegFormer model)"),Smr=l(),aT=a("li"),vve=a("strong"),Rmr=o("swin"),Pmr=o(" \u2014 "),YU=a("a"),Bmr=o("SwinForImageClassification"),Imr=o(" (Swin Transformer model)"),Nmr=l(),nT=a("li"),Fve=a("strong"),qmr=o("swinv2"),jmr=o(" \u2014 "),KU=a("a"),Dmr=o("Swinv2ForImageClassification"),Gmr=o(" (Swin Transformer V2 model)"),Omr=l(),sT=a("li"),Tve=a("strong"),Vmr=o("van"),Xmr=o(" \u2014 "),ZU=a("a"),zmr=o("VanForImageClassification"),Wmr=o(" (VAN model)"),Qmr=l(),lT=a("li"),Mve=a("strong"),Umr=o("vit"),Hmr=o(" \u2014 "),eH=a("a"),Jmr=o("ViTForImageClassification"),Ymr=o(" (ViT model)"),Kmr=l(),iT=a("p"),Zmr=o("The model is set in evaluation mode by default using "),Eve=a("code"),egr=o("model.eval()"),ogr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cve=a("code"),rgr=o("model.train()"),tgr=l(),F(dT.$$.fragment),MQe=l(),Sd=a("h2"),cT=a("a"),wve=a("span"),F(w9.$$.fragment),agr=l(),Ave=a("span"),ngr=o("AutoModelForVideoClassification"),EQe=l(),zo=a("div"),F(A9.$$.fragment),sgr=l(),Rd=a("p"),lgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),oH=a("a"),igr=o("from_pretrained()"),dgr=o(" class method or the "),rH=a("a"),cgr=o("from_config()"),fgr=o(` class
method.`),mgr=l(),L9=a("p"),ggr=o("This class cannot be instantiated directly using "),Lve=a("code"),hgr=o("__init__()"),pgr=o(" (throws an error)."),_gr=l(),Et=a("div"),F(y9.$$.fragment),ugr=l(),yve=a("p"),bgr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),vgr=l(),Pd=a("p"),Fgr=o(`Note:
Loading a model from its configuration file does `),xve=a("strong"),Tgr=o("not"),Mgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=a("a"),Egr=o("from_pretrained()"),Cgr=o(" to load the model weights."),wgr=l(),F(fT.$$.fragment),Agr=l(),co=a("div"),F(x9.$$.fragment),Lgr=l(),$ve=a("p"),ygr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),xgr=l(),Ka=a("p"),$gr=o("The model class to instantiate is selected based on the "),kve=a("code"),kgr=o("model_type"),Sgr=o(` property of the config object (either
passed as an argument or loaded from `),Sve=a("code"),Rgr=o("pretrained_model_name_or_path"),Pgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rve=a("code"),Bgr=o("pretrained_model_name_or_path"),Igr=o(":"),Ngr=l(),Pve=a("ul"),mT=a("li"),Bve=a("strong"),qgr=o("videomae"),jgr=o(" \u2014 "),aH=a("a"),Dgr=o("VideoMAEForVideoClassification"),Ggr=o(" (VideoMAE model)"),Ogr=l(),gT=a("p"),Vgr=o("The model is set in evaluation mode by default using "),Ive=a("code"),Xgr=o("model.eval()"),zgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nve=a("code"),Wgr=o("model.train()"),Qgr=l(),F(hT.$$.fragment),CQe=l(),Bd=a("h2"),pT=a("a"),qve=a("span"),F($9.$$.fragment),Ugr=l(),jve=a("span"),Hgr=o("AutoModelForVision2Seq"),wQe=l(),Wo=a("div"),F(k9.$$.fragment),Jgr=l(),Id=a("p"),Ygr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),nH=a("a"),Kgr=o("from_pretrained()"),Zgr=o(" class method or the "),sH=a("a"),ehr=o("from_config()"),ohr=o(` class
method.`),rhr=l(),S9=a("p"),thr=o("This class cannot be instantiated directly using "),Dve=a("code"),ahr=o("__init__()"),nhr=o(" (throws an error)."),shr=l(),Ct=a("div"),F(R9.$$.fragment),lhr=l(),Gve=a("p"),ihr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dhr=l(),Nd=a("p"),chr=o(`Note:
Loading a model from its configuration file does `),Ove=a("strong"),fhr=o("not"),mhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lH=a("a"),ghr=o("from_pretrained()"),hhr=o(" to load the model weights."),phr=l(),F(_T.$$.fragment),_hr=l(),fo=a("div"),F(P9.$$.fragment),uhr=l(),Vve=a("p"),bhr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),vhr=l(),Za=a("p"),Fhr=o("The model class to instantiate is selected based on the "),Xve=a("code"),Thr=o("model_type"),Mhr=o(` property of the config object (either
passed as an argument or loaded from `),zve=a("code"),Ehr=o("pretrained_model_name_or_path"),Chr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wve=a("code"),whr=o("pretrained_model_name_or_path"),Ahr=o(":"),Lhr=l(),Qve=a("ul"),uT=a("li"),Uve=a("strong"),yhr=o("vision-encoder-decoder"),xhr=o(" \u2014 "),iH=a("a"),$hr=o("VisionEncoderDecoderModel"),khr=o(" (Vision Encoder decoder model)"),Shr=l(),bT=a("p"),Rhr=o("The model is set in evaluation mode by default using "),Hve=a("code"),Phr=o("model.eval()"),Bhr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jve=a("code"),Ihr=o("model.train()"),Nhr=l(),F(vT.$$.fragment),AQe=l(),qd=a("h2"),FT=a("a"),Yve=a("span"),F(B9.$$.fragment),qhr=l(),Kve=a("span"),jhr=o("AutoModelForVisualQuestionAnswering"),LQe=l(),Qo=a("div"),F(I9.$$.fragment),Dhr=l(),jd=a("p"),Ghr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),dH=a("a"),Ohr=o("from_pretrained()"),Vhr=o(" class method or the "),cH=a("a"),Xhr=o("from_config()"),zhr=o(` class
method.`),Whr=l(),N9=a("p"),Qhr=o("This class cannot be instantiated directly using "),Zve=a("code"),Uhr=o("__init__()"),Hhr=o(" (throws an error)."),Jhr=l(),wt=a("div"),F(q9.$$.fragment),Yhr=l(),e5e=a("p"),Khr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Zhr=l(),Dd=a("p"),epr=o(`Note:
Loading a model from its configuration file does `),o5e=a("strong"),opr=o("not"),rpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fH=a("a"),tpr=o("from_pretrained()"),apr=o(" to load the model weights."),npr=l(),F(TT.$$.fragment),spr=l(),mo=a("div"),F(j9.$$.fragment),lpr=l(),r5e=a("p"),ipr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),dpr=l(),en=a("p"),cpr=o("The model class to instantiate is selected based on the "),t5e=a("code"),fpr=o("model_type"),mpr=o(` property of the config object (either
passed as an argument or loaded from `),a5e=a("code"),gpr=o("pretrained_model_name_or_path"),hpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n5e=a("code"),ppr=o("pretrained_model_name_or_path"),_pr=o(":"),upr=l(),s5e=a("ul"),MT=a("li"),l5e=a("strong"),bpr=o("vilt"),vpr=o(" \u2014 "),mH=a("a"),Fpr=o("ViltForQuestionAnswering"),Tpr=o(" (ViLT model)"),Mpr=l(),ET=a("p"),Epr=o("The model is set in evaluation mode by default using "),i5e=a("code"),Cpr=o("model.eval()"),wpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),d5e=a("code"),Apr=o("model.train()"),Lpr=l(),F(CT.$$.fragment),yQe=l(),Gd=a("h2"),wT=a("a"),c5e=a("span"),F(D9.$$.fragment),ypr=l(),f5e=a("span"),xpr=o("AutoModelForAudioClassification"),xQe=l(),Uo=a("div"),F(G9.$$.fragment),$pr=l(),Od=a("p"),kpr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),gH=a("a"),Spr=o("from_pretrained()"),Rpr=o(" class method or the "),hH=a("a"),Ppr=o("from_config()"),Bpr=o(` class
method.`),Ipr=l(),O9=a("p"),Npr=o("This class cannot be instantiated directly using "),m5e=a("code"),qpr=o("__init__()"),jpr=o(" (throws an error)."),Dpr=l(),At=a("div"),F(V9.$$.fragment),Gpr=l(),g5e=a("p"),Opr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Vpr=l(),Vd=a("p"),Xpr=o(`Note:
Loading a model from its configuration file does `),h5e=a("strong"),zpr=o("not"),Wpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pH=a("a"),Qpr=o("from_pretrained()"),Upr=o(" to load the model weights."),Hpr=l(),F(AT.$$.fragment),Jpr=l(),go=a("div"),F(X9.$$.fragment),Ypr=l(),p5e=a("p"),Kpr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Zpr=l(),on=a("p"),e_r=o("The model class to instantiate is selected based on the "),_5e=a("code"),o_r=o("model_type"),r_r=o(` property of the config object (either
passed as an argument or loaded from `),u5e=a("code"),t_r=o("pretrained_model_name_or_path"),a_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b5e=a("code"),n_r=o("pretrained_model_name_or_path"),s_r=o(":"),l_r=l(),Pe=a("ul"),LT=a("li"),v5e=a("strong"),i_r=o("data2vec-audio"),d_r=o(" \u2014 "),_H=a("a"),c_r=o("Data2VecAudioForSequenceClassification"),f_r=o(" (Data2VecAudio model)"),m_r=l(),yT=a("li"),F5e=a("strong"),g_r=o("hubert"),h_r=o(" \u2014 "),uH=a("a"),p_r=o("HubertForSequenceClassification"),__r=o(" (Hubert model)"),u_r=l(),xT=a("li"),T5e=a("strong"),b_r=o("sew"),v_r=o(" \u2014 "),bH=a("a"),F_r=o("SEWForSequenceClassification"),T_r=o(" (SEW model)"),M_r=l(),$T=a("li"),M5e=a("strong"),E_r=o("sew-d"),C_r=o(" \u2014 "),vH=a("a"),w_r=o("SEWDForSequenceClassification"),A_r=o(" (SEW-D model)"),L_r=l(),kT=a("li"),E5e=a("strong"),y_r=o("unispeech"),x_r=o(" \u2014 "),FH=a("a"),$_r=o("UniSpeechForSequenceClassification"),k_r=o(" (UniSpeech model)"),S_r=l(),ST=a("li"),C5e=a("strong"),R_r=o("unispeech-sat"),P_r=o(" \u2014 "),TH=a("a"),B_r=o("UniSpeechSatForSequenceClassification"),I_r=o(" (UniSpeechSat model)"),N_r=l(),RT=a("li"),w5e=a("strong"),q_r=o("wav2vec2"),j_r=o(" \u2014 "),MH=a("a"),D_r=o("Wav2Vec2ForSequenceClassification"),G_r=o(" (Wav2Vec2 model)"),O_r=l(),PT=a("li"),A5e=a("strong"),V_r=o("wav2vec2-conformer"),X_r=o(" \u2014 "),EH=a("a"),z_r=o("Wav2Vec2ConformerForSequenceClassification"),W_r=o(" (Wav2Vec2-Conformer model)"),Q_r=l(),BT=a("li"),L5e=a("strong"),U_r=o("wavlm"),H_r=o(" \u2014 "),CH=a("a"),J_r=o("WavLMForSequenceClassification"),Y_r=o(" (WavLM model)"),K_r=l(),IT=a("p"),Z_r=o("The model is set in evaluation mode by default using "),y5e=a("code"),eur=o("model.eval()"),our=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x5e=a("code"),rur=o("model.train()"),tur=l(),F(NT.$$.fragment),$Qe=l(),Xd=a("h2"),qT=a("a"),$5e=a("span"),F(z9.$$.fragment),aur=l(),k5e=a("span"),nur=o("AutoModelForAudioFrameClassification"),kQe=l(),Ho=a("div"),F(W9.$$.fragment),sur=l(),zd=a("p"),lur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),wH=a("a"),iur=o("from_pretrained()"),dur=o(" class method or the "),AH=a("a"),cur=o("from_config()"),fur=o(` class
method.`),mur=l(),Q9=a("p"),gur=o("This class cannot be instantiated directly using "),S5e=a("code"),hur=o("__init__()"),pur=o(" (throws an error)."),_ur=l(),Lt=a("div"),F(U9.$$.fragment),uur=l(),R5e=a("p"),bur=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),vur=l(),Wd=a("p"),Fur=o(`Note:
Loading a model from its configuration file does `),P5e=a("strong"),Tur=o("not"),Mur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LH=a("a"),Eur=o("from_pretrained()"),Cur=o(" to load the model weights."),wur=l(),F(jT.$$.fragment),Aur=l(),ho=a("div"),F(H9.$$.fragment),Lur=l(),B5e=a("p"),yur=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),xur=l(),rn=a("p"),$ur=o("The model class to instantiate is selected based on the "),I5e=a("code"),kur=o("model_type"),Sur=o(` property of the config object (either
passed as an argument or loaded from `),N5e=a("code"),Rur=o("pretrained_model_name_or_path"),Pur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q5e=a("code"),Bur=o("pretrained_model_name_or_path"),Iur=o(":"),Nur=l(),at=a("ul"),DT=a("li"),j5e=a("strong"),qur=o("data2vec-audio"),jur=o(" \u2014 "),yH=a("a"),Dur=o("Data2VecAudioForAudioFrameClassification"),Gur=o(" (Data2VecAudio model)"),Our=l(),GT=a("li"),D5e=a("strong"),Vur=o("unispeech-sat"),Xur=o(" \u2014 "),xH=a("a"),zur=o("UniSpeechSatForAudioFrameClassification"),Wur=o(" (UniSpeechSat model)"),Qur=l(),OT=a("li"),G5e=a("strong"),Uur=o("wav2vec2"),Hur=o(" \u2014 "),$H=a("a"),Jur=o("Wav2Vec2ForAudioFrameClassification"),Yur=o(" (Wav2Vec2 model)"),Kur=l(),VT=a("li"),O5e=a("strong"),Zur=o("wav2vec2-conformer"),e2r=o(" \u2014 "),kH=a("a"),o2r=o("Wav2Vec2ConformerForAudioFrameClassification"),r2r=o(" (Wav2Vec2-Conformer model)"),t2r=l(),XT=a("li"),V5e=a("strong"),a2r=o("wavlm"),n2r=o(" \u2014 "),SH=a("a"),s2r=o("WavLMForAudioFrameClassification"),l2r=o(" (WavLM model)"),i2r=l(),zT=a("p"),d2r=o("The model is set in evaluation mode by default using "),X5e=a("code"),c2r=o("model.eval()"),f2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z5e=a("code"),m2r=o("model.train()"),g2r=l(),F(WT.$$.fragment),SQe=l(),Qd=a("h2"),QT=a("a"),W5e=a("span"),F(J9.$$.fragment),h2r=l(),Q5e=a("span"),p2r=o("AutoModelForCTC"),RQe=l(),Jo=a("div"),F(Y9.$$.fragment),_2r=l(),Ud=a("p"),u2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),RH=a("a"),b2r=o("from_pretrained()"),v2r=o(" class method or the "),PH=a("a"),F2r=o("from_config()"),T2r=o(` class
method.`),M2r=l(),K9=a("p"),E2r=o("This class cannot be instantiated directly using "),U5e=a("code"),C2r=o("__init__()"),w2r=o(" (throws an error)."),A2r=l(),yt=a("div"),F(Z9.$$.fragment),L2r=l(),H5e=a("p"),y2r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),x2r=l(),Hd=a("p"),$2r=o(`Note:
Loading a model from its configuration file does `),J5e=a("strong"),k2r=o("not"),S2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BH=a("a"),R2r=o("from_pretrained()"),P2r=o(" to load the model weights."),B2r=l(),F(UT.$$.fragment),I2r=l(),po=a("div"),F(ex.$$.fragment),N2r=l(),Y5e=a("p"),q2r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),j2r=l(),tn=a("p"),D2r=o("The model class to instantiate is selected based on the "),K5e=a("code"),G2r=o("model_type"),O2r=o(` property of the config object (either
passed as an argument or loaded from `),Z5e=a("code"),V2r=o("pretrained_model_name_or_path"),X2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eFe=a("code"),z2r=o("pretrained_model_name_or_path"),W2r=o(":"),Q2r=l(),Le=a("ul"),HT=a("li"),oFe=a("strong"),U2r=o("data2vec-audio"),H2r=o(" \u2014 "),IH=a("a"),J2r=o("Data2VecAudioForCTC"),Y2r=o(" (Data2VecAudio model)"),K2r=l(),JT=a("li"),rFe=a("strong"),Z2r=o("hubert"),e1r=o(" \u2014 "),NH=a("a"),o1r=o("HubertForCTC"),r1r=o(" (Hubert model)"),t1r=l(),YT=a("li"),tFe=a("strong"),a1r=o("mctct"),n1r=o(" \u2014 "),qH=a("a"),s1r=o("MCTCTForCTC"),l1r=o(" (M-CTC-T model)"),i1r=l(),KT=a("li"),aFe=a("strong"),d1r=o("sew"),c1r=o(" \u2014 "),jH=a("a"),f1r=o("SEWForCTC"),m1r=o(" (SEW model)"),g1r=l(),ZT=a("li"),nFe=a("strong"),h1r=o("sew-d"),p1r=o(" \u2014 "),DH=a("a"),_1r=o("SEWDForCTC"),u1r=o(" (SEW-D model)"),b1r=l(),e8=a("li"),sFe=a("strong"),v1r=o("unispeech"),F1r=o(" \u2014 "),GH=a("a"),T1r=o("UniSpeechForCTC"),M1r=o(" (UniSpeech model)"),E1r=l(),o8=a("li"),lFe=a("strong"),C1r=o("unispeech-sat"),w1r=o(" \u2014 "),OH=a("a"),A1r=o("UniSpeechSatForCTC"),L1r=o(" (UniSpeechSat model)"),y1r=l(),r8=a("li"),iFe=a("strong"),x1r=o("wav2vec2"),$1r=o(" \u2014 "),VH=a("a"),k1r=o("Wav2Vec2ForCTC"),S1r=o(" (Wav2Vec2 model)"),R1r=l(),t8=a("li"),dFe=a("strong"),P1r=o("wav2vec2-conformer"),B1r=o(" \u2014 "),XH=a("a"),I1r=o("Wav2Vec2ConformerForCTC"),N1r=o(" (Wav2Vec2-Conformer model)"),q1r=l(),a8=a("li"),cFe=a("strong"),j1r=o("wavlm"),D1r=o(" \u2014 "),zH=a("a"),G1r=o("WavLMForCTC"),O1r=o(" (WavLM model)"),V1r=l(),n8=a("p"),X1r=o("The model is set in evaluation mode by default using "),fFe=a("code"),z1r=o("model.eval()"),W1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mFe=a("code"),Q1r=o("model.train()"),U1r=l(),F(s8.$$.fragment),PQe=l(),Jd=a("h2"),l8=a("a"),gFe=a("span"),F(ox.$$.fragment),H1r=l(),hFe=a("span"),J1r=o("AutoModelForSpeechSeq2Seq"),BQe=l(),Yo=a("div"),F(rx.$$.fragment),Y1r=l(),Yd=a("p"),K1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),WH=a("a"),Z1r=o("from_pretrained()"),e4r=o(" class method or the "),QH=a("a"),o4r=o("from_config()"),r4r=o(` class
method.`),t4r=l(),tx=a("p"),a4r=o("This class cannot be instantiated directly using "),pFe=a("code"),n4r=o("__init__()"),s4r=o(" (throws an error)."),l4r=l(),xt=a("div"),F(ax.$$.fragment),i4r=l(),_Fe=a("p"),d4r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),c4r=l(),Kd=a("p"),f4r=o(`Note:
Loading a model from its configuration file does `),uFe=a("strong"),m4r=o("not"),g4r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UH=a("a"),h4r=o("from_pretrained()"),p4r=o(" to load the model weights."),_4r=l(),F(i8.$$.fragment),u4r=l(),_o=a("div"),F(nx.$$.fragment),b4r=l(),bFe=a("p"),v4r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),F4r=l(),an=a("p"),T4r=o("The model class to instantiate is selected based on the "),vFe=a("code"),M4r=o("model_type"),E4r=o(` property of the config object (either
passed as an argument or loaded from `),FFe=a("code"),C4r=o("pretrained_model_name_or_path"),w4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TFe=a("code"),A4r=o("pretrained_model_name_or_path"),L4r=o(":"),y4r=l(),sx=a("ul"),d8=a("li"),MFe=a("strong"),x4r=o("speech-encoder-decoder"),$4r=o(" \u2014 "),HH=a("a"),k4r=o("SpeechEncoderDecoderModel"),S4r=o(" (Speech Encoder decoder model)"),R4r=l(),c8=a("li"),EFe=a("strong"),P4r=o("speech_to_text"),B4r=o(" \u2014 "),JH=a("a"),I4r=o("Speech2TextForConditionalGeneration"),N4r=o(" (Speech2Text model)"),q4r=l(),f8=a("p"),j4r=o("The model is set in evaluation mode by default using "),CFe=a("code"),D4r=o("model.eval()"),G4r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wFe=a("code"),O4r=o("model.train()"),V4r=l(),F(m8.$$.fragment),IQe=l(),Zd=a("h2"),g8=a("a"),AFe=a("span"),F(lx.$$.fragment),X4r=l(),LFe=a("span"),z4r=o("AutoModelForAudioXVector"),NQe=l(),Ko=a("div"),F(ix.$$.fragment),W4r=l(),ec=a("p"),Q4r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),YH=a("a"),U4r=o("from_pretrained()"),H4r=o(" class method or the "),KH=a("a"),J4r=o("from_config()"),Y4r=o(` class
method.`),K4r=l(),dx=a("p"),Z4r=o("This class cannot be instantiated directly using "),yFe=a("code"),ebr=o("__init__()"),obr=o(" (throws an error)."),rbr=l(),$t=a("div"),F(cx.$$.fragment),tbr=l(),xFe=a("p"),abr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),nbr=l(),oc=a("p"),sbr=o(`Note:
Loading a model from its configuration file does `),$Fe=a("strong"),lbr=o("not"),ibr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZH=a("a"),dbr=o("from_pretrained()"),cbr=o(" to load the model weights."),fbr=l(),F(h8.$$.fragment),mbr=l(),uo=a("div"),F(fx.$$.fragment),gbr=l(),kFe=a("p"),hbr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),pbr=l(),nn=a("p"),_br=o("The model class to instantiate is selected based on the "),SFe=a("code"),ubr=o("model_type"),bbr=o(` property of the config object (either
passed as an argument or loaded from `),RFe=a("code"),vbr=o("pretrained_model_name_or_path"),Fbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PFe=a("code"),Tbr=o("pretrained_model_name_or_path"),Mbr=o(":"),Ebr=l(),nt=a("ul"),p8=a("li"),BFe=a("strong"),Cbr=o("data2vec-audio"),wbr=o(" \u2014 "),eJ=a("a"),Abr=o("Data2VecAudioForXVector"),Lbr=o(" (Data2VecAudio model)"),ybr=l(),_8=a("li"),IFe=a("strong"),xbr=o("unispeech-sat"),$br=o(" \u2014 "),oJ=a("a"),kbr=o("UniSpeechSatForXVector"),Sbr=o(" (UniSpeechSat model)"),Rbr=l(),u8=a("li"),NFe=a("strong"),Pbr=o("wav2vec2"),Bbr=o(" \u2014 "),rJ=a("a"),Ibr=o("Wav2Vec2ForXVector"),Nbr=o(" (Wav2Vec2 model)"),qbr=l(),b8=a("li"),qFe=a("strong"),jbr=o("wav2vec2-conformer"),Dbr=o(" \u2014 "),tJ=a("a"),Gbr=o("Wav2Vec2ConformerForXVector"),Obr=o(" (Wav2Vec2-Conformer model)"),Vbr=l(),v8=a("li"),jFe=a("strong"),Xbr=o("wavlm"),zbr=o(" \u2014 "),aJ=a("a"),Wbr=o("WavLMForXVector"),Qbr=o(" (WavLM model)"),Ubr=l(),F8=a("p"),Hbr=o("The model is set in evaluation mode by default using "),DFe=a("code"),Jbr=o("model.eval()"),Ybr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),GFe=a("code"),Kbr=o("model.train()"),Zbr=l(),F(T8.$$.fragment),qQe=l(),rc=a("h2"),M8=a("a"),OFe=a("span"),F(mx.$$.fragment),evr=l(),VFe=a("span"),ovr=o("AutoModelForMaskedImageModeling"),jQe=l(),Zo=a("div"),F(gx.$$.fragment),rvr=l(),tc=a("p"),tvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),nJ=a("a"),avr=o("from_pretrained()"),nvr=o(" class method or the "),sJ=a("a"),svr=o("from_config()"),lvr=o(` class
method.`),ivr=l(),hx=a("p"),dvr=o("This class cannot be instantiated directly using "),XFe=a("code"),cvr=o("__init__()"),fvr=o(" (throws an error)."),mvr=l(),kt=a("div"),F(px.$$.fragment),gvr=l(),zFe=a("p"),hvr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),pvr=l(),ac=a("p"),_vr=o(`Note:
Loading a model from its configuration file does `),WFe=a("strong"),uvr=o("not"),bvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lJ=a("a"),vvr=o("from_pretrained()"),Fvr=o(" to load the model weights."),Tvr=l(),F(E8.$$.fragment),Mvr=l(),bo=a("div"),F(_x.$$.fragment),Evr=l(),QFe=a("p"),Cvr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),wvr=l(),sn=a("p"),Avr=o("The model class to instantiate is selected based on the "),UFe=a("code"),Lvr=o("model_type"),yvr=o(` property of the config object (either
passed as an argument or loaded from `),HFe=a("code"),xvr=o("pretrained_model_name_or_path"),$vr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JFe=a("code"),kvr=o("pretrained_model_name_or_path"),Svr=o(":"),Rvr=l(),ln=a("ul"),C8=a("li"),YFe=a("strong"),Pvr=o("deit"),Bvr=o(" \u2014 "),iJ=a("a"),Ivr=o("DeiTForMaskedImageModeling"),Nvr=o(" (DeiT model)"),qvr=l(),w8=a("li"),KFe=a("strong"),jvr=o("swin"),Dvr=o(" \u2014 "),dJ=a("a"),Gvr=o("SwinForMaskedImageModeling"),Ovr=o(" (Swin Transformer model)"),Vvr=l(),A8=a("li"),ZFe=a("strong"),Xvr=o("swinv2"),zvr=o(" \u2014 "),cJ=a("a"),Wvr=o("Swinv2ForMaskedImageModeling"),Qvr=o(" (Swin Transformer V2 model)"),Uvr=l(),L8=a("li"),eTe=a("strong"),Hvr=o("vit"),Jvr=o(" \u2014 "),fJ=a("a"),Yvr=o("ViTForMaskedImageModeling"),Kvr=o(" (ViT model)"),Zvr=l(),y8=a("p"),e5r=o("The model is set in evaluation mode by default using "),oTe=a("code"),o5r=o("model.eval()"),r5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rTe=a("code"),t5r=o("model.train()"),a5r=l(),F(x8.$$.fragment),DQe=l(),nc=a("h2"),$8=a("a"),tTe=a("span"),F(ux.$$.fragment),n5r=l(),aTe=a("span"),s5r=o("AutoModelForObjectDetection"),GQe=l(),er=a("div"),F(bx.$$.fragment),l5r=l(),sc=a("p"),i5r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),mJ=a("a"),d5r=o("from_pretrained()"),c5r=o(" class method or the "),gJ=a("a"),f5r=o("from_config()"),m5r=o(` class
method.`),g5r=l(),vx=a("p"),h5r=o("This class cannot be instantiated directly using "),nTe=a("code"),p5r=o("__init__()"),_5r=o(" (throws an error)."),u5r=l(),St=a("div"),F(Fx.$$.fragment),b5r=l(),sTe=a("p"),v5r=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),F5r=l(),lc=a("p"),T5r=o(`Note:
Loading a model from its configuration file does `),lTe=a("strong"),M5r=o("not"),E5r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hJ=a("a"),C5r=o("from_pretrained()"),w5r=o(" to load the model weights."),A5r=l(),F(k8.$$.fragment),L5r=l(),vo=a("div"),F(Tx.$$.fragment),y5r=l(),iTe=a("p"),x5r=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),$5r=l(),dn=a("p"),k5r=o("The model class to instantiate is selected based on the "),dTe=a("code"),S5r=o("model_type"),R5r=o(` property of the config object (either
passed as an argument or loaded from `),cTe=a("code"),P5r=o("pretrained_model_name_or_path"),B5r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fTe=a("code"),I5r=o("pretrained_model_name_or_path"),N5r=o(":"),q5r=l(),Mx=a("ul"),S8=a("li"),mTe=a("strong"),j5r=o("detr"),D5r=o(" \u2014 "),pJ=a("a"),G5r=o("DetrForObjectDetection"),O5r=o(" (DETR model)"),V5r=l(),R8=a("li"),gTe=a("strong"),X5r=o("yolos"),z5r=o(" \u2014 "),_J=a("a"),W5r=o("YolosForObjectDetection"),Q5r=o(" (YOLOS model)"),U5r=l(),P8=a("p"),H5r=o("The model is set in evaluation mode by default using "),hTe=a("code"),J5r=o("model.eval()"),Y5r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pTe=a("code"),K5r=o("model.train()"),Z5r=l(),F(B8.$$.fragment),OQe=l(),ic=a("h2"),I8=a("a"),_Te=a("span"),F(Ex.$$.fragment),eFr=l(),uTe=a("span"),oFr=o("AutoModelForImageSegmentation"),VQe=l(),or=a("div"),F(Cx.$$.fragment),rFr=l(),dc=a("p"),tFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),uJ=a("a"),aFr=o("from_pretrained()"),nFr=o(" class method or the "),bJ=a("a"),sFr=o("from_config()"),lFr=o(` class
method.`),iFr=l(),wx=a("p"),dFr=o("This class cannot be instantiated directly using "),bTe=a("code"),cFr=o("__init__()"),fFr=o(" (throws an error)."),mFr=l(),Rt=a("div"),F(Ax.$$.fragment),gFr=l(),vTe=a("p"),hFr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),pFr=l(),cc=a("p"),_Fr=o(`Note:
Loading a model from its configuration file does `),FTe=a("strong"),uFr=o("not"),bFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=a("a"),vFr=o("from_pretrained()"),FFr=o(" to load the model weights."),TFr=l(),F(N8.$$.fragment),MFr=l(),Fo=a("div"),F(Lx.$$.fragment),EFr=l(),TTe=a("p"),CFr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),wFr=l(),cn=a("p"),AFr=o("The model class to instantiate is selected based on the "),MTe=a("code"),LFr=o("model_type"),yFr=o(` property of the config object (either
passed as an argument or loaded from `),ETe=a("code"),xFr=o("pretrained_model_name_or_path"),$Fr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CTe=a("code"),kFr=o("pretrained_model_name_or_path"),SFr=o(":"),RFr=l(),wTe=a("ul"),q8=a("li"),ATe=a("strong"),PFr=o("detr"),BFr=o(" \u2014 "),FJ=a("a"),IFr=o("DetrForSegmentation"),NFr=o(" (DETR model)"),qFr=l(),j8=a("p"),jFr=o("The model is set in evaluation mode by default using "),LTe=a("code"),DFr=o("model.eval()"),GFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yTe=a("code"),OFr=o("model.train()"),VFr=l(),F(D8.$$.fragment),XQe=l(),fc=a("h2"),G8=a("a"),xTe=a("span"),F(yx.$$.fragment),XFr=l(),$Te=a("span"),zFr=o("AutoModelForSemanticSegmentation"),zQe=l(),rr=a("div"),F(xx.$$.fragment),WFr=l(),mc=a("p"),QFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),TJ=a("a"),UFr=o("from_pretrained()"),HFr=o(" class method or the "),MJ=a("a"),JFr=o("from_config()"),YFr=o(` class
method.`),KFr=l(),$x=a("p"),ZFr=o("This class cannot be instantiated directly using "),kTe=a("code"),eTr=o("__init__()"),oTr=o(" (throws an error)."),rTr=l(),Pt=a("div"),F(kx.$$.fragment),tTr=l(),STe=a("p"),aTr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),nTr=l(),gc=a("p"),sTr=o(`Note:
Loading a model from its configuration file does `),RTe=a("strong"),lTr=o("not"),iTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EJ=a("a"),dTr=o("from_pretrained()"),cTr=o(" to load the model weights."),fTr=l(),F(O8.$$.fragment),mTr=l(),To=a("div"),F(Sx.$$.fragment),gTr=l(),PTe=a("p"),hTr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),pTr=l(),fn=a("p"),_Tr=o("The model class to instantiate is selected based on the "),BTe=a("code"),uTr=o("model_type"),bTr=o(` property of the config object (either
passed as an argument or loaded from `),ITe=a("code"),vTr=o("pretrained_model_name_or_path"),FTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NTe=a("code"),TTr=o("pretrained_model_name_or_path"),MTr=o(":"),ETr=l(),st=a("ul"),V8=a("li"),qTe=a("strong"),CTr=o("beit"),wTr=o(" \u2014 "),CJ=a("a"),ATr=o("BeitForSemanticSegmentation"),LTr=o(" (BEiT model)"),yTr=l(),X8=a("li"),jTe=a("strong"),xTr=o("data2vec-vision"),$Tr=o(" \u2014 "),wJ=a("a"),kTr=o("Data2VecVisionForSemanticSegmentation"),STr=o(" (Data2VecVision model)"),RTr=l(),z8=a("li"),DTe=a("strong"),PTr=o("dpt"),BTr=o(" \u2014 "),AJ=a("a"),ITr=o("DPTForSemanticSegmentation"),NTr=o(" (DPT model)"),qTr=l(),W8=a("li"),GTe=a("strong"),jTr=o("mobilevit"),DTr=o(" \u2014 "),LJ=a("a"),GTr=o("MobileViTForSemanticSegmentation"),OTr=o(" (MobileViT model)"),VTr=l(),Q8=a("li"),OTe=a("strong"),XTr=o("segformer"),zTr=o(" \u2014 "),yJ=a("a"),WTr=o("SegformerForSemanticSegmentation"),QTr=o(" (SegFormer model)"),UTr=l(),U8=a("p"),HTr=o("The model is set in evaluation mode by default using "),VTe=a("code"),JTr=o("model.eval()"),YTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XTe=a("code"),KTr=o("model.train()"),ZTr=l(),F(H8.$$.fragment),WQe=l(),hc=a("h2"),J8=a("a"),zTe=a("span"),F(Rx.$$.fragment),e8r=l(),WTe=a("span"),o8r=o("AutoModelForInstanceSegmentation"),QQe=l(),tr=a("div"),F(Px.$$.fragment),r8r=l(),pc=a("p"),t8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),xJ=a("a"),a8r=o("from_pretrained()"),n8r=o(" class method or the "),$J=a("a"),s8r=o("from_config()"),l8r=o(` class
method.`),i8r=l(),Bx=a("p"),d8r=o("This class cannot be instantiated directly using "),QTe=a("code"),c8r=o("__init__()"),f8r=o(" (throws an error)."),m8r=l(),Bt=a("div"),F(Ix.$$.fragment),g8r=l(),UTe=a("p"),h8r=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),p8r=l(),_c=a("p"),_8r=o(`Note:
Loading a model from its configuration file does `),HTe=a("strong"),u8r=o("not"),b8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kJ=a("a"),v8r=o("from_pretrained()"),F8r=o(" to load the model weights."),T8r=l(),F(Y8.$$.fragment),M8r=l(),Mo=a("div"),F(Nx.$$.fragment),E8r=l(),JTe=a("p"),C8r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),w8r=l(),mn=a("p"),A8r=o("The model class to instantiate is selected based on the "),YTe=a("code"),L8r=o("model_type"),y8r=o(` property of the config object (either
passed as an argument or loaded from `),KTe=a("code"),x8r=o("pretrained_model_name_or_path"),$8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZTe=a("code"),k8r=o("pretrained_model_name_or_path"),S8r=o(":"),R8r=l(),e8e=a("ul"),K8=a("li"),o8e=a("strong"),P8r=o("maskformer"),B8r=o(" \u2014 "),SJ=a("a"),I8r=o("MaskFormerForInstanceSegmentation"),N8r=o(" (MaskFormer model)"),q8r=l(),Z8=a("p"),j8r=o("The model is set in evaluation mode by default using "),r8e=a("code"),D8r=o("model.eval()"),G8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t8e=a("code"),O8r=o("model.train()"),V8r=l(),F(eM.$$.fragment),UQe=l(),uc=a("h2"),oM=a("a"),a8e=a("span"),F(qx.$$.fragment),X8r=l(),n8e=a("span"),z8r=o("TFAutoModel"),HQe=l(),ar=a("div"),F(jx.$$.fragment),W8r=l(),bc=a("p"),Q8r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),RJ=a("a"),U8r=o("from_pretrained()"),H8r=o(" class method or the "),PJ=a("a"),J8r=o("from_config()"),Y8r=o(` class
method.`),K8r=l(),Dx=a("p"),Z8r=o("This class cannot be instantiated directly using "),s8e=a("code"),eMr=o("__init__()"),oMr=o(" (throws an error)."),rMr=l(),It=a("div"),F(Gx.$$.fragment),tMr=l(),l8e=a("p"),aMr=o("Instantiates one of the base model classes of the library from a configuration."),nMr=l(),vc=a("p"),sMr=o(`Note:
Loading a model from its configuration file does `),i8e=a("strong"),lMr=o("not"),iMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BJ=a("a"),dMr=o("from_pretrained()"),cMr=o(" to load the model weights."),fMr=l(),F(rM.$$.fragment),mMr=l(),Sr=a("div"),F(Ox.$$.fragment),gMr=l(),d8e=a("p"),hMr=o("Instantiate one of the base model classes of the library from a pretrained model."),pMr=l(),gn=a("p"),_Mr=o("The model class to instantiate is selected based on the "),c8e=a("code"),uMr=o("model_type"),bMr=o(` property of the config object (either
passed as an argument or loaded from `),f8e=a("code"),vMr=o("pretrained_model_name_or_path"),FMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m8e=a("code"),TMr=o("pretrained_model_name_or_path"),MMr=o(":"),EMr=l(),q=a("ul"),tM=a("li"),g8e=a("strong"),CMr=o("albert"),wMr=o(" \u2014 "),IJ=a("a"),AMr=o("TFAlbertModel"),LMr=o(" (ALBERT model)"),yMr=l(),aM=a("li"),h8e=a("strong"),xMr=o("bart"),$Mr=o(" \u2014 "),NJ=a("a"),kMr=o("TFBartModel"),SMr=o(" (BART model)"),RMr=l(),nM=a("li"),p8e=a("strong"),PMr=o("bert"),BMr=o(" \u2014 "),qJ=a("a"),IMr=o("TFBertModel"),NMr=o(" (BERT model)"),qMr=l(),sM=a("li"),_8e=a("strong"),jMr=o("blenderbot"),DMr=o(" \u2014 "),jJ=a("a"),GMr=o("TFBlenderbotModel"),OMr=o(" (Blenderbot model)"),VMr=l(),lM=a("li"),u8e=a("strong"),XMr=o("blenderbot-small"),zMr=o(" \u2014 "),DJ=a("a"),WMr=o("TFBlenderbotSmallModel"),QMr=o(" (BlenderbotSmall model)"),UMr=l(),iM=a("li"),b8e=a("strong"),HMr=o("camembert"),JMr=o(" \u2014 "),GJ=a("a"),YMr=o("TFCamembertModel"),KMr=o(" (CamemBERT model)"),ZMr=l(),dM=a("li"),v8e=a("strong"),eEr=o("clip"),oEr=o(" \u2014 "),OJ=a("a"),rEr=o("TFCLIPModel"),tEr=o(" (CLIP model)"),aEr=l(),cM=a("li"),F8e=a("strong"),nEr=o("convbert"),sEr=o(" \u2014 "),VJ=a("a"),lEr=o("TFConvBertModel"),iEr=o(" (ConvBERT model)"),dEr=l(),fM=a("li"),T8e=a("strong"),cEr=o("convnext"),fEr=o(" \u2014 "),XJ=a("a"),mEr=o("TFConvNextModel"),gEr=o(" (ConvNeXT model)"),hEr=l(),mM=a("li"),M8e=a("strong"),pEr=o("ctrl"),_Er=o(" \u2014 "),zJ=a("a"),uEr=o("TFCTRLModel"),bEr=o(" (CTRL model)"),vEr=l(),gM=a("li"),E8e=a("strong"),FEr=o("data2vec-vision"),TEr=o(" \u2014 "),WJ=a("a"),MEr=o("TFData2VecVisionModel"),EEr=o(" (Data2VecVision model)"),CEr=l(),hM=a("li"),C8e=a("strong"),wEr=o("deberta"),AEr=o(" \u2014 "),QJ=a("a"),LEr=o("TFDebertaModel"),yEr=o(" (DeBERTa model)"),xEr=l(),pM=a("li"),w8e=a("strong"),$Er=o("deberta-v2"),kEr=o(" \u2014 "),UJ=a("a"),SEr=o("TFDebertaV2Model"),REr=o(" (DeBERTa-v2 model)"),PEr=l(),_M=a("li"),A8e=a("strong"),BEr=o("deit"),IEr=o(" \u2014 "),HJ=a("a"),NEr=o("TFDeiTModel"),qEr=o(" (DeiT model)"),jEr=l(),uM=a("li"),L8e=a("strong"),DEr=o("distilbert"),GEr=o(" \u2014 "),JJ=a("a"),OEr=o("TFDistilBertModel"),VEr=o(" (DistilBERT model)"),XEr=l(),bM=a("li"),y8e=a("strong"),zEr=o("dpr"),WEr=o(" \u2014 "),YJ=a("a"),QEr=o("TFDPRQuestionEncoder"),UEr=o(" (DPR model)"),HEr=l(),vM=a("li"),x8e=a("strong"),JEr=o("electra"),YEr=o(" \u2014 "),KJ=a("a"),KEr=o("TFElectraModel"),ZEr=o(" (ELECTRA model)"),eCr=l(),FM=a("li"),$8e=a("strong"),oCr=o("flaubert"),rCr=o(" \u2014 "),ZJ=a("a"),tCr=o("TFFlaubertModel"),aCr=o(" (FlauBERT model)"),nCr=l(),al=a("li"),k8e=a("strong"),sCr=o("funnel"),lCr=o(" \u2014 "),eY=a("a"),iCr=o("TFFunnelModel"),dCr=o(" or "),oY=a("a"),cCr=o("TFFunnelBaseModel"),fCr=o(" (Funnel Transformer model)"),mCr=l(),TM=a("li"),S8e=a("strong"),gCr=o("gpt2"),hCr=o(" \u2014 "),rY=a("a"),pCr=o("TFGPT2Model"),_Cr=o(" (OpenAI GPT-2 model)"),uCr=l(),MM=a("li"),R8e=a("strong"),bCr=o("gptj"),vCr=o(" \u2014 "),tY=a("a"),FCr=o("TFGPTJModel"),TCr=o(" (GPT-J model)"),MCr=l(),EM=a("li"),P8e=a("strong"),ECr=o("hubert"),CCr=o(" \u2014 "),aY=a("a"),wCr=o("TFHubertModel"),ACr=o(" (Hubert model)"),LCr=l(),CM=a("li"),B8e=a("strong"),yCr=o("layoutlm"),xCr=o(" \u2014 "),nY=a("a"),$Cr=o("TFLayoutLMModel"),kCr=o(" (LayoutLM model)"),SCr=l(),wM=a("li"),I8e=a("strong"),RCr=o("led"),PCr=o(" \u2014 "),sY=a("a"),BCr=o("TFLEDModel"),ICr=o(" (LED model)"),NCr=l(),AM=a("li"),N8e=a("strong"),qCr=o("longformer"),jCr=o(" \u2014 "),lY=a("a"),DCr=o("TFLongformerModel"),GCr=o(" (Longformer model)"),OCr=l(),LM=a("li"),q8e=a("strong"),VCr=o("lxmert"),XCr=o(" \u2014 "),iY=a("a"),zCr=o("TFLxmertModel"),WCr=o(" (LXMERT model)"),QCr=l(),yM=a("li"),j8e=a("strong"),UCr=o("marian"),HCr=o(" \u2014 "),dY=a("a"),JCr=o("TFMarianModel"),YCr=o(" (Marian model)"),KCr=l(),xM=a("li"),D8e=a("strong"),ZCr=o("mbart"),e3r=o(" \u2014 "),cY=a("a"),o3r=o("TFMBartModel"),r3r=o(" (mBART model)"),t3r=l(),$M=a("li"),G8e=a("strong"),a3r=o("mobilebert"),n3r=o(" \u2014 "),fY=a("a"),s3r=o("TFMobileBertModel"),l3r=o(" (MobileBERT model)"),i3r=l(),kM=a("li"),O8e=a("strong"),d3r=o("mpnet"),c3r=o(" \u2014 "),mY=a("a"),f3r=o("TFMPNetModel"),m3r=o(" (MPNet model)"),g3r=l(),SM=a("li"),V8e=a("strong"),h3r=o("mt5"),p3r=o(" \u2014 "),gY=a("a"),_3r=o("TFMT5Model"),u3r=o(" (MT5 model)"),b3r=l(),RM=a("li"),X8e=a("strong"),v3r=o("openai-gpt"),F3r=o(" \u2014 "),hY=a("a"),T3r=o("TFOpenAIGPTModel"),M3r=o(" (OpenAI GPT model)"),E3r=l(),PM=a("li"),z8e=a("strong"),C3r=o("opt"),w3r=o(" \u2014 "),pY=a("a"),A3r=o("TFOPTModel"),L3r=o(" (OPT model)"),y3r=l(),BM=a("li"),W8e=a("strong"),x3r=o("pegasus"),$3r=o(" \u2014 "),_Y=a("a"),k3r=o("TFPegasusModel"),S3r=o(" (Pegasus model)"),R3r=l(),IM=a("li"),Q8e=a("strong"),P3r=o("regnet"),B3r=o(" \u2014 "),uY=a("a"),I3r=o("TFRegNetModel"),N3r=o(" (RegNet model)"),q3r=l(),NM=a("li"),U8e=a("strong"),j3r=o("rembert"),D3r=o(" \u2014 "),bY=a("a"),G3r=o("TFRemBertModel"),O3r=o(" (RemBERT model)"),V3r=l(),qM=a("li"),H8e=a("strong"),X3r=o("resnet"),z3r=o(" \u2014 "),vY=a("a"),W3r=o("TFResNetModel"),Q3r=o(" (ResNet model)"),U3r=l(),jM=a("li"),J8e=a("strong"),H3r=o("roberta"),J3r=o(" \u2014 "),FY=a("a"),Y3r=o("TFRobertaModel"),K3r=o(" (RoBERTa model)"),Z3r=l(),DM=a("li"),Y8e=a("strong"),e0r=o("roformer"),o0r=o(" \u2014 "),TY=a("a"),r0r=o("TFRoFormerModel"),t0r=o(" (RoFormer model)"),a0r=l(),GM=a("li"),K8e=a("strong"),n0r=o("segformer"),s0r=o(" \u2014 "),MY=a("a"),l0r=o("TFSegformerModel"),i0r=o(" (SegFormer model)"),d0r=l(),OM=a("li"),Z8e=a("strong"),c0r=o("speech_to_text"),f0r=o(" \u2014 "),EY=a("a"),m0r=o("TFSpeech2TextModel"),g0r=o(" (Speech2Text model)"),h0r=l(),VM=a("li"),eMe=a("strong"),p0r=o("swin"),_0r=o(" \u2014 "),CY=a("a"),u0r=o("TFSwinModel"),b0r=o(" (Swin Transformer model)"),v0r=l(),XM=a("li"),oMe=a("strong"),F0r=o("t5"),T0r=o(" \u2014 "),wY=a("a"),M0r=o("TFT5Model"),E0r=o(" (T5 model)"),C0r=l(),zM=a("li"),rMe=a("strong"),w0r=o("tapas"),A0r=o(" \u2014 "),AY=a("a"),L0r=o("TFTapasModel"),y0r=o(" (TAPAS model)"),x0r=l(),WM=a("li"),tMe=a("strong"),$0r=o("transfo-xl"),k0r=o(" \u2014 "),LY=a("a"),S0r=o("TFTransfoXLModel"),R0r=o(" (Transformer-XL model)"),P0r=l(),QM=a("li"),aMe=a("strong"),B0r=o("vit"),I0r=o(" \u2014 "),yY=a("a"),N0r=o("TFViTModel"),q0r=o(" (ViT model)"),j0r=l(),UM=a("li"),nMe=a("strong"),D0r=o("vit_mae"),G0r=o(" \u2014 "),xY=a("a"),O0r=o("TFViTMAEModel"),V0r=o(" (ViTMAE model)"),X0r=l(),HM=a("li"),sMe=a("strong"),z0r=o("wav2vec2"),W0r=o(" \u2014 "),$Y=a("a"),Q0r=o("TFWav2Vec2Model"),U0r=o(" (Wav2Vec2 model)"),H0r=l(),JM=a("li"),lMe=a("strong"),J0r=o("xlm"),Y0r=o(" \u2014 "),kY=a("a"),K0r=o("TFXLMModel"),Z0r=o(" (XLM model)"),ewr=l(),YM=a("li"),iMe=a("strong"),owr=o("xlm-roberta"),rwr=o(" \u2014 "),SY=a("a"),twr=o("TFXLMRobertaModel"),awr=o(" (XLM-RoBERTa model)"),nwr=l(),KM=a("li"),dMe=a("strong"),swr=o("xlnet"),lwr=o(" \u2014 "),RY=a("a"),iwr=o("TFXLNetModel"),dwr=o(" (XLNet model)"),cwr=l(),F(ZM.$$.fragment),JQe=l(),Fc=a("h2"),eE=a("a"),cMe=a("span"),F(Vx.$$.fragment),fwr=l(),fMe=a("span"),mwr=o("TFAutoModelForPreTraining"),YQe=l(),nr=a("div"),F(Xx.$$.fragment),gwr=l(),Tc=a("p"),hwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),PY=a("a"),pwr=o("from_pretrained()"),_wr=o(" class method or the "),BY=a("a"),uwr=o("from_config()"),bwr=o(` class
method.`),vwr=l(),zx=a("p"),Fwr=o("This class cannot be instantiated directly using "),mMe=a("code"),Twr=o("__init__()"),Mwr=o(" (throws an error)."),Ewr=l(),Nt=a("div"),F(Wx.$$.fragment),Cwr=l(),gMe=a("p"),wwr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Awr=l(),Mc=a("p"),Lwr=o(`Note:
Loading a model from its configuration file does `),hMe=a("strong"),ywr=o("not"),xwr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),$wr=o("from_pretrained()"),kwr=o(" to load the model weights."),Swr=l(),F(oE.$$.fragment),Rwr=l(),Rr=a("div"),F(Qx.$$.fragment),Pwr=l(),pMe=a("p"),Bwr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Iwr=l(),hn=a("p"),Nwr=o("The model class to instantiate is selected based on the "),_Me=a("code"),qwr=o("model_type"),jwr=o(` property of the config object (either
passed as an argument or loaded from `),uMe=a("code"),Dwr=o("pretrained_model_name_or_path"),Gwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bMe=a("code"),Owr=o("pretrained_model_name_or_path"),Vwr=o(":"),Xwr=l(),se=a("ul"),rE=a("li"),vMe=a("strong"),zwr=o("albert"),Wwr=o(" \u2014 "),NY=a("a"),Qwr=o("TFAlbertForPreTraining"),Uwr=o(" (ALBERT model)"),Hwr=l(),tE=a("li"),FMe=a("strong"),Jwr=o("bart"),Ywr=o(" \u2014 "),qY=a("a"),Kwr=o("TFBartForConditionalGeneration"),Zwr=o(" (BART model)"),e6r=l(),aE=a("li"),TMe=a("strong"),o6r=o("bert"),r6r=o(" \u2014 "),jY=a("a"),t6r=o("TFBertForPreTraining"),a6r=o(" (BERT model)"),n6r=l(),nE=a("li"),MMe=a("strong"),s6r=o("camembert"),l6r=o(" \u2014 "),DY=a("a"),i6r=o("TFCamembertForMaskedLM"),d6r=o(" (CamemBERT model)"),c6r=l(),sE=a("li"),EMe=a("strong"),f6r=o("ctrl"),m6r=o(" \u2014 "),GY=a("a"),g6r=o("TFCTRLLMHeadModel"),h6r=o(" (CTRL model)"),p6r=l(),lE=a("li"),CMe=a("strong"),_6r=o("distilbert"),u6r=o(" \u2014 "),OY=a("a"),b6r=o("TFDistilBertForMaskedLM"),v6r=o(" (DistilBERT model)"),F6r=l(),iE=a("li"),wMe=a("strong"),T6r=o("electra"),M6r=o(" \u2014 "),VY=a("a"),E6r=o("TFElectraForPreTraining"),C6r=o(" (ELECTRA model)"),w6r=l(),dE=a("li"),AMe=a("strong"),A6r=o("flaubert"),L6r=o(" \u2014 "),XY=a("a"),y6r=o("TFFlaubertWithLMHeadModel"),x6r=o(" (FlauBERT model)"),$6r=l(),cE=a("li"),LMe=a("strong"),k6r=o("funnel"),S6r=o(" \u2014 "),zY=a("a"),R6r=o("TFFunnelForPreTraining"),P6r=o(" (Funnel Transformer model)"),B6r=l(),fE=a("li"),yMe=a("strong"),I6r=o("gpt2"),N6r=o(" \u2014 "),WY=a("a"),q6r=o("TFGPT2LMHeadModel"),j6r=o(" (OpenAI GPT-2 model)"),D6r=l(),mE=a("li"),xMe=a("strong"),G6r=o("layoutlm"),O6r=o(" \u2014 "),QY=a("a"),V6r=o("TFLayoutLMForMaskedLM"),X6r=o(" (LayoutLM model)"),z6r=l(),gE=a("li"),$Me=a("strong"),W6r=o("lxmert"),Q6r=o(" \u2014 "),UY=a("a"),U6r=o("TFLxmertForPreTraining"),H6r=o(" (LXMERT model)"),J6r=l(),hE=a("li"),kMe=a("strong"),Y6r=o("mobilebert"),K6r=o(" \u2014 "),HY=a("a"),Z6r=o("TFMobileBertForPreTraining"),eAr=o(" (MobileBERT model)"),oAr=l(),pE=a("li"),SMe=a("strong"),rAr=o("mpnet"),tAr=o(" \u2014 "),JY=a("a"),aAr=o("TFMPNetForMaskedLM"),nAr=o(" (MPNet model)"),sAr=l(),_E=a("li"),RMe=a("strong"),lAr=o("openai-gpt"),iAr=o(" \u2014 "),YY=a("a"),dAr=o("TFOpenAIGPTLMHeadModel"),cAr=o(" (OpenAI GPT model)"),fAr=l(),uE=a("li"),PMe=a("strong"),mAr=o("roberta"),gAr=o(" \u2014 "),KY=a("a"),hAr=o("TFRobertaForMaskedLM"),pAr=o(" (RoBERTa model)"),_Ar=l(),bE=a("li"),BMe=a("strong"),uAr=o("t5"),bAr=o(" \u2014 "),ZY=a("a"),vAr=o("TFT5ForConditionalGeneration"),FAr=o(" (T5 model)"),TAr=l(),vE=a("li"),IMe=a("strong"),MAr=o("tapas"),EAr=o(" \u2014 "),eK=a("a"),CAr=o("TFTapasForMaskedLM"),wAr=o(" (TAPAS model)"),AAr=l(),FE=a("li"),NMe=a("strong"),LAr=o("transfo-xl"),yAr=o(" \u2014 "),oK=a("a"),xAr=o("TFTransfoXLLMHeadModel"),$Ar=o(" (Transformer-XL model)"),kAr=l(),TE=a("li"),qMe=a("strong"),SAr=o("vit_mae"),RAr=o(" \u2014 "),rK=a("a"),PAr=o("TFViTMAEForPreTraining"),BAr=o(" (ViTMAE model)"),IAr=l(),ME=a("li"),jMe=a("strong"),NAr=o("xlm"),qAr=o(" \u2014 "),tK=a("a"),jAr=o("TFXLMWithLMHeadModel"),DAr=o(" (XLM model)"),GAr=l(),EE=a("li"),DMe=a("strong"),OAr=o("xlm-roberta"),VAr=o(" \u2014 "),aK=a("a"),XAr=o("TFXLMRobertaForMaskedLM"),zAr=o(" (XLM-RoBERTa model)"),WAr=l(),CE=a("li"),GMe=a("strong"),QAr=o("xlnet"),UAr=o(" \u2014 "),nK=a("a"),HAr=o("TFXLNetLMHeadModel"),JAr=o(" (XLNet model)"),YAr=l(),F(wE.$$.fragment),KQe=l(),Ec=a("h2"),AE=a("a"),OMe=a("span"),F(Ux.$$.fragment),KAr=l(),VMe=a("span"),ZAr=o("TFAutoModelForCausalLM"),ZQe=l(),sr=a("div"),F(Hx.$$.fragment),e7r=l(),Cc=a("p"),o7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),sK=a("a"),r7r=o("from_pretrained()"),t7r=o(" class method or the "),lK=a("a"),a7r=o("from_config()"),n7r=o(` class
method.`),s7r=l(),Jx=a("p"),l7r=o("This class cannot be instantiated directly using "),XMe=a("code"),i7r=o("__init__()"),d7r=o(" (throws an error)."),c7r=l(),qt=a("div"),F(Yx.$$.fragment),f7r=l(),zMe=a("p"),m7r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),g7r=l(),wc=a("p"),h7r=o(`Note:
Loading a model from its configuration file does `),WMe=a("strong"),p7r=o("not"),_7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iK=a("a"),u7r=o("from_pretrained()"),b7r=o(" to load the model weights."),v7r=l(),F(LE.$$.fragment),F7r=l(),Pr=a("div"),F(Kx.$$.fragment),T7r=l(),QMe=a("p"),M7r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),E7r=l(),pn=a("p"),C7r=o("The model class to instantiate is selected based on the "),UMe=a("code"),w7r=o("model_type"),A7r=o(` property of the config object (either
passed as an argument or loaded from `),HMe=a("code"),L7r=o("pretrained_model_name_or_path"),y7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JMe=a("code"),x7r=o("pretrained_model_name_or_path"),$7r=o(":"),k7r=l(),Me=a("ul"),yE=a("li"),YMe=a("strong"),S7r=o("bert"),R7r=o(" \u2014 "),dK=a("a"),P7r=o("TFBertLMHeadModel"),B7r=o(" (BERT model)"),I7r=l(),xE=a("li"),KMe=a("strong"),N7r=o("camembert"),q7r=o(" \u2014 "),cK=a("a"),j7r=o("TFCamembertForCausalLM"),D7r=o(" (CamemBERT model)"),G7r=l(),$E=a("li"),ZMe=a("strong"),O7r=o("ctrl"),V7r=o(" \u2014 "),fK=a("a"),X7r=o("TFCTRLLMHeadModel"),z7r=o(" (CTRL model)"),W7r=l(),kE=a("li"),eEe=a("strong"),Q7r=o("gpt2"),U7r=o(" \u2014 "),mK=a("a"),H7r=o("TFGPT2LMHeadModel"),J7r=o(" (OpenAI GPT-2 model)"),Y7r=l(),SE=a("li"),oEe=a("strong"),K7r=o("gptj"),Z7r=o(" \u2014 "),gK=a("a"),eLr=o("TFGPTJForCausalLM"),oLr=o(" (GPT-J model)"),rLr=l(),RE=a("li"),rEe=a("strong"),tLr=o("openai-gpt"),aLr=o(" \u2014 "),hK=a("a"),nLr=o("TFOpenAIGPTLMHeadModel"),sLr=o(" (OpenAI GPT model)"),lLr=l(),PE=a("li"),tEe=a("strong"),iLr=o("opt"),dLr=o(" \u2014 "),pK=a("a"),cLr=o("TFOPTForCausalLM"),fLr=o(" (OPT model)"),mLr=l(),BE=a("li"),aEe=a("strong"),gLr=o("rembert"),hLr=o(" \u2014 "),_K=a("a"),pLr=o("TFRemBertForCausalLM"),_Lr=o(" (RemBERT model)"),uLr=l(),IE=a("li"),nEe=a("strong"),bLr=o("roberta"),vLr=o(" \u2014 "),uK=a("a"),FLr=o("TFRobertaForCausalLM"),TLr=o(" (RoBERTa model)"),MLr=l(),NE=a("li"),sEe=a("strong"),ELr=o("roformer"),CLr=o(" \u2014 "),bK=a("a"),wLr=o("TFRoFormerForCausalLM"),ALr=o(" (RoFormer model)"),LLr=l(),qE=a("li"),lEe=a("strong"),yLr=o("transfo-xl"),xLr=o(" \u2014 "),vK=a("a"),$Lr=o("TFTransfoXLLMHeadModel"),kLr=o(" (Transformer-XL model)"),SLr=l(),jE=a("li"),iEe=a("strong"),RLr=o("xlm"),PLr=o(" \u2014 "),FK=a("a"),BLr=o("TFXLMWithLMHeadModel"),ILr=o(" (XLM model)"),NLr=l(),DE=a("li"),dEe=a("strong"),qLr=o("xlnet"),jLr=o(" \u2014 "),TK=a("a"),DLr=o("TFXLNetLMHeadModel"),GLr=o(" (XLNet model)"),OLr=l(),F(GE.$$.fragment),eUe=l(),Ac=a("h2"),OE=a("a"),cEe=a("span"),F(Zx.$$.fragment),VLr=l(),fEe=a("span"),XLr=o("TFAutoModelForImageClassification"),oUe=l(),lr=a("div"),F(e$.$$.fragment),zLr=l(),Lc=a("p"),WLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),MK=a("a"),QLr=o("from_pretrained()"),ULr=o(" class method or the "),EK=a("a"),HLr=o("from_config()"),JLr=o(` class
method.`),YLr=l(),o$=a("p"),KLr=o("This class cannot be instantiated directly using "),mEe=a("code"),ZLr=o("__init__()"),eyr=o(" (throws an error)."),oyr=l(),jt=a("div"),F(r$.$$.fragment),ryr=l(),gEe=a("p"),tyr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),ayr=l(),yc=a("p"),nyr=o(`Note:
Loading a model from its configuration file does `),hEe=a("strong"),syr=o("not"),lyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CK=a("a"),iyr=o("from_pretrained()"),dyr=o(" to load the model weights."),cyr=l(),F(VE.$$.fragment),fyr=l(),Br=a("div"),F(t$.$$.fragment),myr=l(),pEe=a("p"),gyr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),hyr=l(),_n=a("p"),pyr=o("The model class to instantiate is selected based on the "),_Ee=a("code"),_yr=o("model_type"),uyr=o(` property of the config object (either
passed as an argument or loaded from `),uEe=a("code"),byr=o("pretrained_model_name_or_path"),vyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bEe=a("code"),Fyr=o("pretrained_model_name_or_path"),Tyr=o(":"),Myr=l(),Ve=a("ul"),XE=a("li"),vEe=a("strong"),Eyr=o("convnext"),Cyr=o(" \u2014 "),wK=a("a"),wyr=o("TFConvNextForImageClassification"),Ayr=o(" (ConvNeXT model)"),Lyr=l(),zE=a("li"),FEe=a("strong"),yyr=o("data2vec-vision"),xyr=o(" \u2014 "),AK=a("a"),$yr=o("TFData2VecVisionForImageClassification"),kyr=o(" (Data2VecVision model)"),Syr=l(),nl=a("li"),TEe=a("strong"),Ryr=o("deit"),Pyr=o(" \u2014 "),LK=a("a"),Byr=o("TFDeiTForImageClassification"),Iyr=o(" or "),yK=a("a"),Nyr=o("TFDeiTForImageClassificationWithTeacher"),qyr=o(" (DeiT model)"),jyr=l(),WE=a("li"),MEe=a("strong"),Dyr=o("regnet"),Gyr=o(" \u2014 "),xK=a("a"),Oyr=o("TFRegNetForImageClassification"),Vyr=o(" (RegNet model)"),Xyr=l(),QE=a("li"),EEe=a("strong"),zyr=o("resnet"),Wyr=o(" \u2014 "),$K=a("a"),Qyr=o("TFResNetForImageClassification"),Uyr=o(" (ResNet model)"),Hyr=l(),UE=a("li"),CEe=a("strong"),Jyr=o("segformer"),Yyr=o(" \u2014 "),kK=a("a"),Kyr=o("TFSegformerForImageClassification"),Zyr=o(" (SegFormer model)"),e9r=l(),HE=a("li"),wEe=a("strong"),o9r=o("swin"),r9r=o(" \u2014 "),SK=a("a"),t9r=o("TFSwinForImageClassification"),a9r=o(" (Swin Transformer model)"),n9r=l(),JE=a("li"),AEe=a("strong"),s9r=o("vit"),l9r=o(" \u2014 "),RK=a("a"),i9r=o("TFViTForImageClassification"),d9r=o(" (ViT model)"),c9r=l(),F(YE.$$.fragment),rUe=l(),xc=a("h2"),KE=a("a"),LEe=a("span"),F(a$.$$.fragment),f9r=l(),yEe=a("span"),m9r=o("TFAutoModelForMaskedLM"),tUe=l(),ir=a("div"),F(n$.$$.fragment),g9r=l(),$c=a("p"),h9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PK=a("a"),p9r=o("from_pretrained()"),_9r=o(" class method or the "),BK=a("a"),u9r=o("from_config()"),b9r=o(` class
method.`),v9r=l(),s$=a("p"),F9r=o("This class cannot be instantiated directly using "),xEe=a("code"),T9r=o("__init__()"),M9r=o(" (throws an error)."),E9r=l(),Dt=a("div"),F(l$.$$.fragment),C9r=l(),$Ee=a("p"),w9r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),A9r=l(),kc=a("p"),L9r=o(`Note:
Loading a model from its configuration file does `),kEe=a("strong"),y9r=o("not"),x9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),$9r=o("from_pretrained()"),k9r=o(" to load the model weights."),S9r=l(),F(ZE.$$.fragment),R9r=l(),Ir=a("div"),F(i$.$$.fragment),P9r=l(),SEe=a("p"),B9r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),I9r=l(),un=a("p"),N9r=o("The model class to instantiate is selected based on the "),REe=a("code"),q9r=o("model_type"),j9r=o(` property of the config object (either
passed as an argument or loaded from `),PEe=a("code"),D9r=o("pretrained_model_name_or_path"),G9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BEe=a("code"),O9r=o("pretrained_model_name_or_path"),V9r=o(":"),X9r=l(),ie=a("ul"),eC=a("li"),IEe=a("strong"),z9r=o("albert"),W9r=o(" \u2014 "),NK=a("a"),Q9r=o("TFAlbertForMaskedLM"),U9r=o(" (ALBERT model)"),H9r=l(),oC=a("li"),NEe=a("strong"),J9r=o("bert"),Y9r=o(" \u2014 "),qK=a("a"),K9r=o("TFBertForMaskedLM"),Z9r=o(" (BERT model)"),exr=l(),rC=a("li"),qEe=a("strong"),oxr=o("camembert"),rxr=o(" \u2014 "),jK=a("a"),txr=o("TFCamembertForMaskedLM"),axr=o(" (CamemBERT model)"),nxr=l(),tC=a("li"),jEe=a("strong"),sxr=o("convbert"),lxr=o(" \u2014 "),DK=a("a"),ixr=o("TFConvBertForMaskedLM"),dxr=o(" (ConvBERT model)"),cxr=l(),aC=a("li"),DEe=a("strong"),fxr=o("deberta"),mxr=o(" \u2014 "),GK=a("a"),gxr=o("TFDebertaForMaskedLM"),hxr=o(" (DeBERTa model)"),pxr=l(),nC=a("li"),GEe=a("strong"),_xr=o("deberta-v2"),uxr=o(" \u2014 "),OK=a("a"),bxr=o("TFDebertaV2ForMaskedLM"),vxr=o(" (DeBERTa-v2 model)"),Fxr=l(),sC=a("li"),OEe=a("strong"),Txr=o("distilbert"),Mxr=o(" \u2014 "),VK=a("a"),Exr=o("TFDistilBertForMaskedLM"),Cxr=o(" (DistilBERT model)"),wxr=l(),lC=a("li"),VEe=a("strong"),Axr=o("electra"),Lxr=o(" \u2014 "),XK=a("a"),yxr=o("TFElectraForMaskedLM"),xxr=o(" (ELECTRA model)"),$xr=l(),iC=a("li"),XEe=a("strong"),kxr=o("flaubert"),Sxr=o(" \u2014 "),zK=a("a"),Rxr=o("TFFlaubertWithLMHeadModel"),Pxr=o(" (FlauBERT model)"),Bxr=l(),dC=a("li"),zEe=a("strong"),Ixr=o("funnel"),Nxr=o(" \u2014 "),WK=a("a"),qxr=o("TFFunnelForMaskedLM"),jxr=o(" (Funnel Transformer model)"),Dxr=l(),cC=a("li"),WEe=a("strong"),Gxr=o("layoutlm"),Oxr=o(" \u2014 "),QK=a("a"),Vxr=o("TFLayoutLMForMaskedLM"),Xxr=o(" (LayoutLM model)"),zxr=l(),fC=a("li"),QEe=a("strong"),Wxr=o("longformer"),Qxr=o(" \u2014 "),UK=a("a"),Uxr=o("TFLongformerForMaskedLM"),Hxr=o(" (Longformer model)"),Jxr=l(),mC=a("li"),UEe=a("strong"),Yxr=o("mobilebert"),Kxr=o(" \u2014 "),HK=a("a"),Zxr=o("TFMobileBertForMaskedLM"),e$r=o(" (MobileBERT model)"),o$r=l(),gC=a("li"),HEe=a("strong"),r$r=o("mpnet"),t$r=o(" \u2014 "),JK=a("a"),a$r=o("TFMPNetForMaskedLM"),n$r=o(" (MPNet model)"),s$r=l(),hC=a("li"),JEe=a("strong"),l$r=o("rembert"),i$r=o(" \u2014 "),YK=a("a"),d$r=o("TFRemBertForMaskedLM"),c$r=o(" (RemBERT model)"),f$r=l(),pC=a("li"),YEe=a("strong"),m$r=o("roberta"),g$r=o(" \u2014 "),KK=a("a"),h$r=o("TFRobertaForMaskedLM"),p$r=o(" (RoBERTa model)"),_$r=l(),_C=a("li"),KEe=a("strong"),u$r=o("roformer"),b$r=o(" \u2014 "),ZK=a("a"),v$r=o("TFRoFormerForMaskedLM"),F$r=o(" (RoFormer model)"),T$r=l(),uC=a("li"),ZEe=a("strong"),M$r=o("tapas"),E$r=o(" \u2014 "),eZ=a("a"),C$r=o("TFTapasForMaskedLM"),w$r=o(" (TAPAS model)"),A$r=l(),bC=a("li"),eCe=a("strong"),L$r=o("xlm"),y$r=o(" \u2014 "),oZ=a("a"),x$r=o("TFXLMWithLMHeadModel"),$$r=o(" (XLM model)"),k$r=l(),vC=a("li"),oCe=a("strong"),S$r=o("xlm-roberta"),R$r=o(" \u2014 "),rZ=a("a"),P$r=o("TFXLMRobertaForMaskedLM"),B$r=o(" (XLM-RoBERTa model)"),I$r=l(),F(FC.$$.fragment),aUe=l(),Sc=a("h2"),TC=a("a"),rCe=a("span"),F(d$.$$.fragment),N$r=l(),tCe=a("span"),q$r=o("TFAutoModelForSeq2SeqLM"),nUe=l(),dr=a("div"),F(c$.$$.fragment),j$r=l(),Rc=a("p"),D$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tZ=a("a"),G$r=o("from_pretrained()"),O$r=o(" class method or the "),aZ=a("a"),V$r=o("from_config()"),X$r=o(` class
method.`),z$r=l(),f$=a("p"),W$r=o("This class cannot be instantiated directly using "),aCe=a("code"),Q$r=o("__init__()"),U$r=o(" (throws an error)."),H$r=l(),Gt=a("div"),F(m$.$$.fragment),J$r=l(),nCe=a("p"),Y$r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),K$r=l(),Pc=a("p"),Z$r=o(`Note:
Loading a model from its configuration file does `),sCe=a("strong"),ekr=o("not"),okr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=a("a"),rkr=o("from_pretrained()"),tkr=o(" to load the model weights."),akr=l(),F(MC.$$.fragment),nkr=l(),Nr=a("div"),F(g$.$$.fragment),skr=l(),lCe=a("p"),lkr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),ikr=l(),bn=a("p"),dkr=o("The model class to instantiate is selected based on the "),iCe=a("code"),ckr=o("model_type"),fkr=o(` property of the config object (either
passed as an argument or loaded from `),dCe=a("code"),mkr=o("pretrained_model_name_or_path"),gkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=a("code"),hkr=o("pretrained_model_name_or_path"),pkr=o(":"),_kr=l(),ye=a("ul"),EC=a("li"),fCe=a("strong"),ukr=o("bart"),bkr=o(" \u2014 "),sZ=a("a"),vkr=o("TFBartForConditionalGeneration"),Fkr=o(" (BART model)"),Tkr=l(),CC=a("li"),mCe=a("strong"),Mkr=o("blenderbot"),Ekr=o(" \u2014 "),lZ=a("a"),Ckr=o("TFBlenderbotForConditionalGeneration"),wkr=o(" (Blenderbot model)"),Akr=l(),wC=a("li"),gCe=a("strong"),Lkr=o("blenderbot-small"),ykr=o(" \u2014 "),iZ=a("a"),xkr=o("TFBlenderbotSmallForConditionalGeneration"),$kr=o(" (BlenderbotSmall model)"),kkr=l(),AC=a("li"),hCe=a("strong"),Skr=o("encoder-decoder"),Rkr=o(" \u2014 "),dZ=a("a"),Pkr=o("TFEncoderDecoderModel"),Bkr=o(" (Encoder decoder model)"),Ikr=l(),LC=a("li"),pCe=a("strong"),Nkr=o("led"),qkr=o(" \u2014 "),cZ=a("a"),jkr=o("TFLEDForConditionalGeneration"),Dkr=o(" (LED model)"),Gkr=l(),yC=a("li"),_Ce=a("strong"),Okr=o("marian"),Vkr=o(" \u2014 "),fZ=a("a"),Xkr=o("TFMarianMTModel"),zkr=o(" (Marian model)"),Wkr=l(),xC=a("li"),uCe=a("strong"),Qkr=o("mbart"),Ukr=o(" \u2014 "),mZ=a("a"),Hkr=o("TFMBartForConditionalGeneration"),Jkr=o(" (mBART model)"),Ykr=l(),$C=a("li"),bCe=a("strong"),Kkr=o("mt5"),Zkr=o(" \u2014 "),gZ=a("a"),eSr=o("TFMT5ForConditionalGeneration"),oSr=o(" (MT5 model)"),rSr=l(),kC=a("li"),vCe=a("strong"),tSr=o("pegasus"),aSr=o(" \u2014 "),hZ=a("a"),nSr=o("TFPegasusForConditionalGeneration"),sSr=o(" (Pegasus model)"),lSr=l(),SC=a("li"),FCe=a("strong"),iSr=o("t5"),dSr=o(" \u2014 "),pZ=a("a"),cSr=o("TFT5ForConditionalGeneration"),fSr=o(" (T5 model)"),mSr=l(),F(RC.$$.fragment),sUe=l(),Bc=a("h2"),PC=a("a"),TCe=a("span"),F(h$.$$.fragment),gSr=l(),MCe=a("span"),hSr=o("TFAutoModelForSequenceClassification"),lUe=l(),cr=a("div"),F(p$.$$.fragment),pSr=l(),Ic=a("p"),_Sr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_Z=a("a"),uSr=o("from_pretrained()"),bSr=o(" class method or the "),uZ=a("a"),vSr=o("from_config()"),FSr=o(` class
method.`),TSr=l(),_$=a("p"),MSr=o("This class cannot be instantiated directly using "),ECe=a("code"),ESr=o("__init__()"),CSr=o(" (throws an error)."),wSr=l(),Ot=a("div"),F(u$.$$.fragment),ASr=l(),CCe=a("p"),LSr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ySr=l(),Nc=a("p"),xSr=o(`Note:
Loading a model from its configuration file does `),wCe=a("strong"),$Sr=o("not"),kSr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bZ=a("a"),SSr=o("from_pretrained()"),RSr=o(" to load the model weights."),PSr=l(),F(BC.$$.fragment),BSr=l(),qr=a("div"),F(b$.$$.fragment),ISr=l(),ACe=a("p"),NSr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qSr=l(),vn=a("p"),jSr=o("The model class to instantiate is selected based on the "),LCe=a("code"),DSr=o("model_type"),GSr=o(` property of the config object (either
passed as an argument or loaded from `),yCe=a("code"),OSr=o("pretrained_model_name_or_path"),VSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xCe=a("code"),XSr=o("pretrained_model_name_or_path"),zSr=o(":"),WSr=l(),te=a("ul"),IC=a("li"),$Ce=a("strong"),QSr=o("albert"),USr=o(" \u2014 "),vZ=a("a"),HSr=o("TFAlbertForSequenceClassification"),JSr=o(" (ALBERT model)"),YSr=l(),NC=a("li"),kCe=a("strong"),KSr=o("bert"),ZSr=o(" \u2014 "),FZ=a("a"),eRr=o("TFBertForSequenceClassification"),oRr=o(" (BERT model)"),rRr=l(),qC=a("li"),SCe=a("strong"),tRr=o("camembert"),aRr=o(" \u2014 "),TZ=a("a"),nRr=o("TFCamembertForSequenceClassification"),sRr=o(" (CamemBERT model)"),lRr=l(),jC=a("li"),RCe=a("strong"),iRr=o("convbert"),dRr=o(" \u2014 "),MZ=a("a"),cRr=o("TFConvBertForSequenceClassification"),fRr=o(" (ConvBERT model)"),mRr=l(),DC=a("li"),PCe=a("strong"),gRr=o("ctrl"),hRr=o(" \u2014 "),EZ=a("a"),pRr=o("TFCTRLForSequenceClassification"),_Rr=o(" (CTRL model)"),uRr=l(),GC=a("li"),BCe=a("strong"),bRr=o("deberta"),vRr=o(" \u2014 "),CZ=a("a"),FRr=o("TFDebertaForSequenceClassification"),TRr=o(" (DeBERTa model)"),MRr=l(),OC=a("li"),ICe=a("strong"),ERr=o("deberta-v2"),CRr=o(" \u2014 "),wZ=a("a"),wRr=o("TFDebertaV2ForSequenceClassification"),ARr=o(" (DeBERTa-v2 model)"),LRr=l(),VC=a("li"),NCe=a("strong"),yRr=o("distilbert"),xRr=o(" \u2014 "),AZ=a("a"),$Rr=o("TFDistilBertForSequenceClassification"),kRr=o(" (DistilBERT model)"),SRr=l(),XC=a("li"),qCe=a("strong"),RRr=o("electra"),PRr=o(" \u2014 "),LZ=a("a"),BRr=o("TFElectraForSequenceClassification"),IRr=o(" (ELECTRA model)"),NRr=l(),zC=a("li"),jCe=a("strong"),qRr=o("flaubert"),jRr=o(" \u2014 "),yZ=a("a"),DRr=o("TFFlaubertForSequenceClassification"),GRr=o(" (FlauBERT model)"),ORr=l(),WC=a("li"),DCe=a("strong"),VRr=o("funnel"),XRr=o(" \u2014 "),xZ=a("a"),zRr=o("TFFunnelForSequenceClassification"),WRr=o(" (Funnel Transformer model)"),QRr=l(),QC=a("li"),GCe=a("strong"),URr=o("gpt2"),HRr=o(" \u2014 "),$Z=a("a"),JRr=o("TFGPT2ForSequenceClassification"),YRr=o(" (OpenAI GPT-2 model)"),KRr=l(),UC=a("li"),OCe=a("strong"),ZRr=o("gptj"),ePr=o(" \u2014 "),kZ=a("a"),oPr=o("TFGPTJForSequenceClassification"),rPr=o(" (GPT-J model)"),tPr=l(),HC=a("li"),VCe=a("strong"),aPr=o("layoutlm"),nPr=o(" \u2014 "),SZ=a("a"),sPr=o("TFLayoutLMForSequenceClassification"),lPr=o(" (LayoutLM model)"),iPr=l(),JC=a("li"),XCe=a("strong"),dPr=o("longformer"),cPr=o(" \u2014 "),RZ=a("a"),fPr=o("TFLongformerForSequenceClassification"),mPr=o(" (Longformer model)"),gPr=l(),YC=a("li"),zCe=a("strong"),hPr=o("mobilebert"),pPr=o(" \u2014 "),PZ=a("a"),_Pr=o("TFMobileBertForSequenceClassification"),uPr=o(" (MobileBERT model)"),bPr=l(),KC=a("li"),WCe=a("strong"),vPr=o("mpnet"),FPr=o(" \u2014 "),BZ=a("a"),TPr=o("TFMPNetForSequenceClassification"),MPr=o(" (MPNet model)"),EPr=l(),ZC=a("li"),QCe=a("strong"),CPr=o("openai-gpt"),wPr=o(" \u2014 "),IZ=a("a"),APr=o("TFOpenAIGPTForSequenceClassification"),LPr=o(" (OpenAI GPT model)"),yPr=l(),e3=a("li"),UCe=a("strong"),xPr=o("rembert"),$Pr=o(" \u2014 "),NZ=a("a"),kPr=o("TFRemBertForSequenceClassification"),SPr=o(" (RemBERT model)"),RPr=l(),o3=a("li"),HCe=a("strong"),PPr=o("roberta"),BPr=o(" \u2014 "),qZ=a("a"),IPr=o("TFRobertaForSequenceClassification"),NPr=o(" (RoBERTa model)"),qPr=l(),r3=a("li"),JCe=a("strong"),jPr=o("roformer"),DPr=o(" \u2014 "),jZ=a("a"),GPr=o("TFRoFormerForSequenceClassification"),OPr=o(" (RoFormer model)"),VPr=l(),t3=a("li"),YCe=a("strong"),XPr=o("tapas"),zPr=o(" \u2014 "),DZ=a("a"),WPr=o("TFTapasForSequenceClassification"),QPr=o(" (TAPAS model)"),UPr=l(),a3=a("li"),KCe=a("strong"),HPr=o("transfo-xl"),JPr=o(" \u2014 "),GZ=a("a"),YPr=o("TFTransfoXLForSequenceClassification"),KPr=o(" (Transformer-XL model)"),ZPr=l(),n3=a("li"),ZCe=a("strong"),eBr=o("xlm"),oBr=o(" \u2014 "),OZ=a("a"),rBr=o("TFXLMForSequenceClassification"),tBr=o(" (XLM model)"),aBr=l(),s3=a("li"),e3e=a("strong"),nBr=o("xlm-roberta"),sBr=o(" \u2014 "),VZ=a("a"),lBr=o("TFXLMRobertaForSequenceClassification"),iBr=o(" (XLM-RoBERTa model)"),dBr=l(),l3=a("li"),o3e=a("strong"),cBr=o("xlnet"),fBr=o(" \u2014 "),XZ=a("a"),mBr=o("TFXLNetForSequenceClassification"),gBr=o(" (XLNet model)"),hBr=l(),F(i3.$$.fragment),iUe=l(),qc=a("h2"),d3=a("a"),r3e=a("span"),F(v$.$$.fragment),pBr=l(),t3e=a("span"),_Br=o("TFAutoModelForMultipleChoice"),dUe=l(),fr=a("div"),F(F$.$$.fragment),uBr=l(),jc=a("p"),bBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zZ=a("a"),vBr=o("from_pretrained()"),FBr=o(" class method or the "),WZ=a("a"),TBr=o("from_config()"),MBr=o(` class
method.`),EBr=l(),T$=a("p"),CBr=o("This class cannot be instantiated directly using "),a3e=a("code"),wBr=o("__init__()"),ABr=o(" (throws an error)."),LBr=l(),Vt=a("div"),F(M$.$$.fragment),yBr=l(),n3e=a("p"),xBr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$Br=l(),Dc=a("p"),kBr=o(`Note:
Loading a model from its configuration file does `),s3e=a("strong"),SBr=o("not"),RBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QZ=a("a"),PBr=o("from_pretrained()"),BBr=o(" to load the model weights."),IBr=l(),F(c3.$$.fragment),NBr=l(),jr=a("div"),F(E$.$$.fragment),qBr=l(),l3e=a("p"),jBr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),DBr=l(),Fn=a("p"),GBr=o("The model class to instantiate is selected based on the "),i3e=a("code"),OBr=o("model_type"),VBr=o(` property of the config object (either
passed as an argument or loaded from `),d3e=a("code"),XBr=o("pretrained_model_name_or_path"),zBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c3e=a("code"),WBr=o("pretrained_model_name_or_path"),QBr=o(":"),UBr=l(),ve=a("ul"),f3=a("li"),f3e=a("strong"),HBr=o("albert"),JBr=o(" \u2014 "),UZ=a("a"),YBr=o("TFAlbertForMultipleChoice"),KBr=o(" (ALBERT model)"),ZBr=l(),m3=a("li"),m3e=a("strong"),eIr=o("bert"),oIr=o(" \u2014 "),HZ=a("a"),rIr=o("TFBertForMultipleChoice"),tIr=o(" (BERT model)"),aIr=l(),g3=a("li"),g3e=a("strong"),nIr=o("camembert"),sIr=o(" \u2014 "),JZ=a("a"),lIr=o("TFCamembertForMultipleChoice"),iIr=o(" (CamemBERT model)"),dIr=l(),h3=a("li"),h3e=a("strong"),cIr=o("convbert"),fIr=o(" \u2014 "),YZ=a("a"),mIr=o("TFConvBertForMultipleChoice"),gIr=o(" (ConvBERT model)"),hIr=l(),p3=a("li"),p3e=a("strong"),pIr=o("distilbert"),_Ir=o(" \u2014 "),KZ=a("a"),uIr=o("TFDistilBertForMultipleChoice"),bIr=o(" (DistilBERT model)"),vIr=l(),_3=a("li"),_3e=a("strong"),FIr=o("electra"),TIr=o(" \u2014 "),ZZ=a("a"),MIr=o("TFElectraForMultipleChoice"),EIr=o(" (ELECTRA model)"),CIr=l(),u3=a("li"),u3e=a("strong"),wIr=o("flaubert"),AIr=o(" \u2014 "),eee=a("a"),LIr=o("TFFlaubertForMultipleChoice"),yIr=o(" (FlauBERT model)"),xIr=l(),b3=a("li"),b3e=a("strong"),$Ir=o("funnel"),kIr=o(" \u2014 "),oee=a("a"),SIr=o("TFFunnelForMultipleChoice"),RIr=o(" (Funnel Transformer model)"),PIr=l(),v3=a("li"),v3e=a("strong"),BIr=o("longformer"),IIr=o(" \u2014 "),ree=a("a"),NIr=o("TFLongformerForMultipleChoice"),qIr=o(" (Longformer model)"),jIr=l(),F3=a("li"),F3e=a("strong"),DIr=o("mobilebert"),GIr=o(" \u2014 "),tee=a("a"),OIr=o("TFMobileBertForMultipleChoice"),VIr=o(" (MobileBERT model)"),XIr=l(),T3=a("li"),T3e=a("strong"),zIr=o("mpnet"),WIr=o(" \u2014 "),aee=a("a"),QIr=o("TFMPNetForMultipleChoice"),UIr=o(" (MPNet model)"),HIr=l(),M3=a("li"),M3e=a("strong"),JIr=o("rembert"),YIr=o(" \u2014 "),nee=a("a"),KIr=o("TFRemBertForMultipleChoice"),ZIr=o(" (RemBERT model)"),eNr=l(),E3=a("li"),E3e=a("strong"),oNr=o("roberta"),rNr=o(" \u2014 "),see=a("a"),tNr=o("TFRobertaForMultipleChoice"),aNr=o(" (RoBERTa model)"),nNr=l(),C3=a("li"),C3e=a("strong"),sNr=o("roformer"),lNr=o(" \u2014 "),lee=a("a"),iNr=o("TFRoFormerForMultipleChoice"),dNr=o(" (RoFormer model)"),cNr=l(),w3=a("li"),w3e=a("strong"),fNr=o("xlm"),mNr=o(" \u2014 "),iee=a("a"),gNr=o("TFXLMForMultipleChoice"),hNr=o(" (XLM model)"),pNr=l(),A3=a("li"),A3e=a("strong"),_Nr=o("xlm-roberta"),uNr=o(" \u2014 "),dee=a("a"),bNr=o("TFXLMRobertaForMultipleChoice"),vNr=o(" (XLM-RoBERTa model)"),FNr=l(),L3=a("li"),L3e=a("strong"),TNr=o("xlnet"),MNr=o(" \u2014 "),cee=a("a"),ENr=o("TFXLNetForMultipleChoice"),CNr=o(" (XLNet model)"),wNr=l(),F(y3.$$.fragment),cUe=l(),Gc=a("h2"),x3=a("a"),y3e=a("span"),F(C$.$$.fragment),ANr=l(),x3e=a("span"),LNr=o("TFAutoModelForNextSentencePrediction"),fUe=l(),mr=a("div"),F(w$.$$.fragment),yNr=l(),Oc=a("p"),xNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fee=a("a"),$Nr=o("from_pretrained()"),kNr=o(" class method or the "),mee=a("a"),SNr=o("from_config()"),RNr=o(` class
method.`),PNr=l(),A$=a("p"),BNr=o("This class cannot be instantiated directly using "),$3e=a("code"),INr=o("__init__()"),NNr=o(" (throws an error)."),qNr=l(),Xt=a("div"),F(L$.$$.fragment),jNr=l(),k3e=a("p"),DNr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),GNr=l(),Vc=a("p"),ONr=o(`Note:
Loading a model from its configuration file does `),S3e=a("strong"),VNr=o("not"),XNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=a("a"),zNr=o("from_pretrained()"),WNr=o(" to load the model weights."),QNr=l(),F($3.$$.fragment),UNr=l(),Dr=a("div"),F(y$.$$.fragment),HNr=l(),R3e=a("p"),JNr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),YNr=l(),Tn=a("p"),KNr=o("The model class to instantiate is selected based on the "),P3e=a("code"),ZNr=o("model_type"),eqr=o(` property of the config object (either
passed as an argument or loaded from `),B3e=a("code"),oqr=o("pretrained_model_name_or_path"),rqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I3e=a("code"),tqr=o("pretrained_model_name_or_path"),aqr=o(":"),nqr=l(),x$=a("ul"),k3=a("li"),N3e=a("strong"),sqr=o("bert"),lqr=o(" \u2014 "),hee=a("a"),iqr=o("TFBertForNextSentencePrediction"),dqr=o(" (BERT model)"),cqr=l(),S3=a("li"),q3e=a("strong"),fqr=o("mobilebert"),mqr=o(" \u2014 "),pee=a("a"),gqr=o("TFMobileBertForNextSentencePrediction"),hqr=o(" (MobileBERT model)"),pqr=l(),F(R3.$$.fragment),mUe=l(),Xc=a("h2"),P3=a("a"),j3e=a("span"),F($$.$$.fragment),_qr=l(),D3e=a("span"),uqr=o("TFAutoModelForTableQuestionAnswering"),gUe=l(),gr=a("div"),F(k$.$$.fragment),bqr=l(),zc=a("p"),vqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),_ee=a("a"),Fqr=o("from_pretrained()"),Tqr=o(" class method or the "),uee=a("a"),Mqr=o("from_config()"),Eqr=o(` class
method.`),Cqr=l(),S$=a("p"),wqr=o("This class cannot be instantiated directly using "),G3e=a("code"),Aqr=o("__init__()"),Lqr=o(" (throws an error)."),yqr=l(),zt=a("div"),F(R$.$$.fragment),xqr=l(),O3e=a("p"),$qr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),kqr=l(),Wc=a("p"),Sqr=o(`Note:
Loading a model from its configuration file does `),V3e=a("strong"),Rqr=o("not"),Pqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bee=a("a"),Bqr=o("from_pretrained()"),Iqr=o(" to load the model weights."),Nqr=l(),F(B3.$$.fragment),qqr=l(),Gr=a("div"),F(P$.$$.fragment),jqr=l(),X3e=a("p"),Dqr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Gqr=l(),Mn=a("p"),Oqr=o("The model class to instantiate is selected based on the "),z3e=a("code"),Vqr=o("model_type"),Xqr=o(` property of the config object (either
passed as an argument or loaded from `),W3e=a("code"),zqr=o("pretrained_model_name_or_path"),Wqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q3e=a("code"),Qqr=o("pretrained_model_name_or_path"),Uqr=o(":"),Hqr=l(),U3e=a("ul"),I3=a("li"),H3e=a("strong"),Jqr=o("tapas"),Yqr=o(" \u2014 "),vee=a("a"),Kqr=o("TFTapasForQuestionAnswering"),Zqr=o(" (TAPAS model)"),ejr=l(),F(N3.$$.fragment),hUe=l(),Qc=a("h2"),q3=a("a"),J3e=a("span"),F(B$.$$.fragment),ojr=l(),Y3e=a("span"),rjr=o("TFAutoModelForTokenClassification"),pUe=l(),hr=a("div"),F(I$.$$.fragment),tjr=l(),Uc=a("p"),ajr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Fee=a("a"),njr=o("from_pretrained()"),sjr=o(" class method or the "),Tee=a("a"),ljr=o("from_config()"),ijr=o(` class
method.`),djr=l(),N$=a("p"),cjr=o("This class cannot be instantiated directly using "),K3e=a("code"),fjr=o("__init__()"),mjr=o(" (throws an error)."),gjr=l(),Wt=a("div"),F(q$.$$.fragment),hjr=l(),Z3e=a("p"),pjr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),_jr=l(),Hc=a("p"),ujr=o(`Note:
Loading a model from its configuration file does `),e0e=a("strong"),bjr=o("not"),vjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mee=a("a"),Fjr=o("from_pretrained()"),Tjr=o(" to load the model weights."),Mjr=l(),F(j3.$$.fragment),Ejr=l(),Or=a("div"),F(j$.$$.fragment),Cjr=l(),o0e=a("p"),wjr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Ajr=l(),En=a("p"),Ljr=o("The model class to instantiate is selected based on the "),r0e=a("code"),yjr=o("model_type"),xjr=o(` property of the config object (either
passed as an argument or loaded from `),t0e=a("code"),$jr=o("pretrained_model_name_or_path"),kjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=a("code"),Sjr=o("pretrained_model_name_or_path"),Rjr=o(":"),Pjr=l(),de=a("ul"),D3=a("li"),n0e=a("strong"),Bjr=o("albert"),Ijr=o(" \u2014 "),Eee=a("a"),Njr=o("TFAlbertForTokenClassification"),qjr=o(" (ALBERT model)"),jjr=l(),G3=a("li"),s0e=a("strong"),Djr=o("bert"),Gjr=o(" \u2014 "),Cee=a("a"),Ojr=o("TFBertForTokenClassification"),Vjr=o(" (BERT model)"),Xjr=l(),O3=a("li"),l0e=a("strong"),zjr=o("camembert"),Wjr=o(" \u2014 "),wee=a("a"),Qjr=o("TFCamembertForTokenClassification"),Ujr=o(" (CamemBERT model)"),Hjr=l(),V3=a("li"),i0e=a("strong"),Jjr=o("convbert"),Yjr=o(" \u2014 "),Aee=a("a"),Kjr=o("TFConvBertForTokenClassification"),Zjr=o(" (ConvBERT model)"),eDr=l(),X3=a("li"),d0e=a("strong"),oDr=o("deberta"),rDr=o(" \u2014 "),Lee=a("a"),tDr=o("TFDebertaForTokenClassification"),aDr=o(" (DeBERTa model)"),nDr=l(),z3=a("li"),c0e=a("strong"),sDr=o("deberta-v2"),lDr=o(" \u2014 "),yee=a("a"),iDr=o("TFDebertaV2ForTokenClassification"),dDr=o(" (DeBERTa-v2 model)"),cDr=l(),W3=a("li"),f0e=a("strong"),fDr=o("distilbert"),mDr=o(" \u2014 "),xee=a("a"),gDr=o("TFDistilBertForTokenClassification"),hDr=o(" (DistilBERT model)"),pDr=l(),Q3=a("li"),m0e=a("strong"),_Dr=o("electra"),uDr=o(" \u2014 "),$ee=a("a"),bDr=o("TFElectraForTokenClassification"),vDr=o(" (ELECTRA model)"),FDr=l(),U3=a("li"),g0e=a("strong"),TDr=o("flaubert"),MDr=o(" \u2014 "),kee=a("a"),EDr=o("TFFlaubertForTokenClassification"),CDr=o(" (FlauBERT model)"),wDr=l(),H3=a("li"),h0e=a("strong"),ADr=o("funnel"),LDr=o(" \u2014 "),See=a("a"),yDr=o("TFFunnelForTokenClassification"),xDr=o(" (Funnel Transformer model)"),$Dr=l(),J3=a("li"),p0e=a("strong"),kDr=o("layoutlm"),SDr=o(" \u2014 "),Ree=a("a"),RDr=o("TFLayoutLMForTokenClassification"),PDr=o(" (LayoutLM model)"),BDr=l(),Y3=a("li"),_0e=a("strong"),IDr=o("longformer"),NDr=o(" \u2014 "),Pee=a("a"),qDr=o("TFLongformerForTokenClassification"),jDr=o(" (Longformer model)"),DDr=l(),K3=a("li"),u0e=a("strong"),GDr=o("mobilebert"),ODr=o(" \u2014 "),Bee=a("a"),VDr=o("TFMobileBertForTokenClassification"),XDr=o(" (MobileBERT model)"),zDr=l(),Z3=a("li"),b0e=a("strong"),WDr=o("mpnet"),QDr=o(" \u2014 "),Iee=a("a"),UDr=o("TFMPNetForTokenClassification"),HDr=o(" (MPNet model)"),JDr=l(),e0=a("li"),v0e=a("strong"),YDr=o("rembert"),KDr=o(" \u2014 "),Nee=a("a"),ZDr=o("TFRemBertForTokenClassification"),eGr=o(" (RemBERT model)"),oGr=l(),o0=a("li"),F0e=a("strong"),rGr=o("roberta"),tGr=o(" \u2014 "),qee=a("a"),aGr=o("TFRobertaForTokenClassification"),nGr=o(" (RoBERTa model)"),sGr=l(),r0=a("li"),T0e=a("strong"),lGr=o("roformer"),iGr=o(" \u2014 "),jee=a("a"),dGr=o("TFRoFormerForTokenClassification"),cGr=o(" (RoFormer model)"),fGr=l(),t0=a("li"),M0e=a("strong"),mGr=o("xlm"),gGr=o(" \u2014 "),Dee=a("a"),hGr=o("TFXLMForTokenClassification"),pGr=o(" (XLM model)"),_Gr=l(),a0=a("li"),E0e=a("strong"),uGr=o("xlm-roberta"),bGr=o(" \u2014 "),Gee=a("a"),vGr=o("TFXLMRobertaForTokenClassification"),FGr=o(" (XLM-RoBERTa model)"),TGr=l(),n0=a("li"),C0e=a("strong"),MGr=o("xlnet"),EGr=o(" \u2014 "),Oee=a("a"),CGr=o("TFXLNetForTokenClassification"),wGr=o(" (XLNet model)"),AGr=l(),F(s0.$$.fragment),_Ue=l(),Jc=a("h2"),l0=a("a"),w0e=a("span"),F(D$.$$.fragment),LGr=l(),A0e=a("span"),yGr=o("TFAutoModelForQuestionAnswering"),uUe=l(),pr=a("div"),F(G$.$$.fragment),xGr=l(),Yc=a("p"),$Gr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Vee=a("a"),kGr=o("from_pretrained()"),SGr=o(" class method or the "),Xee=a("a"),RGr=o("from_config()"),PGr=o(` class
method.`),BGr=l(),O$=a("p"),IGr=o("This class cannot be instantiated directly using "),L0e=a("code"),NGr=o("__init__()"),qGr=o(" (throws an error)."),jGr=l(),Qt=a("div"),F(V$.$$.fragment),DGr=l(),y0e=a("p"),GGr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),OGr=l(),Kc=a("p"),VGr=o(`Note:
Loading a model from its configuration file does `),x0e=a("strong"),XGr=o("not"),zGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=a("a"),WGr=o("from_pretrained()"),QGr=o(" to load the model weights."),UGr=l(),F(i0.$$.fragment),HGr=l(),Vr=a("div"),F(X$.$$.fragment),JGr=l(),$0e=a("p"),YGr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),KGr=l(),Cn=a("p"),ZGr=o("The model class to instantiate is selected based on the "),k0e=a("code"),eOr=o("model_type"),oOr=o(` property of the config object (either
passed as an argument or loaded from `),S0e=a("code"),rOr=o("pretrained_model_name_or_path"),tOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R0e=a("code"),aOr=o("pretrained_model_name_or_path"),nOr=o(":"),sOr=l(),ce=a("ul"),d0=a("li"),P0e=a("strong"),lOr=o("albert"),iOr=o(" \u2014 "),Wee=a("a"),dOr=o("TFAlbertForQuestionAnswering"),cOr=o(" (ALBERT model)"),fOr=l(),c0=a("li"),B0e=a("strong"),mOr=o("bert"),gOr=o(" \u2014 "),Qee=a("a"),hOr=o("TFBertForQuestionAnswering"),pOr=o(" (BERT model)"),_Or=l(),f0=a("li"),I0e=a("strong"),uOr=o("camembert"),bOr=o(" \u2014 "),Uee=a("a"),vOr=o("TFCamembertForQuestionAnswering"),FOr=o(" (CamemBERT model)"),TOr=l(),m0=a("li"),N0e=a("strong"),MOr=o("convbert"),EOr=o(" \u2014 "),Hee=a("a"),COr=o("TFConvBertForQuestionAnswering"),wOr=o(" (ConvBERT model)"),AOr=l(),g0=a("li"),q0e=a("strong"),LOr=o("deberta"),yOr=o(" \u2014 "),Jee=a("a"),xOr=o("TFDebertaForQuestionAnswering"),$Or=o(" (DeBERTa model)"),kOr=l(),h0=a("li"),j0e=a("strong"),SOr=o("deberta-v2"),ROr=o(" \u2014 "),Yee=a("a"),POr=o("TFDebertaV2ForQuestionAnswering"),BOr=o(" (DeBERTa-v2 model)"),IOr=l(),p0=a("li"),D0e=a("strong"),NOr=o("distilbert"),qOr=o(" \u2014 "),Kee=a("a"),jOr=o("TFDistilBertForQuestionAnswering"),DOr=o(" (DistilBERT model)"),GOr=l(),_0=a("li"),G0e=a("strong"),OOr=o("electra"),VOr=o(" \u2014 "),Zee=a("a"),XOr=o("TFElectraForQuestionAnswering"),zOr=o(" (ELECTRA model)"),WOr=l(),u0=a("li"),O0e=a("strong"),QOr=o("flaubert"),UOr=o(" \u2014 "),eoe=a("a"),HOr=o("TFFlaubertForQuestionAnsweringSimple"),JOr=o(" (FlauBERT model)"),YOr=l(),b0=a("li"),V0e=a("strong"),KOr=o("funnel"),ZOr=o(" \u2014 "),ooe=a("a"),eVr=o("TFFunnelForQuestionAnswering"),oVr=o(" (Funnel Transformer model)"),rVr=l(),v0=a("li"),X0e=a("strong"),tVr=o("gptj"),aVr=o(" \u2014 "),roe=a("a"),nVr=o("TFGPTJForQuestionAnswering"),sVr=o(" (GPT-J model)"),lVr=l(),F0=a("li"),z0e=a("strong"),iVr=o("longformer"),dVr=o(" \u2014 "),toe=a("a"),cVr=o("TFLongformerForQuestionAnswering"),fVr=o(" (Longformer model)"),mVr=l(),T0=a("li"),W0e=a("strong"),gVr=o("mobilebert"),hVr=o(" \u2014 "),aoe=a("a"),pVr=o("TFMobileBertForQuestionAnswering"),_Vr=o(" (MobileBERT model)"),uVr=l(),M0=a("li"),Q0e=a("strong"),bVr=o("mpnet"),vVr=o(" \u2014 "),noe=a("a"),FVr=o("TFMPNetForQuestionAnswering"),TVr=o(" (MPNet model)"),MVr=l(),E0=a("li"),U0e=a("strong"),EVr=o("rembert"),CVr=o(" \u2014 "),soe=a("a"),wVr=o("TFRemBertForQuestionAnswering"),AVr=o(" (RemBERT model)"),LVr=l(),C0=a("li"),H0e=a("strong"),yVr=o("roberta"),xVr=o(" \u2014 "),loe=a("a"),$Vr=o("TFRobertaForQuestionAnswering"),kVr=o(" (RoBERTa model)"),SVr=l(),w0=a("li"),J0e=a("strong"),RVr=o("roformer"),PVr=o(" \u2014 "),ioe=a("a"),BVr=o("TFRoFormerForQuestionAnswering"),IVr=o(" (RoFormer model)"),NVr=l(),A0=a("li"),Y0e=a("strong"),qVr=o("xlm"),jVr=o(" \u2014 "),doe=a("a"),DVr=o("TFXLMForQuestionAnsweringSimple"),GVr=o(" (XLM model)"),OVr=l(),L0=a("li"),K0e=a("strong"),VVr=o("xlm-roberta"),XVr=o(" \u2014 "),coe=a("a"),zVr=o("TFXLMRobertaForQuestionAnswering"),WVr=o(" (XLM-RoBERTa model)"),QVr=l(),y0=a("li"),Z0e=a("strong"),UVr=o("xlnet"),HVr=o(" \u2014 "),foe=a("a"),JVr=o("TFXLNetForQuestionAnsweringSimple"),YVr=o(" (XLNet model)"),KVr=l(),F(x0.$$.fragment),bUe=l(),Zc=a("h2"),$0=a("a"),ewe=a("span"),F(z$.$$.fragment),ZVr=l(),owe=a("span"),eXr=o("TFAutoModelForVision2Seq"),vUe=l(),_r=a("div"),F(W$.$$.fragment),oXr=l(),ef=a("p"),rXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),moe=a("a"),tXr=o("from_pretrained()"),aXr=o(" class method or the "),goe=a("a"),nXr=o("from_config()"),sXr=o(` class
method.`),lXr=l(),Q$=a("p"),iXr=o("This class cannot be instantiated directly using "),rwe=a("code"),dXr=o("__init__()"),cXr=o(" (throws an error)."),fXr=l(),Ut=a("div"),F(U$.$$.fragment),mXr=l(),twe=a("p"),gXr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),hXr=l(),of=a("p"),pXr=o(`Note:
Loading a model from its configuration file does `),awe=a("strong"),_Xr=o("not"),uXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hoe=a("a"),bXr=o("from_pretrained()"),vXr=o(" to load the model weights."),FXr=l(),F(k0.$$.fragment),TXr=l(),Xr=a("div"),F(H$.$$.fragment),MXr=l(),nwe=a("p"),EXr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),CXr=l(),wn=a("p"),wXr=o("The model class to instantiate is selected based on the "),swe=a("code"),AXr=o("model_type"),LXr=o(` property of the config object (either
passed as an argument or loaded from `),lwe=a("code"),yXr=o("pretrained_model_name_or_path"),xXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iwe=a("code"),$Xr=o("pretrained_model_name_or_path"),kXr=o(":"),SXr=l(),dwe=a("ul"),S0=a("li"),cwe=a("strong"),RXr=o("vision-encoder-decoder"),PXr=o(" \u2014 "),poe=a("a"),BXr=o("TFVisionEncoderDecoderModel"),IXr=o(" (Vision Encoder decoder model)"),NXr=l(),F(R0.$$.fragment),FUe=l(),rf=a("h2"),P0=a("a"),fwe=a("span"),F(J$.$$.fragment),qXr=l(),mwe=a("span"),jXr=o("TFAutoModelForSpeechSeq2Seq"),TUe=l(),ur=a("div"),F(Y$.$$.fragment),DXr=l(),tf=a("p"),GXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),_oe=a("a"),OXr=o("from_pretrained()"),VXr=o(" class method or the "),uoe=a("a"),XXr=o("from_config()"),zXr=o(` class
method.`),WXr=l(),K$=a("p"),QXr=o("This class cannot be instantiated directly using "),gwe=a("code"),UXr=o("__init__()"),HXr=o(" (throws an error)."),JXr=l(),Ht=a("div"),F(Z$.$$.fragment),YXr=l(),hwe=a("p"),KXr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ZXr=l(),af=a("p"),ezr=o(`Note:
Loading a model from its configuration file does `),pwe=a("strong"),ozr=o("not"),rzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=a("a"),tzr=o("from_pretrained()"),azr=o(" to load the model weights."),nzr=l(),F(B0.$$.fragment),szr=l(),zr=a("div"),F(ek.$$.fragment),lzr=l(),_we=a("p"),izr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),dzr=l(),An=a("p"),czr=o("The model class to instantiate is selected based on the "),uwe=a("code"),fzr=o("model_type"),mzr=o(` property of the config object (either
passed as an argument or loaded from `),bwe=a("code"),gzr=o("pretrained_model_name_or_path"),hzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vwe=a("code"),pzr=o("pretrained_model_name_or_path"),_zr=o(":"),uzr=l(),Fwe=a("ul"),I0=a("li"),Twe=a("strong"),bzr=o("speech_to_text"),vzr=o(" \u2014 "),voe=a("a"),Fzr=o("TFSpeech2TextForConditionalGeneration"),Tzr=o(" (Speech2Text model)"),Mzr=l(),F(N0.$$.fragment),MUe=l(),nf=a("h2"),q0=a("a"),Mwe=a("span"),F(ok.$$.fragment),Ezr=l(),Ewe=a("span"),Czr=o("FlaxAutoModel"),EUe=l(),br=a("div"),F(rk.$$.fragment),wzr=l(),sf=a("p"),Azr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Foe=a("a"),Lzr=o("from_pretrained()"),yzr=o(" class method or the "),Toe=a("a"),xzr=o("from_config()"),$zr=o(` class
method.`),kzr=l(),tk=a("p"),Szr=o("This class cannot be instantiated directly using "),Cwe=a("code"),Rzr=o("__init__()"),Pzr=o(" (throws an error)."),Bzr=l(),Jt=a("div"),F(ak.$$.fragment),Izr=l(),wwe=a("p"),Nzr=o("Instantiates one of the base model classes of the library from a configuration."),qzr=l(),lf=a("p"),jzr=o(`Note:
Loading a model from its configuration file does `),Awe=a("strong"),Dzr=o("not"),Gzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Moe=a("a"),Ozr=o("from_pretrained()"),Vzr=o(" to load the model weights."),Xzr=l(),F(j0.$$.fragment),zzr=l(),Wr=a("div"),F(nk.$$.fragment),Wzr=l(),Lwe=a("p"),Qzr=o("Instantiate one of the base model classes of the library from a pretrained model."),Uzr=l(),Ln=a("p"),Hzr=o("The model class to instantiate is selected based on the "),ywe=a("code"),Jzr=o("model_type"),Yzr=o(` property of the config object (either
passed as an argument or loaded from `),xwe=a("code"),Kzr=o("pretrained_model_name_or_path"),Zzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=a("code"),eWr=o("pretrained_model_name_or_path"),oWr=o(":"),rWr=l(),oe=a("ul"),D0=a("li"),kwe=a("strong"),tWr=o("albert"),aWr=o(" \u2014 "),Eoe=a("a"),nWr=o("FlaxAlbertModel"),sWr=o(" (ALBERT model)"),lWr=l(),G0=a("li"),Swe=a("strong"),iWr=o("bart"),dWr=o(" \u2014 "),Coe=a("a"),cWr=o("FlaxBartModel"),fWr=o(" (BART model)"),mWr=l(),O0=a("li"),Rwe=a("strong"),gWr=o("beit"),hWr=o(" \u2014 "),woe=a("a"),pWr=o("FlaxBeitModel"),_Wr=o(" (BEiT model)"),uWr=l(),V0=a("li"),Pwe=a("strong"),bWr=o("bert"),vWr=o(" \u2014 "),Aoe=a("a"),FWr=o("FlaxBertModel"),TWr=o(" (BERT model)"),MWr=l(),X0=a("li"),Bwe=a("strong"),EWr=o("big_bird"),CWr=o(" \u2014 "),Loe=a("a"),wWr=o("FlaxBigBirdModel"),AWr=o(" (BigBird model)"),LWr=l(),z0=a("li"),Iwe=a("strong"),yWr=o("blenderbot"),xWr=o(" \u2014 "),yoe=a("a"),$Wr=o("FlaxBlenderbotModel"),kWr=o(" (Blenderbot model)"),SWr=l(),W0=a("li"),Nwe=a("strong"),RWr=o("blenderbot-small"),PWr=o(" \u2014 "),xoe=a("a"),BWr=o("FlaxBlenderbotSmallModel"),IWr=o(" (BlenderbotSmall model)"),NWr=l(),Q0=a("li"),qwe=a("strong"),qWr=o("clip"),jWr=o(" \u2014 "),$oe=a("a"),DWr=o("FlaxCLIPModel"),GWr=o(" (CLIP model)"),OWr=l(),U0=a("li"),jwe=a("strong"),VWr=o("distilbert"),XWr=o(" \u2014 "),koe=a("a"),zWr=o("FlaxDistilBertModel"),WWr=o(" (DistilBERT model)"),QWr=l(),H0=a("li"),Dwe=a("strong"),UWr=o("electra"),HWr=o(" \u2014 "),Soe=a("a"),JWr=o("FlaxElectraModel"),YWr=o(" (ELECTRA model)"),KWr=l(),J0=a("li"),Gwe=a("strong"),ZWr=o("gpt2"),eQr=o(" \u2014 "),Roe=a("a"),oQr=o("FlaxGPT2Model"),rQr=o(" (OpenAI GPT-2 model)"),tQr=l(),Y0=a("li"),Owe=a("strong"),aQr=o("gpt_neo"),nQr=o(" \u2014 "),Poe=a("a"),sQr=o("FlaxGPTNeoModel"),lQr=o(" (GPT Neo model)"),iQr=l(),K0=a("li"),Vwe=a("strong"),dQr=o("gptj"),cQr=o(" \u2014 "),Boe=a("a"),fQr=o("FlaxGPTJModel"),mQr=o(" (GPT-J model)"),gQr=l(),Z0=a("li"),Xwe=a("strong"),hQr=o("longt5"),pQr=o(" \u2014 "),Ioe=a("a"),_Qr=o("FlaxLongT5Model"),uQr=o(" (LongT5 model)"),bQr=l(),ew=a("li"),zwe=a("strong"),vQr=o("marian"),FQr=o(" \u2014 "),Noe=a("a"),TQr=o("FlaxMarianModel"),MQr=o(" (Marian model)"),EQr=l(),ow=a("li"),Wwe=a("strong"),CQr=o("mbart"),wQr=o(" \u2014 "),qoe=a("a"),AQr=o("FlaxMBartModel"),LQr=o(" (mBART model)"),yQr=l(),rw=a("li"),Qwe=a("strong"),xQr=o("mt5"),$Qr=o(" \u2014 "),joe=a("a"),kQr=o("FlaxMT5Model"),SQr=o(" (MT5 model)"),RQr=l(),tw=a("li"),Uwe=a("strong"),PQr=o("opt"),BQr=o(" \u2014 "),Doe=a("a"),IQr=o("FlaxOPTModel"),NQr=o(" (OPT model)"),qQr=l(),aw=a("li"),Hwe=a("strong"),jQr=o("pegasus"),DQr=o(" \u2014 "),Goe=a("a"),GQr=o("FlaxPegasusModel"),OQr=o(" (Pegasus model)"),VQr=l(),nw=a("li"),Jwe=a("strong"),XQr=o("roberta"),zQr=o(" \u2014 "),Ooe=a("a"),WQr=o("FlaxRobertaModel"),QQr=o(" (RoBERTa model)"),UQr=l(),sw=a("li"),Ywe=a("strong"),HQr=o("roformer"),JQr=o(" \u2014 "),Voe=a("a"),YQr=o("FlaxRoFormerModel"),KQr=o(" (RoFormer model)"),ZQr=l(),lw=a("li"),Kwe=a("strong"),eUr=o("t5"),oUr=o(" \u2014 "),Xoe=a("a"),rUr=o("FlaxT5Model"),tUr=o(" (T5 model)"),aUr=l(),iw=a("li"),Zwe=a("strong"),nUr=o("vision-text-dual-encoder"),sUr=o(" \u2014 "),zoe=a("a"),lUr=o("FlaxVisionTextDualEncoderModel"),iUr=o(" (VisionTextDualEncoder model)"),dUr=l(),dw=a("li"),e6e=a("strong"),cUr=o("vit"),fUr=o(" \u2014 "),Woe=a("a"),mUr=o("FlaxViTModel"),gUr=o(" (ViT model)"),hUr=l(),cw=a("li"),o6e=a("strong"),pUr=o("wav2vec2"),_Ur=o(" \u2014 "),Qoe=a("a"),uUr=o("FlaxWav2Vec2Model"),bUr=o(" (Wav2Vec2 model)"),vUr=l(),fw=a("li"),r6e=a("strong"),FUr=o("xglm"),TUr=o(" \u2014 "),Uoe=a("a"),MUr=o("FlaxXGLMModel"),EUr=o(" (XGLM model)"),CUr=l(),mw=a("li"),t6e=a("strong"),wUr=o("xlm-roberta"),AUr=o(" \u2014 "),Hoe=a("a"),LUr=o("FlaxXLMRobertaModel"),yUr=o(" (XLM-RoBERTa model)"),xUr=l(),F(gw.$$.fragment),CUe=l(),df=a("h2"),hw=a("a"),a6e=a("span"),F(sk.$$.fragment),$Ur=l(),n6e=a("span"),kUr=o("FlaxAutoModelForCausalLM"),wUe=l(),vr=a("div"),F(lk.$$.fragment),SUr=l(),cf=a("p"),RUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Joe=a("a"),PUr=o("from_pretrained()"),BUr=o(" class method or the "),Yoe=a("a"),IUr=o("from_config()"),NUr=o(` class
method.`),qUr=l(),ik=a("p"),jUr=o("This class cannot be instantiated directly using "),s6e=a("code"),DUr=o("__init__()"),GUr=o(" (throws an error)."),OUr=l(),Yt=a("div"),F(dk.$$.fragment),VUr=l(),l6e=a("p"),XUr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),zUr=l(),ff=a("p"),WUr=o(`Note:
Loading a model from its configuration file does `),i6e=a("strong"),QUr=o("not"),UUr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Koe=a("a"),HUr=o("from_pretrained()"),JUr=o(" to load the model weights."),YUr=l(),F(pw.$$.fragment),KUr=l(),Qr=a("div"),F(ck.$$.fragment),ZUr=l(),d6e=a("p"),eHr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),oHr=l(),yn=a("p"),rHr=o("The model class to instantiate is selected based on the "),c6e=a("code"),tHr=o("model_type"),aHr=o(` property of the config object (either
passed as an argument or loaded from `),f6e=a("code"),nHr=o("pretrained_model_name_or_path"),sHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=a("code"),lHr=o("pretrained_model_name_or_path"),iHr=o(":"),dHr=l(),xe=a("ul"),_w=a("li"),g6e=a("strong"),cHr=o("bart"),fHr=o(" \u2014 "),Zoe=a("a"),mHr=o("FlaxBartForCausalLM"),gHr=o(" (BART model)"),hHr=l(),uw=a("li"),h6e=a("strong"),pHr=o("bert"),_Hr=o(" \u2014 "),ere=a("a"),uHr=o("FlaxBertForCausalLM"),bHr=o(" (BERT model)"),vHr=l(),bw=a("li"),p6e=a("strong"),FHr=o("big_bird"),THr=o(" \u2014 "),ore=a("a"),MHr=o("FlaxBigBirdForCausalLM"),EHr=o(" (BigBird model)"),CHr=l(),vw=a("li"),_6e=a("strong"),wHr=o("electra"),AHr=o(" \u2014 "),rre=a("a"),LHr=o("FlaxElectraForCausalLM"),yHr=o(" (ELECTRA model)"),xHr=l(),Fw=a("li"),u6e=a("strong"),$Hr=o("gpt2"),kHr=o(" \u2014 "),tre=a("a"),SHr=o("FlaxGPT2LMHeadModel"),RHr=o(" (OpenAI GPT-2 model)"),PHr=l(),Tw=a("li"),b6e=a("strong"),BHr=o("gpt_neo"),IHr=o(" \u2014 "),are=a("a"),NHr=o("FlaxGPTNeoForCausalLM"),qHr=o(" (GPT Neo model)"),jHr=l(),Mw=a("li"),v6e=a("strong"),DHr=o("gptj"),GHr=o(" \u2014 "),nre=a("a"),OHr=o("FlaxGPTJForCausalLM"),VHr=o(" (GPT-J model)"),XHr=l(),Ew=a("li"),F6e=a("strong"),zHr=o("opt"),WHr=o(" \u2014 "),sre=a("a"),QHr=o("FlaxOPTForCausalLM"),UHr=o(" (OPT model)"),HHr=l(),Cw=a("li"),T6e=a("strong"),JHr=o("roberta"),YHr=o(" \u2014 "),lre=a("a"),KHr=o("FlaxRobertaForCausalLM"),ZHr=o(" (RoBERTa model)"),eJr=l(),ww=a("li"),M6e=a("strong"),oJr=o("xglm"),rJr=o(" \u2014 "),ire=a("a"),tJr=o("FlaxXGLMForCausalLM"),aJr=o(" (XGLM model)"),nJr=l(),F(Aw.$$.fragment),AUe=l(),mf=a("h2"),Lw=a("a"),E6e=a("span"),F(fk.$$.fragment),sJr=l(),C6e=a("span"),lJr=o("FlaxAutoModelForPreTraining"),LUe=l(),Fr=a("div"),F(mk.$$.fragment),iJr=l(),gf=a("p"),dJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),dre=a("a"),cJr=o("from_pretrained()"),fJr=o(" class method or the "),cre=a("a"),mJr=o("from_config()"),gJr=o(` class
method.`),hJr=l(),gk=a("p"),pJr=o("This class cannot be instantiated directly using "),w6e=a("code"),_Jr=o("__init__()"),uJr=o(" (throws an error)."),bJr=l(),Kt=a("div"),F(hk.$$.fragment),vJr=l(),A6e=a("p"),FJr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),TJr=l(),hf=a("p"),MJr=o(`Note:
Loading a model from its configuration file does `),L6e=a("strong"),EJr=o("not"),CJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fre=a("a"),wJr=o("from_pretrained()"),AJr=o(" to load the model weights."),LJr=l(),F(yw.$$.fragment),yJr=l(),Ur=a("div"),F(pk.$$.fragment),xJr=l(),y6e=a("p"),$Jr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),kJr=l(),xn=a("p"),SJr=o("The model class to instantiate is selected based on the "),x6e=a("code"),RJr=o("model_type"),PJr=o(` property of the config object (either
passed as an argument or loaded from `),$6e=a("code"),BJr=o("pretrained_model_name_or_path"),IJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k6e=a("code"),NJr=o("pretrained_model_name_or_path"),qJr=o(":"),jJr=l(),Ee=a("ul"),xw=a("li"),S6e=a("strong"),DJr=o("albert"),GJr=o(" \u2014 "),mre=a("a"),OJr=o("FlaxAlbertForPreTraining"),VJr=o(" (ALBERT model)"),XJr=l(),$w=a("li"),R6e=a("strong"),zJr=o("bart"),WJr=o(" \u2014 "),gre=a("a"),QJr=o("FlaxBartForConditionalGeneration"),UJr=o(" (BART model)"),HJr=l(),kw=a("li"),P6e=a("strong"),JJr=o("bert"),YJr=o(" \u2014 "),hre=a("a"),KJr=o("FlaxBertForPreTraining"),ZJr=o(" (BERT model)"),eYr=l(),Sw=a("li"),B6e=a("strong"),oYr=o("big_bird"),rYr=o(" \u2014 "),pre=a("a"),tYr=o("FlaxBigBirdForPreTraining"),aYr=o(" (BigBird model)"),nYr=l(),Rw=a("li"),I6e=a("strong"),sYr=o("electra"),lYr=o(" \u2014 "),_re=a("a"),iYr=o("FlaxElectraForPreTraining"),dYr=o(" (ELECTRA model)"),cYr=l(),Pw=a("li"),N6e=a("strong"),fYr=o("longt5"),mYr=o(" \u2014 "),ure=a("a"),gYr=o("FlaxLongT5ForConditionalGeneration"),hYr=o(" (LongT5 model)"),pYr=l(),Bw=a("li"),q6e=a("strong"),_Yr=o("mbart"),uYr=o(" \u2014 "),bre=a("a"),bYr=o("FlaxMBartForConditionalGeneration"),vYr=o(" (mBART model)"),FYr=l(),Iw=a("li"),j6e=a("strong"),TYr=o("mt5"),MYr=o(" \u2014 "),vre=a("a"),EYr=o("FlaxMT5ForConditionalGeneration"),CYr=o(" (MT5 model)"),wYr=l(),Nw=a("li"),D6e=a("strong"),AYr=o("roberta"),LYr=o(" \u2014 "),Fre=a("a"),yYr=o("FlaxRobertaForMaskedLM"),xYr=o(" (RoBERTa model)"),$Yr=l(),qw=a("li"),G6e=a("strong"),kYr=o("roformer"),SYr=o(" \u2014 "),Tre=a("a"),RYr=o("FlaxRoFormerForMaskedLM"),PYr=o(" (RoFormer model)"),BYr=l(),jw=a("li"),O6e=a("strong"),IYr=o("t5"),NYr=o(" \u2014 "),Mre=a("a"),qYr=o("FlaxT5ForConditionalGeneration"),jYr=o(" (T5 model)"),DYr=l(),Dw=a("li"),V6e=a("strong"),GYr=o("wav2vec2"),OYr=o(" \u2014 "),Ere=a("a"),VYr=o("FlaxWav2Vec2ForPreTraining"),XYr=o(" (Wav2Vec2 model)"),zYr=l(),Gw=a("li"),X6e=a("strong"),WYr=o("xlm-roberta"),QYr=o(" \u2014 "),Cre=a("a"),UYr=o("FlaxXLMRobertaForMaskedLM"),HYr=o(" (XLM-RoBERTa model)"),JYr=l(),F(Ow.$$.fragment),yUe=l(),pf=a("h2"),Vw=a("a"),z6e=a("span"),F(_k.$$.fragment),YYr=l(),W6e=a("span"),KYr=o("FlaxAutoModelForMaskedLM"),xUe=l(),Tr=a("div"),F(uk.$$.fragment),ZYr=l(),_f=a("p"),eKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),wre=a("a"),oKr=o("from_pretrained()"),rKr=o(" class method or the "),Are=a("a"),tKr=o("from_config()"),aKr=o(` class
method.`),nKr=l(),bk=a("p"),sKr=o("This class cannot be instantiated directly using "),Q6e=a("code"),lKr=o("__init__()"),iKr=o(" (throws an error)."),dKr=l(),Zt=a("div"),F(vk.$$.fragment),cKr=l(),U6e=a("p"),fKr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),mKr=l(),uf=a("p"),gKr=o(`Note:
Loading a model from its configuration file does `),H6e=a("strong"),hKr=o("not"),pKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Lre=a("a"),_Kr=o("from_pretrained()"),uKr=o(" to load the model weights."),bKr=l(),F(Xw.$$.fragment),vKr=l(),Hr=a("div"),F(Fk.$$.fragment),FKr=l(),J6e=a("p"),TKr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),MKr=l(),$n=a("p"),EKr=o("The model class to instantiate is selected based on the "),Y6e=a("code"),CKr=o("model_type"),wKr=o(` property of the config object (either
passed as an argument or loaded from `),K6e=a("code"),AKr=o("pretrained_model_name_or_path"),LKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z6e=a("code"),yKr=o("pretrained_model_name_or_path"),xKr=o(":"),$Kr=l(),$e=a("ul"),zw=a("li"),eAe=a("strong"),kKr=o("albert"),SKr=o(" \u2014 "),yre=a("a"),RKr=o("FlaxAlbertForMaskedLM"),PKr=o(" (ALBERT model)"),BKr=l(),Ww=a("li"),oAe=a("strong"),IKr=o("bart"),NKr=o(" \u2014 "),xre=a("a"),qKr=o("FlaxBartForConditionalGeneration"),jKr=o(" (BART model)"),DKr=l(),Qw=a("li"),rAe=a("strong"),GKr=o("bert"),OKr=o(" \u2014 "),$re=a("a"),VKr=o("FlaxBertForMaskedLM"),XKr=o(" (BERT model)"),zKr=l(),Uw=a("li"),tAe=a("strong"),WKr=o("big_bird"),QKr=o(" \u2014 "),kre=a("a"),UKr=o("FlaxBigBirdForMaskedLM"),HKr=o(" (BigBird model)"),JKr=l(),Hw=a("li"),aAe=a("strong"),YKr=o("distilbert"),KKr=o(" \u2014 "),Sre=a("a"),ZKr=o("FlaxDistilBertForMaskedLM"),eZr=o(" (DistilBERT model)"),oZr=l(),Jw=a("li"),nAe=a("strong"),rZr=o("electra"),tZr=o(" \u2014 "),Rre=a("a"),aZr=o("FlaxElectraForMaskedLM"),nZr=o(" (ELECTRA model)"),sZr=l(),Yw=a("li"),sAe=a("strong"),lZr=o("mbart"),iZr=o(" \u2014 "),Pre=a("a"),dZr=o("FlaxMBartForConditionalGeneration"),cZr=o(" (mBART model)"),fZr=l(),Kw=a("li"),lAe=a("strong"),mZr=o("roberta"),gZr=o(" \u2014 "),Bre=a("a"),hZr=o("FlaxRobertaForMaskedLM"),pZr=o(" (RoBERTa model)"),_Zr=l(),Zw=a("li"),iAe=a("strong"),uZr=o("roformer"),bZr=o(" \u2014 "),Ire=a("a"),vZr=o("FlaxRoFormerForMaskedLM"),FZr=o(" (RoFormer model)"),TZr=l(),e6=a("li"),dAe=a("strong"),MZr=o("xlm-roberta"),EZr=o(" \u2014 "),Nre=a("a"),CZr=o("FlaxXLMRobertaForMaskedLM"),wZr=o(" (XLM-RoBERTa model)"),AZr=l(),F(o6.$$.fragment),$Ue=l(),bf=a("h2"),r6=a("a"),cAe=a("span"),F(Tk.$$.fragment),LZr=l(),fAe=a("span"),yZr=o("FlaxAutoModelForSeq2SeqLM"),kUe=l(),Mr=a("div"),F(Mk.$$.fragment),xZr=l(),vf=a("p"),$Zr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qre=a("a"),kZr=o("from_pretrained()"),SZr=o(" class method or the "),jre=a("a"),RZr=o("from_config()"),PZr=o(` class
method.`),BZr=l(),Ek=a("p"),IZr=o("This class cannot be instantiated directly using "),mAe=a("code"),NZr=o("__init__()"),qZr=o(" (throws an error)."),jZr=l(),ea=a("div"),F(Ck.$$.fragment),DZr=l(),gAe=a("p"),GZr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),OZr=l(),Ff=a("p"),VZr=o(`Note:
Loading a model from its configuration file does `),hAe=a("strong"),XZr=o("not"),zZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Dre=a("a"),WZr=o("from_pretrained()"),QZr=o(" to load the model weights."),UZr=l(),F(t6.$$.fragment),HZr=l(),Jr=a("div"),F(wk.$$.fragment),JZr=l(),pAe=a("p"),YZr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),KZr=l(),kn=a("p"),ZZr=o("The model class to instantiate is selected based on the "),_Ae=a("code"),eet=o("model_type"),oet=o(` property of the config object (either
passed as an argument or loaded from `),uAe=a("code"),ret=o("pretrained_model_name_or_path"),tet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bAe=a("code"),aet=o("pretrained_model_name_or_path"),net=o(":"),set=l(),ke=a("ul"),a6=a("li"),vAe=a("strong"),iet=o("bart"),det=o(" \u2014 "),Gre=a("a"),cet=o("FlaxBartForConditionalGeneration"),fet=o(" (BART model)"),met=l(),n6=a("li"),FAe=a("strong"),get=o("blenderbot"),het=o(" \u2014 "),Ore=a("a"),pet=o("FlaxBlenderbotForConditionalGeneration"),_et=o(" (Blenderbot model)"),uet=l(),s6=a("li"),TAe=a("strong"),bet=o("blenderbot-small"),vet=o(" \u2014 "),Vre=a("a"),Fet=o("FlaxBlenderbotSmallForConditionalGeneration"),Tet=o(" (BlenderbotSmall model)"),Met=l(),l6=a("li"),MAe=a("strong"),Eet=o("encoder-decoder"),Cet=o(" \u2014 "),Xre=a("a"),wet=o("FlaxEncoderDecoderModel"),Aet=o(" (Encoder decoder model)"),Let=l(),i6=a("li"),EAe=a("strong"),yet=o("longt5"),xet=o(" \u2014 "),zre=a("a"),$et=o("FlaxLongT5ForConditionalGeneration"),ket=o(" (LongT5 model)"),Set=l(),d6=a("li"),CAe=a("strong"),Ret=o("marian"),Pet=o(" \u2014 "),Wre=a("a"),Bet=o("FlaxMarianMTModel"),Iet=o(" (Marian model)"),Net=l(),c6=a("li"),wAe=a("strong"),qet=o("mbart"),jet=o(" \u2014 "),Qre=a("a"),Det=o("FlaxMBartForConditionalGeneration"),Get=o(" (mBART model)"),Oet=l(),f6=a("li"),AAe=a("strong"),Vet=o("mt5"),Xet=o(" \u2014 "),Ure=a("a"),zet=o("FlaxMT5ForConditionalGeneration"),Wet=o(" (MT5 model)"),Qet=l(),m6=a("li"),LAe=a("strong"),Uet=o("pegasus"),Het=o(" \u2014 "),Hre=a("a"),Jet=o("FlaxPegasusForConditionalGeneration"),Yet=o(" (Pegasus model)"),Ket=l(),g6=a("li"),yAe=a("strong"),Zet=o("t5"),eot=o(" \u2014 "),Jre=a("a"),oot=o("FlaxT5ForConditionalGeneration"),rot=o(" (T5 model)"),tot=l(),F(h6.$$.fragment),SUe=l(),Tf=a("h2"),p6=a("a"),xAe=a("span"),F(Ak.$$.fragment),aot=l(),$Ae=a("span"),not=o("FlaxAutoModelForSequenceClassification"),RUe=l(),Er=a("div"),F(Lk.$$.fragment),sot=l(),Mf=a("p"),lot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Yre=a("a"),iot=o("from_pretrained()"),dot=o(" class method or the "),Kre=a("a"),cot=o("from_config()"),fot=o(` class
method.`),mot=l(),yk=a("p"),got=o("This class cannot be instantiated directly using "),kAe=a("code"),hot=o("__init__()"),pot=o(" (throws an error)."),_ot=l(),oa=a("div"),F(xk.$$.fragment),uot=l(),SAe=a("p"),bot=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),vot=l(),Ef=a("p"),Fot=o(`Note:
Loading a model from its configuration file does `),RAe=a("strong"),Tot=o("not"),Mot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zre=a("a"),Eot=o("from_pretrained()"),Cot=o(" to load the model weights."),wot=l(),F(_6.$$.fragment),Aot=l(),Yr=a("div"),F($k.$$.fragment),Lot=l(),PAe=a("p"),yot=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),xot=l(),Sn=a("p"),$ot=o("The model class to instantiate is selected based on the "),BAe=a("code"),kot=o("model_type"),Sot=o(` property of the config object (either
passed as an argument or loaded from `),IAe=a("code"),Rot=o("pretrained_model_name_or_path"),Pot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NAe=a("code"),Bot=o("pretrained_model_name_or_path"),Iot=o(":"),Not=l(),Se=a("ul"),u6=a("li"),qAe=a("strong"),qot=o("albert"),jot=o(" \u2014 "),ete=a("a"),Dot=o("FlaxAlbertForSequenceClassification"),Got=o(" (ALBERT model)"),Oot=l(),b6=a("li"),jAe=a("strong"),Vot=o("bart"),Xot=o(" \u2014 "),ote=a("a"),zot=o("FlaxBartForSequenceClassification"),Wot=o(" (BART model)"),Qot=l(),v6=a("li"),DAe=a("strong"),Uot=o("bert"),Hot=o(" \u2014 "),rte=a("a"),Jot=o("FlaxBertForSequenceClassification"),Yot=o(" (BERT model)"),Kot=l(),F6=a("li"),GAe=a("strong"),Zot=o("big_bird"),ert=o(" \u2014 "),tte=a("a"),ort=o("FlaxBigBirdForSequenceClassification"),rrt=o(" (BigBird model)"),trt=l(),T6=a("li"),OAe=a("strong"),art=o("distilbert"),nrt=o(" \u2014 "),ate=a("a"),srt=o("FlaxDistilBertForSequenceClassification"),lrt=o(" (DistilBERT model)"),irt=l(),M6=a("li"),VAe=a("strong"),drt=o("electra"),crt=o(" \u2014 "),nte=a("a"),frt=o("FlaxElectraForSequenceClassification"),mrt=o(" (ELECTRA model)"),grt=l(),E6=a("li"),XAe=a("strong"),hrt=o("mbart"),prt=o(" \u2014 "),ste=a("a"),_rt=o("FlaxMBartForSequenceClassification"),urt=o(" (mBART model)"),brt=l(),C6=a("li"),zAe=a("strong"),vrt=o("roberta"),Frt=o(" \u2014 "),lte=a("a"),Trt=o("FlaxRobertaForSequenceClassification"),Mrt=o(" (RoBERTa model)"),Ert=l(),w6=a("li"),WAe=a("strong"),Crt=o("roformer"),wrt=o(" \u2014 "),ite=a("a"),Art=o("FlaxRoFormerForSequenceClassification"),Lrt=o(" (RoFormer model)"),yrt=l(),A6=a("li"),QAe=a("strong"),xrt=o("xlm-roberta"),$rt=o(" \u2014 "),dte=a("a"),krt=o("FlaxXLMRobertaForSequenceClassification"),Srt=o(" (XLM-RoBERTa model)"),Rrt=l(),F(L6.$$.fragment),PUe=l(),Cf=a("h2"),y6=a("a"),UAe=a("span"),F(kk.$$.fragment),Prt=l(),HAe=a("span"),Brt=o("FlaxAutoModelForQuestionAnswering"),BUe=l(),Cr=a("div"),F(Sk.$$.fragment),Irt=l(),wf=a("p"),Nrt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cte=a("a"),qrt=o("from_pretrained()"),jrt=o(" class method or the "),fte=a("a"),Drt=o("from_config()"),Grt=o(` class
method.`),Ort=l(),Rk=a("p"),Vrt=o("This class cannot be instantiated directly using "),JAe=a("code"),Xrt=o("__init__()"),zrt=o(" (throws an error)."),Wrt=l(),ra=a("div"),F(Pk.$$.fragment),Qrt=l(),YAe=a("p"),Urt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Hrt=l(),Af=a("p"),Jrt=o(`Note:
Loading a model from its configuration file does `),KAe=a("strong"),Yrt=o("not"),Krt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mte=a("a"),Zrt=o("from_pretrained()"),ett=o(" to load the model weights."),ott=l(),F(x6.$$.fragment),rtt=l(),Kr=a("div"),F(Bk.$$.fragment),ttt=l(),ZAe=a("p"),att=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ntt=l(),Rn=a("p"),stt=o("The model class to instantiate is selected based on the "),e7e=a("code"),ltt=o("model_type"),itt=o(` property of the config object (either
passed as an argument or loaded from `),o7e=a("code"),dtt=o("pretrained_model_name_or_path"),ctt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r7e=a("code"),ftt=o("pretrained_model_name_or_path"),mtt=o(":"),gtt=l(),Re=a("ul"),$6=a("li"),t7e=a("strong"),htt=o("albert"),ptt=o(" \u2014 "),gte=a("a"),_tt=o("FlaxAlbertForQuestionAnswering"),utt=o(" (ALBERT model)"),btt=l(),k6=a("li"),a7e=a("strong"),vtt=o("bart"),Ftt=o(" \u2014 "),hte=a("a"),Ttt=o("FlaxBartForQuestionAnswering"),Mtt=o(" (BART model)"),Ett=l(),S6=a("li"),n7e=a("strong"),Ctt=o("bert"),wtt=o(" \u2014 "),pte=a("a"),Att=o("FlaxBertForQuestionAnswering"),Ltt=o(" (BERT model)"),ytt=l(),R6=a("li"),s7e=a("strong"),xtt=o("big_bird"),$tt=o(" \u2014 "),_te=a("a"),ktt=o("FlaxBigBirdForQuestionAnswering"),Stt=o(" (BigBird model)"),Rtt=l(),P6=a("li"),l7e=a("strong"),Ptt=o("distilbert"),Btt=o(" \u2014 "),ute=a("a"),Itt=o("FlaxDistilBertForQuestionAnswering"),Ntt=o(" (DistilBERT model)"),qtt=l(),B6=a("li"),i7e=a("strong"),jtt=o("electra"),Dtt=o(" \u2014 "),bte=a("a"),Gtt=o("FlaxElectraForQuestionAnswering"),Ott=o(" (ELECTRA model)"),Vtt=l(),I6=a("li"),d7e=a("strong"),Xtt=o("mbart"),ztt=o(" \u2014 "),vte=a("a"),Wtt=o("FlaxMBartForQuestionAnswering"),Qtt=o(" (mBART model)"),Utt=l(),N6=a("li"),c7e=a("strong"),Htt=o("roberta"),Jtt=o(" \u2014 "),Fte=a("a"),Ytt=o("FlaxRobertaForQuestionAnswering"),Ktt=o(" (RoBERTa model)"),Ztt=l(),q6=a("li"),f7e=a("strong"),eat=o("roformer"),oat=o(" \u2014 "),Tte=a("a"),rat=o("FlaxRoFormerForQuestionAnswering"),tat=o(" (RoFormer model)"),aat=l(),j6=a("li"),m7e=a("strong"),nat=o("xlm-roberta"),sat=o(" \u2014 "),Mte=a("a"),lat=o("FlaxXLMRobertaForQuestionAnswering"),iat=o(" (XLM-RoBERTa model)"),dat=l(),F(D6.$$.fragment),IUe=l(),Lf=a("h2"),G6=a("a"),g7e=a("span"),F(Ik.$$.fragment),cat=l(),h7e=a("span"),fat=o("FlaxAutoModelForTokenClassification"),NUe=l(),wr=a("div"),F(Nk.$$.fragment),mat=l(),yf=a("p"),gat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Ete=a("a"),hat=o("from_pretrained()"),pat=o(" class method or the "),Cte=a("a"),_at=o("from_config()"),uat=o(` class
method.`),bat=l(),qk=a("p"),vat=o("This class cannot be instantiated directly using "),p7e=a("code"),Fat=o("__init__()"),Tat=o(" (throws an error)."),Mat=l(),ta=a("div"),F(jk.$$.fragment),Eat=l(),_7e=a("p"),Cat=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),wat=l(),xf=a("p"),Aat=o(`Note:
Loading a model from its configuration file does `),u7e=a("strong"),Lat=o("not"),yat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wte=a("a"),xat=o("from_pretrained()"),$at=o(" to load the model weights."),kat=l(),F(O6.$$.fragment),Sat=l(),Zr=a("div"),F(Dk.$$.fragment),Rat=l(),b7e=a("p"),Pat=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Bat=l(),Pn=a("p"),Iat=o("The model class to instantiate is selected based on the "),v7e=a("code"),Nat=o("model_type"),qat=o(` property of the config object (either
passed as an argument or loaded from `),F7e=a("code"),jat=o("pretrained_model_name_or_path"),Dat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T7e=a("code"),Gat=o("pretrained_model_name_or_path"),Oat=o(":"),Vat=l(),Xe=a("ul"),V6=a("li"),M7e=a("strong"),Xat=o("albert"),zat=o(" \u2014 "),Ate=a("a"),Wat=o("FlaxAlbertForTokenClassification"),Qat=o(" (ALBERT model)"),Uat=l(),X6=a("li"),E7e=a("strong"),Hat=o("bert"),Jat=o(" \u2014 "),Lte=a("a"),Yat=o("FlaxBertForTokenClassification"),Kat=o(" (BERT model)"),Zat=l(),z6=a("li"),C7e=a("strong"),ent=o("big_bird"),ont=o(" \u2014 "),yte=a("a"),rnt=o("FlaxBigBirdForTokenClassification"),tnt=o(" (BigBird model)"),ant=l(),W6=a("li"),w7e=a("strong"),nnt=o("distilbert"),snt=o(" \u2014 "),xte=a("a"),lnt=o("FlaxDistilBertForTokenClassification"),int=o(" (DistilBERT model)"),dnt=l(),Q6=a("li"),A7e=a("strong"),cnt=o("electra"),fnt=o(" \u2014 "),$te=a("a"),mnt=o("FlaxElectraForTokenClassification"),gnt=o(" (ELECTRA model)"),hnt=l(),U6=a("li"),L7e=a("strong"),pnt=o("roberta"),_nt=o(" \u2014 "),kte=a("a"),unt=o("FlaxRobertaForTokenClassification"),bnt=o(" (RoBERTa model)"),vnt=l(),H6=a("li"),y7e=a("strong"),Fnt=o("roformer"),Tnt=o(" \u2014 "),Ste=a("a"),Mnt=o("FlaxRoFormerForTokenClassification"),Ent=o(" (RoFormer model)"),Cnt=l(),J6=a("li"),x7e=a("strong"),wnt=o("xlm-roberta"),Ant=o(" \u2014 "),Rte=a("a"),Lnt=o("FlaxXLMRobertaForTokenClassification"),ynt=o(" (XLM-RoBERTa model)"),xnt=l(),F(Y6.$$.fragment),qUe=l(),$f=a("h2"),K6=a("a"),$7e=a("span"),F(Gk.$$.fragment),$nt=l(),k7e=a("span"),knt=o("FlaxAutoModelForMultipleChoice"),jUe=l(),Ar=a("div"),F(Ok.$$.fragment),Snt=l(),kf=a("p"),Rnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Pte=a("a"),Pnt=o("from_pretrained()"),Bnt=o(" class method or the "),Bte=a("a"),Int=o("from_config()"),Nnt=o(` class
method.`),qnt=l(),Vk=a("p"),jnt=o("This class cannot be instantiated directly using "),S7e=a("code"),Dnt=o("__init__()"),Gnt=o(" (throws an error)."),Ont=l(),aa=a("div"),F(Xk.$$.fragment),Vnt=l(),R7e=a("p"),Xnt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),znt=l(),Sf=a("p"),Wnt=o(`Note:
Loading a model from its configuration file does `),P7e=a("strong"),Qnt=o("not"),Unt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ite=a("a"),Hnt=o("from_pretrained()"),Jnt=o(" to load the model weights."),Ynt=l(),F(Z6.$$.fragment),Knt=l(),et=a("div"),F(zk.$$.fragment),Znt=l(),B7e=a("p"),est=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ost=l(),Bn=a("p"),rst=o("The model class to instantiate is selected based on the "),I7e=a("code"),tst=o("model_type"),ast=o(` property of the config object (either
passed as an argument or loaded from `),N7e=a("code"),nst=o("pretrained_model_name_or_path"),sst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q7e=a("code"),lst=o("pretrained_model_name_or_path"),ist=o(":"),dst=l(),ze=a("ul"),eA=a("li"),j7e=a("strong"),cst=o("albert"),fst=o(" \u2014 "),Nte=a("a"),mst=o("FlaxAlbertForMultipleChoice"),gst=o(" (ALBERT model)"),hst=l(),oA=a("li"),D7e=a("strong"),pst=o("bert"),_st=o(" \u2014 "),qte=a("a"),ust=o("FlaxBertForMultipleChoice"),bst=o(" (BERT model)"),vst=l(),rA=a("li"),G7e=a("strong"),Fst=o("big_bird"),Tst=o(" \u2014 "),jte=a("a"),Mst=o("FlaxBigBirdForMultipleChoice"),Est=o(" (BigBird model)"),Cst=l(),tA=a("li"),O7e=a("strong"),wst=o("distilbert"),Ast=o(" \u2014 "),Dte=a("a"),Lst=o("FlaxDistilBertForMultipleChoice"),yst=o(" (DistilBERT model)"),xst=l(),aA=a("li"),V7e=a("strong"),$st=o("electra"),kst=o(" \u2014 "),Gte=a("a"),Sst=o("FlaxElectraForMultipleChoice"),Rst=o(" (ELECTRA model)"),Pst=l(),nA=a("li"),X7e=a("strong"),Bst=o("roberta"),Ist=o(" \u2014 "),Ote=a("a"),Nst=o("FlaxRobertaForMultipleChoice"),qst=o(" (RoBERTa model)"),jst=l(),sA=a("li"),z7e=a("strong"),Dst=o("roformer"),Gst=o(" \u2014 "),Vte=a("a"),Ost=o("FlaxRoFormerForMultipleChoice"),Vst=o(" (RoFormer model)"),Xst=l(),lA=a("li"),W7e=a("strong"),zst=o("xlm-roberta"),Wst=o(" \u2014 "),Xte=a("a"),Qst=o("FlaxXLMRobertaForMultipleChoice"),Ust=o(" (XLM-RoBERTa model)"),Hst=l(),F(iA.$$.fragment),DUe=l(),Rf=a("h2"),dA=a("a"),Q7e=a("span"),F(Wk.$$.fragment),Jst=l(),U7e=a("span"),Yst=o("FlaxAutoModelForNextSentencePrediction"),GUe=l(),Lr=a("div"),F(Qk.$$.fragment),Kst=l(),Pf=a("p"),Zst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),zte=a("a"),elt=o("from_pretrained()"),olt=o(" class method or the "),Wte=a("a"),rlt=o("from_config()"),tlt=o(` class
method.`),alt=l(),Uk=a("p"),nlt=o("This class cannot be instantiated directly using "),H7e=a("code"),slt=o("__init__()"),llt=o(" (throws an error)."),ilt=l(),na=a("div"),F(Hk.$$.fragment),dlt=l(),J7e=a("p"),clt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),flt=l(),Bf=a("p"),mlt=o(`Note:
Loading a model from its configuration file does `),Y7e=a("strong"),glt=o("not"),hlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Qte=a("a"),plt=o("from_pretrained()"),_lt=o(" to load the model weights."),ult=l(),F(cA.$$.fragment),blt=l(),ot=a("div"),F(Jk.$$.fragment),vlt=l(),K7e=a("p"),Flt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Tlt=l(),In=a("p"),Mlt=o("The model class to instantiate is selected based on the "),Z7e=a("code"),Elt=o("model_type"),Clt=o(` property of the config object (either
passed as an argument or loaded from `),eLe=a("code"),wlt=o("pretrained_model_name_or_path"),Alt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=a("code"),Llt=o("pretrained_model_name_or_path"),ylt=o(":"),xlt=l(),rLe=a("ul"),fA=a("li"),tLe=a("strong"),$lt=o("bert"),klt=o(" \u2014 "),Ute=a("a"),Slt=o("FlaxBertForNextSentencePrediction"),Rlt=o(" (BERT model)"),Plt=l(),F(mA.$$.fragment),OUe=l(),If=a("h2"),gA=a("a"),aLe=a("span"),F(Yk.$$.fragment),Blt=l(),nLe=a("span"),Ilt=o("FlaxAutoModelForImageClassification"),VUe=l(),yr=a("div"),F(Kk.$$.fragment),Nlt=l(),Nf=a("p"),qlt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Hte=a("a"),jlt=o("from_pretrained()"),Dlt=o(" class method or the "),Jte=a("a"),Glt=o("from_config()"),Olt=o(` class
method.`),Vlt=l(),Zk=a("p"),Xlt=o("This class cannot be instantiated directly using "),sLe=a("code"),zlt=o("__init__()"),Wlt=o(" (throws an error)."),Qlt=l(),sa=a("div"),F(eS.$$.fragment),Ult=l(),lLe=a("p"),Hlt=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Jlt=l(),qf=a("p"),Ylt=o(`Note:
Loading a model from its configuration file does `),iLe=a("strong"),Klt=o("not"),Zlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Yte=a("a"),eit=o("from_pretrained()"),oit=o(" to load the model weights."),rit=l(),F(hA.$$.fragment),tit=l(),rt=a("div"),F(oS.$$.fragment),ait=l(),dLe=a("p"),nit=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),sit=l(),Nn=a("p"),lit=o("The model class to instantiate is selected based on the "),cLe=a("code"),iit=o("model_type"),dit=o(` property of the config object (either
passed as an argument or loaded from `),fLe=a("code"),cit=o("pretrained_model_name_or_path"),fit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mLe=a("code"),mit=o("pretrained_model_name_or_path"),git=o(":"),hit=l(),rS=a("ul"),pA=a("li"),gLe=a("strong"),pit=o("beit"),_it=o(" \u2014 "),Kte=a("a"),uit=o("FlaxBeitForImageClassification"),bit=o(" (BEiT model)"),vit=l(),_A=a("li"),hLe=a("strong"),Fit=o("vit"),Tit=o(" \u2014 "),Zte=a("a"),Mit=o("FlaxViTForImageClassification"),Eit=o(" (ViT model)"),Cit=l(),F(uA.$$.fragment),XUe=l(),jf=a("h2"),bA=a("a"),pLe=a("span"),F(tS.$$.fragment),wit=l(),_Le=a("span"),Ait=o("FlaxAutoModelForVision2Seq"),zUe=l(),xr=a("div"),F(aS.$$.fragment),Lit=l(),Df=a("p"),yit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eae=a("a"),xit=o("from_pretrained()"),$it=o(" class method or the "),oae=a("a"),kit=o("from_config()"),Sit=o(` class
method.`),Rit=l(),nS=a("p"),Pit=o("This class cannot be instantiated directly using "),uLe=a("code"),Bit=o("__init__()"),Iit=o(" (throws an error)."),Nit=l(),la=a("div"),F(sS.$$.fragment),qit=l(),bLe=a("p"),jit=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Dit=l(),Gf=a("p"),Git=o(`Note:
Loading a model from its configuration file does `),vLe=a("strong"),Oit=o("not"),Vit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=a("a"),Xit=o("from_pretrained()"),zit=o(" to load the model weights."),Wit=l(),F(vA.$$.fragment),Qit=l(),tt=a("div"),F(lS.$$.fragment),Uit=l(),FLe=a("p"),Hit=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Jit=l(),qn=a("p"),Yit=o("The model class to instantiate is selected based on the "),TLe=a("code"),Kit=o("model_type"),Zit=o(` property of the config object (either
passed as an argument or loaded from `),MLe=a("code"),edt=o("pretrained_model_name_or_path"),odt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ELe=a("code"),rdt=o("pretrained_model_name_or_path"),tdt=o(":"),adt=l(),CLe=a("ul"),FA=a("li"),wLe=a("strong"),ndt=o("vision-encoder-decoder"),sdt=o(" \u2014 "),tae=a("a"),ldt=o("FlaxVisionEncoderDecoderModel"),idt=o(" (Vision Encoder decoder model)"),ddt=l(),F(TA.$$.fragment),this.h()},l(f){const u=tea('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var iS=s(p);m=n(iS,"A",{id:!0,class:!0,href:!0});var ALe=s(m);_=n(ALe,"SPAN",{});var LLe=s(_);T(d.$$.fragment,LLe),LLe.forEach(t),ALe.forEach(t),h=i(iS),Ao=n(iS,"SPAN",{});var yLe=s(Ao);Ii=r(yLe,"Auto Classes"),yLe.forEach(t),iS.forEach(t),zf=i(f),dt=n(f,"P",{});var dS=s(dt);Ni=r(dS,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),qi=n(dS,"CODE",{});var xLe=s(qi);VL=r(xLe,"from_pretrained()"),xLe.forEach(t),Wf=r(dS,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),dS.forEach(t),Oe=i(f),Qe=n(f,"P",{});var jn=s(Qe);ji=r(jn,"Instantiating one of "),Dn=n(jn,"A",{href:!0});var $Le=s(Dn);XL=r($Le,"AutoConfig"),$Le.forEach(t),Gn=r(jn,", "),On=n(jn,"A",{href:!0});var kLe=s(On);zL=r(kLe,"AutoModel"),kLe.forEach(t),Di=r(jn,`, and
`),Vn=n(jn,"A",{href:!0});var SLe=s(Vn);WL=r(SLe,"AutoTokenizer"),SLe.forEach(t),Gi=r(jn," will directly create a class of the relevant architecture. For instance"),jn.forEach(t),Qf=i(f),T(Ia.$$.fragment,f),Ue=i(f),Ae=n(f,"P",{});var cS=s(Ae);kR=r(cS,"will create a model that is an instance of "),Oi=n(cS,"A",{href:!0});var RLe=s(Oi);SR=r(RLe,"BertModel"),RLe.forEach(t),RR=r(cS,"."),cS.forEach(t),Lo=i(f),Na=n(f,"P",{});var fS=s(Na);PR=r(fS,"There is one class of "),Uf=n(fS,"CODE",{});var PLe=s(Uf);BR=r(PLe,"AutoModel"),PLe.forEach(t),aYe=r(fS," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),fS.forEach(t),jWe=i(f),Vi=n(f,"H2",{class:!0});var mS=s(Vi);Hf=n(mS,"A",{id:!0,class:!0,href:!0});var BLe=s(Hf);Zne=n(BLe,"SPAN",{});var ILe=s(Zne);T(QL.$$.fragment,ILe),ILe.forEach(t),BLe.forEach(t),nYe=i(mS),ese=n(mS,"SPAN",{});var NLe=s(ese);sYe=r(NLe,"Extending the Auto Classes"),NLe.forEach(t),mS.forEach(t),DWe=i(f),Xn=n(f,"P",{});var Of=s(Xn);lYe=r(Of,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ose=n(Of,"CODE",{});var qLe=s(ose);iYe=r(qLe,"NewModel"),qLe.forEach(t),dYe=r(Of,", make sure you have a "),rse=n(Of,"CODE",{});var jLe=s(rse);cYe=r(jLe,"NewModelConfig"),jLe.forEach(t),fYe=r(Of,` then you can add those to the auto
classes like this:`),Of.forEach(t),GWe=i(f),T(UL.$$.fragment,f),OWe=i(f),IR=n(f,"P",{});var DLe=s(IR);mYe=r(DLe,"You will then be able to use the auto classes like you would usually do!"),DLe.forEach(t),VWe=i(f),T(Jf.$$.fragment,f),XWe=i(f),Xi=n(f,"H2",{class:!0});var gS=s(Xi);Yf=n(gS,"A",{id:!0,class:!0,href:!0});var GLe=s(Yf);tse=n(GLe,"SPAN",{});var OLe=s(tse);T(HL.$$.fragment,OLe),OLe.forEach(t),GLe.forEach(t),gYe=i(gS),ase=n(gS,"SPAN",{});var VLe=s(ase);hYe=r(VLe,"AutoConfig"),VLe.forEach(t),gS.forEach(t),zWe=i(f),yo=n(f,"DIV",{class:!0});var lt=s(yo);T(JL.$$.fragment,lt),pYe=i(lt),YL=n(lt,"P",{});var hS=s(YL);_Ye=r(hS,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),NR=n(hS,"A",{href:!0});var XLe=s(NR);uYe=r(XLe,"from_pretrained()"),XLe.forEach(t),bYe=r(hS," class method."),hS.forEach(t),vYe=i(lt),KL=n(lt,"P",{});var pS=s(KL);FYe=r(pS,"This class cannot be instantiated directly using "),nse=n(pS,"CODE",{});var zLe=s(nse);TYe=r(zLe,"__init__()"),zLe.forEach(t),MYe=r(pS," (throws an error)."),pS.forEach(t),EYe=i(lt),$r=n(lt,"DIV",{class:!0});var it=s($r);T(ZL.$$.fragment,it),CYe=i(it),sse=n(it,"P",{});var WLe=s(sse);wYe=r(WLe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),WLe.forEach(t),AYe=i(it),zi=n(it,"P",{});var Vf=s(zi);LYe=r(Vf,"The configuration class to instantiate is selected based on the "),lse=n(Vf,"CODE",{});var QLe=s(lse);yYe=r(QLe,"model_type"),QLe.forEach(t),xYe=r(Vf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),ise=n(Vf,"CODE",{});var ULe=s(ise);$Ye=r(ULe,"pretrained_model_name_or_path"),ULe.forEach(t),kYe=r(Vf,":"),Vf.forEach(t),SYe=i(it),A=n(it,"UL",{});var L=s(A);Kf=n(L,"LI",{});var MA=s(Kf);dse=n(MA,"STRONG",{});var HLe=s(dse);RYe=r(HLe,"albert"),HLe.forEach(t),PYe=r(MA," \u2014 "),qR=n(MA,"A",{href:!0});var JLe=s(qR);BYe=r(JLe,"AlbertConfig"),JLe.forEach(t),IYe=r(MA," (ALBERT model)"),MA.forEach(t),NYe=i(L),Zf=n(L,"LI",{});var EA=s(Zf);cse=n(EA,"STRONG",{});var YLe=s(cse);qYe=r(YLe,"bart"),YLe.forEach(t),jYe=r(EA," \u2014 "),jR=n(EA,"A",{href:!0});var KLe=s(jR);DYe=r(KLe,"BartConfig"),KLe.forEach(t),GYe=r(EA," (BART model)"),EA.forEach(t),OYe=i(L),em=n(L,"LI",{});var CA=s(em);fse=n(CA,"STRONG",{});var ZLe=s(fse);VYe=r(ZLe,"beit"),ZLe.forEach(t),XYe=r(CA," \u2014 "),DR=n(CA,"A",{href:!0});var eye=s(DR);zYe=r(eye,"BeitConfig"),eye.forEach(t),WYe=r(CA," (BEiT model)"),CA.forEach(t),QYe=i(L),om=n(L,"LI",{});var wA=s(om);mse=n(wA,"STRONG",{});var oye=s(mse);UYe=r(oye,"bert"),oye.forEach(t),HYe=r(wA," \u2014 "),GR=n(wA,"A",{href:!0});var rye=s(GR);JYe=r(rye,"BertConfig"),rye.forEach(t),YYe=r(wA," (BERT model)"),wA.forEach(t),KYe=i(L),rm=n(L,"LI",{});var AA=s(rm);gse=n(AA,"STRONG",{});var tye=s(gse);ZYe=r(tye,"bert-generation"),tye.forEach(t),eKe=r(AA," \u2014 "),OR=n(AA,"A",{href:!0});var aye=s(OR);oKe=r(aye,"BertGenerationConfig"),aye.forEach(t),rKe=r(AA," (Bert Generation model)"),AA.forEach(t),tKe=i(L),tm=n(L,"LI",{});var LA=s(tm);hse=n(LA,"STRONG",{});var nye=s(hse);aKe=r(nye,"big_bird"),nye.forEach(t),nKe=r(LA," \u2014 "),VR=n(LA,"A",{href:!0});var sye=s(VR);sKe=r(sye,"BigBirdConfig"),sye.forEach(t),lKe=r(LA," (BigBird model)"),LA.forEach(t),iKe=i(L),am=n(L,"LI",{});var yA=s(am);pse=n(yA,"STRONG",{});var lye=s(pse);dKe=r(lye,"bigbird_pegasus"),lye.forEach(t),cKe=r(yA," \u2014 "),XR=n(yA,"A",{href:!0});var iye=s(XR);fKe=r(iye,"BigBirdPegasusConfig"),iye.forEach(t),mKe=r(yA," (BigBird-Pegasus model)"),yA.forEach(t),gKe=i(L),nm=n(L,"LI",{});var xA=s(nm);_se=n(xA,"STRONG",{});var dye=s(_se);hKe=r(dye,"blenderbot"),dye.forEach(t),pKe=r(xA," \u2014 "),zR=n(xA,"A",{href:!0});var cye=s(zR);_Ke=r(cye,"BlenderbotConfig"),cye.forEach(t),uKe=r(xA," (Blenderbot model)"),xA.forEach(t),bKe=i(L),sm=n(L,"LI",{});var $A=s(sm);use=n($A,"STRONG",{});var fye=s(use);vKe=r(fye,"blenderbot-small"),fye.forEach(t),FKe=r($A," \u2014 "),WR=n($A,"A",{href:!0});var mye=s(WR);TKe=r(mye,"BlenderbotSmallConfig"),mye.forEach(t),MKe=r($A," (BlenderbotSmall model)"),$A.forEach(t),EKe=i(L),lm=n(L,"LI",{});var kA=s(lm);bse=n(kA,"STRONG",{});var gye=s(bse);CKe=r(gye,"bloom"),gye.forEach(t),wKe=r(kA," \u2014 "),QR=n(kA,"A",{href:!0});var hye=s(QR);AKe=r(hye,"BloomConfig"),hye.forEach(t),LKe=r(kA," (BLOOM model)"),kA.forEach(t),yKe=i(L),im=n(L,"LI",{});var SA=s(im);vse=n(SA,"STRONG",{});var pye=s(vse);xKe=r(pye,"camembert"),pye.forEach(t),$Ke=r(SA," \u2014 "),UR=n(SA,"A",{href:!0});var _ye=s(UR);kKe=r(_ye,"CamembertConfig"),_ye.forEach(t),SKe=r(SA," (CamemBERT model)"),SA.forEach(t),RKe=i(L),dm=n(L,"LI",{});var RA=s(dm);Fse=n(RA,"STRONG",{});var uye=s(Fse);PKe=r(uye,"canine"),uye.forEach(t),BKe=r(RA," \u2014 "),HR=n(RA,"A",{href:!0});var bye=s(HR);IKe=r(bye,"CanineConfig"),bye.forEach(t),NKe=r(RA," (CANINE model)"),RA.forEach(t),qKe=i(L),cm=n(L,"LI",{});var PA=s(cm);Tse=n(PA,"STRONG",{});var vye=s(Tse);jKe=r(vye,"clip"),vye.forEach(t),DKe=r(PA," \u2014 "),JR=n(PA,"A",{href:!0});var Fye=s(JR);GKe=r(Fye,"CLIPConfig"),Fye.forEach(t),OKe=r(PA," (CLIP model)"),PA.forEach(t),VKe=i(L),fm=n(L,"LI",{});var BA=s(fm);Mse=n(BA,"STRONG",{});var Tye=s(Mse);XKe=r(Tye,"codegen"),Tye.forEach(t),zKe=r(BA," \u2014 "),YR=n(BA,"A",{href:!0});var Mye=s(YR);WKe=r(Mye,"CodeGenConfig"),Mye.forEach(t),QKe=r(BA," (CodeGen model)"),BA.forEach(t),UKe=i(L),mm=n(L,"LI",{});var IA=s(mm);Ese=n(IA,"STRONG",{});var Eye=s(Ese);HKe=r(Eye,"convbert"),Eye.forEach(t),JKe=r(IA," \u2014 "),KR=n(IA,"A",{href:!0});var Cye=s(KR);YKe=r(Cye,"ConvBertConfig"),Cye.forEach(t),KKe=r(IA," (ConvBERT model)"),IA.forEach(t),ZKe=i(L),gm=n(L,"LI",{});var NA=s(gm);Cse=n(NA,"STRONG",{});var wye=s(Cse);eZe=r(wye,"convnext"),wye.forEach(t),oZe=r(NA," \u2014 "),ZR=n(NA,"A",{href:!0});var Aye=s(ZR);rZe=r(Aye,"ConvNextConfig"),Aye.forEach(t),tZe=r(NA," (ConvNeXT model)"),NA.forEach(t),aZe=i(L),hm=n(L,"LI",{});var qA=s(hm);wse=n(qA,"STRONG",{});var Lye=s(wse);nZe=r(Lye,"ctrl"),Lye.forEach(t),sZe=r(qA," \u2014 "),eP=n(qA,"A",{href:!0});var yye=s(eP);lZe=r(yye,"CTRLConfig"),yye.forEach(t),iZe=r(qA," (CTRL model)"),qA.forEach(t),dZe=i(L),pm=n(L,"LI",{});var jA=s(pm);Ase=n(jA,"STRONG",{});var xye=s(Ase);cZe=r(xye,"cvt"),xye.forEach(t),fZe=r(jA," \u2014 "),oP=n(jA,"A",{href:!0});var $ye=s(oP);mZe=r($ye,"CvtConfig"),$ye.forEach(t),gZe=r(jA," (CvT model)"),jA.forEach(t),hZe=i(L),_m=n(L,"LI",{});var DA=s(_m);Lse=n(DA,"STRONG",{});var kye=s(Lse);pZe=r(kye,"data2vec-audio"),kye.forEach(t),_Ze=r(DA," \u2014 "),rP=n(DA,"A",{href:!0});var Sye=s(rP);uZe=r(Sye,"Data2VecAudioConfig"),Sye.forEach(t),bZe=r(DA," (Data2VecAudio model)"),DA.forEach(t),vZe=i(L),um=n(L,"LI",{});var GA=s(um);yse=n(GA,"STRONG",{});var Rye=s(yse);FZe=r(Rye,"data2vec-text"),Rye.forEach(t),TZe=r(GA," \u2014 "),tP=n(GA,"A",{href:!0});var Pye=s(tP);MZe=r(Pye,"Data2VecTextConfig"),Pye.forEach(t),EZe=r(GA," (Data2VecText model)"),GA.forEach(t),CZe=i(L),bm=n(L,"LI",{});var OA=s(bm);xse=n(OA,"STRONG",{});var Bye=s(xse);wZe=r(Bye,"data2vec-vision"),Bye.forEach(t),AZe=r(OA," \u2014 "),aP=n(OA,"A",{href:!0});var Iye=s(aP);LZe=r(Iye,"Data2VecVisionConfig"),Iye.forEach(t),yZe=r(OA," (Data2VecVision model)"),OA.forEach(t),xZe=i(L),vm=n(L,"LI",{});var VA=s(vm);$se=n(VA,"STRONG",{});var Nye=s($se);$Ze=r(Nye,"deberta"),Nye.forEach(t),kZe=r(VA," \u2014 "),nP=n(VA,"A",{href:!0});var qye=s(nP);SZe=r(qye,"DebertaConfig"),qye.forEach(t),RZe=r(VA," (DeBERTa model)"),VA.forEach(t),PZe=i(L),Fm=n(L,"LI",{});var XA=s(Fm);kse=n(XA,"STRONG",{});var jye=s(kse);BZe=r(jye,"deberta-v2"),jye.forEach(t),IZe=r(XA," \u2014 "),sP=n(XA,"A",{href:!0});var Dye=s(sP);NZe=r(Dye,"DebertaV2Config"),Dye.forEach(t),qZe=r(XA," (DeBERTa-v2 model)"),XA.forEach(t),jZe=i(L),Tm=n(L,"LI",{});var zA=s(Tm);Sse=n(zA,"STRONG",{});var Gye=s(Sse);DZe=r(Gye,"decision_transformer"),Gye.forEach(t),GZe=r(zA," \u2014 "),lP=n(zA,"A",{href:!0});var Oye=s(lP);OZe=r(Oye,"DecisionTransformerConfig"),Oye.forEach(t),VZe=r(zA," (Decision Transformer model)"),zA.forEach(t),XZe=i(L),Mm=n(L,"LI",{});var Vye=s(Mm);Rse=n(Vye,"STRONG",{});var fdt=s(Rse);zZe=r(fdt,"deit"),fdt.forEach(t),WZe=r(Vye," \u2014 "),iP=n(Vye,"A",{href:!0});var mdt=s(iP);QZe=r(mdt,"DeiTConfig"),mdt.forEach(t),UZe=r(Vye," (DeiT model)"),Vye.forEach(t),HZe=i(L),Em=n(L,"LI",{});var Xye=s(Em);Pse=n(Xye,"STRONG",{});var gdt=s(Pse);JZe=r(gdt,"detr"),gdt.forEach(t),YZe=r(Xye," \u2014 "),dP=n(Xye,"A",{href:!0});var hdt=s(dP);KZe=r(hdt,"DetrConfig"),hdt.forEach(t),ZZe=r(Xye," (DETR model)"),Xye.forEach(t),eeo=i(L),Cm=n(L,"LI",{});var zye=s(Cm);Bse=n(zye,"STRONG",{});var pdt=s(Bse);oeo=r(pdt,"distilbert"),pdt.forEach(t),reo=r(zye," \u2014 "),cP=n(zye,"A",{href:!0});var _dt=s(cP);teo=r(_dt,"DistilBertConfig"),_dt.forEach(t),aeo=r(zye," (DistilBERT model)"),zye.forEach(t),neo=i(L),wm=n(L,"LI",{});var Wye=s(wm);Ise=n(Wye,"STRONG",{});var udt=s(Ise);seo=r(udt,"dpr"),udt.forEach(t),leo=r(Wye," \u2014 "),fP=n(Wye,"A",{href:!0});var bdt=s(fP);ieo=r(bdt,"DPRConfig"),bdt.forEach(t),deo=r(Wye," (DPR model)"),Wye.forEach(t),ceo=i(L),Am=n(L,"LI",{});var Qye=s(Am);Nse=n(Qye,"STRONG",{});var vdt=s(Nse);feo=r(vdt,"dpt"),vdt.forEach(t),meo=r(Qye," \u2014 "),mP=n(Qye,"A",{href:!0});var Fdt=s(mP);geo=r(Fdt,"DPTConfig"),Fdt.forEach(t),heo=r(Qye," (DPT model)"),Qye.forEach(t),peo=i(L),Lm=n(L,"LI",{});var Uye=s(Lm);qse=n(Uye,"STRONG",{});var Tdt=s(qse);_eo=r(Tdt,"electra"),Tdt.forEach(t),ueo=r(Uye," \u2014 "),gP=n(Uye,"A",{href:!0});var Mdt=s(gP);beo=r(Mdt,"ElectraConfig"),Mdt.forEach(t),veo=r(Uye," (ELECTRA model)"),Uye.forEach(t),Feo=i(L),ym=n(L,"LI",{});var Hye=s(ym);jse=n(Hye,"STRONG",{});var Edt=s(jse);Teo=r(Edt,"encoder-decoder"),Edt.forEach(t),Meo=r(Hye," \u2014 "),hP=n(Hye,"A",{href:!0});var Cdt=s(hP);Eeo=r(Cdt,"EncoderDecoderConfig"),Cdt.forEach(t),Ceo=r(Hye," (Encoder decoder model)"),Hye.forEach(t),weo=i(L),xm=n(L,"LI",{});var Jye=s(xm);Dse=n(Jye,"STRONG",{});var wdt=s(Dse);Aeo=r(wdt,"flaubert"),wdt.forEach(t),Leo=r(Jye," \u2014 "),pP=n(Jye,"A",{href:!0});var Adt=s(pP);yeo=r(Adt,"FlaubertConfig"),Adt.forEach(t),xeo=r(Jye," (FlauBERT model)"),Jye.forEach(t),$eo=i(L),$m=n(L,"LI",{});var Yye=s($m);Gse=n(Yye,"STRONG",{});var Ldt=s(Gse);keo=r(Ldt,"flava"),Ldt.forEach(t),Seo=r(Yye," \u2014 "),_P=n(Yye,"A",{href:!0});var ydt=s(_P);Reo=r(ydt,"FlavaConfig"),ydt.forEach(t),Peo=r(Yye," (FLAVA model)"),Yye.forEach(t),Beo=i(L),km=n(L,"LI",{});var Kye=s(km);Ose=n(Kye,"STRONG",{});var xdt=s(Ose);Ieo=r(xdt,"fnet"),xdt.forEach(t),Neo=r(Kye," \u2014 "),uP=n(Kye,"A",{href:!0});var $dt=s(uP);qeo=r($dt,"FNetConfig"),$dt.forEach(t),jeo=r(Kye," (FNet model)"),Kye.forEach(t),Deo=i(L),Sm=n(L,"LI",{});var Zye=s(Sm);Vse=n(Zye,"STRONG",{});var kdt=s(Vse);Geo=r(kdt,"fsmt"),kdt.forEach(t),Oeo=r(Zye," \u2014 "),bP=n(Zye,"A",{href:!0});var Sdt=s(bP);Veo=r(Sdt,"FSMTConfig"),Sdt.forEach(t),Xeo=r(Zye," (FairSeq Machine-Translation model)"),Zye.forEach(t),zeo=i(L),Rm=n(L,"LI",{});var e9e=s(Rm);Xse=n(e9e,"STRONG",{});var Rdt=s(Xse);Weo=r(Rdt,"funnel"),Rdt.forEach(t),Qeo=r(e9e," \u2014 "),vP=n(e9e,"A",{href:!0});var Pdt=s(vP);Ueo=r(Pdt,"FunnelConfig"),Pdt.forEach(t),Heo=r(e9e," (Funnel Transformer model)"),e9e.forEach(t),Jeo=i(L),Pm=n(L,"LI",{});var o9e=s(Pm);zse=n(o9e,"STRONG",{});var Bdt=s(zse);Yeo=r(Bdt,"glpn"),Bdt.forEach(t),Keo=r(o9e," \u2014 "),FP=n(o9e,"A",{href:!0});var Idt=s(FP);Zeo=r(Idt,"GLPNConfig"),Idt.forEach(t),eoo=r(o9e," (GLPN model)"),o9e.forEach(t),ooo=i(L),Bm=n(L,"LI",{});var r9e=s(Bm);Wse=n(r9e,"STRONG",{});var Ndt=s(Wse);roo=r(Ndt,"gpt2"),Ndt.forEach(t),too=r(r9e," \u2014 "),TP=n(r9e,"A",{href:!0});var qdt=s(TP);aoo=r(qdt,"GPT2Config"),qdt.forEach(t),noo=r(r9e," (OpenAI GPT-2 model)"),r9e.forEach(t),soo=i(L),Im=n(L,"LI",{});var t9e=s(Im);Qse=n(t9e,"STRONG",{});var jdt=s(Qse);loo=r(jdt,"gpt_neo"),jdt.forEach(t),ioo=r(t9e," \u2014 "),MP=n(t9e,"A",{href:!0});var Ddt=s(MP);doo=r(Ddt,"GPTNeoConfig"),Ddt.forEach(t),coo=r(t9e," (GPT Neo model)"),t9e.forEach(t),foo=i(L),Nm=n(L,"LI",{});var a9e=s(Nm);Use=n(a9e,"STRONG",{});var Gdt=s(Use);moo=r(Gdt,"gpt_neox"),Gdt.forEach(t),goo=r(a9e," \u2014 "),EP=n(a9e,"A",{href:!0});var Odt=s(EP);hoo=r(Odt,"GPTNeoXConfig"),Odt.forEach(t),poo=r(a9e," (GPT NeoX model)"),a9e.forEach(t),_oo=i(L),qm=n(L,"LI",{});var n9e=s(qm);Hse=n(n9e,"STRONG",{});var Vdt=s(Hse);uoo=r(Vdt,"gptj"),Vdt.forEach(t),boo=r(n9e," \u2014 "),CP=n(n9e,"A",{href:!0});var Xdt=s(CP);voo=r(Xdt,"GPTJConfig"),Xdt.forEach(t),Foo=r(n9e," (GPT-J model)"),n9e.forEach(t),Too=i(L),jm=n(L,"LI",{});var s9e=s(jm);Jse=n(s9e,"STRONG",{});var zdt=s(Jse);Moo=r(zdt,"groupvit"),zdt.forEach(t),Eoo=r(s9e," \u2014 "),wP=n(s9e,"A",{href:!0});var Wdt=s(wP);Coo=r(Wdt,"GroupViTConfig"),Wdt.forEach(t),woo=r(s9e," (GroupViT model)"),s9e.forEach(t),Aoo=i(L),Dm=n(L,"LI",{});var l9e=s(Dm);Yse=n(l9e,"STRONG",{});var Qdt=s(Yse);Loo=r(Qdt,"hubert"),Qdt.forEach(t),yoo=r(l9e," \u2014 "),AP=n(l9e,"A",{href:!0});var Udt=s(AP);xoo=r(Udt,"HubertConfig"),Udt.forEach(t),$oo=r(l9e," (Hubert model)"),l9e.forEach(t),koo=i(L),Gm=n(L,"LI",{});var i9e=s(Gm);Kse=n(i9e,"STRONG",{});var Hdt=s(Kse);Soo=r(Hdt,"ibert"),Hdt.forEach(t),Roo=r(i9e," \u2014 "),LP=n(i9e,"A",{href:!0});var Jdt=s(LP);Poo=r(Jdt,"IBertConfig"),Jdt.forEach(t),Boo=r(i9e," (I-BERT model)"),i9e.forEach(t),Ioo=i(L),Om=n(L,"LI",{});var d9e=s(Om);Zse=n(d9e,"STRONG",{});var Ydt=s(Zse);Noo=r(Ydt,"imagegpt"),Ydt.forEach(t),qoo=r(d9e," \u2014 "),yP=n(d9e,"A",{href:!0});var Kdt=s(yP);joo=r(Kdt,"ImageGPTConfig"),Kdt.forEach(t),Doo=r(d9e," (ImageGPT model)"),d9e.forEach(t),Goo=i(L),Vm=n(L,"LI",{});var c9e=s(Vm);ele=n(c9e,"STRONG",{});var Zdt=s(ele);Ooo=r(Zdt,"layoutlm"),Zdt.forEach(t),Voo=r(c9e," \u2014 "),xP=n(c9e,"A",{href:!0});var ect=s(xP);Xoo=r(ect,"LayoutLMConfig"),ect.forEach(t),zoo=r(c9e," (LayoutLM model)"),c9e.forEach(t),Woo=i(L),Xm=n(L,"LI",{});var f9e=s(Xm);ole=n(f9e,"STRONG",{});var oct=s(ole);Qoo=r(oct,"layoutlmv2"),oct.forEach(t),Uoo=r(f9e," \u2014 "),$P=n(f9e,"A",{href:!0});var rct=s($P);Hoo=r(rct,"LayoutLMv2Config"),rct.forEach(t),Joo=r(f9e," (LayoutLMv2 model)"),f9e.forEach(t),Yoo=i(L),zm=n(L,"LI",{});var m9e=s(zm);rle=n(m9e,"STRONG",{});var tct=s(rle);Koo=r(tct,"layoutlmv3"),tct.forEach(t),Zoo=r(m9e," \u2014 "),kP=n(m9e,"A",{href:!0});var act=s(kP);ero=r(act,"LayoutLMv3Config"),act.forEach(t),oro=r(m9e," (LayoutLMv3 model)"),m9e.forEach(t),rro=i(L),Wm=n(L,"LI",{});var g9e=s(Wm);tle=n(g9e,"STRONG",{});var nct=s(tle);tro=r(nct,"led"),nct.forEach(t),aro=r(g9e," \u2014 "),SP=n(g9e,"A",{href:!0});var sct=s(SP);nro=r(sct,"LEDConfig"),sct.forEach(t),sro=r(g9e," (LED model)"),g9e.forEach(t),lro=i(L),Qm=n(L,"LI",{});var h9e=s(Qm);ale=n(h9e,"STRONG",{});var lct=s(ale);iro=r(lct,"levit"),lct.forEach(t),dro=r(h9e," \u2014 "),RP=n(h9e,"A",{href:!0});var ict=s(RP);cro=r(ict,"LevitConfig"),ict.forEach(t),fro=r(h9e," (LeViT model)"),h9e.forEach(t),mro=i(L),Um=n(L,"LI",{});var p9e=s(Um);nle=n(p9e,"STRONG",{});var dct=s(nle);gro=r(dct,"longformer"),dct.forEach(t),hro=r(p9e," \u2014 "),PP=n(p9e,"A",{href:!0});var cct=s(PP);pro=r(cct,"LongformerConfig"),cct.forEach(t),_ro=r(p9e," (Longformer model)"),p9e.forEach(t),uro=i(L),Hm=n(L,"LI",{});var _9e=s(Hm);sle=n(_9e,"STRONG",{});var fct=s(sle);bro=r(fct,"longt5"),fct.forEach(t),vro=r(_9e," \u2014 "),BP=n(_9e,"A",{href:!0});var mct=s(BP);Fro=r(mct,"LongT5Config"),mct.forEach(t),Tro=r(_9e," (LongT5 model)"),_9e.forEach(t),Mro=i(L),Jm=n(L,"LI",{});var u9e=s(Jm);lle=n(u9e,"STRONG",{});var gct=s(lle);Ero=r(gct,"luke"),gct.forEach(t),Cro=r(u9e," \u2014 "),IP=n(u9e,"A",{href:!0});var hct=s(IP);wro=r(hct,"LukeConfig"),hct.forEach(t),Aro=r(u9e," (LUKE model)"),u9e.forEach(t),Lro=i(L),Ym=n(L,"LI",{});var b9e=s(Ym);ile=n(b9e,"STRONG",{});var pct=s(ile);yro=r(pct,"lxmert"),pct.forEach(t),xro=r(b9e," \u2014 "),NP=n(b9e,"A",{href:!0});var _ct=s(NP);$ro=r(_ct,"LxmertConfig"),_ct.forEach(t),kro=r(b9e," (LXMERT model)"),b9e.forEach(t),Sro=i(L),Km=n(L,"LI",{});var v9e=s(Km);dle=n(v9e,"STRONG",{});var uct=s(dle);Rro=r(uct,"m2m_100"),uct.forEach(t),Pro=r(v9e," \u2014 "),qP=n(v9e,"A",{href:!0});var bct=s(qP);Bro=r(bct,"M2M100Config"),bct.forEach(t),Iro=r(v9e," (M2M100 model)"),v9e.forEach(t),Nro=i(L),Zm=n(L,"LI",{});var F9e=s(Zm);cle=n(F9e,"STRONG",{});var vct=s(cle);qro=r(vct,"marian"),vct.forEach(t),jro=r(F9e," \u2014 "),jP=n(F9e,"A",{href:!0});var Fct=s(jP);Dro=r(Fct,"MarianConfig"),Fct.forEach(t),Gro=r(F9e," (Marian model)"),F9e.forEach(t),Oro=i(L),eg=n(L,"LI",{});var T9e=s(eg);fle=n(T9e,"STRONG",{});var Tct=s(fle);Vro=r(Tct,"maskformer"),Tct.forEach(t),Xro=r(T9e," \u2014 "),DP=n(T9e,"A",{href:!0});var Mct=s(DP);zro=r(Mct,"MaskFormerConfig"),Mct.forEach(t),Wro=r(T9e," (MaskFormer model)"),T9e.forEach(t),Qro=i(L),og=n(L,"LI",{});var M9e=s(og);mle=n(M9e,"STRONG",{});var Ect=s(mle);Uro=r(Ect,"mbart"),Ect.forEach(t),Hro=r(M9e," \u2014 "),GP=n(M9e,"A",{href:!0});var Cct=s(GP);Jro=r(Cct,"MBartConfig"),Cct.forEach(t),Yro=r(M9e," (mBART model)"),M9e.forEach(t),Kro=i(L),rg=n(L,"LI",{});var E9e=s(rg);gle=n(E9e,"STRONG",{});var wct=s(gle);Zro=r(wct,"mctct"),wct.forEach(t),eto=r(E9e," \u2014 "),OP=n(E9e,"A",{href:!0});var Act=s(OP);oto=r(Act,"MCTCTConfig"),Act.forEach(t),rto=r(E9e," (M-CTC-T model)"),E9e.forEach(t),tto=i(L),tg=n(L,"LI",{});var C9e=s(tg);hle=n(C9e,"STRONG",{});var Lct=s(hle);ato=r(Lct,"megatron-bert"),Lct.forEach(t),nto=r(C9e," \u2014 "),VP=n(C9e,"A",{href:!0});var yct=s(VP);sto=r(yct,"MegatronBertConfig"),yct.forEach(t),lto=r(C9e," (Megatron-BERT model)"),C9e.forEach(t),ito=i(L),ag=n(L,"LI",{});var w9e=s(ag);ple=n(w9e,"STRONG",{});var xct=s(ple);dto=r(xct,"mobilebert"),xct.forEach(t),cto=r(w9e," \u2014 "),XP=n(w9e,"A",{href:!0});var $ct=s(XP);fto=r($ct,"MobileBertConfig"),$ct.forEach(t),mto=r(w9e," (MobileBERT model)"),w9e.forEach(t),gto=i(L),ng=n(L,"LI",{});var A9e=s(ng);_le=n(A9e,"STRONG",{});var kct=s(_le);hto=r(kct,"mobilevit"),kct.forEach(t),pto=r(A9e," \u2014 "),zP=n(A9e,"A",{href:!0});var Sct=s(zP);_to=r(Sct,"MobileViTConfig"),Sct.forEach(t),uto=r(A9e," (MobileViT model)"),A9e.forEach(t),bto=i(L),sg=n(L,"LI",{});var L9e=s(sg);ule=n(L9e,"STRONG",{});var Rct=s(ule);vto=r(Rct,"mpnet"),Rct.forEach(t),Fto=r(L9e," \u2014 "),WP=n(L9e,"A",{href:!0});var Pct=s(WP);Tto=r(Pct,"MPNetConfig"),Pct.forEach(t),Mto=r(L9e," (MPNet model)"),L9e.forEach(t),Eto=i(L),lg=n(L,"LI",{});var y9e=s(lg);ble=n(y9e,"STRONG",{});var Bct=s(ble);Cto=r(Bct,"mt5"),Bct.forEach(t),wto=r(y9e," \u2014 "),QP=n(y9e,"A",{href:!0});var Ict=s(QP);Ato=r(Ict,"MT5Config"),Ict.forEach(t),Lto=r(y9e," (MT5 model)"),y9e.forEach(t),yto=i(L),ig=n(L,"LI",{});var x9e=s(ig);vle=n(x9e,"STRONG",{});var Nct=s(vle);xto=r(Nct,"mvp"),Nct.forEach(t),$to=r(x9e," \u2014 "),UP=n(x9e,"A",{href:!0});var qct=s(UP);kto=r(qct,"MvpConfig"),qct.forEach(t),Sto=r(x9e," (MVP model)"),x9e.forEach(t),Rto=i(L),dg=n(L,"LI",{});var $9e=s(dg);Fle=n($9e,"STRONG",{});var jct=s(Fle);Pto=r(jct,"nezha"),jct.forEach(t),Bto=r($9e," \u2014 "),HP=n($9e,"A",{href:!0});var Dct=s(HP);Ito=r(Dct,"NezhaConfig"),Dct.forEach(t),Nto=r($9e," (Nezha model)"),$9e.forEach(t),qto=i(L),cg=n(L,"LI",{});var k9e=s(cg);Tle=n(k9e,"STRONG",{});var Gct=s(Tle);jto=r(Gct,"nystromformer"),Gct.forEach(t),Dto=r(k9e," \u2014 "),JP=n(k9e,"A",{href:!0});var Oct=s(JP);Gto=r(Oct,"NystromformerConfig"),Oct.forEach(t),Oto=r(k9e," (Nystr\xF6mformer model)"),k9e.forEach(t),Vto=i(L),fg=n(L,"LI",{});var S9e=s(fg);Mle=n(S9e,"STRONG",{});var Vct=s(Mle);Xto=r(Vct,"openai-gpt"),Vct.forEach(t),zto=r(S9e," \u2014 "),YP=n(S9e,"A",{href:!0});var Xct=s(YP);Wto=r(Xct,"OpenAIGPTConfig"),Xct.forEach(t),Qto=r(S9e," (OpenAI GPT model)"),S9e.forEach(t),Uto=i(L),mg=n(L,"LI",{});var R9e=s(mg);Ele=n(R9e,"STRONG",{});var zct=s(Ele);Hto=r(zct,"opt"),zct.forEach(t),Jto=r(R9e," \u2014 "),KP=n(R9e,"A",{href:!0});var Wct=s(KP);Yto=r(Wct,"OPTConfig"),Wct.forEach(t),Kto=r(R9e," (OPT model)"),R9e.forEach(t),Zto=i(L),gg=n(L,"LI",{});var P9e=s(gg);Cle=n(P9e,"STRONG",{});var Qct=s(Cle);eao=r(Qct,"owlvit"),Qct.forEach(t),oao=r(P9e," \u2014 "),ZP=n(P9e,"A",{href:!0});var Uct=s(ZP);rao=r(Uct,"OwlViTConfig"),Uct.forEach(t),tao=r(P9e," (OWL-ViT model)"),P9e.forEach(t),aao=i(L),hg=n(L,"LI",{});var B9e=s(hg);wle=n(B9e,"STRONG",{});var Hct=s(wle);nao=r(Hct,"pegasus"),Hct.forEach(t),sao=r(B9e," \u2014 "),eB=n(B9e,"A",{href:!0});var Jct=s(eB);lao=r(Jct,"PegasusConfig"),Jct.forEach(t),iao=r(B9e," (Pegasus model)"),B9e.forEach(t),dao=i(L),pg=n(L,"LI",{});var I9e=s(pg);Ale=n(I9e,"STRONG",{});var Yct=s(Ale);cao=r(Yct,"perceiver"),Yct.forEach(t),fao=r(I9e," \u2014 "),oB=n(I9e,"A",{href:!0});var Kct=s(oB);mao=r(Kct,"PerceiverConfig"),Kct.forEach(t),gao=r(I9e," (Perceiver model)"),I9e.forEach(t),hao=i(L),_g=n(L,"LI",{});var N9e=s(_g);Lle=n(N9e,"STRONG",{});var Zct=s(Lle);pao=r(Zct,"plbart"),Zct.forEach(t),_ao=r(N9e," \u2014 "),rB=n(N9e,"A",{href:!0});var eft=s(rB);uao=r(eft,"PLBartConfig"),eft.forEach(t),bao=r(N9e," (PLBart model)"),N9e.forEach(t),vao=i(L),ug=n(L,"LI",{});var q9e=s(ug);yle=n(q9e,"STRONG",{});var oft=s(yle);Fao=r(oft,"poolformer"),oft.forEach(t),Tao=r(q9e," \u2014 "),tB=n(q9e,"A",{href:!0});var rft=s(tB);Mao=r(rft,"PoolFormerConfig"),rft.forEach(t),Eao=r(q9e," (PoolFormer model)"),q9e.forEach(t),Cao=i(L),bg=n(L,"LI",{});var j9e=s(bg);xle=n(j9e,"STRONG",{});var tft=s(xle);wao=r(tft,"prophetnet"),tft.forEach(t),Aao=r(j9e," \u2014 "),aB=n(j9e,"A",{href:!0});var aft=s(aB);Lao=r(aft,"ProphetNetConfig"),aft.forEach(t),yao=r(j9e," (ProphetNet model)"),j9e.forEach(t),xao=i(L),vg=n(L,"LI",{});var D9e=s(vg);$le=n(D9e,"STRONG",{});var nft=s($le);$ao=r(nft,"qdqbert"),nft.forEach(t),kao=r(D9e," \u2014 "),nB=n(D9e,"A",{href:!0});var sft=s(nB);Sao=r(sft,"QDQBertConfig"),sft.forEach(t),Rao=r(D9e," (QDQBert model)"),D9e.forEach(t),Pao=i(L),Fg=n(L,"LI",{});var G9e=s(Fg);kle=n(G9e,"STRONG",{});var lft=s(kle);Bao=r(lft,"rag"),lft.forEach(t),Iao=r(G9e," \u2014 "),sB=n(G9e,"A",{href:!0});var ift=s(sB);Nao=r(ift,"RagConfig"),ift.forEach(t),qao=r(G9e," (RAG model)"),G9e.forEach(t),jao=i(L),Tg=n(L,"LI",{});var O9e=s(Tg);Sle=n(O9e,"STRONG",{});var dft=s(Sle);Dao=r(dft,"realm"),dft.forEach(t),Gao=r(O9e," \u2014 "),lB=n(O9e,"A",{href:!0});var cft=s(lB);Oao=r(cft,"RealmConfig"),cft.forEach(t),Vao=r(O9e," (REALM model)"),O9e.forEach(t),Xao=i(L),Mg=n(L,"LI",{});var V9e=s(Mg);Rle=n(V9e,"STRONG",{});var fft=s(Rle);zao=r(fft,"reformer"),fft.forEach(t),Wao=r(V9e," \u2014 "),iB=n(V9e,"A",{href:!0});var mft=s(iB);Qao=r(mft,"ReformerConfig"),mft.forEach(t),Uao=r(V9e," (Reformer model)"),V9e.forEach(t),Hao=i(L),Eg=n(L,"LI",{});var X9e=s(Eg);Ple=n(X9e,"STRONG",{});var gft=s(Ple);Jao=r(gft,"regnet"),gft.forEach(t),Yao=r(X9e," \u2014 "),dB=n(X9e,"A",{href:!0});var hft=s(dB);Kao=r(hft,"RegNetConfig"),hft.forEach(t),Zao=r(X9e," (RegNet model)"),X9e.forEach(t),eno=i(L),Cg=n(L,"LI",{});var z9e=s(Cg);Ble=n(z9e,"STRONG",{});var pft=s(Ble);ono=r(pft,"rembert"),pft.forEach(t),rno=r(z9e," \u2014 "),cB=n(z9e,"A",{href:!0});var _ft=s(cB);tno=r(_ft,"RemBertConfig"),_ft.forEach(t),ano=r(z9e," (RemBERT model)"),z9e.forEach(t),nno=i(L),wg=n(L,"LI",{});var W9e=s(wg);Ile=n(W9e,"STRONG",{});var uft=s(Ile);sno=r(uft,"resnet"),uft.forEach(t),lno=r(W9e," \u2014 "),fB=n(W9e,"A",{href:!0});var bft=s(fB);ino=r(bft,"ResNetConfig"),bft.forEach(t),dno=r(W9e," (ResNet model)"),W9e.forEach(t),cno=i(L),Ag=n(L,"LI",{});var Q9e=s(Ag);Nle=n(Q9e,"STRONG",{});var vft=s(Nle);fno=r(vft,"retribert"),vft.forEach(t),mno=r(Q9e," \u2014 "),mB=n(Q9e,"A",{href:!0});var Fft=s(mB);gno=r(Fft,"RetriBertConfig"),Fft.forEach(t),hno=r(Q9e," (RetriBERT model)"),Q9e.forEach(t),pno=i(L),Lg=n(L,"LI",{});var U9e=s(Lg);qle=n(U9e,"STRONG",{});var Tft=s(qle);_no=r(Tft,"roberta"),Tft.forEach(t),uno=r(U9e," \u2014 "),gB=n(U9e,"A",{href:!0});var Mft=s(gB);bno=r(Mft,"RobertaConfig"),Mft.forEach(t),vno=r(U9e," (RoBERTa model)"),U9e.forEach(t),Fno=i(L),yg=n(L,"LI",{});var H9e=s(yg);jle=n(H9e,"STRONG",{});var Eft=s(jle);Tno=r(Eft,"roformer"),Eft.forEach(t),Mno=r(H9e," \u2014 "),hB=n(H9e,"A",{href:!0});var Cft=s(hB);Eno=r(Cft,"RoFormerConfig"),Cft.forEach(t),Cno=r(H9e," (RoFormer model)"),H9e.forEach(t),wno=i(L),xg=n(L,"LI",{});var J9e=s(xg);Dle=n(J9e,"STRONG",{});var wft=s(Dle);Ano=r(wft,"segformer"),wft.forEach(t),Lno=r(J9e," \u2014 "),pB=n(J9e,"A",{href:!0});var Aft=s(pB);yno=r(Aft,"SegformerConfig"),Aft.forEach(t),xno=r(J9e," (SegFormer model)"),J9e.forEach(t),$no=i(L),$g=n(L,"LI",{});var Y9e=s($g);Gle=n(Y9e,"STRONG",{});var Lft=s(Gle);kno=r(Lft,"sew"),Lft.forEach(t),Sno=r(Y9e," \u2014 "),_B=n(Y9e,"A",{href:!0});var yft=s(_B);Rno=r(yft,"SEWConfig"),yft.forEach(t),Pno=r(Y9e," (SEW model)"),Y9e.forEach(t),Bno=i(L),kg=n(L,"LI",{});var K9e=s(kg);Ole=n(K9e,"STRONG",{});var xft=s(Ole);Ino=r(xft,"sew-d"),xft.forEach(t),Nno=r(K9e," \u2014 "),uB=n(K9e,"A",{href:!0});var $ft=s(uB);qno=r($ft,"SEWDConfig"),$ft.forEach(t),jno=r(K9e," (SEW-D model)"),K9e.forEach(t),Dno=i(L),Sg=n(L,"LI",{});var Z9e=s(Sg);Vle=n(Z9e,"STRONG",{});var kft=s(Vle);Gno=r(kft,"speech-encoder-decoder"),kft.forEach(t),Ono=r(Z9e," \u2014 "),bB=n(Z9e,"A",{href:!0});var Sft=s(bB);Vno=r(Sft,"SpeechEncoderDecoderConfig"),Sft.forEach(t),Xno=r(Z9e," (Speech Encoder decoder model)"),Z9e.forEach(t),zno=i(L),Rg=n(L,"LI",{});var exe=s(Rg);Xle=n(exe,"STRONG",{});var Rft=s(Xle);Wno=r(Rft,"speech_to_text"),Rft.forEach(t),Qno=r(exe," \u2014 "),vB=n(exe,"A",{href:!0});var Pft=s(vB);Uno=r(Pft,"Speech2TextConfig"),Pft.forEach(t),Hno=r(exe," (Speech2Text model)"),exe.forEach(t),Jno=i(L),Pg=n(L,"LI",{});var oxe=s(Pg);zle=n(oxe,"STRONG",{});var Bft=s(zle);Yno=r(Bft,"speech_to_text_2"),Bft.forEach(t),Kno=r(oxe," \u2014 "),FB=n(oxe,"A",{href:!0});var Ift=s(FB);Zno=r(Ift,"Speech2Text2Config"),Ift.forEach(t),eso=r(oxe," (Speech2Text2 model)"),oxe.forEach(t),oso=i(L),Bg=n(L,"LI",{});var rxe=s(Bg);Wle=n(rxe,"STRONG",{});var Nft=s(Wle);rso=r(Nft,"splinter"),Nft.forEach(t),tso=r(rxe," \u2014 "),TB=n(rxe,"A",{href:!0});var qft=s(TB);aso=r(qft,"SplinterConfig"),qft.forEach(t),nso=r(rxe," (Splinter model)"),rxe.forEach(t),sso=i(L),Ig=n(L,"LI",{});var txe=s(Ig);Qle=n(txe,"STRONG",{});var jft=s(Qle);lso=r(jft,"squeezebert"),jft.forEach(t),iso=r(txe," \u2014 "),MB=n(txe,"A",{href:!0});var Dft=s(MB);dso=r(Dft,"SqueezeBertConfig"),Dft.forEach(t),cso=r(txe," (SqueezeBERT model)"),txe.forEach(t),fso=i(L),Ng=n(L,"LI",{});var axe=s(Ng);Ule=n(axe,"STRONG",{});var Gft=s(Ule);mso=r(Gft,"swin"),Gft.forEach(t),gso=r(axe," \u2014 "),EB=n(axe,"A",{href:!0});var Oft=s(EB);hso=r(Oft,"SwinConfig"),Oft.forEach(t),pso=r(axe," (Swin Transformer model)"),axe.forEach(t),_so=i(L),qg=n(L,"LI",{});var nxe=s(qg);Hle=n(nxe,"STRONG",{});var Vft=s(Hle);uso=r(Vft,"swinv2"),Vft.forEach(t),bso=r(nxe," \u2014 "),CB=n(nxe,"A",{href:!0});var Xft=s(CB);vso=r(Xft,"Swinv2Config"),Xft.forEach(t),Fso=r(nxe," (Swin Transformer V2 model)"),nxe.forEach(t),Tso=i(L),jg=n(L,"LI",{});var sxe=s(jg);Jle=n(sxe,"STRONG",{});var zft=s(Jle);Mso=r(zft,"t5"),zft.forEach(t),Eso=r(sxe," \u2014 "),wB=n(sxe,"A",{href:!0});var Wft=s(wB);Cso=r(Wft,"T5Config"),Wft.forEach(t),wso=r(sxe," (T5 model)"),sxe.forEach(t),Aso=i(L),Dg=n(L,"LI",{});var lxe=s(Dg);Yle=n(lxe,"STRONG",{});var Qft=s(Yle);Lso=r(Qft,"tapas"),Qft.forEach(t),yso=r(lxe," \u2014 "),AB=n(lxe,"A",{href:!0});var Uft=s(AB);xso=r(Uft,"TapasConfig"),Uft.forEach(t),$so=r(lxe," (TAPAS model)"),lxe.forEach(t),kso=i(L),Gg=n(L,"LI",{});var ixe=s(Gg);Kle=n(ixe,"STRONG",{});var Hft=s(Kle);Sso=r(Hft,"trajectory_transformer"),Hft.forEach(t),Rso=r(ixe," \u2014 "),LB=n(ixe,"A",{href:!0});var Jft=s(LB);Pso=r(Jft,"TrajectoryTransformerConfig"),Jft.forEach(t),Bso=r(ixe," (Trajectory Transformer model)"),ixe.forEach(t),Iso=i(L),Og=n(L,"LI",{});var dxe=s(Og);Zle=n(dxe,"STRONG",{});var Yft=s(Zle);Nso=r(Yft,"transfo-xl"),Yft.forEach(t),qso=r(dxe," \u2014 "),yB=n(dxe,"A",{href:!0});var Kft=s(yB);jso=r(Kft,"TransfoXLConfig"),Kft.forEach(t),Dso=r(dxe," (Transformer-XL model)"),dxe.forEach(t),Gso=i(L),Vg=n(L,"LI",{});var cxe=s(Vg);eie=n(cxe,"STRONG",{});var Zft=s(eie);Oso=r(Zft,"trocr"),Zft.forEach(t),Vso=r(cxe," \u2014 "),xB=n(cxe,"A",{href:!0});var emt=s(xB);Xso=r(emt,"TrOCRConfig"),emt.forEach(t),zso=r(cxe," (TrOCR model)"),cxe.forEach(t),Wso=i(L),Xg=n(L,"LI",{});var fxe=s(Xg);oie=n(fxe,"STRONG",{});var omt=s(oie);Qso=r(omt,"unispeech"),omt.forEach(t),Uso=r(fxe," \u2014 "),$B=n(fxe,"A",{href:!0});var rmt=s($B);Hso=r(rmt,"UniSpeechConfig"),rmt.forEach(t),Jso=r(fxe," (UniSpeech model)"),fxe.forEach(t),Yso=i(L),zg=n(L,"LI",{});var mxe=s(zg);rie=n(mxe,"STRONG",{});var tmt=s(rie);Kso=r(tmt,"unispeech-sat"),tmt.forEach(t),Zso=r(mxe," \u2014 "),kB=n(mxe,"A",{href:!0});var amt=s(kB);elo=r(amt,"UniSpeechSatConfig"),amt.forEach(t),olo=r(mxe," (UniSpeechSat model)"),mxe.forEach(t),rlo=i(L),Wg=n(L,"LI",{});var gxe=s(Wg);tie=n(gxe,"STRONG",{});var nmt=s(tie);tlo=r(nmt,"van"),nmt.forEach(t),alo=r(gxe," \u2014 "),SB=n(gxe,"A",{href:!0});var smt=s(SB);nlo=r(smt,"VanConfig"),smt.forEach(t),slo=r(gxe," (VAN model)"),gxe.forEach(t),llo=i(L),Qg=n(L,"LI",{});var hxe=s(Qg);aie=n(hxe,"STRONG",{});var lmt=s(aie);ilo=r(lmt,"videomae"),lmt.forEach(t),dlo=r(hxe," \u2014 "),RB=n(hxe,"A",{href:!0});var imt=s(RB);clo=r(imt,"VideoMAEConfig"),imt.forEach(t),flo=r(hxe," (VideoMAE model)"),hxe.forEach(t),mlo=i(L),Ug=n(L,"LI",{});var pxe=s(Ug);nie=n(pxe,"STRONG",{});var dmt=s(nie);glo=r(dmt,"vilt"),dmt.forEach(t),hlo=r(pxe," \u2014 "),PB=n(pxe,"A",{href:!0});var cmt=s(PB);plo=r(cmt,"ViltConfig"),cmt.forEach(t),_lo=r(pxe," (ViLT model)"),pxe.forEach(t),ulo=i(L),Hg=n(L,"LI",{});var _xe=s(Hg);sie=n(_xe,"STRONG",{});var fmt=s(sie);blo=r(fmt,"vision-encoder-decoder"),fmt.forEach(t),vlo=r(_xe," \u2014 "),BB=n(_xe,"A",{href:!0});var mmt=s(BB);Flo=r(mmt,"VisionEncoderDecoderConfig"),mmt.forEach(t),Tlo=r(_xe," (Vision Encoder decoder model)"),_xe.forEach(t),Mlo=i(L),Jg=n(L,"LI",{});var uxe=s(Jg);lie=n(uxe,"STRONG",{});var gmt=s(lie);Elo=r(gmt,"vision-text-dual-encoder"),gmt.forEach(t),Clo=r(uxe," \u2014 "),IB=n(uxe,"A",{href:!0});var hmt=s(IB);wlo=r(hmt,"VisionTextDualEncoderConfig"),hmt.forEach(t),Alo=r(uxe," (VisionTextDualEncoder model)"),uxe.forEach(t),Llo=i(L),Yg=n(L,"LI",{});var bxe=s(Yg);iie=n(bxe,"STRONG",{});var pmt=s(iie);ylo=r(pmt,"visual_bert"),pmt.forEach(t),xlo=r(bxe," \u2014 "),NB=n(bxe,"A",{href:!0});var _mt=s(NB);$lo=r(_mt,"VisualBertConfig"),_mt.forEach(t),klo=r(bxe," (VisualBERT model)"),bxe.forEach(t),Slo=i(L),Kg=n(L,"LI",{});var vxe=s(Kg);die=n(vxe,"STRONG",{});var umt=s(die);Rlo=r(umt,"vit"),umt.forEach(t),Plo=r(vxe," \u2014 "),qB=n(vxe,"A",{href:!0});var bmt=s(qB);Blo=r(bmt,"ViTConfig"),bmt.forEach(t),Ilo=r(vxe," (ViT model)"),vxe.forEach(t),Nlo=i(L),Zg=n(L,"LI",{});var Fxe=s(Zg);cie=n(Fxe,"STRONG",{});var vmt=s(cie);qlo=r(vmt,"vit_mae"),vmt.forEach(t),jlo=r(Fxe," \u2014 "),jB=n(Fxe,"A",{href:!0});var Fmt=s(jB);Dlo=r(Fmt,"ViTMAEConfig"),Fmt.forEach(t),Glo=r(Fxe," (ViTMAE model)"),Fxe.forEach(t),Olo=i(L),eh=n(L,"LI",{});var Txe=s(eh);fie=n(Txe,"STRONG",{});var Tmt=s(fie);Vlo=r(Tmt,"wav2vec2"),Tmt.forEach(t),Xlo=r(Txe," \u2014 "),DB=n(Txe,"A",{href:!0});var Mmt=s(DB);zlo=r(Mmt,"Wav2Vec2Config"),Mmt.forEach(t),Wlo=r(Txe," (Wav2Vec2 model)"),Txe.forEach(t),Qlo=i(L),oh=n(L,"LI",{});var Mxe=s(oh);mie=n(Mxe,"STRONG",{});var Emt=s(mie);Ulo=r(Emt,"wav2vec2-conformer"),Emt.forEach(t),Hlo=r(Mxe," \u2014 "),GB=n(Mxe,"A",{href:!0});var Cmt=s(GB);Jlo=r(Cmt,"Wav2Vec2ConformerConfig"),Cmt.forEach(t),Ylo=r(Mxe," (Wav2Vec2-Conformer model)"),Mxe.forEach(t),Klo=i(L),rh=n(L,"LI",{});var Exe=s(rh);gie=n(Exe,"STRONG",{});var wmt=s(gie);Zlo=r(wmt,"wavlm"),wmt.forEach(t),eio=r(Exe," \u2014 "),OB=n(Exe,"A",{href:!0});var Amt=s(OB);oio=r(Amt,"WavLMConfig"),Amt.forEach(t),rio=r(Exe," (WavLM model)"),Exe.forEach(t),tio=i(L),th=n(L,"LI",{});var Cxe=s(th);hie=n(Cxe,"STRONG",{});var Lmt=s(hie);aio=r(Lmt,"xglm"),Lmt.forEach(t),nio=r(Cxe," \u2014 "),VB=n(Cxe,"A",{href:!0});var ymt=s(VB);sio=r(ymt,"XGLMConfig"),ymt.forEach(t),lio=r(Cxe," (XGLM model)"),Cxe.forEach(t),iio=i(L),ah=n(L,"LI",{});var wxe=s(ah);pie=n(wxe,"STRONG",{});var xmt=s(pie);dio=r(xmt,"xlm"),xmt.forEach(t),cio=r(wxe," \u2014 "),XB=n(wxe,"A",{href:!0});var $mt=s(XB);fio=r($mt,"XLMConfig"),$mt.forEach(t),mio=r(wxe," (XLM model)"),wxe.forEach(t),gio=i(L),nh=n(L,"LI",{});var Axe=s(nh);_ie=n(Axe,"STRONG",{});var kmt=s(_ie);hio=r(kmt,"xlm-prophetnet"),kmt.forEach(t),pio=r(Axe," \u2014 "),zB=n(Axe,"A",{href:!0});var Smt=s(zB);_io=r(Smt,"XLMProphetNetConfig"),Smt.forEach(t),uio=r(Axe," (XLM-ProphetNet model)"),Axe.forEach(t),bio=i(L),sh=n(L,"LI",{});var Lxe=s(sh);uie=n(Lxe,"STRONG",{});var Rmt=s(uie);vio=r(Rmt,"xlm-roberta"),Rmt.forEach(t),Fio=r(Lxe," \u2014 "),WB=n(Lxe,"A",{href:!0});var Pmt=s(WB);Tio=r(Pmt,"XLMRobertaConfig"),Pmt.forEach(t),Mio=r(Lxe," (XLM-RoBERTa model)"),Lxe.forEach(t),Eio=i(L),lh=n(L,"LI",{});var yxe=s(lh);bie=n(yxe,"STRONG",{});var Bmt=s(bie);Cio=r(Bmt,"xlm-roberta-xl"),Bmt.forEach(t),wio=r(yxe," \u2014 "),QB=n(yxe,"A",{href:!0});var Imt=s(QB);Aio=r(Imt,"XLMRobertaXLConfig"),Imt.forEach(t),Lio=r(yxe," (XLM-RoBERTa-XL model)"),yxe.forEach(t),yio=i(L),ih=n(L,"LI",{});var xxe=s(ih);vie=n(xxe,"STRONG",{});var Nmt=s(vie);xio=r(Nmt,"xlnet"),Nmt.forEach(t),$io=r(xxe," \u2014 "),UB=n(xxe,"A",{href:!0});var qmt=s(UB);kio=r(qmt,"XLNetConfig"),qmt.forEach(t),Sio=r(xxe," (XLNet model)"),xxe.forEach(t),Rio=i(L),dh=n(L,"LI",{});var $xe=s(dh);Fie=n($xe,"STRONG",{});var jmt=s(Fie);Pio=r(jmt,"yolos"),jmt.forEach(t),Bio=r($xe," \u2014 "),HB=n($xe,"A",{href:!0});var Dmt=s(HB);Iio=r(Dmt,"YolosConfig"),Dmt.forEach(t),Nio=r($xe," (YOLOS model)"),$xe.forEach(t),qio=i(L),ch=n(L,"LI",{});var kxe=s(ch);Tie=n(kxe,"STRONG",{});var Gmt=s(Tie);jio=r(Gmt,"yoso"),Gmt.forEach(t),Dio=r(kxe," \u2014 "),JB=n(kxe,"A",{href:!0});var Omt=s(JB);Gio=r(Omt,"YosoConfig"),Omt.forEach(t),Oio=r(kxe," (YOSO model)"),kxe.forEach(t),L.forEach(t),Vio=i(it),T(fh.$$.fragment,it),it.forEach(t),Xio=i(lt),mh=n(lt,"DIV",{class:!0});var QUe=s(mh);T(ey.$$.fragment,QUe),zio=i(QUe),Mie=n(QUe,"P",{});var Vmt=s(Mie);Wio=r(Vmt,"Register a new configuration for this class."),Vmt.forEach(t),QUe.forEach(t),lt.forEach(t),WWe=i(f),Wi=n(f,"H2",{class:!0});var UUe=s(Wi);gh=n(UUe,"A",{id:!0,class:!0,href:!0});var Xmt=s(gh);Eie=n(Xmt,"SPAN",{});var zmt=s(Eie);T(oy.$$.fragment,zmt),zmt.forEach(t),Xmt.forEach(t),Qio=i(UUe),Cie=n(UUe,"SPAN",{});var Wmt=s(Cie);Uio=r(Wmt,"AutoTokenizer"),Wmt.forEach(t),UUe.forEach(t),QWe=i(f),xo=n(f,"DIV",{class:!0});var sl=s(xo);T(ry.$$.fragment,sl),Hio=i(sl),ty=n(sl,"P",{});var HUe=s(ty);Jio=r(HUe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),YB=n(HUe,"A",{href:!0});var Qmt=s(YB);Yio=r(Qmt,"AutoTokenizer.from_pretrained()"),Qmt.forEach(t),Kio=r(HUe," class method."),HUe.forEach(t),Zio=i(sl),ay=n(sl,"P",{});var JUe=s(ay);edo=r(JUe,"This class cannot be instantiated directly using "),wie=n(JUe,"CODE",{});var Umt=s(wie);odo=r(Umt,"__init__()"),Umt.forEach(t),rdo=r(JUe," (throws an error)."),JUe.forEach(t),tdo=i(sl),kr=n(sl,"DIV",{class:!0});var ll=s(kr);T(ny.$$.fragment,ll),ado=i(ll),Aie=n(ll,"P",{});var Hmt=s(Aie);ndo=r(Hmt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Hmt.forEach(t),sdo=i(ll),qa=n(ll,"P",{});var WA=s(qa);ldo=r(WA,"The tokenizer class to instantiate is selected based on the "),Lie=n(WA,"CODE",{});var Jmt=s(Lie);ido=r(Jmt,"model_type"),Jmt.forEach(t),ddo=r(WA,` property of the config object (either
passed as an argument or loaded from `),yie=n(WA,"CODE",{});var Ymt=s(yie);cdo=r(Ymt,"pretrained_model_name_or_path"),Ymt.forEach(t),fdo=r(WA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xie=n(WA,"CODE",{});var Kmt=s(xie);mdo=r(Kmt,"pretrained_model_name_or_path"),Kmt.forEach(t),gdo=r(WA,":"),WA.forEach(t),hdo=i(ll),k=n(ll,"UL",{});var S=s(k);zn=n(S,"LI",{});var _S=s(zn);$ie=n(_S,"STRONG",{});var Zmt=s($ie);pdo=r(Zmt,"albert"),Zmt.forEach(t),_do=r(_S," \u2014 "),KB=n(_S,"A",{href:!0});var egt=s(KB);udo=r(egt,"AlbertTokenizer"),egt.forEach(t),bdo=r(_S," or "),ZB=n(_S,"A",{href:!0});var ogt=s(ZB);vdo=r(ogt,"AlbertTokenizerFast"),ogt.forEach(t),Fdo=r(_S," (ALBERT model)"),_S.forEach(t),Tdo=i(S),Wn=n(S,"LI",{});var uS=s(Wn);kie=n(uS,"STRONG",{});var rgt=s(kie);Mdo=r(rgt,"bart"),rgt.forEach(t),Edo=r(uS," \u2014 "),eI=n(uS,"A",{href:!0});var tgt=s(eI);Cdo=r(tgt,"BartTokenizer"),tgt.forEach(t),wdo=r(uS," or "),oI=n(uS,"A",{href:!0});var agt=s(oI);Ado=r(agt,"BartTokenizerFast"),agt.forEach(t),Ldo=r(uS," (BART model)"),uS.forEach(t),ydo=i(S),Qn=n(S,"LI",{});var bS=s(Qn);Sie=n(bS,"STRONG",{});var ngt=s(Sie);xdo=r(ngt,"barthez"),ngt.forEach(t),$do=r(bS," \u2014 "),rI=n(bS,"A",{href:!0});var sgt=s(rI);kdo=r(sgt,"BarthezTokenizer"),sgt.forEach(t),Sdo=r(bS," or "),tI=n(bS,"A",{href:!0});var lgt=s(tI);Rdo=r(lgt,"BarthezTokenizerFast"),lgt.forEach(t),Pdo=r(bS," (BARThez model)"),bS.forEach(t),Bdo=i(S),hh=n(S,"LI",{});var Sxe=s(hh);Rie=n(Sxe,"STRONG",{});var igt=s(Rie);Ido=r(igt,"bartpho"),igt.forEach(t),Ndo=r(Sxe," \u2014 "),aI=n(Sxe,"A",{href:!0});var dgt=s(aI);qdo=r(dgt,"BartphoTokenizer"),dgt.forEach(t),jdo=r(Sxe," (BARTpho model)"),Sxe.forEach(t),Ddo=i(S),Un=n(S,"LI",{});var vS=s(Un);Pie=n(vS,"STRONG",{});var cgt=s(Pie);Gdo=r(cgt,"bert"),cgt.forEach(t),Odo=r(vS," \u2014 "),nI=n(vS,"A",{href:!0});var fgt=s(nI);Vdo=r(fgt,"BertTokenizer"),fgt.forEach(t),Xdo=r(vS," or "),sI=n(vS,"A",{href:!0});var mgt=s(sI);zdo=r(mgt,"BertTokenizerFast"),mgt.forEach(t),Wdo=r(vS," (BERT model)"),vS.forEach(t),Qdo=i(S),ph=n(S,"LI",{});var Rxe=s(ph);Bie=n(Rxe,"STRONG",{});var ggt=s(Bie);Udo=r(ggt,"bert-generation"),ggt.forEach(t),Hdo=r(Rxe," \u2014 "),lI=n(Rxe,"A",{href:!0});var hgt=s(lI);Jdo=r(hgt,"BertGenerationTokenizer"),hgt.forEach(t),Ydo=r(Rxe," (Bert Generation model)"),Rxe.forEach(t),Kdo=i(S),_h=n(S,"LI",{});var Pxe=s(_h);Iie=n(Pxe,"STRONG",{});var pgt=s(Iie);Zdo=r(pgt,"bert-japanese"),pgt.forEach(t),eco=r(Pxe," \u2014 "),iI=n(Pxe,"A",{href:!0});var _gt=s(iI);oco=r(_gt,"BertJapaneseTokenizer"),_gt.forEach(t),rco=r(Pxe," (BertJapanese model)"),Pxe.forEach(t),tco=i(S),uh=n(S,"LI",{});var Bxe=s(uh);Nie=n(Bxe,"STRONG",{});var ugt=s(Nie);aco=r(ugt,"bertweet"),ugt.forEach(t),nco=r(Bxe," \u2014 "),dI=n(Bxe,"A",{href:!0});var bgt=s(dI);sco=r(bgt,"BertweetTokenizer"),bgt.forEach(t),lco=r(Bxe," (BERTweet model)"),Bxe.forEach(t),ico=i(S),Hn=n(S,"LI",{});var FS=s(Hn);qie=n(FS,"STRONG",{});var vgt=s(qie);dco=r(vgt,"big_bird"),vgt.forEach(t),cco=r(FS," \u2014 "),cI=n(FS,"A",{href:!0});var Fgt=s(cI);fco=r(Fgt,"BigBirdTokenizer"),Fgt.forEach(t),mco=r(FS," or "),fI=n(FS,"A",{href:!0});var Tgt=s(fI);gco=r(Tgt,"BigBirdTokenizerFast"),Tgt.forEach(t),hco=r(FS," (BigBird model)"),FS.forEach(t),pco=i(S),Jn=n(S,"LI",{});var TS=s(Jn);jie=n(TS,"STRONG",{});var Mgt=s(jie);_co=r(Mgt,"bigbird_pegasus"),Mgt.forEach(t),uco=r(TS," \u2014 "),mI=n(TS,"A",{href:!0});var Egt=s(mI);bco=r(Egt,"PegasusTokenizer"),Egt.forEach(t),vco=r(TS," or "),gI=n(TS,"A",{href:!0});var Cgt=s(gI);Fco=r(Cgt,"PegasusTokenizerFast"),Cgt.forEach(t),Tco=r(TS," (BigBird-Pegasus model)"),TS.forEach(t),Mco=i(S),Yn=n(S,"LI",{});var MS=s(Yn);Die=n(MS,"STRONG",{});var wgt=s(Die);Eco=r(wgt,"blenderbot"),wgt.forEach(t),Cco=r(MS," \u2014 "),hI=n(MS,"A",{href:!0});var Agt=s(hI);wco=r(Agt,"BlenderbotTokenizer"),Agt.forEach(t),Aco=r(MS," or "),pI=n(MS,"A",{href:!0});var Lgt=s(pI);Lco=r(Lgt,"BlenderbotTokenizerFast"),Lgt.forEach(t),yco=r(MS," (Blenderbot model)"),MS.forEach(t),xco=i(S),bh=n(S,"LI",{});var Ixe=s(bh);Gie=n(Ixe,"STRONG",{});var ygt=s(Gie);$co=r(ygt,"blenderbot-small"),ygt.forEach(t),kco=r(Ixe," \u2014 "),_I=n(Ixe,"A",{href:!0});var xgt=s(_I);Sco=r(xgt,"BlenderbotSmallTokenizer"),xgt.forEach(t),Rco=r(Ixe," (BlenderbotSmall model)"),Ixe.forEach(t),Pco=i(S),vh=n(S,"LI",{});var Nxe=s(vh);Oie=n(Nxe,"STRONG",{});var $gt=s(Oie);Bco=r($gt,"bloom"),$gt.forEach(t),Ico=r(Nxe," \u2014 "),uI=n(Nxe,"A",{href:!0});var kgt=s(uI);Nco=r(kgt,"BloomTokenizerFast"),kgt.forEach(t),qco=r(Nxe," (BLOOM model)"),Nxe.forEach(t),jco=i(S),Fh=n(S,"LI",{});var qxe=s(Fh);Vie=n(qxe,"STRONG",{});var Sgt=s(Vie);Dco=r(Sgt,"byt5"),Sgt.forEach(t),Gco=r(qxe," \u2014 "),bI=n(qxe,"A",{href:!0});var Rgt=s(bI);Oco=r(Rgt,"ByT5Tokenizer"),Rgt.forEach(t),Vco=r(qxe," (ByT5 model)"),qxe.forEach(t),Xco=i(S),Kn=n(S,"LI",{});var ES=s(Kn);Xie=n(ES,"STRONG",{});var Pgt=s(Xie);zco=r(Pgt,"camembert"),Pgt.forEach(t),Wco=r(ES," \u2014 "),vI=n(ES,"A",{href:!0});var Bgt=s(vI);Qco=r(Bgt,"CamembertTokenizer"),Bgt.forEach(t),Uco=r(ES," or "),FI=n(ES,"A",{href:!0});var Igt=s(FI);Hco=r(Igt,"CamembertTokenizerFast"),Igt.forEach(t),Jco=r(ES," (CamemBERT model)"),ES.forEach(t),Yco=i(S),Th=n(S,"LI",{});var jxe=s(Th);zie=n(jxe,"STRONG",{});var Ngt=s(zie);Kco=r(Ngt,"canine"),Ngt.forEach(t),Zco=r(jxe," \u2014 "),TI=n(jxe,"A",{href:!0});var qgt=s(TI);efo=r(qgt,"CanineTokenizer"),qgt.forEach(t),ofo=r(jxe," (CANINE model)"),jxe.forEach(t),rfo=i(S),Zn=n(S,"LI",{});var CS=s(Zn);Wie=n(CS,"STRONG",{});var jgt=s(Wie);tfo=r(jgt,"clip"),jgt.forEach(t),afo=r(CS," \u2014 "),MI=n(CS,"A",{href:!0});var Dgt=s(MI);nfo=r(Dgt,"CLIPTokenizer"),Dgt.forEach(t),sfo=r(CS," or "),EI=n(CS,"A",{href:!0});var Ggt=s(EI);lfo=r(Ggt,"CLIPTokenizerFast"),Ggt.forEach(t),ifo=r(CS," (CLIP model)"),CS.forEach(t),dfo=i(S),es=n(S,"LI",{});var wS=s(es);Qie=n(wS,"STRONG",{});var Ogt=s(Qie);cfo=r(Ogt,"codegen"),Ogt.forEach(t),ffo=r(wS," \u2014 "),CI=n(wS,"A",{href:!0});var Vgt=s(CI);mfo=r(Vgt,"CodeGenTokenizer"),Vgt.forEach(t),gfo=r(wS," or "),wI=n(wS,"A",{href:!0});var Xgt=s(wI);hfo=r(Xgt,"CodeGenTokenizerFast"),Xgt.forEach(t),pfo=r(wS," (CodeGen model)"),wS.forEach(t),_fo=i(S),os=n(S,"LI",{});var AS=s(os);Uie=n(AS,"STRONG",{});var zgt=s(Uie);ufo=r(zgt,"convbert"),zgt.forEach(t),bfo=r(AS," \u2014 "),AI=n(AS,"A",{href:!0});var Wgt=s(AI);vfo=r(Wgt,"ConvBertTokenizer"),Wgt.forEach(t),Ffo=r(AS," or "),LI=n(AS,"A",{href:!0});var Qgt=s(LI);Tfo=r(Qgt,"ConvBertTokenizerFast"),Qgt.forEach(t),Mfo=r(AS," (ConvBERT model)"),AS.forEach(t),Efo=i(S),rs=n(S,"LI",{});var LS=s(rs);Hie=n(LS,"STRONG",{});var Ugt=s(Hie);Cfo=r(Ugt,"cpm"),Ugt.forEach(t),wfo=r(LS," \u2014 "),yI=n(LS,"A",{href:!0});var Hgt=s(yI);Afo=r(Hgt,"CpmTokenizer"),Hgt.forEach(t),Lfo=r(LS," or "),xI=n(LS,"A",{href:!0});var Jgt=s(xI);yfo=r(Jgt,"CpmTokenizerFast"),Jgt.forEach(t),xfo=r(LS," (CPM model)"),LS.forEach(t),$fo=i(S),Mh=n(S,"LI",{});var Dxe=s(Mh);Jie=n(Dxe,"STRONG",{});var Ygt=s(Jie);kfo=r(Ygt,"ctrl"),Ygt.forEach(t),Sfo=r(Dxe," \u2014 "),$I=n(Dxe,"A",{href:!0});var Kgt=s($I);Rfo=r(Kgt,"CTRLTokenizer"),Kgt.forEach(t),Pfo=r(Dxe," (CTRL model)"),Dxe.forEach(t),Bfo=i(S),ts=n(S,"LI",{});var yS=s(ts);Yie=n(yS,"STRONG",{});var Zgt=s(Yie);Ifo=r(Zgt,"data2vec-text"),Zgt.forEach(t),Nfo=r(yS," \u2014 "),kI=n(yS,"A",{href:!0});var eht=s(kI);qfo=r(eht,"RobertaTokenizer"),eht.forEach(t),jfo=r(yS," or "),SI=n(yS,"A",{href:!0});var oht=s(SI);Dfo=r(oht,"RobertaTokenizerFast"),oht.forEach(t),Gfo=r(yS," (Data2VecText model)"),yS.forEach(t),Ofo=i(S),as=n(S,"LI",{});var xS=s(as);Kie=n(xS,"STRONG",{});var rht=s(Kie);Vfo=r(rht,"deberta"),rht.forEach(t),Xfo=r(xS," \u2014 "),RI=n(xS,"A",{href:!0});var tht=s(RI);zfo=r(tht,"DebertaTokenizer"),tht.forEach(t),Wfo=r(xS," or "),PI=n(xS,"A",{href:!0});var aht=s(PI);Qfo=r(aht,"DebertaTokenizerFast"),aht.forEach(t),Ufo=r(xS," (DeBERTa model)"),xS.forEach(t),Hfo=i(S),ns=n(S,"LI",{});var $S=s(ns);Zie=n($S,"STRONG",{});var nht=s(Zie);Jfo=r(nht,"deberta-v2"),nht.forEach(t),Yfo=r($S," \u2014 "),BI=n($S,"A",{href:!0});var sht=s(BI);Kfo=r(sht,"DebertaV2Tokenizer"),sht.forEach(t),Zfo=r($S," or "),II=n($S,"A",{href:!0});var lht=s(II);emo=r(lht,"DebertaV2TokenizerFast"),lht.forEach(t),omo=r($S," (DeBERTa-v2 model)"),$S.forEach(t),rmo=i(S),ss=n(S,"LI",{});var kS=s(ss);ede=n(kS,"STRONG",{});var iht=s(ede);tmo=r(iht,"distilbert"),iht.forEach(t),amo=r(kS," \u2014 "),NI=n(kS,"A",{href:!0});var dht=s(NI);nmo=r(dht,"DistilBertTokenizer"),dht.forEach(t),smo=r(kS," or "),qI=n(kS,"A",{href:!0});var cht=s(qI);lmo=r(cht,"DistilBertTokenizerFast"),cht.forEach(t),imo=r(kS," (DistilBERT model)"),kS.forEach(t),dmo=i(S),ls=n(S,"LI",{});var SS=s(ls);ode=n(SS,"STRONG",{});var fht=s(ode);cmo=r(fht,"dpr"),fht.forEach(t),fmo=r(SS," \u2014 "),jI=n(SS,"A",{href:!0});var mht=s(jI);mmo=r(mht,"DPRQuestionEncoderTokenizer"),mht.forEach(t),gmo=r(SS," or "),DI=n(SS,"A",{href:!0});var ght=s(DI);hmo=r(ght,"DPRQuestionEncoderTokenizerFast"),ght.forEach(t),pmo=r(SS," (DPR model)"),SS.forEach(t),_mo=i(S),is=n(S,"LI",{});var RS=s(is);rde=n(RS,"STRONG",{});var hht=s(rde);umo=r(hht,"electra"),hht.forEach(t),bmo=r(RS," \u2014 "),GI=n(RS,"A",{href:!0});var pht=s(GI);vmo=r(pht,"ElectraTokenizer"),pht.forEach(t),Fmo=r(RS," or "),OI=n(RS,"A",{href:!0});var _ht=s(OI);Tmo=r(_ht,"ElectraTokenizerFast"),_ht.forEach(t),Mmo=r(RS," (ELECTRA model)"),RS.forEach(t),Emo=i(S),Eh=n(S,"LI",{});var Gxe=s(Eh);tde=n(Gxe,"STRONG",{});var uht=s(tde);Cmo=r(uht,"flaubert"),uht.forEach(t),wmo=r(Gxe," \u2014 "),VI=n(Gxe,"A",{href:!0});var bht=s(VI);Amo=r(bht,"FlaubertTokenizer"),bht.forEach(t),Lmo=r(Gxe," (FlauBERT model)"),Gxe.forEach(t),ymo=i(S),ds=n(S,"LI",{});var PS=s(ds);ade=n(PS,"STRONG",{});var vht=s(ade);xmo=r(vht,"fnet"),vht.forEach(t),$mo=r(PS," \u2014 "),XI=n(PS,"A",{href:!0});var Fht=s(XI);kmo=r(Fht,"FNetTokenizer"),Fht.forEach(t),Smo=r(PS," or "),zI=n(PS,"A",{href:!0});var Tht=s(zI);Rmo=r(Tht,"FNetTokenizerFast"),Tht.forEach(t),Pmo=r(PS," (FNet model)"),PS.forEach(t),Bmo=i(S),Ch=n(S,"LI",{});var Oxe=s(Ch);nde=n(Oxe,"STRONG",{});var Mht=s(nde);Imo=r(Mht,"fsmt"),Mht.forEach(t),Nmo=r(Oxe," \u2014 "),WI=n(Oxe,"A",{href:!0});var Eht=s(WI);qmo=r(Eht,"FSMTTokenizer"),Eht.forEach(t),jmo=r(Oxe," (FairSeq Machine-Translation model)"),Oxe.forEach(t),Dmo=i(S),cs=n(S,"LI",{});var BS=s(cs);sde=n(BS,"STRONG",{});var Cht=s(sde);Gmo=r(Cht,"funnel"),Cht.forEach(t),Omo=r(BS," \u2014 "),QI=n(BS,"A",{href:!0});var wht=s(QI);Vmo=r(wht,"FunnelTokenizer"),wht.forEach(t),Xmo=r(BS," or "),UI=n(BS,"A",{href:!0});var Aht=s(UI);zmo=r(Aht,"FunnelTokenizerFast"),Aht.forEach(t),Wmo=r(BS," (Funnel Transformer model)"),BS.forEach(t),Qmo=i(S),fs=n(S,"LI",{});var IS=s(fs);lde=n(IS,"STRONG",{});var Lht=s(lde);Umo=r(Lht,"gpt2"),Lht.forEach(t),Hmo=r(IS," \u2014 "),HI=n(IS,"A",{href:!0});var yht=s(HI);Jmo=r(yht,"GPT2Tokenizer"),yht.forEach(t),Ymo=r(IS," or "),JI=n(IS,"A",{href:!0});var xht=s(JI);Kmo=r(xht,"GPT2TokenizerFast"),xht.forEach(t),Zmo=r(IS," (OpenAI GPT-2 model)"),IS.forEach(t),ego=i(S),ms=n(S,"LI",{});var NS=s(ms);ide=n(NS,"STRONG",{});var $ht=s(ide);ogo=r($ht,"gpt_neo"),$ht.forEach(t),rgo=r(NS," \u2014 "),YI=n(NS,"A",{href:!0});var kht=s(YI);tgo=r(kht,"GPT2Tokenizer"),kht.forEach(t),ago=r(NS," or "),KI=n(NS,"A",{href:!0});var Sht=s(KI);ngo=r(Sht,"GPT2TokenizerFast"),Sht.forEach(t),sgo=r(NS," (GPT Neo model)"),NS.forEach(t),lgo=i(S),wh=n(S,"LI",{});var Vxe=s(wh);dde=n(Vxe,"STRONG",{});var Rht=s(dde);igo=r(Rht,"gpt_neox"),Rht.forEach(t),dgo=r(Vxe," \u2014 "),ZI=n(Vxe,"A",{href:!0});var Pht=s(ZI);cgo=r(Pht,"GPTNeoXTokenizerFast"),Pht.forEach(t),fgo=r(Vxe," (GPT NeoX model)"),Vxe.forEach(t),mgo=i(S),gs=n(S,"LI",{});var qS=s(gs);cde=n(qS,"STRONG",{});var Bht=s(cde);ggo=r(Bht,"gptj"),Bht.forEach(t),hgo=r(qS," \u2014 "),eN=n(qS,"A",{href:!0});var Iht=s(eN);pgo=r(Iht,"GPT2Tokenizer"),Iht.forEach(t),_go=r(qS," or "),oN=n(qS,"A",{href:!0});var Nht=s(oN);ugo=r(Nht,"GPT2TokenizerFast"),Nht.forEach(t),bgo=r(qS," (GPT-J model)"),qS.forEach(t),vgo=i(S),hs=n(S,"LI",{});var jS=s(hs);fde=n(jS,"STRONG",{});var qht=s(fde);Fgo=r(qht,"groupvit"),qht.forEach(t),Tgo=r(jS," \u2014 "),rN=n(jS,"A",{href:!0});var jht=s(rN);Mgo=r(jht,"CLIPTokenizer"),jht.forEach(t),Ego=r(jS," or "),tN=n(jS,"A",{href:!0});var Dht=s(tN);Cgo=r(Dht,"CLIPTokenizerFast"),Dht.forEach(t),wgo=r(jS," (GroupViT model)"),jS.forEach(t),Ago=i(S),ps=n(S,"LI",{});var DS=s(ps);mde=n(DS,"STRONG",{});var Ght=s(mde);Lgo=r(Ght,"herbert"),Ght.forEach(t),ygo=r(DS," \u2014 "),aN=n(DS,"A",{href:!0});var Oht=s(aN);xgo=r(Oht,"HerbertTokenizer"),Oht.forEach(t),$go=r(DS," or "),nN=n(DS,"A",{href:!0});var Vht=s(nN);kgo=r(Vht,"HerbertTokenizerFast"),Vht.forEach(t),Sgo=r(DS," (HerBERT model)"),DS.forEach(t),Rgo=i(S),Ah=n(S,"LI",{});var Xxe=s(Ah);gde=n(Xxe,"STRONG",{});var Xht=s(gde);Pgo=r(Xht,"hubert"),Xht.forEach(t),Bgo=r(Xxe," \u2014 "),sN=n(Xxe,"A",{href:!0});var zht=s(sN);Igo=r(zht,"Wav2Vec2CTCTokenizer"),zht.forEach(t),Ngo=r(Xxe," (Hubert model)"),Xxe.forEach(t),qgo=i(S),_s=n(S,"LI",{});var GS=s(_s);hde=n(GS,"STRONG",{});var Wht=s(hde);jgo=r(Wht,"ibert"),Wht.forEach(t),Dgo=r(GS," \u2014 "),lN=n(GS,"A",{href:!0});var Qht=s(lN);Ggo=r(Qht,"RobertaTokenizer"),Qht.forEach(t),Ogo=r(GS," or "),iN=n(GS,"A",{href:!0});var Uht=s(iN);Vgo=r(Uht,"RobertaTokenizerFast"),Uht.forEach(t),Xgo=r(GS," (I-BERT model)"),GS.forEach(t),zgo=i(S),us=n(S,"LI",{});var OS=s(us);pde=n(OS,"STRONG",{});var Hht=s(pde);Wgo=r(Hht,"layoutlm"),Hht.forEach(t),Qgo=r(OS," \u2014 "),dN=n(OS,"A",{href:!0});var Jht=s(dN);Ugo=r(Jht,"LayoutLMTokenizer"),Jht.forEach(t),Hgo=r(OS," or "),cN=n(OS,"A",{href:!0});var Yht=s(cN);Jgo=r(Yht,"LayoutLMTokenizerFast"),Yht.forEach(t),Ygo=r(OS," (LayoutLM model)"),OS.forEach(t),Kgo=i(S),bs=n(S,"LI",{});var VS=s(bs);_de=n(VS,"STRONG",{});var Kht=s(_de);Zgo=r(Kht,"layoutlmv2"),Kht.forEach(t),eho=r(VS," \u2014 "),fN=n(VS,"A",{href:!0});var Zht=s(fN);oho=r(Zht,"LayoutLMv2Tokenizer"),Zht.forEach(t),rho=r(VS," or "),mN=n(VS,"A",{href:!0});var ept=s(mN);tho=r(ept,"LayoutLMv2TokenizerFast"),ept.forEach(t),aho=r(VS," (LayoutLMv2 model)"),VS.forEach(t),nho=i(S),vs=n(S,"LI",{});var XS=s(vs);ude=n(XS,"STRONG",{});var opt=s(ude);sho=r(opt,"layoutlmv3"),opt.forEach(t),lho=r(XS," \u2014 "),gN=n(XS,"A",{href:!0});var rpt=s(gN);iho=r(rpt,"LayoutLMv3Tokenizer"),rpt.forEach(t),dho=r(XS," or "),hN=n(XS,"A",{href:!0});var tpt=s(hN);cho=r(tpt,"LayoutLMv3TokenizerFast"),tpt.forEach(t),fho=r(XS," (LayoutLMv3 model)"),XS.forEach(t),mho=i(S),Fs=n(S,"LI",{});var zS=s(Fs);bde=n(zS,"STRONG",{});var apt=s(bde);gho=r(apt,"layoutxlm"),apt.forEach(t),hho=r(zS," \u2014 "),pN=n(zS,"A",{href:!0});var npt=s(pN);pho=r(npt,"LayoutXLMTokenizer"),npt.forEach(t),_ho=r(zS," or "),_N=n(zS,"A",{href:!0});var spt=s(_N);uho=r(spt,"LayoutXLMTokenizerFast"),spt.forEach(t),bho=r(zS," (LayoutXLM model)"),zS.forEach(t),vho=i(S),Ts=n(S,"LI",{});var WS=s(Ts);vde=n(WS,"STRONG",{});var lpt=s(vde);Fho=r(lpt,"led"),lpt.forEach(t),Tho=r(WS," \u2014 "),uN=n(WS,"A",{href:!0});var ipt=s(uN);Mho=r(ipt,"LEDTokenizer"),ipt.forEach(t),Eho=r(WS," or "),bN=n(WS,"A",{href:!0});var dpt=s(bN);Cho=r(dpt,"LEDTokenizerFast"),dpt.forEach(t),who=r(WS," (LED model)"),WS.forEach(t),Aho=i(S),Ms=n(S,"LI",{});var QS=s(Ms);Fde=n(QS,"STRONG",{});var cpt=s(Fde);Lho=r(cpt,"longformer"),cpt.forEach(t),yho=r(QS," \u2014 "),vN=n(QS,"A",{href:!0});var fpt=s(vN);xho=r(fpt,"LongformerTokenizer"),fpt.forEach(t),$ho=r(QS," or "),FN=n(QS,"A",{href:!0});var mpt=s(FN);kho=r(mpt,"LongformerTokenizerFast"),mpt.forEach(t),Sho=r(QS," (Longformer model)"),QS.forEach(t),Rho=i(S),Es=n(S,"LI",{});var US=s(Es);Tde=n(US,"STRONG",{});var gpt=s(Tde);Pho=r(gpt,"longt5"),gpt.forEach(t),Bho=r(US," \u2014 "),TN=n(US,"A",{href:!0});var hpt=s(TN);Iho=r(hpt,"T5Tokenizer"),hpt.forEach(t),Nho=r(US," or "),MN=n(US,"A",{href:!0});var ppt=s(MN);qho=r(ppt,"T5TokenizerFast"),ppt.forEach(t),jho=r(US," (LongT5 model)"),US.forEach(t),Dho=i(S),Lh=n(S,"LI",{});var zxe=s(Lh);Mde=n(zxe,"STRONG",{});var _pt=s(Mde);Gho=r(_pt,"luke"),_pt.forEach(t),Oho=r(zxe," \u2014 "),EN=n(zxe,"A",{href:!0});var upt=s(EN);Vho=r(upt,"LukeTokenizer"),upt.forEach(t),Xho=r(zxe," (LUKE model)"),zxe.forEach(t),zho=i(S),Cs=n(S,"LI",{});var HS=s(Cs);Ede=n(HS,"STRONG",{});var bpt=s(Ede);Who=r(bpt,"lxmert"),bpt.forEach(t),Qho=r(HS," \u2014 "),CN=n(HS,"A",{href:!0});var vpt=s(CN);Uho=r(vpt,"LxmertTokenizer"),vpt.forEach(t),Hho=r(HS," or "),wN=n(HS,"A",{href:!0});var Fpt=s(wN);Jho=r(Fpt,"LxmertTokenizerFast"),Fpt.forEach(t),Yho=r(HS," (LXMERT model)"),HS.forEach(t),Kho=i(S),yh=n(S,"LI",{});var Wxe=s(yh);Cde=n(Wxe,"STRONG",{});var Tpt=s(Cde);Zho=r(Tpt,"m2m_100"),Tpt.forEach(t),epo=r(Wxe," \u2014 "),AN=n(Wxe,"A",{href:!0});var Mpt=s(AN);opo=r(Mpt,"M2M100Tokenizer"),Mpt.forEach(t),rpo=r(Wxe," (M2M100 model)"),Wxe.forEach(t),tpo=i(S),xh=n(S,"LI",{});var Qxe=s(xh);wde=n(Qxe,"STRONG",{});var Ept=s(wde);apo=r(Ept,"marian"),Ept.forEach(t),npo=r(Qxe," \u2014 "),LN=n(Qxe,"A",{href:!0});var Cpt=s(LN);spo=r(Cpt,"MarianTokenizer"),Cpt.forEach(t),lpo=r(Qxe," (Marian model)"),Qxe.forEach(t),ipo=i(S),ws=n(S,"LI",{});var JS=s(ws);Ade=n(JS,"STRONG",{});var wpt=s(Ade);dpo=r(wpt,"mbart"),wpt.forEach(t),cpo=r(JS," \u2014 "),yN=n(JS,"A",{href:!0});var Apt=s(yN);fpo=r(Apt,"MBartTokenizer"),Apt.forEach(t),mpo=r(JS," or "),xN=n(JS,"A",{href:!0});var Lpt=s(xN);gpo=r(Lpt,"MBartTokenizerFast"),Lpt.forEach(t),hpo=r(JS," (mBART model)"),JS.forEach(t),ppo=i(S),As=n(S,"LI",{});var YS=s(As);Lde=n(YS,"STRONG",{});var ypt=s(Lde);_po=r(ypt,"mbart50"),ypt.forEach(t),upo=r(YS," \u2014 "),$N=n(YS,"A",{href:!0});var xpt=s($N);bpo=r(xpt,"MBart50Tokenizer"),xpt.forEach(t),vpo=r(YS," or "),kN=n(YS,"A",{href:!0});var $pt=s(kN);Fpo=r($pt,"MBart50TokenizerFast"),$pt.forEach(t),Tpo=r(YS," (mBART-50 model)"),YS.forEach(t),Mpo=i(S),Ls=n(S,"LI",{});var KS=s(Ls);yde=n(KS,"STRONG",{});var kpt=s(yde);Epo=r(kpt,"megatron-bert"),kpt.forEach(t),Cpo=r(KS," \u2014 "),SN=n(KS,"A",{href:!0});var Spt=s(SN);wpo=r(Spt,"BertTokenizer"),Spt.forEach(t),Apo=r(KS," or "),RN=n(KS,"A",{href:!0});var Rpt=s(RN);Lpo=r(Rpt,"BertTokenizerFast"),Rpt.forEach(t),ypo=r(KS," (Megatron-BERT model)"),KS.forEach(t),xpo=i(S),$h=n(S,"LI",{});var Uxe=s($h);xde=n(Uxe,"STRONG",{});var Ppt=s(xde);$po=r(Ppt,"mluke"),Ppt.forEach(t),kpo=r(Uxe," \u2014 "),PN=n(Uxe,"A",{href:!0});var Bpt=s(PN);Spo=r(Bpt,"MLukeTokenizer"),Bpt.forEach(t),Rpo=r(Uxe," (mLUKE model)"),Uxe.forEach(t),Ppo=i(S),ys=n(S,"LI",{});var ZS=s(ys);$de=n(ZS,"STRONG",{});var Ipt=s($de);Bpo=r(Ipt,"mobilebert"),Ipt.forEach(t),Ipo=r(ZS," \u2014 "),BN=n(ZS,"A",{href:!0});var Npt=s(BN);Npo=r(Npt,"MobileBertTokenizer"),Npt.forEach(t),qpo=r(ZS," or "),IN=n(ZS,"A",{href:!0});var qpt=s(IN);jpo=r(qpt,"MobileBertTokenizerFast"),qpt.forEach(t),Dpo=r(ZS," (MobileBERT model)"),ZS.forEach(t),Gpo=i(S),xs=n(S,"LI",{});var eR=s(xs);kde=n(eR,"STRONG",{});var jpt=s(kde);Opo=r(jpt,"mpnet"),jpt.forEach(t),Vpo=r(eR," \u2014 "),NN=n(eR,"A",{href:!0});var Dpt=s(NN);Xpo=r(Dpt,"MPNetTokenizer"),Dpt.forEach(t),zpo=r(eR," or "),qN=n(eR,"A",{href:!0});var Gpt=s(qN);Wpo=r(Gpt,"MPNetTokenizerFast"),Gpt.forEach(t),Qpo=r(eR," (MPNet model)"),eR.forEach(t),Upo=i(S),$s=n(S,"LI",{});var oR=s($s);Sde=n(oR,"STRONG",{});var Opt=s(Sde);Hpo=r(Opt,"mt5"),Opt.forEach(t),Jpo=r(oR," \u2014 "),jN=n(oR,"A",{href:!0});var Vpt=s(jN);Ypo=r(Vpt,"MT5Tokenizer"),Vpt.forEach(t),Kpo=r(oR," or "),DN=n(oR,"A",{href:!0});var Xpt=s(DN);Zpo=r(Xpt,"MT5TokenizerFast"),Xpt.forEach(t),e_o=r(oR," (MT5 model)"),oR.forEach(t),o_o=i(S),ks=n(S,"LI",{});var rR=s(ks);Rde=n(rR,"STRONG",{});var zpt=s(Rde);r_o=r(zpt,"mvp"),zpt.forEach(t),t_o=r(rR," \u2014 "),GN=n(rR,"A",{href:!0});var Wpt=s(GN);a_o=r(Wpt,"MvpTokenizer"),Wpt.forEach(t),n_o=r(rR," or "),ON=n(rR,"A",{href:!0});var Qpt=s(ON);s_o=r(Qpt,"MvpTokenizerFast"),Qpt.forEach(t),l_o=r(rR," (MVP model)"),rR.forEach(t),i_o=i(S),Ss=n(S,"LI",{});var tR=s(Ss);Pde=n(tR,"STRONG",{});var Upt=s(Pde);d_o=r(Upt,"nezha"),Upt.forEach(t),c_o=r(tR," \u2014 "),VN=n(tR,"A",{href:!0});var Hpt=s(VN);f_o=r(Hpt,"BertTokenizer"),Hpt.forEach(t),m_o=r(tR," or "),XN=n(tR,"A",{href:!0});var Jpt=s(XN);g_o=r(Jpt,"BertTokenizerFast"),Jpt.forEach(t),h_o=r(tR," (Nezha model)"),tR.forEach(t),p_o=i(S),Rs=n(S,"LI",{});var aR=s(Rs);Bde=n(aR,"STRONG",{});var Ypt=s(Bde);__o=r(Ypt,"nllb"),Ypt.forEach(t),u_o=r(aR," \u2014 "),zN=n(aR,"A",{href:!0});var Kpt=s(zN);b_o=r(Kpt,"NllbTokenizer"),Kpt.forEach(t),v_o=r(aR," or "),WN=n(aR,"A",{href:!0});var Zpt=s(WN);F_o=r(Zpt,"NllbTokenizerFast"),Zpt.forEach(t),T_o=r(aR," (NLLB model)"),aR.forEach(t),M_o=i(S),Ps=n(S,"LI",{});var nR=s(Ps);Ide=n(nR,"STRONG",{});var e_t=s(Ide);E_o=r(e_t,"nystromformer"),e_t.forEach(t),C_o=r(nR," \u2014 "),QN=n(nR,"A",{href:!0});var o_t=s(QN);w_o=r(o_t,"AlbertTokenizer"),o_t.forEach(t),A_o=r(nR," or "),UN=n(nR,"A",{href:!0});var r_t=s(UN);L_o=r(r_t,"AlbertTokenizerFast"),r_t.forEach(t),y_o=r(nR," (Nystr\xF6mformer model)"),nR.forEach(t),x_o=i(S),Bs=n(S,"LI",{});var sR=s(Bs);Nde=n(sR,"STRONG",{});var t_t=s(Nde);$_o=r(t_t,"openai-gpt"),t_t.forEach(t),k_o=r(sR," \u2014 "),HN=n(sR,"A",{href:!0});var a_t=s(HN);S_o=r(a_t,"OpenAIGPTTokenizer"),a_t.forEach(t),R_o=r(sR," or "),JN=n(sR,"A",{href:!0});var n_t=s(JN);P_o=r(n_t,"OpenAIGPTTokenizerFast"),n_t.forEach(t),B_o=r(sR," (OpenAI GPT model)"),sR.forEach(t),I_o=i(S),kh=n(S,"LI",{});var Hxe=s(kh);qde=n(Hxe,"STRONG",{});var s_t=s(qde);N_o=r(s_t,"opt"),s_t.forEach(t),q_o=r(Hxe," \u2014 "),YN=n(Hxe,"A",{href:!0});var l_t=s(YN);j_o=r(l_t,"GPT2Tokenizer"),l_t.forEach(t),D_o=r(Hxe," (OPT model)"),Hxe.forEach(t),G_o=i(S),Is=n(S,"LI",{});var lR=s(Is);jde=n(lR,"STRONG",{});var i_t=s(jde);O_o=r(i_t,"owlvit"),i_t.forEach(t),V_o=r(lR," \u2014 "),KN=n(lR,"A",{href:!0});var d_t=s(KN);X_o=r(d_t,"CLIPTokenizer"),d_t.forEach(t),z_o=r(lR," or "),ZN=n(lR,"A",{href:!0});var c_t=s(ZN);W_o=r(c_t,"CLIPTokenizerFast"),c_t.forEach(t),Q_o=r(lR," (OWL-ViT model)"),lR.forEach(t),U_o=i(S),Ns=n(S,"LI",{});var iR=s(Ns);Dde=n(iR,"STRONG",{});var f_t=s(Dde);H_o=r(f_t,"pegasus"),f_t.forEach(t),J_o=r(iR," \u2014 "),eq=n(iR,"A",{href:!0});var m_t=s(eq);Y_o=r(m_t,"PegasusTokenizer"),m_t.forEach(t),K_o=r(iR," or "),oq=n(iR,"A",{href:!0});var g_t=s(oq);Z_o=r(g_t,"PegasusTokenizerFast"),g_t.forEach(t),euo=r(iR," (Pegasus model)"),iR.forEach(t),ouo=i(S),Sh=n(S,"LI",{});var Jxe=s(Sh);Gde=n(Jxe,"STRONG",{});var h_t=s(Gde);ruo=r(h_t,"perceiver"),h_t.forEach(t),tuo=r(Jxe," \u2014 "),rq=n(Jxe,"A",{href:!0});var p_t=s(rq);auo=r(p_t,"PerceiverTokenizer"),p_t.forEach(t),nuo=r(Jxe," (Perceiver model)"),Jxe.forEach(t),suo=i(S),Rh=n(S,"LI",{});var Yxe=s(Rh);Ode=n(Yxe,"STRONG",{});var __t=s(Ode);luo=r(__t,"phobert"),__t.forEach(t),iuo=r(Yxe," \u2014 "),tq=n(Yxe,"A",{href:!0});var u_t=s(tq);duo=r(u_t,"PhobertTokenizer"),u_t.forEach(t),cuo=r(Yxe," (PhoBERT model)"),Yxe.forEach(t),fuo=i(S),Ph=n(S,"LI",{});var Kxe=s(Ph);Vde=n(Kxe,"STRONG",{});var b_t=s(Vde);muo=r(b_t,"plbart"),b_t.forEach(t),guo=r(Kxe," \u2014 "),aq=n(Kxe,"A",{href:!0});var v_t=s(aq);huo=r(v_t,"PLBartTokenizer"),v_t.forEach(t),puo=r(Kxe," (PLBart model)"),Kxe.forEach(t),_uo=i(S),Bh=n(S,"LI",{});var Zxe=s(Bh);Xde=n(Zxe,"STRONG",{});var F_t=s(Xde);uuo=r(F_t,"prophetnet"),F_t.forEach(t),buo=r(Zxe," \u2014 "),nq=n(Zxe,"A",{href:!0});var T_t=s(nq);vuo=r(T_t,"ProphetNetTokenizer"),T_t.forEach(t),Fuo=r(Zxe," (ProphetNet model)"),Zxe.forEach(t),Tuo=i(S),qs=n(S,"LI",{});var dR=s(qs);zde=n(dR,"STRONG",{});var M_t=s(zde);Muo=r(M_t,"qdqbert"),M_t.forEach(t),Euo=r(dR," \u2014 "),sq=n(dR,"A",{href:!0});var E_t=s(sq);Cuo=r(E_t,"BertTokenizer"),E_t.forEach(t),wuo=r(dR," or "),lq=n(dR,"A",{href:!0});var C_t=s(lq);Auo=r(C_t,"BertTokenizerFast"),C_t.forEach(t),Luo=r(dR," (QDQBert model)"),dR.forEach(t),yuo=i(S),Ih=n(S,"LI",{});var e$e=s(Ih);Wde=n(e$e,"STRONG",{});var w_t=s(Wde);xuo=r(w_t,"rag"),w_t.forEach(t),$uo=r(e$e," \u2014 "),iq=n(e$e,"A",{href:!0});var A_t=s(iq);kuo=r(A_t,"RagTokenizer"),A_t.forEach(t),Suo=r(e$e," (RAG model)"),e$e.forEach(t),Ruo=i(S),js=n(S,"LI",{});var cR=s(js);Qde=n(cR,"STRONG",{});var L_t=s(Qde);Puo=r(L_t,"realm"),L_t.forEach(t),Buo=r(cR," \u2014 "),dq=n(cR,"A",{href:!0});var y_t=s(dq);Iuo=r(y_t,"RealmTokenizer"),y_t.forEach(t),Nuo=r(cR," or "),cq=n(cR,"A",{href:!0});var x_t=s(cq);quo=r(x_t,"RealmTokenizerFast"),x_t.forEach(t),juo=r(cR," (REALM model)"),cR.forEach(t),Duo=i(S),Ds=n(S,"LI",{});var fR=s(Ds);Ude=n(fR,"STRONG",{});var $_t=s(Ude);Guo=r($_t,"reformer"),$_t.forEach(t),Ouo=r(fR," \u2014 "),fq=n(fR,"A",{href:!0});var k_t=s(fq);Vuo=r(k_t,"ReformerTokenizer"),k_t.forEach(t),Xuo=r(fR," or "),mq=n(fR,"A",{href:!0});var S_t=s(mq);zuo=r(S_t,"ReformerTokenizerFast"),S_t.forEach(t),Wuo=r(fR," (Reformer model)"),fR.forEach(t),Quo=i(S),Gs=n(S,"LI",{});var mR=s(Gs);Hde=n(mR,"STRONG",{});var R_t=s(Hde);Uuo=r(R_t,"rembert"),R_t.forEach(t),Huo=r(mR," \u2014 "),gq=n(mR,"A",{href:!0});var P_t=s(gq);Juo=r(P_t,"RemBertTokenizer"),P_t.forEach(t),Yuo=r(mR," or "),hq=n(mR,"A",{href:!0});var B_t=s(hq);Kuo=r(B_t,"RemBertTokenizerFast"),B_t.forEach(t),Zuo=r(mR," (RemBERT model)"),mR.forEach(t),e2o=i(S),Os=n(S,"LI",{});var gR=s(Os);Jde=n(gR,"STRONG",{});var I_t=s(Jde);o2o=r(I_t,"retribert"),I_t.forEach(t),r2o=r(gR," \u2014 "),pq=n(gR,"A",{href:!0});var N_t=s(pq);t2o=r(N_t,"RetriBertTokenizer"),N_t.forEach(t),a2o=r(gR," or "),_q=n(gR,"A",{href:!0});var q_t=s(_q);n2o=r(q_t,"RetriBertTokenizerFast"),q_t.forEach(t),s2o=r(gR," (RetriBERT model)"),gR.forEach(t),l2o=i(S),Vs=n(S,"LI",{});var hR=s(Vs);Yde=n(hR,"STRONG",{});var j_t=s(Yde);i2o=r(j_t,"roberta"),j_t.forEach(t),d2o=r(hR," \u2014 "),uq=n(hR,"A",{href:!0});var D_t=s(uq);c2o=r(D_t,"RobertaTokenizer"),D_t.forEach(t),f2o=r(hR," or "),bq=n(hR,"A",{href:!0});var G_t=s(bq);m2o=r(G_t,"RobertaTokenizerFast"),G_t.forEach(t),g2o=r(hR," (RoBERTa model)"),hR.forEach(t),h2o=i(S),Xs=n(S,"LI",{});var pR=s(Xs);Kde=n(pR,"STRONG",{});var O_t=s(Kde);p2o=r(O_t,"roformer"),O_t.forEach(t),_2o=r(pR," \u2014 "),vq=n(pR,"A",{href:!0});var V_t=s(vq);u2o=r(V_t,"RoFormerTokenizer"),V_t.forEach(t),b2o=r(pR," or "),Fq=n(pR,"A",{href:!0});var X_t=s(Fq);v2o=r(X_t,"RoFormerTokenizerFast"),X_t.forEach(t),F2o=r(pR," (RoFormer model)"),pR.forEach(t),T2o=i(S),Nh=n(S,"LI",{});var o$e=s(Nh);Zde=n(o$e,"STRONG",{});var z_t=s(Zde);M2o=r(z_t,"speech_to_text"),z_t.forEach(t),E2o=r(o$e," \u2014 "),Tq=n(o$e,"A",{href:!0});var W_t=s(Tq);C2o=r(W_t,"Speech2TextTokenizer"),W_t.forEach(t),w2o=r(o$e," (Speech2Text model)"),o$e.forEach(t),A2o=i(S),qh=n(S,"LI",{});var r$e=s(qh);ece=n(r$e,"STRONG",{});var Q_t=s(ece);L2o=r(Q_t,"speech_to_text_2"),Q_t.forEach(t),y2o=r(r$e," \u2014 "),Mq=n(r$e,"A",{href:!0});var U_t=s(Mq);x2o=r(U_t,"Speech2Text2Tokenizer"),U_t.forEach(t),$2o=r(r$e," (Speech2Text2 model)"),r$e.forEach(t),k2o=i(S),zs=n(S,"LI",{});var _R=s(zs);oce=n(_R,"STRONG",{});var H_t=s(oce);S2o=r(H_t,"splinter"),H_t.forEach(t),R2o=r(_R," \u2014 "),Eq=n(_R,"A",{href:!0});var J_t=s(Eq);P2o=r(J_t,"SplinterTokenizer"),J_t.forEach(t),B2o=r(_R," or "),Cq=n(_R,"A",{href:!0});var Y_t=s(Cq);I2o=r(Y_t,"SplinterTokenizerFast"),Y_t.forEach(t),N2o=r(_R," (Splinter model)"),_R.forEach(t),q2o=i(S),Ws=n(S,"LI",{});var uR=s(Ws);rce=n(uR,"STRONG",{});var K_t=s(rce);j2o=r(K_t,"squeezebert"),K_t.forEach(t),D2o=r(uR," \u2014 "),wq=n(uR,"A",{href:!0});var Z_t=s(wq);G2o=r(Z_t,"SqueezeBertTokenizer"),Z_t.forEach(t),O2o=r(uR," or "),Aq=n(uR,"A",{href:!0});var eut=s(Aq);V2o=r(eut,"SqueezeBertTokenizerFast"),eut.forEach(t),X2o=r(uR," (SqueezeBERT model)"),uR.forEach(t),z2o=i(S),Qs=n(S,"LI",{});var bR=s(Qs);tce=n(bR,"STRONG",{});var out=s(tce);W2o=r(out,"t5"),out.forEach(t),Q2o=r(bR," \u2014 "),Lq=n(bR,"A",{href:!0});var rut=s(Lq);U2o=r(rut,"T5Tokenizer"),rut.forEach(t),H2o=r(bR," or "),yq=n(bR,"A",{href:!0});var tut=s(yq);J2o=r(tut,"T5TokenizerFast"),tut.forEach(t),Y2o=r(bR," (T5 model)"),bR.forEach(t),K2o=i(S),jh=n(S,"LI",{});var t$e=s(jh);ace=n(t$e,"STRONG",{});var aut=s(ace);Z2o=r(aut,"tapas"),aut.forEach(t),e1o=r(t$e," \u2014 "),xq=n(t$e,"A",{href:!0});var nut=s(xq);o1o=r(nut,"TapasTokenizer"),nut.forEach(t),r1o=r(t$e," (TAPAS model)"),t$e.forEach(t),t1o=i(S),Dh=n(S,"LI",{});var a$e=s(Dh);nce=n(a$e,"STRONG",{});var sut=s(nce);a1o=r(sut,"tapex"),sut.forEach(t),n1o=r(a$e," \u2014 "),$q=n(a$e,"A",{href:!0});var lut=s($q);s1o=r(lut,"TapexTokenizer"),lut.forEach(t),l1o=r(a$e," (TAPEX model)"),a$e.forEach(t),i1o=i(S),Gh=n(S,"LI",{});var n$e=s(Gh);sce=n(n$e,"STRONG",{});var iut=s(sce);d1o=r(iut,"transfo-xl"),iut.forEach(t),c1o=r(n$e," \u2014 "),kq=n(n$e,"A",{href:!0});var dut=s(kq);f1o=r(dut,"TransfoXLTokenizer"),dut.forEach(t),m1o=r(n$e," (Transformer-XL model)"),n$e.forEach(t),g1o=i(S),Us=n(S,"LI",{});var vR=s(Us);lce=n(vR,"STRONG",{});var cut=s(lce);h1o=r(cut,"vilt"),cut.forEach(t),p1o=r(vR," \u2014 "),Sq=n(vR,"A",{href:!0});var fut=s(Sq);_1o=r(fut,"BertTokenizer"),fut.forEach(t),u1o=r(vR," or "),Rq=n(vR,"A",{href:!0});var mut=s(Rq);b1o=r(mut,"BertTokenizerFast"),mut.forEach(t),v1o=r(vR," (ViLT model)"),vR.forEach(t),F1o=i(S),Hs=n(S,"LI",{});var FR=s(Hs);ice=n(FR,"STRONG",{});var gut=s(ice);T1o=r(gut,"visual_bert"),gut.forEach(t),M1o=r(FR," \u2014 "),Pq=n(FR,"A",{href:!0});var hut=s(Pq);E1o=r(hut,"BertTokenizer"),hut.forEach(t),C1o=r(FR," or "),Bq=n(FR,"A",{href:!0});var put=s(Bq);w1o=r(put,"BertTokenizerFast"),put.forEach(t),A1o=r(FR," (VisualBERT model)"),FR.forEach(t),L1o=i(S),Oh=n(S,"LI",{});var s$e=s(Oh);dce=n(s$e,"STRONG",{});var _ut=s(dce);y1o=r(_ut,"wav2vec2"),_ut.forEach(t),x1o=r(s$e," \u2014 "),Iq=n(s$e,"A",{href:!0});var uut=s(Iq);$1o=r(uut,"Wav2Vec2CTCTokenizer"),uut.forEach(t),k1o=r(s$e," (Wav2Vec2 model)"),s$e.forEach(t),S1o=i(S),Vh=n(S,"LI",{});var l$e=s(Vh);cce=n(l$e,"STRONG",{});var but=s(cce);R1o=r(but,"wav2vec2-conformer"),but.forEach(t),P1o=r(l$e," \u2014 "),Nq=n(l$e,"A",{href:!0});var vut=s(Nq);B1o=r(vut,"Wav2Vec2CTCTokenizer"),vut.forEach(t),I1o=r(l$e," (Wav2Vec2-Conformer model)"),l$e.forEach(t),N1o=i(S),Xh=n(S,"LI",{});var i$e=s(Xh);fce=n(i$e,"STRONG",{});var Fut=s(fce);q1o=r(Fut,"wav2vec2_phoneme"),Fut.forEach(t),j1o=r(i$e," \u2014 "),qq=n(i$e,"A",{href:!0});var Tut=s(qq);D1o=r(Tut,"Wav2Vec2PhonemeCTCTokenizer"),Tut.forEach(t),G1o=r(i$e," (Wav2Vec2Phoneme model)"),i$e.forEach(t),O1o=i(S),Js=n(S,"LI",{});var TR=s(Js);mce=n(TR,"STRONG",{});var Mut=s(mce);V1o=r(Mut,"xglm"),Mut.forEach(t),X1o=r(TR," \u2014 "),jq=n(TR,"A",{href:!0});var Eut=s(jq);z1o=r(Eut,"XGLMTokenizer"),Eut.forEach(t),W1o=r(TR," or "),Dq=n(TR,"A",{href:!0});var Cut=s(Dq);Q1o=r(Cut,"XGLMTokenizerFast"),Cut.forEach(t),U1o=r(TR," (XGLM model)"),TR.forEach(t),H1o=i(S),zh=n(S,"LI",{});var d$e=s(zh);gce=n(d$e,"STRONG",{});var wut=s(gce);J1o=r(wut,"xlm"),wut.forEach(t),Y1o=r(d$e," \u2014 "),Gq=n(d$e,"A",{href:!0});var Aut=s(Gq);K1o=r(Aut,"XLMTokenizer"),Aut.forEach(t),Z1o=r(d$e," (XLM model)"),d$e.forEach(t),e4o=i(S),Wh=n(S,"LI",{});var c$e=s(Wh);hce=n(c$e,"STRONG",{});var Lut=s(hce);o4o=r(Lut,"xlm-prophetnet"),Lut.forEach(t),r4o=r(c$e," \u2014 "),Oq=n(c$e,"A",{href:!0});var yut=s(Oq);t4o=r(yut,"XLMProphetNetTokenizer"),yut.forEach(t),a4o=r(c$e," (XLM-ProphetNet model)"),c$e.forEach(t),n4o=i(S),Ys=n(S,"LI",{});var MR=s(Ys);pce=n(MR,"STRONG",{});var xut=s(pce);s4o=r(xut,"xlm-roberta"),xut.forEach(t),l4o=r(MR," \u2014 "),Vq=n(MR,"A",{href:!0});var $ut=s(Vq);i4o=r($ut,"XLMRobertaTokenizer"),$ut.forEach(t),d4o=r(MR," or "),Xq=n(MR,"A",{href:!0});var kut=s(Xq);c4o=r(kut,"XLMRobertaTokenizerFast"),kut.forEach(t),f4o=r(MR," (XLM-RoBERTa model)"),MR.forEach(t),m4o=i(S),Ks=n(S,"LI",{});var ER=s(Ks);_ce=n(ER,"STRONG",{});var Sut=s(_ce);g4o=r(Sut,"xlm-roberta-xl"),Sut.forEach(t),h4o=r(ER," \u2014 "),zq=n(ER,"A",{href:!0});var Rut=s(zq);p4o=r(Rut,"RobertaTokenizer"),Rut.forEach(t),_4o=r(ER," or "),Wq=n(ER,"A",{href:!0});var Put=s(Wq);u4o=r(Put,"RobertaTokenizerFast"),Put.forEach(t),b4o=r(ER," (XLM-RoBERTa-XL model)"),ER.forEach(t),v4o=i(S),Zs=n(S,"LI",{});var CR=s(Zs);uce=n(CR,"STRONG",{});var But=s(uce);F4o=r(But,"xlnet"),But.forEach(t),T4o=r(CR," \u2014 "),Qq=n(CR,"A",{href:!0});var Iut=s(Qq);M4o=r(Iut,"XLNetTokenizer"),Iut.forEach(t),E4o=r(CR," or "),Uq=n(CR,"A",{href:!0});var Nut=s(Uq);C4o=r(Nut,"XLNetTokenizerFast"),Nut.forEach(t),w4o=r(CR," (XLNet model)"),CR.forEach(t),A4o=i(S),el=n(S,"LI",{});var wR=s(el);bce=n(wR,"STRONG",{});var qut=s(bce);L4o=r(qut,"yoso"),qut.forEach(t),y4o=r(wR," \u2014 "),Hq=n(wR,"A",{href:!0});var jut=s(Hq);x4o=r(jut,"AlbertTokenizer"),jut.forEach(t),$4o=r(wR," or "),Jq=n(wR,"A",{href:!0});var Dut=s(Jq);k4o=r(Dut,"AlbertTokenizerFast"),Dut.forEach(t),S4o=r(wR," (YOSO model)"),wR.forEach(t),S.forEach(t),R4o=i(ll),T(Qh.$$.fragment,ll),ll.forEach(t),P4o=i(sl),Uh=n(sl,"DIV",{class:!0});var YUe=s(Uh);T(sy.$$.fragment,YUe),B4o=i(YUe),vce=n(YUe,"P",{});var Gut=s(vce);I4o=r(Gut,"Register a new tokenizer in this mapping."),Gut.forEach(t),YUe.forEach(t),sl.forEach(t),UWe=i(f),Qi=n(f,"H2",{class:!0});var KUe=s(Qi);Hh=n(KUe,"A",{id:!0,class:!0,href:!0});var Out=s(Hh);Fce=n(Out,"SPAN",{});var Vut=s(Fce);T(ly.$$.fragment,Vut),Vut.forEach(t),Out.forEach(t),N4o=i(KUe),Tce=n(KUe,"SPAN",{});var Xut=s(Tce);q4o=r(Xut,"AutoFeatureExtractor"),Xut.forEach(t),KUe.forEach(t),HWe=i(f),$o=n(f,"DIV",{class:!0});var il=s($o);T(iy.$$.fragment,il),j4o=i(il),dy=n(il,"P",{});var ZUe=s(dy);D4o=r(ZUe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),Yq=n(ZUe,"A",{href:!0});var zut=s(Yq);G4o=r(zut,"AutoFeatureExtractor.from_pretrained()"),zut.forEach(t),O4o=r(ZUe," class method."),ZUe.forEach(t),V4o=i(il),cy=n(il,"P",{});var eHe=s(cy);X4o=r(eHe,"This class cannot be instantiated directly using "),Mce=n(eHe,"CODE",{});var Wut=s(Mce);z4o=r(Wut,"__init__()"),Wut.forEach(t),W4o=r(eHe," (throws an error)."),eHe.forEach(t),Q4o=i(il),He=n(il,"DIV",{class:!0});var ia=s(He);T(fy.$$.fragment,ia),U4o=i(ia),Ece=n(ia,"P",{});var Qut=s(Ece);H4o=r(Qut,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Qut.forEach(t),J4o=i(ia),ja=n(ia,"P",{});var QA=s(ja);Y4o=r(QA,"The feature extractor class to instantiate is selected based on the "),Cce=n(QA,"CODE",{});var Uut=s(Cce);K4o=r(Uut,"model_type"),Uut.forEach(t),Z4o=r(QA,` property of the config object
(either passed as an argument or loaded from `),wce=n(QA,"CODE",{});var Hut=s(wce);ebo=r(Hut,"pretrained_model_name_or_path"),Hut.forEach(t),obo=r(QA,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Ace=n(QA,"CODE",{});var Jut=s(Ace);rbo=r(Jut,"pretrained_model_name_or_path"),Jut.forEach(t),tbo=r(QA,":"),QA.forEach(t),abo=i(ia),Q=n(ia,"UL",{});var J=s(Q);Jh=n(J,"LI",{});var f$e=s(Jh);Lce=n(f$e,"STRONG",{});var Yut=s(Lce);nbo=r(Yut,"beit"),Yut.forEach(t),sbo=r(f$e," \u2014 "),Kq=n(f$e,"A",{href:!0});var Kut=s(Kq);lbo=r(Kut,"BeitFeatureExtractor"),Kut.forEach(t),ibo=r(f$e," (BEiT model)"),f$e.forEach(t),dbo=i(J),Yh=n(J,"LI",{});var m$e=s(Yh);yce=n(m$e,"STRONG",{});var Zut=s(yce);cbo=r(Zut,"clip"),Zut.forEach(t),fbo=r(m$e," \u2014 "),Zq=n(m$e,"A",{href:!0});var e2t=s(Zq);mbo=r(e2t,"CLIPFeatureExtractor"),e2t.forEach(t),gbo=r(m$e," (CLIP model)"),m$e.forEach(t),hbo=i(J),Kh=n(J,"LI",{});var g$e=s(Kh);xce=n(g$e,"STRONG",{});var o2t=s(xce);pbo=r(o2t,"convnext"),o2t.forEach(t),_bo=r(g$e," \u2014 "),ej=n(g$e,"A",{href:!0});var r2t=s(ej);ubo=r(r2t,"ConvNextFeatureExtractor"),r2t.forEach(t),bbo=r(g$e," (ConvNeXT model)"),g$e.forEach(t),vbo=i(J),Zh=n(J,"LI",{});var h$e=s(Zh);$ce=n(h$e,"STRONG",{});var t2t=s($ce);Fbo=r(t2t,"cvt"),t2t.forEach(t),Tbo=r(h$e," \u2014 "),oj=n(h$e,"A",{href:!0});var a2t=s(oj);Mbo=r(a2t,"ConvNextFeatureExtractor"),a2t.forEach(t),Ebo=r(h$e," (CvT model)"),h$e.forEach(t),Cbo=i(J),ep=n(J,"LI",{});var p$e=s(ep);kce=n(p$e,"STRONG",{});var n2t=s(kce);wbo=r(n2t,"data2vec-audio"),n2t.forEach(t),Abo=r(p$e," \u2014 "),rj=n(p$e,"A",{href:!0});var s2t=s(rj);Lbo=r(s2t,"Wav2Vec2FeatureExtractor"),s2t.forEach(t),ybo=r(p$e," (Data2VecAudio model)"),p$e.forEach(t),xbo=i(J),op=n(J,"LI",{});var _$e=s(op);Sce=n(_$e,"STRONG",{});var l2t=s(Sce);$bo=r(l2t,"data2vec-vision"),l2t.forEach(t),kbo=r(_$e," \u2014 "),tj=n(_$e,"A",{href:!0});var i2t=s(tj);Sbo=r(i2t,"BeitFeatureExtractor"),i2t.forEach(t),Rbo=r(_$e," (Data2VecVision model)"),_$e.forEach(t),Pbo=i(J),rp=n(J,"LI",{});var u$e=s(rp);Rce=n(u$e,"STRONG",{});var d2t=s(Rce);Bbo=r(d2t,"deit"),d2t.forEach(t),Ibo=r(u$e," \u2014 "),aj=n(u$e,"A",{href:!0});var c2t=s(aj);Nbo=r(c2t,"DeiTFeatureExtractor"),c2t.forEach(t),qbo=r(u$e," (DeiT model)"),u$e.forEach(t),jbo=i(J),tp=n(J,"LI",{});var b$e=s(tp);Pce=n(b$e,"STRONG",{});var f2t=s(Pce);Dbo=r(f2t,"detr"),f2t.forEach(t),Gbo=r(b$e," \u2014 "),nj=n(b$e,"A",{href:!0});var m2t=s(nj);Obo=r(m2t,"DetrFeatureExtractor"),m2t.forEach(t),Vbo=r(b$e," (DETR model)"),b$e.forEach(t),Xbo=i(J),ap=n(J,"LI",{});var v$e=s(ap);Bce=n(v$e,"STRONG",{});var g2t=s(Bce);zbo=r(g2t,"dpt"),g2t.forEach(t),Wbo=r(v$e," \u2014 "),sj=n(v$e,"A",{href:!0});var h2t=s(sj);Qbo=r(h2t,"DPTFeatureExtractor"),h2t.forEach(t),Ubo=r(v$e," (DPT model)"),v$e.forEach(t),Hbo=i(J),np=n(J,"LI",{});var F$e=s(np);Ice=n(F$e,"STRONG",{});var p2t=s(Ice);Jbo=r(p2t,"flava"),p2t.forEach(t),Ybo=r(F$e," \u2014 "),lj=n(F$e,"A",{href:!0});var _2t=s(lj);Kbo=r(_2t,"FlavaFeatureExtractor"),_2t.forEach(t),Zbo=r(F$e," (FLAVA model)"),F$e.forEach(t),evo=i(J),sp=n(J,"LI",{});var T$e=s(sp);Nce=n(T$e,"STRONG",{});var u2t=s(Nce);ovo=r(u2t,"glpn"),u2t.forEach(t),rvo=r(T$e," \u2014 "),ij=n(T$e,"A",{href:!0});var b2t=s(ij);tvo=r(b2t,"GLPNFeatureExtractor"),b2t.forEach(t),avo=r(T$e," (GLPN model)"),T$e.forEach(t),nvo=i(J),lp=n(J,"LI",{});var M$e=s(lp);qce=n(M$e,"STRONG",{});var v2t=s(qce);svo=r(v2t,"groupvit"),v2t.forEach(t),lvo=r(M$e," \u2014 "),dj=n(M$e,"A",{href:!0});var F2t=s(dj);ivo=r(F2t,"CLIPFeatureExtractor"),F2t.forEach(t),dvo=r(M$e," (GroupViT model)"),M$e.forEach(t),cvo=i(J),ip=n(J,"LI",{});var E$e=s(ip);jce=n(E$e,"STRONG",{});var T2t=s(jce);fvo=r(T2t,"hubert"),T2t.forEach(t),mvo=r(E$e," \u2014 "),cj=n(E$e,"A",{href:!0});var M2t=s(cj);gvo=r(M2t,"Wav2Vec2FeatureExtractor"),M2t.forEach(t),hvo=r(E$e," (Hubert model)"),E$e.forEach(t),pvo=i(J),dp=n(J,"LI",{});var C$e=s(dp);Dce=n(C$e,"STRONG",{});var E2t=s(Dce);_vo=r(E2t,"imagegpt"),E2t.forEach(t),uvo=r(C$e," \u2014 "),fj=n(C$e,"A",{href:!0});var C2t=s(fj);bvo=r(C2t,"ImageGPTFeatureExtractor"),C2t.forEach(t),vvo=r(C$e," (ImageGPT model)"),C$e.forEach(t),Fvo=i(J),cp=n(J,"LI",{});var w$e=s(cp);Gce=n(w$e,"STRONG",{});var w2t=s(Gce);Tvo=r(w2t,"layoutlmv2"),w2t.forEach(t),Mvo=r(w$e," \u2014 "),mj=n(w$e,"A",{href:!0});var A2t=s(mj);Evo=r(A2t,"LayoutLMv2FeatureExtractor"),A2t.forEach(t),Cvo=r(w$e," (LayoutLMv2 model)"),w$e.forEach(t),wvo=i(J),fp=n(J,"LI",{});var A$e=s(fp);Oce=n(A$e,"STRONG",{});var L2t=s(Oce);Avo=r(L2t,"layoutlmv3"),L2t.forEach(t),Lvo=r(A$e," \u2014 "),gj=n(A$e,"A",{href:!0});var y2t=s(gj);yvo=r(y2t,"LayoutLMv3FeatureExtractor"),y2t.forEach(t),xvo=r(A$e," (LayoutLMv3 model)"),A$e.forEach(t),$vo=i(J),mp=n(J,"LI",{});var L$e=s(mp);Vce=n(L$e,"STRONG",{});var x2t=s(Vce);kvo=r(x2t,"levit"),x2t.forEach(t),Svo=r(L$e," \u2014 "),hj=n(L$e,"A",{href:!0});var $2t=s(hj);Rvo=r($2t,"LevitFeatureExtractor"),$2t.forEach(t),Pvo=r(L$e," (LeViT model)"),L$e.forEach(t),Bvo=i(J),gp=n(J,"LI",{});var y$e=s(gp);Xce=n(y$e,"STRONG",{});var k2t=s(Xce);Ivo=r(k2t,"luke"),k2t.forEach(t),Nvo=r(y$e," \u2014 "),zce=n(y$e,"CODE",{});var S2t=s(zce);qvo=r(S2t,"LukeFeatureExtractor"),S2t.forEach(t),jvo=r(y$e," (LUKE model)"),y$e.forEach(t),Dvo=i(J),hp=n(J,"LI",{});var x$e=s(hp);Wce=n(x$e,"STRONG",{});var R2t=s(Wce);Gvo=r(R2t,"maskformer"),R2t.forEach(t),Ovo=r(x$e," \u2014 "),pj=n(x$e,"A",{href:!0});var P2t=s(pj);Vvo=r(P2t,"MaskFormerFeatureExtractor"),P2t.forEach(t),Xvo=r(x$e," (MaskFormer model)"),x$e.forEach(t),zvo=i(J),pp=n(J,"LI",{});var $$e=s(pp);Qce=n($$e,"STRONG",{});var B2t=s(Qce);Wvo=r(B2t,"mctct"),B2t.forEach(t),Qvo=r($$e," \u2014 "),_j=n($$e,"A",{href:!0});var I2t=s(_j);Uvo=r(I2t,"MCTCTFeatureExtractor"),I2t.forEach(t),Hvo=r($$e," (M-CTC-T model)"),$$e.forEach(t),Jvo=i(J),_p=n(J,"LI",{});var k$e=s(_p);Uce=n(k$e,"STRONG",{});var N2t=s(Uce);Yvo=r(N2t,"mobilevit"),N2t.forEach(t),Kvo=r(k$e," \u2014 "),uj=n(k$e,"A",{href:!0});var q2t=s(uj);Zvo=r(q2t,"MobileViTFeatureExtractor"),q2t.forEach(t),e5o=r(k$e," (MobileViT model)"),k$e.forEach(t),o5o=i(J),up=n(J,"LI",{});var S$e=s(up);Hce=n(S$e,"STRONG",{});var j2t=s(Hce);r5o=r(j2t,"owlvit"),j2t.forEach(t),t5o=r(S$e," \u2014 "),bj=n(S$e,"A",{href:!0});var D2t=s(bj);a5o=r(D2t,"OwlViTFeatureExtractor"),D2t.forEach(t),n5o=r(S$e," (OWL-ViT model)"),S$e.forEach(t),s5o=i(J),bp=n(J,"LI",{});var R$e=s(bp);Jce=n(R$e,"STRONG",{});var G2t=s(Jce);l5o=r(G2t,"perceiver"),G2t.forEach(t),i5o=r(R$e," \u2014 "),vj=n(R$e,"A",{href:!0});var O2t=s(vj);d5o=r(O2t,"PerceiverFeatureExtractor"),O2t.forEach(t),c5o=r(R$e," (Perceiver model)"),R$e.forEach(t),f5o=i(J),vp=n(J,"LI",{});var P$e=s(vp);Yce=n(P$e,"STRONG",{});var V2t=s(Yce);m5o=r(V2t,"poolformer"),V2t.forEach(t),g5o=r(P$e," \u2014 "),Fj=n(P$e,"A",{href:!0});var X2t=s(Fj);h5o=r(X2t,"PoolFormerFeatureExtractor"),X2t.forEach(t),p5o=r(P$e," (PoolFormer model)"),P$e.forEach(t),_5o=i(J),Fp=n(J,"LI",{});var B$e=s(Fp);Kce=n(B$e,"STRONG",{});var z2t=s(Kce);u5o=r(z2t,"regnet"),z2t.forEach(t),b5o=r(B$e," \u2014 "),Tj=n(B$e,"A",{href:!0});var W2t=s(Tj);v5o=r(W2t,"ConvNextFeatureExtractor"),W2t.forEach(t),F5o=r(B$e," (RegNet model)"),B$e.forEach(t),T5o=i(J),Tp=n(J,"LI",{});var I$e=s(Tp);Zce=n(I$e,"STRONG",{});var Q2t=s(Zce);M5o=r(Q2t,"resnet"),Q2t.forEach(t),E5o=r(I$e," \u2014 "),Mj=n(I$e,"A",{href:!0});var U2t=s(Mj);C5o=r(U2t,"ConvNextFeatureExtractor"),U2t.forEach(t),w5o=r(I$e," (ResNet model)"),I$e.forEach(t),A5o=i(J),Mp=n(J,"LI",{});var N$e=s(Mp);efe=n(N$e,"STRONG",{});var H2t=s(efe);L5o=r(H2t,"segformer"),H2t.forEach(t),y5o=r(N$e," \u2014 "),Ej=n(N$e,"A",{href:!0});var J2t=s(Ej);x5o=r(J2t,"SegformerFeatureExtractor"),J2t.forEach(t),$5o=r(N$e," (SegFormer model)"),N$e.forEach(t),k5o=i(J),Ep=n(J,"LI",{});var q$e=s(Ep);ofe=n(q$e,"STRONG",{});var Y2t=s(ofe);S5o=r(Y2t,"speech_to_text"),Y2t.forEach(t),R5o=r(q$e," \u2014 "),Cj=n(q$e,"A",{href:!0});var K2t=s(Cj);P5o=r(K2t,"Speech2TextFeatureExtractor"),K2t.forEach(t),B5o=r(q$e," (Speech2Text model)"),q$e.forEach(t),I5o=i(J),Cp=n(J,"LI",{});var j$e=s(Cp);rfe=n(j$e,"STRONG",{});var Z2t=s(rfe);N5o=r(Z2t,"swin"),Z2t.forEach(t),q5o=r(j$e," \u2014 "),wj=n(j$e,"A",{href:!0});var e1t=s(wj);j5o=r(e1t,"ViTFeatureExtractor"),e1t.forEach(t),D5o=r(j$e," (Swin Transformer model)"),j$e.forEach(t),G5o=i(J),wp=n(J,"LI",{});var D$e=s(wp);tfe=n(D$e,"STRONG",{});var o1t=s(tfe);O5o=r(o1t,"swinv2"),o1t.forEach(t),V5o=r(D$e," \u2014 "),Aj=n(D$e,"A",{href:!0});var r1t=s(Aj);X5o=r(r1t,"ViTFeatureExtractor"),r1t.forEach(t),z5o=r(D$e," (Swin Transformer V2 model)"),D$e.forEach(t),W5o=i(J),Ap=n(J,"LI",{});var G$e=s(Ap);afe=n(G$e,"STRONG",{});var t1t=s(afe);Q5o=r(t1t,"van"),t1t.forEach(t),U5o=r(G$e," \u2014 "),Lj=n(G$e,"A",{href:!0});var a1t=s(Lj);H5o=r(a1t,"ConvNextFeatureExtractor"),a1t.forEach(t),J5o=r(G$e," (VAN model)"),G$e.forEach(t),Y5o=i(J),Lp=n(J,"LI",{});var O$e=s(Lp);nfe=n(O$e,"STRONG",{});var n1t=s(nfe);K5o=r(n1t,"videomae"),n1t.forEach(t),Z5o=r(O$e," \u2014 "),yj=n(O$e,"A",{href:!0});var s1t=s(yj);eFo=r(s1t,"ViTFeatureExtractor"),s1t.forEach(t),oFo=r(O$e," (VideoMAE model)"),O$e.forEach(t),rFo=i(J),yp=n(J,"LI",{});var V$e=s(yp);sfe=n(V$e,"STRONG",{});var l1t=s(sfe);tFo=r(l1t,"vilt"),l1t.forEach(t),aFo=r(V$e," \u2014 "),xj=n(V$e,"A",{href:!0});var i1t=s(xj);nFo=r(i1t,"ViltFeatureExtractor"),i1t.forEach(t),sFo=r(V$e," (ViLT model)"),V$e.forEach(t),lFo=i(J),xp=n(J,"LI",{});var X$e=s(xp);lfe=n(X$e,"STRONG",{});var d1t=s(lfe);iFo=r(d1t,"vit"),d1t.forEach(t),dFo=r(X$e," \u2014 "),$j=n(X$e,"A",{href:!0});var c1t=s($j);cFo=r(c1t,"ViTFeatureExtractor"),c1t.forEach(t),fFo=r(X$e," (ViT model)"),X$e.forEach(t),mFo=i(J),$p=n(J,"LI",{});var z$e=s($p);ife=n(z$e,"STRONG",{});var f1t=s(ife);gFo=r(f1t,"vit_mae"),f1t.forEach(t),hFo=r(z$e," \u2014 "),kj=n(z$e,"A",{href:!0});var m1t=s(kj);pFo=r(m1t,"ViTFeatureExtractor"),m1t.forEach(t),_Fo=r(z$e," (ViTMAE model)"),z$e.forEach(t),uFo=i(J),kp=n(J,"LI",{});var W$e=s(kp);dfe=n(W$e,"STRONG",{});var g1t=s(dfe);bFo=r(g1t,"wav2vec2"),g1t.forEach(t),vFo=r(W$e," \u2014 "),Sj=n(W$e,"A",{href:!0});var h1t=s(Sj);FFo=r(h1t,"Wav2Vec2FeatureExtractor"),h1t.forEach(t),TFo=r(W$e," (Wav2Vec2 model)"),W$e.forEach(t),MFo=i(J),Sp=n(J,"LI",{});var Q$e=s(Sp);cfe=n(Q$e,"STRONG",{});var p1t=s(cfe);EFo=r(p1t,"wav2vec2-conformer"),p1t.forEach(t),CFo=r(Q$e," \u2014 "),Rj=n(Q$e,"A",{href:!0});var _1t=s(Rj);wFo=r(_1t,"Wav2Vec2FeatureExtractor"),_1t.forEach(t),AFo=r(Q$e," (Wav2Vec2-Conformer model)"),Q$e.forEach(t),LFo=i(J),Rp=n(J,"LI",{});var U$e=s(Rp);ffe=n(U$e,"STRONG",{});var u1t=s(ffe);yFo=r(u1t,"yolos"),u1t.forEach(t),xFo=r(U$e," \u2014 "),Pj=n(U$e,"A",{href:!0});var b1t=s(Pj);$Fo=r(b1t,"YolosFeatureExtractor"),b1t.forEach(t),kFo=r(U$e," (YOLOS model)"),U$e.forEach(t),J.forEach(t),SFo=i(ia),T(Pp.$$.fragment,ia),RFo=i(ia),T(Bp.$$.fragment,ia),ia.forEach(t),PFo=i(il),Ip=n(il,"DIV",{class:!0});var oHe=s(Ip);T(my.$$.fragment,oHe),BFo=i(oHe),mfe=n(oHe,"P",{});var v1t=s(mfe);IFo=r(v1t,"Register a new feature extractor for this class."),v1t.forEach(t),oHe.forEach(t),il.forEach(t),JWe=i(f),Ui=n(f,"H2",{class:!0});var rHe=s(Ui);Np=n(rHe,"A",{id:!0,class:!0,href:!0});var F1t=s(Np);gfe=n(F1t,"SPAN",{});var T1t=s(gfe);T(gy.$$.fragment,T1t),T1t.forEach(t),F1t.forEach(t),NFo=i(rHe),hfe=n(rHe,"SPAN",{});var M1t=s(hfe);qFo=r(M1t,"AutoProcessor"),M1t.forEach(t),rHe.forEach(t),YWe=i(f),ko=n(f,"DIV",{class:!0});var dl=s(ko);T(hy.$$.fragment,dl),jFo=i(dl),py=n(dl,"P",{});var tHe=s(py);DFo=r(tHe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Bj=n(tHe,"A",{href:!0});var E1t=s(Bj);GFo=r(E1t,"AutoProcessor.from_pretrained()"),E1t.forEach(t),OFo=r(tHe," class method."),tHe.forEach(t),VFo=i(dl),_y=n(dl,"P",{});var aHe=s(_y);XFo=r(aHe,"This class cannot be instantiated directly using "),pfe=n(aHe,"CODE",{});var C1t=s(pfe);zFo=r(C1t,"__init__()"),C1t.forEach(t),WFo=r(aHe," (throws an error)."),aHe.forEach(t),QFo=i(dl),Je=n(dl,"DIV",{class:!0});var da=s(Je);T(uy.$$.fragment,da),UFo=i(da),_fe=n(da,"P",{});var w1t=s(_fe);HFo=r(w1t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),w1t.forEach(t),JFo=i(da),Hi=n(da,"P",{});var aae=s(Hi);YFo=r(aae,"The processor class to instantiate is selected based on the "),ufe=n(aae,"CODE",{});var A1t=s(ufe);KFo=r(A1t,"model_type"),A1t.forEach(t),ZFo=r(aae,` property of the config object (either
passed as an argument or loaded from `),bfe=n(aae,"CODE",{});var L1t=s(bfe);eTo=r(L1t,"pretrained_model_name_or_path"),L1t.forEach(t),oTo=r(aae," if possible):"),aae.forEach(t),rTo=i(da),fe=n(da,"UL",{});var _e=s(fe);qp=n(_e,"LI",{});var H$e=s(qp);vfe=n(H$e,"STRONG",{});var y1t=s(vfe);tTo=r(y1t,"clip"),y1t.forEach(t),aTo=r(H$e," \u2014 "),Ij=n(H$e,"A",{href:!0});var x1t=s(Ij);nTo=r(x1t,"CLIPProcessor"),x1t.forEach(t),sTo=r(H$e," (CLIP model)"),H$e.forEach(t),lTo=i(_e),jp=n(_e,"LI",{});var J$e=s(jp);Ffe=n(J$e,"STRONG",{});var $1t=s(Ffe);iTo=r($1t,"flava"),$1t.forEach(t),dTo=r(J$e," \u2014 "),Nj=n(J$e,"A",{href:!0});var k1t=s(Nj);cTo=r(k1t,"FlavaProcessor"),k1t.forEach(t),fTo=r(J$e," (FLAVA model)"),J$e.forEach(t),mTo=i(_e),Dp=n(_e,"LI",{});var Y$e=s(Dp);Tfe=n(Y$e,"STRONG",{});var S1t=s(Tfe);gTo=r(S1t,"groupvit"),S1t.forEach(t),hTo=r(Y$e," \u2014 "),qj=n(Y$e,"A",{href:!0});var R1t=s(qj);pTo=r(R1t,"CLIPProcessor"),R1t.forEach(t),_To=r(Y$e," (GroupViT model)"),Y$e.forEach(t),uTo=i(_e),Gp=n(_e,"LI",{});var K$e=s(Gp);Mfe=n(K$e,"STRONG",{});var P1t=s(Mfe);bTo=r(P1t,"layoutlmv2"),P1t.forEach(t),vTo=r(K$e," \u2014 "),jj=n(K$e,"A",{href:!0});var B1t=s(jj);FTo=r(B1t,"LayoutLMv2Processor"),B1t.forEach(t),TTo=r(K$e," (LayoutLMv2 model)"),K$e.forEach(t),MTo=i(_e),Op=n(_e,"LI",{});var Z$e=s(Op);Efe=n(Z$e,"STRONG",{});var I1t=s(Efe);ETo=r(I1t,"layoutlmv3"),I1t.forEach(t),CTo=r(Z$e," \u2014 "),Dj=n(Z$e,"A",{href:!0});var N1t=s(Dj);wTo=r(N1t,"LayoutLMv3Processor"),N1t.forEach(t),ATo=r(Z$e," (LayoutLMv3 model)"),Z$e.forEach(t),LTo=i(_e),Vp=n(_e,"LI",{});var eke=s(Vp);Cfe=n(eke,"STRONG",{});var q1t=s(Cfe);yTo=r(q1t,"layoutxlm"),q1t.forEach(t),xTo=r(eke," \u2014 "),Gj=n(eke,"A",{href:!0});var j1t=s(Gj);$To=r(j1t,"LayoutXLMProcessor"),j1t.forEach(t),kTo=r(eke," (LayoutXLM model)"),eke.forEach(t),STo=i(_e),Xp=n(_e,"LI",{});var oke=s(Xp);wfe=n(oke,"STRONG",{});var D1t=s(wfe);RTo=r(D1t,"owlvit"),D1t.forEach(t),PTo=r(oke," \u2014 "),Oj=n(oke,"A",{href:!0});var G1t=s(Oj);BTo=r(G1t,"OwlViTProcessor"),G1t.forEach(t),ITo=r(oke," (OWL-ViT model)"),oke.forEach(t),NTo=i(_e),zp=n(_e,"LI",{});var rke=s(zp);Afe=n(rke,"STRONG",{});var O1t=s(Afe);qTo=r(O1t,"sew"),O1t.forEach(t),jTo=r(rke," \u2014 "),Vj=n(rke,"A",{href:!0});var V1t=s(Vj);DTo=r(V1t,"Wav2Vec2Processor"),V1t.forEach(t),GTo=r(rke," (SEW model)"),rke.forEach(t),OTo=i(_e),Wp=n(_e,"LI",{});var tke=s(Wp);Lfe=n(tke,"STRONG",{});var X1t=s(Lfe);VTo=r(X1t,"sew-d"),X1t.forEach(t),XTo=r(tke," \u2014 "),Xj=n(tke,"A",{href:!0});var z1t=s(Xj);zTo=r(z1t,"Wav2Vec2Processor"),z1t.forEach(t),WTo=r(tke," (SEW-D model)"),tke.forEach(t),QTo=i(_e),Qp=n(_e,"LI",{});var ake=s(Qp);yfe=n(ake,"STRONG",{});var W1t=s(yfe);UTo=r(W1t,"speech_to_text"),W1t.forEach(t),HTo=r(ake," \u2014 "),zj=n(ake,"A",{href:!0});var Q1t=s(zj);JTo=r(Q1t,"Speech2TextProcessor"),Q1t.forEach(t),YTo=r(ake," (Speech2Text model)"),ake.forEach(t),KTo=i(_e),Up=n(_e,"LI",{});var nke=s(Up);xfe=n(nke,"STRONG",{});var U1t=s(xfe);ZTo=r(U1t,"speech_to_text_2"),U1t.forEach(t),e8o=r(nke," \u2014 "),Wj=n(nke,"A",{href:!0});var H1t=s(Wj);o8o=r(H1t,"Speech2Text2Processor"),H1t.forEach(t),r8o=r(nke," (Speech2Text2 model)"),nke.forEach(t),t8o=i(_e),Hp=n(_e,"LI",{});var ske=s(Hp);$fe=n(ske,"STRONG",{});var J1t=s($fe);a8o=r(J1t,"trocr"),J1t.forEach(t),n8o=r(ske," \u2014 "),Qj=n(ske,"A",{href:!0});var Y1t=s(Qj);s8o=r(Y1t,"TrOCRProcessor"),Y1t.forEach(t),l8o=r(ske," (TrOCR model)"),ske.forEach(t),i8o=i(_e),Jp=n(_e,"LI",{});var lke=s(Jp);kfe=n(lke,"STRONG",{});var K1t=s(kfe);d8o=r(K1t,"unispeech"),K1t.forEach(t),c8o=r(lke," \u2014 "),Uj=n(lke,"A",{href:!0});var Z1t=s(Uj);f8o=r(Z1t,"Wav2Vec2Processor"),Z1t.forEach(t),m8o=r(lke," (UniSpeech model)"),lke.forEach(t),g8o=i(_e),Yp=n(_e,"LI",{});var ike=s(Yp);Sfe=n(ike,"STRONG",{});var e4t=s(Sfe);h8o=r(e4t,"unispeech-sat"),e4t.forEach(t),p8o=r(ike," \u2014 "),Hj=n(ike,"A",{href:!0});var o4t=s(Hj);_8o=r(o4t,"Wav2Vec2Processor"),o4t.forEach(t),u8o=r(ike," (UniSpeechSat model)"),ike.forEach(t),b8o=i(_e),Kp=n(_e,"LI",{});var dke=s(Kp);Rfe=n(dke,"STRONG",{});var r4t=s(Rfe);v8o=r(r4t,"vilt"),r4t.forEach(t),F8o=r(dke," \u2014 "),Jj=n(dke,"A",{href:!0});var t4t=s(Jj);T8o=r(t4t,"ViltProcessor"),t4t.forEach(t),M8o=r(dke," (ViLT model)"),dke.forEach(t),E8o=i(_e),Zp=n(_e,"LI",{});var cke=s(Zp);Pfe=n(cke,"STRONG",{});var a4t=s(Pfe);C8o=r(a4t,"vision-text-dual-encoder"),a4t.forEach(t),w8o=r(cke," \u2014 "),Yj=n(cke,"A",{href:!0});var n4t=s(Yj);A8o=r(n4t,"VisionTextDualEncoderProcessor"),n4t.forEach(t),L8o=r(cke," (VisionTextDualEncoder model)"),cke.forEach(t),y8o=i(_e),e_=n(_e,"LI",{});var fke=s(e_);Bfe=n(fke,"STRONG",{});var s4t=s(Bfe);x8o=r(s4t,"wav2vec2"),s4t.forEach(t),$8o=r(fke," \u2014 "),Kj=n(fke,"A",{href:!0});var l4t=s(Kj);k8o=r(l4t,"Wav2Vec2Processor"),l4t.forEach(t),S8o=r(fke," (Wav2Vec2 model)"),fke.forEach(t),R8o=i(_e),o_=n(_e,"LI",{});var mke=s(o_);Ife=n(mke,"STRONG",{});var i4t=s(Ife);P8o=r(i4t,"wav2vec2-conformer"),i4t.forEach(t),B8o=r(mke," \u2014 "),Zj=n(mke,"A",{href:!0});var d4t=s(Zj);I8o=r(d4t,"Wav2Vec2Processor"),d4t.forEach(t),N8o=r(mke," (Wav2Vec2-Conformer model)"),mke.forEach(t),q8o=i(_e),r_=n(_e,"LI",{});var gke=s(r_);Nfe=n(gke,"STRONG",{});var c4t=s(Nfe);j8o=r(c4t,"wavlm"),c4t.forEach(t),D8o=r(gke," \u2014 "),eD=n(gke,"A",{href:!0});var f4t=s(eD);G8o=r(f4t,"Wav2Vec2Processor"),f4t.forEach(t),O8o=r(gke," (WavLM model)"),gke.forEach(t),_e.forEach(t),V8o=i(da),T(t_.$$.fragment,da),X8o=i(da),T(a_.$$.fragment,da),da.forEach(t),z8o=i(dl),n_=n(dl,"DIV",{class:!0});var nHe=s(n_);T(by.$$.fragment,nHe),W8o=i(nHe),qfe=n(nHe,"P",{});var m4t=s(qfe);Q8o=r(m4t,"Register a new processor for this class."),m4t.forEach(t),nHe.forEach(t),dl.forEach(t),KWe=i(f),Ji=n(f,"H2",{class:!0});var sHe=s(Ji);s_=n(sHe,"A",{id:!0,class:!0,href:!0});var g4t=s(s_);jfe=n(g4t,"SPAN",{});var h4t=s(jfe);T(vy.$$.fragment,h4t),h4t.forEach(t),g4t.forEach(t),U8o=i(sHe),Dfe=n(sHe,"SPAN",{});var p4t=s(Dfe);H8o=r(p4t,"AutoModel"),p4t.forEach(t),sHe.forEach(t),ZWe=i(f),So=n(f,"DIV",{class:!0});var cl=s(So);T(Fy.$$.fragment,cl),J8o=i(cl),Yi=n(cl,"P",{});var nae=s(Yi);Y8o=r(nae,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oD=n(nae,"A",{href:!0});var _4t=s(oD);K8o=r(_4t,"from_pretrained()"),_4t.forEach(t),Z8o=r(nae," class method or the "),rD=n(nae,"A",{href:!0});var u4t=s(rD);eMo=r(u4t,"from_config()"),u4t.forEach(t),oMo=r(nae,` class
method.`),nae.forEach(t),rMo=i(cl),Ty=n(cl,"P",{});var lHe=s(Ty);tMo=r(lHe,"This class cannot be instantiated directly using "),Gfe=n(lHe,"CODE",{});var b4t=s(Gfe);aMo=r(b4t,"__init__()"),b4t.forEach(t),nMo=r(lHe," (throws an error)."),lHe.forEach(t),sMo=i(cl),ct=n(cl,"DIV",{class:!0});var UA=s(ct);T(My.$$.fragment,UA),lMo=i(UA),Ofe=n(UA,"P",{});var v4t=s(Ofe);iMo=r(v4t,"Instantiates one of the base model classes of the library from a configuration."),v4t.forEach(t),dMo=i(UA),Ki=n(UA,"P",{});var sae=s(Ki);cMo=r(sae,`Note:
Loading a model from its configuration file does `),Vfe=n(sae,"STRONG",{});var F4t=s(Vfe);fMo=r(F4t,"not"),F4t.forEach(t),mMo=r(sae,` load the model weights. It only affects the
model\u2019s configuration. Use `),tD=n(sae,"A",{href:!0});var T4t=s(tD);gMo=r(T4t,"from_pretrained()"),T4t.forEach(t),hMo=r(sae," to load the model weights."),sae.forEach(t),pMo=i(UA),T(l_.$$.fragment,UA),UA.forEach(t),_Mo=i(cl),Ye=n(cl,"DIV",{class:!0});var ca=s(Ye);T(Ey.$$.fragment,ca),uMo=i(ca),Xfe=n(ca,"P",{});var M4t=s(Xfe);bMo=r(M4t,"Instantiate one of the base model classes of the library from a pretrained model."),M4t.forEach(t),vMo=i(ca),Da=n(ca,"P",{});var HA=s(Da);FMo=r(HA,"The model class to instantiate is selected based on the "),zfe=n(HA,"CODE",{});var E4t=s(zfe);TMo=r(E4t,"model_type"),E4t.forEach(t),MMo=r(HA,` property of the config object (either
passed as an argument or loaded from `),Wfe=n(HA,"CODE",{});var C4t=s(Wfe);EMo=r(C4t,"pretrained_model_name_or_path"),C4t.forEach(t),CMo=r(HA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qfe=n(HA,"CODE",{});var w4t=s(Qfe);wMo=r(w4t,"pretrained_model_name_or_path"),w4t.forEach(t),AMo=r(HA,":"),HA.forEach(t),LMo=i(ca),y=n(ca,"UL",{});var x=s(y);i_=n(x,"LI",{});var hke=s(i_);Ufe=n(hke,"STRONG",{});var A4t=s(Ufe);yMo=r(A4t,"albert"),A4t.forEach(t),xMo=r(hke," \u2014 "),aD=n(hke,"A",{href:!0});var L4t=s(aD);$Mo=r(L4t,"AlbertModel"),L4t.forEach(t),kMo=r(hke," (ALBERT model)"),hke.forEach(t),SMo=i(x),d_=n(x,"LI",{});var pke=s(d_);Hfe=n(pke,"STRONG",{});var y4t=s(Hfe);RMo=r(y4t,"bart"),y4t.forEach(t),PMo=r(pke," \u2014 "),nD=n(pke,"A",{href:!0});var x4t=s(nD);BMo=r(x4t,"BartModel"),x4t.forEach(t),IMo=r(pke," (BART model)"),pke.forEach(t),NMo=i(x),c_=n(x,"LI",{});var _ke=s(c_);Jfe=n(_ke,"STRONG",{});var $4t=s(Jfe);qMo=r($4t,"beit"),$4t.forEach(t),jMo=r(_ke," \u2014 "),sD=n(_ke,"A",{href:!0});var k4t=s(sD);DMo=r(k4t,"BeitModel"),k4t.forEach(t),GMo=r(_ke," (BEiT model)"),_ke.forEach(t),OMo=i(x),f_=n(x,"LI",{});var uke=s(f_);Yfe=n(uke,"STRONG",{});var S4t=s(Yfe);VMo=r(S4t,"bert"),S4t.forEach(t),XMo=r(uke," \u2014 "),lD=n(uke,"A",{href:!0});var R4t=s(lD);zMo=r(R4t,"BertModel"),R4t.forEach(t),WMo=r(uke," (BERT model)"),uke.forEach(t),QMo=i(x),m_=n(x,"LI",{});var bke=s(m_);Kfe=n(bke,"STRONG",{});var P4t=s(Kfe);UMo=r(P4t,"bert-generation"),P4t.forEach(t),HMo=r(bke," \u2014 "),iD=n(bke,"A",{href:!0});var B4t=s(iD);JMo=r(B4t,"BertGenerationEncoder"),B4t.forEach(t),YMo=r(bke," (Bert Generation model)"),bke.forEach(t),KMo=i(x),g_=n(x,"LI",{});var vke=s(g_);Zfe=n(vke,"STRONG",{});var I4t=s(Zfe);ZMo=r(I4t,"big_bird"),I4t.forEach(t),eEo=r(vke," \u2014 "),dD=n(vke,"A",{href:!0});var N4t=s(dD);oEo=r(N4t,"BigBirdModel"),N4t.forEach(t),rEo=r(vke," (BigBird model)"),vke.forEach(t),tEo=i(x),h_=n(x,"LI",{});var Fke=s(h_);eme=n(Fke,"STRONG",{});var q4t=s(eme);aEo=r(q4t,"bigbird_pegasus"),q4t.forEach(t),nEo=r(Fke," \u2014 "),cD=n(Fke,"A",{href:!0});var j4t=s(cD);sEo=r(j4t,"BigBirdPegasusModel"),j4t.forEach(t),lEo=r(Fke," (BigBird-Pegasus model)"),Fke.forEach(t),iEo=i(x),p_=n(x,"LI",{});var Tke=s(p_);ome=n(Tke,"STRONG",{});var D4t=s(ome);dEo=r(D4t,"blenderbot"),D4t.forEach(t),cEo=r(Tke," \u2014 "),fD=n(Tke,"A",{href:!0});var G4t=s(fD);fEo=r(G4t,"BlenderbotModel"),G4t.forEach(t),mEo=r(Tke," (Blenderbot model)"),Tke.forEach(t),gEo=i(x),__=n(x,"LI",{});var Mke=s(__);rme=n(Mke,"STRONG",{});var O4t=s(rme);hEo=r(O4t,"blenderbot-small"),O4t.forEach(t),pEo=r(Mke," \u2014 "),mD=n(Mke,"A",{href:!0});var V4t=s(mD);_Eo=r(V4t,"BlenderbotSmallModel"),V4t.forEach(t),uEo=r(Mke," (BlenderbotSmall model)"),Mke.forEach(t),bEo=i(x),u_=n(x,"LI",{});var Eke=s(u_);tme=n(Eke,"STRONG",{});var X4t=s(tme);vEo=r(X4t,"bloom"),X4t.forEach(t),FEo=r(Eke," \u2014 "),gD=n(Eke,"A",{href:!0});var z4t=s(gD);TEo=r(z4t,"BloomModel"),z4t.forEach(t),MEo=r(Eke," (BLOOM model)"),Eke.forEach(t),EEo=i(x),b_=n(x,"LI",{});var Cke=s(b_);ame=n(Cke,"STRONG",{});var W4t=s(ame);CEo=r(W4t,"camembert"),W4t.forEach(t),wEo=r(Cke," \u2014 "),hD=n(Cke,"A",{href:!0});var Q4t=s(hD);AEo=r(Q4t,"CamembertModel"),Q4t.forEach(t),LEo=r(Cke," (CamemBERT model)"),Cke.forEach(t),yEo=i(x),v_=n(x,"LI",{});var wke=s(v_);nme=n(wke,"STRONG",{});var U4t=s(nme);xEo=r(U4t,"canine"),U4t.forEach(t),$Eo=r(wke," \u2014 "),pD=n(wke,"A",{href:!0});var H4t=s(pD);kEo=r(H4t,"CanineModel"),H4t.forEach(t),SEo=r(wke," (CANINE model)"),wke.forEach(t),REo=i(x),F_=n(x,"LI",{});var Ake=s(F_);sme=n(Ake,"STRONG",{});var J4t=s(sme);PEo=r(J4t,"clip"),J4t.forEach(t),BEo=r(Ake," \u2014 "),_D=n(Ake,"A",{href:!0});var Y4t=s(_D);IEo=r(Y4t,"CLIPModel"),Y4t.forEach(t),NEo=r(Ake," (CLIP model)"),Ake.forEach(t),qEo=i(x),T_=n(x,"LI",{});var Lke=s(T_);lme=n(Lke,"STRONG",{});var K4t=s(lme);jEo=r(K4t,"codegen"),K4t.forEach(t),DEo=r(Lke," \u2014 "),uD=n(Lke,"A",{href:!0});var Z4t=s(uD);GEo=r(Z4t,"CodeGenModel"),Z4t.forEach(t),OEo=r(Lke," (CodeGen model)"),Lke.forEach(t),VEo=i(x),M_=n(x,"LI",{});var yke=s(M_);ime=n(yke,"STRONG",{});var ebt=s(ime);XEo=r(ebt,"convbert"),ebt.forEach(t),zEo=r(yke," \u2014 "),bD=n(yke,"A",{href:!0});var obt=s(bD);WEo=r(obt,"ConvBertModel"),obt.forEach(t),QEo=r(yke," (ConvBERT model)"),yke.forEach(t),UEo=i(x),E_=n(x,"LI",{});var xke=s(E_);dme=n(xke,"STRONG",{});var rbt=s(dme);HEo=r(rbt,"convnext"),rbt.forEach(t),JEo=r(xke," \u2014 "),vD=n(xke,"A",{href:!0});var tbt=s(vD);YEo=r(tbt,"ConvNextModel"),tbt.forEach(t),KEo=r(xke," (ConvNeXT model)"),xke.forEach(t),ZEo=i(x),C_=n(x,"LI",{});var $ke=s(C_);cme=n($ke,"STRONG",{});var abt=s(cme);eCo=r(abt,"ctrl"),abt.forEach(t),oCo=r($ke," \u2014 "),FD=n($ke,"A",{href:!0});var nbt=s(FD);rCo=r(nbt,"CTRLModel"),nbt.forEach(t),tCo=r($ke," (CTRL model)"),$ke.forEach(t),aCo=i(x),w_=n(x,"LI",{});var kke=s(w_);fme=n(kke,"STRONG",{});var sbt=s(fme);nCo=r(sbt,"cvt"),sbt.forEach(t),sCo=r(kke," \u2014 "),TD=n(kke,"A",{href:!0});var lbt=s(TD);lCo=r(lbt,"CvtModel"),lbt.forEach(t),iCo=r(kke," (CvT model)"),kke.forEach(t),dCo=i(x),A_=n(x,"LI",{});var Ske=s(A_);mme=n(Ske,"STRONG",{});var ibt=s(mme);cCo=r(ibt,"data2vec-audio"),ibt.forEach(t),fCo=r(Ske," \u2014 "),MD=n(Ske,"A",{href:!0});var dbt=s(MD);mCo=r(dbt,"Data2VecAudioModel"),dbt.forEach(t),gCo=r(Ske," (Data2VecAudio model)"),Ske.forEach(t),hCo=i(x),L_=n(x,"LI",{});var Rke=s(L_);gme=n(Rke,"STRONG",{});var cbt=s(gme);pCo=r(cbt,"data2vec-text"),cbt.forEach(t),_Co=r(Rke," \u2014 "),ED=n(Rke,"A",{href:!0});var fbt=s(ED);uCo=r(fbt,"Data2VecTextModel"),fbt.forEach(t),bCo=r(Rke," (Data2VecText model)"),Rke.forEach(t),vCo=i(x),y_=n(x,"LI",{});var Pke=s(y_);hme=n(Pke,"STRONG",{});var mbt=s(hme);FCo=r(mbt,"data2vec-vision"),mbt.forEach(t),TCo=r(Pke," \u2014 "),CD=n(Pke,"A",{href:!0});var gbt=s(CD);MCo=r(gbt,"Data2VecVisionModel"),gbt.forEach(t),ECo=r(Pke," (Data2VecVision model)"),Pke.forEach(t),CCo=i(x),x_=n(x,"LI",{});var Bke=s(x_);pme=n(Bke,"STRONG",{});var hbt=s(pme);wCo=r(hbt,"deberta"),hbt.forEach(t),ACo=r(Bke," \u2014 "),wD=n(Bke,"A",{href:!0});var pbt=s(wD);LCo=r(pbt,"DebertaModel"),pbt.forEach(t),yCo=r(Bke," (DeBERTa model)"),Bke.forEach(t),xCo=i(x),$_=n(x,"LI",{});var Ike=s($_);_me=n(Ike,"STRONG",{});var _bt=s(_me);$Co=r(_bt,"deberta-v2"),_bt.forEach(t),kCo=r(Ike," \u2014 "),AD=n(Ike,"A",{href:!0});var ubt=s(AD);SCo=r(ubt,"DebertaV2Model"),ubt.forEach(t),RCo=r(Ike," (DeBERTa-v2 model)"),Ike.forEach(t),PCo=i(x),k_=n(x,"LI",{});var Nke=s(k_);ume=n(Nke,"STRONG",{});var bbt=s(ume);BCo=r(bbt,"decision_transformer"),bbt.forEach(t),ICo=r(Nke," \u2014 "),LD=n(Nke,"A",{href:!0});var vbt=s(LD);NCo=r(vbt,"DecisionTransformerModel"),vbt.forEach(t),qCo=r(Nke," (Decision Transformer model)"),Nke.forEach(t),jCo=i(x),S_=n(x,"LI",{});var qke=s(S_);bme=n(qke,"STRONG",{});var Fbt=s(bme);DCo=r(Fbt,"deit"),Fbt.forEach(t),GCo=r(qke," \u2014 "),yD=n(qke,"A",{href:!0});var Tbt=s(yD);OCo=r(Tbt,"DeiTModel"),Tbt.forEach(t),VCo=r(qke," (DeiT model)"),qke.forEach(t),XCo=i(x),R_=n(x,"LI",{});var jke=s(R_);vme=n(jke,"STRONG",{});var Mbt=s(vme);zCo=r(Mbt,"detr"),Mbt.forEach(t),WCo=r(jke," \u2014 "),xD=n(jke,"A",{href:!0});var Ebt=s(xD);QCo=r(Ebt,"DetrModel"),Ebt.forEach(t),UCo=r(jke," (DETR model)"),jke.forEach(t),HCo=i(x),P_=n(x,"LI",{});var Dke=s(P_);Fme=n(Dke,"STRONG",{});var Cbt=s(Fme);JCo=r(Cbt,"distilbert"),Cbt.forEach(t),YCo=r(Dke," \u2014 "),$D=n(Dke,"A",{href:!0});var wbt=s($D);KCo=r(wbt,"DistilBertModel"),wbt.forEach(t),ZCo=r(Dke," (DistilBERT model)"),Dke.forEach(t),e3o=i(x),B_=n(x,"LI",{});var Gke=s(B_);Tme=n(Gke,"STRONG",{});var Abt=s(Tme);o3o=r(Abt,"dpr"),Abt.forEach(t),r3o=r(Gke," \u2014 "),kD=n(Gke,"A",{href:!0});var Lbt=s(kD);t3o=r(Lbt,"DPRQuestionEncoder"),Lbt.forEach(t),a3o=r(Gke," (DPR model)"),Gke.forEach(t),n3o=i(x),I_=n(x,"LI",{});var Oke=s(I_);Mme=n(Oke,"STRONG",{});var ybt=s(Mme);s3o=r(ybt,"dpt"),ybt.forEach(t),l3o=r(Oke," \u2014 "),SD=n(Oke,"A",{href:!0});var xbt=s(SD);i3o=r(xbt,"DPTModel"),xbt.forEach(t),d3o=r(Oke," (DPT model)"),Oke.forEach(t),c3o=i(x),N_=n(x,"LI",{});var Vke=s(N_);Eme=n(Vke,"STRONG",{});var $bt=s(Eme);f3o=r($bt,"electra"),$bt.forEach(t),m3o=r(Vke," \u2014 "),RD=n(Vke,"A",{href:!0});var kbt=s(RD);g3o=r(kbt,"ElectraModel"),kbt.forEach(t),h3o=r(Vke," (ELECTRA model)"),Vke.forEach(t),p3o=i(x),q_=n(x,"LI",{});var Xke=s(q_);Cme=n(Xke,"STRONG",{});var Sbt=s(Cme);_3o=r(Sbt,"flaubert"),Sbt.forEach(t),u3o=r(Xke," \u2014 "),PD=n(Xke,"A",{href:!0});var Rbt=s(PD);b3o=r(Rbt,"FlaubertModel"),Rbt.forEach(t),v3o=r(Xke," (FlauBERT model)"),Xke.forEach(t),F3o=i(x),j_=n(x,"LI",{});var zke=s(j_);wme=n(zke,"STRONG",{});var Pbt=s(wme);T3o=r(Pbt,"flava"),Pbt.forEach(t),M3o=r(zke," \u2014 "),BD=n(zke,"A",{href:!0});var Bbt=s(BD);E3o=r(Bbt,"FlavaModel"),Bbt.forEach(t),C3o=r(zke," (FLAVA model)"),zke.forEach(t),w3o=i(x),D_=n(x,"LI",{});var Wke=s(D_);Ame=n(Wke,"STRONG",{});var Ibt=s(Ame);A3o=r(Ibt,"fnet"),Ibt.forEach(t),L3o=r(Wke," \u2014 "),ID=n(Wke,"A",{href:!0});var Nbt=s(ID);y3o=r(Nbt,"FNetModel"),Nbt.forEach(t),x3o=r(Wke," (FNet model)"),Wke.forEach(t),$3o=i(x),G_=n(x,"LI",{});var Qke=s(G_);Lme=n(Qke,"STRONG",{});var qbt=s(Lme);k3o=r(qbt,"fsmt"),qbt.forEach(t),S3o=r(Qke," \u2014 "),ND=n(Qke,"A",{href:!0});var jbt=s(ND);R3o=r(jbt,"FSMTModel"),jbt.forEach(t),P3o=r(Qke," (FairSeq Machine-Translation model)"),Qke.forEach(t),B3o=i(x),ol=n(x,"LI",{});var AR=s(ol);yme=n(AR,"STRONG",{});var Dbt=s(yme);I3o=r(Dbt,"funnel"),Dbt.forEach(t),N3o=r(AR," \u2014 "),qD=n(AR,"A",{href:!0});var Gbt=s(qD);q3o=r(Gbt,"FunnelModel"),Gbt.forEach(t),j3o=r(AR," or "),jD=n(AR,"A",{href:!0});var Obt=s(jD);D3o=r(Obt,"FunnelBaseModel"),Obt.forEach(t),G3o=r(AR," (Funnel Transformer model)"),AR.forEach(t),O3o=i(x),O_=n(x,"LI",{});var Uke=s(O_);xme=n(Uke,"STRONG",{});var Vbt=s(xme);V3o=r(Vbt,"glpn"),Vbt.forEach(t),X3o=r(Uke," \u2014 "),DD=n(Uke,"A",{href:!0});var Xbt=s(DD);z3o=r(Xbt,"GLPNModel"),Xbt.forEach(t),W3o=r(Uke," (GLPN model)"),Uke.forEach(t),Q3o=i(x),V_=n(x,"LI",{});var Hke=s(V_);$me=n(Hke,"STRONG",{});var zbt=s($me);U3o=r(zbt,"gpt2"),zbt.forEach(t),H3o=r(Hke," \u2014 "),GD=n(Hke,"A",{href:!0});var Wbt=s(GD);J3o=r(Wbt,"GPT2Model"),Wbt.forEach(t),Y3o=r(Hke," (OpenAI GPT-2 model)"),Hke.forEach(t),K3o=i(x),X_=n(x,"LI",{});var Jke=s(X_);kme=n(Jke,"STRONG",{});var Qbt=s(kme);Z3o=r(Qbt,"gpt_neo"),Qbt.forEach(t),e0o=r(Jke," \u2014 "),OD=n(Jke,"A",{href:!0});var Ubt=s(OD);o0o=r(Ubt,"GPTNeoModel"),Ubt.forEach(t),r0o=r(Jke," (GPT Neo model)"),Jke.forEach(t),t0o=i(x),z_=n(x,"LI",{});var Yke=s(z_);Sme=n(Yke,"STRONG",{});var Hbt=s(Sme);a0o=r(Hbt,"gpt_neox"),Hbt.forEach(t),n0o=r(Yke," \u2014 "),VD=n(Yke,"A",{href:!0});var Jbt=s(VD);s0o=r(Jbt,"GPTNeoXModel"),Jbt.forEach(t),l0o=r(Yke," (GPT NeoX model)"),Yke.forEach(t),i0o=i(x),W_=n(x,"LI",{});var Kke=s(W_);Rme=n(Kke,"STRONG",{});var Ybt=s(Rme);d0o=r(Ybt,"gptj"),Ybt.forEach(t),c0o=r(Kke," \u2014 "),XD=n(Kke,"A",{href:!0});var Kbt=s(XD);f0o=r(Kbt,"GPTJModel"),Kbt.forEach(t),m0o=r(Kke," (GPT-J model)"),Kke.forEach(t),g0o=i(x),Q_=n(x,"LI",{});var Zke=s(Q_);Pme=n(Zke,"STRONG",{});var Zbt=s(Pme);h0o=r(Zbt,"groupvit"),Zbt.forEach(t),p0o=r(Zke," \u2014 "),zD=n(Zke,"A",{href:!0});var evt=s(zD);_0o=r(evt,"GroupViTModel"),evt.forEach(t),u0o=r(Zke," (GroupViT model)"),Zke.forEach(t),b0o=i(x),U_=n(x,"LI",{});var eSe=s(U_);Bme=n(eSe,"STRONG",{});var ovt=s(Bme);v0o=r(ovt,"hubert"),ovt.forEach(t),F0o=r(eSe," \u2014 "),WD=n(eSe,"A",{href:!0});var rvt=s(WD);T0o=r(rvt,"HubertModel"),rvt.forEach(t),M0o=r(eSe," (Hubert model)"),eSe.forEach(t),E0o=i(x),H_=n(x,"LI",{});var oSe=s(H_);Ime=n(oSe,"STRONG",{});var tvt=s(Ime);C0o=r(tvt,"ibert"),tvt.forEach(t),w0o=r(oSe," \u2014 "),QD=n(oSe,"A",{href:!0});var avt=s(QD);A0o=r(avt,"IBertModel"),avt.forEach(t),L0o=r(oSe," (I-BERT model)"),oSe.forEach(t),y0o=i(x),J_=n(x,"LI",{});var rSe=s(J_);Nme=n(rSe,"STRONG",{});var nvt=s(Nme);x0o=r(nvt,"imagegpt"),nvt.forEach(t),$0o=r(rSe," \u2014 "),UD=n(rSe,"A",{href:!0});var svt=s(UD);k0o=r(svt,"ImageGPTModel"),svt.forEach(t),S0o=r(rSe," (ImageGPT model)"),rSe.forEach(t),R0o=i(x),Y_=n(x,"LI",{});var tSe=s(Y_);qme=n(tSe,"STRONG",{});var lvt=s(qme);P0o=r(lvt,"layoutlm"),lvt.forEach(t),B0o=r(tSe," \u2014 "),HD=n(tSe,"A",{href:!0});var ivt=s(HD);I0o=r(ivt,"LayoutLMModel"),ivt.forEach(t),N0o=r(tSe," (LayoutLM model)"),tSe.forEach(t),q0o=i(x),K_=n(x,"LI",{});var aSe=s(K_);jme=n(aSe,"STRONG",{});var dvt=s(jme);j0o=r(dvt,"layoutlmv2"),dvt.forEach(t),D0o=r(aSe," \u2014 "),JD=n(aSe,"A",{href:!0});var cvt=s(JD);G0o=r(cvt,"LayoutLMv2Model"),cvt.forEach(t),O0o=r(aSe," (LayoutLMv2 model)"),aSe.forEach(t),V0o=i(x),Z_=n(x,"LI",{});var nSe=s(Z_);Dme=n(nSe,"STRONG",{});var fvt=s(Dme);X0o=r(fvt,"layoutlmv3"),fvt.forEach(t),z0o=r(nSe," \u2014 "),YD=n(nSe,"A",{href:!0});var mvt=s(YD);W0o=r(mvt,"LayoutLMv3Model"),mvt.forEach(t),Q0o=r(nSe," (LayoutLMv3 model)"),nSe.forEach(t),U0o=i(x),eu=n(x,"LI",{});var sSe=s(eu);Gme=n(sSe,"STRONG",{});var gvt=s(Gme);H0o=r(gvt,"led"),gvt.forEach(t),J0o=r(sSe," \u2014 "),KD=n(sSe,"A",{href:!0});var hvt=s(KD);Y0o=r(hvt,"LEDModel"),hvt.forEach(t),K0o=r(sSe," (LED model)"),sSe.forEach(t),Z0o=i(x),ou=n(x,"LI",{});var lSe=s(ou);Ome=n(lSe,"STRONG",{});var pvt=s(Ome);ewo=r(pvt,"levit"),pvt.forEach(t),owo=r(lSe," \u2014 "),ZD=n(lSe,"A",{href:!0});var _vt=s(ZD);rwo=r(_vt,"LevitModel"),_vt.forEach(t),two=r(lSe," (LeViT model)"),lSe.forEach(t),awo=i(x),ru=n(x,"LI",{});var iSe=s(ru);Vme=n(iSe,"STRONG",{});var uvt=s(Vme);nwo=r(uvt,"longformer"),uvt.forEach(t),swo=r(iSe," \u2014 "),eG=n(iSe,"A",{href:!0});var bvt=s(eG);lwo=r(bvt,"LongformerModel"),bvt.forEach(t),iwo=r(iSe," (Longformer model)"),iSe.forEach(t),dwo=i(x),tu=n(x,"LI",{});var dSe=s(tu);Xme=n(dSe,"STRONG",{});var vvt=s(Xme);cwo=r(vvt,"longt5"),vvt.forEach(t),fwo=r(dSe," \u2014 "),oG=n(dSe,"A",{href:!0});var Fvt=s(oG);mwo=r(Fvt,"LongT5Model"),Fvt.forEach(t),gwo=r(dSe," (LongT5 model)"),dSe.forEach(t),hwo=i(x),au=n(x,"LI",{});var cSe=s(au);zme=n(cSe,"STRONG",{});var Tvt=s(zme);pwo=r(Tvt,"luke"),Tvt.forEach(t),_wo=r(cSe," \u2014 "),rG=n(cSe,"A",{href:!0});var Mvt=s(rG);uwo=r(Mvt,"LukeModel"),Mvt.forEach(t),bwo=r(cSe," (LUKE model)"),cSe.forEach(t),vwo=i(x),nu=n(x,"LI",{});var fSe=s(nu);Wme=n(fSe,"STRONG",{});var Evt=s(Wme);Fwo=r(Evt,"lxmert"),Evt.forEach(t),Two=r(fSe," \u2014 "),tG=n(fSe,"A",{href:!0});var Cvt=s(tG);Mwo=r(Cvt,"LxmertModel"),Cvt.forEach(t),Ewo=r(fSe," (LXMERT model)"),fSe.forEach(t),Cwo=i(x),su=n(x,"LI",{});var mSe=s(su);Qme=n(mSe,"STRONG",{});var wvt=s(Qme);wwo=r(wvt,"m2m_100"),wvt.forEach(t),Awo=r(mSe," \u2014 "),aG=n(mSe,"A",{href:!0});var Avt=s(aG);Lwo=r(Avt,"M2M100Model"),Avt.forEach(t),ywo=r(mSe," (M2M100 model)"),mSe.forEach(t),xwo=i(x),lu=n(x,"LI",{});var gSe=s(lu);Ume=n(gSe,"STRONG",{});var Lvt=s(Ume);$wo=r(Lvt,"marian"),Lvt.forEach(t),kwo=r(gSe," \u2014 "),nG=n(gSe,"A",{href:!0});var yvt=s(nG);Swo=r(yvt,"MarianModel"),yvt.forEach(t),Rwo=r(gSe," (Marian model)"),gSe.forEach(t),Pwo=i(x),iu=n(x,"LI",{});var hSe=s(iu);Hme=n(hSe,"STRONG",{});var xvt=s(Hme);Bwo=r(xvt,"maskformer"),xvt.forEach(t),Iwo=r(hSe," \u2014 "),sG=n(hSe,"A",{href:!0});var $vt=s(sG);Nwo=r($vt,"MaskFormerModel"),$vt.forEach(t),qwo=r(hSe," (MaskFormer model)"),hSe.forEach(t),jwo=i(x),du=n(x,"LI",{});var pSe=s(du);Jme=n(pSe,"STRONG",{});var kvt=s(Jme);Dwo=r(kvt,"mbart"),kvt.forEach(t),Gwo=r(pSe," \u2014 "),lG=n(pSe,"A",{href:!0});var Svt=s(lG);Owo=r(Svt,"MBartModel"),Svt.forEach(t),Vwo=r(pSe," (mBART model)"),pSe.forEach(t),Xwo=i(x),cu=n(x,"LI",{});var _Se=s(cu);Yme=n(_Se,"STRONG",{});var Rvt=s(Yme);zwo=r(Rvt,"mctct"),Rvt.forEach(t),Wwo=r(_Se," \u2014 "),iG=n(_Se,"A",{href:!0});var Pvt=s(iG);Qwo=r(Pvt,"MCTCTModel"),Pvt.forEach(t),Uwo=r(_Se," (M-CTC-T model)"),_Se.forEach(t),Hwo=i(x),fu=n(x,"LI",{});var uSe=s(fu);Kme=n(uSe,"STRONG",{});var Bvt=s(Kme);Jwo=r(Bvt,"megatron-bert"),Bvt.forEach(t),Ywo=r(uSe," \u2014 "),dG=n(uSe,"A",{href:!0});var Ivt=s(dG);Kwo=r(Ivt,"MegatronBertModel"),Ivt.forEach(t),Zwo=r(uSe," (Megatron-BERT model)"),uSe.forEach(t),e6o=i(x),mu=n(x,"LI",{});var bSe=s(mu);Zme=n(bSe,"STRONG",{});var Nvt=s(Zme);o6o=r(Nvt,"mobilebert"),Nvt.forEach(t),r6o=r(bSe," \u2014 "),cG=n(bSe,"A",{href:!0});var qvt=s(cG);t6o=r(qvt,"MobileBertModel"),qvt.forEach(t),a6o=r(bSe," (MobileBERT model)"),bSe.forEach(t),n6o=i(x),gu=n(x,"LI",{});var vSe=s(gu);ege=n(vSe,"STRONG",{});var jvt=s(ege);s6o=r(jvt,"mobilevit"),jvt.forEach(t),l6o=r(vSe," \u2014 "),fG=n(vSe,"A",{href:!0});var Dvt=s(fG);i6o=r(Dvt,"MobileViTModel"),Dvt.forEach(t),d6o=r(vSe," (MobileViT model)"),vSe.forEach(t),c6o=i(x),hu=n(x,"LI",{});var FSe=s(hu);oge=n(FSe,"STRONG",{});var Gvt=s(oge);f6o=r(Gvt,"mpnet"),Gvt.forEach(t),m6o=r(FSe," \u2014 "),mG=n(FSe,"A",{href:!0});var Ovt=s(mG);g6o=r(Ovt,"MPNetModel"),Ovt.forEach(t),h6o=r(FSe," (MPNet model)"),FSe.forEach(t),p6o=i(x),pu=n(x,"LI",{});var TSe=s(pu);rge=n(TSe,"STRONG",{});var Vvt=s(rge);_6o=r(Vvt,"mt5"),Vvt.forEach(t),u6o=r(TSe," \u2014 "),gG=n(TSe,"A",{href:!0});var Xvt=s(gG);b6o=r(Xvt,"MT5Model"),Xvt.forEach(t),v6o=r(TSe," (MT5 model)"),TSe.forEach(t),F6o=i(x),_u=n(x,"LI",{});var MSe=s(_u);tge=n(MSe,"STRONG",{});var zvt=s(tge);T6o=r(zvt,"mvp"),zvt.forEach(t),M6o=r(MSe," \u2014 "),hG=n(MSe,"A",{href:!0});var Wvt=s(hG);E6o=r(Wvt,"MvpModel"),Wvt.forEach(t),C6o=r(MSe," (MVP model)"),MSe.forEach(t),w6o=i(x),uu=n(x,"LI",{});var ESe=s(uu);age=n(ESe,"STRONG",{});var Qvt=s(age);A6o=r(Qvt,"nezha"),Qvt.forEach(t),L6o=r(ESe," \u2014 "),pG=n(ESe,"A",{href:!0});var Uvt=s(pG);y6o=r(Uvt,"NezhaModel"),Uvt.forEach(t),x6o=r(ESe," (Nezha model)"),ESe.forEach(t),$6o=i(x),bu=n(x,"LI",{});var CSe=s(bu);nge=n(CSe,"STRONG",{});var Hvt=s(nge);k6o=r(Hvt,"nllb"),Hvt.forEach(t),S6o=r(CSe," \u2014 "),_G=n(CSe,"A",{href:!0});var Jvt=s(_G);R6o=r(Jvt,"M2M100Model"),Jvt.forEach(t),P6o=r(CSe," (NLLB model)"),CSe.forEach(t),B6o=i(x),vu=n(x,"LI",{});var wSe=s(vu);sge=n(wSe,"STRONG",{});var Yvt=s(sge);I6o=r(Yvt,"nystromformer"),Yvt.forEach(t),N6o=r(wSe," \u2014 "),uG=n(wSe,"A",{href:!0});var Kvt=s(uG);q6o=r(Kvt,"NystromformerModel"),Kvt.forEach(t),j6o=r(wSe," (Nystr\xF6mformer model)"),wSe.forEach(t),D6o=i(x),Fu=n(x,"LI",{});var ASe=s(Fu);lge=n(ASe,"STRONG",{});var Zvt=s(lge);G6o=r(Zvt,"openai-gpt"),Zvt.forEach(t),O6o=r(ASe," \u2014 "),bG=n(ASe,"A",{href:!0});var e5t=s(bG);V6o=r(e5t,"OpenAIGPTModel"),e5t.forEach(t),X6o=r(ASe," (OpenAI GPT model)"),ASe.forEach(t),z6o=i(x),Tu=n(x,"LI",{});var LSe=s(Tu);ige=n(LSe,"STRONG",{});var o5t=s(ige);W6o=r(o5t,"opt"),o5t.forEach(t),Q6o=r(LSe," \u2014 "),vG=n(LSe,"A",{href:!0});var r5t=s(vG);U6o=r(r5t,"OPTModel"),r5t.forEach(t),H6o=r(LSe," (OPT model)"),LSe.forEach(t),J6o=i(x),Mu=n(x,"LI",{});var ySe=s(Mu);dge=n(ySe,"STRONG",{});var t5t=s(dge);Y6o=r(t5t,"owlvit"),t5t.forEach(t),K6o=r(ySe," \u2014 "),FG=n(ySe,"A",{href:!0});var a5t=s(FG);Z6o=r(a5t,"OwlViTModel"),a5t.forEach(t),eAo=r(ySe," (OWL-ViT model)"),ySe.forEach(t),oAo=i(x),Eu=n(x,"LI",{});var xSe=s(Eu);cge=n(xSe,"STRONG",{});var n5t=s(cge);rAo=r(n5t,"pegasus"),n5t.forEach(t),tAo=r(xSe," \u2014 "),TG=n(xSe,"A",{href:!0});var s5t=s(TG);aAo=r(s5t,"PegasusModel"),s5t.forEach(t),nAo=r(xSe," (Pegasus model)"),xSe.forEach(t),sAo=i(x),Cu=n(x,"LI",{});var $Se=s(Cu);fge=n($Se,"STRONG",{});var l5t=s(fge);lAo=r(l5t,"perceiver"),l5t.forEach(t),iAo=r($Se," \u2014 "),MG=n($Se,"A",{href:!0});var i5t=s(MG);dAo=r(i5t,"PerceiverModel"),i5t.forEach(t),cAo=r($Se," (Perceiver model)"),$Se.forEach(t),fAo=i(x),wu=n(x,"LI",{});var kSe=s(wu);mge=n(kSe,"STRONG",{});var d5t=s(mge);mAo=r(d5t,"plbart"),d5t.forEach(t),gAo=r(kSe," \u2014 "),EG=n(kSe,"A",{href:!0});var c5t=s(EG);hAo=r(c5t,"PLBartModel"),c5t.forEach(t),pAo=r(kSe," (PLBart model)"),kSe.forEach(t),_Ao=i(x),Au=n(x,"LI",{});var SSe=s(Au);gge=n(SSe,"STRONG",{});var f5t=s(gge);uAo=r(f5t,"poolformer"),f5t.forEach(t),bAo=r(SSe," \u2014 "),CG=n(SSe,"A",{href:!0});var m5t=s(CG);vAo=r(m5t,"PoolFormerModel"),m5t.forEach(t),FAo=r(SSe," (PoolFormer model)"),SSe.forEach(t),TAo=i(x),Lu=n(x,"LI",{});var RSe=s(Lu);hge=n(RSe,"STRONG",{});var g5t=s(hge);MAo=r(g5t,"prophetnet"),g5t.forEach(t),EAo=r(RSe," \u2014 "),wG=n(RSe,"A",{href:!0});var h5t=s(wG);CAo=r(h5t,"ProphetNetModel"),h5t.forEach(t),wAo=r(RSe," (ProphetNet model)"),RSe.forEach(t),AAo=i(x),yu=n(x,"LI",{});var PSe=s(yu);pge=n(PSe,"STRONG",{});var p5t=s(pge);LAo=r(p5t,"qdqbert"),p5t.forEach(t),yAo=r(PSe," \u2014 "),AG=n(PSe,"A",{href:!0});var _5t=s(AG);xAo=r(_5t,"QDQBertModel"),_5t.forEach(t),$Ao=r(PSe," (QDQBert model)"),PSe.forEach(t),kAo=i(x),xu=n(x,"LI",{});var BSe=s(xu);_ge=n(BSe,"STRONG",{});var u5t=s(_ge);SAo=r(u5t,"reformer"),u5t.forEach(t),RAo=r(BSe," \u2014 "),LG=n(BSe,"A",{href:!0});var b5t=s(LG);PAo=r(b5t,"ReformerModel"),b5t.forEach(t),BAo=r(BSe," (Reformer model)"),BSe.forEach(t),IAo=i(x),$u=n(x,"LI",{});var ISe=s($u);uge=n(ISe,"STRONG",{});var v5t=s(uge);NAo=r(v5t,"regnet"),v5t.forEach(t),qAo=r(ISe," \u2014 "),yG=n(ISe,"A",{href:!0});var F5t=s(yG);jAo=r(F5t,"RegNetModel"),F5t.forEach(t),DAo=r(ISe," (RegNet model)"),ISe.forEach(t),GAo=i(x),ku=n(x,"LI",{});var NSe=s(ku);bge=n(NSe,"STRONG",{});var T5t=s(bge);OAo=r(T5t,"rembert"),T5t.forEach(t),VAo=r(NSe," \u2014 "),xG=n(NSe,"A",{href:!0});var M5t=s(xG);XAo=r(M5t,"RemBertModel"),M5t.forEach(t),zAo=r(NSe," (RemBERT model)"),NSe.forEach(t),WAo=i(x),Su=n(x,"LI",{});var qSe=s(Su);vge=n(qSe,"STRONG",{});var E5t=s(vge);QAo=r(E5t,"resnet"),E5t.forEach(t),UAo=r(qSe," \u2014 "),$G=n(qSe,"A",{href:!0});var C5t=s($G);HAo=r(C5t,"ResNetModel"),C5t.forEach(t),JAo=r(qSe," (ResNet model)"),qSe.forEach(t),YAo=i(x),Ru=n(x,"LI",{});var jSe=s(Ru);Fge=n(jSe,"STRONG",{});var w5t=s(Fge);KAo=r(w5t,"retribert"),w5t.forEach(t),ZAo=r(jSe," \u2014 "),kG=n(jSe,"A",{href:!0});var A5t=s(kG);e7o=r(A5t,"RetriBertModel"),A5t.forEach(t),o7o=r(jSe," (RetriBERT model)"),jSe.forEach(t),r7o=i(x),Pu=n(x,"LI",{});var DSe=s(Pu);Tge=n(DSe,"STRONG",{});var L5t=s(Tge);t7o=r(L5t,"roberta"),L5t.forEach(t),a7o=r(DSe," \u2014 "),SG=n(DSe,"A",{href:!0});var y5t=s(SG);n7o=r(y5t,"RobertaModel"),y5t.forEach(t),s7o=r(DSe," (RoBERTa model)"),DSe.forEach(t),l7o=i(x),Bu=n(x,"LI",{});var GSe=s(Bu);Mge=n(GSe,"STRONG",{});var x5t=s(Mge);i7o=r(x5t,"roformer"),x5t.forEach(t),d7o=r(GSe," \u2014 "),RG=n(GSe,"A",{href:!0});var $5t=s(RG);c7o=r($5t,"RoFormerModel"),$5t.forEach(t),f7o=r(GSe," (RoFormer model)"),GSe.forEach(t),m7o=i(x),Iu=n(x,"LI",{});var OSe=s(Iu);Ege=n(OSe,"STRONG",{});var k5t=s(Ege);g7o=r(k5t,"segformer"),k5t.forEach(t),h7o=r(OSe," \u2014 "),PG=n(OSe,"A",{href:!0});var S5t=s(PG);p7o=r(S5t,"SegformerModel"),S5t.forEach(t),_7o=r(OSe," (SegFormer model)"),OSe.forEach(t),u7o=i(x),Nu=n(x,"LI",{});var VSe=s(Nu);Cge=n(VSe,"STRONG",{});var R5t=s(Cge);b7o=r(R5t,"sew"),R5t.forEach(t),v7o=r(VSe," \u2014 "),BG=n(VSe,"A",{href:!0});var P5t=s(BG);F7o=r(P5t,"SEWModel"),P5t.forEach(t),T7o=r(VSe," (SEW model)"),VSe.forEach(t),M7o=i(x),qu=n(x,"LI",{});var XSe=s(qu);wge=n(XSe,"STRONG",{});var B5t=s(wge);E7o=r(B5t,"sew-d"),B5t.forEach(t),C7o=r(XSe," \u2014 "),IG=n(XSe,"A",{href:!0});var I5t=s(IG);w7o=r(I5t,"SEWDModel"),I5t.forEach(t),A7o=r(XSe," (SEW-D model)"),XSe.forEach(t),L7o=i(x),ju=n(x,"LI",{});var zSe=s(ju);Age=n(zSe,"STRONG",{});var N5t=s(Age);y7o=r(N5t,"speech_to_text"),N5t.forEach(t),x7o=r(zSe," \u2014 "),NG=n(zSe,"A",{href:!0});var q5t=s(NG);$7o=r(q5t,"Speech2TextModel"),q5t.forEach(t),k7o=r(zSe," (Speech2Text model)"),zSe.forEach(t),S7o=i(x),Du=n(x,"LI",{});var WSe=s(Du);Lge=n(WSe,"STRONG",{});var j5t=s(Lge);R7o=r(j5t,"splinter"),j5t.forEach(t),P7o=r(WSe," \u2014 "),qG=n(WSe,"A",{href:!0});var D5t=s(qG);B7o=r(D5t,"SplinterModel"),D5t.forEach(t),I7o=r(WSe," (Splinter model)"),WSe.forEach(t),N7o=i(x),Gu=n(x,"LI",{});var QSe=s(Gu);yge=n(QSe,"STRONG",{});var G5t=s(yge);q7o=r(G5t,"squeezebert"),G5t.forEach(t),j7o=r(QSe," \u2014 "),jG=n(QSe,"A",{href:!0});var O5t=s(jG);D7o=r(O5t,"SqueezeBertModel"),O5t.forEach(t),G7o=r(QSe," (SqueezeBERT model)"),QSe.forEach(t),O7o=i(x),Ou=n(x,"LI",{});var USe=s(Ou);xge=n(USe,"STRONG",{});var V5t=s(xge);V7o=r(V5t,"swin"),V5t.forEach(t),X7o=r(USe," \u2014 "),DG=n(USe,"A",{href:!0});var X5t=s(DG);z7o=r(X5t,"SwinModel"),X5t.forEach(t),W7o=r(USe," (Swin Transformer model)"),USe.forEach(t),Q7o=i(x),Vu=n(x,"LI",{});var HSe=s(Vu);$ge=n(HSe,"STRONG",{});var z5t=s($ge);U7o=r(z5t,"swinv2"),z5t.forEach(t),H7o=r(HSe," \u2014 "),GG=n(HSe,"A",{href:!0});var W5t=s(GG);J7o=r(W5t,"Swinv2Model"),W5t.forEach(t),Y7o=r(HSe," (Swin Transformer V2 model)"),HSe.forEach(t),K7o=i(x),Xu=n(x,"LI",{});var JSe=s(Xu);kge=n(JSe,"STRONG",{});var Q5t=s(kge);Z7o=r(Q5t,"t5"),Q5t.forEach(t),eLo=r(JSe," \u2014 "),OG=n(JSe,"A",{href:!0});var U5t=s(OG);oLo=r(U5t,"T5Model"),U5t.forEach(t),rLo=r(JSe," (T5 model)"),JSe.forEach(t),tLo=i(x),zu=n(x,"LI",{});var YSe=s(zu);Sge=n(YSe,"STRONG",{});var H5t=s(Sge);aLo=r(H5t,"tapas"),H5t.forEach(t),nLo=r(YSe," \u2014 "),VG=n(YSe,"A",{href:!0});var J5t=s(VG);sLo=r(J5t,"TapasModel"),J5t.forEach(t),lLo=r(YSe," (TAPAS model)"),YSe.forEach(t),iLo=i(x),Wu=n(x,"LI",{});var KSe=s(Wu);Rge=n(KSe,"STRONG",{});var Y5t=s(Rge);dLo=r(Y5t,"trajectory_transformer"),Y5t.forEach(t),cLo=r(KSe," \u2014 "),XG=n(KSe,"A",{href:!0});var K5t=s(XG);fLo=r(K5t,"TrajectoryTransformerModel"),K5t.forEach(t),mLo=r(KSe," (Trajectory Transformer model)"),KSe.forEach(t),gLo=i(x),Qu=n(x,"LI",{});var ZSe=s(Qu);Pge=n(ZSe,"STRONG",{});var Z5t=s(Pge);hLo=r(Z5t,"transfo-xl"),Z5t.forEach(t),pLo=r(ZSe," \u2014 "),zG=n(ZSe,"A",{href:!0});var eFt=s(zG);_Lo=r(eFt,"TransfoXLModel"),eFt.forEach(t),uLo=r(ZSe," (Transformer-XL model)"),ZSe.forEach(t),bLo=i(x),Uu=n(x,"LI",{});var eRe=s(Uu);Bge=n(eRe,"STRONG",{});var oFt=s(Bge);vLo=r(oFt,"unispeech"),oFt.forEach(t),FLo=r(eRe," \u2014 "),WG=n(eRe,"A",{href:!0});var rFt=s(WG);TLo=r(rFt,"UniSpeechModel"),rFt.forEach(t),MLo=r(eRe," (UniSpeech model)"),eRe.forEach(t),ELo=i(x),Hu=n(x,"LI",{});var oRe=s(Hu);Ige=n(oRe,"STRONG",{});var tFt=s(Ige);CLo=r(tFt,"unispeech-sat"),tFt.forEach(t),wLo=r(oRe," \u2014 "),QG=n(oRe,"A",{href:!0});var aFt=s(QG);ALo=r(aFt,"UniSpeechSatModel"),aFt.forEach(t),LLo=r(oRe," (UniSpeechSat model)"),oRe.forEach(t),yLo=i(x),Ju=n(x,"LI",{});var rRe=s(Ju);Nge=n(rRe,"STRONG",{});var nFt=s(Nge);xLo=r(nFt,"van"),nFt.forEach(t),$Lo=r(rRe," \u2014 "),UG=n(rRe,"A",{href:!0});var sFt=s(UG);kLo=r(sFt,"VanModel"),sFt.forEach(t),SLo=r(rRe," (VAN model)"),rRe.forEach(t),RLo=i(x),Yu=n(x,"LI",{});var tRe=s(Yu);qge=n(tRe,"STRONG",{});var lFt=s(qge);PLo=r(lFt,"videomae"),lFt.forEach(t),BLo=r(tRe," \u2014 "),HG=n(tRe,"A",{href:!0});var iFt=s(HG);ILo=r(iFt,"VideoMAEModel"),iFt.forEach(t),NLo=r(tRe," (VideoMAE model)"),tRe.forEach(t),qLo=i(x),Ku=n(x,"LI",{});var aRe=s(Ku);jge=n(aRe,"STRONG",{});var dFt=s(jge);jLo=r(dFt,"vilt"),dFt.forEach(t),DLo=r(aRe," \u2014 "),JG=n(aRe,"A",{href:!0});var cFt=s(JG);GLo=r(cFt,"ViltModel"),cFt.forEach(t),OLo=r(aRe," (ViLT model)"),aRe.forEach(t),VLo=i(x),Zu=n(x,"LI",{});var nRe=s(Zu);Dge=n(nRe,"STRONG",{});var fFt=s(Dge);XLo=r(fFt,"vision-text-dual-encoder"),fFt.forEach(t),zLo=r(nRe," \u2014 "),YG=n(nRe,"A",{href:!0});var mFt=s(YG);WLo=r(mFt,"VisionTextDualEncoderModel"),mFt.forEach(t),QLo=r(nRe," (VisionTextDualEncoder model)"),nRe.forEach(t),ULo=i(x),e2=n(x,"LI",{});var sRe=s(e2);Gge=n(sRe,"STRONG",{});var gFt=s(Gge);HLo=r(gFt,"visual_bert"),gFt.forEach(t),JLo=r(sRe," \u2014 "),KG=n(sRe,"A",{href:!0});var hFt=s(KG);YLo=r(hFt,"VisualBertModel"),hFt.forEach(t),KLo=r(sRe," (VisualBERT model)"),sRe.forEach(t),ZLo=i(x),o2=n(x,"LI",{});var lRe=s(o2);Oge=n(lRe,"STRONG",{});var pFt=s(Oge);eyo=r(pFt,"vit"),pFt.forEach(t),oyo=r(lRe," \u2014 "),ZG=n(lRe,"A",{href:!0});var _Ft=s(ZG);ryo=r(_Ft,"ViTModel"),_Ft.forEach(t),tyo=r(lRe," (ViT model)"),lRe.forEach(t),ayo=i(x),r2=n(x,"LI",{});var iRe=s(r2);Vge=n(iRe,"STRONG",{});var uFt=s(Vge);nyo=r(uFt,"vit_mae"),uFt.forEach(t),syo=r(iRe," \u2014 "),eO=n(iRe,"A",{href:!0});var bFt=s(eO);lyo=r(bFt,"ViTMAEModel"),bFt.forEach(t),iyo=r(iRe," (ViTMAE model)"),iRe.forEach(t),dyo=i(x),t2=n(x,"LI",{});var dRe=s(t2);Xge=n(dRe,"STRONG",{});var vFt=s(Xge);cyo=r(vFt,"wav2vec2"),vFt.forEach(t),fyo=r(dRe," \u2014 "),oO=n(dRe,"A",{href:!0});var FFt=s(oO);myo=r(FFt,"Wav2Vec2Model"),FFt.forEach(t),gyo=r(dRe," (Wav2Vec2 model)"),dRe.forEach(t),hyo=i(x),a2=n(x,"LI",{});var cRe=s(a2);zge=n(cRe,"STRONG",{});var TFt=s(zge);pyo=r(TFt,"wav2vec2-conformer"),TFt.forEach(t),_yo=r(cRe," \u2014 "),rO=n(cRe,"A",{href:!0});var MFt=s(rO);uyo=r(MFt,"Wav2Vec2ConformerModel"),MFt.forEach(t),byo=r(cRe," (Wav2Vec2-Conformer model)"),cRe.forEach(t),vyo=i(x),n2=n(x,"LI",{});var fRe=s(n2);Wge=n(fRe,"STRONG",{});var EFt=s(Wge);Fyo=r(EFt,"wavlm"),EFt.forEach(t),Tyo=r(fRe," \u2014 "),tO=n(fRe,"A",{href:!0});var CFt=s(tO);Myo=r(CFt,"WavLMModel"),CFt.forEach(t),Eyo=r(fRe," (WavLM model)"),fRe.forEach(t),Cyo=i(x),s2=n(x,"LI",{});var mRe=s(s2);Qge=n(mRe,"STRONG",{});var wFt=s(Qge);wyo=r(wFt,"xglm"),wFt.forEach(t),Ayo=r(mRe," \u2014 "),aO=n(mRe,"A",{href:!0});var AFt=s(aO);Lyo=r(AFt,"XGLMModel"),AFt.forEach(t),yyo=r(mRe," (XGLM model)"),mRe.forEach(t),xyo=i(x),l2=n(x,"LI",{});var gRe=s(l2);Uge=n(gRe,"STRONG",{});var LFt=s(Uge);$yo=r(LFt,"xlm"),LFt.forEach(t),kyo=r(gRe," \u2014 "),nO=n(gRe,"A",{href:!0});var yFt=s(nO);Syo=r(yFt,"XLMModel"),yFt.forEach(t),Ryo=r(gRe," (XLM model)"),gRe.forEach(t),Pyo=i(x),i2=n(x,"LI",{});var hRe=s(i2);Hge=n(hRe,"STRONG",{});var xFt=s(Hge);Byo=r(xFt,"xlm-prophetnet"),xFt.forEach(t),Iyo=r(hRe," \u2014 "),sO=n(hRe,"A",{href:!0});var $Ft=s(sO);Nyo=r($Ft,"XLMProphetNetModel"),$Ft.forEach(t),qyo=r(hRe," (XLM-ProphetNet model)"),hRe.forEach(t),jyo=i(x),d2=n(x,"LI",{});var pRe=s(d2);Jge=n(pRe,"STRONG",{});var kFt=s(Jge);Dyo=r(kFt,"xlm-roberta"),kFt.forEach(t),Gyo=r(pRe," \u2014 "),lO=n(pRe,"A",{href:!0});var SFt=s(lO);Oyo=r(SFt,"XLMRobertaModel"),SFt.forEach(t),Vyo=r(pRe," (XLM-RoBERTa model)"),pRe.forEach(t),Xyo=i(x),c2=n(x,"LI",{});var _Re=s(c2);Yge=n(_Re,"STRONG",{});var RFt=s(Yge);zyo=r(RFt,"xlm-roberta-xl"),RFt.forEach(t),Wyo=r(_Re," \u2014 "),iO=n(_Re,"A",{href:!0});var PFt=s(iO);Qyo=r(PFt,"XLMRobertaXLModel"),PFt.forEach(t),Uyo=r(_Re," (XLM-RoBERTa-XL model)"),_Re.forEach(t),Hyo=i(x),f2=n(x,"LI",{});var uRe=s(f2);Kge=n(uRe,"STRONG",{});var BFt=s(Kge);Jyo=r(BFt,"xlnet"),BFt.forEach(t),Yyo=r(uRe," \u2014 "),dO=n(uRe,"A",{href:!0});var IFt=s(dO);Kyo=r(IFt,"XLNetModel"),IFt.forEach(t),Zyo=r(uRe," (XLNet model)"),uRe.forEach(t),e9o=i(x),m2=n(x,"LI",{});var bRe=s(m2);Zge=n(bRe,"STRONG",{});var NFt=s(Zge);o9o=r(NFt,"yolos"),NFt.forEach(t),r9o=r(bRe," \u2014 "),cO=n(bRe,"A",{href:!0});var qFt=s(cO);t9o=r(qFt,"YolosModel"),qFt.forEach(t),a9o=r(bRe," (YOLOS model)"),bRe.forEach(t),n9o=i(x),g2=n(x,"LI",{});var vRe=s(g2);ehe=n(vRe,"STRONG",{});var jFt=s(ehe);s9o=r(jFt,"yoso"),jFt.forEach(t),l9o=r(vRe," \u2014 "),fO=n(vRe,"A",{href:!0});var DFt=s(fO);i9o=r(DFt,"YosoModel"),DFt.forEach(t),d9o=r(vRe," (YOSO model)"),vRe.forEach(t),x.forEach(t),c9o=i(ca),h2=n(ca,"P",{});var FRe=s(h2);f9o=r(FRe,"The model is set in evaluation mode by default using "),ohe=n(FRe,"CODE",{});var GFt=s(ohe);m9o=r(GFt,"model.eval()"),GFt.forEach(t),g9o=r(FRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rhe=n(FRe,"CODE",{});var OFt=s(rhe);h9o=r(OFt,"model.train()"),OFt.forEach(t),FRe.forEach(t),p9o=i(ca),T(p2.$$.fragment,ca),ca.forEach(t),cl.forEach(t),eQe=i(f),Zi=n(f,"H2",{class:!0});var iHe=s(Zi);_2=n(iHe,"A",{id:!0,class:!0,href:!0});var VFt=s(_2);the=n(VFt,"SPAN",{});var XFt=s(the);T(Cy.$$.fragment,XFt),XFt.forEach(t),VFt.forEach(t),_9o=i(iHe),ahe=n(iHe,"SPAN",{});var zFt=s(ahe);u9o=r(zFt,"AutoModelForPreTraining"),zFt.forEach(t),iHe.forEach(t),oQe=i(f),Ro=n(f,"DIV",{class:!0});var fl=s(Ro);T(wy.$$.fragment,fl),b9o=i(fl),ed=n(fl,"P",{});var lae=s(ed);v9o=r(lae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mO=n(lae,"A",{href:!0});var WFt=s(mO);F9o=r(WFt,"from_pretrained()"),WFt.forEach(t),T9o=r(lae," class method or the "),gO=n(lae,"A",{href:!0});var QFt=s(gO);M9o=r(QFt,"from_config()"),QFt.forEach(t),E9o=r(lae,` class
method.`),lae.forEach(t),C9o=i(fl),Ay=n(fl,"P",{});var dHe=s(Ay);w9o=r(dHe,"This class cannot be instantiated directly using "),nhe=n(dHe,"CODE",{});var UFt=s(nhe);A9o=r(UFt,"__init__()"),UFt.forEach(t),L9o=r(dHe," (throws an error)."),dHe.forEach(t),y9o=i(fl),ft=n(fl,"DIV",{class:!0});var JA=s(ft);T(Ly.$$.fragment,JA),x9o=i(JA),she=n(JA,"P",{});var HFt=s(she);$9o=r(HFt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),HFt.forEach(t),k9o=i(JA),od=n(JA,"P",{});var iae=s(od);S9o=r(iae,`Note:
Loading a model from its configuration file does `),lhe=n(iae,"STRONG",{});var JFt=s(lhe);R9o=r(JFt,"not"),JFt.forEach(t),P9o=r(iae,` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=n(iae,"A",{href:!0});var YFt=s(hO);B9o=r(YFt,"from_pretrained()"),YFt.forEach(t),I9o=r(iae," to load the model weights."),iae.forEach(t),N9o=i(JA),T(u2.$$.fragment,JA),JA.forEach(t),q9o=i(fl),Ke=n(fl,"DIV",{class:!0});var fa=s(Ke);T(yy.$$.fragment,fa),j9o=i(fa),ihe=n(fa,"P",{});var KFt=s(ihe);D9o=r(KFt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),KFt.forEach(t),G9o=i(fa),Ga=n(fa,"P",{});var YA=s(Ga);O9o=r(YA,"The model class to instantiate is selected based on the "),dhe=n(YA,"CODE",{});var ZFt=s(dhe);V9o=r(ZFt,"model_type"),ZFt.forEach(t),X9o=r(YA,` property of the config object (either
passed as an argument or loaded from `),che=n(YA,"CODE",{});var eTt=s(che);z9o=r(eTt,"pretrained_model_name_or_path"),eTt.forEach(t),W9o=r(YA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fhe=n(YA,"CODE",{});var oTt=s(fhe);Q9o=r(oTt,"pretrained_model_name_or_path"),oTt.forEach(t),U9o=r(YA,":"),YA.forEach(t),H9o=i(fa),G=n(fa,"UL",{});var O=s(G);b2=n(O,"LI",{});var TRe=s(b2);mhe=n(TRe,"STRONG",{});var rTt=s(mhe);J9o=r(rTt,"albert"),rTt.forEach(t),Y9o=r(TRe," \u2014 "),pO=n(TRe,"A",{href:!0});var tTt=s(pO);K9o=r(tTt,"AlbertForPreTraining"),tTt.forEach(t),Z9o=r(TRe," (ALBERT model)"),TRe.forEach(t),exo=i(O),v2=n(O,"LI",{});var MRe=s(v2);ghe=n(MRe,"STRONG",{});var aTt=s(ghe);oxo=r(aTt,"bart"),aTt.forEach(t),rxo=r(MRe," \u2014 "),_O=n(MRe,"A",{href:!0});var nTt=s(_O);txo=r(nTt,"BartForConditionalGeneration"),nTt.forEach(t),axo=r(MRe," (BART model)"),MRe.forEach(t),nxo=i(O),F2=n(O,"LI",{});var ERe=s(F2);hhe=n(ERe,"STRONG",{});var sTt=s(hhe);sxo=r(sTt,"bert"),sTt.forEach(t),lxo=r(ERe," \u2014 "),uO=n(ERe,"A",{href:!0});var lTt=s(uO);ixo=r(lTt,"BertForPreTraining"),lTt.forEach(t),dxo=r(ERe," (BERT model)"),ERe.forEach(t),cxo=i(O),T2=n(O,"LI",{});var CRe=s(T2);phe=n(CRe,"STRONG",{});var iTt=s(phe);fxo=r(iTt,"big_bird"),iTt.forEach(t),mxo=r(CRe," \u2014 "),bO=n(CRe,"A",{href:!0});var dTt=s(bO);gxo=r(dTt,"BigBirdForPreTraining"),dTt.forEach(t),hxo=r(CRe," (BigBird model)"),CRe.forEach(t),pxo=i(O),M2=n(O,"LI",{});var wRe=s(M2);_he=n(wRe,"STRONG",{});var cTt=s(_he);_xo=r(cTt,"bloom"),cTt.forEach(t),uxo=r(wRe," \u2014 "),vO=n(wRe,"A",{href:!0});var fTt=s(vO);bxo=r(fTt,"BloomForCausalLM"),fTt.forEach(t),vxo=r(wRe," (BLOOM model)"),wRe.forEach(t),Fxo=i(O),E2=n(O,"LI",{});var ARe=s(E2);uhe=n(ARe,"STRONG",{});var mTt=s(uhe);Txo=r(mTt,"camembert"),mTt.forEach(t),Mxo=r(ARe," \u2014 "),FO=n(ARe,"A",{href:!0});var gTt=s(FO);Exo=r(gTt,"CamembertForMaskedLM"),gTt.forEach(t),Cxo=r(ARe," (CamemBERT model)"),ARe.forEach(t),wxo=i(O),C2=n(O,"LI",{});var LRe=s(C2);bhe=n(LRe,"STRONG",{});var hTt=s(bhe);Axo=r(hTt,"ctrl"),hTt.forEach(t),Lxo=r(LRe," \u2014 "),TO=n(LRe,"A",{href:!0});var pTt=s(TO);yxo=r(pTt,"CTRLLMHeadModel"),pTt.forEach(t),xxo=r(LRe," (CTRL model)"),LRe.forEach(t),$xo=i(O),w2=n(O,"LI",{});var yRe=s(w2);vhe=n(yRe,"STRONG",{});var _Tt=s(vhe);kxo=r(_Tt,"data2vec-text"),_Tt.forEach(t),Sxo=r(yRe," \u2014 "),MO=n(yRe,"A",{href:!0});var uTt=s(MO);Rxo=r(uTt,"Data2VecTextForMaskedLM"),uTt.forEach(t),Pxo=r(yRe," (Data2VecText model)"),yRe.forEach(t),Bxo=i(O),A2=n(O,"LI",{});var xRe=s(A2);Fhe=n(xRe,"STRONG",{});var bTt=s(Fhe);Ixo=r(bTt,"deberta"),bTt.forEach(t),Nxo=r(xRe," \u2014 "),EO=n(xRe,"A",{href:!0});var vTt=s(EO);qxo=r(vTt,"DebertaForMaskedLM"),vTt.forEach(t),jxo=r(xRe," (DeBERTa model)"),xRe.forEach(t),Dxo=i(O),L2=n(O,"LI",{});var $Re=s(L2);The=n($Re,"STRONG",{});var FTt=s(The);Gxo=r(FTt,"deberta-v2"),FTt.forEach(t),Oxo=r($Re," \u2014 "),CO=n($Re,"A",{href:!0});var TTt=s(CO);Vxo=r(TTt,"DebertaV2ForMaskedLM"),TTt.forEach(t),Xxo=r($Re," (DeBERTa-v2 model)"),$Re.forEach(t),zxo=i(O),y2=n(O,"LI",{});var kRe=s(y2);Mhe=n(kRe,"STRONG",{});var MTt=s(Mhe);Wxo=r(MTt,"distilbert"),MTt.forEach(t),Qxo=r(kRe," \u2014 "),wO=n(kRe,"A",{href:!0});var ETt=s(wO);Uxo=r(ETt,"DistilBertForMaskedLM"),ETt.forEach(t),Hxo=r(kRe," (DistilBERT model)"),kRe.forEach(t),Jxo=i(O),x2=n(O,"LI",{});var SRe=s(x2);Ehe=n(SRe,"STRONG",{});var CTt=s(Ehe);Yxo=r(CTt,"electra"),CTt.forEach(t),Kxo=r(SRe," \u2014 "),AO=n(SRe,"A",{href:!0});var wTt=s(AO);Zxo=r(wTt,"ElectraForPreTraining"),wTt.forEach(t),e$o=r(SRe," (ELECTRA model)"),SRe.forEach(t),o$o=i(O),$2=n(O,"LI",{});var RRe=s($2);Che=n(RRe,"STRONG",{});var ATt=s(Che);r$o=r(ATt,"flaubert"),ATt.forEach(t),t$o=r(RRe," \u2014 "),LO=n(RRe,"A",{href:!0});var LTt=s(LO);a$o=r(LTt,"FlaubertWithLMHeadModel"),LTt.forEach(t),n$o=r(RRe," (FlauBERT model)"),RRe.forEach(t),s$o=i(O),k2=n(O,"LI",{});var PRe=s(k2);whe=n(PRe,"STRONG",{});var yTt=s(whe);l$o=r(yTt,"flava"),yTt.forEach(t),i$o=r(PRe," \u2014 "),yO=n(PRe,"A",{href:!0});var xTt=s(yO);d$o=r(xTt,"FlavaForPreTraining"),xTt.forEach(t),c$o=r(PRe," (FLAVA model)"),PRe.forEach(t),f$o=i(O),S2=n(O,"LI",{});var BRe=s(S2);Ahe=n(BRe,"STRONG",{});var $Tt=s(Ahe);m$o=r($Tt,"fnet"),$Tt.forEach(t),g$o=r(BRe," \u2014 "),xO=n(BRe,"A",{href:!0});var kTt=s(xO);h$o=r(kTt,"FNetForPreTraining"),kTt.forEach(t),p$o=r(BRe," (FNet model)"),BRe.forEach(t),_$o=i(O),R2=n(O,"LI",{});var IRe=s(R2);Lhe=n(IRe,"STRONG",{});var STt=s(Lhe);u$o=r(STt,"fsmt"),STt.forEach(t),b$o=r(IRe," \u2014 "),$O=n(IRe,"A",{href:!0});var RTt=s($O);v$o=r(RTt,"FSMTForConditionalGeneration"),RTt.forEach(t),F$o=r(IRe," (FairSeq Machine-Translation model)"),IRe.forEach(t),T$o=i(O),P2=n(O,"LI",{});var NRe=s(P2);yhe=n(NRe,"STRONG",{});var PTt=s(yhe);M$o=r(PTt,"funnel"),PTt.forEach(t),E$o=r(NRe," \u2014 "),kO=n(NRe,"A",{href:!0});var BTt=s(kO);C$o=r(BTt,"FunnelForPreTraining"),BTt.forEach(t),w$o=r(NRe," (Funnel Transformer model)"),NRe.forEach(t),A$o=i(O),B2=n(O,"LI",{});var qRe=s(B2);xhe=n(qRe,"STRONG",{});var ITt=s(xhe);L$o=r(ITt,"gpt2"),ITt.forEach(t),y$o=r(qRe," \u2014 "),SO=n(qRe,"A",{href:!0});var NTt=s(SO);x$o=r(NTt,"GPT2LMHeadModel"),NTt.forEach(t),$$o=r(qRe," (OpenAI GPT-2 model)"),qRe.forEach(t),k$o=i(O),I2=n(O,"LI",{});var jRe=s(I2);$he=n(jRe,"STRONG",{});var qTt=s($he);S$o=r(qTt,"ibert"),qTt.forEach(t),R$o=r(jRe," \u2014 "),RO=n(jRe,"A",{href:!0});var jTt=s(RO);P$o=r(jTt,"IBertForMaskedLM"),jTt.forEach(t),B$o=r(jRe," (I-BERT model)"),jRe.forEach(t),I$o=i(O),N2=n(O,"LI",{});var DRe=s(N2);khe=n(DRe,"STRONG",{});var DTt=s(khe);N$o=r(DTt,"layoutlm"),DTt.forEach(t),q$o=r(DRe," \u2014 "),PO=n(DRe,"A",{href:!0});var GTt=s(PO);j$o=r(GTt,"LayoutLMForMaskedLM"),GTt.forEach(t),D$o=r(DRe," (LayoutLM model)"),DRe.forEach(t),G$o=i(O),q2=n(O,"LI",{});var GRe=s(q2);She=n(GRe,"STRONG",{});var OTt=s(She);O$o=r(OTt,"longformer"),OTt.forEach(t),V$o=r(GRe," \u2014 "),BO=n(GRe,"A",{href:!0});var VTt=s(BO);X$o=r(VTt,"LongformerForMaskedLM"),VTt.forEach(t),z$o=r(GRe," (Longformer model)"),GRe.forEach(t),W$o=i(O),j2=n(O,"LI",{});var ORe=s(j2);Rhe=n(ORe,"STRONG",{});var XTt=s(Rhe);Q$o=r(XTt,"luke"),XTt.forEach(t),U$o=r(ORe," \u2014 "),IO=n(ORe,"A",{href:!0});var zTt=s(IO);H$o=r(zTt,"LukeForMaskedLM"),zTt.forEach(t),J$o=r(ORe," (LUKE model)"),ORe.forEach(t),Y$o=i(O),D2=n(O,"LI",{});var VRe=s(D2);Phe=n(VRe,"STRONG",{});var WTt=s(Phe);K$o=r(WTt,"lxmert"),WTt.forEach(t),Z$o=r(VRe," \u2014 "),NO=n(VRe,"A",{href:!0});var QTt=s(NO);eko=r(QTt,"LxmertForPreTraining"),QTt.forEach(t),oko=r(VRe," (LXMERT model)"),VRe.forEach(t),rko=i(O),G2=n(O,"LI",{});var XRe=s(G2);Bhe=n(XRe,"STRONG",{});var UTt=s(Bhe);tko=r(UTt,"megatron-bert"),UTt.forEach(t),ako=r(XRe," \u2014 "),qO=n(XRe,"A",{href:!0});var HTt=s(qO);nko=r(HTt,"MegatronBertForPreTraining"),HTt.forEach(t),sko=r(XRe," (Megatron-BERT model)"),XRe.forEach(t),lko=i(O),O2=n(O,"LI",{});var zRe=s(O2);Ihe=n(zRe,"STRONG",{});var JTt=s(Ihe);iko=r(JTt,"mobilebert"),JTt.forEach(t),dko=r(zRe," \u2014 "),jO=n(zRe,"A",{href:!0});var YTt=s(jO);cko=r(YTt,"MobileBertForPreTraining"),YTt.forEach(t),fko=r(zRe," (MobileBERT model)"),zRe.forEach(t),mko=i(O),V2=n(O,"LI",{});var WRe=s(V2);Nhe=n(WRe,"STRONG",{});var KTt=s(Nhe);gko=r(KTt,"mpnet"),KTt.forEach(t),hko=r(WRe," \u2014 "),DO=n(WRe,"A",{href:!0});var ZTt=s(DO);pko=r(ZTt,"MPNetForMaskedLM"),ZTt.forEach(t),_ko=r(WRe," (MPNet model)"),WRe.forEach(t),uko=i(O),X2=n(O,"LI",{});var QRe=s(X2);qhe=n(QRe,"STRONG",{});var e8t=s(qhe);bko=r(e8t,"mvp"),e8t.forEach(t),vko=r(QRe," \u2014 "),GO=n(QRe,"A",{href:!0});var o8t=s(GO);Fko=r(o8t,"MvpForConditionalGeneration"),o8t.forEach(t),Tko=r(QRe," (MVP model)"),QRe.forEach(t),Mko=i(O),z2=n(O,"LI",{});var URe=s(z2);jhe=n(URe,"STRONG",{});var r8t=s(jhe);Eko=r(r8t,"nezha"),r8t.forEach(t),Cko=r(URe," \u2014 "),OO=n(URe,"A",{href:!0});var t8t=s(OO);wko=r(t8t,"NezhaForPreTraining"),t8t.forEach(t),Ako=r(URe," (Nezha model)"),URe.forEach(t),Lko=i(O),W2=n(O,"LI",{});var HRe=s(W2);Dhe=n(HRe,"STRONG",{});var a8t=s(Dhe);yko=r(a8t,"openai-gpt"),a8t.forEach(t),xko=r(HRe," \u2014 "),VO=n(HRe,"A",{href:!0});var n8t=s(VO);$ko=r(n8t,"OpenAIGPTLMHeadModel"),n8t.forEach(t),kko=r(HRe," (OpenAI GPT model)"),HRe.forEach(t),Sko=i(O),Q2=n(O,"LI",{});var JRe=s(Q2);Ghe=n(JRe,"STRONG",{});var s8t=s(Ghe);Rko=r(s8t,"retribert"),s8t.forEach(t),Pko=r(JRe," \u2014 "),XO=n(JRe,"A",{href:!0});var l8t=s(XO);Bko=r(l8t,"RetriBertModel"),l8t.forEach(t),Iko=r(JRe," (RetriBERT model)"),JRe.forEach(t),Nko=i(O),U2=n(O,"LI",{});var YRe=s(U2);Ohe=n(YRe,"STRONG",{});var i8t=s(Ohe);qko=r(i8t,"roberta"),i8t.forEach(t),jko=r(YRe," \u2014 "),zO=n(YRe,"A",{href:!0});var d8t=s(zO);Dko=r(d8t,"RobertaForMaskedLM"),d8t.forEach(t),Gko=r(YRe," (RoBERTa model)"),YRe.forEach(t),Oko=i(O),H2=n(O,"LI",{});var KRe=s(H2);Vhe=n(KRe,"STRONG",{});var c8t=s(Vhe);Vko=r(c8t,"splinter"),c8t.forEach(t),Xko=r(KRe," \u2014 "),WO=n(KRe,"A",{href:!0});var f8t=s(WO);zko=r(f8t,"SplinterForPreTraining"),f8t.forEach(t),Wko=r(KRe," (Splinter model)"),KRe.forEach(t),Qko=i(O),J2=n(O,"LI",{});var ZRe=s(J2);Xhe=n(ZRe,"STRONG",{});var m8t=s(Xhe);Uko=r(m8t,"squeezebert"),m8t.forEach(t),Hko=r(ZRe," \u2014 "),QO=n(ZRe,"A",{href:!0});var g8t=s(QO);Jko=r(g8t,"SqueezeBertForMaskedLM"),g8t.forEach(t),Yko=r(ZRe," (SqueezeBERT model)"),ZRe.forEach(t),Kko=i(O),Y2=n(O,"LI",{});var ePe=s(Y2);zhe=n(ePe,"STRONG",{});var h8t=s(zhe);Zko=r(h8t,"t5"),h8t.forEach(t),eSo=r(ePe," \u2014 "),UO=n(ePe,"A",{href:!0});var p8t=s(UO);oSo=r(p8t,"T5ForConditionalGeneration"),p8t.forEach(t),rSo=r(ePe," (T5 model)"),ePe.forEach(t),tSo=i(O),K2=n(O,"LI",{});var oPe=s(K2);Whe=n(oPe,"STRONG",{});var _8t=s(Whe);aSo=r(_8t,"tapas"),_8t.forEach(t),nSo=r(oPe," \u2014 "),HO=n(oPe,"A",{href:!0});var u8t=s(HO);sSo=r(u8t,"TapasForMaskedLM"),u8t.forEach(t),lSo=r(oPe," (TAPAS model)"),oPe.forEach(t),iSo=i(O),Z2=n(O,"LI",{});var rPe=s(Z2);Qhe=n(rPe,"STRONG",{});var b8t=s(Qhe);dSo=r(b8t,"transfo-xl"),b8t.forEach(t),cSo=r(rPe," \u2014 "),JO=n(rPe,"A",{href:!0});var v8t=s(JO);fSo=r(v8t,"TransfoXLLMHeadModel"),v8t.forEach(t),mSo=r(rPe," (Transformer-XL model)"),rPe.forEach(t),gSo=i(O),e1=n(O,"LI",{});var tPe=s(e1);Uhe=n(tPe,"STRONG",{});var F8t=s(Uhe);hSo=r(F8t,"unispeech"),F8t.forEach(t),pSo=r(tPe," \u2014 "),YO=n(tPe,"A",{href:!0});var T8t=s(YO);_So=r(T8t,"UniSpeechForPreTraining"),T8t.forEach(t),uSo=r(tPe," (UniSpeech model)"),tPe.forEach(t),bSo=i(O),o1=n(O,"LI",{});var aPe=s(o1);Hhe=n(aPe,"STRONG",{});var M8t=s(Hhe);vSo=r(M8t,"unispeech-sat"),M8t.forEach(t),FSo=r(aPe," \u2014 "),KO=n(aPe,"A",{href:!0});var E8t=s(KO);TSo=r(E8t,"UniSpeechSatForPreTraining"),E8t.forEach(t),MSo=r(aPe," (UniSpeechSat model)"),aPe.forEach(t),ESo=i(O),r1=n(O,"LI",{});var nPe=s(r1);Jhe=n(nPe,"STRONG",{});var C8t=s(Jhe);CSo=r(C8t,"videomae"),C8t.forEach(t),wSo=r(nPe," \u2014 "),ZO=n(nPe,"A",{href:!0});var w8t=s(ZO);ASo=r(w8t,"VideoMAEForPreTraining"),w8t.forEach(t),LSo=r(nPe," (VideoMAE model)"),nPe.forEach(t),ySo=i(O),t1=n(O,"LI",{});var sPe=s(t1);Yhe=n(sPe,"STRONG",{});var A8t=s(Yhe);xSo=r(A8t,"visual_bert"),A8t.forEach(t),$So=r(sPe," \u2014 "),eV=n(sPe,"A",{href:!0});var L8t=s(eV);kSo=r(L8t,"VisualBertForPreTraining"),L8t.forEach(t),SSo=r(sPe," (VisualBERT model)"),sPe.forEach(t),RSo=i(O),a1=n(O,"LI",{});var lPe=s(a1);Khe=n(lPe,"STRONG",{});var y8t=s(Khe);PSo=r(y8t,"vit_mae"),y8t.forEach(t),BSo=r(lPe," \u2014 "),oV=n(lPe,"A",{href:!0});var x8t=s(oV);ISo=r(x8t,"ViTMAEForPreTraining"),x8t.forEach(t),NSo=r(lPe," (ViTMAE model)"),lPe.forEach(t),qSo=i(O),n1=n(O,"LI",{});var iPe=s(n1);Zhe=n(iPe,"STRONG",{});var $8t=s(Zhe);jSo=r($8t,"wav2vec2"),$8t.forEach(t),DSo=r(iPe," \u2014 "),rV=n(iPe,"A",{href:!0});var k8t=s(rV);GSo=r(k8t,"Wav2Vec2ForPreTraining"),k8t.forEach(t),OSo=r(iPe," (Wav2Vec2 model)"),iPe.forEach(t),VSo=i(O),s1=n(O,"LI",{});var dPe=s(s1);epe=n(dPe,"STRONG",{});var S8t=s(epe);XSo=r(S8t,"wav2vec2-conformer"),S8t.forEach(t),zSo=r(dPe," \u2014 "),tV=n(dPe,"A",{href:!0});var R8t=s(tV);WSo=r(R8t,"Wav2Vec2ConformerForPreTraining"),R8t.forEach(t),QSo=r(dPe," (Wav2Vec2-Conformer model)"),dPe.forEach(t),USo=i(O),l1=n(O,"LI",{});var cPe=s(l1);ope=n(cPe,"STRONG",{});var P8t=s(ope);HSo=r(P8t,"xlm"),P8t.forEach(t),JSo=r(cPe," \u2014 "),aV=n(cPe,"A",{href:!0});var B8t=s(aV);YSo=r(B8t,"XLMWithLMHeadModel"),B8t.forEach(t),KSo=r(cPe," (XLM model)"),cPe.forEach(t),ZSo=i(O),i1=n(O,"LI",{});var fPe=s(i1);rpe=n(fPe,"STRONG",{});var I8t=s(rpe);eRo=r(I8t,"xlm-roberta"),I8t.forEach(t),oRo=r(fPe," \u2014 "),nV=n(fPe,"A",{href:!0});var N8t=s(nV);rRo=r(N8t,"XLMRobertaForMaskedLM"),N8t.forEach(t),tRo=r(fPe," (XLM-RoBERTa model)"),fPe.forEach(t),aRo=i(O),d1=n(O,"LI",{});var mPe=s(d1);tpe=n(mPe,"STRONG",{});var q8t=s(tpe);nRo=r(q8t,"xlm-roberta-xl"),q8t.forEach(t),sRo=r(mPe," \u2014 "),sV=n(mPe,"A",{href:!0});var j8t=s(sV);lRo=r(j8t,"XLMRobertaXLForMaskedLM"),j8t.forEach(t),iRo=r(mPe," (XLM-RoBERTa-XL model)"),mPe.forEach(t),dRo=i(O),c1=n(O,"LI",{});var gPe=s(c1);ape=n(gPe,"STRONG",{});var D8t=s(ape);cRo=r(D8t,"xlnet"),D8t.forEach(t),fRo=r(gPe," \u2014 "),lV=n(gPe,"A",{href:!0});var G8t=s(lV);mRo=r(G8t,"XLNetLMHeadModel"),G8t.forEach(t),gRo=r(gPe," (XLNet model)"),gPe.forEach(t),O.forEach(t),hRo=i(fa),f1=n(fa,"P",{});var hPe=s(f1);pRo=r(hPe,"The model is set in evaluation mode by default using "),npe=n(hPe,"CODE",{});var O8t=s(npe);_Ro=r(O8t,"model.eval()"),O8t.forEach(t),uRo=r(hPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),spe=n(hPe,"CODE",{});var V8t=s(spe);bRo=r(V8t,"model.train()"),V8t.forEach(t),hPe.forEach(t),vRo=i(fa),T(m1.$$.fragment,fa),fa.forEach(t),fl.forEach(t),rQe=i(f),rd=n(f,"H2",{class:!0});var cHe=s(rd);g1=n(cHe,"A",{id:!0,class:!0,href:!0});var X8t=s(g1);lpe=n(X8t,"SPAN",{});var z8t=s(lpe);T(xy.$$.fragment,z8t),z8t.forEach(t),X8t.forEach(t),FRo=i(cHe),ipe=n(cHe,"SPAN",{});var W8t=s(ipe);TRo=r(W8t,"AutoModelForCausalLM"),W8t.forEach(t),cHe.forEach(t),tQe=i(f),Po=n(f,"DIV",{class:!0});var ml=s(Po);T($y.$$.fragment,ml),MRo=i(ml),td=n(ml,"P",{});var dae=s(td);ERo=r(dae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),iV=n(dae,"A",{href:!0});var Q8t=s(iV);CRo=r(Q8t,"from_pretrained()"),Q8t.forEach(t),wRo=r(dae," class method or the "),dV=n(dae,"A",{href:!0});var U8t=s(dV);ARo=r(U8t,"from_config()"),U8t.forEach(t),LRo=r(dae,` class
method.`),dae.forEach(t),yRo=i(ml),ky=n(ml,"P",{});var fHe=s(ky);xRo=r(fHe,"This class cannot be instantiated directly using "),dpe=n(fHe,"CODE",{});var H8t=s(dpe);$Ro=r(H8t,"__init__()"),H8t.forEach(t),kRo=r(fHe," (throws an error)."),fHe.forEach(t),SRo=i(ml),mt=n(ml,"DIV",{class:!0});var KA=s(mt);T(Sy.$$.fragment,KA),RRo=i(KA),cpe=n(KA,"P",{});var J8t=s(cpe);PRo=r(J8t,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),J8t.forEach(t),BRo=i(KA),ad=n(KA,"P",{});var cae=s(ad);IRo=r(cae,`Note:
Loading a model from its configuration file does `),fpe=n(cae,"STRONG",{});var Y8t=s(fpe);NRo=r(Y8t,"not"),Y8t.forEach(t),qRo=r(cae,` load the model weights. It only affects the
model\u2019s configuration. Use `),cV=n(cae,"A",{href:!0});var K8t=s(cV);jRo=r(K8t,"from_pretrained()"),K8t.forEach(t),DRo=r(cae," to load the model weights."),cae.forEach(t),GRo=i(KA),T(h1.$$.fragment,KA),KA.forEach(t),ORo=i(ml),Ze=n(ml,"DIV",{class:!0});var ma=s(Ze);T(Ry.$$.fragment,ma),VRo=i(ma),mpe=n(ma,"P",{});var Z8t=s(mpe);XRo=r(Z8t,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),Z8t.forEach(t),zRo=i(ma),Oa=n(ma,"P",{});var ZA=s(Oa);WRo=r(ZA,"The model class to instantiate is selected based on the "),gpe=n(ZA,"CODE",{});var eMt=s(gpe);QRo=r(eMt,"model_type"),eMt.forEach(t),URo=r(ZA,` property of the config object (either
passed as an argument or loaded from `),hpe=n(ZA,"CODE",{});var oMt=s(hpe);HRo=r(oMt,"pretrained_model_name_or_path"),oMt.forEach(t),JRo=r(ZA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ppe=n(ZA,"CODE",{});var rMt=s(ppe);YRo=r(rMt,"pretrained_model_name_or_path"),rMt.forEach(t),KRo=r(ZA,":"),ZA.forEach(t),ZRo=i(ma),z=n(ma,"UL",{});var W=s(z);p1=n(W,"LI",{});var pPe=s(p1);_pe=n(pPe,"STRONG",{});var tMt=s(_pe);ePo=r(tMt,"bart"),tMt.forEach(t),oPo=r(pPe," \u2014 "),fV=n(pPe,"A",{href:!0});var aMt=s(fV);rPo=r(aMt,"BartForCausalLM"),aMt.forEach(t),tPo=r(pPe," (BART model)"),pPe.forEach(t),aPo=i(W),_1=n(W,"LI",{});var _Pe=s(_1);upe=n(_Pe,"STRONG",{});var nMt=s(upe);nPo=r(nMt,"bert"),nMt.forEach(t),sPo=r(_Pe," \u2014 "),mV=n(_Pe,"A",{href:!0});var sMt=s(mV);lPo=r(sMt,"BertLMHeadModel"),sMt.forEach(t),iPo=r(_Pe," (BERT model)"),_Pe.forEach(t),dPo=i(W),u1=n(W,"LI",{});var uPe=s(u1);bpe=n(uPe,"STRONG",{});var lMt=s(bpe);cPo=r(lMt,"bert-generation"),lMt.forEach(t),fPo=r(uPe," \u2014 "),gV=n(uPe,"A",{href:!0});var iMt=s(gV);mPo=r(iMt,"BertGenerationDecoder"),iMt.forEach(t),gPo=r(uPe," (Bert Generation model)"),uPe.forEach(t),hPo=i(W),b1=n(W,"LI",{});var bPe=s(b1);vpe=n(bPe,"STRONG",{});var dMt=s(vpe);pPo=r(dMt,"big_bird"),dMt.forEach(t),_Po=r(bPe," \u2014 "),hV=n(bPe,"A",{href:!0});var cMt=s(hV);uPo=r(cMt,"BigBirdForCausalLM"),cMt.forEach(t),bPo=r(bPe," (BigBird model)"),bPe.forEach(t),vPo=i(W),v1=n(W,"LI",{});var vPe=s(v1);Fpe=n(vPe,"STRONG",{});var fMt=s(Fpe);FPo=r(fMt,"bigbird_pegasus"),fMt.forEach(t),TPo=r(vPe," \u2014 "),pV=n(vPe,"A",{href:!0});var mMt=s(pV);MPo=r(mMt,"BigBirdPegasusForCausalLM"),mMt.forEach(t),EPo=r(vPe," (BigBird-Pegasus model)"),vPe.forEach(t),CPo=i(W),F1=n(W,"LI",{});var FPe=s(F1);Tpe=n(FPe,"STRONG",{});var gMt=s(Tpe);wPo=r(gMt,"blenderbot"),gMt.forEach(t),APo=r(FPe," \u2014 "),_V=n(FPe,"A",{href:!0});var hMt=s(_V);LPo=r(hMt,"BlenderbotForCausalLM"),hMt.forEach(t),yPo=r(FPe," (Blenderbot model)"),FPe.forEach(t),xPo=i(W),T1=n(W,"LI",{});var TPe=s(T1);Mpe=n(TPe,"STRONG",{});var pMt=s(Mpe);$Po=r(pMt,"blenderbot-small"),pMt.forEach(t),kPo=r(TPe," \u2014 "),uV=n(TPe,"A",{href:!0});var _Mt=s(uV);SPo=r(_Mt,"BlenderbotSmallForCausalLM"),_Mt.forEach(t),RPo=r(TPe," (BlenderbotSmall model)"),TPe.forEach(t),PPo=i(W),M1=n(W,"LI",{});var MPe=s(M1);Epe=n(MPe,"STRONG",{});var uMt=s(Epe);BPo=r(uMt,"bloom"),uMt.forEach(t),IPo=r(MPe," \u2014 "),bV=n(MPe,"A",{href:!0});var bMt=s(bV);NPo=r(bMt,"BloomForCausalLM"),bMt.forEach(t),qPo=r(MPe," (BLOOM model)"),MPe.forEach(t),jPo=i(W),E1=n(W,"LI",{});var EPe=s(E1);Cpe=n(EPe,"STRONG",{});var vMt=s(Cpe);DPo=r(vMt,"camembert"),vMt.forEach(t),GPo=r(EPe," \u2014 "),vV=n(EPe,"A",{href:!0});var FMt=s(vV);OPo=r(FMt,"CamembertForCausalLM"),FMt.forEach(t),VPo=r(EPe," (CamemBERT model)"),EPe.forEach(t),XPo=i(W),C1=n(W,"LI",{});var CPe=s(C1);wpe=n(CPe,"STRONG",{});var TMt=s(wpe);zPo=r(TMt,"codegen"),TMt.forEach(t),WPo=r(CPe," \u2014 "),FV=n(CPe,"A",{href:!0});var MMt=s(FV);QPo=r(MMt,"CodeGenForCausalLM"),MMt.forEach(t),UPo=r(CPe," (CodeGen model)"),CPe.forEach(t),HPo=i(W),w1=n(W,"LI",{});var wPe=s(w1);Ape=n(wPe,"STRONG",{});var EMt=s(Ape);JPo=r(EMt,"ctrl"),EMt.forEach(t),YPo=r(wPe," \u2014 "),TV=n(wPe,"A",{href:!0});var CMt=s(TV);KPo=r(CMt,"CTRLLMHeadModel"),CMt.forEach(t),ZPo=r(wPe," (CTRL model)"),wPe.forEach(t),eBo=i(W),A1=n(W,"LI",{});var APe=s(A1);Lpe=n(APe,"STRONG",{});var wMt=s(Lpe);oBo=r(wMt,"data2vec-text"),wMt.forEach(t),rBo=r(APe," \u2014 "),MV=n(APe,"A",{href:!0});var AMt=s(MV);tBo=r(AMt,"Data2VecTextForCausalLM"),AMt.forEach(t),aBo=r(APe," (Data2VecText model)"),APe.forEach(t),nBo=i(W),L1=n(W,"LI",{});var LPe=s(L1);ype=n(LPe,"STRONG",{});var LMt=s(ype);sBo=r(LMt,"electra"),LMt.forEach(t),lBo=r(LPe," \u2014 "),EV=n(LPe,"A",{href:!0});var yMt=s(EV);iBo=r(yMt,"ElectraForCausalLM"),yMt.forEach(t),dBo=r(LPe," (ELECTRA model)"),LPe.forEach(t),cBo=i(W),y1=n(W,"LI",{});var yPe=s(y1);xpe=n(yPe,"STRONG",{});var xMt=s(xpe);fBo=r(xMt,"gpt2"),xMt.forEach(t),mBo=r(yPe," \u2014 "),CV=n(yPe,"A",{href:!0});var $Mt=s(CV);gBo=r($Mt,"GPT2LMHeadModel"),$Mt.forEach(t),hBo=r(yPe," (OpenAI GPT-2 model)"),yPe.forEach(t),pBo=i(W),x1=n(W,"LI",{});var xPe=s(x1);$pe=n(xPe,"STRONG",{});var kMt=s($pe);_Bo=r(kMt,"gpt_neo"),kMt.forEach(t),uBo=r(xPe," \u2014 "),wV=n(xPe,"A",{href:!0});var SMt=s(wV);bBo=r(SMt,"GPTNeoForCausalLM"),SMt.forEach(t),vBo=r(xPe," (GPT Neo model)"),xPe.forEach(t),FBo=i(W),$1=n(W,"LI",{});var $Pe=s($1);kpe=n($Pe,"STRONG",{});var RMt=s(kpe);TBo=r(RMt,"gpt_neox"),RMt.forEach(t),MBo=r($Pe," \u2014 "),AV=n($Pe,"A",{href:!0});var PMt=s(AV);EBo=r(PMt,"GPTNeoXForCausalLM"),PMt.forEach(t),CBo=r($Pe," (GPT NeoX model)"),$Pe.forEach(t),wBo=i(W),k1=n(W,"LI",{});var kPe=s(k1);Spe=n(kPe,"STRONG",{});var BMt=s(Spe);ABo=r(BMt,"gptj"),BMt.forEach(t),LBo=r(kPe," \u2014 "),LV=n(kPe,"A",{href:!0});var IMt=s(LV);yBo=r(IMt,"GPTJForCausalLM"),IMt.forEach(t),xBo=r(kPe," (GPT-J model)"),kPe.forEach(t),$Bo=i(W),S1=n(W,"LI",{});var SPe=s(S1);Rpe=n(SPe,"STRONG",{});var NMt=s(Rpe);kBo=r(NMt,"marian"),NMt.forEach(t),SBo=r(SPe," \u2014 "),yV=n(SPe,"A",{href:!0});var qMt=s(yV);RBo=r(qMt,"MarianForCausalLM"),qMt.forEach(t),PBo=r(SPe," (Marian model)"),SPe.forEach(t),BBo=i(W),R1=n(W,"LI",{});var RPe=s(R1);Ppe=n(RPe,"STRONG",{});var jMt=s(Ppe);IBo=r(jMt,"mbart"),jMt.forEach(t),NBo=r(RPe," \u2014 "),xV=n(RPe,"A",{href:!0});var DMt=s(xV);qBo=r(DMt,"MBartForCausalLM"),DMt.forEach(t),jBo=r(RPe," (mBART model)"),RPe.forEach(t),DBo=i(W),P1=n(W,"LI",{});var PPe=s(P1);Bpe=n(PPe,"STRONG",{});var GMt=s(Bpe);GBo=r(GMt,"megatron-bert"),GMt.forEach(t),OBo=r(PPe," \u2014 "),$V=n(PPe,"A",{href:!0});var OMt=s($V);VBo=r(OMt,"MegatronBertForCausalLM"),OMt.forEach(t),XBo=r(PPe," (Megatron-BERT model)"),PPe.forEach(t),zBo=i(W),B1=n(W,"LI",{});var BPe=s(B1);Ipe=n(BPe,"STRONG",{});var VMt=s(Ipe);WBo=r(VMt,"mvp"),VMt.forEach(t),QBo=r(BPe," \u2014 "),kV=n(BPe,"A",{href:!0});var XMt=s(kV);UBo=r(XMt,"MvpForCausalLM"),XMt.forEach(t),HBo=r(BPe," (MVP model)"),BPe.forEach(t),JBo=i(W),I1=n(W,"LI",{});var IPe=s(I1);Npe=n(IPe,"STRONG",{});var zMt=s(Npe);YBo=r(zMt,"openai-gpt"),zMt.forEach(t),KBo=r(IPe," \u2014 "),SV=n(IPe,"A",{href:!0});var WMt=s(SV);ZBo=r(WMt,"OpenAIGPTLMHeadModel"),WMt.forEach(t),eIo=r(IPe," (OpenAI GPT model)"),IPe.forEach(t),oIo=i(W),N1=n(W,"LI",{});var NPe=s(N1);qpe=n(NPe,"STRONG",{});var QMt=s(qpe);rIo=r(QMt,"opt"),QMt.forEach(t),tIo=r(NPe," \u2014 "),RV=n(NPe,"A",{href:!0});var UMt=s(RV);aIo=r(UMt,"OPTForCausalLM"),UMt.forEach(t),nIo=r(NPe," (OPT model)"),NPe.forEach(t),sIo=i(W),q1=n(W,"LI",{});var qPe=s(q1);jpe=n(qPe,"STRONG",{});var HMt=s(jpe);lIo=r(HMt,"pegasus"),HMt.forEach(t),iIo=r(qPe," \u2014 "),PV=n(qPe,"A",{href:!0});var JMt=s(PV);dIo=r(JMt,"PegasusForCausalLM"),JMt.forEach(t),cIo=r(qPe," (Pegasus model)"),qPe.forEach(t),fIo=i(W),j1=n(W,"LI",{});var jPe=s(j1);Dpe=n(jPe,"STRONG",{});var YMt=s(Dpe);mIo=r(YMt,"plbart"),YMt.forEach(t),gIo=r(jPe," \u2014 "),BV=n(jPe,"A",{href:!0});var KMt=s(BV);hIo=r(KMt,"PLBartForCausalLM"),KMt.forEach(t),pIo=r(jPe," (PLBart model)"),jPe.forEach(t),_Io=i(W),D1=n(W,"LI",{});var DPe=s(D1);Gpe=n(DPe,"STRONG",{});var ZMt=s(Gpe);uIo=r(ZMt,"prophetnet"),ZMt.forEach(t),bIo=r(DPe," \u2014 "),IV=n(DPe,"A",{href:!0});var eEt=s(IV);vIo=r(eEt,"ProphetNetForCausalLM"),eEt.forEach(t),FIo=r(DPe," (ProphetNet model)"),DPe.forEach(t),TIo=i(W),G1=n(W,"LI",{});var GPe=s(G1);Ope=n(GPe,"STRONG",{});var oEt=s(Ope);MIo=r(oEt,"qdqbert"),oEt.forEach(t),EIo=r(GPe," \u2014 "),NV=n(GPe,"A",{href:!0});var rEt=s(NV);CIo=r(rEt,"QDQBertLMHeadModel"),rEt.forEach(t),wIo=r(GPe," (QDQBert model)"),GPe.forEach(t),AIo=i(W),O1=n(W,"LI",{});var OPe=s(O1);Vpe=n(OPe,"STRONG",{});var tEt=s(Vpe);LIo=r(tEt,"reformer"),tEt.forEach(t),yIo=r(OPe," \u2014 "),qV=n(OPe,"A",{href:!0});var aEt=s(qV);xIo=r(aEt,"ReformerModelWithLMHead"),aEt.forEach(t),$Io=r(OPe," (Reformer model)"),OPe.forEach(t),kIo=i(W),V1=n(W,"LI",{});var VPe=s(V1);Xpe=n(VPe,"STRONG",{});var nEt=s(Xpe);SIo=r(nEt,"rembert"),nEt.forEach(t),RIo=r(VPe," \u2014 "),jV=n(VPe,"A",{href:!0});var sEt=s(jV);PIo=r(sEt,"RemBertForCausalLM"),sEt.forEach(t),BIo=r(VPe," (RemBERT model)"),VPe.forEach(t),IIo=i(W),X1=n(W,"LI",{});var XPe=s(X1);zpe=n(XPe,"STRONG",{});var lEt=s(zpe);NIo=r(lEt,"roberta"),lEt.forEach(t),qIo=r(XPe," \u2014 "),DV=n(XPe,"A",{href:!0});var iEt=s(DV);jIo=r(iEt,"RobertaForCausalLM"),iEt.forEach(t),DIo=r(XPe," (RoBERTa model)"),XPe.forEach(t),GIo=i(W),z1=n(W,"LI",{});var zPe=s(z1);Wpe=n(zPe,"STRONG",{});var dEt=s(Wpe);OIo=r(dEt,"roformer"),dEt.forEach(t),VIo=r(zPe," \u2014 "),GV=n(zPe,"A",{href:!0});var cEt=s(GV);XIo=r(cEt,"RoFormerForCausalLM"),cEt.forEach(t),zIo=r(zPe," (RoFormer model)"),zPe.forEach(t),WIo=i(W),W1=n(W,"LI",{});var WPe=s(W1);Qpe=n(WPe,"STRONG",{});var fEt=s(Qpe);QIo=r(fEt,"speech_to_text_2"),fEt.forEach(t),UIo=r(WPe," \u2014 "),OV=n(WPe,"A",{href:!0});var mEt=s(OV);HIo=r(mEt,"Speech2Text2ForCausalLM"),mEt.forEach(t),JIo=r(WPe," (Speech2Text2 model)"),WPe.forEach(t),YIo=i(W),Q1=n(W,"LI",{});var QPe=s(Q1);Upe=n(QPe,"STRONG",{});var gEt=s(Upe);KIo=r(gEt,"transfo-xl"),gEt.forEach(t),ZIo=r(QPe," \u2014 "),VV=n(QPe,"A",{href:!0});var hEt=s(VV);eNo=r(hEt,"TransfoXLLMHeadModel"),hEt.forEach(t),oNo=r(QPe," (Transformer-XL model)"),QPe.forEach(t),rNo=i(W),U1=n(W,"LI",{});var UPe=s(U1);Hpe=n(UPe,"STRONG",{});var pEt=s(Hpe);tNo=r(pEt,"trocr"),pEt.forEach(t),aNo=r(UPe," \u2014 "),XV=n(UPe,"A",{href:!0});var _Et=s(XV);nNo=r(_Et,"TrOCRForCausalLM"),_Et.forEach(t),sNo=r(UPe," (TrOCR model)"),UPe.forEach(t),lNo=i(W),H1=n(W,"LI",{});var HPe=s(H1);Jpe=n(HPe,"STRONG",{});var uEt=s(Jpe);iNo=r(uEt,"xglm"),uEt.forEach(t),dNo=r(HPe," \u2014 "),zV=n(HPe,"A",{href:!0});var bEt=s(zV);cNo=r(bEt,"XGLMForCausalLM"),bEt.forEach(t),fNo=r(HPe," (XGLM model)"),HPe.forEach(t),mNo=i(W),J1=n(W,"LI",{});var JPe=s(J1);Ype=n(JPe,"STRONG",{});var vEt=s(Ype);gNo=r(vEt,"xlm"),vEt.forEach(t),hNo=r(JPe," \u2014 "),WV=n(JPe,"A",{href:!0});var FEt=s(WV);pNo=r(FEt,"XLMWithLMHeadModel"),FEt.forEach(t),_No=r(JPe," (XLM model)"),JPe.forEach(t),uNo=i(W),Y1=n(W,"LI",{});var YPe=s(Y1);Kpe=n(YPe,"STRONG",{});var TEt=s(Kpe);bNo=r(TEt,"xlm-prophetnet"),TEt.forEach(t),vNo=r(YPe," \u2014 "),QV=n(YPe,"A",{href:!0});var MEt=s(QV);FNo=r(MEt,"XLMProphetNetForCausalLM"),MEt.forEach(t),TNo=r(YPe," (XLM-ProphetNet model)"),YPe.forEach(t),MNo=i(W),K1=n(W,"LI",{});var KPe=s(K1);Zpe=n(KPe,"STRONG",{});var EEt=s(Zpe);ENo=r(EEt,"xlm-roberta"),EEt.forEach(t),CNo=r(KPe," \u2014 "),UV=n(KPe,"A",{href:!0});var CEt=s(UV);wNo=r(CEt,"XLMRobertaForCausalLM"),CEt.forEach(t),ANo=r(KPe," (XLM-RoBERTa model)"),KPe.forEach(t),LNo=i(W),Z1=n(W,"LI",{});var ZPe=s(Z1);e_e=n(ZPe,"STRONG",{});var wEt=s(e_e);yNo=r(wEt,"xlm-roberta-xl"),wEt.forEach(t),xNo=r(ZPe," \u2014 "),HV=n(ZPe,"A",{href:!0});var AEt=s(HV);$No=r(AEt,"XLMRobertaXLForCausalLM"),AEt.forEach(t),kNo=r(ZPe," (XLM-RoBERTa-XL model)"),ZPe.forEach(t),SNo=i(W),e4=n(W,"LI",{});var eBe=s(e4);o_e=n(eBe,"STRONG",{});var LEt=s(o_e);RNo=r(LEt,"xlnet"),LEt.forEach(t),PNo=r(eBe," \u2014 "),JV=n(eBe,"A",{href:!0});var yEt=s(JV);BNo=r(yEt,"XLNetLMHeadModel"),yEt.forEach(t),INo=r(eBe," (XLNet model)"),eBe.forEach(t),W.forEach(t),NNo=i(ma),o4=n(ma,"P",{});var oBe=s(o4);qNo=r(oBe,"The model is set in evaluation mode by default using "),r_e=n(oBe,"CODE",{});var xEt=s(r_e);jNo=r(xEt,"model.eval()"),xEt.forEach(t),DNo=r(oBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t_e=n(oBe,"CODE",{});var $Et=s(t_e);GNo=r($Et,"model.train()"),$Et.forEach(t),oBe.forEach(t),ONo=i(ma),T(r4.$$.fragment,ma),ma.forEach(t),ml.forEach(t),aQe=i(f),nd=n(f,"H2",{class:!0});var mHe=s(nd);t4=n(mHe,"A",{id:!0,class:!0,href:!0});var kEt=s(t4);a_e=n(kEt,"SPAN",{});var SEt=s(a_e);T(Py.$$.fragment,SEt),SEt.forEach(t),kEt.forEach(t),VNo=i(mHe),n_e=n(mHe,"SPAN",{});var REt=s(n_e);XNo=r(REt,"AutoModelForMaskedLM"),REt.forEach(t),mHe.forEach(t),nQe=i(f),Bo=n(f,"DIV",{class:!0});var gl=s(Bo);T(By.$$.fragment,gl),zNo=i(gl),sd=n(gl,"P",{});var fae=s(sd);WNo=r(fae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),YV=n(fae,"A",{href:!0});var PEt=s(YV);QNo=r(PEt,"from_pretrained()"),PEt.forEach(t),UNo=r(fae," class method or the "),KV=n(fae,"A",{href:!0});var BEt=s(KV);HNo=r(BEt,"from_config()"),BEt.forEach(t),JNo=r(fae,` class
method.`),fae.forEach(t),YNo=i(gl),Iy=n(gl,"P",{});var gHe=s(Iy);KNo=r(gHe,"This class cannot be instantiated directly using "),s_e=n(gHe,"CODE",{});var IEt=s(s_e);ZNo=r(IEt,"__init__()"),IEt.forEach(t),eqo=r(gHe," (throws an error)."),gHe.forEach(t),oqo=i(gl),gt=n(gl,"DIV",{class:!0});var e7=s(gt);T(Ny.$$.fragment,e7),rqo=i(e7),l_e=n(e7,"P",{});var NEt=s(l_e);tqo=r(NEt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),NEt.forEach(t),aqo=i(e7),ld=n(e7,"P",{});var mae=s(ld);nqo=r(mae,`Note:
Loading a model from its configuration file does `),i_e=n(mae,"STRONG",{});var qEt=s(i_e);sqo=r(qEt,"not"),qEt.forEach(t),lqo=r(mae,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZV=n(mae,"A",{href:!0});var jEt=s(ZV);iqo=r(jEt,"from_pretrained()"),jEt.forEach(t),dqo=r(mae," to load the model weights."),mae.forEach(t),cqo=i(e7),T(a4.$$.fragment,e7),e7.forEach(t),fqo=i(gl),eo=n(gl,"DIV",{class:!0});var ga=s(eo);T(qy.$$.fragment,ga),mqo=i(ga),d_e=n(ga,"P",{});var DEt=s(d_e);gqo=r(DEt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),DEt.forEach(t),hqo=i(ga),Va=n(ga,"P",{});var o7=s(Va);pqo=r(o7,"The model class to instantiate is selected based on the "),c_e=n(o7,"CODE",{});var GEt=s(c_e);_qo=r(GEt,"model_type"),GEt.forEach(t),uqo=r(o7,` property of the config object (either
passed as an argument or loaded from `),f_e=n(o7,"CODE",{});var OEt=s(f_e);bqo=r(OEt,"pretrained_model_name_or_path"),OEt.forEach(t),vqo=r(o7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m_e=n(o7,"CODE",{});var VEt=s(m_e);Fqo=r(VEt,"pretrained_model_name_or_path"),VEt.forEach(t),Tqo=r(o7,":"),o7.forEach(t),Mqo=i(ga),U=n(ga,"UL",{});var Y=s(U);n4=n(Y,"LI",{});var rBe=s(n4);g_e=n(rBe,"STRONG",{});var XEt=s(g_e);Eqo=r(XEt,"albert"),XEt.forEach(t),Cqo=r(rBe," \u2014 "),eX=n(rBe,"A",{href:!0});var zEt=s(eX);wqo=r(zEt,"AlbertForMaskedLM"),zEt.forEach(t),Aqo=r(rBe," (ALBERT model)"),rBe.forEach(t),Lqo=i(Y),s4=n(Y,"LI",{});var tBe=s(s4);h_e=n(tBe,"STRONG",{});var WEt=s(h_e);yqo=r(WEt,"bart"),WEt.forEach(t),xqo=r(tBe," \u2014 "),oX=n(tBe,"A",{href:!0});var QEt=s(oX);$qo=r(QEt,"BartForConditionalGeneration"),QEt.forEach(t),kqo=r(tBe," (BART model)"),tBe.forEach(t),Sqo=i(Y),l4=n(Y,"LI",{});var aBe=s(l4);p_e=n(aBe,"STRONG",{});var UEt=s(p_e);Rqo=r(UEt,"bert"),UEt.forEach(t),Pqo=r(aBe," \u2014 "),rX=n(aBe,"A",{href:!0});var HEt=s(rX);Bqo=r(HEt,"BertForMaskedLM"),HEt.forEach(t),Iqo=r(aBe," (BERT model)"),aBe.forEach(t),Nqo=i(Y),i4=n(Y,"LI",{});var nBe=s(i4);__e=n(nBe,"STRONG",{});var JEt=s(__e);qqo=r(JEt,"big_bird"),JEt.forEach(t),jqo=r(nBe," \u2014 "),tX=n(nBe,"A",{href:!0});var YEt=s(tX);Dqo=r(YEt,"BigBirdForMaskedLM"),YEt.forEach(t),Gqo=r(nBe," (BigBird model)"),nBe.forEach(t),Oqo=i(Y),d4=n(Y,"LI",{});var sBe=s(d4);u_e=n(sBe,"STRONG",{});var KEt=s(u_e);Vqo=r(KEt,"camembert"),KEt.forEach(t),Xqo=r(sBe," \u2014 "),aX=n(sBe,"A",{href:!0});var ZEt=s(aX);zqo=r(ZEt,"CamembertForMaskedLM"),ZEt.forEach(t),Wqo=r(sBe," (CamemBERT model)"),sBe.forEach(t),Qqo=i(Y),c4=n(Y,"LI",{});var lBe=s(c4);b_e=n(lBe,"STRONG",{});var eCt=s(b_e);Uqo=r(eCt,"convbert"),eCt.forEach(t),Hqo=r(lBe," \u2014 "),nX=n(lBe,"A",{href:!0});var oCt=s(nX);Jqo=r(oCt,"ConvBertForMaskedLM"),oCt.forEach(t),Yqo=r(lBe," (ConvBERT model)"),lBe.forEach(t),Kqo=i(Y),f4=n(Y,"LI",{});var iBe=s(f4);v_e=n(iBe,"STRONG",{});var rCt=s(v_e);Zqo=r(rCt,"data2vec-text"),rCt.forEach(t),ejo=r(iBe," \u2014 "),sX=n(iBe,"A",{href:!0});var tCt=s(sX);ojo=r(tCt,"Data2VecTextForMaskedLM"),tCt.forEach(t),rjo=r(iBe," (Data2VecText model)"),iBe.forEach(t),tjo=i(Y),m4=n(Y,"LI",{});var dBe=s(m4);F_e=n(dBe,"STRONG",{});var aCt=s(F_e);ajo=r(aCt,"deberta"),aCt.forEach(t),njo=r(dBe," \u2014 "),lX=n(dBe,"A",{href:!0});var nCt=s(lX);sjo=r(nCt,"DebertaForMaskedLM"),nCt.forEach(t),ljo=r(dBe," (DeBERTa model)"),dBe.forEach(t),ijo=i(Y),g4=n(Y,"LI",{});var cBe=s(g4);T_e=n(cBe,"STRONG",{});var sCt=s(T_e);djo=r(sCt,"deberta-v2"),sCt.forEach(t),cjo=r(cBe," \u2014 "),iX=n(cBe,"A",{href:!0});var lCt=s(iX);fjo=r(lCt,"DebertaV2ForMaskedLM"),lCt.forEach(t),mjo=r(cBe," (DeBERTa-v2 model)"),cBe.forEach(t),gjo=i(Y),h4=n(Y,"LI",{});var fBe=s(h4);M_e=n(fBe,"STRONG",{});var iCt=s(M_e);hjo=r(iCt,"distilbert"),iCt.forEach(t),pjo=r(fBe," \u2014 "),dX=n(fBe,"A",{href:!0});var dCt=s(dX);_jo=r(dCt,"DistilBertForMaskedLM"),dCt.forEach(t),ujo=r(fBe," (DistilBERT model)"),fBe.forEach(t),bjo=i(Y),p4=n(Y,"LI",{});var mBe=s(p4);E_e=n(mBe,"STRONG",{});var cCt=s(E_e);vjo=r(cCt,"electra"),cCt.forEach(t),Fjo=r(mBe," \u2014 "),cX=n(mBe,"A",{href:!0});var fCt=s(cX);Tjo=r(fCt,"ElectraForMaskedLM"),fCt.forEach(t),Mjo=r(mBe," (ELECTRA model)"),mBe.forEach(t),Ejo=i(Y),_4=n(Y,"LI",{});var gBe=s(_4);C_e=n(gBe,"STRONG",{});var mCt=s(C_e);Cjo=r(mCt,"flaubert"),mCt.forEach(t),wjo=r(gBe," \u2014 "),fX=n(gBe,"A",{href:!0});var gCt=s(fX);Ajo=r(gCt,"FlaubertWithLMHeadModel"),gCt.forEach(t),Ljo=r(gBe," (FlauBERT model)"),gBe.forEach(t),yjo=i(Y),u4=n(Y,"LI",{});var hBe=s(u4);w_e=n(hBe,"STRONG",{});var hCt=s(w_e);xjo=r(hCt,"fnet"),hCt.forEach(t),$jo=r(hBe," \u2014 "),mX=n(hBe,"A",{href:!0});var pCt=s(mX);kjo=r(pCt,"FNetForMaskedLM"),pCt.forEach(t),Sjo=r(hBe," (FNet model)"),hBe.forEach(t),Rjo=i(Y),b4=n(Y,"LI",{});var pBe=s(b4);A_e=n(pBe,"STRONG",{});var _Ct=s(A_e);Pjo=r(_Ct,"funnel"),_Ct.forEach(t),Bjo=r(pBe," \u2014 "),gX=n(pBe,"A",{href:!0});var uCt=s(gX);Ijo=r(uCt,"FunnelForMaskedLM"),uCt.forEach(t),Njo=r(pBe," (Funnel Transformer model)"),pBe.forEach(t),qjo=i(Y),v4=n(Y,"LI",{});var _Be=s(v4);L_e=n(_Be,"STRONG",{});var bCt=s(L_e);jjo=r(bCt,"ibert"),bCt.forEach(t),Djo=r(_Be," \u2014 "),hX=n(_Be,"A",{href:!0});var vCt=s(hX);Gjo=r(vCt,"IBertForMaskedLM"),vCt.forEach(t),Ojo=r(_Be," (I-BERT model)"),_Be.forEach(t),Vjo=i(Y),F4=n(Y,"LI",{});var uBe=s(F4);y_e=n(uBe,"STRONG",{});var FCt=s(y_e);Xjo=r(FCt,"layoutlm"),FCt.forEach(t),zjo=r(uBe," \u2014 "),pX=n(uBe,"A",{href:!0});var TCt=s(pX);Wjo=r(TCt,"LayoutLMForMaskedLM"),TCt.forEach(t),Qjo=r(uBe," (LayoutLM model)"),uBe.forEach(t),Ujo=i(Y),T4=n(Y,"LI",{});var bBe=s(T4);x_e=n(bBe,"STRONG",{});var MCt=s(x_e);Hjo=r(MCt,"longformer"),MCt.forEach(t),Jjo=r(bBe," \u2014 "),_X=n(bBe,"A",{href:!0});var ECt=s(_X);Yjo=r(ECt,"LongformerForMaskedLM"),ECt.forEach(t),Kjo=r(bBe," (Longformer model)"),bBe.forEach(t),Zjo=i(Y),M4=n(Y,"LI",{});var vBe=s(M4);$_e=n(vBe,"STRONG",{});var CCt=s($_e);eDo=r(CCt,"luke"),CCt.forEach(t),oDo=r(vBe," \u2014 "),uX=n(vBe,"A",{href:!0});var wCt=s(uX);rDo=r(wCt,"LukeForMaskedLM"),wCt.forEach(t),tDo=r(vBe," (LUKE model)"),vBe.forEach(t),aDo=i(Y),E4=n(Y,"LI",{});var FBe=s(E4);k_e=n(FBe,"STRONG",{});var ACt=s(k_e);nDo=r(ACt,"mbart"),ACt.forEach(t),sDo=r(FBe," \u2014 "),bX=n(FBe,"A",{href:!0});var LCt=s(bX);lDo=r(LCt,"MBartForConditionalGeneration"),LCt.forEach(t),iDo=r(FBe," (mBART model)"),FBe.forEach(t),dDo=i(Y),C4=n(Y,"LI",{});var TBe=s(C4);S_e=n(TBe,"STRONG",{});var yCt=s(S_e);cDo=r(yCt,"megatron-bert"),yCt.forEach(t),fDo=r(TBe," \u2014 "),vX=n(TBe,"A",{href:!0});var xCt=s(vX);mDo=r(xCt,"MegatronBertForMaskedLM"),xCt.forEach(t),gDo=r(TBe," (Megatron-BERT model)"),TBe.forEach(t),hDo=i(Y),w4=n(Y,"LI",{});var MBe=s(w4);R_e=n(MBe,"STRONG",{});var $Ct=s(R_e);pDo=r($Ct,"mobilebert"),$Ct.forEach(t),_Do=r(MBe," \u2014 "),FX=n(MBe,"A",{href:!0});var kCt=s(FX);uDo=r(kCt,"MobileBertForMaskedLM"),kCt.forEach(t),bDo=r(MBe," (MobileBERT model)"),MBe.forEach(t),vDo=i(Y),A4=n(Y,"LI",{});var EBe=s(A4);P_e=n(EBe,"STRONG",{});var SCt=s(P_e);FDo=r(SCt,"mpnet"),SCt.forEach(t),TDo=r(EBe," \u2014 "),TX=n(EBe,"A",{href:!0});var RCt=s(TX);MDo=r(RCt,"MPNetForMaskedLM"),RCt.forEach(t),EDo=r(EBe," (MPNet model)"),EBe.forEach(t),CDo=i(Y),L4=n(Y,"LI",{});var CBe=s(L4);B_e=n(CBe,"STRONG",{});var PCt=s(B_e);wDo=r(PCt,"mvp"),PCt.forEach(t),ADo=r(CBe," \u2014 "),MX=n(CBe,"A",{href:!0});var BCt=s(MX);LDo=r(BCt,"MvpForConditionalGeneration"),BCt.forEach(t),yDo=r(CBe," (MVP model)"),CBe.forEach(t),xDo=i(Y),y4=n(Y,"LI",{});var wBe=s(y4);I_e=n(wBe,"STRONG",{});var ICt=s(I_e);$Do=r(ICt,"nezha"),ICt.forEach(t),kDo=r(wBe," \u2014 "),EX=n(wBe,"A",{href:!0});var NCt=s(EX);SDo=r(NCt,"NezhaForMaskedLM"),NCt.forEach(t),RDo=r(wBe," (Nezha model)"),wBe.forEach(t),PDo=i(Y),x4=n(Y,"LI",{});var ABe=s(x4);N_e=n(ABe,"STRONG",{});var qCt=s(N_e);BDo=r(qCt,"nystromformer"),qCt.forEach(t),IDo=r(ABe," \u2014 "),CX=n(ABe,"A",{href:!0});var jCt=s(CX);NDo=r(jCt,"NystromformerForMaskedLM"),jCt.forEach(t),qDo=r(ABe," (Nystr\xF6mformer model)"),ABe.forEach(t),jDo=i(Y),$4=n(Y,"LI",{});var LBe=s($4);q_e=n(LBe,"STRONG",{});var DCt=s(q_e);DDo=r(DCt,"perceiver"),DCt.forEach(t),GDo=r(LBe," \u2014 "),wX=n(LBe,"A",{href:!0});var GCt=s(wX);ODo=r(GCt,"PerceiverForMaskedLM"),GCt.forEach(t),VDo=r(LBe," (Perceiver model)"),LBe.forEach(t),XDo=i(Y),k4=n(Y,"LI",{});var yBe=s(k4);j_e=n(yBe,"STRONG",{});var OCt=s(j_e);zDo=r(OCt,"qdqbert"),OCt.forEach(t),WDo=r(yBe," \u2014 "),AX=n(yBe,"A",{href:!0});var VCt=s(AX);QDo=r(VCt,"QDQBertForMaskedLM"),VCt.forEach(t),UDo=r(yBe," (QDQBert model)"),yBe.forEach(t),HDo=i(Y),S4=n(Y,"LI",{});var xBe=s(S4);D_e=n(xBe,"STRONG",{});var XCt=s(D_e);JDo=r(XCt,"reformer"),XCt.forEach(t),YDo=r(xBe," \u2014 "),LX=n(xBe,"A",{href:!0});var zCt=s(LX);KDo=r(zCt,"ReformerForMaskedLM"),zCt.forEach(t),ZDo=r(xBe," (Reformer model)"),xBe.forEach(t),eGo=i(Y),R4=n(Y,"LI",{});var $Be=s(R4);G_e=n($Be,"STRONG",{});var WCt=s(G_e);oGo=r(WCt,"rembert"),WCt.forEach(t),rGo=r($Be," \u2014 "),yX=n($Be,"A",{href:!0});var QCt=s(yX);tGo=r(QCt,"RemBertForMaskedLM"),QCt.forEach(t),aGo=r($Be," (RemBERT model)"),$Be.forEach(t),nGo=i(Y),P4=n(Y,"LI",{});var kBe=s(P4);O_e=n(kBe,"STRONG",{});var UCt=s(O_e);sGo=r(UCt,"roberta"),UCt.forEach(t),lGo=r(kBe," \u2014 "),xX=n(kBe,"A",{href:!0});var HCt=s(xX);iGo=r(HCt,"RobertaForMaskedLM"),HCt.forEach(t),dGo=r(kBe," (RoBERTa model)"),kBe.forEach(t),cGo=i(Y),B4=n(Y,"LI",{});var SBe=s(B4);V_e=n(SBe,"STRONG",{});var JCt=s(V_e);fGo=r(JCt,"roformer"),JCt.forEach(t),mGo=r(SBe," \u2014 "),$X=n(SBe,"A",{href:!0});var YCt=s($X);gGo=r(YCt,"RoFormerForMaskedLM"),YCt.forEach(t),hGo=r(SBe," (RoFormer model)"),SBe.forEach(t),pGo=i(Y),I4=n(Y,"LI",{});var RBe=s(I4);X_e=n(RBe,"STRONG",{});var KCt=s(X_e);_Go=r(KCt,"squeezebert"),KCt.forEach(t),uGo=r(RBe," \u2014 "),kX=n(RBe,"A",{href:!0});var ZCt=s(kX);bGo=r(ZCt,"SqueezeBertForMaskedLM"),ZCt.forEach(t),vGo=r(RBe," (SqueezeBERT model)"),RBe.forEach(t),FGo=i(Y),N4=n(Y,"LI",{});var PBe=s(N4);z_e=n(PBe,"STRONG",{});var e3t=s(z_e);TGo=r(e3t,"tapas"),e3t.forEach(t),MGo=r(PBe," \u2014 "),SX=n(PBe,"A",{href:!0});var o3t=s(SX);EGo=r(o3t,"TapasForMaskedLM"),o3t.forEach(t),CGo=r(PBe," (TAPAS model)"),PBe.forEach(t),wGo=i(Y),q4=n(Y,"LI",{});var BBe=s(q4);W_e=n(BBe,"STRONG",{});var r3t=s(W_e);AGo=r(r3t,"wav2vec2"),r3t.forEach(t),LGo=r(BBe," \u2014 "),Q_e=n(BBe,"CODE",{});var t3t=s(Q_e);yGo=r(t3t,"Wav2Vec2ForMaskedLM"),t3t.forEach(t),xGo=r(BBe," (Wav2Vec2 model)"),BBe.forEach(t),$Go=i(Y),j4=n(Y,"LI",{});var IBe=s(j4);U_e=n(IBe,"STRONG",{});var a3t=s(U_e);kGo=r(a3t,"xlm"),a3t.forEach(t),SGo=r(IBe," \u2014 "),RX=n(IBe,"A",{href:!0});var n3t=s(RX);RGo=r(n3t,"XLMWithLMHeadModel"),n3t.forEach(t),PGo=r(IBe," (XLM model)"),IBe.forEach(t),BGo=i(Y),D4=n(Y,"LI",{});var NBe=s(D4);H_e=n(NBe,"STRONG",{});var s3t=s(H_e);IGo=r(s3t,"xlm-roberta"),s3t.forEach(t),NGo=r(NBe," \u2014 "),PX=n(NBe,"A",{href:!0});var l3t=s(PX);qGo=r(l3t,"XLMRobertaForMaskedLM"),l3t.forEach(t),jGo=r(NBe," (XLM-RoBERTa model)"),NBe.forEach(t),DGo=i(Y),G4=n(Y,"LI",{});var qBe=s(G4);J_e=n(qBe,"STRONG",{});var i3t=s(J_e);GGo=r(i3t,"xlm-roberta-xl"),i3t.forEach(t),OGo=r(qBe," \u2014 "),BX=n(qBe,"A",{href:!0});var d3t=s(BX);VGo=r(d3t,"XLMRobertaXLForMaskedLM"),d3t.forEach(t),XGo=r(qBe," (XLM-RoBERTa-XL model)"),qBe.forEach(t),zGo=i(Y),O4=n(Y,"LI",{});var jBe=s(O4);Y_e=n(jBe,"STRONG",{});var c3t=s(Y_e);WGo=r(c3t,"yoso"),c3t.forEach(t),QGo=r(jBe," \u2014 "),IX=n(jBe,"A",{href:!0});var f3t=s(IX);UGo=r(f3t,"YosoForMaskedLM"),f3t.forEach(t),HGo=r(jBe," (YOSO model)"),jBe.forEach(t),Y.forEach(t),JGo=i(ga),V4=n(ga,"P",{});var DBe=s(V4);YGo=r(DBe,"The model is set in evaluation mode by default using "),K_e=n(DBe,"CODE",{});var m3t=s(K_e);KGo=r(m3t,"model.eval()"),m3t.forEach(t),ZGo=r(DBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Z_e=n(DBe,"CODE",{});var g3t=s(Z_e);eOo=r(g3t,"model.train()"),g3t.forEach(t),DBe.forEach(t),oOo=i(ga),T(X4.$$.fragment,ga),ga.forEach(t),gl.forEach(t),sQe=i(f),id=n(f,"H2",{class:!0});var hHe=s(id);z4=n(hHe,"A",{id:!0,class:!0,href:!0});var h3t=s(z4);eue=n(h3t,"SPAN",{});var p3t=s(eue);T(jy.$$.fragment,p3t),p3t.forEach(t),h3t.forEach(t),rOo=i(hHe),oue=n(hHe,"SPAN",{});var _3t=s(oue);tOo=r(_3t,"AutoModelForSeq2SeqLM"),_3t.forEach(t),hHe.forEach(t),lQe=i(f),Io=n(f,"DIV",{class:!0});var hl=s(Io);T(Dy.$$.fragment,hl),aOo=i(hl),dd=n(hl,"P",{});var gae=s(dd);nOo=r(gae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),NX=n(gae,"A",{href:!0});var u3t=s(NX);sOo=r(u3t,"from_pretrained()"),u3t.forEach(t),lOo=r(gae," class method or the "),qX=n(gae,"A",{href:!0});var b3t=s(qX);iOo=r(b3t,"from_config()"),b3t.forEach(t),dOo=r(gae,` class
method.`),gae.forEach(t),cOo=i(hl),Gy=n(hl,"P",{});var pHe=s(Gy);fOo=r(pHe,"This class cannot be instantiated directly using "),rue=n(pHe,"CODE",{});var v3t=s(rue);mOo=r(v3t,"__init__()"),v3t.forEach(t),gOo=r(pHe," (throws an error)."),pHe.forEach(t),hOo=i(hl),ht=n(hl,"DIV",{class:!0});var r7=s(ht);T(Oy.$$.fragment,r7),pOo=i(r7),tue=n(r7,"P",{});var F3t=s(tue);_Oo=r(F3t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),F3t.forEach(t),uOo=i(r7),cd=n(r7,"P",{});var hae=s(cd);bOo=r(hae,`Note:
Loading a model from its configuration file does `),aue=n(hae,"STRONG",{});var T3t=s(aue);vOo=r(T3t,"not"),T3t.forEach(t),FOo=r(hae,` load the model weights. It only affects the
model\u2019s configuration. Use `),jX=n(hae,"A",{href:!0});var M3t=s(jX);TOo=r(M3t,"from_pretrained()"),M3t.forEach(t),MOo=r(hae," to load the model weights."),hae.forEach(t),EOo=i(r7),T(W4.$$.fragment,r7),r7.forEach(t),COo=i(hl),oo=n(hl,"DIV",{class:!0});var ha=s(oo);T(Vy.$$.fragment,ha),wOo=i(ha),nue=n(ha,"P",{});var E3t=s(nue);AOo=r(E3t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),E3t.forEach(t),LOo=i(ha),Xa=n(ha,"P",{});var t7=s(Xa);yOo=r(t7,"The model class to instantiate is selected based on the "),sue=n(t7,"CODE",{});var C3t=s(sue);xOo=r(C3t,"model_type"),C3t.forEach(t),$Oo=r(t7,` property of the config object (either
passed as an argument or loaded from `),lue=n(t7,"CODE",{});var w3t=s(lue);kOo=r(w3t,"pretrained_model_name_or_path"),w3t.forEach(t),SOo=r(t7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iue=n(t7,"CODE",{});var A3t=s(iue);ROo=r(A3t,"pretrained_model_name_or_path"),A3t.forEach(t),POo=r(t7,":"),t7.forEach(t),BOo=i(ha),me=n(ha,"UL",{});var ue=s(me);Q4=n(ue,"LI",{});var GBe=s(Q4);due=n(GBe,"STRONG",{});var L3t=s(due);IOo=r(L3t,"bart"),L3t.forEach(t),NOo=r(GBe," \u2014 "),DX=n(GBe,"A",{href:!0});var y3t=s(DX);qOo=r(y3t,"BartForConditionalGeneration"),y3t.forEach(t),jOo=r(GBe," (BART model)"),GBe.forEach(t),DOo=i(ue),U4=n(ue,"LI",{});var OBe=s(U4);cue=n(OBe,"STRONG",{});var x3t=s(cue);GOo=r(x3t,"bigbird_pegasus"),x3t.forEach(t),OOo=r(OBe," \u2014 "),GX=n(OBe,"A",{href:!0});var $3t=s(GX);VOo=r($3t,"BigBirdPegasusForConditionalGeneration"),$3t.forEach(t),XOo=r(OBe," (BigBird-Pegasus model)"),OBe.forEach(t),zOo=i(ue),H4=n(ue,"LI",{});var VBe=s(H4);fue=n(VBe,"STRONG",{});var k3t=s(fue);WOo=r(k3t,"blenderbot"),k3t.forEach(t),QOo=r(VBe," \u2014 "),OX=n(VBe,"A",{href:!0});var S3t=s(OX);UOo=r(S3t,"BlenderbotForConditionalGeneration"),S3t.forEach(t),HOo=r(VBe," (Blenderbot model)"),VBe.forEach(t),JOo=i(ue),J4=n(ue,"LI",{});var XBe=s(J4);mue=n(XBe,"STRONG",{});var R3t=s(mue);YOo=r(R3t,"blenderbot-small"),R3t.forEach(t),KOo=r(XBe," \u2014 "),VX=n(XBe,"A",{href:!0});var P3t=s(VX);ZOo=r(P3t,"BlenderbotSmallForConditionalGeneration"),P3t.forEach(t),eVo=r(XBe," (BlenderbotSmall model)"),XBe.forEach(t),oVo=i(ue),Y4=n(ue,"LI",{});var zBe=s(Y4);gue=n(zBe,"STRONG",{});var B3t=s(gue);rVo=r(B3t,"encoder-decoder"),B3t.forEach(t),tVo=r(zBe," \u2014 "),XX=n(zBe,"A",{href:!0});var I3t=s(XX);aVo=r(I3t,"EncoderDecoderModel"),I3t.forEach(t),nVo=r(zBe," (Encoder decoder model)"),zBe.forEach(t),sVo=i(ue),K4=n(ue,"LI",{});var WBe=s(K4);hue=n(WBe,"STRONG",{});var N3t=s(hue);lVo=r(N3t,"fsmt"),N3t.forEach(t),iVo=r(WBe," \u2014 "),zX=n(WBe,"A",{href:!0});var q3t=s(zX);dVo=r(q3t,"FSMTForConditionalGeneration"),q3t.forEach(t),cVo=r(WBe," (FairSeq Machine-Translation model)"),WBe.forEach(t),fVo=i(ue),Z4=n(ue,"LI",{});var QBe=s(Z4);pue=n(QBe,"STRONG",{});var j3t=s(pue);mVo=r(j3t,"led"),j3t.forEach(t),gVo=r(QBe," \u2014 "),WX=n(QBe,"A",{href:!0});var D3t=s(WX);hVo=r(D3t,"LEDForConditionalGeneration"),D3t.forEach(t),pVo=r(QBe," (LED model)"),QBe.forEach(t),_Vo=i(ue),eb=n(ue,"LI",{});var UBe=s(eb);_ue=n(UBe,"STRONG",{});var G3t=s(_ue);uVo=r(G3t,"longt5"),G3t.forEach(t),bVo=r(UBe," \u2014 "),QX=n(UBe,"A",{href:!0});var O3t=s(QX);vVo=r(O3t,"LongT5ForConditionalGeneration"),O3t.forEach(t),FVo=r(UBe," (LongT5 model)"),UBe.forEach(t),TVo=i(ue),ob=n(ue,"LI",{});var HBe=s(ob);uue=n(HBe,"STRONG",{});var V3t=s(uue);MVo=r(V3t,"m2m_100"),V3t.forEach(t),EVo=r(HBe," \u2014 "),UX=n(HBe,"A",{href:!0});var X3t=s(UX);CVo=r(X3t,"M2M100ForConditionalGeneration"),X3t.forEach(t),wVo=r(HBe," (M2M100 model)"),HBe.forEach(t),AVo=i(ue),rb=n(ue,"LI",{});var JBe=s(rb);bue=n(JBe,"STRONG",{});var z3t=s(bue);LVo=r(z3t,"marian"),z3t.forEach(t),yVo=r(JBe," \u2014 "),HX=n(JBe,"A",{href:!0});var W3t=s(HX);xVo=r(W3t,"MarianMTModel"),W3t.forEach(t),$Vo=r(JBe," (Marian model)"),JBe.forEach(t),kVo=i(ue),tb=n(ue,"LI",{});var YBe=s(tb);vue=n(YBe,"STRONG",{});var Q3t=s(vue);SVo=r(Q3t,"mbart"),Q3t.forEach(t),RVo=r(YBe," \u2014 "),JX=n(YBe,"A",{href:!0});var U3t=s(JX);PVo=r(U3t,"MBartForConditionalGeneration"),U3t.forEach(t),BVo=r(YBe," (mBART model)"),YBe.forEach(t),IVo=i(ue),ab=n(ue,"LI",{});var KBe=s(ab);Fue=n(KBe,"STRONG",{});var H3t=s(Fue);NVo=r(H3t,"mt5"),H3t.forEach(t),qVo=r(KBe," \u2014 "),YX=n(KBe,"A",{href:!0});var J3t=s(YX);jVo=r(J3t,"MT5ForConditionalGeneration"),J3t.forEach(t),DVo=r(KBe," (MT5 model)"),KBe.forEach(t),GVo=i(ue),nb=n(ue,"LI",{});var ZBe=s(nb);Tue=n(ZBe,"STRONG",{});var Y3t=s(Tue);OVo=r(Y3t,"mvp"),Y3t.forEach(t),VVo=r(ZBe," \u2014 "),KX=n(ZBe,"A",{href:!0});var K3t=s(KX);XVo=r(K3t,"MvpForConditionalGeneration"),K3t.forEach(t),zVo=r(ZBe," (MVP model)"),ZBe.forEach(t),WVo=i(ue),sb=n(ue,"LI",{});var eIe=s(sb);Mue=n(eIe,"STRONG",{});var Z3t=s(Mue);QVo=r(Z3t,"nllb"),Z3t.forEach(t),UVo=r(eIe," \u2014 "),ZX=n(eIe,"A",{href:!0});var e0t=s(ZX);HVo=r(e0t,"M2M100ForConditionalGeneration"),e0t.forEach(t),JVo=r(eIe," (NLLB model)"),eIe.forEach(t),YVo=i(ue),lb=n(ue,"LI",{});var oIe=s(lb);Eue=n(oIe,"STRONG",{});var o0t=s(Eue);KVo=r(o0t,"pegasus"),o0t.forEach(t),ZVo=r(oIe," \u2014 "),ez=n(oIe,"A",{href:!0});var r0t=s(ez);eXo=r(r0t,"PegasusForConditionalGeneration"),r0t.forEach(t),oXo=r(oIe," (Pegasus model)"),oIe.forEach(t),rXo=i(ue),ib=n(ue,"LI",{});var rIe=s(ib);Cue=n(rIe,"STRONG",{});var t0t=s(Cue);tXo=r(t0t,"plbart"),t0t.forEach(t),aXo=r(rIe," \u2014 "),oz=n(rIe,"A",{href:!0});var a0t=s(oz);nXo=r(a0t,"PLBartForConditionalGeneration"),a0t.forEach(t),sXo=r(rIe," (PLBart model)"),rIe.forEach(t),lXo=i(ue),db=n(ue,"LI",{});var tIe=s(db);wue=n(tIe,"STRONG",{});var n0t=s(wue);iXo=r(n0t,"prophetnet"),n0t.forEach(t),dXo=r(tIe," \u2014 "),rz=n(tIe,"A",{href:!0});var s0t=s(rz);cXo=r(s0t,"ProphetNetForConditionalGeneration"),s0t.forEach(t),fXo=r(tIe," (ProphetNet model)"),tIe.forEach(t),mXo=i(ue),cb=n(ue,"LI",{});var aIe=s(cb);Aue=n(aIe,"STRONG",{});var l0t=s(Aue);gXo=r(l0t,"t5"),l0t.forEach(t),hXo=r(aIe," \u2014 "),tz=n(aIe,"A",{href:!0});var i0t=s(tz);pXo=r(i0t,"T5ForConditionalGeneration"),i0t.forEach(t),_Xo=r(aIe," (T5 model)"),aIe.forEach(t),uXo=i(ue),fb=n(ue,"LI",{});var nIe=s(fb);Lue=n(nIe,"STRONG",{});var d0t=s(Lue);bXo=r(d0t,"xlm-prophetnet"),d0t.forEach(t),vXo=r(nIe," \u2014 "),az=n(nIe,"A",{href:!0});var c0t=s(az);FXo=r(c0t,"XLMProphetNetForConditionalGeneration"),c0t.forEach(t),TXo=r(nIe," (XLM-ProphetNet model)"),nIe.forEach(t),ue.forEach(t),MXo=i(ha),mb=n(ha,"P",{});var sIe=s(mb);EXo=r(sIe,"The model is set in evaluation mode by default using "),yue=n(sIe,"CODE",{});var f0t=s(yue);CXo=r(f0t,"model.eval()"),f0t.forEach(t),wXo=r(sIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),xue=n(sIe,"CODE",{});var m0t=s(xue);AXo=r(m0t,"model.train()"),m0t.forEach(t),sIe.forEach(t),LXo=i(ha),T(gb.$$.fragment,ha),ha.forEach(t),hl.forEach(t),iQe=i(f),fd=n(f,"H2",{class:!0});var _He=s(fd);hb=n(_He,"A",{id:!0,class:!0,href:!0});var g0t=s(hb);$ue=n(g0t,"SPAN",{});var h0t=s($ue);T(Xy.$$.fragment,h0t),h0t.forEach(t),g0t.forEach(t),yXo=i(_He),kue=n(_He,"SPAN",{});var p0t=s(kue);xXo=r(p0t,"AutoModelForSequenceClassification"),p0t.forEach(t),_He.forEach(t),dQe=i(f),No=n(f,"DIV",{class:!0});var pl=s(No);T(zy.$$.fragment,pl),$Xo=i(pl),md=n(pl,"P",{});var pae=s(md);kXo=r(pae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nz=n(pae,"A",{href:!0});var _0t=s(nz);SXo=r(_0t,"from_pretrained()"),_0t.forEach(t),RXo=r(pae," class method or the "),sz=n(pae,"A",{href:!0});var u0t=s(sz);PXo=r(u0t,"from_config()"),u0t.forEach(t),BXo=r(pae,` class
method.`),pae.forEach(t),IXo=i(pl),Wy=n(pl,"P",{});var uHe=s(Wy);NXo=r(uHe,"This class cannot be instantiated directly using "),Sue=n(uHe,"CODE",{});var b0t=s(Sue);qXo=r(b0t,"__init__()"),b0t.forEach(t),jXo=r(uHe," (throws an error)."),uHe.forEach(t),DXo=i(pl),pt=n(pl,"DIV",{class:!0});var a7=s(pt);T(Qy.$$.fragment,a7),GXo=i(a7),Rue=n(a7,"P",{});var v0t=s(Rue);OXo=r(v0t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),v0t.forEach(t),VXo=i(a7),gd=n(a7,"P",{});var _ae=s(gd);XXo=r(_ae,`Note:
Loading a model from its configuration file does `),Pue=n(_ae,"STRONG",{});var F0t=s(Pue);zXo=r(F0t,"not"),F0t.forEach(t),WXo=r(_ae,` load the model weights. It only affects the
model\u2019s configuration. Use `),lz=n(_ae,"A",{href:!0});var T0t=s(lz);QXo=r(T0t,"from_pretrained()"),T0t.forEach(t),UXo=r(_ae," to load the model weights."),_ae.forEach(t),HXo=i(a7),T(pb.$$.fragment,a7),a7.forEach(t),JXo=i(pl),ro=n(pl,"DIV",{class:!0});var pa=s(ro);T(Uy.$$.fragment,pa),YXo=i(pa),Bue=n(pa,"P",{});var M0t=s(Bue);KXo=r(M0t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),M0t.forEach(t),ZXo=i(pa),za=n(pa,"P",{});var n7=s(za);ezo=r(n7,"The model class to instantiate is selected based on the "),Iue=n(n7,"CODE",{});var E0t=s(Iue);ozo=r(E0t,"model_type"),E0t.forEach(t),rzo=r(n7,` property of the config object (either
passed as an argument or loaded from `),Nue=n(n7,"CODE",{});var C0t=s(Nue);tzo=r(C0t,"pretrained_model_name_or_path"),C0t.forEach(t),azo=r(n7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),que=n(n7,"CODE",{});var w0t=s(que);nzo=r(w0t,"pretrained_model_name_or_path"),w0t.forEach(t),szo=r(n7,":"),n7.forEach(t),lzo=i(pa),B=n(pa,"UL",{});var j=s(B);_b=n(j,"LI",{});var lIe=s(_b);jue=n(lIe,"STRONG",{});var A0t=s(jue);izo=r(A0t,"albert"),A0t.forEach(t),dzo=r(lIe," \u2014 "),iz=n(lIe,"A",{href:!0});var L0t=s(iz);czo=r(L0t,"AlbertForSequenceClassification"),L0t.forEach(t),fzo=r(lIe," (ALBERT model)"),lIe.forEach(t),mzo=i(j),ub=n(j,"LI",{});var iIe=s(ub);Due=n(iIe,"STRONG",{});var y0t=s(Due);gzo=r(y0t,"bart"),y0t.forEach(t),hzo=r(iIe," \u2014 "),dz=n(iIe,"A",{href:!0});var x0t=s(dz);pzo=r(x0t,"BartForSequenceClassification"),x0t.forEach(t),_zo=r(iIe," (BART model)"),iIe.forEach(t),uzo=i(j),bb=n(j,"LI",{});var dIe=s(bb);Gue=n(dIe,"STRONG",{});var $0t=s(Gue);bzo=r($0t,"bert"),$0t.forEach(t),vzo=r(dIe," \u2014 "),cz=n(dIe,"A",{href:!0});var k0t=s(cz);Fzo=r(k0t,"BertForSequenceClassification"),k0t.forEach(t),Tzo=r(dIe," (BERT model)"),dIe.forEach(t),Mzo=i(j),vb=n(j,"LI",{});var cIe=s(vb);Oue=n(cIe,"STRONG",{});var S0t=s(Oue);Ezo=r(S0t,"big_bird"),S0t.forEach(t),Czo=r(cIe," \u2014 "),fz=n(cIe,"A",{href:!0});var R0t=s(fz);wzo=r(R0t,"BigBirdForSequenceClassification"),R0t.forEach(t),Azo=r(cIe," (BigBird model)"),cIe.forEach(t),Lzo=i(j),Fb=n(j,"LI",{});var fIe=s(Fb);Vue=n(fIe,"STRONG",{});var P0t=s(Vue);yzo=r(P0t,"bigbird_pegasus"),P0t.forEach(t),xzo=r(fIe," \u2014 "),mz=n(fIe,"A",{href:!0});var B0t=s(mz);$zo=r(B0t,"BigBirdPegasusForSequenceClassification"),B0t.forEach(t),kzo=r(fIe," (BigBird-Pegasus model)"),fIe.forEach(t),Szo=i(j),Tb=n(j,"LI",{});var mIe=s(Tb);Xue=n(mIe,"STRONG",{});var I0t=s(Xue);Rzo=r(I0t,"bloom"),I0t.forEach(t),Pzo=r(mIe," \u2014 "),gz=n(mIe,"A",{href:!0});var N0t=s(gz);Bzo=r(N0t,"BloomForSequenceClassification"),N0t.forEach(t),Izo=r(mIe," (BLOOM model)"),mIe.forEach(t),Nzo=i(j),Mb=n(j,"LI",{});var gIe=s(Mb);zue=n(gIe,"STRONG",{});var q0t=s(zue);qzo=r(q0t,"camembert"),q0t.forEach(t),jzo=r(gIe," \u2014 "),hz=n(gIe,"A",{href:!0});var j0t=s(hz);Dzo=r(j0t,"CamembertForSequenceClassification"),j0t.forEach(t),Gzo=r(gIe," (CamemBERT model)"),gIe.forEach(t),Ozo=i(j),Eb=n(j,"LI",{});var hIe=s(Eb);Wue=n(hIe,"STRONG",{});var D0t=s(Wue);Vzo=r(D0t,"canine"),D0t.forEach(t),Xzo=r(hIe," \u2014 "),pz=n(hIe,"A",{href:!0});var G0t=s(pz);zzo=r(G0t,"CanineForSequenceClassification"),G0t.forEach(t),Wzo=r(hIe," (CANINE model)"),hIe.forEach(t),Qzo=i(j),Cb=n(j,"LI",{});var pIe=s(Cb);Que=n(pIe,"STRONG",{});var O0t=s(Que);Uzo=r(O0t,"convbert"),O0t.forEach(t),Hzo=r(pIe," \u2014 "),_z=n(pIe,"A",{href:!0});var V0t=s(_z);Jzo=r(V0t,"ConvBertForSequenceClassification"),V0t.forEach(t),Yzo=r(pIe," (ConvBERT model)"),pIe.forEach(t),Kzo=i(j),wb=n(j,"LI",{});var _Ie=s(wb);Uue=n(_Ie,"STRONG",{});var X0t=s(Uue);Zzo=r(X0t,"ctrl"),X0t.forEach(t),eWo=r(_Ie," \u2014 "),uz=n(_Ie,"A",{href:!0});var z0t=s(uz);oWo=r(z0t,"CTRLForSequenceClassification"),z0t.forEach(t),rWo=r(_Ie," (CTRL model)"),_Ie.forEach(t),tWo=i(j),Ab=n(j,"LI",{});var uIe=s(Ab);Hue=n(uIe,"STRONG",{});var W0t=s(Hue);aWo=r(W0t,"data2vec-text"),W0t.forEach(t),nWo=r(uIe," \u2014 "),bz=n(uIe,"A",{href:!0});var Q0t=s(bz);sWo=r(Q0t,"Data2VecTextForSequenceClassification"),Q0t.forEach(t),lWo=r(uIe," (Data2VecText model)"),uIe.forEach(t),iWo=i(j),Lb=n(j,"LI",{});var bIe=s(Lb);Jue=n(bIe,"STRONG",{});var U0t=s(Jue);dWo=r(U0t,"deberta"),U0t.forEach(t),cWo=r(bIe," \u2014 "),vz=n(bIe,"A",{href:!0});var H0t=s(vz);fWo=r(H0t,"DebertaForSequenceClassification"),H0t.forEach(t),mWo=r(bIe," (DeBERTa model)"),bIe.forEach(t),gWo=i(j),yb=n(j,"LI",{});var vIe=s(yb);Yue=n(vIe,"STRONG",{});var J0t=s(Yue);hWo=r(J0t,"deberta-v2"),J0t.forEach(t),pWo=r(vIe," \u2014 "),Fz=n(vIe,"A",{href:!0});var Y0t=s(Fz);_Wo=r(Y0t,"DebertaV2ForSequenceClassification"),Y0t.forEach(t),uWo=r(vIe," (DeBERTa-v2 model)"),vIe.forEach(t),bWo=i(j),xb=n(j,"LI",{});var FIe=s(xb);Kue=n(FIe,"STRONG",{});var K0t=s(Kue);vWo=r(K0t,"distilbert"),K0t.forEach(t),FWo=r(FIe," \u2014 "),Tz=n(FIe,"A",{href:!0});var Z0t=s(Tz);TWo=r(Z0t,"DistilBertForSequenceClassification"),Z0t.forEach(t),MWo=r(FIe," (DistilBERT model)"),FIe.forEach(t),EWo=i(j),$b=n(j,"LI",{});var TIe=s($b);Zue=n(TIe,"STRONG",{});var ewt=s(Zue);CWo=r(ewt,"electra"),ewt.forEach(t),wWo=r(TIe," \u2014 "),Mz=n(TIe,"A",{href:!0});var owt=s(Mz);AWo=r(owt,"ElectraForSequenceClassification"),owt.forEach(t),LWo=r(TIe," (ELECTRA model)"),TIe.forEach(t),yWo=i(j),kb=n(j,"LI",{});var MIe=s(kb);e2e=n(MIe,"STRONG",{});var rwt=s(e2e);xWo=r(rwt,"flaubert"),rwt.forEach(t),$Wo=r(MIe," \u2014 "),Ez=n(MIe,"A",{href:!0});var twt=s(Ez);kWo=r(twt,"FlaubertForSequenceClassification"),twt.forEach(t),SWo=r(MIe," (FlauBERT model)"),MIe.forEach(t),RWo=i(j),Sb=n(j,"LI",{});var EIe=s(Sb);o2e=n(EIe,"STRONG",{});var awt=s(o2e);PWo=r(awt,"fnet"),awt.forEach(t),BWo=r(EIe," \u2014 "),Cz=n(EIe,"A",{href:!0});var nwt=s(Cz);IWo=r(nwt,"FNetForSequenceClassification"),nwt.forEach(t),NWo=r(EIe," (FNet model)"),EIe.forEach(t),qWo=i(j),Rb=n(j,"LI",{});var CIe=s(Rb);r2e=n(CIe,"STRONG",{});var swt=s(r2e);jWo=r(swt,"funnel"),swt.forEach(t),DWo=r(CIe," \u2014 "),wz=n(CIe,"A",{href:!0});var lwt=s(wz);GWo=r(lwt,"FunnelForSequenceClassification"),lwt.forEach(t),OWo=r(CIe," (Funnel Transformer model)"),CIe.forEach(t),VWo=i(j),Pb=n(j,"LI",{});var wIe=s(Pb);t2e=n(wIe,"STRONG",{});var iwt=s(t2e);XWo=r(iwt,"gpt2"),iwt.forEach(t),zWo=r(wIe," \u2014 "),Az=n(wIe,"A",{href:!0});var dwt=s(Az);WWo=r(dwt,"GPT2ForSequenceClassification"),dwt.forEach(t),QWo=r(wIe," (OpenAI GPT-2 model)"),wIe.forEach(t),UWo=i(j),Bb=n(j,"LI",{});var AIe=s(Bb);a2e=n(AIe,"STRONG",{});var cwt=s(a2e);HWo=r(cwt,"gpt_neo"),cwt.forEach(t),JWo=r(AIe," \u2014 "),Lz=n(AIe,"A",{href:!0});var fwt=s(Lz);YWo=r(fwt,"GPTNeoForSequenceClassification"),fwt.forEach(t),KWo=r(AIe," (GPT Neo model)"),AIe.forEach(t),ZWo=i(j),Ib=n(j,"LI",{});var LIe=s(Ib);n2e=n(LIe,"STRONG",{});var mwt=s(n2e);eQo=r(mwt,"gptj"),mwt.forEach(t),oQo=r(LIe," \u2014 "),yz=n(LIe,"A",{href:!0});var gwt=s(yz);rQo=r(gwt,"GPTJForSequenceClassification"),gwt.forEach(t),tQo=r(LIe," (GPT-J model)"),LIe.forEach(t),aQo=i(j),Nb=n(j,"LI",{});var yIe=s(Nb);s2e=n(yIe,"STRONG",{});var hwt=s(s2e);nQo=r(hwt,"ibert"),hwt.forEach(t),sQo=r(yIe," \u2014 "),xz=n(yIe,"A",{href:!0});var pwt=s(xz);lQo=r(pwt,"IBertForSequenceClassification"),pwt.forEach(t),iQo=r(yIe," (I-BERT model)"),yIe.forEach(t),dQo=i(j),qb=n(j,"LI",{});var xIe=s(qb);l2e=n(xIe,"STRONG",{});var _wt=s(l2e);cQo=r(_wt,"layoutlm"),_wt.forEach(t),fQo=r(xIe," \u2014 "),$z=n(xIe,"A",{href:!0});var uwt=s($z);mQo=r(uwt,"LayoutLMForSequenceClassification"),uwt.forEach(t),gQo=r(xIe," (LayoutLM model)"),xIe.forEach(t),hQo=i(j),jb=n(j,"LI",{});var $Ie=s(jb);i2e=n($Ie,"STRONG",{});var bwt=s(i2e);pQo=r(bwt,"layoutlmv2"),bwt.forEach(t),_Qo=r($Ie," \u2014 "),kz=n($Ie,"A",{href:!0});var vwt=s(kz);uQo=r(vwt,"LayoutLMv2ForSequenceClassification"),vwt.forEach(t),bQo=r($Ie," (LayoutLMv2 model)"),$Ie.forEach(t),vQo=i(j),Db=n(j,"LI",{});var kIe=s(Db);d2e=n(kIe,"STRONG",{});var Fwt=s(d2e);FQo=r(Fwt,"layoutlmv3"),Fwt.forEach(t),TQo=r(kIe," \u2014 "),Sz=n(kIe,"A",{href:!0});var Twt=s(Sz);MQo=r(Twt,"LayoutLMv3ForSequenceClassification"),Twt.forEach(t),EQo=r(kIe," (LayoutLMv3 model)"),kIe.forEach(t),CQo=i(j),Gb=n(j,"LI",{});var SIe=s(Gb);c2e=n(SIe,"STRONG",{});var Mwt=s(c2e);wQo=r(Mwt,"led"),Mwt.forEach(t),AQo=r(SIe," \u2014 "),Rz=n(SIe,"A",{href:!0});var Ewt=s(Rz);LQo=r(Ewt,"LEDForSequenceClassification"),Ewt.forEach(t),yQo=r(SIe," (LED model)"),SIe.forEach(t),xQo=i(j),Ob=n(j,"LI",{});var RIe=s(Ob);f2e=n(RIe,"STRONG",{});var Cwt=s(f2e);$Qo=r(Cwt,"longformer"),Cwt.forEach(t),kQo=r(RIe," \u2014 "),Pz=n(RIe,"A",{href:!0});var wwt=s(Pz);SQo=r(wwt,"LongformerForSequenceClassification"),wwt.forEach(t),RQo=r(RIe," (Longformer model)"),RIe.forEach(t),PQo=i(j),Vb=n(j,"LI",{});var PIe=s(Vb);m2e=n(PIe,"STRONG",{});var Awt=s(m2e);BQo=r(Awt,"luke"),Awt.forEach(t),IQo=r(PIe," \u2014 "),Bz=n(PIe,"A",{href:!0});var Lwt=s(Bz);NQo=r(Lwt,"LukeForSequenceClassification"),Lwt.forEach(t),qQo=r(PIe," (LUKE model)"),PIe.forEach(t),jQo=i(j),Xb=n(j,"LI",{});var BIe=s(Xb);g2e=n(BIe,"STRONG",{});var ywt=s(g2e);DQo=r(ywt,"mbart"),ywt.forEach(t),GQo=r(BIe," \u2014 "),Iz=n(BIe,"A",{href:!0});var xwt=s(Iz);OQo=r(xwt,"MBartForSequenceClassification"),xwt.forEach(t),VQo=r(BIe," (mBART model)"),BIe.forEach(t),XQo=i(j),zb=n(j,"LI",{});var IIe=s(zb);h2e=n(IIe,"STRONG",{});var $wt=s(h2e);zQo=r($wt,"megatron-bert"),$wt.forEach(t),WQo=r(IIe," \u2014 "),Nz=n(IIe,"A",{href:!0});var kwt=s(Nz);QQo=r(kwt,"MegatronBertForSequenceClassification"),kwt.forEach(t),UQo=r(IIe," (Megatron-BERT model)"),IIe.forEach(t),HQo=i(j),Wb=n(j,"LI",{});var NIe=s(Wb);p2e=n(NIe,"STRONG",{});var Swt=s(p2e);JQo=r(Swt,"mobilebert"),Swt.forEach(t),YQo=r(NIe," \u2014 "),qz=n(NIe,"A",{href:!0});var Rwt=s(qz);KQo=r(Rwt,"MobileBertForSequenceClassification"),Rwt.forEach(t),ZQo=r(NIe," (MobileBERT model)"),NIe.forEach(t),eUo=i(j),Qb=n(j,"LI",{});var qIe=s(Qb);_2e=n(qIe,"STRONG",{});var Pwt=s(_2e);oUo=r(Pwt,"mpnet"),Pwt.forEach(t),rUo=r(qIe," \u2014 "),jz=n(qIe,"A",{href:!0});var Bwt=s(jz);tUo=r(Bwt,"MPNetForSequenceClassification"),Bwt.forEach(t),aUo=r(qIe," (MPNet model)"),qIe.forEach(t),nUo=i(j),Ub=n(j,"LI",{});var jIe=s(Ub);u2e=n(jIe,"STRONG",{});var Iwt=s(u2e);sUo=r(Iwt,"mvp"),Iwt.forEach(t),lUo=r(jIe," \u2014 "),Dz=n(jIe,"A",{href:!0});var Nwt=s(Dz);iUo=r(Nwt,"MvpForSequenceClassification"),Nwt.forEach(t),dUo=r(jIe," (MVP model)"),jIe.forEach(t),cUo=i(j),Hb=n(j,"LI",{});var DIe=s(Hb);b2e=n(DIe,"STRONG",{});var qwt=s(b2e);fUo=r(qwt,"nezha"),qwt.forEach(t),mUo=r(DIe," \u2014 "),Gz=n(DIe,"A",{href:!0});var jwt=s(Gz);gUo=r(jwt,"NezhaForSequenceClassification"),jwt.forEach(t),hUo=r(DIe," (Nezha model)"),DIe.forEach(t),pUo=i(j),Jb=n(j,"LI",{});var GIe=s(Jb);v2e=n(GIe,"STRONG",{});var Dwt=s(v2e);_Uo=r(Dwt,"nystromformer"),Dwt.forEach(t),uUo=r(GIe," \u2014 "),Oz=n(GIe,"A",{href:!0});var Gwt=s(Oz);bUo=r(Gwt,"NystromformerForSequenceClassification"),Gwt.forEach(t),vUo=r(GIe," (Nystr\xF6mformer model)"),GIe.forEach(t),FUo=i(j),Yb=n(j,"LI",{});var OIe=s(Yb);F2e=n(OIe,"STRONG",{});var Owt=s(F2e);TUo=r(Owt,"openai-gpt"),Owt.forEach(t),MUo=r(OIe," \u2014 "),Vz=n(OIe,"A",{href:!0});var Vwt=s(Vz);EUo=r(Vwt,"OpenAIGPTForSequenceClassification"),Vwt.forEach(t),CUo=r(OIe," (OpenAI GPT model)"),OIe.forEach(t),wUo=i(j),Kb=n(j,"LI",{});var VIe=s(Kb);T2e=n(VIe,"STRONG",{});var Xwt=s(T2e);AUo=r(Xwt,"opt"),Xwt.forEach(t),LUo=r(VIe," \u2014 "),Xz=n(VIe,"A",{href:!0});var zwt=s(Xz);yUo=r(zwt,"OPTForSequenceClassification"),zwt.forEach(t),xUo=r(VIe," (OPT model)"),VIe.forEach(t),$Uo=i(j),Zb=n(j,"LI",{});var XIe=s(Zb);M2e=n(XIe,"STRONG",{});var Wwt=s(M2e);kUo=r(Wwt,"perceiver"),Wwt.forEach(t),SUo=r(XIe," \u2014 "),zz=n(XIe,"A",{href:!0});var Qwt=s(zz);RUo=r(Qwt,"PerceiverForSequenceClassification"),Qwt.forEach(t),PUo=r(XIe," (Perceiver model)"),XIe.forEach(t),BUo=i(j),ev=n(j,"LI",{});var zIe=s(ev);E2e=n(zIe,"STRONG",{});var Uwt=s(E2e);IUo=r(Uwt,"plbart"),Uwt.forEach(t),NUo=r(zIe," \u2014 "),Wz=n(zIe,"A",{href:!0});var Hwt=s(Wz);qUo=r(Hwt,"PLBartForSequenceClassification"),Hwt.forEach(t),jUo=r(zIe," (PLBart model)"),zIe.forEach(t),DUo=i(j),ov=n(j,"LI",{});var WIe=s(ov);C2e=n(WIe,"STRONG",{});var Jwt=s(C2e);GUo=r(Jwt,"qdqbert"),Jwt.forEach(t),OUo=r(WIe," \u2014 "),Qz=n(WIe,"A",{href:!0});var Ywt=s(Qz);VUo=r(Ywt,"QDQBertForSequenceClassification"),Ywt.forEach(t),XUo=r(WIe," (QDQBert model)"),WIe.forEach(t),zUo=i(j),rv=n(j,"LI",{});var QIe=s(rv);w2e=n(QIe,"STRONG",{});var Kwt=s(w2e);WUo=r(Kwt,"reformer"),Kwt.forEach(t),QUo=r(QIe," \u2014 "),Uz=n(QIe,"A",{href:!0});var Zwt=s(Uz);UUo=r(Zwt,"ReformerForSequenceClassification"),Zwt.forEach(t),HUo=r(QIe," (Reformer model)"),QIe.forEach(t),JUo=i(j),tv=n(j,"LI",{});var UIe=s(tv);A2e=n(UIe,"STRONG",{});var e6t=s(A2e);YUo=r(e6t,"rembert"),e6t.forEach(t),KUo=r(UIe," \u2014 "),Hz=n(UIe,"A",{href:!0});var o6t=s(Hz);ZUo=r(o6t,"RemBertForSequenceClassification"),o6t.forEach(t),eHo=r(UIe," (RemBERT model)"),UIe.forEach(t),oHo=i(j),av=n(j,"LI",{});var HIe=s(av);L2e=n(HIe,"STRONG",{});var r6t=s(L2e);rHo=r(r6t,"roberta"),r6t.forEach(t),tHo=r(HIe," \u2014 "),Jz=n(HIe,"A",{href:!0});var t6t=s(Jz);aHo=r(t6t,"RobertaForSequenceClassification"),t6t.forEach(t),nHo=r(HIe," (RoBERTa model)"),HIe.forEach(t),sHo=i(j),nv=n(j,"LI",{});var JIe=s(nv);y2e=n(JIe,"STRONG",{});var a6t=s(y2e);lHo=r(a6t,"roformer"),a6t.forEach(t),iHo=r(JIe," \u2014 "),Yz=n(JIe,"A",{href:!0});var n6t=s(Yz);dHo=r(n6t,"RoFormerForSequenceClassification"),n6t.forEach(t),cHo=r(JIe," (RoFormer model)"),JIe.forEach(t),fHo=i(j),sv=n(j,"LI",{});var YIe=s(sv);x2e=n(YIe,"STRONG",{});var s6t=s(x2e);mHo=r(s6t,"squeezebert"),s6t.forEach(t),gHo=r(YIe," \u2014 "),Kz=n(YIe,"A",{href:!0});var l6t=s(Kz);hHo=r(l6t,"SqueezeBertForSequenceClassification"),l6t.forEach(t),pHo=r(YIe," (SqueezeBERT model)"),YIe.forEach(t),_Ho=i(j),lv=n(j,"LI",{});var KIe=s(lv);$2e=n(KIe,"STRONG",{});var i6t=s($2e);uHo=r(i6t,"tapas"),i6t.forEach(t),bHo=r(KIe," \u2014 "),Zz=n(KIe,"A",{href:!0});var d6t=s(Zz);vHo=r(d6t,"TapasForSequenceClassification"),d6t.forEach(t),FHo=r(KIe," (TAPAS model)"),KIe.forEach(t),THo=i(j),iv=n(j,"LI",{});var ZIe=s(iv);k2e=n(ZIe,"STRONG",{});var c6t=s(k2e);MHo=r(c6t,"transfo-xl"),c6t.forEach(t),EHo=r(ZIe," \u2014 "),eW=n(ZIe,"A",{href:!0});var f6t=s(eW);CHo=r(f6t,"TransfoXLForSequenceClassification"),f6t.forEach(t),wHo=r(ZIe," (Transformer-XL model)"),ZIe.forEach(t),AHo=i(j),dv=n(j,"LI",{});var eNe=s(dv);S2e=n(eNe,"STRONG",{});var m6t=s(S2e);LHo=r(m6t,"xlm"),m6t.forEach(t),yHo=r(eNe," \u2014 "),oW=n(eNe,"A",{href:!0});var g6t=s(oW);xHo=r(g6t,"XLMForSequenceClassification"),g6t.forEach(t),$Ho=r(eNe," (XLM model)"),eNe.forEach(t),kHo=i(j),cv=n(j,"LI",{});var oNe=s(cv);R2e=n(oNe,"STRONG",{});var h6t=s(R2e);SHo=r(h6t,"xlm-roberta"),h6t.forEach(t),RHo=r(oNe," \u2014 "),rW=n(oNe,"A",{href:!0});var p6t=s(rW);PHo=r(p6t,"XLMRobertaForSequenceClassification"),p6t.forEach(t),BHo=r(oNe," (XLM-RoBERTa model)"),oNe.forEach(t),IHo=i(j),fv=n(j,"LI",{});var rNe=s(fv);P2e=n(rNe,"STRONG",{});var _6t=s(P2e);NHo=r(_6t,"xlm-roberta-xl"),_6t.forEach(t),qHo=r(rNe," \u2014 "),tW=n(rNe,"A",{href:!0});var u6t=s(tW);jHo=r(u6t,"XLMRobertaXLForSequenceClassification"),u6t.forEach(t),DHo=r(rNe," (XLM-RoBERTa-XL model)"),rNe.forEach(t),GHo=i(j),mv=n(j,"LI",{});var tNe=s(mv);B2e=n(tNe,"STRONG",{});var b6t=s(B2e);OHo=r(b6t,"xlnet"),b6t.forEach(t),VHo=r(tNe," \u2014 "),aW=n(tNe,"A",{href:!0});var v6t=s(aW);XHo=r(v6t,"XLNetForSequenceClassification"),v6t.forEach(t),zHo=r(tNe," (XLNet model)"),tNe.forEach(t),WHo=i(j),gv=n(j,"LI",{});var aNe=s(gv);I2e=n(aNe,"STRONG",{});var F6t=s(I2e);QHo=r(F6t,"yoso"),F6t.forEach(t),UHo=r(aNe," \u2014 "),nW=n(aNe,"A",{href:!0});var T6t=s(nW);HHo=r(T6t,"YosoForSequenceClassification"),T6t.forEach(t),JHo=r(aNe," (YOSO model)"),aNe.forEach(t),j.forEach(t),YHo=i(pa),hv=n(pa,"P",{});var nNe=s(hv);KHo=r(nNe,"The model is set in evaluation mode by default using "),N2e=n(nNe,"CODE",{});var M6t=s(N2e);ZHo=r(M6t,"model.eval()"),M6t.forEach(t),eJo=r(nNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q2e=n(nNe,"CODE",{});var E6t=s(q2e);oJo=r(E6t,"model.train()"),E6t.forEach(t),nNe.forEach(t),rJo=i(pa),T(pv.$$.fragment,pa),pa.forEach(t),pl.forEach(t),cQe=i(f),hd=n(f,"H2",{class:!0});var bHe=s(hd);_v=n(bHe,"A",{id:!0,class:!0,href:!0});var C6t=s(_v);j2e=n(C6t,"SPAN",{});var w6t=s(j2e);T(Hy.$$.fragment,w6t),w6t.forEach(t),C6t.forEach(t),tJo=i(bHe),D2e=n(bHe,"SPAN",{});var A6t=s(D2e);aJo=r(A6t,"AutoModelForMultipleChoice"),A6t.forEach(t),bHe.forEach(t),fQe=i(f),qo=n(f,"DIV",{class:!0});var _l=s(qo);T(Jy.$$.fragment,_l),nJo=i(_l),pd=n(_l,"P",{});var uae=s(pd);sJo=r(uae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),sW=n(uae,"A",{href:!0});var L6t=s(sW);lJo=r(L6t,"from_pretrained()"),L6t.forEach(t),iJo=r(uae," class method or the "),lW=n(uae,"A",{href:!0});var y6t=s(lW);dJo=r(y6t,"from_config()"),y6t.forEach(t),cJo=r(uae,` class
method.`),uae.forEach(t),fJo=i(_l),Yy=n(_l,"P",{});var vHe=s(Yy);mJo=r(vHe,"This class cannot be instantiated directly using "),G2e=n(vHe,"CODE",{});var x6t=s(G2e);gJo=r(x6t,"__init__()"),x6t.forEach(t),hJo=r(vHe," (throws an error)."),vHe.forEach(t),pJo=i(_l),_t=n(_l,"DIV",{class:!0});var s7=s(_t);T(Ky.$$.fragment,s7),_Jo=i(s7),O2e=n(s7,"P",{});var $6t=s(O2e);uJo=r($6t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),$6t.forEach(t),bJo=i(s7),_d=n(s7,"P",{});var bae=s(_d);vJo=r(bae,`Note:
Loading a model from its configuration file does `),V2e=n(bae,"STRONG",{});var k6t=s(V2e);FJo=r(k6t,"not"),k6t.forEach(t),TJo=r(bae,` load the model weights. It only affects the
model\u2019s configuration. Use `),iW=n(bae,"A",{href:!0});var S6t=s(iW);MJo=r(S6t,"from_pretrained()"),S6t.forEach(t),EJo=r(bae," to load the model weights."),bae.forEach(t),CJo=i(s7),T(uv.$$.fragment,s7),s7.forEach(t),wJo=i(_l),to=n(_l,"DIV",{class:!0});var _a=s(to);T(Zy.$$.fragment,_a),AJo=i(_a),X2e=n(_a,"P",{});var R6t=s(X2e);LJo=r(R6t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),R6t.forEach(t),yJo=i(_a),Wa=n(_a,"P",{});var l7=s(Wa);xJo=r(l7,"The model class to instantiate is selected based on the "),z2e=n(l7,"CODE",{});var P6t=s(z2e);$Jo=r(P6t,"model_type"),P6t.forEach(t),kJo=r(l7,` property of the config object (either
passed as an argument or loaded from `),W2e=n(l7,"CODE",{});var B6t=s(W2e);SJo=r(B6t,"pretrained_model_name_or_path"),B6t.forEach(t),RJo=r(l7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q2e=n(l7,"CODE",{});var I6t=s(Q2e);PJo=r(I6t,"pretrained_model_name_or_path"),I6t.forEach(t),BJo=r(l7,":"),l7.forEach(t),IJo=i(_a),Z=n(_a,"UL",{});var ee=s(Z);bv=n(ee,"LI",{});var sNe=s(bv);U2e=n(sNe,"STRONG",{});var N6t=s(U2e);NJo=r(N6t,"albert"),N6t.forEach(t),qJo=r(sNe," \u2014 "),dW=n(sNe,"A",{href:!0});var q6t=s(dW);jJo=r(q6t,"AlbertForMultipleChoice"),q6t.forEach(t),DJo=r(sNe," (ALBERT model)"),sNe.forEach(t),GJo=i(ee),vv=n(ee,"LI",{});var lNe=s(vv);H2e=n(lNe,"STRONG",{});var j6t=s(H2e);OJo=r(j6t,"bert"),j6t.forEach(t),VJo=r(lNe," \u2014 "),cW=n(lNe,"A",{href:!0});var D6t=s(cW);XJo=r(D6t,"BertForMultipleChoice"),D6t.forEach(t),zJo=r(lNe," (BERT model)"),lNe.forEach(t),WJo=i(ee),Fv=n(ee,"LI",{});var iNe=s(Fv);J2e=n(iNe,"STRONG",{});var G6t=s(J2e);QJo=r(G6t,"big_bird"),G6t.forEach(t),UJo=r(iNe," \u2014 "),fW=n(iNe,"A",{href:!0});var O6t=s(fW);HJo=r(O6t,"BigBirdForMultipleChoice"),O6t.forEach(t),JJo=r(iNe," (BigBird model)"),iNe.forEach(t),YJo=i(ee),Tv=n(ee,"LI",{});var dNe=s(Tv);Y2e=n(dNe,"STRONG",{});var V6t=s(Y2e);KJo=r(V6t,"camembert"),V6t.forEach(t),ZJo=r(dNe," \u2014 "),mW=n(dNe,"A",{href:!0});var X6t=s(mW);eYo=r(X6t,"CamembertForMultipleChoice"),X6t.forEach(t),oYo=r(dNe," (CamemBERT model)"),dNe.forEach(t),rYo=i(ee),Mv=n(ee,"LI",{});var cNe=s(Mv);K2e=n(cNe,"STRONG",{});var z6t=s(K2e);tYo=r(z6t,"canine"),z6t.forEach(t),aYo=r(cNe," \u2014 "),gW=n(cNe,"A",{href:!0});var W6t=s(gW);nYo=r(W6t,"CanineForMultipleChoice"),W6t.forEach(t),sYo=r(cNe," (CANINE model)"),cNe.forEach(t),lYo=i(ee),Ev=n(ee,"LI",{});var fNe=s(Ev);Z2e=n(fNe,"STRONG",{});var Q6t=s(Z2e);iYo=r(Q6t,"convbert"),Q6t.forEach(t),dYo=r(fNe," \u2014 "),hW=n(fNe,"A",{href:!0});var U6t=s(hW);cYo=r(U6t,"ConvBertForMultipleChoice"),U6t.forEach(t),fYo=r(fNe," (ConvBERT model)"),fNe.forEach(t),mYo=i(ee),Cv=n(ee,"LI",{});var mNe=s(Cv);e1e=n(mNe,"STRONG",{});var H6t=s(e1e);gYo=r(H6t,"data2vec-text"),H6t.forEach(t),hYo=r(mNe," \u2014 "),pW=n(mNe,"A",{href:!0});var J6t=s(pW);pYo=r(J6t,"Data2VecTextForMultipleChoice"),J6t.forEach(t),_Yo=r(mNe," (Data2VecText model)"),mNe.forEach(t),uYo=i(ee),wv=n(ee,"LI",{});var gNe=s(wv);o1e=n(gNe,"STRONG",{});var Y6t=s(o1e);bYo=r(Y6t,"deberta-v2"),Y6t.forEach(t),vYo=r(gNe," \u2014 "),_W=n(gNe,"A",{href:!0});var K6t=s(_W);FYo=r(K6t,"DebertaV2ForMultipleChoice"),K6t.forEach(t),TYo=r(gNe," (DeBERTa-v2 model)"),gNe.forEach(t),MYo=i(ee),Av=n(ee,"LI",{});var hNe=s(Av);r1e=n(hNe,"STRONG",{});var Z6t=s(r1e);EYo=r(Z6t,"distilbert"),Z6t.forEach(t),CYo=r(hNe," \u2014 "),uW=n(hNe,"A",{href:!0});var eAt=s(uW);wYo=r(eAt,"DistilBertForMultipleChoice"),eAt.forEach(t),AYo=r(hNe," (DistilBERT model)"),hNe.forEach(t),LYo=i(ee),Lv=n(ee,"LI",{});var pNe=s(Lv);t1e=n(pNe,"STRONG",{});var oAt=s(t1e);yYo=r(oAt,"electra"),oAt.forEach(t),xYo=r(pNe," \u2014 "),bW=n(pNe,"A",{href:!0});var rAt=s(bW);$Yo=r(rAt,"ElectraForMultipleChoice"),rAt.forEach(t),kYo=r(pNe," (ELECTRA model)"),pNe.forEach(t),SYo=i(ee),yv=n(ee,"LI",{});var _Ne=s(yv);a1e=n(_Ne,"STRONG",{});var tAt=s(a1e);RYo=r(tAt,"flaubert"),tAt.forEach(t),PYo=r(_Ne," \u2014 "),vW=n(_Ne,"A",{href:!0});var aAt=s(vW);BYo=r(aAt,"FlaubertForMultipleChoice"),aAt.forEach(t),IYo=r(_Ne," (FlauBERT model)"),_Ne.forEach(t),NYo=i(ee),xv=n(ee,"LI",{});var uNe=s(xv);n1e=n(uNe,"STRONG",{});var nAt=s(n1e);qYo=r(nAt,"fnet"),nAt.forEach(t),jYo=r(uNe," \u2014 "),FW=n(uNe,"A",{href:!0});var sAt=s(FW);DYo=r(sAt,"FNetForMultipleChoice"),sAt.forEach(t),GYo=r(uNe," (FNet model)"),uNe.forEach(t),OYo=i(ee),$v=n(ee,"LI",{});var bNe=s($v);s1e=n(bNe,"STRONG",{});var lAt=s(s1e);VYo=r(lAt,"funnel"),lAt.forEach(t),XYo=r(bNe," \u2014 "),TW=n(bNe,"A",{href:!0});var iAt=s(TW);zYo=r(iAt,"FunnelForMultipleChoice"),iAt.forEach(t),WYo=r(bNe," (Funnel Transformer model)"),bNe.forEach(t),QYo=i(ee),kv=n(ee,"LI",{});var vNe=s(kv);l1e=n(vNe,"STRONG",{});var dAt=s(l1e);UYo=r(dAt,"ibert"),dAt.forEach(t),HYo=r(vNe," \u2014 "),MW=n(vNe,"A",{href:!0});var cAt=s(MW);JYo=r(cAt,"IBertForMultipleChoice"),cAt.forEach(t),YYo=r(vNe," (I-BERT model)"),vNe.forEach(t),KYo=i(ee),Sv=n(ee,"LI",{});var FNe=s(Sv);i1e=n(FNe,"STRONG",{});var fAt=s(i1e);ZYo=r(fAt,"longformer"),fAt.forEach(t),eKo=r(FNe," \u2014 "),EW=n(FNe,"A",{href:!0});var mAt=s(EW);oKo=r(mAt,"LongformerForMultipleChoice"),mAt.forEach(t),rKo=r(FNe," (Longformer model)"),FNe.forEach(t),tKo=i(ee),Rv=n(ee,"LI",{});var TNe=s(Rv);d1e=n(TNe,"STRONG",{});var gAt=s(d1e);aKo=r(gAt,"luke"),gAt.forEach(t),nKo=r(TNe," \u2014 "),CW=n(TNe,"A",{href:!0});var hAt=s(CW);sKo=r(hAt,"LukeForMultipleChoice"),hAt.forEach(t),lKo=r(TNe," (LUKE model)"),TNe.forEach(t),iKo=i(ee),Pv=n(ee,"LI",{});var MNe=s(Pv);c1e=n(MNe,"STRONG",{});var pAt=s(c1e);dKo=r(pAt,"megatron-bert"),pAt.forEach(t),cKo=r(MNe," \u2014 "),wW=n(MNe,"A",{href:!0});var _At=s(wW);fKo=r(_At,"MegatronBertForMultipleChoice"),_At.forEach(t),mKo=r(MNe," (Megatron-BERT model)"),MNe.forEach(t),gKo=i(ee),Bv=n(ee,"LI",{});var ENe=s(Bv);f1e=n(ENe,"STRONG",{});var uAt=s(f1e);hKo=r(uAt,"mobilebert"),uAt.forEach(t),pKo=r(ENe," \u2014 "),AW=n(ENe,"A",{href:!0});var bAt=s(AW);_Ko=r(bAt,"MobileBertForMultipleChoice"),bAt.forEach(t),uKo=r(ENe," (MobileBERT model)"),ENe.forEach(t),bKo=i(ee),Iv=n(ee,"LI",{});var CNe=s(Iv);m1e=n(CNe,"STRONG",{});var vAt=s(m1e);vKo=r(vAt,"mpnet"),vAt.forEach(t),FKo=r(CNe," \u2014 "),LW=n(CNe,"A",{href:!0});var FAt=s(LW);TKo=r(FAt,"MPNetForMultipleChoice"),FAt.forEach(t),MKo=r(CNe," (MPNet model)"),CNe.forEach(t),EKo=i(ee),Nv=n(ee,"LI",{});var wNe=s(Nv);g1e=n(wNe,"STRONG",{});var TAt=s(g1e);CKo=r(TAt,"nezha"),TAt.forEach(t),wKo=r(wNe," \u2014 "),yW=n(wNe,"A",{href:!0});var MAt=s(yW);AKo=r(MAt,"NezhaForMultipleChoice"),MAt.forEach(t),LKo=r(wNe," (Nezha model)"),wNe.forEach(t),yKo=i(ee),qv=n(ee,"LI",{});var ANe=s(qv);h1e=n(ANe,"STRONG",{});var EAt=s(h1e);xKo=r(EAt,"nystromformer"),EAt.forEach(t),$Ko=r(ANe," \u2014 "),xW=n(ANe,"A",{href:!0});var CAt=s(xW);kKo=r(CAt,"NystromformerForMultipleChoice"),CAt.forEach(t),SKo=r(ANe," (Nystr\xF6mformer model)"),ANe.forEach(t),RKo=i(ee),jv=n(ee,"LI",{});var LNe=s(jv);p1e=n(LNe,"STRONG",{});var wAt=s(p1e);PKo=r(wAt,"qdqbert"),wAt.forEach(t),BKo=r(LNe," \u2014 "),$W=n(LNe,"A",{href:!0});var AAt=s($W);IKo=r(AAt,"QDQBertForMultipleChoice"),AAt.forEach(t),NKo=r(LNe," (QDQBert model)"),LNe.forEach(t),qKo=i(ee),Dv=n(ee,"LI",{});var yNe=s(Dv);_1e=n(yNe,"STRONG",{});var LAt=s(_1e);jKo=r(LAt,"rembert"),LAt.forEach(t),DKo=r(yNe," \u2014 "),kW=n(yNe,"A",{href:!0});var yAt=s(kW);GKo=r(yAt,"RemBertForMultipleChoice"),yAt.forEach(t),OKo=r(yNe," (RemBERT model)"),yNe.forEach(t),VKo=i(ee),Gv=n(ee,"LI",{});var xNe=s(Gv);u1e=n(xNe,"STRONG",{});var xAt=s(u1e);XKo=r(xAt,"roberta"),xAt.forEach(t),zKo=r(xNe," \u2014 "),SW=n(xNe,"A",{href:!0});var $At=s(SW);WKo=r($At,"RobertaForMultipleChoice"),$At.forEach(t),QKo=r(xNe," (RoBERTa model)"),xNe.forEach(t),UKo=i(ee),Ov=n(ee,"LI",{});var $Ne=s(Ov);b1e=n($Ne,"STRONG",{});var kAt=s(b1e);HKo=r(kAt,"roformer"),kAt.forEach(t),JKo=r($Ne," \u2014 "),RW=n($Ne,"A",{href:!0});var SAt=s(RW);YKo=r(SAt,"RoFormerForMultipleChoice"),SAt.forEach(t),KKo=r($Ne," (RoFormer model)"),$Ne.forEach(t),ZKo=i(ee),Vv=n(ee,"LI",{});var kNe=s(Vv);v1e=n(kNe,"STRONG",{});var RAt=s(v1e);eZo=r(RAt,"squeezebert"),RAt.forEach(t),oZo=r(kNe," \u2014 "),PW=n(kNe,"A",{href:!0});var PAt=s(PW);rZo=r(PAt,"SqueezeBertForMultipleChoice"),PAt.forEach(t),tZo=r(kNe," (SqueezeBERT model)"),kNe.forEach(t),aZo=i(ee),Xv=n(ee,"LI",{});var SNe=s(Xv);F1e=n(SNe,"STRONG",{});var BAt=s(F1e);nZo=r(BAt,"xlm"),BAt.forEach(t),sZo=r(SNe," \u2014 "),BW=n(SNe,"A",{href:!0});var IAt=s(BW);lZo=r(IAt,"XLMForMultipleChoice"),IAt.forEach(t),iZo=r(SNe," (XLM model)"),SNe.forEach(t),dZo=i(ee),zv=n(ee,"LI",{});var RNe=s(zv);T1e=n(RNe,"STRONG",{});var NAt=s(T1e);cZo=r(NAt,"xlm-roberta"),NAt.forEach(t),fZo=r(RNe," \u2014 "),IW=n(RNe,"A",{href:!0});var qAt=s(IW);mZo=r(qAt,"XLMRobertaForMultipleChoice"),qAt.forEach(t),gZo=r(RNe," (XLM-RoBERTa model)"),RNe.forEach(t),hZo=i(ee),Wv=n(ee,"LI",{});var PNe=s(Wv);M1e=n(PNe,"STRONG",{});var jAt=s(M1e);pZo=r(jAt,"xlm-roberta-xl"),jAt.forEach(t),_Zo=r(PNe," \u2014 "),NW=n(PNe,"A",{href:!0});var DAt=s(NW);uZo=r(DAt,"XLMRobertaXLForMultipleChoice"),DAt.forEach(t),bZo=r(PNe," (XLM-RoBERTa-XL model)"),PNe.forEach(t),vZo=i(ee),Qv=n(ee,"LI",{});var BNe=s(Qv);E1e=n(BNe,"STRONG",{});var GAt=s(E1e);FZo=r(GAt,"xlnet"),GAt.forEach(t),TZo=r(BNe," \u2014 "),qW=n(BNe,"A",{href:!0});var OAt=s(qW);MZo=r(OAt,"XLNetForMultipleChoice"),OAt.forEach(t),EZo=r(BNe," (XLNet model)"),BNe.forEach(t),CZo=i(ee),Uv=n(ee,"LI",{});var INe=s(Uv);C1e=n(INe,"STRONG",{});var VAt=s(C1e);wZo=r(VAt,"yoso"),VAt.forEach(t),AZo=r(INe," \u2014 "),jW=n(INe,"A",{href:!0});var XAt=s(jW);LZo=r(XAt,"YosoForMultipleChoice"),XAt.forEach(t),yZo=r(INe," (YOSO model)"),INe.forEach(t),ee.forEach(t),xZo=i(_a),Hv=n(_a,"P",{});var NNe=s(Hv);$Zo=r(NNe,"The model is set in evaluation mode by default using "),w1e=n(NNe,"CODE",{});var zAt=s(w1e);kZo=r(zAt,"model.eval()"),zAt.forEach(t),SZo=r(NNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),A1e=n(NNe,"CODE",{});var WAt=s(A1e);RZo=r(WAt,"model.train()"),WAt.forEach(t),NNe.forEach(t),PZo=i(_a),T(Jv.$$.fragment,_a),_a.forEach(t),_l.forEach(t),mQe=i(f),ud=n(f,"H2",{class:!0});var FHe=s(ud);Yv=n(FHe,"A",{id:!0,class:!0,href:!0});var QAt=s(Yv);L1e=n(QAt,"SPAN",{});var UAt=s(L1e);T(e9.$$.fragment,UAt),UAt.forEach(t),QAt.forEach(t),BZo=i(FHe),y1e=n(FHe,"SPAN",{});var HAt=s(y1e);IZo=r(HAt,"AutoModelForNextSentencePrediction"),HAt.forEach(t),FHe.forEach(t),gQe=i(f),jo=n(f,"DIV",{class:!0});var ul=s(jo);T(o9.$$.fragment,ul),NZo=i(ul),bd=n(ul,"P",{});var vae=s(bd);qZo=r(vae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DW=n(vae,"A",{href:!0});var JAt=s(DW);jZo=r(JAt,"from_pretrained()"),JAt.forEach(t),DZo=r(vae," class method or the "),GW=n(vae,"A",{href:!0});var YAt=s(GW);GZo=r(YAt,"from_config()"),YAt.forEach(t),OZo=r(vae,` class
method.`),vae.forEach(t),VZo=i(ul),r9=n(ul,"P",{});var THe=s(r9);XZo=r(THe,"This class cannot be instantiated directly using "),x1e=n(THe,"CODE",{});var KAt=s(x1e);zZo=r(KAt,"__init__()"),KAt.forEach(t),WZo=r(THe," (throws an error)."),THe.forEach(t),QZo=i(ul),ut=n(ul,"DIV",{class:!0});var i7=s(ut);T(t9.$$.fragment,i7),UZo=i(i7),$1e=n(i7,"P",{});var ZAt=s($1e);HZo=r(ZAt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ZAt.forEach(t),JZo=i(i7),vd=n(i7,"P",{});var Fae=s(vd);YZo=r(Fae,`Note:
Loading a model from its configuration file does `),k1e=n(Fae,"STRONG",{});var e7t=s(k1e);KZo=r(e7t,"not"),e7t.forEach(t),ZZo=r(Fae,` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=n(Fae,"A",{href:!0});var o7t=s(OW);eer=r(o7t,"from_pretrained()"),o7t.forEach(t),oer=r(Fae," to load the model weights."),Fae.forEach(t),rer=i(i7),T(Kv.$$.fragment,i7),i7.forEach(t),ter=i(ul),ao=n(ul,"DIV",{class:!0});var ua=s(ao);T(a9.$$.fragment,ua),aer=i(ua),S1e=n(ua,"P",{});var r7t=s(S1e);ner=r(r7t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),r7t.forEach(t),ser=i(ua),Qa=n(ua,"P",{});var d7=s(Qa);ler=r(d7,"The model class to instantiate is selected based on the "),R1e=n(d7,"CODE",{});var t7t=s(R1e);ier=r(t7t,"model_type"),t7t.forEach(t),der=r(d7,` property of the config object (either
passed as an argument or loaded from `),P1e=n(d7,"CODE",{});var a7t=s(P1e);cer=r(a7t,"pretrained_model_name_or_path"),a7t.forEach(t),fer=r(d7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B1e=n(d7,"CODE",{});var n7t=s(B1e);mer=r(n7t,"pretrained_model_name_or_path"),n7t.forEach(t),ger=r(d7,":"),d7.forEach(t),her=i(ua),Do=n(ua,"UL",{});var ba=s(Do);Zv=n(ba,"LI",{});var qNe=s(Zv);I1e=n(qNe,"STRONG",{});var s7t=s(I1e);per=r(s7t,"bert"),s7t.forEach(t),_er=r(qNe," \u2014 "),VW=n(qNe,"A",{href:!0});var l7t=s(VW);uer=r(l7t,"BertForNextSentencePrediction"),l7t.forEach(t),ber=r(qNe," (BERT model)"),qNe.forEach(t),ver=i(ba),e5=n(ba,"LI",{});var jNe=s(e5);N1e=n(jNe,"STRONG",{});var i7t=s(N1e);Fer=r(i7t,"fnet"),i7t.forEach(t),Ter=r(jNe," \u2014 "),XW=n(jNe,"A",{href:!0});var d7t=s(XW);Mer=r(d7t,"FNetForNextSentencePrediction"),d7t.forEach(t),Eer=r(jNe," (FNet model)"),jNe.forEach(t),Cer=i(ba),o5=n(ba,"LI",{});var DNe=s(o5);q1e=n(DNe,"STRONG",{});var c7t=s(q1e);wer=r(c7t,"megatron-bert"),c7t.forEach(t),Aer=r(DNe," \u2014 "),zW=n(DNe,"A",{href:!0});var f7t=s(zW);Ler=r(f7t,"MegatronBertForNextSentencePrediction"),f7t.forEach(t),yer=r(DNe," (Megatron-BERT model)"),DNe.forEach(t),xer=i(ba),r5=n(ba,"LI",{});var GNe=s(r5);j1e=n(GNe,"STRONG",{});var m7t=s(j1e);$er=r(m7t,"mobilebert"),m7t.forEach(t),ker=r(GNe," \u2014 "),WW=n(GNe,"A",{href:!0});var g7t=s(WW);Ser=r(g7t,"MobileBertForNextSentencePrediction"),g7t.forEach(t),Rer=r(GNe," (MobileBERT model)"),GNe.forEach(t),Per=i(ba),t5=n(ba,"LI",{});var ONe=s(t5);D1e=n(ONe,"STRONG",{});var h7t=s(D1e);Ber=r(h7t,"nezha"),h7t.forEach(t),Ier=r(ONe," \u2014 "),QW=n(ONe,"A",{href:!0});var p7t=s(QW);Ner=r(p7t,"NezhaForNextSentencePrediction"),p7t.forEach(t),qer=r(ONe," (Nezha model)"),ONe.forEach(t),jer=i(ba),a5=n(ba,"LI",{});var VNe=s(a5);G1e=n(VNe,"STRONG",{});var _7t=s(G1e);Der=r(_7t,"qdqbert"),_7t.forEach(t),Ger=r(VNe," \u2014 "),UW=n(VNe,"A",{href:!0});var u7t=s(UW);Oer=r(u7t,"QDQBertForNextSentencePrediction"),u7t.forEach(t),Ver=r(VNe," (QDQBert model)"),VNe.forEach(t),ba.forEach(t),Xer=i(ua),n5=n(ua,"P",{});var XNe=s(n5);zer=r(XNe,"The model is set in evaluation mode by default using "),O1e=n(XNe,"CODE",{});var b7t=s(O1e);Wer=r(b7t,"model.eval()"),b7t.forEach(t),Qer=r(XNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V1e=n(XNe,"CODE",{});var v7t=s(V1e);Uer=r(v7t,"model.train()"),v7t.forEach(t),XNe.forEach(t),Her=i(ua),T(s5.$$.fragment,ua),ua.forEach(t),ul.forEach(t),hQe=i(f),Fd=n(f,"H2",{class:!0});var MHe=s(Fd);l5=n(MHe,"A",{id:!0,class:!0,href:!0});var F7t=s(l5);X1e=n(F7t,"SPAN",{});var T7t=s(X1e);T(n9.$$.fragment,T7t),T7t.forEach(t),F7t.forEach(t),Jer=i(MHe),z1e=n(MHe,"SPAN",{});var M7t=s(z1e);Yer=r(M7t,"AutoModelForTokenClassification"),M7t.forEach(t),MHe.forEach(t),pQe=i(f),Go=n(f,"DIV",{class:!0});var bl=s(Go);T(s9.$$.fragment,bl),Ker=i(bl),Td=n(bl,"P",{});var Tae=s(Td);Zer=r(Tae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),HW=n(Tae,"A",{href:!0});var E7t=s(HW);eor=r(E7t,"from_pretrained()"),E7t.forEach(t),oor=r(Tae," class method or the "),JW=n(Tae,"A",{href:!0});var C7t=s(JW);ror=r(C7t,"from_config()"),C7t.forEach(t),tor=r(Tae,` class
method.`),Tae.forEach(t),aor=i(bl),l9=n(bl,"P",{});var EHe=s(l9);nor=r(EHe,"This class cannot be instantiated directly using "),W1e=n(EHe,"CODE",{});var w7t=s(W1e);sor=r(w7t,"__init__()"),w7t.forEach(t),lor=r(EHe," (throws an error)."),EHe.forEach(t),ior=i(bl),bt=n(bl,"DIV",{class:!0});var c7=s(bt);T(i9.$$.fragment,c7),dor=i(c7),Q1e=n(c7,"P",{});var A7t=s(Q1e);cor=r(A7t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),A7t.forEach(t),mor=i(c7),Md=n(c7,"P",{});var Mae=s(Md);gor=r(Mae,`Note:
Loading a model from its configuration file does `),U1e=n(Mae,"STRONG",{});var L7t=s(U1e);hor=r(L7t,"not"),L7t.forEach(t),por=r(Mae,` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=n(Mae,"A",{href:!0});var y7t=s(YW);_or=r(y7t,"from_pretrained()"),y7t.forEach(t),uor=r(Mae," to load the model weights."),Mae.forEach(t),bor=i(c7),T(i5.$$.fragment,c7),c7.forEach(t),vor=i(bl),no=n(bl,"DIV",{class:!0});var va=s(no);T(d9.$$.fragment,va),For=i(va),H1e=n(va,"P",{});var x7t=s(H1e);Tor=r(x7t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),x7t.forEach(t),Mor=i(va),Ua=n(va,"P",{});var f7=s(Ua);Eor=r(f7,"The model class to instantiate is selected based on the "),J1e=n(f7,"CODE",{});var $7t=s(J1e);Cor=r($7t,"model_type"),$7t.forEach(t),wor=r(f7,` property of the config object (either
passed as an argument or loaded from `),Y1e=n(f7,"CODE",{});var k7t=s(Y1e);Aor=r(k7t,"pretrained_model_name_or_path"),k7t.forEach(t),Lor=r(f7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K1e=n(f7,"CODE",{});var S7t=s(K1e);yor=r(S7t,"pretrained_model_name_or_path"),S7t.forEach(t),xor=r(f7,":"),f7.forEach(t),$or=i(va),H=n(va,"UL",{});var K=s(H);d5=n(K,"LI",{});var zNe=s(d5);Z1e=n(zNe,"STRONG",{});var R7t=s(Z1e);kor=r(R7t,"albert"),R7t.forEach(t),Sor=r(zNe," \u2014 "),KW=n(zNe,"A",{href:!0});var P7t=s(KW);Ror=r(P7t,"AlbertForTokenClassification"),P7t.forEach(t),Por=r(zNe," (ALBERT model)"),zNe.forEach(t),Bor=i(K),c5=n(K,"LI",{});var WNe=s(c5);e4e=n(WNe,"STRONG",{});var B7t=s(e4e);Ior=r(B7t,"bert"),B7t.forEach(t),Nor=r(WNe," \u2014 "),ZW=n(WNe,"A",{href:!0});var I7t=s(ZW);qor=r(I7t,"BertForTokenClassification"),I7t.forEach(t),jor=r(WNe," (BERT model)"),WNe.forEach(t),Dor=i(K),f5=n(K,"LI",{});var QNe=s(f5);o4e=n(QNe,"STRONG",{});var N7t=s(o4e);Gor=r(N7t,"big_bird"),N7t.forEach(t),Oor=r(QNe," \u2014 "),eQ=n(QNe,"A",{href:!0});var q7t=s(eQ);Vor=r(q7t,"BigBirdForTokenClassification"),q7t.forEach(t),Xor=r(QNe," (BigBird model)"),QNe.forEach(t),zor=i(K),m5=n(K,"LI",{});var UNe=s(m5);r4e=n(UNe,"STRONG",{});var j7t=s(r4e);Wor=r(j7t,"bloom"),j7t.forEach(t),Qor=r(UNe," \u2014 "),oQ=n(UNe,"A",{href:!0});var D7t=s(oQ);Uor=r(D7t,"BloomForTokenClassification"),D7t.forEach(t),Hor=r(UNe," (BLOOM model)"),UNe.forEach(t),Jor=i(K),g5=n(K,"LI",{});var HNe=s(g5);t4e=n(HNe,"STRONG",{});var G7t=s(t4e);Yor=r(G7t,"camembert"),G7t.forEach(t),Kor=r(HNe," \u2014 "),rQ=n(HNe,"A",{href:!0});var O7t=s(rQ);Zor=r(O7t,"CamembertForTokenClassification"),O7t.forEach(t),err=r(HNe," (CamemBERT model)"),HNe.forEach(t),orr=i(K),h5=n(K,"LI",{});var JNe=s(h5);a4e=n(JNe,"STRONG",{});var V7t=s(a4e);rrr=r(V7t,"canine"),V7t.forEach(t),trr=r(JNe," \u2014 "),tQ=n(JNe,"A",{href:!0});var X7t=s(tQ);arr=r(X7t,"CanineForTokenClassification"),X7t.forEach(t),nrr=r(JNe," (CANINE model)"),JNe.forEach(t),srr=i(K),p5=n(K,"LI",{});var YNe=s(p5);n4e=n(YNe,"STRONG",{});var z7t=s(n4e);lrr=r(z7t,"convbert"),z7t.forEach(t),irr=r(YNe," \u2014 "),aQ=n(YNe,"A",{href:!0});var W7t=s(aQ);drr=r(W7t,"ConvBertForTokenClassification"),W7t.forEach(t),crr=r(YNe," (ConvBERT model)"),YNe.forEach(t),frr=i(K),_5=n(K,"LI",{});var KNe=s(_5);s4e=n(KNe,"STRONG",{});var Q7t=s(s4e);mrr=r(Q7t,"data2vec-text"),Q7t.forEach(t),grr=r(KNe," \u2014 "),nQ=n(KNe,"A",{href:!0});var U7t=s(nQ);hrr=r(U7t,"Data2VecTextForTokenClassification"),U7t.forEach(t),prr=r(KNe," (Data2VecText model)"),KNe.forEach(t),_rr=i(K),u5=n(K,"LI",{});var ZNe=s(u5);l4e=n(ZNe,"STRONG",{});var H7t=s(l4e);urr=r(H7t,"deberta"),H7t.forEach(t),brr=r(ZNe," \u2014 "),sQ=n(ZNe,"A",{href:!0});var J7t=s(sQ);vrr=r(J7t,"DebertaForTokenClassification"),J7t.forEach(t),Frr=r(ZNe," (DeBERTa model)"),ZNe.forEach(t),Trr=i(K),b5=n(K,"LI",{});var eqe=s(b5);i4e=n(eqe,"STRONG",{});var Y7t=s(i4e);Mrr=r(Y7t,"deberta-v2"),Y7t.forEach(t),Err=r(eqe," \u2014 "),lQ=n(eqe,"A",{href:!0});var K7t=s(lQ);Crr=r(K7t,"DebertaV2ForTokenClassification"),K7t.forEach(t),wrr=r(eqe," (DeBERTa-v2 model)"),eqe.forEach(t),Arr=i(K),v5=n(K,"LI",{});var oqe=s(v5);d4e=n(oqe,"STRONG",{});var Z7t=s(d4e);Lrr=r(Z7t,"distilbert"),Z7t.forEach(t),yrr=r(oqe," \u2014 "),iQ=n(oqe,"A",{href:!0});var eLt=s(iQ);xrr=r(eLt,"DistilBertForTokenClassification"),eLt.forEach(t),$rr=r(oqe," (DistilBERT model)"),oqe.forEach(t),krr=i(K),F5=n(K,"LI",{});var rqe=s(F5);c4e=n(rqe,"STRONG",{});var oLt=s(c4e);Srr=r(oLt,"electra"),oLt.forEach(t),Rrr=r(rqe," \u2014 "),dQ=n(rqe,"A",{href:!0});var rLt=s(dQ);Prr=r(rLt,"ElectraForTokenClassification"),rLt.forEach(t),Brr=r(rqe," (ELECTRA model)"),rqe.forEach(t),Irr=i(K),T5=n(K,"LI",{});var tqe=s(T5);f4e=n(tqe,"STRONG",{});var tLt=s(f4e);Nrr=r(tLt,"flaubert"),tLt.forEach(t),qrr=r(tqe," \u2014 "),cQ=n(tqe,"A",{href:!0});var aLt=s(cQ);jrr=r(aLt,"FlaubertForTokenClassification"),aLt.forEach(t),Drr=r(tqe," (FlauBERT model)"),tqe.forEach(t),Grr=i(K),M5=n(K,"LI",{});var aqe=s(M5);m4e=n(aqe,"STRONG",{});var nLt=s(m4e);Orr=r(nLt,"fnet"),nLt.forEach(t),Vrr=r(aqe," \u2014 "),fQ=n(aqe,"A",{href:!0});var sLt=s(fQ);Xrr=r(sLt,"FNetForTokenClassification"),sLt.forEach(t),zrr=r(aqe," (FNet model)"),aqe.forEach(t),Wrr=i(K),E5=n(K,"LI",{});var nqe=s(E5);g4e=n(nqe,"STRONG",{});var lLt=s(g4e);Qrr=r(lLt,"funnel"),lLt.forEach(t),Urr=r(nqe," \u2014 "),mQ=n(nqe,"A",{href:!0});var iLt=s(mQ);Hrr=r(iLt,"FunnelForTokenClassification"),iLt.forEach(t),Jrr=r(nqe," (Funnel Transformer model)"),nqe.forEach(t),Yrr=i(K),C5=n(K,"LI",{});var sqe=s(C5);h4e=n(sqe,"STRONG",{});var dLt=s(h4e);Krr=r(dLt,"gpt2"),dLt.forEach(t),Zrr=r(sqe," \u2014 "),gQ=n(sqe,"A",{href:!0});var cLt=s(gQ);etr=r(cLt,"GPT2ForTokenClassification"),cLt.forEach(t),otr=r(sqe," (OpenAI GPT-2 model)"),sqe.forEach(t),rtr=i(K),w5=n(K,"LI",{});var lqe=s(w5);p4e=n(lqe,"STRONG",{});var fLt=s(p4e);ttr=r(fLt,"ibert"),fLt.forEach(t),atr=r(lqe," \u2014 "),hQ=n(lqe,"A",{href:!0});var mLt=s(hQ);ntr=r(mLt,"IBertForTokenClassification"),mLt.forEach(t),str=r(lqe," (I-BERT model)"),lqe.forEach(t),ltr=i(K),A5=n(K,"LI",{});var iqe=s(A5);_4e=n(iqe,"STRONG",{});var gLt=s(_4e);itr=r(gLt,"layoutlm"),gLt.forEach(t),dtr=r(iqe," \u2014 "),pQ=n(iqe,"A",{href:!0});var hLt=s(pQ);ctr=r(hLt,"LayoutLMForTokenClassification"),hLt.forEach(t),ftr=r(iqe," (LayoutLM model)"),iqe.forEach(t),mtr=i(K),L5=n(K,"LI",{});var dqe=s(L5);u4e=n(dqe,"STRONG",{});var pLt=s(u4e);gtr=r(pLt,"layoutlmv2"),pLt.forEach(t),htr=r(dqe," \u2014 "),_Q=n(dqe,"A",{href:!0});var _Lt=s(_Q);ptr=r(_Lt,"LayoutLMv2ForTokenClassification"),_Lt.forEach(t),_tr=r(dqe," (LayoutLMv2 model)"),dqe.forEach(t),utr=i(K),y5=n(K,"LI",{});var cqe=s(y5);b4e=n(cqe,"STRONG",{});var uLt=s(b4e);btr=r(uLt,"layoutlmv3"),uLt.forEach(t),vtr=r(cqe," \u2014 "),uQ=n(cqe,"A",{href:!0});var bLt=s(uQ);Ftr=r(bLt,"LayoutLMv3ForTokenClassification"),bLt.forEach(t),Ttr=r(cqe," (LayoutLMv3 model)"),cqe.forEach(t),Mtr=i(K),x5=n(K,"LI",{});var fqe=s(x5);v4e=n(fqe,"STRONG",{});var vLt=s(v4e);Etr=r(vLt,"longformer"),vLt.forEach(t),Ctr=r(fqe," \u2014 "),bQ=n(fqe,"A",{href:!0});var FLt=s(bQ);wtr=r(FLt,"LongformerForTokenClassification"),FLt.forEach(t),Atr=r(fqe," (Longformer model)"),fqe.forEach(t),Ltr=i(K),$5=n(K,"LI",{});var mqe=s($5);F4e=n(mqe,"STRONG",{});var TLt=s(F4e);ytr=r(TLt,"luke"),TLt.forEach(t),xtr=r(mqe," \u2014 "),vQ=n(mqe,"A",{href:!0});var MLt=s(vQ);$tr=r(MLt,"LukeForTokenClassification"),MLt.forEach(t),ktr=r(mqe," (LUKE model)"),mqe.forEach(t),Str=i(K),k5=n(K,"LI",{});var gqe=s(k5);T4e=n(gqe,"STRONG",{});var ELt=s(T4e);Rtr=r(ELt,"megatron-bert"),ELt.forEach(t),Ptr=r(gqe," \u2014 "),FQ=n(gqe,"A",{href:!0});var CLt=s(FQ);Btr=r(CLt,"MegatronBertForTokenClassification"),CLt.forEach(t),Itr=r(gqe," (Megatron-BERT model)"),gqe.forEach(t),Ntr=i(K),S5=n(K,"LI",{});var hqe=s(S5);M4e=n(hqe,"STRONG",{});var wLt=s(M4e);qtr=r(wLt,"mobilebert"),wLt.forEach(t),jtr=r(hqe," \u2014 "),TQ=n(hqe,"A",{href:!0});var ALt=s(TQ);Dtr=r(ALt,"MobileBertForTokenClassification"),ALt.forEach(t),Gtr=r(hqe," (MobileBERT model)"),hqe.forEach(t),Otr=i(K),R5=n(K,"LI",{});var pqe=s(R5);E4e=n(pqe,"STRONG",{});var LLt=s(E4e);Vtr=r(LLt,"mpnet"),LLt.forEach(t),Xtr=r(pqe," \u2014 "),MQ=n(pqe,"A",{href:!0});var yLt=s(MQ);ztr=r(yLt,"MPNetForTokenClassification"),yLt.forEach(t),Wtr=r(pqe," (MPNet model)"),pqe.forEach(t),Qtr=i(K),P5=n(K,"LI",{});var _qe=s(P5);C4e=n(_qe,"STRONG",{});var xLt=s(C4e);Utr=r(xLt,"nezha"),xLt.forEach(t),Htr=r(_qe," \u2014 "),EQ=n(_qe,"A",{href:!0});var $Lt=s(EQ);Jtr=r($Lt,"NezhaForTokenClassification"),$Lt.forEach(t),Ytr=r(_qe," (Nezha model)"),_qe.forEach(t),Ktr=i(K),B5=n(K,"LI",{});var uqe=s(B5);w4e=n(uqe,"STRONG",{});var kLt=s(w4e);Ztr=r(kLt,"nystromformer"),kLt.forEach(t),ear=r(uqe," \u2014 "),CQ=n(uqe,"A",{href:!0});var SLt=s(CQ);oar=r(SLt,"NystromformerForTokenClassification"),SLt.forEach(t),rar=r(uqe," (Nystr\xF6mformer model)"),uqe.forEach(t),tar=i(K),I5=n(K,"LI",{});var bqe=s(I5);A4e=n(bqe,"STRONG",{});var RLt=s(A4e);aar=r(RLt,"qdqbert"),RLt.forEach(t),nar=r(bqe," \u2014 "),wQ=n(bqe,"A",{href:!0});var PLt=s(wQ);sar=r(PLt,"QDQBertForTokenClassification"),PLt.forEach(t),lar=r(bqe," (QDQBert model)"),bqe.forEach(t),iar=i(K),N5=n(K,"LI",{});var vqe=s(N5);L4e=n(vqe,"STRONG",{});var BLt=s(L4e);dar=r(BLt,"rembert"),BLt.forEach(t),car=r(vqe," \u2014 "),AQ=n(vqe,"A",{href:!0});var ILt=s(AQ);far=r(ILt,"RemBertForTokenClassification"),ILt.forEach(t),mar=r(vqe," (RemBERT model)"),vqe.forEach(t),gar=i(K),q5=n(K,"LI",{});var Fqe=s(q5);y4e=n(Fqe,"STRONG",{});var NLt=s(y4e);har=r(NLt,"roberta"),NLt.forEach(t),par=r(Fqe," \u2014 "),LQ=n(Fqe,"A",{href:!0});var qLt=s(LQ);_ar=r(qLt,"RobertaForTokenClassification"),qLt.forEach(t),uar=r(Fqe," (RoBERTa model)"),Fqe.forEach(t),bar=i(K),j5=n(K,"LI",{});var Tqe=s(j5);x4e=n(Tqe,"STRONG",{});var jLt=s(x4e);Far=r(jLt,"roformer"),jLt.forEach(t),Tar=r(Tqe," \u2014 "),yQ=n(Tqe,"A",{href:!0});var DLt=s(yQ);Mar=r(DLt,"RoFormerForTokenClassification"),DLt.forEach(t),Ear=r(Tqe," (RoFormer model)"),Tqe.forEach(t),Car=i(K),D5=n(K,"LI",{});var Mqe=s(D5);$4e=n(Mqe,"STRONG",{});var GLt=s($4e);war=r(GLt,"squeezebert"),GLt.forEach(t),Aar=r(Mqe," \u2014 "),xQ=n(Mqe,"A",{href:!0});var OLt=s(xQ);Lar=r(OLt,"SqueezeBertForTokenClassification"),OLt.forEach(t),yar=r(Mqe," (SqueezeBERT model)"),Mqe.forEach(t),xar=i(K),G5=n(K,"LI",{});var Eqe=s(G5);k4e=n(Eqe,"STRONG",{});var VLt=s(k4e);$ar=r(VLt,"xlm"),VLt.forEach(t),kar=r(Eqe," \u2014 "),$Q=n(Eqe,"A",{href:!0});var XLt=s($Q);Sar=r(XLt,"XLMForTokenClassification"),XLt.forEach(t),Rar=r(Eqe," (XLM model)"),Eqe.forEach(t),Par=i(K),O5=n(K,"LI",{});var Cqe=s(O5);S4e=n(Cqe,"STRONG",{});var zLt=s(S4e);Bar=r(zLt,"xlm-roberta"),zLt.forEach(t),Iar=r(Cqe," \u2014 "),kQ=n(Cqe,"A",{href:!0});var WLt=s(kQ);Nar=r(WLt,"XLMRobertaForTokenClassification"),WLt.forEach(t),qar=r(Cqe," (XLM-RoBERTa model)"),Cqe.forEach(t),jar=i(K),V5=n(K,"LI",{});var wqe=s(V5);R4e=n(wqe,"STRONG",{});var QLt=s(R4e);Dar=r(QLt,"xlm-roberta-xl"),QLt.forEach(t),Gar=r(wqe," \u2014 "),SQ=n(wqe,"A",{href:!0});var ULt=s(SQ);Oar=r(ULt,"XLMRobertaXLForTokenClassification"),ULt.forEach(t),Var=r(wqe," (XLM-RoBERTa-XL model)"),wqe.forEach(t),Xar=i(K),X5=n(K,"LI",{});var Aqe=s(X5);P4e=n(Aqe,"STRONG",{});var HLt=s(P4e);zar=r(HLt,"xlnet"),HLt.forEach(t),War=r(Aqe," \u2014 "),RQ=n(Aqe,"A",{href:!0});var JLt=s(RQ);Qar=r(JLt,"XLNetForTokenClassification"),JLt.forEach(t),Uar=r(Aqe," (XLNet model)"),Aqe.forEach(t),Har=i(K),z5=n(K,"LI",{});var Lqe=s(z5);B4e=n(Lqe,"STRONG",{});var YLt=s(B4e);Jar=r(YLt,"yoso"),YLt.forEach(t),Yar=r(Lqe," \u2014 "),PQ=n(Lqe,"A",{href:!0});var KLt=s(PQ);Kar=r(KLt,"YosoForTokenClassification"),KLt.forEach(t),Zar=r(Lqe," (YOSO model)"),Lqe.forEach(t),K.forEach(t),enr=i(va),W5=n(va,"P",{});var yqe=s(W5);onr=r(yqe,"The model is set in evaluation mode by default using "),I4e=n(yqe,"CODE",{});var ZLt=s(I4e);rnr=r(ZLt,"model.eval()"),ZLt.forEach(t),tnr=r(yqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N4e=n(yqe,"CODE",{});var eyt=s(N4e);anr=r(eyt,"model.train()"),eyt.forEach(t),yqe.forEach(t),nnr=i(va),T(Q5.$$.fragment,va),va.forEach(t),bl.forEach(t),_Qe=i(f),Ed=n(f,"H2",{class:!0});var CHe=s(Ed);U5=n(CHe,"A",{id:!0,class:!0,href:!0});var oyt=s(U5);q4e=n(oyt,"SPAN",{});var ryt=s(q4e);T(c9.$$.fragment,ryt),ryt.forEach(t),oyt.forEach(t),snr=i(CHe),j4e=n(CHe,"SPAN",{});var tyt=s(j4e);lnr=r(tyt,"AutoModelForQuestionAnswering"),tyt.forEach(t),CHe.forEach(t),uQe=i(f),Oo=n(f,"DIV",{class:!0});var vl=s(Oo);T(f9.$$.fragment,vl),inr=i(vl),Cd=n(vl,"P",{});var Eae=s(Cd);dnr=r(Eae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),BQ=n(Eae,"A",{href:!0});var ayt=s(BQ);cnr=r(ayt,"from_pretrained()"),ayt.forEach(t),fnr=r(Eae," class method or the "),IQ=n(Eae,"A",{href:!0});var nyt=s(IQ);mnr=r(nyt,"from_config()"),nyt.forEach(t),gnr=r(Eae,` class
method.`),Eae.forEach(t),hnr=i(vl),m9=n(vl,"P",{});var wHe=s(m9);pnr=r(wHe,"This class cannot be instantiated directly using "),D4e=n(wHe,"CODE",{});var syt=s(D4e);_nr=r(syt,"__init__()"),syt.forEach(t),unr=r(wHe," (throws an error)."),wHe.forEach(t),bnr=i(vl),vt=n(vl,"DIV",{class:!0});var m7=s(vt);T(g9.$$.fragment,m7),vnr=i(m7),G4e=n(m7,"P",{});var lyt=s(G4e);Fnr=r(lyt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),lyt.forEach(t),Tnr=i(m7),wd=n(m7,"P",{});var Cae=s(wd);Mnr=r(Cae,`Note:
Loading a model from its configuration file does `),O4e=n(Cae,"STRONG",{});var iyt=s(O4e);Enr=r(iyt,"not"),iyt.forEach(t),Cnr=r(Cae,` load the model weights. It only affects the
model\u2019s configuration. Use `),NQ=n(Cae,"A",{href:!0});var dyt=s(NQ);wnr=r(dyt,"from_pretrained()"),dyt.forEach(t),Anr=r(Cae," to load the model weights."),Cae.forEach(t),Lnr=i(m7),T(H5.$$.fragment,m7),m7.forEach(t),ynr=i(vl),so=n(vl,"DIV",{class:!0});var Fa=s(so);T(h9.$$.fragment,Fa),xnr=i(Fa),V4e=n(Fa,"P",{});var cyt=s(V4e);$nr=r(cyt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),cyt.forEach(t),knr=i(Fa),Ha=n(Fa,"P",{});var g7=s(Ha);Snr=r(g7,"The model class to instantiate is selected based on the "),X4e=n(g7,"CODE",{});var fyt=s(X4e);Rnr=r(fyt,"model_type"),fyt.forEach(t),Pnr=r(g7,` property of the config object (either
passed as an argument or loaded from `),z4e=n(g7,"CODE",{});var myt=s(z4e);Bnr=r(myt,"pretrained_model_name_or_path"),myt.forEach(t),Inr=r(g7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W4e=n(g7,"CODE",{});var gyt=s(W4e);Nnr=r(gyt,"pretrained_model_name_or_path"),gyt.forEach(t),qnr=r(g7,":"),g7.forEach(t),jnr=i(Fa),V=n(Fa,"UL",{});var X=s(V);J5=n(X,"LI",{});var xqe=s(J5);Q4e=n(xqe,"STRONG",{});var hyt=s(Q4e);Dnr=r(hyt,"albert"),hyt.forEach(t),Gnr=r(xqe," \u2014 "),qQ=n(xqe,"A",{href:!0});var pyt=s(qQ);Onr=r(pyt,"AlbertForQuestionAnswering"),pyt.forEach(t),Vnr=r(xqe," (ALBERT model)"),xqe.forEach(t),Xnr=i(X),Y5=n(X,"LI",{});var $qe=s(Y5);U4e=n($qe,"STRONG",{});var _yt=s(U4e);znr=r(_yt,"bart"),_yt.forEach(t),Wnr=r($qe," \u2014 "),jQ=n($qe,"A",{href:!0});var uyt=s(jQ);Qnr=r(uyt,"BartForQuestionAnswering"),uyt.forEach(t),Unr=r($qe," (BART model)"),$qe.forEach(t),Hnr=i(X),K5=n(X,"LI",{});var kqe=s(K5);H4e=n(kqe,"STRONG",{});var byt=s(H4e);Jnr=r(byt,"bert"),byt.forEach(t),Ynr=r(kqe," \u2014 "),DQ=n(kqe,"A",{href:!0});var vyt=s(DQ);Knr=r(vyt,"BertForQuestionAnswering"),vyt.forEach(t),Znr=r(kqe," (BERT model)"),kqe.forEach(t),esr=i(X),Z5=n(X,"LI",{});var Sqe=s(Z5);J4e=n(Sqe,"STRONG",{});var Fyt=s(J4e);osr=r(Fyt,"big_bird"),Fyt.forEach(t),rsr=r(Sqe," \u2014 "),GQ=n(Sqe,"A",{href:!0});var Tyt=s(GQ);tsr=r(Tyt,"BigBirdForQuestionAnswering"),Tyt.forEach(t),asr=r(Sqe," (BigBird model)"),Sqe.forEach(t),nsr=i(X),eF=n(X,"LI",{});var Rqe=s(eF);Y4e=n(Rqe,"STRONG",{});var Myt=s(Y4e);ssr=r(Myt,"bigbird_pegasus"),Myt.forEach(t),lsr=r(Rqe," \u2014 "),OQ=n(Rqe,"A",{href:!0});var Eyt=s(OQ);isr=r(Eyt,"BigBirdPegasusForQuestionAnswering"),Eyt.forEach(t),dsr=r(Rqe," (BigBird-Pegasus model)"),Rqe.forEach(t),csr=i(X),oF=n(X,"LI",{});var Pqe=s(oF);K4e=n(Pqe,"STRONG",{});var Cyt=s(K4e);fsr=r(Cyt,"camembert"),Cyt.forEach(t),msr=r(Pqe," \u2014 "),VQ=n(Pqe,"A",{href:!0});var wyt=s(VQ);gsr=r(wyt,"CamembertForQuestionAnswering"),wyt.forEach(t),hsr=r(Pqe," (CamemBERT model)"),Pqe.forEach(t),psr=i(X),rF=n(X,"LI",{});var Bqe=s(rF);Z4e=n(Bqe,"STRONG",{});var Ayt=s(Z4e);_sr=r(Ayt,"canine"),Ayt.forEach(t),usr=r(Bqe," \u2014 "),XQ=n(Bqe,"A",{href:!0});var Lyt=s(XQ);bsr=r(Lyt,"CanineForQuestionAnswering"),Lyt.forEach(t),vsr=r(Bqe," (CANINE model)"),Bqe.forEach(t),Fsr=i(X),tF=n(X,"LI",{});var Iqe=s(tF);ebe=n(Iqe,"STRONG",{});var yyt=s(ebe);Tsr=r(yyt,"convbert"),yyt.forEach(t),Msr=r(Iqe," \u2014 "),zQ=n(Iqe,"A",{href:!0});var xyt=s(zQ);Esr=r(xyt,"ConvBertForQuestionAnswering"),xyt.forEach(t),Csr=r(Iqe," (ConvBERT model)"),Iqe.forEach(t),wsr=i(X),aF=n(X,"LI",{});var Nqe=s(aF);obe=n(Nqe,"STRONG",{});var $yt=s(obe);Asr=r($yt,"data2vec-text"),$yt.forEach(t),Lsr=r(Nqe," \u2014 "),WQ=n(Nqe,"A",{href:!0});var kyt=s(WQ);ysr=r(kyt,"Data2VecTextForQuestionAnswering"),kyt.forEach(t),xsr=r(Nqe," (Data2VecText model)"),Nqe.forEach(t),$sr=i(X),nF=n(X,"LI",{});var qqe=s(nF);rbe=n(qqe,"STRONG",{});var Syt=s(rbe);ksr=r(Syt,"deberta"),Syt.forEach(t),Ssr=r(qqe," \u2014 "),QQ=n(qqe,"A",{href:!0});var Ryt=s(QQ);Rsr=r(Ryt,"DebertaForQuestionAnswering"),Ryt.forEach(t),Psr=r(qqe," (DeBERTa model)"),qqe.forEach(t),Bsr=i(X),sF=n(X,"LI",{});var jqe=s(sF);tbe=n(jqe,"STRONG",{});var Pyt=s(tbe);Isr=r(Pyt,"deberta-v2"),Pyt.forEach(t),Nsr=r(jqe," \u2014 "),UQ=n(jqe,"A",{href:!0});var Byt=s(UQ);qsr=r(Byt,"DebertaV2ForQuestionAnswering"),Byt.forEach(t),jsr=r(jqe," (DeBERTa-v2 model)"),jqe.forEach(t),Dsr=i(X),lF=n(X,"LI",{});var Dqe=s(lF);abe=n(Dqe,"STRONG",{});var Iyt=s(abe);Gsr=r(Iyt,"distilbert"),Iyt.forEach(t),Osr=r(Dqe," \u2014 "),HQ=n(Dqe,"A",{href:!0});var Nyt=s(HQ);Vsr=r(Nyt,"DistilBertForQuestionAnswering"),Nyt.forEach(t),Xsr=r(Dqe," (DistilBERT model)"),Dqe.forEach(t),zsr=i(X),iF=n(X,"LI",{});var Gqe=s(iF);nbe=n(Gqe,"STRONG",{});var qyt=s(nbe);Wsr=r(qyt,"electra"),qyt.forEach(t),Qsr=r(Gqe," \u2014 "),JQ=n(Gqe,"A",{href:!0});var jyt=s(JQ);Usr=r(jyt,"ElectraForQuestionAnswering"),jyt.forEach(t),Hsr=r(Gqe," (ELECTRA model)"),Gqe.forEach(t),Jsr=i(X),dF=n(X,"LI",{});var Oqe=s(dF);sbe=n(Oqe,"STRONG",{});var Dyt=s(sbe);Ysr=r(Dyt,"flaubert"),Dyt.forEach(t),Ksr=r(Oqe," \u2014 "),YQ=n(Oqe,"A",{href:!0});var Gyt=s(YQ);Zsr=r(Gyt,"FlaubertForQuestionAnsweringSimple"),Gyt.forEach(t),elr=r(Oqe," (FlauBERT model)"),Oqe.forEach(t),olr=i(X),cF=n(X,"LI",{});var Vqe=s(cF);lbe=n(Vqe,"STRONG",{});var Oyt=s(lbe);rlr=r(Oyt,"fnet"),Oyt.forEach(t),tlr=r(Vqe," \u2014 "),KQ=n(Vqe,"A",{href:!0});var Vyt=s(KQ);alr=r(Vyt,"FNetForQuestionAnswering"),Vyt.forEach(t),nlr=r(Vqe," (FNet model)"),Vqe.forEach(t),slr=i(X),fF=n(X,"LI",{});var Xqe=s(fF);ibe=n(Xqe,"STRONG",{});var Xyt=s(ibe);llr=r(Xyt,"funnel"),Xyt.forEach(t),ilr=r(Xqe," \u2014 "),ZQ=n(Xqe,"A",{href:!0});var zyt=s(ZQ);dlr=r(zyt,"FunnelForQuestionAnswering"),zyt.forEach(t),clr=r(Xqe," (Funnel Transformer model)"),Xqe.forEach(t),flr=i(X),mF=n(X,"LI",{});var zqe=s(mF);dbe=n(zqe,"STRONG",{});var Wyt=s(dbe);mlr=r(Wyt,"gptj"),Wyt.forEach(t),glr=r(zqe," \u2014 "),eU=n(zqe,"A",{href:!0});var Qyt=s(eU);hlr=r(Qyt,"GPTJForQuestionAnswering"),Qyt.forEach(t),plr=r(zqe," (GPT-J model)"),zqe.forEach(t),_lr=i(X),gF=n(X,"LI",{});var Wqe=s(gF);cbe=n(Wqe,"STRONG",{});var Uyt=s(cbe);ulr=r(Uyt,"ibert"),Uyt.forEach(t),blr=r(Wqe," \u2014 "),oU=n(Wqe,"A",{href:!0});var Hyt=s(oU);vlr=r(Hyt,"IBertForQuestionAnswering"),Hyt.forEach(t),Flr=r(Wqe," (I-BERT model)"),Wqe.forEach(t),Tlr=i(X),hF=n(X,"LI",{});var Qqe=s(hF);fbe=n(Qqe,"STRONG",{});var Jyt=s(fbe);Mlr=r(Jyt,"layoutlmv2"),Jyt.forEach(t),Elr=r(Qqe," \u2014 "),rU=n(Qqe,"A",{href:!0});var Yyt=s(rU);Clr=r(Yyt,"LayoutLMv2ForQuestionAnswering"),Yyt.forEach(t),wlr=r(Qqe," (LayoutLMv2 model)"),Qqe.forEach(t),Alr=i(X),pF=n(X,"LI",{});var Uqe=s(pF);mbe=n(Uqe,"STRONG",{});var Kyt=s(mbe);Llr=r(Kyt,"layoutlmv3"),Kyt.forEach(t),ylr=r(Uqe," \u2014 "),tU=n(Uqe,"A",{href:!0});var Zyt=s(tU);xlr=r(Zyt,"LayoutLMv3ForQuestionAnswering"),Zyt.forEach(t),$lr=r(Uqe," (LayoutLMv3 model)"),Uqe.forEach(t),klr=i(X),_F=n(X,"LI",{});var Hqe=s(_F);gbe=n(Hqe,"STRONG",{});var e9t=s(gbe);Slr=r(e9t,"led"),e9t.forEach(t),Rlr=r(Hqe," \u2014 "),aU=n(Hqe,"A",{href:!0});var o9t=s(aU);Plr=r(o9t,"LEDForQuestionAnswering"),o9t.forEach(t),Blr=r(Hqe," (LED model)"),Hqe.forEach(t),Ilr=i(X),uF=n(X,"LI",{});var Jqe=s(uF);hbe=n(Jqe,"STRONG",{});var r9t=s(hbe);Nlr=r(r9t,"longformer"),r9t.forEach(t),qlr=r(Jqe," \u2014 "),nU=n(Jqe,"A",{href:!0});var t9t=s(nU);jlr=r(t9t,"LongformerForQuestionAnswering"),t9t.forEach(t),Dlr=r(Jqe," (Longformer model)"),Jqe.forEach(t),Glr=i(X),bF=n(X,"LI",{});var Yqe=s(bF);pbe=n(Yqe,"STRONG",{});var a9t=s(pbe);Olr=r(a9t,"luke"),a9t.forEach(t),Vlr=r(Yqe," \u2014 "),sU=n(Yqe,"A",{href:!0});var n9t=s(sU);Xlr=r(n9t,"LukeForQuestionAnswering"),n9t.forEach(t),zlr=r(Yqe," (LUKE model)"),Yqe.forEach(t),Wlr=i(X),vF=n(X,"LI",{});var Kqe=s(vF);_be=n(Kqe,"STRONG",{});var s9t=s(_be);Qlr=r(s9t,"lxmert"),s9t.forEach(t),Ulr=r(Kqe," \u2014 "),lU=n(Kqe,"A",{href:!0});var l9t=s(lU);Hlr=r(l9t,"LxmertForQuestionAnswering"),l9t.forEach(t),Jlr=r(Kqe," (LXMERT model)"),Kqe.forEach(t),Ylr=i(X),FF=n(X,"LI",{});var Zqe=s(FF);ube=n(Zqe,"STRONG",{});var i9t=s(ube);Klr=r(i9t,"mbart"),i9t.forEach(t),Zlr=r(Zqe," \u2014 "),iU=n(Zqe,"A",{href:!0});var d9t=s(iU);eir=r(d9t,"MBartForQuestionAnswering"),d9t.forEach(t),oir=r(Zqe," (mBART model)"),Zqe.forEach(t),rir=i(X),TF=n(X,"LI",{});var eje=s(TF);bbe=n(eje,"STRONG",{});var c9t=s(bbe);tir=r(c9t,"megatron-bert"),c9t.forEach(t),air=r(eje," \u2014 "),dU=n(eje,"A",{href:!0});var f9t=s(dU);nir=r(f9t,"MegatronBertForQuestionAnswering"),f9t.forEach(t),sir=r(eje," (Megatron-BERT model)"),eje.forEach(t),lir=i(X),MF=n(X,"LI",{});var oje=s(MF);vbe=n(oje,"STRONG",{});var m9t=s(vbe);iir=r(m9t,"mobilebert"),m9t.forEach(t),dir=r(oje," \u2014 "),cU=n(oje,"A",{href:!0});var g9t=s(cU);cir=r(g9t,"MobileBertForQuestionAnswering"),g9t.forEach(t),fir=r(oje," (MobileBERT model)"),oje.forEach(t),mir=i(X),EF=n(X,"LI",{});var rje=s(EF);Fbe=n(rje,"STRONG",{});var h9t=s(Fbe);gir=r(h9t,"mpnet"),h9t.forEach(t),hir=r(rje," \u2014 "),fU=n(rje,"A",{href:!0});var p9t=s(fU);pir=r(p9t,"MPNetForQuestionAnswering"),p9t.forEach(t),_ir=r(rje," (MPNet model)"),rje.forEach(t),uir=i(X),CF=n(X,"LI",{});var tje=s(CF);Tbe=n(tje,"STRONG",{});var _9t=s(Tbe);bir=r(_9t,"mvp"),_9t.forEach(t),vir=r(tje," \u2014 "),mU=n(tje,"A",{href:!0});var u9t=s(mU);Fir=r(u9t,"MvpForQuestionAnswering"),u9t.forEach(t),Tir=r(tje," (MVP model)"),tje.forEach(t),Mir=i(X),wF=n(X,"LI",{});var aje=s(wF);Mbe=n(aje,"STRONG",{});var b9t=s(Mbe);Eir=r(b9t,"nezha"),b9t.forEach(t),Cir=r(aje," \u2014 "),gU=n(aje,"A",{href:!0});var v9t=s(gU);wir=r(v9t,"NezhaForQuestionAnswering"),v9t.forEach(t),Air=r(aje," (Nezha model)"),aje.forEach(t),Lir=i(X),AF=n(X,"LI",{});var nje=s(AF);Ebe=n(nje,"STRONG",{});var F9t=s(Ebe);yir=r(F9t,"nystromformer"),F9t.forEach(t),xir=r(nje," \u2014 "),hU=n(nje,"A",{href:!0});var T9t=s(hU);$ir=r(T9t,"NystromformerForQuestionAnswering"),T9t.forEach(t),kir=r(nje," (Nystr\xF6mformer model)"),nje.forEach(t),Sir=i(X),LF=n(X,"LI",{});var sje=s(LF);Cbe=n(sje,"STRONG",{});var M9t=s(Cbe);Rir=r(M9t,"qdqbert"),M9t.forEach(t),Pir=r(sje," \u2014 "),pU=n(sje,"A",{href:!0});var E9t=s(pU);Bir=r(E9t,"QDQBertForQuestionAnswering"),E9t.forEach(t),Iir=r(sje," (QDQBert model)"),sje.forEach(t),Nir=i(X),yF=n(X,"LI",{});var lje=s(yF);wbe=n(lje,"STRONG",{});var C9t=s(wbe);qir=r(C9t,"reformer"),C9t.forEach(t),jir=r(lje," \u2014 "),_U=n(lje,"A",{href:!0});var w9t=s(_U);Dir=r(w9t,"ReformerForQuestionAnswering"),w9t.forEach(t),Gir=r(lje," (Reformer model)"),lje.forEach(t),Oir=i(X),xF=n(X,"LI",{});var ije=s(xF);Abe=n(ije,"STRONG",{});var A9t=s(Abe);Vir=r(A9t,"rembert"),A9t.forEach(t),Xir=r(ije," \u2014 "),uU=n(ije,"A",{href:!0});var L9t=s(uU);zir=r(L9t,"RemBertForQuestionAnswering"),L9t.forEach(t),Wir=r(ije," (RemBERT model)"),ije.forEach(t),Qir=i(X),$F=n(X,"LI",{});var dje=s($F);Lbe=n(dje,"STRONG",{});var y9t=s(Lbe);Uir=r(y9t,"roberta"),y9t.forEach(t),Hir=r(dje," \u2014 "),bU=n(dje,"A",{href:!0});var x9t=s(bU);Jir=r(x9t,"RobertaForQuestionAnswering"),x9t.forEach(t),Yir=r(dje," (RoBERTa model)"),dje.forEach(t),Kir=i(X),kF=n(X,"LI",{});var cje=s(kF);ybe=n(cje,"STRONG",{});var $9t=s(ybe);Zir=r($9t,"roformer"),$9t.forEach(t),edr=r(cje," \u2014 "),vU=n(cje,"A",{href:!0});var k9t=s(vU);odr=r(k9t,"RoFormerForQuestionAnswering"),k9t.forEach(t),rdr=r(cje," (RoFormer model)"),cje.forEach(t),tdr=i(X),SF=n(X,"LI",{});var fje=s(SF);xbe=n(fje,"STRONG",{});var S9t=s(xbe);adr=r(S9t,"splinter"),S9t.forEach(t),ndr=r(fje," \u2014 "),FU=n(fje,"A",{href:!0});var R9t=s(FU);sdr=r(R9t,"SplinterForQuestionAnswering"),R9t.forEach(t),ldr=r(fje," (Splinter model)"),fje.forEach(t),idr=i(X),RF=n(X,"LI",{});var mje=s(RF);$be=n(mje,"STRONG",{});var P9t=s($be);ddr=r(P9t,"squeezebert"),P9t.forEach(t),cdr=r(mje," \u2014 "),TU=n(mje,"A",{href:!0});var B9t=s(TU);fdr=r(B9t,"SqueezeBertForQuestionAnswering"),B9t.forEach(t),mdr=r(mje," (SqueezeBERT model)"),mje.forEach(t),gdr=i(X),PF=n(X,"LI",{});var gje=s(PF);kbe=n(gje,"STRONG",{});var I9t=s(kbe);hdr=r(I9t,"xlm"),I9t.forEach(t),pdr=r(gje," \u2014 "),MU=n(gje,"A",{href:!0});var N9t=s(MU);_dr=r(N9t,"XLMForQuestionAnsweringSimple"),N9t.forEach(t),udr=r(gje," (XLM model)"),gje.forEach(t),bdr=i(X),BF=n(X,"LI",{});var hje=s(BF);Sbe=n(hje,"STRONG",{});var q9t=s(Sbe);vdr=r(q9t,"xlm-roberta"),q9t.forEach(t),Fdr=r(hje," \u2014 "),EU=n(hje,"A",{href:!0});var j9t=s(EU);Tdr=r(j9t,"XLMRobertaForQuestionAnswering"),j9t.forEach(t),Mdr=r(hje," (XLM-RoBERTa model)"),hje.forEach(t),Edr=i(X),IF=n(X,"LI",{});var pje=s(IF);Rbe=n(pje,"STRONG",{});var D9t=s(Rbe);Cdr=r(D9t,"xlm-roberta-xl"),D9t.forEach(t),wdr=r(pje," \u2014 "),CU=n(pje,"A",{href:!0});var G9t=s(CU);Adr=r(G9t,"XLMRobertaXLForQuestionAnswering"),G9t.forEach(t),Ldr=r(pje," (XLM-RoBERTa-XL model)"),pje.forEach(t),ydr=i(X),NF=n(X,"LI",{});var _je=s(NF);Pbe=n(_je,"STRONG",{});var O9t=s(Pbe);xdr=r(O9t,"xlnet"),O9t.forEach(t),$dr=r(_je," \u2014 "),wU=n(_je,"A",{href:!0});var V9t=s(wU);kdr=r(V9t,"XLNetForQuestionAnsweringSimple"),V9t.forEach(t),Sdr=r(_je," (XLNet model)"),_je.forEach(t),Rdr=i(X),qF=n(X,"LI",{});var uje=s(qF);Bbe=n(uje,"STRONG",{});var X9t=s(Bbe);Pdr=r(X9t,"yoso"),X9t.forEach(t),Bdr=r(uje," \u2014 "),AU=n(uje,"A",{href:!0});var z9t=s(AU);Idr=r(z9t,"YosoForQuestionAnswering"),z9t.forEach(t),Ndr=r(uje," (YOSO model)"),uje.forEach(t),X.forEach(t),qdr=i(Fa),jF=n(Fa,"P",{});var bje=s(jF);jdr=r(bje,"The model is set in evaluation mode by default using "),Ibe=n(bje,"CODE",{});var W9t=s(Ibe);Ddr=r(W9t,"model.eval()"),W9t.forEach(t),Gdr=r(bje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nbe=n(bje,"CODE",{});var Q9t=s(Nbe);Odr=r(Q9t,"model.train()"),Q9t.forEach(t),bje.forEach(t),Vdr=i(Fa),T(DF.$$.fragment,Fa),Fa.forEach(t),vl.forEach(t),bQe=i(f),Ad=n(f,"H2",{class:!0});var AHe=s(Ad);GF=n(AHe,"A",{id:!0,class:!0,href:!0});var U9t=s(GF);qbe=n(U9t,"SPAN",{});var H9t=s(qbe);T(p9.$$.fragment,H9t),H9t.forEach(t),U9t.forEach(t),Xdr=i(AHe),jbe=n(AHe,"SPAN",{});var J9t=s(jbe);zdr=r(J9t,"AutoModelForTableQuestionAnswering"),J9t.forEach(t),AHe.forEach(t),vQe=i(f),Vo=n(f,"DIV",{class:!0});var Fl=s(Vo);T(_9.$$.fragment,Fl),Wdr=i(Fl),Ld=n(Fl,"P",{});var wae=s(Ld);Qdr=r(wae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),LU=n(wae,"A",{href:!0});var Y9t=s(LU);Udr=r(Y9t,"from_pretrained()"),Y9t.forEach(t),Hdr=r(wae," class method or the "),yU=n(wae,"A",{href:!0});var K9t=s(yU);Jdr=r(K9t,"from_config()"),K9t.forEach(t),Ydr=r(wae,` class
method.`),wae.forEach(t),Kdr=i(Fl),u9=n(Fl,"P",{});var LHe=s(u9);Zdr=r(LHe,"This class cannot be instantiated directly using "),Dbe=n(LHe,"CODE",{});var Z9t=s(Dbe);ecr=r(Z9t,"__init__()"),Z9t.forEach(t),ocr=r(LHe," (throws an error)."),LHe.forEach(t),rcr=i(Fl),Ft=n(Fl,"DIV",{class:!0});var h7=s(Ft);T(b9.$$.fragment,h7),tcr=i(h7),Gbe=n(h7,"P",{});var ext=s(Gbe);acr=r(ext,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),ext.forEach(t),ncr=i(h7),yd=n(h7,"P",{});var Aae=s(yd);scr=r(Aae,`Note:
Loading a model from its configuration file does `),Obe=n(Aae,"STRONG",{});var oxt=s(Obe);lcr=r(oxt,"not"),oxt.forEach(t),icr=r(Aae,` load the model weights. It only affects the
model\u2019s configuration. Use `),xU=n(Aae,"A",{href:!0});var rxt=s(xU);dcr=r(rxt,"from_pretrained()"),rxt.forEach(t),ccr=r(Aae," to load the model weights."),Aae.forEach(t),fcr=i(h7),T(OF.$$.fragment,h7),h7.forEach(t),mcr=i(Fl),lo=n(Fl,"DIV",{class:!0});var Ta=s(lo);T(v9.$$.fragment,Ta),gcr=i(Ta),Vbe=n(Ta,"P",{});var txt=s(Vbe);hcr=r(txt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),txt.forEach(t),pcr=i(Ta),Ja=n(Ta,"P",{});var p7=s(Ja);_cr=r(p7,"The model class to instantiate is selected based on the "),Xbe=n(p7,"CODE",{});var axt=s(Xbe);ucr=r(axt,"model_type"),axt.forEach(t),bcr=r(p7,` property of the config object (either
passed as an argument or loaded from `),zbe=n(p7,"CODE",{});var nxt=s(zbe);vcr=r(nxt,"pretrained_model_name_or_path"),nxt.forEach(t),Fcr=r(p7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wbe=n(p7,"CODE",{});var sxt=s(Wbe);Tcr=r(sxt,"pretrained_model_name_or_path"),sxt.forEach(t),Mcr=r(p7,":"),p7.forEach(t),Ecr=i(Ta),Qbe=n(Ta,"UL",{});var lxt=s(Qbe);VF=n(lxt,"LI",{});var vje=s(VF);Ube=n(vje,"STRONG",{});var ixt=s(Ube);Ccr=r(ixt,"tapas"),ixt.forEach(t),wcr=r(vje," \u2014 "),$U=n(vje,"A",{href:!0});var dxt=s($U);Acr=r(dxt,"TapasForQuestionAnswering"),dxt.forEach(t),Lcr=r(vje," (TAPAS model)"),vje.forEach(t),lxt.forEach(t),ycr=i(Ta),XF=n(Ta,"P",{});var Fje=s(XF);xcr=r(Fje,"The model is set in evaluation mode by default using "),Hbe=n(Fje,"CODE",{});var cxt=s(Hbe);$cr=r(cxt,"model.eval()"),cxt.forEach(t),kcr=r(Fje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=n(Fje,"CODE",{});var fxt=s(Jbe);Scr=r(fxt,"model.train()"),fxt.forEach(t),Fje.forEach(t),Rcr=i(Ta),T(zF.$$.fragment,Ta),Ta.forEach(t),Fl.forEach(t),FQe=i(f),xd=n(f,"H2",{class:!0});var yHe=s(xd);WF=n(yHe,"A",{id:!0,class:!0,href:!0});var mxt=s(WF);Ybe=n(mxt,"SPAN",{});var gxt=s(Ybe);T(F9.$$.fragment,gxt),gxt.forEach(t),mxt.forEach(t),Pcr=i(yHe),Kbe=n(yHe,"SPAN",{});var hxt=s(Kbe);Bcr=r(hxt,"AutoModelForImageClassification"),hxt.forEach(t),yHe.forEach(t),TQe=i(f),Xo=n(f,"DIV",{class:!0});var Tl=s(Xo);T(T9.$$.fragment,Tl),Icr=i(Tl),$d=n(Tl,"P",{});var Lae=s($d);Ncr=r(Lae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),kU=n(Lae,"A",{href:!0});var pxt=s(kU);qcr=r(pxt,"from_pretrained()"),pxt.forEach(t),jcr=r(Lae," class method or the "),SU=n(Lae,"A",{href:!0});var _xt=s(SU);Dcr=r(_xt,"from_config()"),_xt.forEach(t),Gcr=r(Lae,` class
method.`),Lae.forEach(t),Ocr=i(Tl),M9=n(Tl,"P",{});var xHe=s(M9);Vcr=r(xHe,"This class cannot be instantiated directly using "),Zbe=n(xHe,"CODE",{});var uxt=s(Zbe);Xcr=r(uxt,"__init__()"),uxt.forEach(t),zcr=r(xHe," (throws an error)."),xHe.forEach(t),Wcr=i(Tl),Tt=n(Tl,"DIV",{class:!0});var _7=s(Tt);T(E9.$$.fragment,_7),Qcr=i(_7),eve=n(_7,"P",{});var bxt=s(eve);Ucr=r(bxt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),bxt.forEach(t),Hcr=i(_7),kd=n(_7,"P",{});var yae=s(kd);Jcr=r(yae,`Note:
Loading a model from its configuration file does `),ove=n(yae,"STRONG",{});var vxt=s(ove);Ycr=r(vxt,"not"),vxt.forEach(t),Kcr=r(yae,` load the model weights. It only affects the
model\u2019s configuration. Use `),RU=n(yae,"A",{href:!0});var Fxt=s(RU);Zcr=r(Fxt,"from_pretrained()"),Fxt.forEach(t),efr=r(yae," to load the model weights."),yae.forEach(t),ofr=i(_7),T(QF.$$.fragment,_7),_7.forEach(t),rfr=i(Tl),io=n(Tl,"DIV",{class:!0});var Ma=s(io);T(C9.$$.fragment,Ma),tfr=i(Ma),rve=n(Ma,"P",{});var Txt=s(rve);afr=r(Txt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Txt.forEach(t),nfr=i(Ma),Ya=n(Ma,"P",{});var u7=s(Ya);sfr=r(u7,"The model class to instantiate is selected based on the "),tve=n(u7,"CODE",{});var Mxt=s(tve);lfr=r(Mxt,"model_type"),Mxt.forEach(t),ifr=r(u7,` property of the config object (either
passed as an argument or loaded from `),ave=n(u7,"CODE",{});var Ext=s(ave);dfr=r(Ext,"pretrained_model_name_or_path"),Ext.forEach(t),cfr=r(u7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=n(u7,"CODE",{});var Cxt=s(nve);ffr=r(Cxt,"pretrained_model_name_or_path"),Cxt.forEach(t),mfr=r(u7,":"),u7.forEach(t),gfr=i(Ma),be=n(Ma,"UL",{});var Fe=s(be);UF=n(Fe,"LI",{});var Tje=s(UF);sve=n(Tje,"STRONG",{});var wxt=s(sve);hfr=r(wxt,"beit"),wxt.forEach(t),pfr=r(Tje," \u2014 "),PU=n(Tje,"A",{href:!0});var Axt=s(PU);_fr=r(Axt,"BeitForImageClassification"),Axt.forEach(t),ufr=r(Tje," (BEiT model)"),Tje.forEach(t),bfr=i(Fe),HF=n(Fe,"LI",{});var Mje=s(HF);lve=n(Mje,"STRONG",{});var Lxt=s(lve);vfr=r(Lxt,"convnext"),Lxt.forEach(t),Ffr=r(Mje," \u2014 "),BU=n(Mje,"A",{href:!0});var yxt=s(BU);Tfr=r(yxt,"ConvNextForImageClassification"),yxt.forEach(t),Mfr=r(Mje," (ConvNeXT model)"),Mje.forEach(t),Efr=i(Fe),JF=n(Fe,"LI",{});var Eje=s(JF);ive=n(Eje,"STRONG",{});var xxt=s(ive);Cfr=r(xxt,"cvt"),xxt.forEach(t),wfr=r(Eje," \u2014 "),IU=n(Eje,"A",{href:!0});var $xt=s(IU);Afr=r($xt,"CvtForImageClassification"),$xt.forEach(t),Lfr=r(Eje," (CvT model)"),Eje.forEach(t),yfr=i(Fe),YF=n(Fe,"LI",{});var Cje=s(YF);dve=n(Cje,"STRONG",{});var kxt=s(dve);xfr=r(kxt,"data2vec-vision"),kxt.forEach(t),$fr=r(Cje," \u2014 "),NU=n(Cje,"A",{href:!0});var Sxt=s(NU);kfr=r(Sxt,"Data2VecVisionForImageClassification"),Sxt.forEach(t),Sfr=r(Cje," (Data2VecVision model)"),Cje.forEach(t),Rfr=i(Fe),rl=n(Fe,"LI",{});var LR=s(rl);cve=n(LR,"STRONG",{});var Rxt=s(cve);Pfr=r(Rxt,"deit"),Rxt.forEach(t),Bfr=r(LR," \u2014 "),qU=n(LR,"A",{href:!0});var Pxt=s(qU);Ifr=r(Pxt,"DeiTForImageClassification"),Pxt.forEach(t),Nfr=r(LR," or "),jU=n(LR,"A",{href:!0});var Bxt=s(jU);qfr=r(Bxt,"DeiTForImageClassificationWithTeacher"),Bxt.forEach(t),jfr=r(LR," (DeiT model)"),LR.forEach(t),Dfr=i(Fe),KF=n(Fe,"LI",{});var wje=s(KF);fve=n(wje,"STRONG",{});var Ixt=s(fve);Gfr=r(Ixt,"imagegpt"),Ixt.forEach(t),Ofr=r(wje," \u2014 "),DU=n(wje,"A",{href:!0});var Nxt=s(DU);Vfr=r(Nxt,"ImageGPTForImageClassification"),Nxt.forEach(t),Xfr=r(wje," (ImageGPT model)"),wje.forEach(t),zfr=i(Fe),tl=n(Fe,"LI",{});var yR=s(tl);mve=n(yR,"STRONG",{});var qxt=s(mve);Wfr=r(qxt,"levit"),qxt.forEach(t),Qfr=r(yR," \u2014 "),GU=n(yR,"A",{href:!0});var jxt=s(GU);Ufr=r(jxt,"LevitForImageClassification"),jxt.forEach(t),Hfr=r(yR," or "),OU=n(yR,"A",{href:!0});var Dxt=s(OU);Jfr=r(Dxt,"LevitForImageClassificationWithTeacher"),Dxt.forEach(t),Yfr=r(yR," (LeViT model)"),yR.forEach(t),Kfr=i(Fe),ZF=n(Fe,"LI",{});var Aje=s(ZF);gve=n(Aje,"STRONG",{});var Gxt=s(gve);Zfr=r(Gxt,"mobilevit"),Gxt.forEach(t),emr=r(Aje," \u2014 "),VU=n(Aje,"A",{href:!0});var Oxt=s(VU);omr=r(Oxt,"MobileViTForImageClassification"),Oxt.forEach(t),rmr=r(Aje," (MobileViT model)"),Aje.forEach(t),tmr=i(Fe),Mt=n(Fe,"LI",{});var Xf=s(Mt);hve=n(Xf,"STRONG",{});var Vxt=s(hve);amr=r(Vxt,"perceiver"),Vxt.forEach(t),nmr=r(Xf," \u2014 "),XU=n(Xf,"A",{href:!0});var Xxt=s(XU);smr=r(Xxt,"PerceiverForImageClassificationLearned"),Xxt.forEach(t),lmr=r(Xf," or "),zU=n(Xf,"A",{href:!0});var zxt=s(zU);imr=r(zxt,"PerceiverForImageClassificationFourier"),zxt.forEach(t),dmr=r(Xf," or "),WU=n(Xf,"A",{href:!0});var Wxt=s(WU);cmr=r(Wxt,"PerceiverForImageClassificationConvProcessing"),Wxt.forEach(t),fmr=r(Xf," (Perceiver model)"),Xf.forEach(t),mmr=i(Fe),eT=n(Fe,"LI",{});var Lje=s(eT);pve=n(Lje,"STRONG",{});var Qxt=s(pve);gmr=r(Qxt,"poolformer"),Qxt.forEach(t),hmr=r(Lje," \u2014 "),QU=n(Lje,"A",{href:!0});var Uxt=s(QU);pmr=r(Uxt,"PoolFormerForImageClassification"),Uxt.forEach(t),_mr=r(Lje," (PoolFormer model)"),Lje.forEach(t),umr=i(Fe),oT=n(Fe,"LI",{});var yje=s(oT);_ve=n(yje,"STRONG",{});var Hxt=s(_ve);bmr=r(Hxt,"regnet"),Hxt.forEach(t),vmr=r(yje," \u2014 "),UU=n(yje,"A",{href:!0});var Jxt=s(UU);Fmr=r(Jxt,"RegNetForImageClassification"),Jxt.forEach(t),Tmr=r(yje," (RegNet model)"),yje.forEach(t),Mmr=i(Fe),rT=n(Fe,"LI",{});var xje=s(rT);uve=n(xje,"STRONG",{});var Yxt=s(uve);Emr=r(Yxt,"resnet"),Yxt.forEach(t),Cmr=r(xje," \u2014 "),HU=n(xje,"A",{href:!0});var Kxt=s(HU);wmr=r(Kxt,"ResNetForImageClassification"),Kxt.forEach(t),Amr=r(xje," (ResNet model)"),xje.forEach(t),Lmr=i(Fe),tT=n(Fe,"LI",{});var $je=s(tT);bve=n($je,"STRONG",{});var Zxt=s(bve);ymr=r(Zxt,"segformer"),Zxt.forEach(t),xmr=r($je," \u2014 "),JU=n($je,"A",{href:!0});var e$t=s(JU);$mr=r(e$t,"SegformerForImageClassification"),e$t.forEach(t),kmr=r($je," (SegFormer model)"),$je.forEach(t),Smr=i(Fe),aT=n(Fe,"LI",{});var kje=s(aT);vve=n(kje,"STRONG",{});var o$t=s(vve);Rmr=r(o$t,"swin"),o$t.forEach(t),Pmr=r(kje," \u2014 "),YU=n(kje,"A",{href:!0});var r$t=s(YU);Bmr=r(r$t,"SwinForImageClassification"),r$t.forEach(t),Imr=r(kje," (Swin Transformer model)"),kje.forEach(t),Nmr=i(Fe),nT=n(Fe,"LI",{});var Sje=s(nT);Fve=n(Sje,"STRONG",{});var t$t=s(Fve);qmr=r(t$t,"swinv2"),t$t.forEach(t),jmr=r(Sje," \u2014 "),KU=n(Sje,"A",{href:!0});var a$t=s(KU);Dmr=r(a$t,"Swinv2ForImageClassification"),a$t.forEach(t),Gmr=r(Sje," (Swin Transformer V2 model)"),Sje.forEach(t),Omr=i(Fe),sT=n(Fe,"LI",{});var Rje=s(sT);Tve=n(Rje,"STRONG",{});var n$t=s(Tve);Vmr=r(n$t,"van"),n$t.forEach(t),Xmr=r(Rje," \u2014 "),ZU=n(Rje,"A",{href:!0});var s$t=s(ZU);zmr=r(s$t,"VanForImageClassification"),s$t.forEach(t),Wmr=r(Rje," (VAN model)"),Rje.forEach(t),Qmr=i(Fe),lT=n(Fe,"LI",{});var Pje=s(lT);Mve=n(Pje,"STRONG",{});var l$t=s(Mve);Umr=r(l$t,"vit"),l$t.forEach(t),Hmr=r(Pje," \u2014 "),eH=n(Pje,"A",{href:!0});var i$t=s(eH);Jmr=r(i$t,"ViTForImageClassification"),i$t.forEach(t),Ymr=r(Pje," (ViT model)"),Pje.forEach(t),Fe.forEach(t),Kmr=i(Ma),iT=n(Ma,"P",{});var Bje=s(iT);Zmr=r(Bje,"The model is set in evaluation mode by default using "),Eve=n(Bje,"CODE",{});var d$t=s(Eve);egr=r(d$t,"model.eval()"),d$t.forEach(t),ogr=r(Bje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Cve=n(Bje,"CODE",{});var c$t=s(Cve);rgr=r(c$t,"model.train()"),c$t.forEach(t),Bje.forEach(t),tgr=i(Ma),T(dT.$$.fragment,Ma),Ma.forEach(t),Tl.forEach(t),MQe=i(f),Sd=n(f,"H2",{class:!0});var $He=s(Sd);cT=n($He,"A",{id:!0,class:!0,href:!0});var f$t=s(cT);wve=n(f$t,"SPAN",{});var m$t=s(wve);T(w9.$$.fragment,m$t),m$t.forEach(t),f$t.forEach(t),agr=i($He),Ave=n($He,"SPAN",{});var g$t=s(Ave);ngr=r(g$t,"AutoModelForVideoClassification"),g$t.forEach(t),$He.forEach(t),EQe=i(f),zo=n(f,"DIV",{class:!0});var Ml=s(zo);T(A9.$$.fragment,Ml),sgr=i(Ml),Rd=n(Ml,"P",{});var xae=s(Rd);lgr=r(xae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),oH=n(xae,"A",{href:!0});var h$t=s(oH);igr=r(h$t,"from_pretrained()"),h$t.forEach(t),dgr=r(xae," class method or the "),rH=n(xae,"A",{href:!0});var p$t=s(rH);cgr=r(p$t,"from_config()"),p$t.forEach(t),fgr=r(xae,` class
method.`),xae.forEach(t),mgr=i(Ml),L9=n(Ml,"P",{});var kHe=s(L9);ggr=r(kHe,"This class cannot be instantiated directly using "),Lve=n(kHe,"CODE",{});var _$t=s(Lve);hgr=r(_$t,"__init__()"),_$t.forEach(t),pgr=r(kHe," (throws an error)."),kHe.forEach(t),_gr=i(Ml),Et=n(Ml,"DIV",{class:!0});var b7=s(Et);T(y9.$$.fragment,b7),ugr=i(b7),yve=n(b7,"P",{});var u$t=s(yve);bgr=r(u$t,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),u$t.forEach(t),vgr=i(b7),Pd=n(b7,"P",{});var $ae=s(Pd);Fgr=r($ae,`Note:
Loading a model from its configuration file does `),xve=n($ae,"STRONG",{});var b$t=s(xve);Tgr=r(b$t,"not"),b$t.forEach(t),Mgr=r($ae,` load the model weights. It only affects the
model\u2019s configuration. Use `),tH=n($ae,"A",{href:!0});var v$t=s(tH);Egr=r(v$t,"from_pretrained()"),v$t.forEach(t),Cgr=r($ae," to load the model weights."),$ae.forEach(t),wgr=i(b7),T(fT.$$.fragment,b7),b7.forEach(t),Agr=i(Ml),co=n(Ml,"DIV",{class:!0});var Ea=s(co);T(x9.$$.fragment,Ea),Lgr=i(Ea),$ve=n(Ea,"P",{});var F$t=s($ve);ygr=r(F$t,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),F$t.forEach(t),xgr=i(Ea),Ka=n(Ea,"P",{});var v7=s(Ka);$gr=r(v7,"The model class to instantiate is selected based on the "),kve=n(v7,"CODE",{});var T$t=s(kve);kgr=r(T$t,"model_type"),T$t.forEach(t),Sgr=r(v7,` property of the config object (either
passed as an argument or loaded from `),Sve=n(v7,"CODE",{});var M$t=s(Sve);Rgr=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),Pgr=r(v7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Rve=n(v7,"CODE",{});var E$t=s(Rve);Bgr=r(E$t,"pretrained_model_name_or_path"),E$t.forEach(t),Igr=r(v7,":"),v7.forEach(t),Ngr=i(Ea),Pve=n(Ea,"UL",{});var C$t=s(Pve);mT=n(C$t,"LI",{});var Ije=s(mT);Bve=n(Ije,"STRONG",{});var w$t=s(Bve);qgr=r(w$t,"videomae"),w$t.forEach(t),jgr=r(Ije," \u2014 "),aH=n(Ije,"A",{href:!0});var A$t=s(aH);Dgr=r(A$t,"VideoMAEForVideoClassification"),A$t.forEach(t),Ggr=r(Ije," (VideoMAE model)"),Ije.forEach(t),C$t.forEach(t),Ogr=i(Ea),gT=n(Ea,"P",{});var Nje=s(gT);Vgr=r(Nje,"The model is set in evaluation mode by default using "),Ive=n(Nje,"CODE",{});var L$t=s(Ive);Xgr=r(L$t,"model.eval()"),L$t.forEach(t),zgr=r(Nje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nve=n(Nje,"CODE",{});var y$t=s(Nve);Wgr=r(y$t,"model.train()"),y$t.forEach(t),Nje.forEach(t),Qgr=i(Ea),T(hT.$$.fragment,Ea),Ea.forEach(t),Ml.forEach(t),CQe=i(f),Bd=n(f,"H2",{class:!0});var SHe=s(Bd);pT=n(SHe,"A",{id:!0,class:!0,href:!0});var x$t=s(pT);qve=n(x$t,"SPAN",{});var $$t=s(qve);T($9.$$.fragment,$$t),$$t.forEach(t),x$t.forEach(t),Ugr=i(SHe),jve=n(SHe,"SPAN",{});var k$t=s(jve);Hgr=r(k$t,"AutoModelForVision2Seq"),k$t.forEach(t),SHe.forEach(t),wQe=i(f),Wo=n(f,"DIV",{class:!0});var El=s(Wo);T(k9.$$.fragment,El),Jgr=i(El),Id=n(El,"P",{});var kae=s(Id);Ygr=r(kae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),nH=n(kae,"A",{href:!0});var S$t=s(nH);Kgr=r(S$t,"from_pretrained()"),S$t.forEach(t),Zgr=r(kae," class method or the "),sH=n(kae,"A",{href:!0});var R$t=s(sH);ehr=r(R$t,"from_config()"),R$t.forEach(t),ohr=r(kae,` class
method.`),kae.forEach(t),rhr=i(El),S9=n(El,"P",{});var RHe=s(S9);thr=r(RHe,"This class cannot be instantiated directly using "),Dve=n(RHe,"CODE",{});var P$t=s(Dve);ahr=r(P$t,"__init__()"),P$t.forEach(t),nhr=r(RHe," (throws an error)."),RHe.forEach(t),shr=i(El),Ct=n(El,"DIV",{class:!0});var F7=s(Ct);T(R9.$$.fragment,F7),lhr=i(F7),Gve=n(F7,"P",{});var B$t=s(Gve);ihr=r(B$t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),B$t.forEach(t),dhr=i(F7),Nd=n(F7,"P",{});var Sae=s(Nd);chr=r(Sae,`Note:
Loading a model from its configuration file does `),Ove=n(Sae,"STRONG",{});var I$t=s(Ove);fhr=r(I$t,"not"),I$t.forEach(t),mhr=r(Sae,` load the model weights. It only affects the
model\u2019s configuration. Use `),lH=n(Sae,"A",{href:!0});var N$t=s(lH);ghr=r(N$t,"from_pretrained()"),N$t.forEach(t),hhr=r(Sae," to load the model weights."),Sae.forEach(t),phr=i(F7),T(_T.$$.fragment,F7),F7.forEach(t),_hr=i(El),fo=n(El,"DIV",{class:!0});var Ca=s(fo);T(P9.$$.fragment,Ca),uhr=i(Ca),Vve=n(Ca,"P",{});var q$t=s(Vve);bhr=r(q$t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),q$t.forEach(t),vhr=i(Ca),Za=n(Ca,"P",{});var T7=s(Za);Fhr=r(T7,"The model class to instantiate is selected based on the "),Xve=n(T7,"CODE",{});var j$t=s(Xve);Thr=r(j$t,"model_type"),j$t.forEach(t),Mhr=r(T7,` property of the config object (either
passed as an argument or loaded from `),zve=n(T7,"CODE",{});var D$t=s(zve);Ehr=r(D$t,"pretrained_model_name_or_path"),D$t.forEach(t),Chr=r(T7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wve=n(T7,"CODE",{});var G$t=s(Wve);whr=r(G$t,"pretrained_model_name_or_path"),G$t.forEach(t),Ahr=r(T7,":"),T7.forEach(t),Lhr=i(Ca),Qve=n(Ca,"UL",{});var O$t=s(Qve);uT=n(O$t,"LI",{});var qje=s(uT);Uve=n(qje,"STRONG",{});var V$t=s(Uve);yhr=r(V$t,"vision-encoder-decoder"),V$t.forEach(t),xhr=r(qje," \u2014 "),iH=n(qje,"A",{href:!0});var X$t=s(iH);$hr=r(X$t,"VisionEncoderDecoderModel"),X$t.forEach(t),khr=r(qje," (Vision Encoder decoder model)"),qje.forEach(t),O$t.forEach(t),Shr=i(Ca),bT=n(Ca,"P",{});var jje=s(bT);Rhr=r(jje,"The model is set in evaluation mode by default using "),Hve=n(jje,"CODE",{});var z$t=s(Hve);Phr=r(z$t,"model.eval()"),z$t.forEach(t),Bhr=r(jje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jve=n(jje,"CODE",{});var W$t=s(Jve);Ihr=r(W$t,"model.train()"),W$t.forEach(t),jje.forEach(t),Nhr=i(Ca),T(vT.$$.fragment,Ca),Ca.forEach(t),El.forEach(t),AQe=i(f),qd=n(f,"H2",{class:!0});var PHe=s(qd);FT=n(PHe,"A",{id:!0,class:!0,href:!0});var Q$t=s(FT);Yve=n(Q$t,"SPAN",{});var U$t=s(Yve);T(B9.$$.fragment,U$t),U$t.forEach(t),Q$t.forEach(t),qhr=i(PHe),Kve=n(PHe,"SPAN",{});var H$t=s(Kve);jhr=r(H$t,"AutoModelForVisualQuestionAnswering"),H$t.forEach(t),PHe.forEach(t),LQe=i(f),Qo=n(f,"DIV",{class:!0});var Cl=s(Qo);T(I9.$$.fragment,Cl),Dhr=i(Cl),jd=n(Cl,"P",{});var Rae=s(jd);Ghr=r(Rae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),dH=n(Rae,"A",{href:!0});var J$t=s(dH);Ohr=r(J$t,"from_pretrained()"),J$t.forEach(t),Vhr=r(Rae," class method or the "),cH=n(Rae,"A",{href:!0});var Y$t=s(cH);Xhr=r(Y$t,"from_config()"),Y$t.forEach(t),zhr=r(Rae,` class
method.`),Rae.forEach(t),Whr=i(Cl),N9=n(Cl,"P",{});var BHe=s(N9);Qhr=r(BHe,"This class cannot be instantiated directly using "),Zve=n(BHe,"CODE",{});var K$t=s(Zve);Uhr=r(K$t,"__init__()"),K$t.forEach(t),Hhr=r(BHe," (throws an error)."),BHe.forEach(t),Jhr=i(Cl),wt=n(Cl,"DIV",{class:!0});var M7=s(wt);T(q9.$$.fragment,M7),Yhr=i(M7),e5e=n(M7,"P",{});var Z$t=s(e5e);Khr=r(Z$t,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Z$t.forEach(t),Zhr=i(M7),Dd=n(M7,"P",{});var Pae=s(Dd);epr=r(Pae,`Note:
Loading a model from its configuration file does `),o5e=n(Pae,"STRONG",{});var ekt=s(o5e);opr=r(ekt,"not"),ekt.forEach(t),rpr=r(Pae,` load the model weights. It only affects the
model\u2019s configuration. Use `),fH=n(Pae,"A",{href:!0});var okt=s(fH);tpr=r(okt,"from_pretrained()"),okt.forEach(t),apr=r(Pae," to load the model weights."),Pae.forEach(t),npr=i(M7),T(TT.$$.fragment,M7),M7.forEach(t),spr=i(Cl),mo=n(Cl,"DIV",{class:!0});var wa=s(mo);T(j9.$$.fragment,wa),lpr=i(wa),r5e=n(wa,"P",{});var rkt=s(r5e);ipr=r(rkt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),rkt.forEach(t),dpr=i(wa),en=n(wa,"P",{});var E7=s(en);cpr=r(E7,"The model class to instantiate is selected based on the "),t5e=n(E7,"CODE",{});var tkt=s(t5e);fpr=r(tkt,"model_type"),tkt.forEach(t),mpr=r(E7,` property of the config object (either
passed as an argument or loaded from `),a5e=n(E7,"CODE",{});var akt=s(a5e);gpr=r(akt,"pretrained_model_name_or_path"),akt.forEach(t),hpr=r(E7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n5e=n(E7,"CODE",{});var nkt=s(n5e);ppr=r(nkt,"pretrained_model_name_or_path"),nkt.forEach(t),_pr=r(E7,":"),E7.forEach(t),upr=i(wa),s5e=n(wa,"UL",{});var skt=s(s5e);MT=n(skt,"LI",{});var Dje=s(MT);l5e=n(Dje,"STRONG",{});var lkt=s(l5e);bpr=r(lkt,"vilt"),lkt.forEach(t),vpr=r(Dje," \u2014 "),mH=n(Dje,"A",{href:!0});var ikt=s(mH);Fpr=r(ikt,"ViltForQuestionAnswering"),ikt.forEach(t),Tpr=r(Dje," (ViLT model)"),Dje.forEach(t),skt.forEach(t),Mpr=i(wa),ET=n(wa,"P",{});var Gje=s(ET);Epr=r(Gje,"The model is set in evaluation mode by default using "),i5e=n(Gje,"CODE",{});var dkt=s(i5e);Cpr=r(dkt,"model.eval()"),dkt.forEach(t),wpr=r(Gje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),d5e=n(Gje,"CODE",{});var ckt=s(d5e);Apr=r(ckt,"model.train()"),ckt.forEach(t),Gje.forEach(t),Lpr=i(wa),T(CT.$$.fragment,wa),wa.forEach(t),Cl.forEach(t),yQe=i(f),Gd=n(f,"H2",{class:!0});var IHe=s(Gd);wT=n(IHe,"A",{id:!0,class:!0,href:!0});var fkt=s(wT);c5e=n(fkt,"SPAN",{});var mkt=s(c5e);T(D9.$$.fragment,mkt),mkt.forEach(t),fkt.forEach(t),ypr=i(IHe),f5e=n(IHe,"SPAN",{});var gkt=s(f5e);xpr=r(gkt,"AutoModelForAudioClassification"),gkt.forEach(t),IHe.forEach(t),xQe=i(f),Uo=n(f,"DIV",{class:!0});var wl=s(Uo);T(G9.$$.fragment,wl),$pr=i(wl),Od=n(wl,"P",{});var Bae=s(Od);kpr=r(Bae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),gH=n(Bae,"A",{href:!0});var hkt=s(gH);Spr=r(hkt,"from_pretrained()"),hkt.forEach(t),Rpr=r(Bae," class method or the "),hH=n(Bae,"A",{href:!0});var pkt=s(hH);Ppr=r(pkt,"from_config()"),pkt.forEach(t),Bpr=r(Bae,` class
method.`),Bae.forEach(t),Ipr=i(wl),O9=n(wl,"P",{});var NHe=s(O9);Npr=r(NHe,"This class cannot be instantiated directly using "),m5e=n(NHe,"CODE",{});var _kt=s(m5e);qpr=r(_kt,"__init__()"),_kt.forEach(t),jpr=r(NHe," (throws an error)."),NHe.forEach(t),Dpr=i(wl),At=n(wl,"DIV",{class:!0});var C7=s(At);T(V9.$$.fragment,C7),Gpr=i(C7),g5e=n(C7,"P",{});var ukt=s(g5e);Opr=r(ukt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),ukt.forEach(t),Vpr=i(C7),Vd=n(C7,"P",{});var Iae=s(Vd);Xpr=r(Iae,`Note:
Loading a model from its configuration file does `),h5e=n(Iae,"STRONG",{});var bkt=s(h5e);zpr=r(bkt,"not"),bkt.forEach(t),Wpr=r(Iae,` load the model weights. It only affects the
model\u2019s configuration. Use `),pH=n(Iae,"A",{href:!0});var vkt=s(pH);Qpr=r(vkt,"from_pretrained()"),vkt.forEach(t),Upr=r(Iae," to load the model weights."),Iae.forEach(t),Hpr=i(C7),T(AT.$$.fragment,C7),C7.forEach(t),Jpr=i(wl),go=n(wl,"DIV",{class:!0});var Aa=s(go);T(X9.$$.fragment,Aa),Ypr=i(Aa),p5e=n(Aa,"P",{});var Fkt=s(p5e);Kpr=r(Fkt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Fkt.forEach(t),Zpr=i(Aa),on=n(Aa,"P",{});var w7=s(on);e_r=r(w7,"The model class to instantiate is selected based on the "),_5e=n(w7,"CODE",{});var Tkt=s(_5e);o_r=r(Tkt,"model_type"),Tkt.forEach(t),r_r=r(w7,` property of the config object (either
passed as an argument or loaded from `),u5e=n(w7,"CODE",{});var Mkt=s(u5e);t_r=r(Mkt,"pretrained_model_name_or_path"),Mkt.forEach(t),a_r=r(w7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b5e=n(w7,"CODE",{});var Ekt=s(b5e);n_r=r(Ekt,"pretrained_model_name_or_path"),Ekt.forEach(t),s_r=r(w7,":"),w7.forEach(t),l_r=i(Aa),Pe=n(Aa,"UL",{});var We=s(Pe);LT=n(We,"LI",{});var Oje=s(LT);v5e=n(Oje,"STRONG",{});var Ckt=s(v5e);i_r=r(Ckt,"data2vec-audio"),Ckt.forEach(t),d_r=r(Oje," \u2014 "),_H=n(Oje,"A",{href:!0});var wkt=s(_H);c_r=r(wkt,"Data2VecAudioForSequenceClassification"),wkt.forEach(t),f_r=r(Oje," (Data2VecAudio model)"),Oje.forEach(t),m_r=i(We),yT=n(We,"LI",{});var Vje=s(yT);F5e=n(Vje,"STRONG",{});var Akt=s(F5e);g_r=r(Akt,"hubert"),Akt.forEach(t),h_r=r(Vje," \u2014 "),uH=n(Vje,"A",{href:!0});var Lkt=s(uH);p_r=r(Lkt,"HubertForSequenceClassification"),Lkt.forEach(t),__r=r(Vje," (Hubert model)"),Vje.forEach(t),u_r=i(We),xT=n(We,"LI",{});var Xje=s(xT);T5e=n(Xje,"STRONG",{});var ykt=s(T5e);b_r=r(ykt,"sew"),ykt.forEach(t),v_r=r(Xje," \u2014 "),bH=n(Xje,"A",{href:!0});var xkt=s(bH);F_r=r(xkt,"SEWForSequenceClassification"),xkt.forEach(t),T_r=r(Xje," (SEW model)"),Xje.forEach(t),M_r=i(We),$T=n(We,"LI",{});var zje=s($T);M5e=n(zje,"STRONG",{});var $kt=s(M5e);E_r=r($kt,"sew-d"),$kt.forEach(t),C_r=r(zje," \u2014 "),vH=n(zje,"A",{href:!0});var kkt=s(vH);w_r=r(kkt,"SEWDForSequenceClassification"),kkt.forEach(t),A_r=r(zje," (SEW-D model)"),zje.forEach(t),L_r=i(We),kT=n(We,"LI",{});var Wje=s(kT);E5e=n(Wje,"STRONG",{});var Skt=s(E5e);y_r=r(Skt,"unispeech"),Skt.forEach(t),x_r=r(Wje," \u2014 "),FH=n(Wje,"A",{href:!0});var Rkt=s(FH);$_r=r(Rkt,"UniSpeechForSequenceClassification"),Rkt.forEach(t),k_r=r(Wje," (UniSpeech model)"),Wje.forEach(t),S_r=i(We),ST=n(We,"LI",{});var Qje=s(ST);C5e=n(Qje,"STRONG",{});var Pkt=s(C5e);R_r=r(Pkt,"unispeech-sat"),Pkt.forEach(t),P_r=r(Qje," \u2014 "),TH=n(Qje,"A",{href:!0});var Bkt=s(TH);B_r=r(Bkt,"UniSpeechSatForSequenceClassification"),Bkt.forEach(t),I_r=r(Qje," (UniSpeechSat model)"),Qje.forEach(t),N_r=i(We),RT=n(We,"LI",{});var Uje=s(RT);w5e=n(Uje,"STRONG",{});var Ikt=s(w5e);q_r=r(Ikt,"wav2vec2"),Ikt.forEach(t),j_r=r(Uje," \u2014 "),MH=n(Uje,"A",{href:!0});var Nkt=s(MH);D_r=r(Nkt,"Wav2Vec2ForSequenceClassification"),Nkt.forEach(t),G_r=r(Uje," (Wav2Vec2 model)"),Uje.forEach(t),O_r=i(We),PT=n(We,"LI",{});var Hje=s(PT);A5e=n(Hje,"STRONG",{});var qkt=s(A5e);V_r=r(qkt,"wav2vec2-conformer"),qkt.forEach(t),X_r=r(Hje," \u2014 "),EH=n(Hje,"A",{href:!0});var jkt=s(EH);z_r=r(jkt,"Wav2Vec2ConformerForSequenceClassification"),jkt.forEach(t),W_r=r(Hje," (Wav2Vec2-Conformer model)"),Hje.forEach(t),Q_r=i(We),BT=n(We,"LI",{});var Jje=s(BT);L5e=n(Jje,"STRONG",{});var Dkt=s(L5e);U_r=r(Dkt,"wavlm"),Dkt.forEach(t),H_r=r(Jje," \u2014 "),CH=n(Jje,"A",{href:!0});var Gkt=s(CH);J_r=r(Gkt,"WavLMForSequenceClassification"),Gkt.forEach(t),Y_r=r(Jje," (WavLM model)"),Jje.forEach(t),We.forEach(t),K_r=i(Aa),IT=n(Aa,"P",{});var Yje=s(IT);Z_r=r(Yje,"The model is set in evaluation mode by default using "),y5e=n(Yje,"CODE",{});var Okt=s(y5e);eur=r(Okt,"model.eval()"),Okt.forEach(t),our=r(Yje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x5e=n(Yje,"CODE",{});var Vkt=s(x5e);rur=r(Vkt,"model.train()"),Vkt.forEach(t),Yje.forEach(t),tur=i(Aa),T(NT.$$.fragment,Aa),Aa.forEach(t),wl.forEach(t),$Qe=i(f),Xd=n(f,"H2",{class:!0});var qHe=s(Xd);qT=n(qHe,"A",{id:!0,class:!0,href:!0});var Xkt=s(qT);$5e=n(Xkt,"SPAN",{});var zkt=s($5e);T(z9.$$.fragment,zkt),zkt.forEach(t),Xkt.forEach(t),aur=i(qHe),k5e=n(qHe,"SPAN",{});var Wkt=s(k5e);nur=r(Wkt,"AutoModelForAudioFrameClassification"),Wkt.forEach(t),qHe.forEach(t),kQe=i(f),Ho=n(f,"DIV",{class:!0});var Al=s(Ho);T(W9.$$.fragment,Al),sur=i(Al),zd=n(Al,"P",{});var Nae=s(zd);lur=r(Nae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),wH=n(Nae,"A",{href:!0});var Qkt=s(wH);iur=r(Qkt,"from_pretrained()"),Qkt.forEach(t),dur=r(Nae," class method or the "),AH=n(Nae,"A",{href:!0});var Ukt=s(AH);cur=r(Ukt,"from_config()"),Ukt.forEach(t),fur=r(Nae,` class
method.`),Nae.forEach(t),mur=i(Al),Q9=n(Al,"P",{});var jHe=s(Q9);gur=r(jHe,"This class cannot be instantiated directly using "),S5e=n(jHe,"CODE",{});var Hkt=s(S5e);hur=r(Hkt,"__init__()"),Hkt.forEach(t),pur=r(jHe," (throws an error)."),jHe.forEach(t),_ur=i(Al),Lt=n(Al,"DIV",{class:!0});var A7=s(Lt);T(U9.$$.fragment,A7),uur=i(A7),R5e=n(A7,"P",{});var Jkt=s(R5e);bur=r(Jkt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Jkt.forEach(t),vur=i(A7),Wd=n(A7,"P",{});var qae=s(Wd);Fur=r(qae,`Note:
Loading a model from its configuration file does `),P5e=n(qae,"STRONG",{});var Ykt=s(P5e);Tur=r(Ykt,"not"),Ykt.forEach(t),Mur=r(qae,` load the model weights. It only affects the
model\u2019s configuration. Use `),LH=n(qae,"A",{href:!0});var Kkt=s(LH);Eur=r(Kkt,"from_pretrained()"),Kkt.forEach(t),Cur=r(qae," to load the model weights."),qae.forEach(t),wur=i(A7),T(jT.$$.fragment,A7),A7.forEach(t),Aur=i(Al),ho=n(Al,"DIV",{class:!0});var La=s(ho);T(H9.$$.fragment,La),Lur=i(La),B5e=n(La,"P",{});var Zkt=s(B5e);yur=r(Zkt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Zkt.forEach(t),xur=i(La),rn=n(La,"P",{});var L7=s(rn);$ur=r(L7,"The model class to instantiate is selected based on the "),I5e=n(L7,"CODE",{});var eSt=s(I5e);kur=r(eSt,"model_type"),eSt.forEach(t),Sur=r(L7,` property of the config object (either
passed as an argument or loaded from `),N5e=n(L7,"CODE",{});var oSt=s(N5e);Rur=r(oSt,"pretrained_model_name_or_path"),oSt.forEach(t),Pur=r(L7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q5e=n(L7,"CODE",{});var rSt=s(q5e);Bur=r(rSt,"pretrained_model_name_or_path"),rSt.forEach(t),Iur=r(L7,":"),L7.forEach(t),Nur=i(La),at=n(La,"UL",{});var Ll=s(at);DT=n(Ll,"LI",{});var Kje=s(DT);j5e=n(Kje,"STRONG",{});var tSt=s(j5e);qur=r(tSt,"data2vec-audio"),tSt.forEach(t),jur=r(Kje," \u2014 "),yH=n(Kje,"A",{href:!0});var aSt=s(yH);Dur=r(aSt,"Data2VecAudioForAudioFrameClassification"),aSt.forEach(t),Gur=r(Kje," (Data2VecAudio model)"),Kje.forEach(t),Our=i(Ll),GT=n(Ll,"LI",{});var Zje=s(GT);D5e=n(Zje,"STRONG",{});var nSt=s(D5e);Vur=r(nSt,"unispeech-sat"),nSt.forEach(t),Xur=r(Zje," \u2014 "),xH=n(Zje,"A",{href:!0});var sSt=s(xH);zur=r(sSt,"UniSpeechSatForAudioFrameClassification"),sSt.forEach(t),Wur=r(Zje," (UniSpeechSat model)"),Zje.forEach(t),Qur=i(Ll),OT=n(Ll,"LI",{});var eDe=s(OT);G5e=n(eDe,"STRONG",{});var lSt=s(G5e);Uur=r(lSt,"wav2vec2"),lSt.forEach(t),Hur=r(eDe," \u2014 "),$H=n(eDe,"A",{href:!0});var iSt=s($H);Jur=r(iSt,"Wav2Vec2ForAudioFrameClassification"),iSt.forEach(t),Yur=r(eDe," (Wav2Vec2 model)"),eDe.forEach(t),Kur=i(Ll),VT=n(Ll,"LI",{});var oDe=s(VT);O5e=n(oDe,"STRONG",{});var dSt=s(O5e);Zur=r(dSt,"wav2vec2-conformer"),dSt.forEach(t),e2r=r(oDe," \u2014 "),kH=n(oDe,"A",{href:!0});var cSt=s(kH);o2r=r(cSt,"Wav2Vec2ConformerForAudioFrameClassification"),cSt.forEach(t),r2r=r(oDe," (Wav2Vec2-Conformer model)"),oDe.forEach(t),t2r=i(Ll),XT=n(Ll,"LI",{});var rDe=s(XT);V5e=n(rDe,"STRONG",{});var fSt=s(V5e);a2r=r(fSt,"wavlm"),fSt.forEach(t),n2r=r(rDe," \u2014 "),SH=n(rDe,"A",{href:!0});var mSt=s(SH);s2r=r(mSt,"WavLMForAudioFrameClassification"),mSt.forEach(t),l2r=r(rDe," (WavLM model)"),rDe.forEach(t),Ll.forEach(t),i2r=i(La),zT=n(La,"P",{});var tDe=s(zT);d2r=r(tDe,"The model is set in evaluation mode by default using "),X5e=n(tDe,"CODE",{});var gSt=s(X5e);c2r=r(gSt,"model.eval()"),gSt.forEach(t),f2r=r(tDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z5e=n(tDe,"CODE",{});var hSt=s(z5e);m2r=r(hSt,"model.train()"),hSt.forEach(t),tDe.forEach(t),g2r=i(La),T(WT.$$.fragment,La),La.forEach(t),Al.forEach(t),SQe=i(f),Qd=n(f,"H2",{class:!0});var DHe=s(Qd);QT=n(DHe,"A",{id:!0,class:!0,href:!0});var pSt=s(QT);W5e=n(pSt,"SPAN",{});var _St=s(W5e);T(J9.$$.fragment,_St),_St.forEach(t),pSt.forEach(t),h2r=i(DHe),Q5e=n(DHe,"SPAN",{});var uSt=s(Q5e);p2r=r(uSt,"AutoModelForCTC"),uSt.forEach(t),DHe.forEach(t),RQe=i(f),Jo=n(f,"DIV",{class:!0});var yl=s(Jo);T(Y9.$$.fragment,yl),_2r=i(yl),Ud=n(yl,"P",{});var jae=s(Ud);u2r=r(jae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),RH=n(jae,"A",{href:!0});var bSt=s(RH);b2r=r(bSt,"from_pretrained()"),bSt.forEach(t),v2r=r(jae," class method or the "),PH=n(jae,"A",{href:!0});var vSt=s(PH);F2r=r(vSt,"from_config()"),vSt.forEach(t),T2r=r(jae,` class
method.`),jae.forEach(t),M2r=i(yl),K9=n(yl,"P",{});var GHe=s(K9);E2r=r(GHe,"This class cannot be instantiated directly using "),U5e=n(GHe,"CODE",{});var FSt=s(U5e);C2r=r(FSt,"__init__()"),FSt.forEach(t),w2r=r(GHe," (throws an error)."),GHe.forEach(t),A2r=i(yl),yt=n(yl,"DIV",{class:!0});var y7=s(yt);T(Z9.$$.fragment,y7),L2r=i(y7),H5e=n(y7,"P",{});var TSt=s(H5e);y2r=r(TSt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),TSt.forEach(t),x2r=i(y7),Hd=n(y7,"P",{});var Dae=s(Hd);$2r=r(Dae,`Note:
Loading a model from its configuration file does `),J5e=n(Dae,"STRONG",{});var MSt=s(J5e);k2r=r(MSt,"not"),MSt.forEach(t),S2r=r(Dae,` load the model weights. It only affects the
model\u2019s configuration. Use `),BH=n(Dae,"A",{href:!0});var ESt=s(BH);R2r=r(ESt,"from_pretrained()"),ESt.forEach(t),P2r=r(Dae," to load the model weights."),Dae.forEach(t),B2r=i(y7),T(UT.$$.fragment,y7),y7.forEach(t),I2r=i(yl),po=n(yl,"DIV",{class:!0});var ya=s(po);T(ex.$$.fragment,ya),N2r=i(ya),Y5e=n(ya,"P",{});var CSt=s(Y5e);q2r=r(CSt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),CSt.forEach(t),j2r=i(ya),tn=n(ya,"P",{});var x7=s(tn);D2r=r(x7,"The model class to instantiate is selected based on the "),K5e=n(x7,"CODE",{});var wSt=s(K5e);G2r=r(wSt,"model_type"),wSt.forEach(t),O2r=r(x7,` property of the config object (either
passed as an argument or loaded from `),Z5e=n(x7,"CODE",{});var ASt=s(Z5e);V2r=r(ASt,"pretrained_model_name_or_path"),ASt.forEach(t),X2r=r(x7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eFe=n(x7,"CODE",{});var LSt=s(eFe);z2r=r(LSt,"pretrained_model_name_or_path"),LSt.forEach(t),W2r=r(x7,":"),x7.forEach(t),Q2r=i(ya),Le=n(ya,"UL",{});var Be=s(Le);HT=n(Be,"LI",{});var aDe=s(HT);oFe=n(aDe,"STRONG",{});var ySt=s(oFe);U2r=r(ySt,"data2vec-audio"),ySt.forEach(t),H2r=r(aDe," \u2014 "),IH=n(aDe,"A",{href:!0});var xSt=s(IH);J2r=r(xSt,"Data2VecAudioForCTC"),xSt.forEach(t),Y2r=r(aDe," (Data2VecAudio model)"),aDe.forEach(t),K2r=i(Be),JT=n(Be,"LI",{});var nDe=s(JT);rFe=n(nDe,"STRONG",{});var $St=s(rFe);Z2r=r($St,"hubert"),$St.forEach(t),e1r=r(nDe," \u2014 "),NH=n(nDe,"A",{href:!0});var kSt=s(NH);o1r=r(kSt,"HubertForCTC"),kSt.forEach(t),r1r=r(nDe," (Hubert model)"),nDe.forEach(t),t1r=i(Be),YT=n(Be,"LI",{});var sDe=s(YT);tFe=n(sDe,"STRONG",{});var SSt=s(tFe);a1r=r(SSt,"mctct"),SSt.forEach(t),n1r=r(sDe," \u2014 "),qH=n(sDe,"A",{href:!0});var RSt=s(qH);s1r=r(RSt,"MCTCTForCTC"),RSt.forEach(t),l1r=r(sDe," (M-CTC-T model)"),sDe.forEach(t),i1r=i(Be),KT=n(Be,"LI",{});var lDe=s(KT);aFe=n(lDe,"STRONG",{});var PSt=s(aFe);d1r=r(PSt,"sew"),PSt.forEach(t),c1r=r(lDe," \u2014 "),jH=n(lDe,"A",{href:!0});var BSt=s(jH);f1r=r(BSt,"SEWForCTC"),BSt.forEach(t),m1r=r(lDe," (SEW model)"),lDe.forEach(t),g1r=i(Be),ZT=n(Be,"LI",{});var iDe=s(ZT);nFe=n(iDe,"STRONG",{});var ISt=s(nFe);h1r=r(ISt,"sew-d"),ISt.forEach(t),p1r=r(iDe," \u2014 "),DH=n(iDe,"A",{href:!0});var NSt=s(DH);_1r=r(NSt,"SEWDForCTC"),NSt.forEach(t),u1r=r(iDe," (SEW-D model)"),iDe.forEach(t),b1r=i(Be),e8=n(Be,"LI",{});var dDe=s(e8);sFe=n(dDe,"STRONG",{});var qSt=s(sFe);v1r=r(qSt,"unispeech"),qSt.forEach(t),F1r=r(dDe," \u2014 "),GH=n(dDe,"A",{href:!0});var jSt=s(GH);T1r=r(jSt,"UniSpeechForCTC"),jSt.forEach(t),M1r=r(dDe," (UniSpeech model)"),dDe.forEach(t),E1r=i(Be),o8=n(Be,"LI",{});var cDe=s(o8);lFe=n(cDe,"STRONG",{});var DSt=s(lFe);C1r=r(DSt,"unispeech-sat"),DSt.forEach(t),w1r=r(cDe," \u2014 "),OH=n(cDe,"A",{href:!0});var GSt=s(OH);A1r=r(GSt,"UniSpeechSatForCTC"),GSt.forEach(t),L1r=r(cDe," (UniSpeechSat model)"),cDe.forEach(t),y1r=i(Be),r8=n(Be,"LI",{});var fDe=s(r8);iFe=n(fDe,"STRONG",{});var OSt=s(iFe);x1r=r(OSt,"wav2vec2"),OSt.forEach(t),$1r=r(fDe," \u2014 "),VH=n(fDe,"A",{href:!0});var VSt=s(VH);k1r=r(VSt,"Wav2Vec2ForCTC"),VSt.forEach(t),S1r=r(fDe," (Wav2Vec2 model)"),fDe.forEach(t),R1r=i(Be),t8=n(Be,"LI",{});var mDe=s(t8);dFe=n(mDe,"STRONG",{});var XSt=s(dFe);P1r=r(XSt,"wav2vec2-conformer"),XSt.forEach(t),B1r=r(mDe," \u2014 "),XH=n(mDe,"A",{href:!0});var zSt=s(XH);I1r=r(zSt,"Wav2Vec2ConformerForCTC"),zSt.forEach(t),N1r=r(mDe," (Wav2Vec2-Conformer model)"),mDe.forEach(t),q1r=i(Be),a8=n(Be,"LI",{});var gDe=s(a8);cFe=n(gDe,"STRONG",{});var WSt=s(cFe);j1r=r(WSt,"wavlm"),WSt.forEach(t),D1r=r(gDe," \u2014 "),zH=n(gDe,"A",{href:!0});var QSt=s(zH);G1r=r(QSt,"WavLMForCTC"),QSt.forEach(t),O1r=r(gDe," (WavLM model)"),gDe.forEach(t),Be.forEach(t),V1r=i(ya),n8=n(ya,"P",{});var hDe=s(n8);X1r=r(hDe,"The model is set in evaluation mode by default using "),fFe=n(hDe,"CODE",{});var USt=s(fFe);z1r=r(USt,"model.eval()"),USt.forEach(t),W1r=r(hDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mFe=n(hDe,"CODE",{});var HSt=s(mFe);Q1r=r(HSt,"model.train()"),HSt.forEach(t),hDe.forEach(t),U1r=i(ya),T(s8.$$.fragment,ya),ya.forEach(t),yl.forEach(t),PQe=i(f),Jd=n(f,"H2",{class:!0});var OHe=s(Jd);l8=n(OHe,"A",{id:!0,class:!0,href:!0});var JSt=s(l8);gFe=n(JSt,"SPAN",{});var YSt=s(gFe);T(ox.$$.fragment,YSt),YSt.forEach(t),JSt.forEach(t),H1r=i(OHe),hFe=n(OHe,"SPAN",{});var KSt=s(hFe);J1r=r(KSt,"AutoModelForSpeechSeq2Seq"),KSt.forEach(t),OHe.forEach(t),BQe=i(f),Yo=n(f,"DIV",{class:!0});var xl=s(Yo);T(rx.$$.fragment,xl),Y1r=i(xl),Yd=n(xl,"P",{});var Gae=s(Yd);K1r=r(Gae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),WH=n(Gae,"A",{href:!0});var ZSt=s(WH);Z1r=r(ZSt,"from_pretrained()"),ZSt.forEach(t),e4r=r(Gae," class method or the "),QH=n(Gae,"A",{href:!0});var eRt=s(QH);o4r=r(eRt,"from_config()"),eRt.forEach(t),r4r=r(Gae,` class
method.`),Gae.forEach(t),t4r=i(xl),tx=n(xl,"P",{});var VHe=s(tx);a4r=r(VHe,"This class cannot be instantiated directly using "),pFe=n(VHe,"CODE",{});var oRt=s(pFe);n4r=r(oRt,"__init__()"),oRt.forEach(t),s4r=r(VHe," (throws an error)."),VHe.forEach(t),l4r=i(xl),xt=n(xl,"DIV",{class:!0});var $7=s(xt);T(ax.$$.fragment,$7),i4r=i($7),_Fe=n($7,"P",{});var rRt=s(_Fe);d4r=r(rRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),rRt.forEach(t),c4r=i($7),Kd=n($7,"P",{});var Oae=s(Kd);f4r=r(Oae,`Note:
Loading a model from its configuration file does `),uFe=n(Oae,"STRONG",{});var tRt=s(uFe);m4r=r(tRt,"not"),tRt.forEach(t),g4r=r(Oae,` load the model weights. It only affects the
model\u2019s configuration. Use `),UH=n(Oae,"A",{href:!0});var aRt=s(UH);h4r=r(aRt,"from_pretrained()"),aRt.forEach(t),p4r=r(Oae," to load the model weights."),Oae.forEach(t),_4r=i($7),T(i8.$$.fragment,$7),$7.forEach(t),u4r=i(xl),_o=n(xl,"DIV",{class:!0});var xa=s(_o);T(nx.$$.fragment,xa),b4r=i(xa),bFe=n(xa,"P",{});var nRt=s(bFe);v4r=r(nRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),nRt.forEach(t),F4r=i(xa),an=n(xa,"P",{});var k7=s(an);T4r=r(k7,"The model class to instantiate is selected based on the "),vFe=n(k7,"CODE",{});var sRt=s(vFe);M4r=r(sRt,"model_type"),sRt.forEach(t),E4r=r(k7,` property of the config object (either
passed as an argument or loaded from `),FFe=n(k7,"CODE",{});var lRt=s(FFe);C4r=r(lRt,"pretrained_model_name_or_path"),lRt.forEach(t),w4r=r(k7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TFe=n(k7,"CODE",{});var iRt=s(TFe);A4r=r(iRt,"pretrained_model_name_or_path"),iRt.forEach(t),L4r=r(k7,":"),k7.forEach(t),y4r=i(xa),sx=n(xa,"UL",{});var XHe=s(sx);d8=n(XHe,"LI",{});var pDe=s(d8);MFe=n(pDe,"STRONG",{});var dRt=s(MFe);x4r=r(dRt,"speech-encoder-decoder"),dRt.forEach(t),$4r=r(pDe," \u2014 "),HH=n(pDe,"A",{href:!0});var cRt=s(HH);k4r=r(cRt,"SpeechEncoderDecoderModel"),cRt.forEach(t),S4r=r(pDe," (Speech Encoder decoder model)"),pDe.forEach(t),R4r=i(XHe),c8=n(XHe,"LI",{});var _De=s(c8);EFe=n(_De,"STRONG",{});var fRt=s(EFe);P4r=r(fRt,"speech_to_text"),fRt.forEach(t),B4r=r(_De," \u2014 "),JH=n(_De,"A",{href:!0});var mRt=s(JH);I4r=r(mRt,"Speech2TextForConditionalGeneration"),mRt.forEach(t),N4r=r(_De," (Speech2Text model)"),_De.forEach(t),XHe.forEach(t),q4r=i(xa),f8=n(xa,"P",{});var uDe=s(f8);j4r=r(uDe,"The model is set in evaluation mode by default using "),CFe=n(uDe,"CODE",{});var gRt=s(CFe);D4r=r(gRt,"model.eval()"),gRt.forEach(t),G4r=r(uDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),wFe=n(uDe,"CODE",{});var hRt=s(wFe);O4r=r(hRt,"model.train()"),hRt.forEach(t),uDe.forEach(t),V4r=i(xa),T(m8.$$.fragment,xa),xa.forEach(t),xl.forEach(t),IQe=i(f),Zd=n(f,"H2",{class:!0});var zHe=s(Zd);g8=n(zHe,"A",{id:!0,class:!0,href:!0});var pRt=s(g8);AFe=n(pRt,"SPAN",{});var _Rt=s(AFe);T(lx.$$.fragment,_Rt),_Rt.forEach(t),pRt.forEach(t),X4r=i(zHe),LFe=n(zHe,"SPAN",{});var uRt=s(LFe);z4r=r(uRt,"AutoModelForAudioXVector"),uRt.forEach(t),zHe.forEach(t),NQe=i(f),Ko=n(f,"DIV",{class:!0});var $l=s(Ko);T(ix.$$.fragment,$l),W4r=i($l),ec=n($l,"P",{});var Vae=s(ec);Q4r=r(Vae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),YH=n(Vae,"A",{href:!0});var bRt=s(YH);U4r=r(bRt,"from_pretrained()"),bRt.forEach(t),H4r=r(Vae," class method or the "),KH=n(Vae,"A",{href:!0});var vRt=s(KH);J4r=r(vRt,"from_config()"),vRt.forEach(t),Y4r=r(Vae,` class
method.`),Vae.forEach(t),K4r=i($l),dx=n($l,"P",{});var WHe=s(dx);Z4r=r(WHe,"This class cannot be instantiated directly using "),yFe=n(WHe,"CODE",{});var FRt=s(yFe);ebr=r(FRt,"__init__()"),FRt.forEach(t),obr=r(WHe," (throws an error)."),WHe.forEach(t),rbr=i($l),$t=n($l,"DIV",{class:!0});var S7=s($t);T(cx.$$.fragment,S7),tbr=i(S7),xFe=n(S7,"P",{});var TRt=s(xFe);abr=r(TRt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),TRt.forEach(t),nbr=i(S7),oc=n(S7,"P",{});var Xae=s(oc);sbr=r(Xae,`Note:
Loading a model from its configuration file does `),$Fe=n(Xae,"STRONG",{});var MRt=s($Fe);lbr=r(MRt,"not"),MRt.forEach(t),ibr=r(Xae,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZH=n(Xae,"A",{href:!0});var ERt=s(ZH);dbr=r(ERt,"from_pretrained()"),ERt.forEach(t),cbr=r(Xae," to load the model weights."),Xae.forEach(t),fbr=i(S7),T(h8.$$.fragment,S7),S7.forEach(t),mbr=i($l),uo=n($l,"DIV",{class:!0});var $a=s(uo);T(fx.$$.fragment,$a),gbr=i($a),kFe=n($a,"P",{});var CRt=s(kFe);hbr=r(CRt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),CRt.forEach(t),pbr=i($a),nn=n($a,"P",{});var R7=s(nn);_br=r(R7,"The model class to instantiate is selected based on the "),SFe=n(R7,"CODE",{});var wRt=s(SFe);ubr=r(wRt,"model_type"),wRt.forEach(t),bbr=r(R7,` property of the config object (either
passed as an argument or loaded from `),RFe=n(R7,"CODE",{});var ARt=s(RFe);vbr=r(ARt,"pretrained_model_name_or_path"),ARt.forEach(t),Fbr=r(R7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PFe=n(R7,"CODE",{});var LRt=s(PFe);Tbr=r(LRt,"pretrained_model_name_or_path"),LRt.forEach(t),Mbr=r(R7,":"),R7.forEach(t),Ebr=i($a),nt=n($a,"UL",{});var kl=s(nt);p8=n(kl,"LI",{});var bDe=s(p8);BFe=n(bDe,"STRONG",{});var yRt=s(BFe);Cbr=r(yRt,"data2vec-audio"),yRt.forEach(t),wbr=r(bDe," \u2014 "),eJ=n(bDe,"A",{href:!0});var xRt=s(eJ);Abr=r(xRt,"Data2VecAudioForXVector"),xRt.forEach(t),Lbr=r(bDe," (Data2VecAudio model)"),bDe.forEach(t),ybr=i(kl),_8=n(kl,"LI",{});var vDe=s(_8);IFe=n(vDe,"STRONG",{});var $Rt=s(IFe);xbr=r($Rt,"unispeech-sat"),$Rt.forEach(t),$br=r(vDe," \u2014 "),oJ=n(vDe,"A",{href:!0});var kRt=s(oJ);kbr=r(kRt,"UniSpeechSatForXVector"),kRt.forEach(t),Sbr=r(vDe," (UniSpeechSat model)"),vDe.forEach(t),Rbr=i(kl),u8=n(kl,"LI",{});var FDe=s(u8);NFe=n(FDe,"STRONG",{});var SRt=s(NFe);Pbr=r(SRt,"wav2vec2"),SRt.forEach(t),Bbr=r(FDe," \u2014 "),rJ=n(FDe,"A",{href:!0});var RRt=s(rJ);Ibr=r(RRt,"Wav2Vec2ForXVector"),RRt.forEach(t),Nbr=r(FDe," (Wav2Vec2 model)"),FDe.forEach(t),qbr=i(kl),b8=n(kl,"LI",{});var TDe=s(b8);qFe=n(TDe,"STRONG",{});var PRt=s(qFe);jbr=r(PRt,"wav2vec2-conformer"),PRt.forEach(t),Dbr=r(TDe," \u2014 "),tJ=n(TDe,"A",{href:!0});var BRt=s(tJ);Gbr=r(BRt,"Wav2Vec2ConformerForXVector"),BRt.forEach(t),Obr=r(TDe," (Wav2Vec2-Conformer model)"),TDe.forEach(t),Vbr=i(kl),v8=n(kl,"LI",{});var MDe=s(v8);jFe=n(MDe,"STRONG",{});var IRt=s(jFe);Xbr=r(IRt,"wavlm"),IRt.forEach(t),zbr=r(MDe," \u2014 "),aJ=n(MDe,"A",{href:!0});var NRt=s(aJ);Wbr=r(NRt,"WavLMForXVector"),NRt.forEach(t),Qbr=r(MDe," (WavLM model)"),MDe.forEach(t),kl.forEach(t),Ubr=i($a),F8=n($a,"P",{});var EDe=s(F8);Hbr=r(EDe,"The model is set in evaluation mode by default using "),DFe=n(EDe,"CODE",{});var qRt=s(DFe);Jbr=r(qRt,"model.eval()"),qRt.forEach(t),Ybr=r(EDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),GFe=n(EDe,"CODE",{});var jRt=s(GFe);Kbr=r(jRt,"model.train()"),jRt.forEach(t),EDe.forEach(t),Zbr=i($a),T(T8.$$.fragment,$a),$a.forEach(t),$l.forEach(t),qQe=i(f),rc=n(f,"H2",{class:!0});var QHe=s(rc);M8=n(QHe,"A",{id:!0,class:!0,href:!0});var DRt=s(M8);OFe=n(DRt,"SPAN",{});var GRt=s(OFe);T(mx.$$.fragment,GRt),GRt.forEach(t),DRt.forEach(t),evr=i(QHe),VFe=n(QHe,"SPAN",{});var ORt=s(VFe);ovr=r(ORt,"AutoModelForMaskedImageModeling"),ORt.forEach(t),QHe.forEach(t),jQe=i(f),Zo=n(f,"DIV",{class:!0});var Sl=s(Zo);T(gx.$$.fragment,Sl),rvr=i(Sl),tc=n(Sl,"P",{});var zae=s(tc);tvr=r(zae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),nJ=n(zae,"A",{href:!0});var VRt=s(nJ);avr=r(VRt,"from_pretrained()"),VRt.forEach(t),nvr=r(zae," class method or the "),sJ=n(zae,"A",{href:!0});var XRt=s(sJ);svr=r(XRt,"from_config()"),XRt.forEach(t),lvr=r(zae,` class
method.`),zae.forEach(t),ivr=i(Sl),hx=n(Sl,"P",{});var UHe=s(hx);dvr=r(UHe,"This class cannot be instantiated directly using "),XFe=n(UHe,"CODE",{});var zRt=s(XFe);cvr=r(zRt,"__init__()"),zRt.forEach(t),fvr=r(UHe," (throws an error)."),UHe.forEach(t),mvr=i(Sl),kt=n(Sl,"DIV",{class:!0});var P7=s(kt);T(px.$$.fragment,P7),gvr=i(P7),zFe=n(P7,"P",{});var WRt=s(zFe);hvr=r(WRt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),WRt.forEach(t),pvr=i(P7),ac=n(P7,"P",{});var Wae=s(ac);_vr=r(Wae,`Note:
Loading a model from its configuration file does `),WFe=n(Wae,"STRONG",{});var QRt=s(WFe);uvr=r(QRt,"not"),QRt.forEach(t),bvr=r(Wae,` load the model weights. It only affects the
model\u2019s configuration. Use `),lJ=n(Wae,"A",{href:!0});var URt=s(lJ);vvr=r(URt,"from_pretrained()"),URt.forEach(t),Fvr=r(Wae," to load the model weights."),Wae.forEach(t),Tvr=i(P7),T(E8.$$.fragment,P7),P7.forEach(t),Mvr=i(Sl),bo=n(Sl,"DIV",{class:!0});var ka=s(bo);T(_x.$$.fragment,ka),Evr=i(ka),QFe=n(ka,"P",{});var HRt=s(QFe);Cvr=r(HRt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),HRt.forEach(t),wvr=i(ka),sn=n(ka,"P",{});var B7=s(sn);Avr=r(B7,"The model class to instantiate is selected based on the "),UFe=n(B7,"CODE",{});var JRt=s(UFe);Lvr=r(JRt,"model_type"),JRt.forEach(t),yvr=r(B7,` property of the config object (either
passed as an argument or loaded from `),HFe=n(B7,"CODE",{});var YRt=s(HFe);xvr=r(YRt,"pretrained_model_name_or_path"),YRt.forEach(t),$vr=r(B7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JFe=n(B7,"CODE",{});var KRt=s(JFe);kvr=r(KRt,"pretrained_model_name_or_path"),KRt.forEach(t),Svr=r(B7,":"),B7.forEach(t),Rvr=i(ka),ln=n(ka,"UL",{});var I7=s(ln);C8=n(I7,"LI",{});var CDe=s(C8);YFe=n(CDe,"STRONG",{});var ZRt=s(YFe);Pvr=r(ZRt,"deit"),ZRt.forEach(t),Bvr=r(CDe," \u2014 "),iJ=n(CDe,"A",{href:!0});var ePt=s(iJ);Ivr=r(ePt,"DeiTForMaskedImageModeling"),ePt.forEach(t),Nvr=r(CDe," (DeiT model)"),CDe.forEach(t),qvr=i(I7),w8=n(I7,"LI",{});var wDe=s(w8);KFe=n(wDe,"STRONG",{});var oPt=s(KFe);jvr=r(oPt,"swin"),oPt.forEach(t),Dvr=r(wDe," \u2014 "),dJ=n(wDe,"A",{href:!0});var rPt=s(dJ);Gvr=r(rPt,"SwinForMaskedImageModeling"),rPt.forEach(t),Ovr=r(wDe," (Swin Transformer model)"),wDe.forEach(t),Vvr=i(I7),A8=n(I7,"LI",{});var ADe=s(A8);ZFe=n(ADe,"STRONG",{});var tPt=s(ZFe);Xvr=r(tPt,"swinv2"),tPt.forEach(t),zvr=r(ADe," \u2014 "),cJ=n(ADe,"A",{href:!0});var aPt=s(cJ);Wvr=r(aPt,"Swinv2ForMaskedImageModeling"),aPt.forEach(t),Qvr=r(ADe," (Swin Transformer V2 model)"),ADe.forEach(t),Uvr=i(I7),L8=n(I7,"LI",{});var LDe=s(L8);eTe=n(LDe,"STRONG",{});var nPt=s(eTe);Hvr=r(nPt,"vit"),nPt.forEach(t),Jvr=r(LDe," \u2014 "),fJ=n(LDe,"A",{href:!0});var sPt=s(fJ);Yvr=r(sPt,"ViTForMaskedImageModeling"),sPt.forEach(t),Kvr=r(LDe," (ViT model)"),LDe.forEach(t),I7.forEach(t),Zvr=i(ka),y8=n(ka,"P",{});var yDe=s(y8);e5r=r(yDe,"The model is set in evaluation mode by default using "),oTe=n(yDe,"CODE",{});var lPt=s(oTe);o5r=r(lPt,"model.eval()"),lPt.forEach(t),r5r=r(yDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rTe=n(yDe,"CODE",{});var iPt=s(rTe);t5r=r(iPt,"model.train()"),iPt.forEach(t),yDe.forEach(t),a5r=i(ka),T(x8.$$.fragment,ka),ka.forEach(t),Sl.forEach(t),DQe=i(f),nc=n(f,"H2",{class:!0});var HHe=s(nc);$8=n(HHe,"A",{id:!0,class:!0,href:!0});var dPt=s($8);tTe=n(dPt,"SPAN",{});var cPt=s(tTe);T(ux.$$.fragment,cPt),cPt.forEach(t),dPt.forEach(t),n5r=i(HHe),aTe=n(HHe,"SPAN",{});var fPt=s(aTe);s5r=r(fPt,"AutoModelForObjectDetection"),fPt.forEach(t),HHe.forEach(t),GQe=i(f),er=n(f,"DIV",{class:!0});var Rl=s(er);T(bx.$$.fragment,Rl),l5r=i(Rl),sc=n(Rl,"P",{});var Qae=s(sc);i5r=r(Qae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),mJ=n(Qae,"A",{href:!0});var mPt=s(mJ);d5r=r(mPt,"from_pretrained()"),mPt.forEach(t),c5r=r(Qae," class method or the "),gJ=n(Qae,"A",{href:!0});var gPt=s(gJ);f5r=r(gPt,"from_config()"),gPt.forEach(t),m5r=r(Qae,` class
method.`),Qae.forEach(t),g5r=i(Rl),vx=n(Rl,"P",{});var JHe=s(vx);h5r=r(JHe,"This class cannot be instantiated directly using "),nTe=n(JHe,"CODE",{});var hPt=s(nTe);p5r=r(hPt,"__init__()"),hPt.forEach(t),_5r=r(JHe," (throws an error)."),JHe.forEach(t),u5r=i(Rl),St=n(Rl,"DIV",{class:!0});var N7=s(St);T(Fx.$$.fragment,N7),b5r=i(N7),sTe=n(N7,"P",{});var pPt=s(sTe);v5r=r(pPt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),pPt.forEach(t),F5r=i(N7),lc=n(N7,"P",{});var Uae=s(lc);T5r=r(Uae,`Note:
Loading a model from its configuration file does `),lTe=n(Uae,"STRONG",{});var _Pt=s(lTe);M5r=r(_Pt,"not"),_Pt.forEach(t),E5r=r(Uae,` load the model weights. It only affects the
model\u2019s configuration. Use `),hJ=n(Uae,"A",{href:!0});var uPt=s(hJ);C5r=r(uPt,"from_pretrained()"),uPt.forEach(t),w5r=r(Uae," to load the model weights."),Uae.forEach(t),A5r=i(N7),T(k8.$$.fragment,N7),N7.forEach(t),L5r=i(Rl),vo=n(Rl,"DIV",{class:!0});var Sa=s(vo);T(Tx.$$.fragment,Sa),y5r=i(Sa),iTe=n(Sa,"P",{});var bPt=s(iTe);x5r=r(bPt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),bPt.forEach(t),$5r=i(Sa),dn=n(Sa,"P",{});var q7=s(dn);k5r=r(q7,"The model class to instantiate is selected based on the "),dTe=n(q7,"CODE",{});var vPt=s(dTe);S5r=r(vPt,"model_type"),vPt.forEach(t),R5r=r(q7,` property of the config object (either
passed as an argument or loaded from `),cTe=n(q7,"CODE",{});var FPt=s(cTe);P5r=r(FPt,"pretrained_model_name_or_path"),FPt.forEach(t),B5r=r(q7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fTe=n(q7,"CODE",{});var TPt=s(fTe);I5r=r(TPt,"pretrained_model_name_or_path"),TPt.forEach(t),N5r=r(q7,":"),q7.forEach(t),q5r=i(Sa),Mx=n(Sa,"UL",{});var YHe=s(Mx);S8=n(YHe,"LI",{});var xDe=s(S8);mTe=n(xDe,"STRONG",{});var MPt=s(mTe);j5r=r(MPt,"detr"),MPt.forEach(t),D5r=r(xDe," \u2014 "),pJ=n(xDe,"A",{href:!0});var EPt=s(pJ);G5r=r(EPt,"DetrForObjectDetection"),EPt.forEach(t),O5r=r(xDe," (DETR model)"),xDe.forEach(t),V5r=i(YHe),R8=n(YHe,"LI",{});var $De=s(R8);gTe=n($De,"STRONG",{});var CPt=s(gTe);X5r=r(CPt,"yolos"),CPt.forEach(t),z5r=r($De," \u2014 "),_J=n($De,"A",{href:!0});var wPt=s(_J);W5r=r(wPt,"YolosForObjectDetection"),wPt.forEach(t),Q5r=r($De," (YOLOS model)"),$De.forEach(t),YHe.forEach(t),U5r=i(Sa),P8=n(Sa,"P",{});var kDe=s(P8);H5r=r(kDe,"The model is set in evaluation mode by default using "),hTe=n(kDe,"CODE",{});var APt=s(hTe);J5r=r(APt,"model.eval()"),APt.forEach(t),Y5r=r(kDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),pTe=n(kDe,"CODE",{});var LPt=s(pTe);K5r=r(LPt,"model.train()"),LPt.forEach(t),kDe.forEach(t),Z5r=i(Sa),T(B8.$$.fragment,Sa),Sa.forEach(t),Rl.forEach(t),OQe=i(f),ic=n(f,"H2",{class:!0});var KHe=s(ic);I8=n(KHe,"A",{id:!0,class:!0,href:!0});var yPt=s(I8);_Te=n(yPt,"SPAN",{});var xPt=s(_Te);T(Ex.$$.fragment,xPt),xPt.forEach(t),yPt.forEach(t),eFr=i(KHe),uTe=n(KHe,"SPAN",{});var $Pt=s(uTe);oFr=r($Pt,"AutoModelForImageSegmentation"),$Pt.forEach(t),KHe.forEach(t),VQe=i(f),or=n(f,"DIV",{class:!0});var Pl=s(or);T(Cx.$$.fragment,Pl),rFr=i(Pl),dc=n(Pl,"P",{});var Hae=s(dc);tFr=r(Hae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),uJ=n(Hae,"A",{href:!0});var kPt=s(uJ);aFr=r(kPt,"from_pretrained()"),kPt.forEach(t),nFr=r(Hae," class method or the "),bJ=n(Hae,"A",{href:!0});var SPt=s(bJ);sFr=r(SPt,"from_config()"),SPt.forEach(t),lFr=r(Hae,` class
method.`),Hae.forEach(t),iFr=i(Pl),wx=n(Pl,"P",{});var ZHe=s(wx);dFr=r(ZHe,"This class cannot be instantiated directly using "),bTe=n(ZHe,"CODE",{});var RPt=s(bTe);cFr=r(RPt,"__init__()"),RPt.forEach(t),fFr=r(ZHe," (throws an error)."),ZHe.forEach(t),mFr=i(Pl),Rt=n(Pl,"DIV",{class:!0});var j7=s(Rt);T(Ax.$$.fragment,j7),gFr=i(j7),vTe=n(j7,"P",{});var PPt=s(vTe);hFr=r(PPt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),PPt.forEach(t),pFr=i(j7),cc=n(j7,"P",{});var Jae=s(cc);_Fr=r(Jae,`Note:
Loading a model from its configuration file does `),FTe=n(Jae,"STRONG",{});var BPt=s(FTe);uFr=r(BPt,"not"),BPt.forEach(t),bFr=r(Jae,` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=n(Jae,"A",{href:!0});var IPt=s(vJ);vFr=r(IPt,"from_pretrained()"),IPt.forEach(t),FFr=r(Jae," to load the model weights."),Jae.forEach(t),TFr=i(j7),T(N8.$$.fragment,j7),j7.forEach(t),MFr=i(Pl),Fo=n(Pl,"DIV",{class:!0});var Ra=s(Fo);T(Lx.$$.fragment,Ra),EFr=i(Ra),TTe=n(Ra,"P",{});var NPt=s(TTe);CFr=r(NPt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),NPt.forEach(t),wFr=i(Ra),cn=n(Ra,"P",{});var D7=s(cn);AFr=r(D7,"The model class to instantiate is selected based on the "),MTe=n(D7,"CODE",{});var qPt=s(MTe);LFr=r(qPt,"model_type"),qPt.forEach(t),yFr=r(D7,` property of the config object (either
passed as an argument or loaded from `),ETe=n(D7,"CODE",{});var jPt=s(ETe);xFr=r(jPt,"pretrained_model_name_or_path"),jPt.forEach(t),$Fr=r(D7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),CTe=n(D7,"CODE",{});var DPt=s(CTe);kFr=r(DPt,"pretrained_model_name_or_path"),DPt.forEach(t),SFr=r(D7,":"),D7.forEach(t),RFr=i(Ra),wTe=n(Ra,"UL",{});var GPt=s(wTe);q8=n(GPt,"LI",{});var SDe=s(q8);ATe=n(SDe,"STRONG",{});var OPt=s(ATe);PFr=r(OPt,"detr"),OPt.forEach(t),BFr=r(SDe," \u2014 "),FJ=n(SDe,"A",{href:!0});var VPt=s(FJ);IFr=r(VPt,"DetrForSegmentation"),VPt.forEach(t),NFr=r(SDe," (DETR model)"),SDe.forEach(t),GPt.forEach(t),qFr=i(Ra),j8=n(Ra,"P",{});var RDe=s(j8);jFr=r(RDe,"The model is set in evaluation mode by default using "),LTe=n(RDe,"CODE",{});var XPt=s(LTe);DFr=r(XPt,"model.eval()"),XPt.forEach(t),GFr=r(RDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yTe=n(RDe,"CODE",{});var zPt=s(yTe);OFr=r(zPt,"model.train()"),zPt.forEach(t),RDe.forEach(t),VFr=i(Ra),T(D8.$$.fragment,Ra),Ra.forEach(t),Pl.forEach(t),XQe=i(f),fc=n(f,"H2",{class:!0});var eJe=s(fc);G8=n(eJe,"A",{id:!0,class:!0,href:!0});var WPt=s(G8);xTe=n(WPt,"SPAN",{});var QPt=s(xTe);T(yx.$$.fragment,QPt),QPt.forEach(t),WPt.forEach(t),XFr=i(eJe),$Te=n(eJe,"SPAN",{});var UPt=s($Te);zFr=r(UPt,"AutoModelForSemanticSegmentation"),UPt.forEach(t),eJe.forEach(t),zQe=i(f),rr=n(f,"DIV",{class:!0});var Bl=s(rr);T(xx.$$.fragment,Bl),WFr=i(Bl),mc=n(Bl,"P",{});var Yae=s(mc);QFr=r(Yae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),TJ=n(Yae,"A",{href:!0});var HPt=s(TJ);UFr=r(HPt,"from_pretrained()"),HPt.forEach(t),HFr=r(Yae," class method or the "),MJ=n(Yae,"A",{href:!0});var JPt=s(MJ);JFr=r(JPt,"from_config()"),JPt.forEach(t),YFr=r(Yae,` class
method.`),Yae.forEach(t),KFr=i(Bl),$x=n(Bl,"P",{});var oJe=s($x);ZFr=r(oJe,"This class cannot be instantiated directly using "),kTe=n(oJe,"CODE",{});var YPt=s(kTe);eTr=r(YPt,"__init__()"),YPt.forEach(t),oTr=r(oJe," (throws an error)."),oJe.forEach(t),rTr=i(Bl),Pt=n(Bl,"DIV",{class:!0});var G7=s(Pt);T(kx.$$.fragment,G7),tTr=i(G7),STe=n(G7,"P",{});var KPt=s(STe);aTr=r(KPt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),KPt.forEach(t),nTr=i(G7),gc=n(G7,"P",{});var Kae=s(gc);sTr=r(Kae,`Note:
Loading a model from its configuration file does `),RTe=n(Kae,"STRONG",{});var ZPt=s(RTe);lTr=r(ZPt,"not"),ZPt.forEach(t),iTr=r(Kae,` load the model weights. It only affects the
model\u2019s configuration. Use `),EJ=n(Kae,"A",{href:!0});var eBt=s(EJ);dTr=r(eBt,"from_pretrained()"),eBt.forEach(t),cTr=r(Kae," to load the model weights."),Kae.forEach(t),fTr=i(G7),T(O8.$$.fragment,G7),G7.forEach(t),mTr=i(Bl),To=n(Bl,"DIV",{class:!0});var Pa=s(To);T(Sx.$$.fragment,Pa),gTr=i(Pa),PTe=n(Pa,"P",{});var oBt=s(PTe);hTr=r(oBt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),oBt.forEach(t),pTr=i(Pa),fn=n(Pa,"P",{});var O7=s(fn);_Tr=r(O7,"The model class to instantiate is selected based on the "),BTe=n(O7,"CODE",{});var rBt=s(BTe);uTr=r(rBt,"model_type"),rBt.forEach(t),bTr=r(O7,` property of the config object (either
passed as an argument or loaded from `),ITe=n(O7,"CODE",{});var tBt=s(ITe);vTr=r(tBt,"pretrained_model_name_or_path"),tBt.forEach(t),FTr=r(O7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NTe=n(O7,"CODE",{});var aBt=s(NTe);TTr=r(aBt,"pretrained_model_name_or_path"),aBt.forEach(t),MTr=r(O7,":"),O7.forEach(t),ETr=i(Pa),st=n(Pa,"UL",{});var Il=s(st);V8=n(Il,"LI",{});var PDe=s(V8);qTe=n(PDe,"STRONG",{});var nBt=s(qTe);CTr=r(nBt,"beit"),nBt.forEach(t),wTr=r(PDe," \u2014 "),CJ=n(PDe,"A",{href:!0});var sBt=s(CJ);ATr=r(sBt,"BeitForSemanticSegmentation"),sBt.forEach(t),LTr=r(PDe," (BEiT model)"),PDe.forEach(t),yTr=i(Il),X8=n(Il,"LI",{});var BDe=s(X8);jTe=n(BDe,"STRONG",{});var lBt=s(jTe);xTr=r(lBt,"data2vec-vision"),lBt.forEach(t),$Tr=r(BDe," \u2014 "),wJ=n(BDe,"A",{href:!0});var iBt=s(wJ);kTr=r(iBt,"Data2VecVisionForSemanticSegmentation"),iBt.forEach(t),STr=r(BDe," (Data2VecVision model)"),BDe.forEach(t),RTr=i(Il),z8=n(Il,"LI",{});var IDe=s(z8);DTe=n(IDe,"STRONG",{});var dBt=s(DTe);PTr=r(dBt,"dpt"),dBt.forEach(t),BTr=r(IDe," \u2014 "),AJ=n(IDe,"A",{href:!0});var cBt=s(AJ);ITr=r(cBt,"DPTForSemanticSegmentation"),cBt.forEach(t),NTr=r(IDe," (DPT model)"),IDe.forEach(t),qTr=i(Il),W8=n(Il,"LI",{});var NDe=s(W8);GTe=n(NDe,"STRONG",{});var fBt=s(GTe);jTr=r(fBt,"mobilevit"),fBt.forEach(t),DTr=r(NDe," \u2014 "),LJ=n(NDe,"A",{href:!0});var mBt=s(LJ);GTr=r(mBt,"MobileViTForSemanticSegmentation"),mBt.forEach(t),OTr=r(NDe," (MobileViT model)"),NDe.forEach(t),VTr=i(Il),Q8=n(Il,"LI",{});var qDe=s(Q8);OTe=n(qDe,"STRONG",{});var gBt=s(OTe);XTr=r(gBt,"segformer"),gBt.forEach(t),zTr=r(qDe," \u2014 "),yJ=n(qDe,"A",{href:!0});var hBt=s(yJ);WTr=r(hBt,"SegformerForSemanticSegmentation"),hBt.forEach(t),QTr=r(qDe," (SegFormer model)"),qDe.forEach(t),Il.forEach(t),UTr=i(Pa),U8=n(Pa,"P",{});var jDe=s(U8);HTr=r(jDe,"The model is set in evaluation mode by default using "),VTe=n(jDe,"CODE",{});var pBt=s(VTe);JTr=r(pBt,"model.eval()"),pBt.forEach(t),YTr=r(jDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XTe=n(jDe,"CODE",{});var _Bt=s(XTe);KTr=r(_Bt,"model.train()"),_Bt.forEach(t),jDe.forEach(t),ZTr=i(Pa),T(H8.$$.fragment,Pa),Pa.forEach(t),Bl.forEach(t),WQe=i(f),hc=n(f,"H2",{class:!0});var rJe=s(hc);J8=n(rJe,"A",{id:!0,class:!0,href:!0});var uBt=s(J8);zTe=n(uBt,"SPAN",{});var bBt=s(zTe);T(Rx.$$.fragment,bBt),bBt.forEach(t),uBt.forEach(t),e8r=i(rJe),WTe=n(rJe,"SPAN",{});var vBt=s(WTe);o8r=r(vBt,"AutoModelForInstanceSegmentation"),vBt.forEach(t),rJe.forEach(t),QQe=i(f),tr=n(f,"DIV",{class:!0});var Nl=s(tr);T(Px.$$.fragment,Nl),r8r=i(Nl),pc=n(Nl,"P",{});var Zae=s(pc);t8r=r(Zae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),xJ=n(Zae,"A",{href:!0});var FBt=s(xJ);a8r=r(FBt,"from_pretrained()"),FBt.forEach(t),n8r=r(Zae," class method or the "),$J=n(Zae,"A",{href:!0});var TBt=s($J);s8r=r(TBt,"from_config()"),TBt.forEach(t),l8r=r(Zae,` class
method.`),Zae.forEach(t),i8r=i(Nl),Bx=n(Nl,"P",{});var tJe=s(Bx);d8r=r(tJe,"This class cannot be instantiated directly using "),QTe=n(tJe,"CODE",{});var MBt=s(QTe);c8r=r(MBt,"__init__()"),MBt.forEach(t),f8r=r(tJe," (throws an error)."),tJe.forEach(t),m8r=i(Nl),Bt=n(Nl,"DIV",{class:!0});var V7=s(Bt);T(Ix.$$.fragment,V7),g8r=i(V7),UTe=n(V7,"P",{});var EBt=s(UTe);h8r=r(EBt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),EBt.forEach(t),p8r=i(V7),_c=n(V7,"P",{});var ene=s(_c);_8r=r(ene,`Note:
Loading a model from its configuration file does `),HTe=n(ene,"STRONG",{});var CBt=s(HTe);u8r=r(CBt,"not"),CBt.forEach(t),b8r=r(ene,` load the model weights. It only affects the
model\u2019s configuration. Use `),kJ=n(ene,"A",{href:!0});var wBt=s(kJ);v8r=r(wBt,"from_pretrained()"),wBt.forEach(t),F8r=r(ene," to load the model weights."),ene.forEach(t),T8r=i(V7),T(Y8.$$.fragment,V7),V7.forEach(t),M8r=i(Nl),Mo=n(Nl,"DIV",{class:!0});var Ba=s(Mo);T(Nx.$$.fragment,Ba),E8r=i(Ba),JTe=n(Ba,"P",{});var ABt=s(JTe);C8r=r(ABt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),ABt.forEach(t),w8r=i(Ba),mn=n(Ba,"P",{});var X7=s(mn);A8r=r(X7,"The model class to instantiate is selected based on the "),YTe=n(X7,"CODE",{});var LBt=s(YTe);L8r=r(LBt,"model_type"),LBt.forEach(t),y8r=r(X7,` property of the config object (either
passed as an argument or loaded from `),KTe=n(X7,"CODE",{});var yBt=s(KTe);x8r=r(yBt,"pretrained_model_name_or_path"),yBt.forEach(t),$8r=r(X7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZTe=n(X7,"CODE",{});var xBt=s(ZTe);k8r=r(xBt,"pretrained_model_name_or_path"),xBt.forEach(t),S8r=r(X7,":"),X7.forEach(t),R8r=i(Ba),e8e=n(Ba,"UL",{});var $Bt=s(e8e);K8=n($Bt,"LI",{});var DDe=s(K8);o8e=n(DDe,"STRONG",{});var kBt=s(o8e);P8r=r(kBt,"maskformer"),kBt.forEach(t),B8r=r(DDe," \u2014 "),SJ=n(DDe,"A",{href:!0});var SBt=s(SJ);I8r=r(SBt,"MaskFormerForInstanceSegmentation"),SBt.forEach(t),N8r=r(DDe," (MaskFormer model)"),DDe.forEach(t),$Bt.forEach(t),q8r=i(Ba),Z8=n(Ba,"P",{});var GDe=s(Z8);j8r=r(GDe,"The model is set in evaluation mode by default using "),r8e=n(GDe,"CODE",{});var RBt=s(r8e);D8r=r(RBt,"model.eval()"),RBt.forEach(t),G8r=r(GDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t8e=n(GDe,"CODE",{});var PBt=s(t8e);O8r=r(PBt,"model.train()"),PBt.forEach(t),GDe.forEach(t),V8r=i(Ba),T(eM.$$.fragment,Ba),Ba.forEach(t),Nl.forEach(t),UQe=i(f),uc=n(f,"H2",{class:!0});var aJe=s(uc);oM=n(aJe,"A",{id:!0,class:!0,href:!0});var BBt=s(oM);a8e=n(BBt,"SPAN",{});var IBt=s(a8e);T(qx.$$.fragment,IBt),IBt.forEach(t),BBt.forEach(t),X8r=i(aJe),n8e=n(aJe,"SPAN",{});var NBt=s(n8e);z8r=r(NBt,"TFAutoModel"),NBt.forEach(t),aJe.forEach(t),HQe=i(f),ar=n(f,"DIV",{class:!0});var ql=s(ar);T(jx.$$.fragment,ql),W8r=i(ql),bc=n(ql,"P",{});var one=s(bc);Q8r=r(one,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),RJ=n(one,"A",{href:!0});var qBt=s(RJ);U8r=r(qBt,"from_pretrained()"),qBt.forEach(t),H8r=r(one," class method or the "),PJ=n(one,"A",{href:!0});var jBt=s(PJ);J8r=r(jBt,"from_config()"),jBt.forEach(t),Y8r=r(one,` class
method.`),one.forEach(t),K8r=i(ql),Dx=n(ql,"P",{});var nJe=s(Dx);Z8r=r(nJe,"This class cannot be instantiated directly using "),s8e=n(nJe,"CODE",{});var DBt=s(s8e);eMr=r(DBt,"__init__()"),DBt.forEach(t),oMr=r(nJe," (throws an error)."),nJe.forEach(t),rMr=i(ql),It=n(ql,"DIV",{class:!0});var z7=s(It);T(Gx.$$.fragment,z7),tMr=i(z7),l8e=n(z7,"P",{});var GBt=s(l8e);aMr=r(GBt,"Instantiates one of the base model classes of the library from a configuration."),GBt.forEach(t),nMr=i(z7),vc=n(z7,"P",{});var rne=s(vc);sMr=r(rne,`Note:
Loading a model from its configuration file does `),i8e=n(rne,"STRONG",{});var OBt=s(i8e);lMr=r(OBt,"not"),OBt.forEach(t),iMr=r(rne,` load the model weights. It only affects the
model\u2019s configuration. Use `),BJ=n(rne,"A",{href:!0});var VBt=s(BJ);dMr=r(VBt,"from_pretrained()"),VBt.forEach(t),cMr=r(rne," to load the model weights."),rne.forEach(t),fMr=i(z7),T(rM.$$.fragment,z7),z7.forEach(t),mMr=i(ql),Sr=n(ql,"DIV",{class:!0});var jl=s(Sr);T(Ox.$$.fragment,jl),gMr=i(jl),d8e=n(jl,"P",{});var XBt=s(d8e);hMr=r(XBt,"Instantiate one of the base model classes of the library from a pretrained model."),XBt.forEach(t),pMr=i(jl),gn=n(jl,"P",{});var W7=s(gn);_Mr=r(W7,"The model class to instantiate is selected based on the "),c8e=n(W7,"CODE",{});var zBt=s(c8e);uMr=r(zBt,"model_type"),zBt.forEach(t),bMr=r(W7,` property of the config object (either
passed as an argument or loaded from `),f8e=n(W7,"CODE",{});var WBt=s(f8e);vMr=r(WBt,"pretrained_model_name_or_path"),WBt.forEach(t),FMr=r(W7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m8e=n(W7,"CODE",{});var QBt=s(m8e);TMr=r(QBt,"pretrained_model_name_or_path"),QBt.forEach(t),MMr=r(W7,":"),W7.forEach(t),EMr=i(jl),q=n(jl,"UL",{});var D=s(q);tM=n(D,"LI",{});var ODe=s(tM);g8e=n(ODe,"STRONG",{});var UBt=s(g8e);CMr=r(UBt,"albert"),UBt.forEach(t),wMr=r(ODe," \u2014 "),IJ=n(ODe,"A",{href:!0});var HBt=s(IJ);AMr=r(HBt,"TFAlbertModel"),HBt.forEach(t),LMr=r(ODe," (ALBERT model)"),ODe.forEach(t),yMr=i(D),aM=n(D,"LI",{});var VDe=s(aM);h8e=n(VDe,"STRONG",{});var JBt=s(h8e);xMr=r(JBt,"bart"),JBt.forEach(t),$Mr=r(VDe," \u2014 "),NJ=n(VDe,"A",{href:!0});var YBt=s(NJ);kMr=r(YBt,"TFBartModel"),YBt.forEach(t),SMr=r(VDe," (BART model)"),VDe.forEach(t),RMr=i(D),nM=n(D,"LI",{});var XDe=s(nM);p8e=n(XDe,"STRONG",{});var KBt=s(p8e);PMr=r(KBt,"bert"),KBt.forEach(t),BMr=r(XDe," \u2014 "),qJ=n(XDe,"A",{href:!0});var ZBt=s(qJ);IMr=r(ZBt,"TFBertModel"),ZBt.forEach(t),NMr=r(XDe," (BERT model)"),XDe.forEach(t),qMr=i(D),sM=n(D,"LI",{});var zDe=s(sM);_8e=n(zDe,"STRONG",{});var eIt=s(_8e);jMr=r(eIt,"blenderbot"),eIt.forEach(t),DMr=r(zDe," \u2014 "),jJ=n(zDe,"A",{href:!0});var oIt=s(jJ);GMr=r(oIt,"TFBlenderbotModel"),oIt.forEach(t),OMr=r(zDe," (Blenderbot model)"),zDe.forEach(t),VMr=i(D),lM=n(D,"LI",{});var WDe=s(lM);u8e=n(WDe,"STRONG",{});var rIt=s(u8e);XMr=r(rIt,"blenderbot-small"),rIt.forEach(t),zMr=r(WDe," \u2014 "),DJ=n(WDe,"A",{href:!0});var tIt=s(DJ);WMr=r(tIt,"TFBlenderbotSmallModel"),tIt.forEach(t),QMr=r(WDe," (BlenderbotSmall model)"),WDe.forEach(t),UMr=i(D),iM=n(D,"LI",{});var QDe=s(iM);b8e=n(QDe,"STRONG",{});var aIt=s(b8e);HMr=r(aIt,"camembert"),aIt.forEach(t),JMr=r(QDe," \u2014 "),GJ=n(QDe,"A",{href:!0});var nIt=s(GJ);YMr=r(nIt,"TFCamembertModel"),nIt.forEach(t),KMr=r(QDe," (CamemBERT model)"),QDe.forEach(t),ZMr=i(D),dM=n(D,"LI",{});var UDe=s(dM);v8e=n(UDe,"STRONG",{});var sIt=s(v8e);eEr=r(sIt,"clip"),sIt.forEach(t),oEr=r(UDe," \u2014 "),OJ=n(UDe,"A",{href:!0});var lIt=s(OJ);rEr=r(lIt,"TFCLIPModel"),lIt.forEach(t),tEr=r(UDe," (CLIP model)"),UDe.forEach(t),aEr=i(D),cM=n(D,"LI",{});var HDe=s(cM);F8e=n(HDe,"STRONG",{});var iIt=s(F8e);nEr=r(iIt,"convbert"),iIt.forEach(t),sEr=r(HDe," \u2014 "),VJ=n(HDe,"A",{href:!0});var dIt=s(VJ);lEr=r(dIt,"TFConvBertModel"),dIt.forEach(t),iEr=r(HDe," (ConvBERT model)"),HDe.forEach(t),dEr=i(D),fM=n(D,"LI",{});var JDe=s(fM);T8e=n(JDe,"STRONG",{});var cIt=s(T8e);cEr=r(cIt,"convnext"),cIt.forEach(t),fEr=r(JDe," \u2014 "),XJ=n(JDe,"A",{href:!0});var fIt=s(XJ);mEr=r(fIt,"TFConvNextModel"),fIt.forEach(t),gEr=r(JDe," (ConvNeXT model)"),JDe.forEach(t),hEr=i(D),mM=n(D,"LI",{});var YDe=s(mM);M8e=n(YDe,"STRONG",{});var mIt=s(M8e);pEr=r(mIt,"ctrl"),mIt.forEach(t),_Er=r(YDe," \u2014 "),zJ=n(YDe,"A",{href:!0});var gIt=s(zJ);uEr=r(gIt,"TFCTRLModel"),gIt.forEach(t),bEr=r(YDe," (CTRL model)"),YDe.forEach(t),vEr=i(D),gM=n(D,"LI",{});var KDe=s(gM);E8e=n(KDe,"STRONG",{});var hIt=s(E8e);FEr=r(hIt,"data2vec-vision"),hIt.forEach(t),TEr=r(KDe," \u2014 "),WJ=n(KDe,"A",{href:!0});var pIt=s(WJ);MEr=r(pIt,"TFData2VecVisionModel"),pIt.forEach(t),EEr=r(KDe," (Data2VecVision model)"),KDe.forEach(t),CEr=i(D),hM=n(D,"LI",{});var ZDe=s(hM);C8e=n(ZDe,"STRONG",{});var _It=s(C8e);wEr=r(_It,"deberta"),_It.forEach(t),AEr=r(ZDe," \u2014 "),QJ=n(ZDe,"A",{href:!0});var uIt=s(QJ);LEr=r(uIt,"TFDebertaModel"),uIt.forEach(t),yEr=r(ZDe," (DeBERTa model)"),ZDe.forEach(t),xEr=i(D),pM=n(D,"LI",{});var eGe=s(pM);w8e=n(eGe,"STRONG",{});var bIt=s(w8e);$Er=r(bIt,"deberta-v2"),bIt.forEach(t),kEr=r(eGe," \u2014 "),UJ=n(eGe,"A",{href:!0});var vIt=s(UJ);SEr=r(vIt,"TFDebertaV2Model"),vIt.forEach(t),REr=r(eGe," (DeBERTa-v2 model)"),eGe.forEach(t),PEr=i(D),_M=n(D,"LI",{});var oGe=s(_M);A8e=n(oGe,"STRONG",{});var FIt=s(A8e);BEr=r(FIt,"deit"),FIt.forEach(t),IEr=r(oGe," \u2014 "),HJ=n(oGe,"A",{href:!0});var TIt=s(HJ);NEr=r(TIt,"TFDeiTModel"),TIt.forEach(t),qEr=r(oGe," (DeiT model)"),oGe.forEach(t),jEr=i(D),uM=n(D,"LI",{});var rGe=s(uM);L8e=n(rGe,"STRONG",{});var MIt=s(L8e);DEr=r(MIt,"distilbert"),MIt.forEach(t),GEr=r(rGe," \u2014 "),JJ=n(rGe,"A",{href:!0});var EIt=s(JJ);OEr=r(EIt,"TFDistilBertModel"),EIt.forEach(t),VEr=r(rGe," (DistilBERT model)"),rGe.forEach(t),XEr=i(D),bM=n(D,"LI",{});var tGe=s(bM);y8e=n(tGe,"STRONG",{});var CIt=s(y8e);zEr=r(CIt,"dpr"),CIt.forEach(t),WEr=r(tGe," \u2014 "),YJ=n(tGe,"A",{href:!0});var wIt=s(YJ);QEr=r(wIt,"TFDPRQuestionEncoder"),wIt.forEach(t),UEr=r(tGe," (DPR model)"),tGe.forEach(t),HEr=i(D),vM=n(D,"LI",{});var aGe=s(vM);x8e=n(aGe,"STRONG",{});var AIt=s(x8e);JEr=r(AIt,"electra"),AIt.forEach(t),YEr=r(aGe," \u2014 "),KJ=n(aGe,"A",{href:!0});var LIt=s(KJ);KEr=r(LIt,"TFElectraModel"),LIt.forEach(t),ZEr=r(aGe," (ELECTRA model)"),aGe.forEach(t),eCr=i(D),FM=n(D,"LI",{});var nGe=s(FM);$8e=n(nGe,"STRONG",{});var yIt=s($8e);oCr=r(yIt,"flaubert"),yIt.forEach(t),rCr=r(nGe," \u2014 "),ZJ=n(nGe,"A",{href:!0});var xIt=s(ZJ);tCr=r(xIt,"TFFlaubertModel"),xIt.forEach(t),aCr=r(nGe," (FlauBERT model)"),nGe.forEach(t),nCr=i(D),al=n(D,"LI",{});var xR=s(al);k8e=n(xR,"STRONG",{});var $It=s(k8e);sCr=r($It,"funnel"),$It.forEach(t),lCr=r(xR," \u2014 "),eY=n(xR,"A",{href:!0});var kIt=s(eY);iCr=r(kIt,"TFFunnelModel"),kIt.forEach(t),dCr=r(xR," or "),oY=n(xR,"A",{href:!0});var SIt=s(oY);cCr=r(SIt,"TFFunnelBaseModel"),SIt.forEach(t),fCr=r(xR," (Funnel Transformer model)"),xR.forEach(t),mCr=i(D),TM=n(D,"LI",{});var sGe=s(TM);S8e=n(sGe,"STRONG",{});var RIt=s(S8e);gCr=r(RIt,"gpt2"),RIt.forEach(t),hCr=r(sGe," \u2014 "),rY=n(sGe,"A",{href:!0});var PIt=s(rY);pCr=r(PIt,"TFGPT2Model"),PIt.forEach(t),_Cr=r(sGe," (OpenAI GPT-2 model)"),sGe.forEach(t),uCr=i(D),MM=n(D,"LI",{});var lGe=s(MM);R8e=n(lGe,"STRONG",{});var BIt=s(R8e);bCr=r(BIt,"gptj"),BIt.forEach(t),vCr=r(lGe," \u2014 "),tY=n(lGe,"A",{href:!0});var IIt=s(tY);FCr=r(IIt,"TFGPTJModel"),IIt.forEach(t),TCr=r(lGe," (GPT-J model)"),lGe.forEach(t),MCr=i(D),EM=n(D,"LI",{});var iGe=s(EM);P8e=n(iGe,"STRONG",{});var NIt=s(P8e);ECr=r(NIt,"hubert"),NIt.forEach(t),CCr=r(iGe," \u2014 "),aY=n(iGe,"A",{href:!0});var qIt=s(aY);wCr=r(qIt,"TFHubertModel"),qIt.forEach(t),ACr=r(iGe," (Hubert model)"),iGe.forEach(t),LCr=i(D),CM=n(D,"LI",{});var dGe=s(CM);B8e=n(dGe,"STRONG",{});var jIt=s(B8e);yCr=r(jIt,"layoutlm"),jIt.forEach(t),xCr=r(dGe," \u2014 "),nY=n(dGe,"A",{href:!0});var DIt=s(nY);$Cr=r(DIt,"TFLayoutLMModel"),DIt.forEach(t),kCr=r(dGe," (LayoutLM model)"),dGe.forEach(t),SCr=i(D),wM=n(D,"LI",{});var cGe=s(wM);I8e=n(cGe,"STRONG",{});var GIt=s(I8e);RCr=r(GIt,"led"),GIt.forEach(t),PCr=r(cGe," \u2014 "),sY=n(cGe,"A",{href:!0});var OIt=s(sY);BCr=r(OIt,"TFLEDModel"),OIt.forEach(t),ICr=r(cGe," (LED model)"),cGe.forEach(t),NCr=i(D),AM=n(D,"LI",{});var fGe=s(AM);N8e=n(fGe,"STRONG",{});var VIt=s(N8e);qCr=r(VIt,"longformer"),VIt.forEach(t),jCr=r(fGe," \u2014 "),lY=n(fGe,"A",{href:!0});var XIt=s(lY);DCr=r(XIt,"TFLongformerModel"),XIt.forEach(t),GCr=r(fGe," (Longformer model)"),fGe.forEach(t),OCr=i(D),LM=n(D,"LI",{});var mGe=s(LM);q8e=n(mGe,"STRONG",{});var zIt=s(q8e);VCr=r(zIt,"lxmert"),zIt.forEach(t),XCr=r(mGe," \u2014 "),iY=n(mGe,"A",{href:!0});var WIt=s(iY);zCr=r(WIt,"TFLxmertModel"),WIt.forEach(t),WCr=r(mGe," (LXMERT model)"),mGe.forEach(t),QCr=i(D),yM=n(D,"LI",{});var gGe=s(yM);j8e=n(gGe,"STRONG",{});var QIt=s(j8e);UCr=r(QIt,"marian"),QIt.forEach(t),HCr=r(gGe," \u2014 "),dY=n(gGe,"A",{href:!0});var UIt=s(dY);JCr=r(UIt,"TFMarianModel"),UIt.forEach(t),YCr=r(gGe," (Marian model)"),gGe.forEach(t),KCr=i(D),xM=n(D,"LI",{});var hGe=s(xM);D8e=n(hGe,"STRONG",{});var HIt=s(D8e);ZCr=r(HIt,"mbart"),HIt.forEach(t),e3r=r(hGe," \u2014 "),cY=n(hGe,"A",{href:!0});var JIt=s(cY);o3r=r(JIt,"TFMBartModel"),JIt.forEach(t),r3r=r(hGe," (mBART model)"),hGe.forEach(t),t3r=i(D),$M=n(D,"LI",{});var pGe=s($M);G8e=n(pGe,"STRONG",{});var YIt=s(G8e);a3r=r(YIt,"mobilebert"),YIt.forEach(t),n3r=r(pGe," \u2014 "),fY=n(pGe,"A",{href:!0});var KIt=s(fY);s3r=r(KIt,"TFMobileBertModel"),KIt.forEach(t),l3r=r(pGe," (MobileBERT model)"),pGe.forEach(t),i3r=i(D),kM=n(D,"LI",{});var _Ge=s(kM);O8e=n(_Ge,"STRONG",{});var ZIt=s(O8e);d3r=r(ZIt,"mpnet"),ZIt.forEach(t),c3r=r(_Ge," \u2014 "),mY=n(_Ge,"A",{href:!0});var eNt=s(mY);f3r=r(eNt,"TFMPNetModel"),eNt.forEach(t),m3r=r(_Ge," (MPNet model)"),_Ge.forEach(t),g3r=i(D),SM=n(D,"LI",{});var uGe=s(SM);V8e=n(uGe,"STRONG",{});var oNt=s(V8e);h3r=r(oNt,"mt5"),oNt.forEach(t),p3r=r(uGe," \u2014 "),gY=n(uGe,"A",{href:!0});var rNt=s(gY);_3r=r(rNt,"TFMT5Model"),rNt.forEach(t),u3r=r(uGe," (MT5 model)"),uGe.forEach(t),b3r=i(D),RM=n(D,"LI",{});var bGe=s(RM);X8e=n(bGe,"STRONG",{});var tNt=s(X8e);v3r=r(tNt,"openai-gpt"),tNt.forEach(t),F3r=r(bGe," \u2014 "),hY=n(bGe,"A",{href:!0});var aNt=s(hY);T3r=r(aNt,"TFOpenAIGPTModel"),aNt.forEach(t),M3r=r(bGe," (OpenAI GPT model)"),bGe.forEach(t),E3r=i(D),PM=n(D,"LI",{});var vGe=s(PM);z8e=n(vGe,"STRONG",{});var nNt=s(z8e);C3r=r(nNt,"opt"),nNt.forEach(t),w3r=r(vGe," \u2014 "),pY=n(vGe,"A",{href:!0});var sNt=s(pY);A3r=r(sNt,"TFOPTModel"),sNt.forEach(t),L3r=r(vGe," (OPT model)"),vGe.forEach(t),y3r=i(D),BM=n(D,"LI",{});var FGe=s(BM);W8e=n(FGe,"STRONG",{});var lNt=s(W8e);x3r=r(lNt,"pegasus"),lNt.forEach(t),$3r=r(FGe," \u2014 "),_Y=n(FGe,"A",{href:!0});var iNt=s(_Y);k3r=r(iNt,"TFPegasusModel"),iNt.forEach(t),S3r=r(FGe," (Pegasus model)"),FGe.forEach(t),R3r=i(D),IM=n(D,"LI",{});var TGe=s(IM);Q8e=n(TGe,"STRONG",{});var dNt=s(Q8e);P3r=r(dNt,"regnet"),dNt.forEach(t),B3r=r(TGe," \u2014 "),uY=n(TGe,"A",{href:!0});var cNt=s(uY);I3r=r(cNt,"TFRegNetModel"),cNt.forEach(t),N3r=r(TGe," (RegNet model)"),TGe.forEach(t),q3r=i(D),NM=n(D,"LI",{});var MGe=s(NM);U8e=n(MGe,"STRONG",{});var fNt=s(U8e);j3r=r(fNt,"rembert"),fNt.forEach(t),D3r=r(MGe," \u2014 "),bY=n(MGe,"A",{href:!0});var mNt=s(bY);G3r=r(mNt,"TFRemBertModel"),mNt.forEach(t),O3r=r(MGe," (RemBERT model)"),MGe.forEach(t),V3r=i(D),qM=n(D,"LI",{});var EGe=s(qM);H8e=n(EGe,"STRONG",{});var gNt=s(H8e);X3r=r(gNt,"resnet"),gNt.forEach(t),z3r=r(EGe," \u2014 "),vY=n(EGe,"A",{href:!0});var hNt=s(vY);W3r=r(hNt,"TFResNetModel"),hNt.forEach(t),Q3r=r(EGe," (ResNet model)"),EGe.forEach(t),U3r=i(D),jM=n(D,"LI",{});var CGe=s(jM);J8e=n(CGe,"STRONG",{});var pNt=s(J8e);H3r=r(pNt,"roberta"),pNt.forEach(t),J3r=r(CGe," \u2014 "),FY=n(CGe,"A",{href:!0});var _Nt=s(FY);Y3r=r(_Nt,"TFRobertaModel"),_Nt.forEach(t),K3r=r(CGe," (RoBERTa model)"),CGe.forEach(t),Z3r=i(D),DM=n(D,"LI",{});var wGe=s(DM);Y8e=n(wGe,"STRONG",{});var uNt=s(Y8e);e0r=r(uNt,"roformer"),uNt.forEach(t),o0r=r(wGe," \u2014 "),TY=n(wGe,"A",{href:!0});var bNt=s(TY);r0r=r(bNt,"TFRoFormerModel"),bNt.forEach(t),t0r=r(wGe," (RoFormer model)"),wGe.forEach(t),a0r=i(D),GM=n(D,"LI",{});var AGe=s(GM);K8e=n(AGe,"STRONG",{});var vNt=s(K8e);n0r=r(vNt,"segformer"),vNt.forEach(t),s0r=r(AGe," \u2014 "),MY=n(AGe,"A",{href:!0});var FNt=s(MY);l0r=r(FNt,"TFSegformerModel"),FNt.forEach(t),i0r=r(AGe," (SegFormer model)"),AGe.forEach(t),d0r=i(D),OM=n(D,"LI",{});var LGe=s(OM);Z8e=n(LGe,"STRONG",{});var TNt=s(Z8e);c0r=r(TNt,"speech_to_text"),TNt.forEach(t),f0r=r(LGe," \u2014 "),EY=n(LGe,"A",{href:!0});var MNt=s(EY);m0r=r(MNt,"TFSpeech2TextModel"),MNt.forEach(t),g0r=r(LGe," (Speech2Text model)"),LGe.forEach(t),h0r=i(D),VM=n(D,"LI",{});var yGe=s(VM);eMe=n(yGe,"STRONG",{});var ENt=s(eMe);p0r=r(ENt,"swin"),ENt.forEach(t),_0r=r(yGe," \u2014 "),CY=n(yGe,"A",{href:!0});var CNt=s(CY);u0r=r(CNt,"TFSwinModel"),CNt.forEach(t),b0r=r(yGe," (Swin Transformer model)"),yGe.forEach(t),v0r=i(D),XM=n(D,"LI",{});var xGe=s(XM);oMe=n(xGe,"STRONG",{});var wNt=s(oMe);F0r=r(wNt,"t5"),wNt.forEach(t),T0r=r(xGe," \u2014 "),wY=n(xGe,"A",{href:!0});var ANt=s(wY);M0r=r(ANt,"TFT5Model"),ANt.forEach(t),E0r=r(xGe," (T5 model)"),xGe.forEach(t),C0r=i(D),zM=n(D,"LI",{});var $Ge=s(zM);rMe=n($Ge,"STRONG",{});var LNt=s(rMe);w0r=r(LNt,"tapas"),LNt.forEach(t),A0r=r($Ge," \u2014 "),AY=n($Ge,"A",{href:!0});var yNt=s(AY);L0r=r(yNt,"TFTapasModel"),yNt.forEach(t),y0r=r($Ge," (TAPAS model)"),$Ge.forEach(t),x0r=i(D),WM=n(D,"LI",{});var kGe=s(WM);tMe=n(kGe,"STRONG",{});var xNt=s(tMe);$0r=r(xNt,"transfo-xl"),xNt.forEach(t),k0r=r(kGe," \u2014 "),LY=n(kGe,"A",{href:!0});var $Nt=s(LY);S0r=r($Nt,"TFTransfoXLModel"),$Nt.forEach(t),R0r=r(kGe," (Transformer-XL model)"),kGe.forEach(t),P0r=i(D),QM=n(D,"LI",{});var SGe=s(QM);aMe=n(SGe,"STRONG",{});var kNt=s(aMe);B0r=r(kNt,"vit"),kNt.forEach(t),I0r=r(SGe," \u2014 "),yY=n(SGe,"A",{href:!0});var SNt=s(yY);N0r=r(SNt,"TFViTModel"),SNt.forEach(t),q0r=r(SGe," (ViT model)"),SGe.forEach(t),j0r=i(D),UM=n(D,"LI",{});var RGe=s(UM);nMe=n(RGe,"STRONG",{});var RNt=s(nMe);D0r=r(RNt,"vit_mae"),RNt.forEach(t),G0r=r(RGe," \u2014 "),xY=n(RGe,"A",{href:!0});var PNt=s(xY);O0r=r(PNt,"TFViTMAEModel"),PNt.forEach(t),V0r=r(RGe," (ViTMAE model)"),RGe.forEach(t),X0r=i(D),HM=n(D,"LI",{});var PGe=s(HM);sMe=n(PGe,"STRONG",{});var BNt=s(sMe);z0r=r(BNt,"wav2vec2"),BNt.forEach(t),W0r=r(PGe," \u2014 "),$Y=n(PGe,"A",{href:!0});var INt=s($Y);Q0r=r(INt,"TFWav2Vec2Model"),INt.forEach(t),U0r=r(PGe," (Wav2Vec2 model)"),PGe.forEach(t),H0r=i(D),JM=n(D,"LI",{});var BGe=s(JM);lMe=n(BGe,"STRONG",{});var NNt=s(lMe);J0r=r(NNt,"xlm"),NNt.forEach(t),Y0r=r(BGe," \u2014 "),kY=n(BGe,"A",{href:!0});var qNt=s(kY);K0r=r(qNt,"TFXLMModel"),qNt.forEach(t),Z0r=r(BGe," (XLM model)"),BGe.forEach(t),ewr=i(D),YM=n(D,"LI",{});var IGe=s(YM);iMe=n(IGe,"STRONG",{});var jNt=s(iMe);owr=r(jNt,"xlm-roberta"),jNt.forEach(t),rwr=r(IGe," \u2014 "),SY=n(IGe,"A",{href:!0});var DNt=s(SY);twr=r(DNt,"TFXLMRobertaModel"),DNt.forEach(t),awr=r(IGe," (XLM-RoBERTa model)"),IGe.forEach(t),nwr=i(D),KM=n(D,"LI",{});var NGe=s(KM);dMe=n(NGe,"STRONG",{});var GNt=s(dMe);swr=r(GNt,"xlnet"),GNt.forEach(t),lwr=r(NGe," \u2014 "),RY=n(NGe,"A",{href:!0});var ONt=s(RY);iwr=r(ONt,"TFXLNetModel"),ONt.forEach(t),dwr=r(NGe," (XLNet model)"),NGe.forEach(t),D.forEach(t),cwr=i(jl),T(ZM.$$.fragment,jl),jl.forEach(t),ql.forEach(t),JQe=i(f),Fc=n(f,"H2",{class:!0});var sJe=s(Fc);eE=n(sJe,"A",{id:!0,class:!0,href:!0});var VNt=s(eE);cMe=n(VNt,"SPAN",{});var XNt=s(cMe);T(Vx.$$.fragment,XNt),XNt.forEach(t),VNt.forEach(t),fwr=i(sJe),fMe=n(sJe,"SPAN",{});var zNt=s(fMe);mwr=r(zNt,"TFAutoModelForPreTraining"),zNt.forEach(t),sJe.forEach(t),YQe=i(f),nr=n(f,"DIV",{class:!0});var Dl=s(nr);T(Xx.$$.fragment,Dl),gwr=i(Dl),Tc=n(Dl,"P",{});var tne=s(Tc);hwr=r(tne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),PY=n(tne,"A",{href:!0});var WNt=s(PY);pwr=r(WNt,"from_pretrained()"),WNt.forEach(t),_wr=r(tne," class method or the "),BY=n(tne,"A",{href:!0});var QNt=s(BY);uwr=r(QNt,"from_config()"),QNt.forEach(t),bwr=r(tne,` class
method.`),tne.forEach(t),vwr=i(Dl),zx=n(Dl,"P",{});var lJe=s(zx);Fwr=r(lJe,"This class cannot be instantiated directly using "),mMe=n(lJe,"CODE",{});var UNt=s(mMe);Twr=r(UNt,"__init__()"),UNt.forEach(t),Mwr=r(lJe," (throws an error)."),lJe.forEach(t),Ewr=i(Dl),Nt=n(Dl,"DIV",{class:!0});var Q7=s(Nt);T(Wx.$$.fragment,Q7),Cwr=i(Q7),gMe=n(Q7,"P",{});var HNt=s(gMe);wwr=r(HNt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),HNt.forEach(t),Awr=i(Q7),Mc=n(Q7,"P",{});var ane=s(Mc);Lwr=r(ane,`Note:
Loading a model from its configuration file does `),hMe=n(ane,"STRONG",{});var JNt=s(hMe);ywr=r(JNt,"not"),JNt.forEach(t),xwr=r(ane,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(ane,"A",{href:!0});var YNt=s(IY);$wr=r(YNt,"from_pretrained()"),YNt.forEach(t),kwr=r(ane," to load the model weights."),ane.forEach(t),Swr=i(Q7),T(oE.$$.fragment,Q7),Q7.forEach(t),Rwr=i(Dl),Rr=n(Dl,"DIV",{class:!0});var Gl=s(Rr);T(Qx.$$.fragment,Gl),Pwr=i(Gl),pMe=n(Gl,"P",{});var KNt=s(pMe);Bwr=r(KNt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),KNt.forEach(t),Iwr=i(Gl),hn=n(Gl,"P",{});var U7=s(hn);Nwr=r(U7,"The model class to instantiate is selected based on the "),_Me=n(U7,"CODE",{});var ZNt=s(_Me);qwr=r(ZNt,"model_type"),ZNt.forEach(t),jwr=r(U7,` property of the config object (either
passed as an argument or loaded from `),uMe=n(U7,"CODE",{});var eqt=s(uMe);Dwr=r(eqt,"pretrained_model_name_or_path"),eqt.forEach(t),Gwr=r(U7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bMe=n(U7,"CODE",{});var oqt=s(bMe);Owr=r(oqt,"pretrained_model_name_or_path"),oqt.forEach(t),Vwr=r(U7,":"),U7.forEach(t),Xwr=i(Gl),se=n(Gl,"UL",{});var le=s(se);rE=n(le,"LI",{});var qGe=s(rE);vMe=n(qGe,"STRONG",{});var rqt=s(vMe);zwr=r(rqt,"albert"),rqt.forEach(t),Wwr=r(qGe," \u2014 "),NY=n(qGe,"A",{href:!0});var tqt=s(NY);Qwr=r(tqt,"TFAlbertForPreTraining"),tqt.forEach(t),Uwr=r(qGe," (ALBERT model)"),qGe.forEach(t),Hwr=i(le),tE=n(le,"LI",{});var jGe=s(tE);FMe=n(jGe,"STRONG",{});var aqt=s(FMe);Jwr=r(aqt,"bart"),aqt.forEach(t),Ywr=r(jGe," \u2014 "),qY=n(jGe,"A",{href:!0});var nqt=s(qY);Kwr=r(nqt,"TFBartForConditionalGeneration"),nqt.forEach(t),Zwr=r(jGe," (BART model)"),jGe.forEach(t),e6r=i(le),aE=n(le,"LI",{});var DGe=s(aE);TMe=n(DGe,"STRONG",{});var sqt=s(TMe);o6r=r(sqt,"bert"),sqt.forEach(t),r6r=r(DGe," \u2014 "),jY=n(DGe,"A",{href:!0});var lqt=s(jY);t6r=r(lqt,"TFBertForPreTraining"),lqt.forEach(t),a6r=r(DGe," (BERT model)"),DGe.forEach(t),n6r=i(le),nE=n(le,"LI",{});var GGe=s(nE);MMe=n(GGe,"STRONG",{});var iqt=s(MMe);s6r=r(iqt,"camembert"),iqt.forEach(t),l6r=r(GGe," \u2014 "),DY=n(GGe,"A",{href:!0});var dqt=s(DY);i6r=r(dqt,"TFCamembertForMaskedLM"),dqt.forEach(t),d6r=r(GGe," (CamemBERT model)"),GGe.forEach(t),c6r=i(le),sE=n(le,"LI",{});var OGe=s(sE);EMe=n(OGe,"STRONG",{});var cqt=s(EMe);f6r=r(cqt,"ctrl"),cqt.forEach(t),m6r=r(OGe," \u2014 "),GY=n(OGe,"A",{href:!0});var fqt=s(GY);g6r=r(fqt,"TFCTRLLMHeadModel"),fqt.forEach(t),h6r=r(OGe," (CTRL model)"),OGe.forEach(t),p6r=i(le),lE=n(le,"LI",{});var VGe=s(lE);CMe=n(VGe,"STRONG",{});var mqt=s(CMe);_6r=r(mqt,"distilbert"),mqt.forEach(t),u6r=r(VGe," \u2014 "),OY=n(VGe,"A",{href:!0});var gqt=s(OY);b6r=r(gqt,"TFDistilBertForMaskedLM"),gqt.forEach(t),v6r=r(VGe," (DistilBERT model)"),VGe.forEach(t),F6r=i(le),iE=n(le,"LI",{});var XGe=s(iE);wMe=n(XGe,"STRONG",{});var hqt=s(wMe);T6r=r(hqt,"electra"),hqt.forEach(t),M6r=r(XGe," \u2014 "),VY=n(XGe,"A",{href:!0});var pqt=s(VY);E6r=r(pqt,"TFElectraForPreTraining"),pqt.forEach(t),C6r=r(XGe," (ELECTRA model)"),XGe.forEach(t),w6r=i(le),dE=n(le,"LI",{});var zGe=s(dE);AMe=n(zGe,"STRONG",{});var _qt=s(AMe);A6r=r(_qt,"flaubert"),_qt.forEach(t),L6r=r(zGe," \u2014 "),XY=n(zGe,"A",{href:!0});var uqt=s(XY);y6r=r(uqt,"TFFlaubertWithLMHeadModel"),uqt.forEach(t),x6r=r(zGe," (FlauBERT model)"),zGe.forEach(t),$6r=i(le),cE=n(le,"LI",{});var WGe=s(cE);LMe=n(WGe,"STRONG",{});var bqt=s(LMe);k6r=r(bqt,"funnel"),bqt.forEach(t),S6r=r(WGe," \u2014 "),zY=n(WGe,"A",{href:!0});var vqt=s(zY);R6r=r(vqt,"TFFunnelForPreTraining"),vqt.forEach(t),P6r=r(WGe," (Funnel Transformer model)"),WGe.forEach(t),B6r=i(le),fE=n(le,"LI",{});var QGe=s(fE);yMe=n(QGe,"STRONG",{});var Fqt=s(yMe);I6r=r(Fqt,"gpt2"),Fqt.forEach(t),N6r=r(QGe," \u2014 "),WY=n(QGe,"A",{href:!0});var Tqt=s(WY);q6r=r(Tqt,"TFGPT2LMHeadModel"),Tqt.forEach(t),j6r=r(QGe," (OpenAI GPT-2 model)"),QGe.forEach(t),D6r=i(le),mE=n(le,"LI",{});var UGe=s(mE);xMe=n(UGe,"STRONG",{});var Mqt=s(xMe);G6r=r(Mqt,"layoutlm"),Mqt.forEach(t),O6r=r(UGe," \u2014 "),QY=n(UGe,"A",{href:!0});var Eqt=s(QY);V6r=r(Eqt,"TFLayoutLMForMaskedLM"),Eqt.forEach(t),X6r=r(UGe," (LayoutLM model)"),UGe.forEach(t),z6r=i(le),gE=n(le,"LI",{});var HGe=s(gE);$Me=n(HGe,"STRONG",{});var Cqt=s($Me);W6r=r(Cqt,"lxmert"),Cqt.forEach(t),Q6r=r(HGe," \u2014 "),UY=n(HGe,"A",{href:!0});var wqt=s(UY);U6r=r(wqt,"TFLxmertForPreTraining"),wqt.forEach(t),H6r=r(HGe," (LXMERT model)"),HGe.forEach(t),J6r=i(le),hE=n(le,"LI",{});var JGe=s(hE);kMe=n(JGe,"STRONG",{});var Aqt=s(kMe);Y6r=r(Aqt,"mobilebert"),Aqt.forEach(t),K6r=r(JGe," \u2014 "),HY=n(JGe,"A",{href:!0});var Lqt=s(HY);Z6r=r(Lqt,"TFMobileBertForPreTraining"),Lqt.forEach(t),eAr=r(JGe," (MobileBERT model)"),JGe.forEach(t),oAr=i(le),pE=n(le,"LI",{});var YGe=s(pE);SMe=n(YGe,"STRONG",{});var yqt=s(SMe);rAr=r(yqt,"mpnet"),yqt.forEach(t),tAr=r(YGe," \u2014 "),JY=n(YGe,"A",{href:!0});var xqt=s(JY);aAr=r(xqt,"TFMPNetForMaskedLM"),xqt.forEach(t),nAr=r(YGe," (MPNet model)"),YGe.forEach(t),sAr=i(le),_E=n(le,"LI",{});var KGe=s(_E);RMe=n(KGe,"STRONG",{});var $qt=s(RMe);lAr=r($qt,"openai-gpt"),$qt.forEach(t),iAr=r(KGe," \u2014 "),YY=n(KGe,"A",{href:!0});var kqt=s(YY);dAr=r(kqt,"TFOpenAIGPTLMHeadModel"),kqt.forEach(t),cAr=r(KGe," (OpenAI GPT model)"),KGe.forEach(t),fAr=i(le),uE=n(le,"LI",{});var ZGe=s(uE);PMe=n(ZGe,"STRONG",{});var Sqt=s(PMe);mAr=r(Sqt,"roberta"),Sqt.forEach(t),gAr=r(ZGe," \u2014 "),KY=n(ZGe,"A",{href:!0});var Rqt=s(KY);hAr=r(Rqt,"TFRobertaForMaskedLM"),Rqt.forEach(t),pAr=r(ZGe," (RoBERTa model)"),ZGe.forEach(t),_Ar=i(le),bE=n(le,"LI",{});var eOe=s(bE);BMe=n(eOe,"STRONG",{});var Pqt=s(BMe);uAr=r(Pqt,"t5"),Pqt.forEach(t),bAr=r(eOe," \u2014 "),ZY=n(eOe,"A",{href:!0});var Bqt=s(ZY);vAr=r(Bqt,"TFT5ForConditionalGeneration"),Bqt.forEach(t),FAr=r(eOe," (T5 model)"),eOe.forEach(t),TAr=i(le),vE=n(le,"LI",{});var oOe=s(vE);IMe=n(oOe,"STRONG",{});var Iqt=s(IMe);MAr=r(Iqt,"tapas"),Iqt.forEach(t),EAr=r(oOe," \u2014 "),eK=n(oOe,"A",{href:!0});var Nqt=s(eK);CAr=r(Nqt,"TFTapasForMaskedLM"),Nqt.forEach(t),wAr=r(oOe," (TAPAS model)"),oOe.forEach(t),AAr=i(le),FE=n(le,"LI",{});var rOe=s(FE);NMe=n(rOe,"STRONG",{});var qqt=s(NMe);LAr=r(qqt,"transfo-xl"),qqt.forEach(t),yAr=r(rOe," \u2014 "),oK=n(rOe,"A",{href:!0});var jqt=s(oK);xAr=r(jqt,"TFTransfoXLLMHeadModel"),jqt.forEach(t),$Ar=r(rOe," (Transformer-XL model)"),rOe.forEach(t),kAr=i(le),TE=n(le,"LI",{});var tOe=s(TE);qMe=n(tOe,"STRONG",{});var Dqt=s(qMe);SAr=r(Dqt,"vit_mae"),Dqt.forEach(t),RAr=r(tOe," \u2014 "),rK=n(tOe,"A",{href:!0});var Gqt=s(rK);PAr=r(Gqt,"TFViTMAEForPreTraining"),Gqt.forEach(t),BAr=r(tOe," (ViTMAE model)"),tOe.forEach(t),IAr=i(le),ME=n(le,"LI",{});var aOe=s(ME);jMe=n(aOe,"STRONG",{});var Oqt=s(jMe);NAr=r(Oqt,"xlm"),Oqt.forEach(t),qAr=r(aOe," \u2014 "),tK=n(aOe,"A",{href:!0});var Vqt=s(tK);jAr=r(Vqt,"TFXLMWithLMHeadModel"),Vqt.forEach(t),DAr=r(aOe," (XLM model)"),aOe.forEach(t),GAr=i(le),EE=n(le,"LI",{});var nOe=s(EE);DMe=n(nOe,"STRONG",{});var Xqt=s(DMe);OAr=r(Xqt,"xlm-roberta"),Xqt.forEach(t),VAr=r(nOe," \u2014 "),aK=n(nOe,"A",{href:!0});var zqt=s(aK);XAr=r(zqt,"TFXLMRobertaForMaskedLM"),zqt.forEach(t),zAr=r(nOe," (XLM-RoBERTa model)"),nOe.forEach(t),WAr=i(le),CE=n(le,"LI",{});var sOe=s(CE);GMe=n(sOe,"STRONG",{});var Wqt=s(GMe);QAr=r(Wqt,"xlnet"),Wqt.forEach(t),UAr=r(sOe," \u2014 "),nK=n(sOe,"A",{href:!0});var Qqt=s(nK);HAr=r(Qqt,"TFXLNetLMHeadModel"),Qqt.forEach(t),JAr=r(sOe," (XLNet model)"),sOe.forEach(t),le.forEach(t),YAr=i(Gl),T(wE.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),KQe=i(f),Ec=n(f,"H2",{class:!0});var iJe=s(Ec);AE=n(iJe,"A",{id:!0,class:!0,href:!0});var Uqt=s(AE);OMe=n(Uqt,"SPAN",{});var Hqt=s(OMe);T(Ux.$$.fragment,Hqt),Hqt.forEach(t),Uqt.forEach(t),KAr=i(iJe),VMe=n(iJe,"SPAN",{});var Jqt=s(VMe);ZAr=r(Jqt,"TFAutoModelForCausalLM"),Jqt.forEach(t),iJe.forEach(t),ZQe=i(f),sr=n(f,"DIV",{class:!0});var Ol=s(sr);T(Hx.$$.fragment,Ol),e7r=i(Ol),Cc=n(Ol,"P",{});var nne=s(Cc);o7r=r(nne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),sK=n(nne,"A",{href:!0});var Yqt=s(sK);r7r=r(Yqt,"from_pretrained()"),Yqt.forEach(t),t7r=r(nne," class method or the "),lK=n(nne,"A",{href:!0});var Kqt=s(lK);a7r=r(Kqt,"from_config()"),Kqt.forEach(t),n7r=r(nne,` class
method.`),nne.forEach(t),s7r=i(Ol),Jx=n(Ol,"P",{});var dJe=s(Jx);l7r=r(dJe,"This class cannot be instantiated directly using "),XMe=n(dJe,"CODE",{});var Zqt=s(XMe);i7r=r(Zqt,"__init__()"),Zqt.forEach(t),d7r=r(dJe," (throws an error)."),dJe.forEach(t),c7r=i(Ol),qt=n(Ol,"DIV",{class:!0});var H7=s(qt);T(Yx.$$.fragment,H7),f7r=i(H7),zMe=n(H7,"P",{});var ejt=s(zMe);m7r=r(ejt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ejt.forEach(t),g7r=i(H7),wc=n(H7,"P",{});var sne=s(wc);h7r=r(sne,`Note:
Loading a model from its configuration file does `),WMe=n(sne,"STRONG",{});var ojt=s(WMe);p7r=r(ojt,"not"),ojt.forEach(t),_7r=r(sne,` load the model weights. It only affects the
model\u2019s configuration. Use `),iK=n(sne,"A",{href:!0});var rjt=s(iK);u7r=r(rjt,"from_pretrained()"),rjt.forEach(t),b7r=r(sne," to load the model weights."),sne.forEach(t),v7r=i(H7),T(LE.$$.fragment,H7),H7.forEach(t),F7r=i(Ol),Pr=n(Ol,"DIV",{class:!0});var Vl=s(Pr);T(Kx.$$.fragment,Vl),T7r=i(Vl),QMe=n(Vl,"P",{});var tjt=s(QMe);M7r=r(tjt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),tjt.forEach(t),E7r=i(Vl),pn=n(Vl,"P",{});var J7=s(pn);C7r=r(J7,"The model class to instantiate is selected based on the "),UMe=n(J7,"CODE",{});var ajt=s(UMe);w7r=r(ajt,"model_type"),ajt.forEach(t),A7r=r(J7,` property of the config object (either
passed as an argument or loaded from `),HMe=n(J7,"CODE",{});var njt=s(HMe);L7r=r(njt,"pretrained_model_name_or_path"),njt.forEach(t),y7r=r(J7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),JMe=n(J7,"CODE",{});var sjt=s(JMe);x7r=r(sjt,"pretrained_model_name_or_path"),sjt.forEach(t),$7r=r(J7,":"),J7.forEach(t),k7r=i(Vl),Me=n(Vl,"UL",{});var Ce=s(Me);yE=n(Ce,"LI",{});var lOe=s(yE);YMe=n(lOe,"STRONG",{});var ljt=s(YMe);S7r=r(ljt,"bert"),ljt.forEach(t),R7r=r(lOe," \u2014 "),dK=n(lOe,"A",{href:!0});var ijt=s(dK);P7r=r(ijt,"TFBertLMHeadModel"),ijt.forEach(t),B7r=r(lOe," (BERT model)"),lOe.forEach(t),I7r=i(Ce),xE=n(Ce,"LI",{});var iOe=s(xE);KMe=n(iOe,"STRONG",{});var djt=s(KMe);N7r=r(djt,"camembert"),djt.forEach(t),q7r=r(iOe," \u2014 "),cK=n(iOe,"A",{href:!0});var cjt=s(cK);j7r=r(cjt,"TFCamembertForCausalLM"),cjt.forEach(t),D7r=r(iOe," (CamemBERT model)"),iOe.forEach(t),G7r=i(Ce),$E=n(Ce,"LI",{});var dOe=s($E);ZMe=n(dOe,"STRONG",{});var fjt=s(ZMe);O7r=r(fjt,"ctrl"),fjt.forEach(t),V7r=r(dOe," \u2014 "),fK=n(dOe,"A",{href:!0});var mjt=s(fK);X7r=r(mjt,"TFCTRLLMHeadModel"),mjt.forEach(t),z7r=r(dOe," (CTRL model)"),dOe.forEach(t),W7r=i(Ce),kE=n(Ce,"LI",{});var cOe=s(kE);eEe=n(cOe,"STRONG",{});var gjt=s(eEe);Q7r=r(gjt,"gpt2"),gjt.forEach(t),U7r=r(cOe," \u2014 "),mK=n(cOe,"A",{href:!0});var hjt=s(mK);H7r=r(hjt,"TFGPT2LMHeadModel"),hjt.forEach(t),J7r=r(cOe," (OpenAI GPT-2 model)"),cOe.forEach(t),Y7r=i(Ce),SE=n(Ce,"LI",{});var fOe=s(SE);oEe=n(fOe,"STRONG",{});var pjt=s(oEe);K7r=r(pjt,"gptj"),pjt.forEach(t),Z7r=r(fOe," \u2014 "),gK=n(fOe,"A",{href:!0});var _jt=s(gK);eLr=r(_jt,"TFGPTJForCausalLM"),_jt.forEach(t),oLr=r(fOe," (GPT-J model)"),fOe.forEach(t),rLr=i(Ce),RE=n(Ce,"LI",{});var mOe=s(RE);rEe=n(mOe,"STRONG",{});var ujt=s(rEe);tLr=r(ujt,"openai-gpt"),ujt.forEach(t),aLr=r(mOe," \u2014 "),hK=n(mOe,"A",{href:!0});var bjt=s(hK);nLr=r(bjt,"TFOpenAIGPTLMHeadModel"),bjt.forEach(t),sLr=r(mOe," (OpenAI GPT model)"),mOe.forEach(t),lLr=i(Ce),PE=n(Ce,"LI",{});var gOe=s(PE);tEe=n(gOe,"STRONG",{});var vjt=s(tEe);iLr=r(vjt,"opt"),vjt.forEach(t),dLr=r(gOe," \u2014 "),pK=n(gOe,"A",{href:!0});var Fjt=s(pK);cLr=r(Fjt,"TFOPTForCausalLM"),Fjt.forEach(t),fLr=r(gOe," (OPT model)"),gOe.forEach(t),mLr=i(Ce),BE=n(Ce,"LI",{});var hOe=s(BE);aEe=n(hOe,"STRONG",{});var Tjt=s(aEe);gLr=r(Tjt,"rembert"),Tjt.forEach(t),hLr=r(hOe," \u2014 "),_K=n(hOe,"A",{href:!0});var Mjt=s(_K);pLr=r(Mjt,"TFRemBertForCausalLM"),Mjt.forEach(t),_Lr=r(hOe," (RemBERT model)"),hOe.forEach(t),uLr=i(Ce),IE=n(Ce,"LI",{});var pOe=s(IE);nEe=n(pOe,"STRONG",{});var Ejt=s(nEe);bLr=r(Ejt,"roberta"),Ejt.forEach(t),vLr=r(pOe," \u2014 "),uK=n(pOe,"A",{href:!0});var Cjt=s(uK);FLr=r(Cjt,"TFRobertaForCausalLM"),Cjt.forEach(t),TLr=r(pOe," (RoBERTa model)"),pOe.forEach(t),MLr=i(Ce),NE=n(Ce,"LI",{});var _Oe=s(NE);sEe=n(_Oe,"STRONG",{});var wjt=s(sEe);ELr=r(wjt,"roformer"),wjt.forEach(t),CLr=r(_Oe," \u2014 "),bK=n(_Oe,"A",{href:!0});var Ajt=s(bK);wLr=r(Ajt,"TFRoFormerForCausalLM"),Ajt.forEach(t),ALr=r(_Oe," (RoFormer model)"),_Oe.forEach(t),LLr=i(Ce),qE=n(Ce,"LI",{});var uOe=s(qE);lEe=n(uOe,"STRONG",{});var Ljt=s(lEe);yLr=r(Ljt,"transfo-xl"),Ljt.forEach(t),xLr=r(uOe," \u2014 "),vK=n(uOe,"A",{href:!0});var yjt=s(vK);$Lr=r(yjt,"TFTransfoXLLMHeadModel"),yjt.forEach(t),kLr=r(uOe," (Transformer-XL model)"),uOe.forEach(t),SLr=i(Ce),jE=n(Ce,"LI",{});var bOe=s(jE);iEe=n(bOe,"STRONG",{});var xjt=s(iEe);RLr=r(xjt,"xlm"),xjt.forEach(t),PLr=r(bOe," \u2014 "),FK=n(bOe,"A",{href:!0});var $jt=s(FK);BLr=r($jt,"TFXLMWithLMHeadModel"),$jt.forEach(t),ILr=r(bOe," (XLM model)"),bOe.forEach(t),NLr=i(Ce),DE=n(Ce,"LI",{});var vOe=s(DE);dEe=n(vOe,"STRONG",{});var kjt=s(dEe);qLr=r(kjt,"xlnet"),kjt.forEach(t),jLr=r(vOe," \u2014 "),TK=n(vOe,"A",{href:!0});var Sjt=s(TK);DLr=r(Sjt,"TFXLNetLMHeadModel"),Sjt.forEach(t),GLr=r(vOe," (XLNet model)"),vOe.forEach(t),Ce.forEach(t),OLr=i(Vl),T(GE.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),eUe=i(f),Ac=n(f,"H2",{class:!0});var cJe=s(Ac);OE=n(cJe,"A",{id:!0,class:!0,href:!0});var Rjt=s(OE);cEe=n(Rjt,"SPAN",{});var Pjt=s(cEe);T(Zx.$$.fragment,Pjt),Pjt.forEach(t),Rjt.forEach(t),VLr=i(cJe),fEe=n(cJe,"SPAN",{});var Bjt=s(fEe);XLr=r(Bjt,"TFAutoModelForImageClassification"),Bjt.forEach(t),cJe.forEach(t),oUe=i(f),lr=n(f,"DIV",{class:!0});var Xl=s(lr);T(e$.$$.fragment,Xl),zLr=i(Xl),Lc=n(Xl,"P",{});var lne=s(Lc);WLr=r(lne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),MK=n(lne,"A",{href:!0});var Ijt=s(MK);QLr=r(Ijt,"from_pretrained()"),Ijt.forEach(t),ULr=r(lne," class method or the "),EK=n(lne,"A",{href:!0});var Njt=s(EK);HLr=r(Njt,"from_config()"),Njt.forEach(t),JLr=r(lne,` class
method.`),lne.forEach(t),YLr=i(Xl),o$=n(Xl,"P",{});var fJe=s(o$);KLr=r(fJe,"This class cannot be instantiated directly using "),mEe=n(fJe,"CODE",{});var qjt=s(mEe);ZLr=r(qjt,"__init__()"),qjt.forEach(t),eyr=r(fJe," (throws an error)."),fJe.forEach(t),oyr=i(Xl),jt=n(Xl,"DIV",{class:!0});var Y7=s(jt);T(r$.$$.fragment,Y7),ryr=i(Y7),gEe=n(Y7,"P",{});var jjt=s(gEe);tyr=r(jjt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),jjt.forEach(t),ayr=i(Y7),yc=n(Y7,"P",{});var ine=s(yc);nyr=r(ine,`Note:
Loading a model from its configuration file does `),hEe=n(ine,"STRONG",{});var Djt=s(hEe);syr=r(Djt,"not"),Djt.forEach(t),lyr=r(ine,` load the model weights. It only affects the
model\u2019s configuration. Use `),CK=n(ine,"A",{href:!0});var Gjt=s(CK);iyr=r(Gjt,"from_pretrained()"),Gjt.forEach(t),dyr=r(ine," to load the model weights."),ine.forEach(t),cyr=i(Y7),T(VE.$$.fragment,Y7),Y7.forEach(t),fyr=i(Xl),Br=n(Xl,"DIV",{class:!0});var zl=s(Br);T(t$.$$.fragment,zl),myr=i(zl),pEe=n(zl,"P",{});var Ojt=s(pEe);gyr=r(Ojt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ojt.forEach(t),hyr=i(zl),_n=n(zl,"P",{});var K7=s(_n);pyr=r(K7,"The model class to instantiate is selected based on the "),_Ee=n(K7,"CODE",{});var Vjt=s(_Ee);_yr=r(Vjt,"model_type"),Vjt.forEach(t),uyr=r(K7,` property of the config object (either
passed as an argument or loaded from `),uEe=n(K7,"CODE",{});var Xjt=s(uEe);byr=r(Xjt,"pretrained_model_name_or_path"),Xjt.forEach(t),vyr=r(K7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bEe=n(K7,"CODE",{});var zjt=s(bEe);Fyr=r(zjt,"pretrained_model_name_or_path"),zjt.forEach(t),Tyr=r(K7,":"),K7.forEach(t),Myr=i(zl),Ve=n(zl,"UL",{});var Eo=s(Ve);XE=n(Eo,"LI",{});var FOe=s(XE);vEe=n(FOe,"STRONG",{});var Wjt=s(vEe);Eyr=r(Wjt,"convnext"),Wjt.forEach(t),Cyr=r(FOe," \u2014 "),wK=n(FOe,"A",{href:!0});var Qjt=s(wK);wyr=r(Qjt,"TFConvNextForImageClassification"),Qjt.forEach(t),Ayr=r(FOe," (ConvNeXT model)"),FOe.forEach(t),Lyr=i(Eo),zE=n(Eo,"LI",{});var TOe=s(zE);FEe=n(TOe,"STRONG",{});var Ujt=s(FEe);yyr=r(Ujt,"data2vec-vision"),Ujt.forEach(t),xyr=r(TOe," \u2014 "),AK=n(TOe,"A",{href:!0});var Hjt=s(AK);$yr=r(Hjt,"TFData2VecVisionForImageClassification"),Hjt.forEach(t),kyr=r(TOe," (Data2VecVision model)"),TOe.forEach(t),Syr=i(Eo),nl=n(Eo,"LI",{});var $R=s(nl);TEe=n($R,"STRONG",{});var Jjt=s(TEe);Ryr=r(Jjt,"deit"),Jjt.forEach(t),Pyr=r($R," \u2014 "),LK=n($R,"A",{href:!0});var Yjt=s(LK);Byr=r(Yjt,"TFDeiTForImageClassification"),Yjt.forEach(t),Iyr=r($R," or "),yK=n($R,"A",{href:!0});var Kjt=s(yK);Nyr=r(Kjt,"TFDeiTForImageClassificationWithTeacher"),Kjt.forEach(t),qyr=r($R," (DeiT model)"),$R.forEach(t),jyr=i(Eo),WE=n(Eo,"LI",{});var MOe=s(WE);MEe=n(MOe,"STRONG",{});var Zjt=s(MEe);Dyr=r(Zjt,"regnet"),Zjt.forEach(t),Gyr=r(MOe," \u2014 "),xK=n(MOe,"A",{href:!0});var eDt=s(xK);Oyr=r(eDt,"TFRegNetForImageClassification"),eDt.forEach(t),Vyr=r(MOe," (RegNet model)"),MOe.forEach(t),Xyr=i(Eo),QE=n(Eo,"LI",{});var EOe=s(QE);EEe=n(EOe,"STRONG",{});var oDt=s(EEe);zyr=r(oDt,"resnet"),oDt.forEach(t),Wyr=r(EOe," \u2014 "),$K=n(EOe,"A",{href:!0});var rDt=s($K);Qyr=r(rDt,"TFResNetForImageClassification"),rDt.forEach(t),Uyr=r(EOe," (ResNet model)"),EOe.forEach(t),Hyr=i(Eo),UE=n(Eo,"LI",{});var COe=s(UE);CEe=n(COe,"STRONG",{});var tDt=s(CEe);Jyr=r(tDt,"segformer"),tDt.forEach(t),Yyr=r(COe," \u2014 "),kK=n(COe,"A",{href:!0});var aDt=s(kK);Kyr=r(aDt,"TFSegformerForImageClassification"),aDt.forEach(t),Zyr=r(COe," (SegFormer model)"),COe.forEach(t),e9r=i(Eo),HE=n(Eo,"LI",{});var wOe=s(HE);wEe=n(wOe,"STRONG",{});var nDt=s(wEe);o9r=r(nDt,"swin"),nDt.forEach(t),r9r=r(wOe," \u2014 "),SK=n(wOe,"A",{href:!0});var sDt=s(SK);t9r=r(sDt,"TFSwinForImageClassification"),sDt.forEach(t),a9r=r(wOe," (Swin Transformer model)"),wOe.forEach(t),n9r=i(Eo),JE=n(Eo,"LI",{});var AOe=s(JE);AEe=n(AOe,"STRONG",{});var lDt=s(AEe);s9r=r(lDt,"vit"),lDt.forEach(t),l9r=r(AOe," \u2014 "),RK=n(AOe,"A",{href:!0});var iDt=s(RK);i9r=r(iDt,"TFViTForImageClassification"),iDt.forEach(t),d9r=r(AOe," (ViT model)"),AOe.forEach(t),Eo.forEach(t),c9r=i(zl),T(YE.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),rUe=i(f),xc=n(f,"H2",{class:!0});var mJe=s(xc);KE=n(mJe,"A",{id:!0,class:!0,href:!0});var dDt=s(KE);LEe=n(dDt,"SPAN",{});var cDt=s(LEe);T(a$.$$.fragment,cDt),cDt.forEach(t),dDt.forEach(t),f9r=i(mJe),yEe=n(mJe,"SPAN",{});var fDt=s(yEe);m9r=r(fDt,"TFAutoModelForMaskedLM"),fDt.forEach(t),mJe.forEach(t),tUe=i(f),ir=n(f,"DIV",{class:!0});var Wl=s(ir);T(n$.$$.fragment,Wl),g9r=i(Wl),$c=n(Wl,"P",{});var dne=s($c);h9r=r(dne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PK=n(dne,"A",{href:!0});var mDt=s(PK);p9r=r(mDt,"from_pretrained()"),mDt.forEach(t),_9r=r(dne," class method or the "),BK=n(dne,"A",{href:!0});var gDt=s(BK);u9r=r(gDt,"from_config()"),gDt.forEach(t),b9r=r(dne,` class
method.`),dne.forEach(t),v9r=i(Wl),s$=n(Wl,"P",{});var gJe=s(s$);F9r=r(gJe,"This class cannot be instantiated directly using "),xEe=n(gJe,"CODE",{});var hDt=s(xEe);T9r=r(hDt,"__init__()"),hDt.forEach(t),M9r=r(gJe," (throws an error)."),gJe.forEach(t),E9r=i(Wl),Dt=n(Wl,"DIV",{class:!0});var Z7=s(Dt);T(l$.$$.fragment,Z7),C9r=i(Z7),$Ee=n(Z7,"P",{});var pDt=s($Ee);w9r=r(pDt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),pDt.forEach(t),A9r=i(Z7),kc=n(Z7,"P",{});var cne=s(kc);L9r=r(cne,`Note:
Loading a model from its configuration file does `),kEe=n(cne,"STRONG",{});var _Dt=s(kEe);y9r=r(_Dt,"not"),_Dt.forEach(t),x9r=r(cne,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(cne,"A",{href:!0});var uDt=s(IK);$9r=r(uDt,"from_pretrained()"),uDt.forEach(t),k9r=r(cne," to load the model weights."),cne.forEach(t),S9r=i(Z7),T(ZE.$$.fragment,Z7),Z7.forEach(t),R9r=i(Wl),Ir=n(Wl,"DIV",{class:!0});var Ql=s(Ir);T(i$.$$.fragment,Ql),P9r=i(Ql),SEe=n(Ql,"P",{});var bDt=s(SEe);B9r=r(bDt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),bDt.forEach(t),I9r=i(Ql),un=n(Ql,"P",{});var eL=s(un);N9r=r(eL,"The model class to instantiate is selected based on the "),REe=n(eL,"CODE",{});var vDt=s(REe);q9r=r(vDt,"model_type"),vDt.forEach(t),j9r=r(eL,` property of the config object (either
passed as an argument or loaded from `),PEe=n(eL,"CODE",{});var FDt=s(PEe);D9r=r(FDt,"pretrained_model_name_or_path"),FDt.forEach(t),G9r=r(eL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BEe=n(eL,"CODE",{});var TDt=s(BEe);O9r=r(TDt,"pretrained_model_name_or_path"),TDt.forEach(t),V9r=r(eL,":"),eL.forEach(t),X9r=i(Ql),ie=n(Ql,"UL",{});var ge=s(ie);eC=n(ge,"LI",{});var LOe=s(eC);IEe=n(LOe,"STRONG",{});var MDt=s(IEe);z9r=r(MDt,"albert"),MDt.forEach(t),W9r=r(LOe," \u2014 "),NK=n(LOe,"A",{href:!0});var EDt=s(NK);Q9r=r(EDt,"TFAlbertForMaskedLM"),EDt.forEach(t),U9r=r(LOe," (ALBERT model)"),LOe.forEach(t),H9r=i(ge),oC=n(ge,"LI",{});var yOe=s(oC);NEe=n(yOe,"STRONG",{});var CDt=s(NEe);J9r=r(CDt,"bert"),CDt.forEach(t),Y9r=r(yOe," \u2014 "),qK=n(yOe,"A",{href:!0});var wDt=s(qK);K9r=r(wDt,"TFBertForMaskedLM"),wDt.forEach(t),Z9r=r(yOe," (BERT model)"),yOe.forEach(t),exr=i(ge),rC=n(ge,"LI",{});var xOe=s(rC);qEe=n(xOe,"STRONG",{});var ADt=s(qEe);oxr=r(ADt,"camembert"),ADt.forEach(t),rxr=r(xOe," \u2014 "),jK=n(xOe,"A",{href:!0});var LDt=s(jK);txr=r(LDt,"TFCamembertForMaskedLM"),LDt.forEach(t),axr=r(xOe," (CamemBERT model)"),xOe.forEach(t),nxr=i(ge),tC=n(ge,"LI",{});var $Oe=s(tC);jEe=n($Oe,"STRONG",{});var yDt=s(jEe);sxr=r(yDt,"convbert"),yDt.forEach(t),lxr=r($Oe," \u2014 "),DK=n($Oe,"A",{href:!0});var xDt=s(DK);ixr=r(xDt,"TFConvBertForMaskedLM"),xDt.forEach(t),dxr=r($Oe," (ConvBERT model)"),$Oe.forEach(t),cxr=i(ge),aC=n(ge,"LI",{});var kOe=s(aC);DEe=n(kOe,"STRONG",{});var $Dt=s(DEe);fxr=r($Dt,"deberta"),$Dt.forEach(t),mxr=r(kOe," \u2014 "),GK=n(kOe,"A",{href:!0});var kDt=s(GK);gxr=r(kDt,"TFDebertaForMaskedLM"),kDt.forEach(t),hxr=r(kOe," (DeBERTa model)"),kOe.forEach(t),pxr=i(ge),nC=n(ge,"LI",{});var SOe=s(nC);GEe=n(SOe,"STRONG",{});var SDt=s(GEe);_xr=r(SDt,"deberta-v2"),SDt.forEach(t),uxr=r(SOe," \u2014 "),OK=n(SOe,"A",{href:!0});var RDt=s(OK);bxr=r(RDt,"TFDebertaV2ForMaskedLM"),RDt.forEach(t),vxr=r(SOe," (DeBERTa-v2 model)"),SOe.forEach(t),Fxr=i(ge),sC=n(ge,"LI",{});var ROe=s(sC);OEe=n(ROe,"STRONG",{});var PDt=s(OEe);Txr=r(PDt,"distilbert"),PDt.forEach(t),Mxr=r(ROe," \u2014 "),VK=n(ROe,"A",{href:!0});var BDt=s(VK);Exr=r(BDt,"TFDistilBertForMaskedLM"),BDt.forEach(t),Cxr=r(ROe," (DistilBERT model)"),ROe.forEach(t),wxr=i(ge),lC=n(ge,"LI",{});var POe=s(lC);VEe=n(POe,"STRONG",{});var IDt=s(VEe);Axr=r(IDt,"electra"),IDt.forEach(t),Lxr=r(POe," \u2014 "),XK=n(POe,"A",{href:!0});var NDt=s(XK);yxr=r(NDt,"TFElectraForMaskedLM"),NDt.forEach(t),xxr=r(POe," (ELECTRA model)"),POe.forEach(t),$xr=i(ge),iC=n(ge,"LI",{});var BOe=s(iC);XEe=n(BOe,"STRONG",{});var qDt=s(XEe);kxr=r(qDt,"flaubert"),qDt.forEach(t),Sxr=r(BOe," \u2014 "),zK=n(BOe,"A",{href:!0});var jDt=s(zK);Rxr=r(jDt,"TFFlaubertWithLMHeadModel"),jDt.forEach(t),Pxr=r(BOe," (FlauBERT model)"),BOe.forEach(t),Bxr=i(ge),dC=n(ge,"LI",{});var IOe=s(dC);zEe=n(IOe,"STRONG",{});var DDt=s(zEe);Ixr=r(DDt,"funnel"),DDt.forEach(t),Nxr=r(IOe," \u2014 "),WK=n(IOe,"A",{href:!0});var GDt=s(WK);qxr=r(GDt,"TFFunnelForMaskedLM"),GDt.forEach(t),jxr=r(IOe," (Funnel Transformer model)"),IOe.forEach(t),Dxr=i(ge),cC=n(ge,"LI",{});var NOe=s(cC);WEe=n(NOe,"STRONG",{});var ODt=s(WEe);Gxr=r(ODt,"layoutlm"),ODt.forEach(t),Oxr=r(NOe," \u2014 "),QK=n(NOe,"A",{href:!0});var VDt=s(QK);Vxr=r(VDt,"TFLayoutLMForMaskedLM"),VDt.forEach(t),Xxr=r(NOe," (LayoutLM model)"),NOe.forEach(t),zxr=i(ge),fC=n(ge,"LI",{});var qOe=s(fC);QEe=n(qOe,"STRONG",{});var XDt=s(QEe);Wxr=r(XDt,"longformer"),XDt.forEach(t),Qxr=r(qOe," \u2014 "),UK=n(qOe,"A",{href:!0});var zDt=s(UK);Uxr=r(zDt,"TFLongformerForMaskedLM"),zDt.forEach(t),Hxr=r(qOe," (Longformer model)"),qOe.forEach(t),Jxr=i(ge),mC=n(ge,"LI",{});var jOe=s(mC);UEe=n(jOe,"STRONG",{});var WDt=s(UEe);Yxr=r(WDt,"mobilebert"),WDt.forEach(t),Kxr=r(jOe," \u2014 "),HK=n(jOe,"A",{href:!0});var QDt=s(HK);Zxr=r(QDt,"TFMobileBertForMaskedLM"),QDt.forEach(t),e$r=r(jOe," (MobileBERT model)"),jOe.forEach(t),o$r=i(ge),gC=n(ge,"LI",{});var DOe=s(gC);HEe=n(DOe,"STRONG",{});var UDt=s(HEe);r$r=r(UDt,"mpnet"),UDt.forEach(t),t$r=r(DOe," \u2014 "),JK=n(DOe,"A",{href:!0});var HDt=s(JK);a$r=r(HDt,"TFMPNetForMaskedLM"),HDt.forEach(t),n$r=r(DOe," (MPNet model)"),DOe.forEach(t),s$r=i(ge),hC=n(ge,"LI",{});var GOe=s(hC);JEe=n(GOe,"STRONG",{});var JDt=s(JEe);l$r=r(JDt,"rembert"),JDt.forEach(t),i$r=r(GOe," \u2014 "),YK=n(GOe,"A",{href:!0});var YDt=s(YK);d$r=r(YDt,"TFRemBertForMaskedLM"),YDt.forEach(t),c$r=r(GOe," (RemBERT model)"),GOe.forEach(t),f$r=i(ge),pC=n(ge,"LI",{});var OOe=s(pC);YEe=n(OOe,"STRONG",{});var KDt=s(YEe);m$r=r(KDt,"roberta"),KDt.forEach(t),g$r=r(OOe," \u2014 "),KK=n(OOe,"A",{href:!0});var ZDt=s(KK);h$r=r(ZDt,"TFRobertaForMaskedLM"),ZDt.forEach(t),p$r=r(OOe," (RoBERTa model)"),OOe.forEach(t),_$r=i(ge),_C=n(ge,"LI",{});var VOe=s(_C);KEe=n(VOe,"STRONG",{});var eGt=s(KEe);u$r=r(eGt,"roformer"),eGt.forEach(t),b$r=r(VOe," \u2014 "),ZK=n(VOe,"A",{href:!0});var oGt=s(ZK);v$r=r(oGt,"TFRoFormerForMaskedLM"),oGt.forEach(t),F$r=r(VOe," (RoFormer model)"),VOe.forEach(t),T$r=i(ge),uC=n(ge,"LI",{});var XOe=s(uC);ZEe=n(XOe,"STRONG",{});var rGt=s(ZEe);M$r=r(rGt,"tapas"),rGt.forEach(t),E$r=r(XOe," \u2014 "),eZ=n(XOe,"A",{href:!0});var tGt=s(eZ);C$r=r(tGt,"TFTapasForMaskedLM"),tGt.forEach(t),w$r=r(XOe," (TAPAS model)"),XOe.forEach(t),A$r=i(ge),bC=n(ge,"LI",{});var zOe=s(bC);eCe=n(zOe,"STRONG",{});var aGt=s(eCe);L$r=r(aGt,"xlm"),aGt.forEach(t),y$r=r(zOe," \u2014 "),oZ=n(zOe,"A",{href:!0});var nGt=s(oZ);x$r=r(nGt,"TFXLMWithLMHeadModel"),nGt.forEach(t),$$r=r(zOe," (XLM model)"),zOe.forEach(t),k$r=i(ge),vC=n(ge,"LI",{});var WOe=s(vC);oCe=n(WOe,"STRONG",{});var sGt=s(oCe);S$r=r(sGt,"xlm-roberta"),sGt.forEach(t),R$r=r(WOe," \u2014 "),rZ=n(WOe,"A",{href:!0});var lGt=s(rZ);P$r=r(lGt,"TFXLMRobertaForMaskedLM"),lGt.forEach(t),B$r=r(WOe," (XLM-RoBERTa model)"),WOe.forEach(t),ge.forEach(t),I$r=i(Ql),T(FC.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),aUe=i(f),Sc=n(f,"H2",{class:!0});var hJe=s(Sc);TC=n(hJe,"A",{id:!0,class:!0,href:!0});var iGt=s(TC);rCe=n(iGt,"SPAN",{});var dGt=s(rCe);T(d$.$$.fragment,dGt),dGt.forEach(t),iGt.forEach(t),N$r=i(hJe),tCe=n(hJe,"SPAN",{});var cGt=s(tCe);q$r=r(cGt,"TFAutoModelForSeq2SeqLM"),cGt.forEach(t),hJe.forEach(t),nUe=i(f),dr=n(f,"DIV",{class:!0});var Ul=s(dr);T(c$.$$.fragment,Ul),j$r=i(Ul),Rc=n(Ul,"P",{});var fne=s(Rc);D$r=r(fne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tZ=n(fne,"A",{href:!0});var fGt=s(tZ);G$r=r(fGt,"from_pretrained()"),fGt.forEach(t),O$r=r(fne," class method or the "),aZ=n(fne,"A",{href:!0});var mGt=s(aZ);V$r=r(mGt,"from_config()"),mGt.forEach(t),X$r=r(fne,` class
method.`),fne.forEach(t),z$r=i(Ul),f$=n(Ul,"P",{});var pJe=s(f$);W$r=r(pJe,"This class cannot be instantiated directly using "),aCe=n(pJe,"CODE",{});var gGt=s(aCe);Q$r=r(gGt,"__init__()"),gGt.forEach(t),U$r=r(pJe," (throws an error)."),pJe.forEach(t),H$r=i(Ul),Gt=n(Ul,"DIV",{class:!0});var oL=s(Gt);T(m$.$$.fragment,oL),J$r=i(oL),nCe=n(oL,"P",{});var hGt=s(nCe);Y$r=r(hGt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),hGt.forEach(t),K$r=i(oL),Pc=n(oL,"P",{});var mne=s(Pc);Z$r=r(mne,`Note:
Loading a model from its configuration file does `),sCe=n(mne,"STRONG",{});var pGt=s(sCe);ekr=r(pGt,"not"),pGt.forEach(t),okr=r(mne,` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=n(mne,"A",{href:!0});var _Gt=s(nZ);rkr=r(_Gt,"from_pretrained()"),_Gt.forEach(t),tkr=r(mne," to load the model weights."),mne.forEach(t),akr=i(oL),T(MC.$$.fragment,oL),oL.forEach(t),nkr=i(Ul),Nr=n(Ul,"DIV",{class:!0});var Hl=s(Nr);T(g$.$$.fragment,Hl),skr=i(Hl),lCe=n(Hl,"P",{});var uGt=s(lCe);lkr=r(uGt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),uGt.forEach(t),ikr=i(Hl),bn=n(Hl,"P",{});var rL=s(bn);dkr=r(rL,"The model class to instantiate is selected based on the "),iCe=n(rL,"CODE",{});var bGt=s(iCe);ckr=r(bGt,"model_type"),bGt.forEach(t),fkr=r(rL,` property of the config object (either
passed as an argument or loaded from `),dCe=n(rL,"CODE",{});var vGt=s(dCe);mkr=r(vGt,"pretrained_model_name_or_path"),vGt.forEach(t),gkr=r(rL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),cCe=n(rL,"CODE",{});var FGt=s(cCe);hkr=r(FGt,"pretrained_model_name_or_path"),FGt.forEach(t),pkr=r(rL,":"),rL.forEach(t),_kr=i(Hl),ye=n(Hl,"UL",{});var Ie=s(ye);EC=n(Ie,"LI",{});var QOe=s(EC);fCe=n(QOe,"STRONG",{});var TGt=s(fCe);ukr=r(TGt,"bart"),TGt.forEach(t),bkr=r(QOe," \u2014 "),sZ=n(QOe,"A",{href:!0});var MGt=s(sZ);vkr=r(MGt,"TFBartForConditionalGeneration"),MGt.forEach(t),Fkr=r(QOe," (BART model)"),QOe.forEach(t),Tkr=i(Ie),CC=n(Ie,"LI",{});var UOe=s(CC);mCe=n(UOe,"STRONG",{});var EGt=s(mCe);Mkr=r(EGt,"blenderbot"),EGt.forEach(t),Ekr=r(UOe," \u2014 "),lZ=n(UOe,"A",{href:!0});var CGt=s(lZ);Ckr=r(CGt,"TFBlenderbotForConditionalGeneration"),CGt.forEach(t),wkr=r(UOe," (Blenderbot model)"),UOe.forEach(t),Akr=i(Ie),wC=n(Ie,"LI",{});var HOe=s(wC);gCe=n(HOe,"STRONG",{});var wGt=s(gCe);Lkr=r(wGt,"blenderbot-small"),wGt.forEach(t),ykr=r(HOe," \u2014 "),iZ=n(HOe,"A",{href:!0});var AGt=s(iZ);xkr=r(AGt,"TFBlenderbotSmallForConditionalGeneration"),AGt.forEach(t),$kr=r(HOe," (BlenderbotSmall model)"),HOe.forEach(t),kkr=i(Ie),AC=n(Ie,"LI",{});var JOe=s(AC);hCe=n(JOe,"STRONG",{});var LGt=s(hCe);Skr=r(LGt,"encoder-decoder"),LGt.forEach(t),Rkr=r(JOe," \u2014 "),dZ=n(JOe,"A",{href:!0});var yGt=s(dZ);Pkr=r(yGt,"TFEncoderDecoderModel"),yGt.forEach(t),Bkr=r(JOe," (Encoder decoder model)"),JOe.forEach(t),Ikr=i(Ie),LC=n(Ie,"LI",{});var YOe=s(LC);pCe=n(YOe,"STRONG",{});var xGt=s(pCe);Nkr=r(xGt,"led"),xGt.forEach(t),qkr=r(YOe," \u2014 "),cZ=n(YOe,"A",{href:!0});var $Gt=s(cZ);jkr=r($Gt,"TFLEDForConditionalGeneration"),$Gt.forEach(t),Dkr=r(YOe," (LED model)"),YOe.forEach(t),Gkr=i(Ie),yC=n(Ie,"LI",{});var KOe=s(yC);_Ce=n(KOe,"STRONG",{});var kGt=s(_Ce);Okr=r(kGt,"marian"),kGt.forEach(t),Vkr=r(KOe," \u2014 "),fZ=n(KOe,"A",{href:!0});var SGt=s(fZ);Xkr=r(SGt,"TFMarianMTModel"),SGt.forEach(t),zkr=r(KOe," (Marian model)"),KOe.forEach(t),Wkr=i(Ie),xC=n(Ie,"LI",{});var ZOe=s(xC);uCe=n(ZOe,"STRONG",{});var RGt=s(uCe);Qkr=r(RGt,"mbart"),RGt.forEach(t),Ukr=r(ZOe," \u2014 "),mZ=n(ZOe,"A",{href:!0});var PGt=s(mZ);Hkr=r(PGt,"TFMBartForConditionalGeneration"),PGt.forEach(t),Jkr=r(ZOe," (mBART model)"),ZOe.forEach(t),Ykr=i(Ie),$C=n(Ie,"LI",{});var eVe=s($C);bCe=n(eVe,"STRONG",{});var BGt=s(bCe);Kkr=r(BGt,"mt5"),BGt.forEach(t),Zkr=r(eVe," \u2014 "),gZ=n(eVe,"A",{href:!0});var IGt=s(gZ);eSr=r(IGt,"TFMT5ForConditionalGeneration"),IGt.forEach(t),oSr=r(eVe," (MT5 model)"),eVe.forEach(t),rSr=i(Ie),kC=n(Ie,"LI",{});var oVe=s(kC);vCe=n(oVe,"STRONG",{});var NGt=s(vCe);tSr=r(NGt,"pegasus"),NGt.forEach(t),aSr=r(oVe," \u2014 "),hZ=n(oVe,"A",{href:!0});var qGt=s(hZ);nSr=r(qGt,"TFPegasusForConditionalGeneration"),qGt.forEach(t),sSr=r(oVe," (Pegasus model)"),oVe.forEach(t),lSr=i(Ie),SC=n(Ie,"LI",{});var rVe=s(SC);FCe=n(rVe,"STRONG",{});var jGt=s(FCe);iSr=r(jGt,"t5"),jGt.forEach(t),dSr=r(rVe," \u2014 "),pZ=n(rVe,"A",{href:!0});var DGt=s(pZ);cSr=r(DGt,"TFT5ForConditionalGeneration"),DGt.forEach(t),fSr=r(rVe," (T5 model)"),rVe.forEach(t),Ie.forEach(t),mSr=i(Hl),T(RC.$$.fragment,Hl),Hl.forEach(t),Ul.forEach(t),sUe=i(f),Bc=n(f,"H2",{class:!0});var _Je=s(Bc);PC=n(_Je,"A",{id:!0,class:!0,href:!0});var GGt=s(PC);TCe=n(GGt,"SPAN",{});var OGt=s(TCe);T(h$.$$.fragment,OGt),OGt.forEach(t),GGt.forEach(t),gSr=i(_Je),MCe=n(_Je,"SPAN",{});var VGt=s(MCe);hSr=r(VGt,"TFAutoModelForSequenceClassification"),VGt.forEach(t),_Je.forEach(t),lUe=i(f),cr=n(f,"DIV",{class:!0});var Jl=s(cr);T(p$.$$.fragment,Jl),pSr=i(Jl),Ic=n(Jl,"P",{});var gne=s(Ic);_Sr=r(gne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_Z=n(gne,"A",{href:!0});var XGt=s(_Z);uSr=r(XGt,"from_pretrained()"),XGt.forEach(t),bSr=r(gne," class method or the "),uZ=n(gne,"A",{href:!0});var zGt=s(uZ);vSr=r(zGt,"from_config()"),zGt.forEach(t),FSr=r(gne,` class
method.`),gne.forEach(t),TSr=i(Jl),_$=n(Jl,"P",{});var uJe=s(_$);MSr=r(uJe,"This class cannot be instantiated directly using "),ECe=n(uJe,"CODE",{});var WGt=s(ECe);ESr=r(WGt,"__init__()"),WGt.forEach(t),CSr=r(uJe," (throws an error)."),uJe.forEach(t),wSr=i(Jl),Ot=n(Jl,"DIV",{class:!0});var tL=s(Ot);T(u$.$$.fragment,tL),ASr=i(tL),CCe=n(tL,"P",{});var QGt=s(CCe);LSr=r(QGt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),QGt.forEach(t),ySr=i(tL),Nc=n(tL,"P",{});var hne=s(Nc);xSr=r(hne,`Note:
Loading a model from its configuration file does `),wCe=n(hne,"STRONG",{});var UGt=s(wCe);$Sr=r(UGt,"not"),UGt.forEach(t),kSr=r(hne,` load the model weights. It only affects the
model\u2019s configuration. Use `),bZ=n(hne,"A",{href:!0});var HGt=s(bZ);SSr=r(HGt,"from_pretrained()"),HGt.forEach(t),RSr=r(hne," to load the model weights."),hne.forEach(t),PSr=i(tL),T(BC.$$.fragment,tL),tL.forEach(t),BSr=i(Jl),qr=n(Jl,"DIV",{class:!0});var Yl=s(qr);T(b$.$$.fragment,Yl),ISr=i(Yl),ACe=n(Yl,"P",{});var JGt=s(ACe);NSr=r(JGt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),JGt.forEach(t),qSr=i(Yl),vn=n(Yl,"P",{});var aL=s(vn);jSr=r(aL,"The model class to instantiate is selected based on the "),LCe=n(aL,"CODE",{});var YGt=s(LCe);DSr=r(YGt,"model_type"),YGt.forEach(t),GSr=r(aL,` property of the config object (either
passed as an argument or loaded from `),yCe=n(aL,"CODE",{});var KGt=s(yCe);OSr=r(KGt,"pretrained_model_name_or_path"),KGt.forEach(t),VSr=r(aL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xCe=n(aL,"CODE",{});var ZGt=s(xCe);XSr=r(ZGt,"pretrained_model_name_or_path"),ZGt.forEach(t),zSr=r(aL,":"),aL.forEach(t),WSr=i(Yl),te=n(Yl,"UL",{});var ne=s(te);IC=n(ne,"LI",{});var tVe=s(IC);$Ce=n(tVe,"STRONG",{});var eOt=s($Ce);QSr=r(eOt,"albert"),eOt.forEach(t),USr=r(tVe," \u2014 "),vZ=n(tVe,"A",{href:!0});var oOt=s(vZ);HSr=r(oOt,"TFAlbertForSequenceClassification"),oOt.forEach(t),JSr=r(tVe," (ALBERT model)"),tVe.forEach(t),YSr=i(ne),NC=n(ne,"LI",{});var aVe=s(NC);kCe=n(aVe,"STRONG",{});var rOt=s(kCe);KSr=r(rOt,"bert"),rOt.forEach(t),ZSr=r(aVe," \u2014 "),FZ=n(aVe,"A",{href:!0});var tOt=s(FZ);eRr=r(tOt,"TFBertForSequenceClassification"),tOt.forEach(t),oRr=r(aVe," (BERT model)"),aVe.forEach(t),rRr=i(ne),qC=n(ne,"LI",{});var nVe=s(qC);SCe=n(nVe,"STRONG",{});var aOt=s(SCe);tRr=r(aOt,"camembert"),aOt.forEach(t),aRr=r(nVe," \u2014 "),TZ=n(nVe,"A",{href:!0});var nOt=s(TZ);nRr=r(nOt,"TFCamembertForSequenceClassification"),nOt.forEach(t),sRr=r(nVe," (CamemBERT model)"),nVe.forEach(t),lRr=i(ne),jC=n(ne,"LI",{});var sVe=s(jC);RCe=n(sVe,"STRONG",{});var sOt=s(RCe);iRr=r(sOt,"convbert"),sOt.forEach(t),dRr=r(sVe," \u2014 "),MZ=n(sVe,"A",{href:!0});var lOt=s(MZ);cRr=r(lOt,"TFConvBertForSequenceClassification"),lOt.forEach(t),fRr=r(sVe," (ConvBERT model)"),sVe.forEach(t),mRr=i(ne),DC=n(ne,"LI",{});var lVe=s(DC);PCe=n(lVe,"STRONG",{});var iOt=s(PCe);gRr=r(iOt,"ctrl"),iOt.forEach(t),hRr=r(lVe," \u2014 "),EZ=n(lVe,"A",{href:!0});var dOt=s(EZ);pRr=r(dOt,"TFCTRLForSequenceClassification"),dOt.forEach(t),_Rr=r(lVe," (CTRL model)"),lVe.forEach(t),uRr=i(ne),GC=n(ne,"LI",{});var iVe=s(GC);BCe=n(iVe,"STRONG",{});var cOt=s(BCe);bRr=r(cOt,"deberta"),cOt.forEach(t),vRr=r(iVe," \u2014 "),CZ=n(iVe,"A",{href:!0});var fOt=s(CZ);FRr=r(fOt,"TFDebertaForSequenceClassification"),fOt.forEach(t),TRr=r(iVe," (DeBERTa model)"),iVe.forEach(t),MRr=i(ne),OC=n(ne,"LI",{});var dVe=s(OC);ICe=n(dVe,"STRONG",{});var mOt=s(ICe);ERr=r(mOt,"deberta-v2"),mOt.forEach(t),CRr=r(dVe," \u2014 "),wZ=n(dVe,"A",{href:!0});var gOt=s(wZ);wRr=r(gOt,"TFDebertaV2ForSequenceClassification"),gOt.forEach(t),ARr=r(dVe," (DeBERTa-v2 model)"),dVe.forEach(t),LRr=i(ne),VC=n(ne,"LI",{});var cVe=s(VC);NCe=n(cVe,"STRONG",{});var hOt=s(NCe);yRr=r(hOt,"distilbert"),hOt.forEach(t),xRr=r(cVe," \u2014 "),AZ=n(cVe,"A",{href:!0});var pOt=s(AZ);$Rr=r(pOt,"TFDistilBertForSequenceClassification"),pOt.forEach(t),kRr=r(cVe," (DistilBERT model)"),cVe.forEach(t),SRr=i(ne),XC=n(ne,"LI",{});var fVe=s(XC);qCe=n(fVe,"STRONG",{});var _Ot=s(qCe);RRr=r(_Ot,"electra"),_Ot.forEach(t),PRr=r(fVe," \u2014 "),LZ=n(fVe,"A",{href:!0});var uOt=s(LZ);BRr=r(uOt,"TFElectraForSequenceClassification"),uOt.forEach(t),IRr=r(fVe," (ELECTRA model)"),fVe.forEach(t),NRr=i(ne),zC=n(ne,"LI",{});var mVe=s(zC);jCe=n(mVe,"STRONG",{});var bOt=s(jCe);qRr=r(bOt,"flaubert"),bOt.forEach(t),jRr=r(mVe," \u2014 "),yZ=n(mVe,"A",{href:!0});var vOt=s(yZ);DRr=r(vOt,"TFFlaubertForSequenceClassification"),vOt.forEach(t),GRr=r(mVe," (FlauBERT model)"),mVe.forEach(t),ORr=i(ne),WC=n(ne,"LI",{});var gVe=s(WC);DCe=n(gVe,"STRONG",{});var FOt=s(DCe);VRr=r(FOt,"funnel"),FOt.forEach(t),XRr=r(gVe," \u2014 "),xZ=n(gVe,"A",{href:!0});var TOt=s(xZ);zRr=r(TOt,"TFFunnelForSequenceClassification"),TOt.forEach(t),WRr=r(gVe," (Funnel Transformer model)"),gVe.forEach(t),QRr=i(ne),QC=n(ne,"LI",{});var hVe=s(QC);GCe=n(hVe,"STRONG",{});var MOt=s(GCe);URr=r(MOt,"gpt2"),MOt.forEach(t),HRr=r(hVe," \u2014 "),$Z=n(hVe,"A",{href:!0});var EOt=s($Z);JRr=r(EOt,"TFGPT2ForSequenceClassification"),EOt.forEach(t),YRr=r(hVe," (OpenAI GPT-2 model)"),hVe.forEach(t),KRr=i(ne),UC=n(ne,"LI",{});var pVe=s(UC);OCe=n(pVe,"STRONG",{});var COt=s(OCe);ZRr=r(COt,"gptj"),COt.forEach(t),ePr=r(pVe," \u2014 "),kZ=n(pVe,"A",{href:!0});var wOt=s(kZ);oPr=r(wOt,"TFGPTJForSequenceClassification"),wOt.forEach(t),rPr=r(pVe," (GPT-J model)"),pVe.forEach(t),tPr=i(ne),HC=n(ne,"LI",{});var _Ve=s(HC);VCe=n(_Ve,"STRONG",{});var AOt=s(VCe);aPr=r(AOt,"layoutlm"),AOt.forEach(t),nPr=r(_Ve," \u2014 "),SZ=n(_Ve,"A",{href:!0});var LOt=s(SZ);sPr=r(LOt,"TFLayoutLMForSequenceClassification"),LOt.forEach(t),lPr=r(_Ve," (LayoutLM model)"),_Ve.forEach(t),iPr=i(ne),JC=n(ne,"LI",{});var uVe=s(JC);XCe=n(uVe,"STRONG",{});var yOt=s(XCe);dPr=r(yOt,"longformer"),yOt.forEach(t),cPr=r(uVe," \u2014 "),RZ=n(uVe,"A",{href:!0});var xOt=s(RZ);fPr=r(xOt,"TFLongformerForSequenceClassification"),xOt.forEach(t),mPr=r(uVe," (Longformer model)"),uVe.forEach(t),gPr=i(ne),YC=n(ne,"LI",{});var bVe=s(YC);zCe=n(bVe,"STRONG",{});var $Ot=s(zCe);hPr=r($Ot,"mobilebert"),$Ot.forEach(t),pPr=r(bVe," \u2014 "),PZ=n(bVe,"A",{href:!0});var kOt=s(PZ);_Pr=r(kOt,"TFMobileBertForSequenceClassification"),kOt.forEach(t),uPr=r(bVe," (MobileBERT model)"),bVe.forEach(t),bPr=i(ne),KC=n(ne,"LI",{});var vVe=s(KC);WCe=n(vVe,"STRONG",{});var SOt=s(WCe);vPr=r(SOt,"mpnet"),SOt.forEach(t),FPr=r(vVe," \u2014 "),BZ=n(vVe,"A",{href:!0});var ROt=s(BZ);TPr=r(ROt,"TFMPNetForSequenceClassification"),ROt.forEach(t),MPr=r(vVe," (MPNet model)"),vVe.forEach(t),EPr=i(ne),ZC=n(ne,"LI",{});var FVe=s(ZC);QCe=n(FVe,"STRONG",{});var POt=s(QCe);CPr=r(POt,"openai-gpt"),POt.forEach(t),wPr=r(FVe," \u2014 "),IZ=n(FVe,"A",{href:!0});var BOt=s(IZ);APr=r(BOt,"TFOpenAIGPTForSequenceClassification"),BOt.forEach(t),LPr=r(FVe," (OpenAI GPT model)"),FVe.forEach(t),yPr=i(ne),e3=n(ne,"LI",{});var TVe=s(e3);UCe=n(TVe,"STRONG",{});var IOt=s(UCe);xPr=r(IOt,"rembert"),IOt.forEach(t),$Pr=r(TVe," \u2014 "),NZ=n(TVe,"A",{href:!0});var NOt=s(NZ);kPr=r(NOt,"TFRemBertForSequenceClassification"),NOt.forEach(t),SPr=r(TVe," (RemBERT model)"),TVe.forEach(t),RPr=i(ne),o3=n(ne,"LI",{});var MVe=s(o3);HCe=n(MVe,"STRONG",{});var qOt=s(HCe);PPr=r(qOt,"roberta"),qOt.forEach(t),BPr=r(MVe," \u2014 "),qZ=n(MVe,"A",{href:!0});var jOt=s(qZ);IPr=r(jOt,"TFRobertaForSequenceClassification"),jOt.forEach(t),NPr=r(MVe," (RoBERTa model)"),MVe.forEach(t),qPr=i(ne),r3=n(ne,"LI",{});var EVe=s(r3);JCe=n(EVe,"STRONG",{});var DOt=s(JCe);jPr=r(DOt,"roformer"),DOt.forEach(t),DPr=r(EVe," \u2014 "),jZ=n(EVe,"A",{href:!0});var GOt=s(jZ);GPr=r(GOt,"TFRoFormerForSequenceClassification"),GOt.forEach(t),OPr=r(EVe," (RoFormer model)"),EVe.forEach(t),VPr=i(ne),t3=n(ne,"LI",{});var CVe=s(t3);YCe=n(CVe,"STRONG",{});var OOt=s(YCe);XPr=r(OOt,"tapas"),OOt.forEach(t),zPr=r(CVe," \u2014 "),DZ=n(CVe,"A",{href:!0});var VOt=s(DZ);WPr=r(VOt,"TFTapasForSequenceClassification"),VOt.forEach(t),QPr=r(CVe," (TAPAS model)"),CVe.forEach(t),UPr=i(ne),a3=n(ne,"LI",{});var wVe=s(a3);KCe=n(wVe,"STRONG",{});var XOt=s(KCe);HPr=r(XOt,"transfo-xl"),XOt.forEach(t),JPr=r(wVe," \u2014 "),GZ=n(wVe,"A",{href:!0});var zOt=s(GZ);YPr=r(zOt,"TFTransfoXLForSequenceClassification"),zOt.forEach(t),KPr=r(wVe," (Transformer-XL model)"),wVe.forEach(t),ZPr=i(ne),n3=n(ne,"LI",{});var AVe=s(n3);ZCe=n(AVe,"STRONG",{});var WOt=s(ZCe);eBr=r(WOt,"xlm"),WOt.forEach(t),oBr=r(AVe," \u2014 "),OZ=n(AVe,"A",{href:!0});var QOt=s(OZ);rBr=r(QOt,"TFXLMForSequenceClassification"),QOt.forEach(t),tBr=r(AVe," (XLM model)"),AVe.forEach(t),aBr=i(ne),s3=n(ne,"LI",{});var LVe=s(s3);e3e=n(LVe,"STRONG",{});var UOt=s(e3e);nBr=r(UOt,"xlm-roberta"),UOt.forEach(t),sBr=r(LVe," \u2014 "),VZ=n(LVe,"A",{href:!0});var HOt=s(VZ);lBr=r(HOt,"TFXLMRobertaForSequenceClassification"),HOt.forEach(t),iBr=r(LVe," (XLM-RoBERTa model)"),LVe.forEach(t),dBr=i(ne),l3=n(ne,"LI",{});var yVe=s(l3);o3e=n(yVe,"STRONG",{});var JOt=s(o3e);cBr=r(JOt,"xlnet"),JOt.forEach(t),fBr=r(yVe," \u2014 "),XZ=n(yVe,"A",{href:!0});var YOt=s(XZ);mBr=r(YOt,"TFXLNetForSequenceClassification"),YOt.forEach(t),gBr=r(yVe," (XLNet model)"),yVe.forEach(t),ne.forEach(t),hBr=i(Yl),T(i3.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),iUe=i(f),qc=n(f,"H2",{class:!0});var bJe=s(qc);d3=n(bJe,"A",{id:!0,class:!0,href:!0});var KOt=s(d3);r3e=n(KOt,"SPAN",{});var ZOt=s(r3e);T(v$.$$.fragment,ZOt),ZOt.forEach(t),KOt.forEach(t),pBr=i(bJe),t3e=n(bJe,"SPAN",{});var eVt=s(t3e);_Br=r(eVt,"TFAutoModelForMultipleChoice"),eVt.forEach(t),bJe.forEach(t),dUe=i(f),fr=n(f,"DIV",{class:!0});var Kl=s(fr);T(F$.$$.fragment,Kl),uBr=i(Kl),jc=n(Kl,"P",{});var pne=s(jc);bBr=r(pne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zZ=n(pne,"A",{href:!0});var oVt=s(zZ);vBr=r(oVt,"from_pretrained()"),oVt.forEach(t),FBr=r(pne," class method or the "),WZ=n(pne,"A",{href:!0});var rVt=s(WZ);TBr=r(rVt,"from_config()"),rVt.forEach(t),MBr=r(pne,` class
method.`),pne.forEach(t),EBr=i(Kl),T$=n(Kl,"P",{});var vJe=s(T$);CBr=r(vJe,"This class cannot be instantiated directly using "),a3e=n(vJe,"CODE",{});var tVt=s(a3e);wBr=r(tVt,"__init__()"),tVt.forEach(t),ABr=r(vJe," (throws an error)."),vJe.forEach(t),LBr=i(Kl),Vt=n(Kl,"DIV",{class:!0});var nL=s(Vt);T(M$.$$.fragment,nL),yBr=i(nL),n3e=n(nL,"P",{});var aVt=s(n3e);xBr=r(aVt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),aVt.forEach(t),$Br=i(nL),Dc=n(nL,"P",{});var _ne=s(Dc);kBr=r(_ne,`Note:
Loading a model from its configuration file does `),s3e=n(_ne,"STRONG",{});var nVt=s(s3e);SBr=r(nVt,"not"),nVt.forEach(t),RBr=r(_ne,` load the model weights. It only affects the
model\u2019s configuration. Use `),QZ=n(_ne,"A",{href:!0});var sVt=s(QZ);PBr=r(sVt,"from_pretrained()"),sVt.forEach(t),BBr=r(_ne," to load the model weights."),_ne.forEach(t),IBr=i(nL),T(c3.$$.fragment,nL),nL.forEach(t),NBr=i(Kl),jr=n(Kl,"DIV",{class:!0});var Zl=s(jr);T(E$.$$.fragment,Zl),qBr=i(Zl),l3e=n(Zl,"P",{});var lVt=s(l3e);jBr=r(lVt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),lVt.forEach(t),DBr=i(Zl),Fn=n(Zl,"P",{});var sL=s(Fn);GBr=r(sL,"The model class to instantiate is selected based on the "),i3e=n(sL,"CODE",{});var iVt=s(i3e);OBr=r(iVt,"model_type"),iVt.forEach(t),VBr=r(sL,` property of the config object (either
passed as an argument or loaded from `),d3e=n(sL,"CODE",{});var dVt=s(d3e);XBr=r(dVt,"pretrained_model_name_or_path"),dVt.forEach(t),zBr=r(sL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c3e=n(sL,"CODE",{});var cVt=s(c3e);WBr=r(cVt,"pretrained_model_name_or_path"),cVt.forEach(t),QBr=r(sL,":"),sL.forEach(t),UBr=i(Zl),ve=n(Zl,"UL",{});var Te=s(ve);f3=n(Te,"LI",{});var xVe=s(f3);f3e=n(xVe,"STRONG",{});var fVt=s(f3e);HBr=r(fVt,"albert"),fVt.forEach(t),JBr=r(xVe," \u2014 "),UZ=n(xVe,"A",{href:!0});var mVt=s(UZ);YBr=r(mVt,"TFAlbertForMultipleChoice"),mVt.forEach(t),KBr=r(xVe," (ALBERT model)"),xVe.forEach(t),ZBr=i(Te),m3=n(Te,"LI",{});var $Ve=s(m3);m3e=n($Ve,"STRONG",{});var gVt=s(m3e);eIr=r(gVt,"bert"),gVt.forEach(t),oIr=r($Ve," \u2014 "),HZ=n($Ve,"A",{href:!0});var hVt=s(HZ);rIr=r(hVt,"TFBertForMultipleChoice"),hVt.forEach(t),tIr=r($Ve," (BERT model)"),$Ve.forEach(t),aIr=i(Te),g3=n(Te,"LI",{});var kVe=s(g3);g3e=n(kVe,"STRONG",{});var pVt=s(g3e);nIr=r(pVt,"camembert"),pVt.forEach(t),sIr=r(kVe," \u2014 "),JZ=n(kVe,"A",{href:!0});var _Vt=s(JZ);lIr=r(_Vt,"TFCamembertForMultipleChoice"),_Vt.forEach(t),iIr=r(kVe," (CamemBERT model)"),kVe.forEach(t),dIr=i(Te),h3=n(Te,"LI",{});var SVe=s(h3);h3e=n(SVe,"STRONG",{});var uVt=s(h3e);cIr=r(uVt,"convbert"),uVt.forEach(t),fIr=r(SVe," \u2014 "),YZ=n(SVe,"A",{href:!0});var bVt=s(YZ);mIr=r(bVt,"TFConvBertForMultipleChoice"),bVt.forEach(t),gIr=r(SVe," (ConvBERT model)"),SVe.forEach(t),hIr=i(Te),p3=n(Te,"LI",{});var RVe=s(p3);p3e=n(RVe,"STRONG",{});var vVt=s(p3e);pIr=r(vVt,"distilbert"),vVt.forEach(t),_Ir=r(RVe," \u2014 "),KZ=n(RVe,"A",{href:!0});var FVt=s(KZ);uIr=r(FVt,"TFDistilBertForMultipleChoice"),FVt.forEach(t),bIr=r(RVe," (DistilBERT model)"),RVe.forEach(t),vIr=i(Te),_3=n(Te,"LI",{});var PVe=s(_3);_3e=n(PVe,"STRONG",{});var TVt=s(_3e);FIr=r(TVt,"electra"),TVt.forEach(t),TIr=r(PVe," \u2014 "),ZZ=n(PVe,"A",{href:!0});var MVt=s(ZZ);MIr=r(MVt,"TFElectraForMultipleChoice"),MVt.forEach(t),EIr=r(PVe," (ELECTRA model)"),PVe.forEach(t),CIr=i(Te),u3=n(Te,"LI",{});var BVe=s(u3);u3e=n(BVe,"STRONG",{});var EVt=s(u3e);wIr=r(EVt,"flaubert"),EVt.forEach(t),AIr=r(BVe," \u2014 "),eee=n(BVe,"A",{href:!0});var CVt=s(eee);LIr=r(CVt,"TFFlaubertForMultipleChoice"),CVt.forEach(t),yIr=r(BVe," (FlauBERT model)"),BVe.forEach(t),xIr=i(Te),b3=n(Te,"LI",{});var IVe=s(b3);b3e=n(IVe,"STRONG",{});var wVt=s(b3e);$Ir=r(wVt,"funnel"),wVt.forEach(t),kIr=r(IVe," \u2014 "),oee=n(IVe,"A",{href:!0});var AVt=s(oee);SIr=r(AVt,"TFFunnelForMultipleChoice"),AVt.forEach(t),RIr=r(IVe," (Funnel Transformer model)"),IVe.forEach(t),PIr=i(Te),v3=n(Te,"LI",{});var NVe=s(v3);v3e=n(NVe,"STRONG",{});var LVt=s(v3e);BIr=r(LVt,"longformer"),LVt.forEach(t),IIr=r(NVe," \u2014 "),ree=n(NVe,"A",{href:!0});var yVt=s(ree);NIr=r(yVt,"TFLongformerForMultipleChoice"),yVt.forEach(t),qIr=r(NVe," (Longformer model)"),NVe.forEach(t),jIr=i(Te),F3=n(Te,"LI",{});var qVe=s(F3);F3e=n(qVe,"STRONG",{});var xVt=s(F3e);DIr=r(xVt,"mobilebert"),xVt.forEach(t),GIr=r(qVe," \u2014 "),tee=n(qVe,"A",{href:!0});var $Vt=s(tee);OIr=r($Vt,"TFMobileBertForMultipleChoice"),$Vt.forEach(t),VIr=r(qVe," (MobileBERT model)"),qVe.forEach(t),XIr=i(Te),T3=n(Te,"LI",{});var jVe=s(T3);T3e=n(jVe,"STRONG",{});var kVt=s(T3e);zIr=r(kVt,"mpnet"),kVt.forEach(t),WIr=r(jVe," \u2014 "),aee=n(jVe,"A",{href:!0});var SVt=s(aee);QIr=r(SVt,"TFMPNetForMultipleChoice"),SVt.forEach(t),UIr=r(jVe," (MPNet model)"),jVe.forEach(t),HIr=i(Te),M3=n(Te,"LI",{});var DVe=s(M3);M3e=n(DVe,"STRONG",{});var RVt=s(M3e);JIr=r(RVt,"rembert"),RVt.forEach(t),YIr=r(DVe," \u2014 "),nee=n(DVe,"A",{href:!0});var PVt=s(nee);KIr=r(PVt,"TFRemBertForMultipleChoice"),PVt.forEach(t),ZIr=r(DVe," (RemBERT model)"),DVe.forEach(t),eNr=i(Te),E3=n(Te,"LI",{});var GVe=s(E3);E3e=n(GVe,"STRONG",{});var BVt=s(E3e);oNr=r(BVt,"roberta"),BVt.forEach(t),rNr=r(GVe," \u2014 "),see=n(GVe,"A",{href:!0});var IVt=s(see);tNr=r(IVt,"TFRobertaForMultipleChoice"),IVt.forEach(t),aNr=r(GVe," (RoBERTa model)"),GVe.forEach(t),nNr=i(Te),C3=n(Te,"LI",{});var OVe=s(C3);C3e=n(OVe,"STRONG",{});var NVt=s(C3e);sNr=r(NVt,"roformer"),NVt.forEach(t),lNr=r(OVe," \u2014 "),lee=n(OVe,"A",{href:!0});var qVt=s(lee);iNr=r(qVt,"TFRoFormerForMultipleChoice"),qVt.forEach(t),dNr=r(OVe," (RoFormer model)"),OVe.forEach(t),cNr=i(Te),w3=n(Te,"LI",{});var VVe=s(w3);w3e=n(VVe,"STRONG",{});var jVt=s(w3e);fNr=r(jVt,"xlm"),jVt.forEach(t),mNr=r(VVe," \u2014 "),iee=n(VVe,"A",{href:!0});var DVt=s(iee);gNr=r(DVt,"TFXLMForMultipleChoice"),DVt.forEach(t),hNr=r(VVe," (XLM model)"),VVe.forEach(t),pNr=i(Te),A3=n(Te,"LI",{});var XVe=s(A3);A3e=n(XVe,"STRONG",{});var GVt=s(A3e);_Nr=r(GVt,"xlm-roberta"),GVt.forEach(t),uNr=r(XVe," \u2014 "),dee=n(XVe,"A",{href:!0});var OVt=s(dee);bNr=r(OVt,"TFXLMRobertaForMultipleChoice"),OVt.forEach(t),vNr=r(XVe," (XLM-RoBERTa model)"),XVe.forEach(t),FNr=i(Te),L3=n(Te,"LI",{});var zVe=s(L3);L3e=n(zVe,"STRONG",{});var VVt=s(L3e);TNr=r(VVt,"xlnet"),VVt.forEach(t),MNr=r(zVe," \u2014 "),cee=n(zVe,"A",{href:!0});var XVt=s(cee);ENr=r(XVt,"TFXLNetForMultipleChoice"),XVt.forEach(t),CNr=r(zVe," (XLNet model)"),zVe.forEach(t),Te.forEach(t),wNr=i(Zl),T(y3.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),cUe=i(f),Gc=n(f,"H2",{class:!0});var FJe=s(Gc);x3=n(FJe,"A",{id:!0,class:!0,href:!0});var zVt=s(x3);y3e=n(zVt,"SPAN",{});var WVt=s(y3e);T(C$.$$.fragment,WVt),WVt.forEach(t),zVt.forEach(t),ANr=i(FJe),x3e=n(FJe,"SPAN",{});var QVt=s(x3e);LNr=r(QVt,"TFAutoModelForNextSentencePrediction"),QVt.forEach(t),FJe.forEach(t),fUe=i(f),mr=n(f,"DIV",{class:!0});var ei=s(mr);T(w$.$$.fragment,ei),yNr=i(ei),Oc=n(ei,"P",{});var une=s(Oc);xNr=r(une,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fee=n(une,"A",{href:!0});var UVt=s(fee);$Nr=r(UVt,"from_pretrained()"),UVt.forEach(t),kNr=r(une," class method or the "),mee=n(une,"A",{href:!0});var HVt=s(mee);SNr=r(HVt,"from_config()"),HVt.forEach(t),RNr=r(une,` class
method.`),une.forEach(t),PNr=i(ei),A$=n(ei,"P",{});var TJe=s(A$);BNr=r(TJe,"This class cannot be instantiated directly using "),$3e=n(TJe,"CODE",{});var JVt=s($3e);INr=r(JVt,"__init__()"),JVt.forEach(t),NNr=r(TJe," (throws an error)."),TJe.forEach(t),qNr=i(ei),Xt=n(ei,"DIV",{class:!0});var lL=s(Xt);T(L$.$$.fragment,lL),jNr=i(lL),k3e=n(lL,"P",{});var YVt=s(k3e);DNr=r(YVt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),YVt.forEach(t),GNr=i(lL),Vc=n(lL,"P",{});var bne=s(Vc);ONr=r(bne,`Note:
Loading a model from its configuration file does `),S3e=n(bne,"STRONG",{});var KVt=s(S3e);VNr=r(KVt,"not"),KVt.forEach(t),XNr=r(bne,` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=n(bne,"A",{href:!0});var ZVt=s(gee);zNr=r(ZVt,"from_pretrained()"),ZVt.forEach(t),WNr=r(bne," to load the model weights."),bne.forEach(t),QNr=i(lL),T($3.$$.fragment,lL),lL.forEach(t),UNr=i(ei),Dr=n(ei,"DIV",{class:!0});var oi=s(Dr);T(y$.$$.fragment,oi),HNr=i(oi),R3e=n(oi,"P",{});var eXt=s(R3e);JNr=r(eXt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),eXt.forEach(t),YNr=i(oi),Tn=n(oi,"P",{});var iL=s(Tn);KNr=r(iL,"The model class to instantiate is selected based on the "),P3e=n(iL,"CODE",{});var oXt=s(P3e);ZNr=r(oXt,"model_type"),oXt.forEach(t),eqr=r(iL,` property of the config object (either
passed as an argument or loaded from `),B3e=n(iL,"CODE",{});var rXt=s(B3e);oqr=r(rXt,"pretrained_model_name_or_path"),rXt.forEach(t),rqr=r(iL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I3e=n(iL,"CODE",{});var tXt=s(I3e);tqr=r(tXt,"pretrained_model_name_or_path"),tXt.forEach(t),aqr=r(iL,":"),iL.forEach(t),nqr=i(oi),x$=n(oi,"UL",{});var MJe=s(x$);k3=n(MJe,"LI",{});var WVe=s(k3);N3e=n(WVe,"STRONG",{});var aXt=s(N3e);sqr=r(aXt,"bert"),aXt.forEach(t),lqr=r(WVe," \u2014 "),hee=n(WVe,"A",{href:!0});var nXt=s(hee);iqr=r(nXt,"TFBertForNextSentencePrediction"),nXt.forEach(t),dqr=r(WVe," (BERT model)"),WVe.forEach(t),cqr=i(MJe),S3=n(MJe,"LI",{});var QVe=s(S3);q3e=n(QVe,"STRONG",{});var sXt=s(q3e);fqr=r(sXt,"mobilebert"),sXt.forEach(t),mqr=r(QVe," \u2014 "),pee=n(QVe,"A",{href:!0});var lXt=s(pee);gqr=r(lXt,"TFMobileBertForNextSentencePrediction"),lXt.forEach(t),hqr=r(QVe," (MobileBERT model)"),QVe.forEach(t),MJe.forEach(t),pqr=i(oi),T(R3.$$.fragment,oi),oi.forEach(t),ei.forEach(t),mUe=i(f),Xc=n(f,"H2",{class:!0});var EJe=s(Xc);P3=n(EJe,"A",{id:!0,class:!0,href:!0});var iXt=s(P3);j3e=n(iXt,"SPAN",{});var dXt=s(j3e);T($$.$$.fragment,dXt),dXt.forEach(t),iXt.forEach(t),_qr=i(EJe),D3e=n(EJe,"SPAN",{});var cXt=s(D3e);uqr=r(cXt,"TFAutoModelForTableQuestionAnswering"),cXt.forEach(t),EJe.forEach(t),gUe=i(f),gr=n(f,"DIV",{class:!0});var ri=s(gr);T(k$.$$.fragment,ri),bqr=i(ri),zc=n(ri,"P",{});var vne=s(zc);vqr=r(vne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),_ee=n(vne,"A",{href:!0});var fXt=s(_ee);Fqr=r(fXt,"from_pretrained()"),fXt.forEach(t),Tqr=r(vne," class method or the "),uee=n(vne,"A",{href:!0});var mXt=s(uee);Mqr=r(mXt,"from_config()"),mXt.forEach(t),Eqr=r(vne,` class
method.`),vne.forEach(t),Cqr=i(ri),S$=n(ri,"P",{});var CJe=s(S$);wqr=r(CJe,"This class cannot be instantiated directly using "),G3e=n(CJe,"CODE",{});var gXt=s(G3e);Aqr=r(gXt,"__init__()"),gXt.forEach(t),Lqr=r(CJe," (throws an error)."),CJe.forEach(t),yqr=i(ri),zt=n(ri,"DIV",{class:!0});var dL=s(zt);T(R$.$$.fragment,dL),xqr=i(dL),O3e=n(dL,"P",{});var hXt=s(O3e);$qr=r(hXt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),hXt.forEach(t),kqr=i(dL),Wc=n(dL,"P",{});var Fne=s(Wc);Sqr=r(Fne,`Note:
Loading a model from its configuration file does `),V3e=n(Fne,"STRONG",{});var pXt=s(V3e);Rqr=r(pXt,"not"),pXt.forEach(t),Pqr=r(Fne,` load the model weights. It only affects the
model\u2019s configuration. Use `),bee=n(Fne,"A",{href:!0});var _Xt=s(bee);Bqr=r(_Xt,"from_pretrained()"),_Xt.forEach(t),Iqr=r(Fne," to load the model weights."),Fne.forEach(t),Nqr=i(dL),T(B3.$$.fragment,dL),dL.forEach(t),qqr=i(ri),Gr=n(ri,"DIV",{class:!0});var ti=s(Gr);T(P$.$$.fragment,ti),jqr=i(ti),X3e=n(ti,"P",{});var uXt=s(X3e);Dqr=r(uXt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),uXt.forEach(t),Gqr=i(ti),Mn=n(ti,"P",{});var cL=s(Mn);Oqr=r(cL,"The model class to instantiate is selected based on the "),z3e=n(cL,"CODE",{});var bXt=s(z3e);Vqr=r(bXt,"model_type"),bXt.forEach(t),Xqr=r(cL,` property of the config object (either
passed as an argument or loaded from `),W3e=n(cL,"CODE",{});var vXt=s(W3e);zqr=r(vXt,"pretrained_model_name_or_path"),vXt.forEach(t),Wqr=r(cL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q3e=n(cL,"CODE",{});var FXt=s(Q3e);Qqr=r(FXt,"pretrained_model_name_or_path"),FXt.forEach(t),Uqr=r(cL,":"),cL.forEach(t),Hqr=i(ti),U3e=n(ti,"UL",{});var TXt=s(U3e);I3=n(TXt,"LI",{});var UVe=s(I3);H3e=n(UVe,"STRONG",{});var MXt=s(H3e);Jqr=r(MXt,"tapas"),MXt.forEach(t),Yqr=r(UVe," \u2014 "),vee=n(UVe,"A",{href:!0});var EXt=s(vee);Kqr=r(EXt,"TFTapasForQuestionAnswering"),EXt.forEach(t),Zqr=r(UVe," (TAPAS model)"),UVe.forEach(t),TXt.forEach(t),ejr=i(ti),T(N3.$$.fragment,ti),ti.forEach(t),ri.forEach(t),hUe=i(f),Qc=n(f,"H2",{class:!0});var wJe=s(Qc);q3=n(wJe,"A",{id:!0,class:!0,href:!0});var CXt=s(q3);J3e=n(CXt,"SPAN",{});var wXt=s(J3e);T(B$.$$.fragment,wXt),wXt.forEach(t),CXt.forEach(t),ojr=i(wJe),Y3e=n(wJe,"SPAN",{});var AXt=s(Y3e);rjr=r(AXt,"TFAutoModelForTokenClassification"),AXt.forEach(t),wJe.forEach(t),pUe=i(f),hr=n(f,"DIV",{class:!0});var ai=s(hr);T(I$.$$.fragment,ai),tjr=i(ai),Uc=n(ai,"P",{});var Tne=s(Uc);ajr=r(Tne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Fee=n(Tne,"A",{href:!0});var LXt=s(Fee);njr=r(LXt,"from_pretrained()"),LXt.forEach(t),sjr=r(Tne," class method or the "),Tee=n(Tne,"A",{href:!0});var yXt=s(Tee);ljr=r(yXt,"from_config()"),yXt.forEach(t),ijr=r(Tne,` class
method.`),Tne.forEach(t),djr=i(ai),N$=n(ai,"P",{});var AJe=s(N$);cjr=r(AJe,"This class cannot be instantiated directly using "),K3e=n(AJe,"CODE",{});var xXt=s(K3e);fjr=r(xXt,"__init__()"),xXt.forEach(t),mjr=r(AJe," (throws an error)."),AJe.forEach(t),gjr=i(ai),Wt=n(ai,"DIV",{class:!0});var fL=s(Wt);T(q$.$$.fragment,fL),hjr=i(fL),Z3e=n(fL,"P",{});var $Xt=s(Z3e);pjr=r($Xt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),$Xt.forEach(t),_jr=i(fL),Hc=n(fL,"P",{});var Mne=s(Hc);ujr=r(Mne,`Note:
Loading a model from its configuration file does `),e0e=n(Mne,"STRONG",{});var kXt=s(e0e);bjr=r(kXt,"not"),kXt.forEach(t),vjr=r(Mne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mee=n(Mne,"A",{href:!0});var SXt=s(Mee);Fjr=r(SXt,"from_pretrained()"),SXt.forEach(t),Tjr=r(Mne," to load the model weights."),Mne.forEach(t),Mjr=i(fL),T(j3.$$.fragment,fL),fL.forEach(t),Ejr=i(ai),Or=n(ai,"DIV",{class:!0});var ni=s(Or);T(j$.$$.fragment,ni),Cjr=i(ni),o0e=n(ni,"P",{});var RXt=s(o0e);wjr=r(RXt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),RXt.forEach(t),Ajr=i(ni),En=n(ni,"P",{});var mL=s(En);Ljr=r(mL,"The model class to instantiate is selected based on the "),r0e=n(mL,"CODE",{});var PXt=s(r0e);yjr=r(PXt,"model_type"),PXt.forEach(t),xjr=r(mL,` property of the config object (either
passed as an argument or loaded from `),t0e=n(mL,"CODE",{});var BXt=s(t0e);$jr=r(BXt,"pretrained_model_name_or_path"),BXt.forEach(t),kjr=r(mL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),a0e=n(mL,"CODE",{});var IXt=s(a0e);Sjr=r(IXt,"pretrained_model_name_or_path"),IXt.forEach(t),Rjr=r(mL,":"),mL.forEach(t),Pjr=i(ni),de=n(ni,"UL",{});var he=s(de);D3=n(he,"LI",{});var HVe=s(D3);n0e=n(HVe,"STRONG",{});var NXt=s(n0e);Bjr=r(NXt,"albert"),NXt.forEach(t),Ijr=r(HVe," \u2014 "),Eee=n(HVe,"A",{href:!0});var qXt=s(Eee);Njr=r(qXt,"TFAlbertForTokenClassification"),qXt.forEach(t),qjr=r(HVe," (ALBERT model)"),HVe.forEach(t),jjr=i(he),G3=n(he,"LI",{});var JVe=s(G3);s0e=n(JVe,"STRONG",{});var jXt=s(s0e);Djr=r(jXt,"bert"),jXt.forEach(t),Gjr=r(JVe," \u2014 "),Cee=n(JVe,"A",{href:!0});var DXt=s(Cee);Ojr=r(DXt,"TFBertForTokenClassification"),DXt.forEach(t),Vjr=r(JVe," (BERT model)"),JVe.forEach(t),Xjr=i(he),O3=n(he,"LI",{});var YVe=s(O3);l0e=n(YVe,"STRONG",{});var GXt=s(l0e);zjr=r(GXt,"camembert"),GXt.forEach(t),Wjr=r(YVe," \u2014 "),wee=n(YVe,"A",{href:!0});var OXt=s(wee);Qjr=r(OXt,"TFCamembertForTokenClassification"),OXt.forEach(t),Ujr=r(YVe," (CamemBERT model)"),YVe.forEach(t),Hjr=i(he),V3=n(he,"LI",{});var KVe=s(V3);i0e=n(KVe,"STRONG",{});var VXt=s(i0e);Jjr=r(VXt,"convbert"),VXt.forEach(t),Yjr=r(KVe," \u2014 "),Aee=n(KVe,"A",{href:!0});var XXt=s(Aee);Kjr=r(XXt,"TFConvBertForTokenClassification"),XXt.forEach(t),Zjr=r(KVe," (ConvBERT model)"),KVe.forEach(t),eDr=i(he),X3=n(he,"LI",{});var ZVe=s(X3);d0e=n(ZVe,"STRONG",{});var zXt=s(d0e);oDr=r(zXt,"deberta"),zXt.forEach(t),rDr=r(ZVe," \u2014 "),Lee=n(ZVe,"A",{href:!0});var WXt=s(Lee);tDr=r(WXt,"TFDebertaForTokenClassification"),WXt.forEach(t),aDr=r(ZVe," (DeBERTa model)"),ZVe.forEach(t),nDr=i(he),z3=n(he,"LI",{});var eXe=s(z3);c0e=n(eXe,"STRONG",{});var QXt=s(c0e);sDr=r(QXt,"deberta-v2"),QXt.forEach(t),lDr=r(eXe," \u2014 "),yee=n(eXe,"A",{href:!0});var UXt=s(yee);iDr=r(UXt,"TFDebertaV2ForTokenClassification"),UXt.forEach(t),dDr=r(eXe," (DeBERTa-v2 model)"),eXe.forEach(t),cDr=i(he),W3=n(he,"LI",{});var oXe=s(W3);f0e=n(oXe,"STRONG",{});var HXt=s(f0e);fDr=r(HXt,"distilbert"),HXt.forEach(t),mDr=r(oXe," \u2014 "),xee=n(oXe,"A",{href:!0});var JXt=s(xee);gDr=r(JXt,"TFDistilBertForTokenClassification"),JXt.forEach(t),hDr=r(oXe," (DistilBERT model)"),oXe.forEach(t),pDr=i(he),Q3=n(he,"LI",{});var rXe=s(Q3);m0e=n(rXe,"STRONG",{});var YXt=s(m0e);_Dr=r(YXt,"electra"),YXt.forEach(t),uDr=r(rXe," \u2014 "),$ee=n(rXe,"A",{href:!0});var KXt=s($ee);bDr=r(KXt,"TFElectraForTokenClassification"),KXt.forEach(t),vDr=r(rXe," (ELECTRA model)"),rXe.forEach(t),FDr=i(he),U3=n(he,"LI",{});var tXe=s(U3);g0e=n(tXe,"STRONG",{});var ZXt=s(g0e);TDr=r(ZXt,"flaubert"),ZXt.forEach(t),MDr=r(tXe," \u2014 "),kee=n(tXe,"A",{href:!0});var ezt=s(kee);EDr=r(ezt,"TFFlaubertForTokenClassification"),ezt.forEach(t),CDr=r(tXe," (FlauBERT model)"),tXe.forEach(t),wDr=i(he),H3=n(he,"LI",{});var aXe=s(H3);h0e=n(aXe,"STRONG",{});var ozt=s(h0e);ADr=r(ozt,"funnel"),ozt.forEach(t),LDr=r(aXe," \u2014 "),See=n(aXe,"A",{href:!0});var rzt=s(See);yDr=r(rzt,"TFFunnelForTokenClassification"),rzt.forEach(t),xDr=r(aXe," (Funnel Transformer model)"),aXe.forEach(t),$Dr=i(he),J3=n(he,"LI",{});var nXe=s(J3);p0e=n(nXe,"STRONG",{});var tzt=s(p0e);kDr=r(tzt,"layoutlm"),tzt.forEach(t),SDr=r(nXe," \u2014 "),Ree=n(nXe,"A",{href:!0});var azt=s(Ree);RDr=r(azt,"TFLayoutLMForTokenClassification"),azt.forEach(t),PDr=r(nXe," (LayoutLM model)"),nXe.forEach(t),BDr=i(he),Y3=n(he,"LI",{});var sXe=s(Y3);_0e=n(sXe,"STRONG",{});var nzt=s(_0e);IDr=r(nzt,"longformer"),nzt.forEach(t),NDr=r(sXe," \u2014 "),Pee=n(sXe,"A",{href:!0});var szt=s(Pee);qDr=r(szt,"TFLongformerForTokenClassification"),szt.forEach(t),jDr=r(sXe," (Longformer model)"),sXe.forEach(t),DDr=i(he),K3=n(he,"LI",{});var lXe=s(K3);u0e=n(lXe,"STRONG",{});var lzt=s(u0e);GDr=r(lzt,"mobilebert"),lzt.forEach(t),ODr=r(lXe," \u2014 "),Bee=n(lXe,"A",{href:!0});var izt=s(Bee);VDr=r(izt,"TFMobileBertForTokenClassification"),izt.forEach(t),XDr=r(lXe," (MobileBERT model)"),lXe.forEach(t),zDr=i(he),Z3=n(he,"LI",{});var iXe=s(Z3);b0e=n(iXe,"STRONG",{});var dzt=s(b0e);WDr=r(dzt,"mpnet"),dzt.forEach(t),QDr=r(iXe," \u2014 "),Iee=n(iXe,"A",{href:!0});var czt=s(Iee);UDr=r(czt,"TFMPNetForTokenClassification"),czt.forEach(t),HDr=r(iXe," (MPNet model)"),iXe.forEach(t),JDr=i(he),e0=n(he,"LI",{});var dXe=s(e0);v0e=n(dXe,"STRONG",{});var fzt=s(v0e);YDr=r(fzt,"rembert"),fzt.forEach(t),KDr=r(dXe," \u2014 "),Nee=n(dXe,"A",{href:!0});var mzt=s(Nee);ZDr=r(mzt,"TFRemBertForTokenClassification"),mzt.forEach(t),eGr=r(dXe," (RemBERT model)"),dXe.forEach(t),oGr=i(he),o0=n(he,"LI",{});var cXe=s(o0);F0e=n(cXe,"STRONG",{});var gzt=s(F0e);rGr=r(gzt,"roberta"),gzt.forEach(t),tGr=r(cXe," \u2014 "),qee=n(cXe,"A",{href:!0});var hzt=s(qee);aGr=r(hzt,"TFRobertaForTokenClassification"),hzt.forEach(t),nGr=r(cXe," (RoBERTa model)"),cXe.forEach(t),sGr=i(he),r0=n(he,"LI",{});var fXe=s(r0);T0e=n(fXe,"STRONG",{});var pzt=s(T0e);lGr=r(pzt,"roformer"),pzt.forEach(t),iGr=r(fXe," \u2014 "),jee=n(fXe,"A",{href:!0});var _zt=s(jee);dGr=r(_zt,"TFRoFormerForTokenClassification"),_zt.forEach(t),cGr=r(fXe," (RoFormer model)"),fXe.forEach(t),fGr=i(he),t0=n(he,"LI",{});var mXe=s(t0);M0e=n(mXe,"STRONG",{});var uzt=s(M0e);mGr=r(uzt,"xlm"),uzt.forEach(t),gGr=r(mXe," \u2014 "),Dee=n(mXe,"A",{href:!0});var bzt=s(Dee);hGr=r(bzt,"TFXLMForTokenClassification"),bzt.forEach(t),pGr=r(mXe," (XLM model)"),mXe.forEach(t),_Gr=i(he),a0=n(he,"LI",{});var gXe=s(a0);E0e=n(gXe,"STRONG",{});var vzt=s(E0e);uGr=r(vzt,"xlm-roberta"),vzt.forEach(t),bGr=r(gXe," \u2014 "),Gee=n(gXe,"A",{href:!0});var Fzt=s(Gee);vGr=r(Fzt,"TFXLMRobertaForTokenClassification"),Fzt.forEach(t),FGr=r(gXe," (XLM-RoBERTa model)"),gXe.forEach(t),TGr=i(he),n0=n(he,"LI",{});var hXe=s(n0);C0e=n(hXe,"STRONG",{});var Tzt=s(C0e);MGr=r(Tzt,"xlnet"),Tzt.forEach(t),EGr=r(hXe," \u2014 "),Oee=n(hXe,"A",{href:!0});var Mzt=s(Oee);CGr=r(Mzt,"TFXLNetForTokenClassification"),Mzt.forEach(t),wGr=r(hXe," (XLNet model)"),hXe.forEach(t),he.forEach(t),AGr=i(ni),T(s0.$$.fragment,ni),ni.forEach(t),ai.forEach(t),_Ue=i(f),Jc=n(f,"H2",{class:!0});var LJe=s(Jc);l0=n(LJe,"A",{id:!0,class:!0,href:!0});var Ezt=s(l0);w0e=n(Ezt,"SPAN",{});var Czt=s(w0e);T(D$.$$.fragment,Czt),Czt.forEach(t),Ezt.forEach(t),LGr=i(LJe),A0e=n(LJe,"SPAN",{});var wzt=s(A0e);yGr=r(wzt,"TFAutoModelForQuestionAnswering"),wzt.forEach(t),LJe.forEach(t),uUe=i(f),pr=n(f,"DIV",{class:!0});var si=s(pr);T(G$.$$.fragment,si),xGr=i(si),Yc=n(si,"P",{});var Ene=s(Yc);$Gr=r(Ene,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Vee=n(Ene,"A",{href:!0});var Azt=s(Vee);kGr=r(Azt,"from_pretrained()"),Azt.forEach(t),SGr=r(Ene," class method or the "),Xee=n(Ene,"A",{href:!0});var Lzt=s(Xee);RGr=r(Lzt,"from_config()"),Lzt.forEach(t),PGr=r(Ene,` class
method.`),Ene.forEach(t),BGr=i(si),O$=n(si,"P",{});var yJe=s(O$);IGr=r(yJe,"This class cannot be instantiated directly using "),L0e=n(yJe,"CODE",{});var yzt=s(L0e);NGr=r(yzt,"__init__()"),yzt.forEach(t),qGr=r(yJe," (throws an error)."),yJe.forEach(t),jGr=i(si),Qt=n(si,"DIV",{class:!0});var gL=s(Qt);T(V$.$$.fragment,gL),DGr=i(gL),y0e=n(gL,"P",{});var xzt=s(y0e);GGr=r(xzt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),xzt.forEach(t),OGr=i(gL),Kc=n(gL,"P",{});var Cne=s(Kc);VGr=r(Cne,`Note:
Loading a model from its configuration file does `),x0e=n(Cne,"STRONG",{});var $zt=s(x0e);XGr=r($zt,"not"),$zt.forEach(t),zGr=r(Cne,` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=n(Cne,"A",{href:!0});var kzt=s(zee);WGr=r(kzt,"from_pretrained()"),kzt.forEach(t),QGr=r(Cne," to load the model weights."),Cne.forEach(t),UGr=i(gL),T(i0.$$.fragment,gL),gL.forEach(t),HGr=i(si),Vr=n(si,"DIV",{class:!0});var li=s(Vr);T(X$.$$.fragment,li),JGr=i(li),$0e=n(li,"P",{});var Szt=s($0e);YGr=r(Szt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Szt.forEach(t),KGr=i(li),Cn=n(li,"P",{});var hL=s(Cn);ZGr=r(hL,"The model class to instantiate is selected based on the "),k0e=n(hL,"CODE",{});var Rzt=s(k0e);eOr=r(Rzt,"model_type"),Rzt.forEach(t),oOr=r(hL,` property of the config object (either
passed as an argument or loaded from `),S0e=n(hL,"CODE",{});var Pzt=s(S0e);rOr=r(Pzt,"pretrained_model_name_or_path"),Pzt.forEach(t),tOr=r(hL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),R0e=n(hL,"CODE",{});var Bzt=s(R0e);aOr=r(Bzt,"pretrained_model_name_or_path"),Bzt.forEach(t),nOr=r(hL,":"),hL.forEach(t),sOr=i(li),ce=n(li,"UL",{});var pe=s(ce);d0=n(pe,"LI",{});var pXe=s(d0);P0e=n(pXe,"STRONG",{});var Izt=s(P0e);lOr=r(Izt,"albert"),Izt.forEach(t),iOr=r(pXe," \u2014 "),Wee=n(pXe,"A",{href:!0});var Nzt=s(Wee);dOr=r(Nzt,"TFAlbertForQuestionAnswering"),Nzt.forEach(t),cOr=r(pXe," (ALBERT model)"),pXe.forEach(t),fOr=i(pe),c0=n(pe,"LI",{});var _Xe=s(c0);B0e=n(_Xe,"STRONG",{});var qzt=s(B0e);mOr=r(qzt,"bert"),qzt.forEach(t),gOr=r(_Xe," \u2014 "),Qee=n(_Xe,"A",{href:!0});var jzt=s(Qee);hOr=r(jzt,"TFBertForQuestionAnswering"),jzt.forEach(t),pOr=r(_Xe," (BERT model)"),_Xe.forEach(t),_Or=i(pe),f0=n(pe,"LI",{});var uXe=s(f0);I0e=n(uXe,"STRONG",{});var Dzt=s(I0e);uOr=r(Dzt,"camembert"),Dzt.forEach(t),bOr=r(uXe," \u2014 "),Uee=n(uXe,"A",{href:!0});var Gzt=s(Uee);vOr=r(Gzt,"TFCamembertForQuestionAnswering"),Gzt.forEach(t),FOr=r(uXe," (CamemBERT model)"),uXe.forEach(t),TOr=i(pe),m0=n(pe,"LI",{});var bXe=s(m0);N0e=n(bXe,"STRONG",{});var Ozt=s(N0e);MOr=r(Ozt,"convbert"),Ozt.forEach(t),EOr=r(bXe," \u2014 "),Hee=n(bXe,"A",{href:!0});var Vzt=s(Hee);COr=r(Vzt,"TFConvBertForQuestionAnswering"),Vzt.forEach(t),wOr=r(bXe," (ConvBERT model)"),bXe.forEach(t),AOr=i(pe),g0=n(pe,"LI",{});var vXe=s(g0);q0e=n(vXe,"STRONG",{});var Xzt=s(q0e);LOr=r(Xzt,"deberta"),Xzt.forEach(t),yOr=r(vXe," \u2014 "),Jee=n(vXe,"A",{href:!0});var zzt=s(Jee);xOr=r(zzt,"TFDebertaForQuestionAnswering"),zzt.forEach(t),$Or=r(vXe," (DeBERTa model)"),vXe.forEach(t),kOr=i(pe),h0=n(pe,"LI",{});var FXe=s(h0);j0e=n(FXe,"STRONG",{});var Wzt=s(j0e);SOr=r(Wzt,"deberta-v2"),Wzt.forEach(t),ROr=r(FXe," \u2014 "),Yee=n(FXe,"A",{href:!0});var Qzt=s(Yee);POr=r(Qzt,"TFDebertaV2ForQuestionAnswering"),Qzt.forEach(t),BOr=r(FXe," (DeBERTa-v2 model)"),FXe.forEach(t),IOr=i(pe),p0=n(pe,"LI",{});var TXe=s(p0);D0e=n(TXe,"STRONG",{});var Uzt=s(D0e);NOr=r(Uzt,"distilbert"),Uzt.forEach(t),qOr=r(TXe," \u2014 "),Kee=n(TXe,"A",{href:!0});var Hzt=s(Kee);jOr=r(Hzt,"TFDistilBertForQuestionAnswering"),Hzt.forEach(t),DOr=r(TXe," (DistilBERT model)"),TXe.forEach(t),GOr=i(pe),_0=n(pe,"LI",{});var MXe=s(_0);G0e=n(MXe,"STRONG",{});var Jzt=s(G0e);OOr=r(Jzt,"electra"),Jzt.forEach(t),VOr=r(MXe," \u2014 "),Zee=n(MXe,"A",{href:!0});var Yzt=s(Zee);XOr=r(Yzt,"TFElectraForQuestionAnswering"),Yzt.forEach(t),zOr=r(MXe," (ELECTRA model)"),MXe.forEach(t),WOr=i(pe),u0=n(pe,"LI",{});var EXe=s(u0);O0e=n(EXe,"STRONG",{});var Kzt=s(O0e);QOr=r(Kzt,"flaubert"),Kzt.forEach(t),UOr=r(EXe," \u2014 "),eoe=n(EXe,"A",{href:!0});var Zzt=s(eoe);HOr=r(Zzt,"TFFlaubertForQuestionAnsweringSimple"),Zzt.forEach(t),JOr=r(EXe," (FlauBERT model)"),EXe.forEach(t),YOr=i(pe),b0=n(pe,"LI",{});var CXe=s(b0);V0e=n(CXe,"STRONG",{});var eWt=s(V0e);KOr=r(eWt,"funnel"),eWt.forEach(t),ZOr=r(CXe," \u2014 "),ooe=n(CXe,"A",{href:!0});var oWt=s(ooe);eVr=r(oWt,"TFFunnelForQuestionAnswering"),oWt.forEach(t),oVr=r(CXe," (Funnel Transformer model)"),CXe.forEach(t),rVr=i(pe),v0=n(pe,"LI",{});var wXe=s(v0);X0e=n(wXe,"STRONG",{});var rWt=s(X0e);tVr=r(rWt,"gptj"),rWt.forEach(t),aVr=r(wXe," \u2014 "),roe=n(wXe,"A",{href:!0});var tWt=s(roe);nVr=r(tWt,"TFGPTJForQuestionAnswering"),tWt.forEach(t),sVr=r(wXe," (GPT-J model)"),wXe.forEach(t),lVr=i(pe),F0=n(pe,"LI",{});var AXe=s(F0);z0e=n(AXe,"STRONG",{});var aWt=s(z0e);iVr=r(aWt,"longformer"),aWt.forEach(t),dVr=r(AXe," \u2014 "),toe=n(AXe,"A",{href:!0});var nWt=s(toe);cVr=r(nWt,"TFLongformerForQuestionAnswering"),nWt.forEach(t),fVr=r(AXe," (Longformer model)"),AXe.forEach(t),mVr=i(pe),T0=n(pe,"LI",{});var LXe=s(T0);W0e=n(LXe,"STRONG",{});var sWt=s(W0e);gVr=r(sWt,"mobilebert"),sWt.forEach(t),hVr=r(LXe," \u2014 "),aoe=n(LXe,"A",{href:!0});var lWt=s(aoe);pVr=r(lWt,"TFMobileBertForQuestionAnswering"),lWt.forEach(t),_Vr=r(LXe," (MobileBERT model)"),LXe.forEach(t),uVr=i(pe),M0=n(pe,"LI",{});var yXe=s(M0);Q0e=n(yXe,"STRONG",{});var iWt=s(Q0e);bVr=r(iWt,"mpnet"),iWt.forEach(t),vVr=r(yXe," \u2014 "),noe=n(yXe,"A",{href:!0});var dWt=s(noe);FVr=r(dWt,"TFMPNetForQuestionAnswering"),dWt.forEach(t),TVr=r(yXe," (MPNet model)"),yXe.forEach(t),MVr=i(pe),E0=n(pe,"LI",{});var xXe=s(E0);U0e=n(xXe,"STRONG",{});var cWt=s(U0e);EVr=r(cWt,"rembert"),cWt.forEach(t),CVr=r(xXe," \u2014 "),soe=n(xXe,"A",{href:!0});var fWt=s(soe);wVr=r(fWt,"TFRemBertForQuestionAnswering"),fWt.forEach(t),AVr=r(xXe," (RemBERT model)"),xXe.forEach(t),LVr=i(pe),C0=n(pe,"LI",{});var $Xe=s(C0);H0e=n($Xe,"STRONG",{});var mWt=s(H0e);yVr=r(mWt,"roberta"),mWt.forEach(t),xVr=r($Xe," \u2014 "),loe=n($Xe,"A",{href:!0});var gWt=s(loe);$Vr=r(gWt,"TFRobertaForQuestionAnswering"),gWt.forEach(t),kVr=r($Xe," (RoBERTa model)"),$Xe.forEach(t),SVr=i(pe),w0=n(pe,"LI",{});var kXe=s(w0);J0e=n(kXe,"STRONG",{});var hWt=s(J0e);RVr=r(hWt,"roformer"),hWt.forEach(t),PVr=r(kXe," \u2014 "),ioe=n(kXe,"A",{href:!0});var pWt=s(ioe);BVr=r(pWt,"TFRoFormerForQuestionAnswering"),pWt.forEach(t),IVr=r(kXe," (RoFormer model)"),kXe.forEach(t),NVr=i(pe),A0=n(pe,"LI",{});var SXe=s(A0);Y0e=n(SXe,"STRONG",{});var _Wt=s(Y0e);qVr=r(_Wt,"xlm"),_Wt.forEach(t),jVr=r(SXe," \u2014 "),doe=n(SXe,"A",{href:!0});var uWt=s(doe);DVr=r(uWt,"TFXLMForQuestionAnsweringSimple"),uWt.forEach(t),GVr=r(SXe," (XLM model)"),SXe.forEach(t),OVr=i(pe),L0=n(pe,"LI",{});var RXe=s(L0);K0e=n(RXe,"STRONG",{});var bWt=s(K0e);VVr=r(bWt,"xlm-roberta"),bWt.forEach(t),XVr=r(RXe," \u2014 "),coe=n(RXe,"A",{href:!0});var vWt=s(coe);zVr=r(vWt,"TFXLMRobertaForQuestionAnswering"),vWt.forEach(t),WVr=r(RXe," (XLM-RoBERTa model)"),RXe.forEach(t),QVr=i(pe),y0=n(pe,"LI",{});var PXe=s(y0);Z0e=n(PXe,"STRONG",{});var FWt=s(Z0e);UVr=r(FWt,"xlnet"),FWt.forEach(t),HVr=r(PXe," \u2014 "),foe=n(PXe,"A",{href:!0});var TWt=s(foe);JVr=r(TWt,"TFXLNetForQuestionAnsweringSimple"),TWt.forEach(t),YVr=r(PXe," (XLNet model)"),PXe.forEach(t),pe.forEach(t),KVr=i(li),T(x0.$$.fragment,li),li.forEach(t),si.forEach(t),bUe=i(f),Zc=n(f,"H2",{class:!0});var xJe=s(Zc);$0=n(xJe,"A",{id:!0,class:!0,href:!0});var MWt=s($0);ewe=n(MWt,"SPAN",{});var EWt=s(ewe);T(z$.$$.fragment,EWt),EWt.forEach(t),MWt.forEach(t),ZVr=i(xJe),owe=n(xJe,"SPAN",{});var CWt=s(owe);eXr=r(CWt,"TFAutoModelForVision2Seq"),CWt.forEach(t),xJe.forEach(t),vUe=i(f),_r=n(f,"DIV",{class:!0});var ii=s(_r);T(W$.$$.fragment,ii),oXr=i(ii),ef=n(ii,"P",{});var wne=s(ef);rXr=r(wne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),moe=n(wne,"A",{href:!0});var wWt=s(moe);tXr=r(wWt,"from_pretrained()"),wWt.forEach(t),aXr=r(wne," class method or the "),goe=n(wne,"A",{href:!0});var AWt=s(goe);nXr=r(AWt,"from_config()"),AWt.forEach(t),sXr=r(wne,` class
method.`),wne.forEach(t),lXr=i(ii),Q$=n(ii,"P",{});var $Je=s(Q$);iXr=r($Je,"This class cannot be instantiated directly using "),rwe=n($Je,"CODE",{});var LWt=s(rwe);dXr=r(LWt,"__init__()"),LWt.forEach(t),cXr=r($Je," (throws an error)."),$Je.forEach(t),fXr=i(ii),Ut=n(ii,"DIV",{class:!0});var pL=s(Ut);T(U$.$$.fragment,pL),mXr=i(pL),twe=n(pL,"P",{});var yWt=s(twe);gXr=r(yWt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yWt.forEach(t),hXr=i(pL),of=n(pL,"P",{});var Ane=s(of);pXr=r(Ane,`Note:
Loading a model from its configuration file does `),awe=n(Ane,"STRONG",{});var xWt=s(awe);_Xr=r(xWt,"not"),xWt.forEach(t),uXr=r(Ane,` load the model weights. It only affects the
model\u2019s configuration. Use `),hoe=n(Ane,"A",{href:!0});var $Wt=s(hoe);bXr=r($Wt,"from_pretrained()"),$Wt.forEach(t),vXr=r(Ane," to load the model weights."),Ane.forEach(t),FXr=i(pL),T(k0.$$.fragment,pL),pL.forEach(t),TXr=i(ii),Xr=n(ii,"DIV",{class:!0});var di=s(Xr);T(H$.$$.fragment,di),MXr=i(di),nwe=n(di,"P",{});var kWt=s(nwe);EXr=r(kWt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),kWt.forEach(t),CXr=i(di),wn=n(di,"P",{});var _L=s(wn);wXr=r(_L,"The model class to instantiate is selected based on the "),swe=n(_L,"CODE",{});var SWt=s(swe);AXr=r(SWt,"model_type"),SWt.forEach(t),LXr=r(_L,` property of the config object (either
passed as an argument or loaded from `),lwe=n(_L,"CODE",{});var RWt=s(lwe);yXr=r(RWt,"pretrained_model_name_or_path"),RWt.forEach(t),xXr=r(_L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),iwe=n(_L,"CODE",{});var PWt=s(iwe);$Xr=r(PWt,"pretrained_model_name_or_path"),PWt.forEach(t),kXr=r(_L,":"),_L.forEach(t),SXr=i(di),dwe=n(di,"UL",{});var BWt=s(dwe);S0=n(BWt,"LI",{});var BXe=s(S0);cwe=n(BXe,"STRONG",{});var IWt=s(cwe);RXr=r(IWt,"vision-encoder-decoder"),IWt.forEach(t),PXr=r(BXe," \u2014 "),poe=n(BXe,"A",{href:!0});var NWt=s(poe);BXr=r(NWt,"TFVisionEncoderDecoderModel"),NWt.forEach(t),IXr=r(BXe," (Vision Encoder decoder model)"),BXe.forEach(t),BWt.forEach(t),NXr=i(di),T(R0.$$.fragment,di),di.forEach(t),ii.forEach(t),FUe=i(f),rf=n(f,"H2",{class:!0});var kJe=s(rf);P0=n(kJe,"A",{id:!0,class:!0,href:!0});var qWt=s(P0);fwe=n(qWt,"SPAN",{});var jWt=s(fwe);T(J$.$$.fragment,jWt),jWt.forEach(t),qWt.forEach(t),qXr=i(kJe),mwe=n(kJe,"SPAN",{});var DWt=s(mwe);jXr=r(DWt,"TFAutoModelForSpeechSeq2Seq"),DWt.forEach(t),kJe.forEach(t),TUe=i(f),ur=n(f,"DIV",{class:!0});var ci=s(ur);T(Y$.$$.fragment,ci),DXr=i(ci),tf=n(ci,"P",{});var Lne=s(tf);GXr=r(Lne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),_oe=n(Lne,"A",{href:!0});var GWt=s(_oe);OXr=r(GWt,"from_pretrained()"),GWt.forEach(t),VXr=r(Lne," class method or the "),uoe=n(Lne,"A",{href:!0});var OWt=s(uoe);XXr=r(OWt,"from_config()"),OWt.forEach(t),zXr=r(Lne,` class
method.`),Lne.forEach(t),WXr=i(ci),K$=n(ci,"P",{});var SJe=s(K$);QXr=r(SJe,"This class cannot be instantiated directly using "),gwe=n(SJe,"CODE",{});var VWt=s(gwe);UXr=r(VWt,"__init__()"),VWt.forEach(t),HXr=r(SJe," (throws an error)."),SJe.forEach(t),JXr=i(ci),Ht=n(ci,"DIV",{class:!0});var uL=s(Ht);T(Z$.$$.fragment,uL),YXr=i(uL),hwe=n(uL,"P",{});var XWt=s(hwe);KXr=r(XWt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),XWt.forEach(t),ZXr=i(uL),af=n(uL,"P",{});var yne=s(af);ezr=r(yne,`Note:
Loading a model from its configuration file does `),pwe=n(yne,"STRONG",{});var zWt=s(pwe);ozr=r(zWt,"not"),zWt.forEach(t),rzr=r(yne,` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=n(yne,"A",{href:!0});var WWt=s(boe);tzr=r(WWt,"from_pretrained()"),WWt.forEach(t),azr=r(yne," to load the model weights."),yne.forEach(t),nzr=i(uL),T(B0.$$.fragment,uL),uL.forEach(t),szr=i(ci),zr=n(ci,"DIV",{class:!0});var fi=s(zr);T(ek.$$.fragment,fi),lzr=i(fi),_we=n(fi,"P",{});var QWt=s(_we);izr=r(QWt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),QWt.forEach(t),dzr=i(fi),An=n(fi,"P",{});var bL=s(An);czr=r(bL,"The model class to instantiate is selected based on the "),uwe=n(bL,"CODE",{});var UWt=s(uwe);fzr=r(UWt,"model_type"),UWt.forEach(t),mzr=r(bL,` property of the config object (either
passed as an argument or loaded from `),bwe=n(bL,"CODE",{});var HWt=s(bwe);gzr=r(HWt,"pretrained_model_name_or_path"),HWt.forEach(t),hzr=r(bL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vwe=n(bL,"CODE",{});var JWt=s(vwe);pzr=r(JWt,"pretrained_model_name_or_path"),JWt.forEach(t),_zr=r(bL,":"),bL.forEach(t),uzr=i(fi),Fwe=n(fi,"UL",{});var YWt=s(Fwe);I0=n(YWt,"LI",{});var IXe=s(I0);Twe=n(IXe,"STRONG",{});var KWt=s(Twe);bzr=r(KWt,"speech_to_text"),KWt.forEach(t),vzr=r(IXe," \u2014 "),voe=n(IXe,"A",{href:!0});var ZWt=s(voe);Fzr=r(ZWt,"TFSpeech2TextForConditionalGeneration"),ZWt.forEach(t),Tzr=r(IXe," (Speech2Text model)"),IXe.forEach(t),YWt.forEach(t),Mzr=i(fi),T(N0.$$.fragment,fi),fi.forEach(t),ci.forEach(t),MUe=i(f),nf=n(f,"H2",{class:!0});var RJe=s(nf);q0=n(RJe,"A",{id:!0,class:!0,href:!0});var eQt=s(q0);Mwe=n(eQt,"SPAN",{});var oQt=s(Mwe);T(ok.$$.fragment,oQt),oQt.forEach(t),eQt.forEach(t),Ezr=i(RJe),Ewe=n(RJe,"SPAN",{});var rQt=s(Ewe);Czr=r(rQt,"FlaxAutoModel"),rQt.forEach(t),RJe.forEach(t),EUe=i(f),br=n(f,"DIV",{class:!0});var mi=s(br);T(rk.$$.fragment,mi),wzr=i(mi),sf=n(mi,"P",{});var xne=s(sf);Azr=r(xne,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Foe=n(xne,"A",{href:!0});var tQt=s(Foe);Lzr=r(tQt,"from_pretrained()"),tQt.forEach(t),yzr=r(xne," class method or the "),Toe=n(xne,"A",{href:!0});var aQt=s(Toe);xzr=r(aQt,"from_config()"),aQt.forEach(t),$zr=r(xne,` class
method.`),xne.forEach(t),kzr=i(mi),tk=n(mi,"P",{});var PJe=s(tk);Szr=r(PJe,"This class cannot be instantiated directly using "),Cwe=n(PJe,"CODE",{});var nQt=s(Cwe);Rzr=r(nQt,"__init__()"),nQt.forEach(t),Pzr=r(PJe," (throws an error)."),PJe.forEach(t),Bzr=i(mi),Jt=n(mi,"DIV",{class:!0});var vL=s(Jt);T(ak.$$.fragment,vL),Izr=i(vL),wwe=n(vL,"P",{});var sQt=s(wwe);Nzr=r(sQt,"Instantiates one of the base model classes of the library from a configuration."),sQt.forEach(t),qzr=i(vL),lf=n(vL,"P",{});var $ne=s(lf);jzr=r($ne,`Note:
Loading a model from its configuration file does `),Awe=n($ne,"STRONG",{});var lQt=s(Awe);Dzr=r(lQt,"not"),lQt.forEach(t),Gzr=r($ne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Moe=n($ne,"A",{href:!0});var iQt=s(Moe);Ozr=r(iQt,"from_pretrained()"),iQt.forEach(t),Vzr=r($ne," to load the model weights."),$ne.forEach(t),Xzr=i(vL),T(j0.$$.fragment,vL),vL.forEach(t),zzr=i(mi),Wr=n(mi,"DIV",{class:!0});var gi=s(Wr);T(nk.$$.fragment,gi),Wzr=i(gi),Lwe=n(gi,"P",{});var dQt=s(Lwe);Qzr=r(dQt,"Instantiate one of the base model classes of the library from a pretrained model."),dQt.forEach(t),Uzr=i(gi),Ln=n(gi,"P",{});var FL=s(Ln);Hzr=r(FL,"The model class to instantiate is selected based on the "),ywe=n(FL,"CODE",{});var cQt=s(ywe);Jzr=r(cQt,"model_type"),cQt.forEach(t),Yzr=r(FL,` property of the config object (either
passed as an argument or loaded from `),xwe=n(FL,"CODE",{});var fQt=s(xwe);Kzr=r(fQt,"pretrained_model_name_or_path"),fQt.forEach(t),Zzr=r(FL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$we=n(FL,"CODE",{});var mQt=s($we);eWr=r(mQt,"pretrained_model_name_or_path"),mQt.forEach(t),oWr=r(FL,":"),FL.forEach(t),rWr=i(gi),oe=n(gi,"UL",{});var ae=s(oe);D0=n(ae,"LI",{});var NXe=s(D0);kwe=n(NXe,"STRONG",{});var gQt=s(kwe);tWr=r(gQt,"albert"),gQt.forEach(t),aWr=r(NXe," \u2014 "),Eoe=n(NXe,"A",{href:!0});var hQt=s(Eoe);nWr=r(hQt,"FlaxAlbertModel"),hQt.forEach(t),sWr=r(NXe," (ALBERT model)"),NXe.forEach(t),lWr=i(ae),G0=n(ae,"LI",{});var qXe=s(G0);Swe=n(qXe,"STRONG",{});var pQt=s(Swe);iWr=r(pQt,"bart"),pQt.forEach(t),dWr=r(qXe," \u2014 "),Coe=n(qXe,"A",{href:!0});var _Qt=s(Coe);cWr=r(_Qt,"FlaxBartModel"),_Qt.forEach(t),fWr=r(qXe," (BART model)"),qXe.forEach(t),mWr=i(ae),O0=n(ae,"LI",{});var jXe=s(O0);Rwe=n(jXe,"STRONG",{});var uQt=s(Rwe);gWr=r(uQt,"beit"),uQt.forEach(t),hWr=r(jXe," \u2014 "),woe=n(jXe,"A",{href:!0});var bQt=s(woe);pWr=r(bQt,"FlaxBeitModel"),bQt.forEach(t),_Wr=r(jXe," (BEiT model)"),jXe.forEach(t),uWr=i(ae),V0=n(ae,"LI",{});var DXe=s(V0);Pwe=n(DXe,"STRONG",{});var vQt=s(Pwe);bWr=r(vQt,"bert"),vQt.forEach(t),vWr=r(DXe," \u2014 "),Aoe=n(DXe,"A",{href:!0});var FQt=s(Aoe);FWr=r(FQt,"FlaxBertModel"),FQt.forEach(t),TWr=r(DXe," (BERT model)"),DXe.forEach(t),MWr=i(ae),X0=n(ae,"LI",{});var GXe=s(X0);Bwe=n(GXe,"STRONG",{});var TQt=s(Bwe);EWr=r(TQt,"big_bird"),TQt.forEach(t),CWr=r(GXe," \u2014 "),Loe=n(GXe,"A",{href:!0});var MQt=s(Loe);wWr=r(MQt,"FlaxBigBirdModel"),MQt.forEach(t),AWr=r(GXe," (BigBird model)"),GXe.forEach(t),LWr=i(ae),z0=n(ae,"LI",{});var OXe=s(z0);Iwe=n(OXe,"STRONG",{});var EQt=s(Iwe);yWr=r(EQt,"blenderbot"),EQt.forEach(t),xWr=r(OXe," \u2014 "),yoe=n(OXe,"A",{href:!0});var CQt=s(yoe);$Wr=r(CQt,"FlaxBlenderbotModel"),CQt.forEach(t),kWr=r(OXe," (Blenderbot model)"),OXe.forEach(t),SWr=i(ae),W0=n(ae,"LI",{});var VXe=s(W0);Nwe=n(VXe,"STRONG",{});var wQt=s(Nwe);RWr=r(wQt,"blenderbot-small"),wQt.forEach(t),PWr=r(VXe," \u2014 "),xoe=n(VXe,"A",{href:!0});var AQt=s(xoe);BWr=r(AQt,"FlaxBlenderbotSmallModel"),AQt.forEach(t),IWr=r(VXe," (BlenderbotSmall model)"),VXe.forEach(t),NWr=i(ae),Q0=n(ae,"LI",{});var XXe=s(Q0);qwe=n(XXe,"STRONG",{});var LQt=s(qwe);qWr=r(LQt,"clip"),LQt.forEach(t),jWr=r(XXe," \u2014 "),$oe=n(XXe,"A",{href:!0});var yQt=s($oe);DWr=r(yQt,"FlaxCLIPModel"),yQt.forEach(t),GWr=r(XXe," (CLIP model)"),XXe.forEach(t),OWr=i(ae),U0=n(ae,"LI",{});var zXe=s(U0);jwe=n(zXe,"STRONG",{});var xQt=s(jwe);VWr=r(xQt,"distilbert"),xQt.forEach(t),XWr=r(zXe," \u2014 "),koe=n(zXe,"A",{href:!0});var $Qt=s(koe);zWr=r($Qt,"FlaxDistilBertModel"),$Qt.forEach(t),WWr=r(zXe," (DistilBERT model)"),zXe.forEach(t),QWr=i(ae),H0=n(ae,"LI",{});var WXe=s(H0);Dwe=n(WXe,"STRONG",{});var kQt=s(Dwe);UWr=r(kQt,"electra"),kQt.forEach(t),HWr=r(WXe," \u2014 "),Soe=n(WXe,"A",{href:!0});var SQt=s(Soe);JWr=r(SQt,"FlaxElectraModel"),SQt.forEach(t),YWr=r(WXe," (ELECTRA model)"),WXe.forEach(t),KWr=i(ae),J0=n(ae,"LI",{});var QXe=s(J0);Gwe=n(QXe,"STRONG",{});var RQt=s(Gwe);ZWr=r(RQt,"gpt2"),RQt.forEach(t),eQr=r(QXe," \u2014 "),Roe=n(QXe,"A",{href:!0});var PQt=s(Roe);oQr=r(PQt,"FlaxGPT2Model"),PQt.forEach(t),rQr=r(QXe," (OpenAI GPT-2 model)"),QXe.forEach(t),tQr=i(ae),Y0=n(ae,"LI",{});var UXe=s(Y0);Owe=n(UXe,"STRONG",{});var BQt=s(Owe);aQr=r(BQt,"gpt_neo"),BQt.forEach(t),nQr=r(UXe," \u2014 "),Poe=n(UXe,"A",{href:!0});var IQt=s(Poe);sQr=r(IQt,"FlaxGPTNeoModel"),IQt.forEach(t),lQr=r(UXe," (GPT Neo model)"),UXe.forEach(t),iQr=i(ae),K0=n(ae,"LI",{});var HXe=s(K0);Vwe=n(HXe,"STRONG",{});var NQt=s(Vwe);dQr=r(NQt,"gptj"),NQt.forEach(t),cQr=r(HXe," \u2014 "),Boe=n(HXe,"A",{href:!0});var qQt=s(Boe);fQr=r(qQt,"FlaxGPTJModel"),qQt.forEach(t),mQr=r(HXe," (GPT-J model)"),HXe.forEach(t),gQr=i(ae),Z0=n(ae,"LI",{});var JXe=s(Z0);Xwe=n(JXe,"STRONG",{});var jQt=s(Xwe);hQr=r(jQt,"longt5"),jQt.forEach(t),pQr=r(JXe," \u2014 "),Ioe=n(JXe,"A",{href:!0});var DQt=s(Ioe);_Qr=r(DQt,"FlaxLongT5Model"),DQt.forEach(t),uQr=r(JXe," (LongT5 model)"),JXe.forEach(t),bQr=i(ae),ew=n(ae,"LI",{});var YXe=s(ew);zwe=n(YXe,"STRONG",{});var GQt=s(zwe);vQr=r(GQt,"marian"),GQt.forEach(t),FQr=r(YXe," \u2014 "),Noe=n(YXe,"A",{href:!0});var OQt=s(Noe);TQr=r(OQt,"FlaxMarianModel"),OQt.forEach(t),MQr=r(YXe," (Marian model)"),YXe.forEach(t),EQr=i(ae),ow=n(ae,"LI",{});var KXe=s(ow);Wwe=n(KXe,"STRONG",{});var VQt=s(Wwe);CQr=r(VQt,"mbart"),VQt.forEach(t),wQr=r(KXe," \u2014 "),qoe=n(KXe,"A",{href:!0});var XQt=s(qoe);AQr=r(XQt,"FlaxMBartModel"),XQt.forEach(t),LQr=r(KXe," (mBART model)"),KXe.forEach(t),yQr=i(ae),rw=n(ae,"LI",{});var ZXe=s(rw);Qwe=n(ZXe,"STRONG",{});var zQt=s(Qwe);xQr=r(zQt,"mt5"),zQt.forEach(t),$Qr=r(ZXe," \u2014 "),joe=n(ZXe,"A",{href:!0});var WQt=s(joe);kQr=r(WQt,"FlaxMT5Model"),WQt.forEach(t),SQr=r(ZXe," (MT5 model)"),ZXe.forEach(t),RQr=i(ae),tw=n(ae,"LI",{});var eze=s(tw);Uwe=n(eze,"STRONG",{});var QQt=s(Uwe);PQr=r(QQt,"opt"),QQt.forEach(t),BQr=r(eze," \u2014 "),Doe=n(eze,"A",{href:!0});var UQt=s(Doe);IQr=r(UQt,"FlaxOPTModel"),UQt.forEach(t),NQr=r(eze," (OPT model)"),eze.forEach(t),qQr=i(ae),aw=n(ae,"LI",{});var oze=s(aw);Hwe=n(oze,"STRONG",{});var HQt=s(Hwe);jQr=r(HQt,"pegasus"),HQt.forEach(t),DQr=r(oze," \u2014 "),Goe=n(oze,"A",{href:!0});var JQt=s(Goe);GQr=r(JQt,"FlaxPegasusModel"),JQt.forEach(t),OQr=r(oze," (Pegasus model)"),oze.forEach(t),VQr=i(ae),nw=n(ae,"LI",{});var rze=s(nw);Jwe=n(rze,"STRONG",{});var YQt=s(Jwe);XQr=r(YQt,"roberta"),YQt.forEach(t),zQr=r(rze," \u2014 "),Ooe=n(rze,"A",{href:!0});var KQt=s(Ooe);WQr=r(KQt,"FlaxRobertaModel"),KQt.forEach(t),QQr=r(rze," (RoBERTa model)"),rze.forEach(t),UQr=i(ae),sw=n(ae,"LI",{});var tze=s(sw);Ywe=n(tze,"STRONG",{});var ZQt=s(Ywe);HQr=r(ZQt,"roformer"),ZQt.forEach(t),JQr=r(tze," \u2014 "),Voe=n(tze,"A",{href:!0});var eUt=s(Voe);YQr=r(eUt,"FlaxRoFormerModel"),eUt.forEach(t),KQr=r(tze," (RoFormer model)"),tze.forEach(t),ZQr=i(ae),lw=n(ae,"LI",{});var aze=s(lw);Kwe=n(aze,"STRONG",{});var oUt=s(Kwe);eUr=r(oUt,"t5"),oUt.forEach(t),oUr=r(aze," \u2014 "),Xoe=n(aze,"A",{href:!0});var rUt=s(Xoe);rUr=r(rUt,"FlaxT5Model"),rUt.forEach(t),tUr=r(aze," (T5 model)"),aze.forEach(t),aUr=i(ae),iw=n(ae,"LI",{});var nze=s(iw);Zwe=n(nze,"STRONG",{});var tUt=s(Zwe);nUr=r(tUt,"vision-text-dual-encoder"),tUt.forEach(t),sUr=r(nze," \u2014 "),zoe=n(nze,"A",{href:!0});var aUt=s(zoe);lUr=r(aUt,"FlaxVisionTextDualEncoderModel"),aUt.forEach(t),iUr=r(nze," (VisionTextDualEncoder model)"),nze.forEach(t),dUr=i(ae),dw=n(ae,"LI",{});var sze=s(dw);e6e=n(sze,"STRONG",{});var nUt=s(e6e);cUr=r(nUt,"vit"),nUt.forEach(t),fUr=r(sze," \u2014 "),Woe=n(sze,"A",{href:!0});var sUt=s(Woe);mUr=r(sUt,"FlaxViTModel"),sUt.forEach(t),gUr=r(sze," (ViT model)"),sze.forEach(t),hUr=i(ae),cw=n(ae,"LI",{});var lze=s(cw);o6e=n(lze,"STRONG",{});var lUt=s(o6e);pUr=r(lUt,"wav2vec2"),lUt.forEach(t),_Ur=r(lze," \u2014 "),Qoe=n(lze,"A",{href:!0});var iUt=s(Qoe);uUr=r(iUt,"FlaxWav2Vec2Model"),iUt.forEach(t),bUr=r(lze," (Wav2Vec2 model)"),lze.forEach(t),vUr=i(ae),fw=n(ae,"LI",{});var ize=s(fw);r6e=n(ize,"STRONG",{});var dUt=s(r6e);FUr=r(dUt,"xglm"),dUt.forEach(t),TUr=r(ize," \u2014 "),Uoe=n(ize,"A",{href:!0});var cUt=s(Uoe);MUr=r(cUt,"FlaxXGLMModel"),cUt.forEach(t),EUr=r(ize," (XGLM model)"),ize.forEach(t),CUr=i(ae),mw=n(ae,"LI",{});var dze=s(mw);t6e=n(dze,"STRONG",{});var fUt=s(t6e);wUr=r(fUt,"xlm-roberta"),fUt.forEach(t),AUr=r(dze," \u2014 "),Hoe=n(dze,"A",{href:!0});var mUt=s(Hoe);LUr=r(mUt,"FlaxXLMRobertaModel"),mUt.forEach(t),yUr=r(dze," (XLM-RoBERTa model)"),dze.forEach(t),ae.forEach(t),xUr=i(gi),T(gw.$$.fragment,gi),gi.forEach(t),mi.forEach(t),CUe=i(f),df=n(f,"H2",{class:!0});var BJe=s(df);hw=n(BJe,"A",{id:!0,class:!0,href:!0});var gUt=s(hw);a6e=n(gUt,"SPAN",{});var hUt=s(a6e);T(sk.$$.fragment,hUt),hUt.forEach(t),gUt.forEach(t),$Ur=i(BJe),n6e=n(BJe,"SPAN",{});var pUt=s(n6e);kUr=r(pUt,"FlaxAutoModelForCausalLM"),pUt.forEach(t),BJe.forEach(t),wUe=i(f),vr=n(f,"DIV",{class:!0});var hi=s(vr);T(lk.$$.fragment,hi),SUr=i(hi),cf=n(hi,"P",{});var kne=s(cf);RUr=r(kne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Joe=n(kne,"A",{href:!0});var _Ut=s(Joe);PUr=r(_Ut,"from_pretrained()"),_Ut.forEach(t),BUr=r(kne," class method or the "),Yoe=n(kne,"A",{href:!0});var uUt=s(Yoe);IUr=r(uUt,"from_config()"),uUt.forEach(t),NUr=r(kne,` class
method.`),kne.forEach(t),qUr=i(hi),ik=n(hi,"P",{});var IJe=s(ik);jUr=r(IJe,"This class cannot be instantiated directly using "),s6e=n(IJe,"CODE",{});var bUt=s(s6e);DUr=r(bUt,"__init__()"),bUt.forEach(t),GUr=r(IJe," (throws an error)."),IJe.forEach(t),OUr=i(hi),Yt=n(hi,"DIV",{class:!0});var TL=s(Yt);T(dk.$$.fragment,TL),VUr=i(TL),l6e=n(TL,"P",{});var vUt=s(l6e);XUr=r(vUt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),vUt.forEach(t),zUr=i(TL),ff=n(TL,"P",{});var Sne=s(ff);WUr=r(Sne,`Note:
Loading a model from its configuration file does `),i6e=n(Sne,"STRONG",{});var FUt=s(i6e);QUr=r(FUt,"not"),FUt.forEach(t),UUr=r(Sne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Koe=n(Sne,"A",{href:!0});var TUt=s(Koe);HUr=r(TUt,"from_pretrained()"),TUt.forEach(t),JUr=r(Sne," to load the model weights."),Sne.forEach(t),YUr=i(TL),T(pw.$$.fragment,TL),TL.forEach(t),KUr=i(hi),Qr=n(hi,"DIV",{class:!0});var pi=s(Qr);T(ck.$$.fragment,pi),ZUr=i(pi),d6e=n(pi,"P",{});var MUt=s(d6e);eHr=r(MUt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),MUt.forEach(t),oHr=i(pi),yn=n(pi,"P",{});var ML=s(yn);rHr=r(ML,"The model class to instantiate is selected based on the "),c6e=n(ML,"CODE",{});var EUt=s(c6e);tHr=r(EUt,"model_type"),EUt.forEach(t),aHr=r(ML,` property of the config object (either
passed as an argument or loaded from `),f6e=n(ML,"CODE",{});var CUt=s(f6e);nHr=r(CUt,"pretrained_model_name_or_path"),CUt.forEach(t),sHr=r(ML,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m6e=n(ML,"CODE",{});var wUt=s(m6e);lHr=r(wUt,"pretrained_model_name_or_path"),wUt.forEach(t),iHr=r(ML,":"),ML.forEach(t),dHr=i(pi),xe=n(pi,"UL",{});var Ne=s(xe);_w=n(Ne,"LI",{});var cze=s(_w);g6e=n(cze,"STRONG",{});var AUt=s(g6e);cHr=r(AUt,"bart"),AUt.forEach(t),fHr=r(cze," \u2014 "),Zoe=n(cze,"A",{href:!0});var LUt=s(Zoe);mHr=r(LUt,"FlaxBartForCausalLM"),LUt.forEach(t),gHr=r(cze," (BART model)"),cze.forEach(t),hHr=i(Ne),uw=n(Ne,"LI",{});var fze=s(uw);h6e=n(fze,"STRONG",{});var yUt=s(h6e);pHr=r(yUt,"bert"),yUt.forEach(t),_Hr=r(fze," \u2014 "),ere=n(fze,"A",{href:!0});var xUt=s(ere);uHr=r(xUt,"FlaxBertForCausalLM"),xUt.forEach(t),bHr=r(fze," (BERT model)"),fze.forEach(t),vHr=i(Ne),bw=n(Ne,"LI",{});var mze=s(bw);p6e=n(mze,"STRONG",{});var $Ut=s(p6e);FHr=r($Ut,"big_bird"),$Ut.forEach(t),THr=r(mze," \u2014 "),ore=n(mze,"A",{href:!0});var kUt=s(ore);MHr=r(kUt,"FlaxBigBirdForCausalLM"),kUt.forEach(t),EHr=r(mze," (BigBird model)"),mze.forEach(t),CHr=i(Ne),vw=n(Ne,"LI",{});var gze=s(vw);_6e=n(gze,"STRONG",{});var SUt=s(_6e);wHr=r(SUt,"electra"),SUt.forEach(t),AHr=r(gze," \u2014 "),rre=n(gze,"A",{href:!0});var RUt=s(rre);LHr=r(RUt,"FlaxElectraForCausalLM"),RUt.forEach(t),yHr=r(gze," (ELECTRA model)"),gze.forEach(t),xHr=i(Ne),Fw=n(Ne,"LI",{});var hze=s(Fw);u6e=n(hze,"STRONG",{});var PUt=s(u6e);$Hr=r(PUt,"gpt2"),PUt.forEach(t),kHr=r(hze," \u2014 "),tre=n(hze,"A",{href:!0});var BUt=s(tre);SHr=r(BUt,"FlaxGPT2LMHeadModel"),BUt.forEach(t),RHr=r(hze," (OpenAI GPT-2 model)"),hze.forEach(t),PHr=i(Ne),Tw=n(Ne,"LI",{});var pze=s(Tw);b6e=n(pze,"STRONG",{});var IUt=s(b6e);BHr=r(IUt,"gpt_neo"),IUt.forEach(t),IHr=r(pze," \u2014 "),are=n(pze,"A",{href:!0});var NUt=s(are);NHr=r(NUt,"FlaxGPTNeoForCausalLM"),NUt.forEach(t),qHr=r(pze," (GPT Neo model)"),pze.forEach(t),jHr=i(Ne),Mw=n(Ne,"LI",{});var _ze=s(Mw);v6e=n(_ze,"STRONG",{});var qUt=s(v6e);DHr=r(qUt,"gptj"),qUt.forEach(t),GHr=r(_ze," \u2014 "),nre=n(_ze,"A",{href:!0});var jUt=s(nre);OHr=r(jUt,"FlaxGPTJForCausalLM"),jUt.forEach(t),VHr=r(_ze," (GPT-J model)"),_ze.forEach(t),XHr=i(Ne),Ew=n(Ne,"LI",{});var uze=s(Ew);F6e=n(uze,"STRONG",{});var DUt=s(F6e);zHr=r(DUt,"opt"),DUt.forEach(t),WHr=r(uze," \u2014 "),sre=n(uze,"A",{href:!0});var GUt=s(sre);QHr=r(GUt,"FlaxOPTForCausalLM"),GUt.forEach(t),UHr=r(uze," (OPT model)"),uze.forEach(t),HHr=i(Ne),Cw=n(Ne,"LI",{});var bze=s(Cw);T6e=n(bze,"STRONG",{});var OUt=s(T6e);JHr=r(OUt,"roberta"),OUt.forEach(t),YHr=r(bze," \u2014 "),lre=n(bze,"A",{href:!0});var VUt=s(lre);KHr=r(VUt,"FlaxRobertaForCausalLM"),VUt.forEach(t),ZHr=r(bze," (RoBERTa model)"),bze.forEach(t),eJr=i(Ne),ww=n(Ne,"LI",{});var vze=s(ww);M6e=n(vze,"STRONG",{});var XUt=s(M6e);oJr=r(XUt,"xglm"),XUt.forEach(t),rJr=r(vze," \u2014 "),ire=n(vze,"A",{href:!0});var zUt=s(ire);tJr=r(zUt,"FlaxXGLMForCausalLM"),zUt.forEach(t),aJr=r(vze," (XGLM model)"),vze.forEach(t),Ne.forEach(t),nJr=i(pi),T(Aw.$$.fragment,pi),pi.forEach(t),hi.forEach(t),AUe=i(f),mf=n(f,"H2",{class:!0});var NJe=s(mf);Lw=n(NJe,"A",{id:!0,class:!0,href:!0});var WUt=s(Lw);E6e=n(WUt,"SPAN",{});var QUt=s(E6e);T(fk.$$.fragment,QUt),QUt.forEach(t),WUt.forEach(t),sJr=i(NJe),C6e=n(NJe,"SPAN",{});var UUt=s(C6e);lJr=r(UUt,"FlaxAutoModelForPreTraining"),UUt.forEach(t),NJe.forEach(t),LUe=i(f),Fr=n(f,"DIV",{class:!0});var _i=s(Fr);T(mk.$$.fragment,_i),iJr=i(_i),gf=n(_i,"P",{});var Rne=s(gf);dJr=r(Rne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),dre=n(Rne,"A",{href:!0});var HUt=s(dre);cJr=r(HUt,"from_pretrained()"),HUt.forEach(t),fJr=r(Rne," class method or the "),cre=n(Rne,"A",{href:!0});var JUt=s(cre);mJr=r(JUt,"from_config()"),JUt.forEach(t),gJr=r(Rne,` class
method.`),Rne.forEach(t),hJr=i(_i),gk=n(_i,"P",{});var qJe=s(gk);pJr=r(qJe,"This class cannot be instantiated directly using "),w6e=n(qJe,"CODE",{});var YUt=s(w6e);_Jr=r(YUt,"__init__()"),YUt.forEach(t),uJr=r(qJe," (throws an error)."),qJe.forEach(t),bJr=i(_i),Kt=n(_i,"DIV",{class:!0});var EL=s(Kt);T(hk.$$.fragment,EL),vJr=i(EL),A6e=n(EL,"P",{});var KUt=s(A6e);FJr=r(KUt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),KUt.forEach(t),TJr=i(EL),hf=n(EL,"P",{});var Pne=s(hf);MJr=r(Pne,`Note:
Loading a model from its configuration file does `),L6e=n(Pne,"STRONG",{});var ZUt=s(L6e);EJr=r(ZUt,"not"),ZUt.forEach(t),CJr=r(Pne,` load the model weights. It only affects the
model\u2019s configuration. Use `),fre=n(Pne,"A",{href:!0});var eHt=s(fre);wJr=r(eHt,"from_pretrained()"),eHt.forEach(t),AJr=r(Pne," to load the model weights."),Pne.forEach(t),LJr=i(EL),T(yw.$$.fragment,EL),EL.forEach(t),yJr=i(_i),Ur=n(_i,"DIV",{class:!0});var ui=s(Ur);T(pk.$$.fragment,ui),xJr=i(ui),y6e=n(ui,"P",{});var oHt=s(y6e);$Jr=r(oHt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),oHt.forEach(t),kJr=i(ui),xn=n(ui,"P",{});var CL=s(xn);SJr=r(CL,"The model class to instantiate is selected based on the "),x6e=n(CL,"CODE",{});var rHt=s(x6e);RJr=r(rHt,"model_type"),rHt.forEach(t),PJr=r(CL,` property of the config object (either
passed as an argument or loaded from `),$6e=n(CL,"CODE",{});var tHt=s($6e);BJr=r(tHt,"pretrained_model_name_or_path"),tHt.forEach(t),IJr=r(CL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),k6e=n(CL,"CODE",{});var aHt=s(k6e);NJr=r(aHt,"pretrained_model_name_or_path"),aHt.forEach(t),qJr=r(CL,":"),CL.forEach(t),jJr=i(ui),Ee=n(ui,"UL",{});var we=s(Ee);xw=n(we,"LI",{});var Fze=s(xw);S6e=n(Fze,"STRONG",{});var nHt=s(S6e);DJr=r(nHt,"albert"),nHt.forEach(t),GJr=r(Fze," \u2014 "),mre=n(Fze,"A",{href:!0});var sHt=s(mre);OJr=r(sHt,"FlaxAlbertForPreTraining"),sHt.forEach(t),VJr=r(Fze," (ALBERT model)"),Fze.forEach(t),XJr=i(we),$w=n(we,"LI",{});var Tze=s($w);R6e=n(Tze,"STRONG",{});var lHt=s(R6e);zJr=r(lHt,"bart"),lHt.forEach(t),WJr=r(Tze," \u2014 "),gre=n(Tze,"A",{href:!0});var iHt=s(gre);QJr=r(iHt,"FlaxBartForConditionalGeneration"),iHt.forEach(t),UJr=r(Tze," (BART model)"),Tze.forEach(t),HJr=i(we),kw=n(we,"LI",{});var Mze=s(kw);P6e=n(Mze,"STRONG",{});var dHt=s(P6e);JJr=r(dHt,"bert"),dHt.forEach(t),YJr=r(Mze," \u2014 "),hre=n(Mze,"A",{href:!0});var cHt=s(hre);KJr=r(cHt,"FlaxBertForPreTraining"),cHt.forEach(t),ZJr=r(Mze," (BERT model)"),Mze.forEach(t),eYr=i(we),Sw=n(we,"LI",{});var Eze=s(Sw);B6e=n(Eze,"STRONG",{});var fHt=s(B6e);oYr=r(fHt,"big_bird"),fHt.forEach(t),rYr=r(Eze," \u2014 "),pre=n(Eze,"A",{href:!0});var mHt=s(pre);tYr=r(mHt,"FlaxBigBirdForPreTraining"),mHt.forEach(t),aYr=r(Eze," (BigBird model)"),Eze.forEach(t),nYr=i(we),Rw=n(we,"LI",{});var Cze=s(Rw);I6e=n(Cze,"STRONG",{});var gHt=s(I6e);sYr=r(gHt,"electra"),gHt.forEach(t),lYr=r(Cze," \u2014 "),_re=n(Cze,"A",{href:!0});var hHt=s(_re);iYr=r(hHt,"FlaxElectraForPreTraining"),hHt.forEach(t),dYr=r(Cze," (ELECTRA model)"),Cze.forEach(t),cYr=i(we),Pw=n(we,"LI",{});var wze=s(Pw);N6e=n(wze,"STRONG",{});var pHt=s(N6e);fYr=r(pHt,"longt5"),pHt.forEach(t),mYr=r(wze," \u2014 "),ure=n(wze,"A",{href:!0});var _Ht=s(ure);gYr=r(_Ht,"FlaxLongT5ForConditionalGeneration"),_Ht.forEach(t),hYr=r(wze," (LongT5 model)"),wze.forEach(t),pYr=i(we),Bw=n(we,"LI",{});var Aze=s(Bw);q6e=n(Aze,"STRONG",{});var uHt=s(q6e);_Yr=r(uHt,"mbart"),uHt.forEach(t),uYr=r(Aze," \u2014 "),bre=n(Aze,"A",{href:!0});var bHt=s(bre);bYr=r(bHt,"FlaxMBartForConditionalGeneration"),bHt.forEach(t),vYr=r(Aze," (mBART model)"),Aze.forEach(t),FYr=i(we),Iw=n(we,"LI",{});var Lze=s(Iw);j6e=n(Lze,"STRONG",{});var vHt=s(j6e);TYr=r(vHt,"mt5"),vHt.forEach(t),MYr=r(Lze," \u2014 "),vre=n(Lze,"A",{href:!0});var FHt=s(vre);EYr=r(FHt,"FlaxMT5ForConditionalGeneration"),FHt.forEach(t),CYr=r(Lze," (MT5 model)"),Lze.forEach(t),wYr=i(we),Nw=n(we,"LI",{});var yze=s(Nw);D6e=n(yze,"STRONG",{});var THt=s(D6e);AYr=r(THt,"roberta"),THt.forEach(t),LYr=r(yze," \u2014 "),Fre=n(yze,"A",{href:!0});var MHt=s(Fre);yYr=r(MHt,"FlaxRobertaForMaskedLM"),MHt.forEach(t),xYr=r(yze," (RoBERTa model)"),yze.forEach(t),$Yr=i(we),qw=n(we,"LI",{});var xze=s(qw);G6e=n(xze,"STRONG",{});var EHt=s(G6e);kYr=r(EHt,"roformer"),EHt.forEach(t),SYr=r(xze," \u2014 "),Tre=n(xze,"A",{href:!0});var CHt=s(Tre);RYr=r(CHt,"FlaxRoFormerForMaskedLM"),CHt.forEach(t),PYr=r(xze," (RoFormer model)"),xze.forEach(t),BYr=i(we),jw=n(we,"LI",{});var $ze=s(jw);O6e=n($ze,"STRONG",{});var wHt=s(O6e);IYr=r(wHt,"t5"),wHt.forEach(t),NYr=r($ze," \u2014 "),Mre=n($ze,"A",{href:!0});var AHt=s(Mre);qYr=r(AHt,"FlaxT5ForConditionalGeneration"),AHt.forEach(t),jYr=r($ze," (T5 model)"),$ze.forEach(t),DYr=i(we),Dw=n(we,"LI",{});var kze=s(Dw);V6e=n(kze,"STRONG",{});var LHt=s(V6e);GYr=r(LHt,"wav2vec2"),LHt.forEach(t),OYr=r(kze," \u2014 "),Ere=n(kze,"A",{href:!0});var yHt=s(Ere);VYr=r(yHt,"FlaxWav2Vec2ForPreTraining"),yHt.forEach(t),XYr=r(kze," (Wav2Vec2 model)"),kze.forEach(t),zYr=i(we),Gw=n(we,"LI",{});var Sze=s(Gw);X6e=n(Sze,"STRONG",{});var xHt=s(X6e);WYr=r(xHt,"xlm-roberta"),xHt.forEach(t),QYr=r(Sze," \u2014 "),Cre=n(Sze,"A",{href:!0});var $Ht=s(Cre);UYr=r($Ht,"FlaxXLMRobertaForMaskedLM"),$Ht.forEach(t),HYr=r(Sze," (XLM-RoBERTa model)"),Sze.forEach(t),we.forEach(t),JYr=i(ui),T(Ow.$$.fragment,ui),ui.forEach(t),_i.forEach(t),yUe=i(f),pf=n(f,"H2",{class:!0});var jJe=s(pf);Vw=n(jJe,"A",{id:!0,class:!0,href:!0});var kHt=s(Vw);z6e=n(kHt,"SPAN",{});var SHt=s(z6e);T(_k.$$.fragment,SHt),SHt.forEach(t),kHt.forEach(t),YYr=i(jJe),W6e=n(jJe,"SPAN",{});var RHt=s(W6e);KYr=r(RHt,"FlaxAutoModelForMaskedLM"),RHt.forEach(t),jJe.forEach(t),xUe=i(f),Tr=n(f,"DIV",{class:!0});var bi=s(Tr);T(uk.$$.fragment,bi),ZYr=i(bi),_f=n(bi,"P",{});var Bne=s(_f);eKr=r(Bne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),wre=n(Bne,"A",{href:!0});var PHt=s(wre);oKr=r(PHt,"from_pretrained()"),PHt.forEach(t),rKr=r(Bne," class method or the "),Are=n(Bne,"A",{href:!0});var BHt=s(Are);tKr=r(BHt,"from_config()"),BHt.forEach(t),aKr=r(Bne,` class
method.`),Bne.forEach(t),nKr=i(bi),bk=n(bi,"P",{});var DJe=s(bk);sKr=r(DJe,"This class cannot be instantiated directly using "),Q6e=n(DJe,"CODE",{});var IHt=s(Q6e);lKr=r(IHt,"__init__()"),IHt.forEach(t),iKr=r(DJe," (throws an error)."),DJe.forEach(t),dKr=i(bi),Zt=n(bi,"DIV",{class:!0});var wL=s(Zt);T(vk.$$.fragment,wL),cKr=i(wL),U6e=n(wL,"P",{});var NHt=s(U6e);fKr=r(NHt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),NHt.forEach(t),mKr=i(wL),uf=n(wL,"P",{});var Ine=s(uf);gKr=r(Ine,`Note:
Loading a model from its configuration file does `),H6e=n(Ine,"STRONG",{});var qHt=s(H6e);hKr=r(qHt,"not"),qHt.forEach(t),pKr=r(Ine,` load the model weights. It only affects the
model\u2019s configuration. Use `),Lre=n(Ine,"A",{href:!0});var jHt=s(Lre);_Kr=r(jHt,"from_pretrained()"),jHt.forEach(t),uKr=r(Ine," to load the model weights."),Ine.forEach(t),bKr=i(wL),T(Xw.$$.fragment,wL),wL.forEach(t),vKr=i(bi),Hr=n(bi,"DIV",{class:!0});var vi=s(Hr);T(Fk.$$.fragment,vi),FKr=i(vi),J6e=n(vi,"P",{});var DHt=s(J6e);TKr=r(DHt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),DHt.forEach(t),MKr=i(vi),$n=n(vi,"P",{});var AL=s($n);EKr=r(AL,"The model class to instantiate is selected based on the "),Y6e=n(AL,"CODE",{});var GHt=s(Y6e);CKr=r(GHt,"model_type"),GHt.forEach(t),wKr=r(AL,` property of the config object (either
passed as an argument or loaded from `),K6e=n(AL,"CODE",{});var OHt=s(K6e);AKr=r(OHt,"pretrained_model_name_or_path"),OHt.forEach(t),LKr=r(AL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z6e=n(AL,"CODE",{});var VHt=s(Z6e);yKr=r(VHt,"pretrained_model_name_or_path"),VHt.forEach(t),xKr=r(AL,":"),AL.forEach(t),$Kr=i(vi),$e=n(vi,"UL",{});var qe=s($e);zw=n(qe,"LI",{});var Rze=s(zw);eAe=n(Rze,"STRONG",{});var XHt=s(eAe);kKr=r(XHt,"albert"),XHt.forEach(t),SKr=r(Rze," \u2014 "),yre=n(Rze,"A",{href:!0});var zHt=s(yre);RKr=r(zHt,"FlaxAlbertForMaskedLM"),zHt.forEach(t),PKr=r(Rze," (ALBERT model)"),Rze.forEach(t),BKr=i(qe),Ww=n(qe,"LI",{});var Pze=s(Ww);oAe=n(Pze,"STRONG",{});var WHt=s(oAe);IKr=r(WHt,"bart"),WHt.forEach(t),NKr=r(Pze," \u2014 "),xre=n(Pze,"A",{href:!0});var QHt=s(xre);qKr=r(QHt,"FlaxBartForConditionalGeneration"),QHt.forEach(t),jKr=r(Pze," (BART model)"),Pze.forEach(t),DKr=i(qe),Qw=n(qe,"LI",{});var Bze=s(Qw);rAe=n(Bze,"STRONG",{});var UHt=s(rAe);GKr=r(UHt,"bert"),UHt.forEach(t),OKr=r(Bze," \u2014 "),$re=n(Bze,"A",{href:!0});var HHt=s($re);VKr=r(HHt,"FlaxBertForMaskedLM"),HHt.forEach(t),XKr=r(Bze," (BERT model)"),Bze.forEach(t),zKr=i(qe),Uw=n(qe,"LI",{});var Ize=s(Uw);tAe=n(Ize,"STRONG",{});var JHt=s(tAe);WKr=r(JHt,"big_bird"),JHt.forEach(t),QKr=r(Ize," \u2014 "),kre=n(Ize,"A",{href:!0});var YHt=s(kre);UKr=r(YHt,"FlaxBigBirdForMaskedLM"),YHt.forEach(t),HKr=r(Ize," (BigBird model)"),Ize.forEach(t),JKr=i(qe),Hw=n(qe,"LI",{});var Nze=s(Hw);aAe=n(Nze,"STRONG",{});var KHt=s(aAe);YKr=r(KHt,"distilbert"),KHt.forEach(t),KKr=r(Nze," \u2014 "),Sre=n(Nze,"A",{href:!0});var ZHt=s(Sre);ZKr=r(ZHt,"FlaxDistilBertForMaskedLM"),ZHt.forEach(t),eZr=r(Nze," (DistilBERT model)"),Nze.forEach(t),oZr=i(qe),Jw=n(qe,"LI",{});var qze=s(Jw);nAe=n(qze,"STRONG",{});var eJt=s(nAe);rZr=r(eJt,"electra"),eJt.forEach(t),tZr=r(qze," \u2014 "),Rre=n(qze,"A",{href:!0});var oJt=s(Rre);aZr=r(oJt,"FlaxElectraForMaskedLM"),oJt.forEach(t),nZr=r(qze," (ELECTRA model)"),qze.forEach(t),sZr=i(qe),Yw=n(qe,"LI",{});var jze=s(Yw);sAe=n(jze,"STRONG",{});var rJt=s(sAe);lZr=r(rJt,"mbart"),rJt.forEach(t),iZr=r(jze," \u2014 "),Pre=n(jze,"A",{href:!0});var tJt=s(Pre);dZr=r(tJt,"FlaxMBartForConditionalGeneration"),tJt.forEach(t),cZr=r(jze," (mBART model)"),jze.forEach(t),fZr=i(qe),Kw=n(qe,"LI",{});var Dze=s(Kw);lAe=n(Dze,"STRONG",{});var aJt=s(lAe);mZr=r(aJt,"roberta"),aJt.forEach(t),gZr=r(Dze," \u2014 "),Bre=n(Dze,"A",{href:!0});var nJt=s(Bre);hZr=r(nJt,"FlaxRobertaForMaskedLM"),nJt.forEach(t),pZr=r(Dze," (RoBERTa model)"),Dze.forEach(t),_Zr=i(qe),Zw=n(qe,"LI",{});var Gze=s(Zw);iAe=n(Gze,"STRONG",{});var sJt=s(iAe);uZr=r(sJt,"roformer"),sJt.forEach(t),bZr=r(Gze," \u2014 "),Ire=n(Gze,"A",{href:!0});var lJt=s(Ire);vZr=r(lJt,"FlaxRoFormerForMaskedLM"),lJt.forEach(t),FZr=r(Gze," (RoFormer model)"),Gze.forEach(t),TZr=i(qe),e6=n(qe,"LI",{});var Oze=s(e6);dAe=n(Oze,"STRONG",{});var iJt=s(dAe);MZr=r(iJt,"xlm-roberta"),iJt.forEach(t),EZr=r(Oze," \u2014 "),Nre=n(Oze,"A",{href:!0});var dJt=s(Nre);CZr=r(dJt,"FlaxXLMRobertaForMaskedLM"),dJt.forEach(t),wZr=r(Oze," (XLM-RoBERTa model)"),Oze.forEach(t),qe.forEach(t),AZr=i(vi),T(o6.$$.fragment,vi),vi.forEach(t),bi.forEach(t),$Ue=i(f),bf=n(f,"H2",{class:!0});var GJe=s(bf);r6=n(GJe,"A",{id:!0,class:!0,href:!0});var cJt=s(r6);cAe=n(cJt,"SPAN",{});var fJt=s(cAe);T(Tk.$$.fragment,fJt),fJt.forEach(t),cJt.forEach(t),LZr=i(GJe),fAe=n(GJe,"SPAN",{});var mJt=s(fAe);yZr=r(mJt,"FlaxAutoModelForSeq2SeqLM"),mJt.forEach(t),GJe.forEach(t),kUe=i(f),Mr=n(f,"DIV",{class:!0});var Fi=s(Mr);T(Mk.$$.fragment,Fi),xZr=i(Fi),vf=n(Fi,"P",{});var Nne=s(vf);$Zr=r(Nne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qre=n(Nne,"A",{href:!0});var gJt=s(qre);kZr=r(gJt,"from_pretrained()"),gJt.forEach(t),SZr=r(Nne," class method or the "),jre=n(Nne,"A",{href:!0});var hJt=s(jre);RZr=r(hJt,"from_config()"),hJt.forEach(t),PZr=r(Nne,` class
method.`),Nne.forEach(t),BZr=i(Fi),Ek=n(Fi,"P",{});var OJe=s(Ek);IZr=r(OJe,"This class cannot be instantiated directly using "),mAe=n(OJe,"CODE",{});var pJt=s(mAe);NZr=r(pJt,"__init__()"),pJt.forEach(t),qZr=r(OJe," (throws an error)."),OJe.forEach(t),jZr=i(Fi),ea=n(Fi,"DIV",{class:!0});var LL=s(ea);T(Ck.$$.fragment,LL),DZr=i(LL),gAe=n(LL,"P",{});var _Jt=s(gAe);GZr=r(_Jt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_Jt.forEach(t),OZr=i(LL),Ff=n(LL,"P",{});var qne=s(Ff);VZr=r(qne,`Note:
Loading a model from its configuration file does `),hAe=n(qne,"STRONG",{});var uJt=s(hAe);XZr=r(uJt,"not"),uJt.forEach(t),zZr=r(qne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Dre=n(qne,"A",{href:!0});var bJt=s(Dre);WZr=r(bJt,"from_pretrained()"),bJt.forEach(t),QZr=r(qne," to load the model weights."),qne.forEach(t),UZr=i(LL),T(t6.$$.fragment,LL),LL.forEach(t),HZr=i(Fi),Jr=n(Fi,"DIV",{class:!0});var Ti=s(Jr);T(wk.$$.fragment,Ti),JZr=i(Ti),pAe=n(Ti,"P",{});var vJt=s(pAe);YZr=r(vJt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),vJt.forEach(t),KZr=i(Ti),kn=n(Ti,"P",{});var yL=s(kn);ZZr=r(yL,"The model class to instantiate is selected based on the "),_Ae=n(yL,"CODE",{});var FJt=s(_Ae);eet=r(FJt,"model_type"),FJt.forEach(t),oet=r(yL,` property of the config object (either
passed as an argument or loaded from `),uAe=n(yL,"CODE",{});var TJt=s(uAe);ret=r(TJt,"pretrained_model_name_or_path"),TJt.forEach(t),tet=r(yL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bAe=n(yL,"CODE",{});var MJt=s(bAe);aet=r(MJt,"pretrained_model_name_or_path"),MJt.forEach(t),net=r(yL,":"),yL.forEach(t),set=i(Ti),ke=n(Ti,"UL",{});var je=s(ke);a6=n(je,"LI",{});var Vze=s(a6);vAe=n(Vze,"STRONG",{});var EJt=s(vAe);iet=r(EJt,"bart"),EJt.forEach(t),det=r(Vze," \u2014 "),Gre=n(Vze,"A",{href:!0});var CJt=s(Gre);cet=r(CJt,"FlaxBartForConditionalGeneration"),CJt.forEach(t),fet=r(Vze," (BART model)"),Vze.forEach(t),met=i(je),n6=n(je,"LI",{});var Xze=s(n6);FAe=n(Xze,"STRONG",{});var wJt=s(FAe);get=r(wJt,"blenderbot"),wJt.forEach(t),het=r(Xze," \u2014 "),Ore=n(Xze,"A",{href:!0});var AJt=s(Ore);pet=r(AJt,"FlaxBlenderbotForConditionalGeneration"),AJt.forEach(t),_et=r(Xze," (Blenderbot model)"),Xze.forEach(t),uet=i(je),s6=n(je,"LI",{});var zze=s(s6);TAe=n(zze,"STRONG",{});var LJt=s(TAe);bet=r(LJt,"blenderbot-small"),LJt.forEach(t),vet=r(zze," \u2014 "),Vre=n(zze,"A",{href:!0});var yJt=s(Vre);Fet=r(yJt,"FlaxBlenderbotSmallForConditionalGeneration"),yJt.forEach(t),Tet=r(zze," (BlenderbotSmall model)"),zze.forEach(t),Met=i(je),l6=n(je,"LI",{});var Wze=s(l6);MAe=n(Wze,"STRONG",{});var xJt=s(MAe);Eet=r(xJt,"encoder-decoder"),xJt.forEach(t),Cet=r(Wze," \u2014 "),Xre=n(Wze,"A",{href:!0});var $Jt=s(Xre);wet=r($Jt,"FlaxEncoderDecoderModel"),$Jt.forEach(t),Aet=r(Wze," (Encoder decoder model)"),Wze.forEach(t),Let=i(je),i6=n(je,"LI",{});var Qze=s(i6);EAe=n(Qze,"STRONG",{});var kJt=s(EAe);yet=r(kJt,"longt5"),kJt.forEach(t),xet=r(Qze," \u2014 "),zre=n(Qze,"A",{href:!0});var SJt=s(zre);$et=r(SJt,"FlaxLongT5ForConditionalGeneration"),SJt.forEach(t),ket=r(Qze," (LongT5 model)"),Qze.forEach(t),Set=i(je),d6=n(je,"LI",{});var Uze=s(d6);CAe=n(Uze,"STRONG",{});var RJt=s(CAe);Ret=r(RJt,"marian"),RJt.forEach(t),Pet=r(Uze," \u2014 "),Wre=n(Uze,"A",{href:!0});var PJt=s(Wre);Bet=r(PJt,"FlaxMarianMTModel"),PJt.forEach(t),Iet=r(Uze," (Marian model)"),Uze.forEach(t),Net=i(je),c6=n(je,"LI",{});var Hze=s(c6);wAe=n(Hze,"STRONG",{});var BJt=s(wAe);qet=r(BJt,"mbart"),BJt.forEach(t),jet=r(Hze," \u2014 "),Qre=n(Hze,"A",{href:!0});var IJt=s(Qre);Det=r(IJt,"FlaxMBartForConditionalGeneration"),IJt.forEach(t),Get=r(Hze," (mBART model)"),Hze.forEach(t),Oet=i(je),f6=n(je,"LI",{});var Jze=s(f6);AAe=n(Jze,"STRONG",{});var NJt=s(AAe);Vet=r(NJt,"mt5"),NJt.forEach(t),Xet=r(Jze," \u2014 "),Ure=n(Jze,"A",{href:!0});var qJt=s(Ure);zet=r(qJt,"FlaxMT5ForConditionalGeneration"),qJt.forEach(t),Wet=r(Jze," (MT5 model)"),Jze.forEach(t),Qet=i(je),m6=n(je,"LI",{});var Yze=s(m6);LAe=n(Yze,"STRONG",{});var jJt=s(LAe);Uet=r(jJt,"pegasus"),jJt.forEach(t),Het=r(Yze," \u2014 "),Hre=n(Yze,"A",{href:!0});var DJt=s(Hre);Jet=r(DJt,"FlaxPegasusForConditionalGeneration"),DJt.forEach(t),Yet=r(Yze," (Pegasus model)"),Yze.forEach(t),Ket=i(je),g6=n(je,"LI",{});var Kze=s(g6);yAe=n(Kze,"STRONG",{});var GJt=s(yAe);Zet=r(GJt,"t5"),GJt.forEach(t),eot=r(Kze," \u2014 "),Jre=n(Kze,"A",{href:!0});var OJt=s(Jre);oot=r(OJt,"FlaxT5ForConditionalGeneration"),OJt.forEach(t),rot=r(Kze," (T5 model)"),Kze.forEach(t),je.forEach(t),tot=i(Ti),T(h6.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),SUe=i(f),Tf=n(f,"H2",{class:!0});var VJe=s(Tf);p6=n(VJe,"A",{id:!0,class:!0,href:!0});var VJt=s(p6);xAe=n(VJt,"SPAN",{});var XJt=s(xAe);T(Ak.$$.fragment,XJt),XJt.forEach(t),VJt.forEach(t),aot=i(VJe),$Ae=n(VJe,"SPAN",{});var zJt=s($Ae);not=r(zJt,"FlaxAutoModelForSequenceClassification"),zJt.forEach(t),VJe.forEach(t),RUe=i(f),Er=n(f,"DIV",{class:!0});var Mi=s(Er);T(Lk.$$.fragment,Mi),sot=i(Mi),Mf=n(Mi,"P",{});var jne=s(Mf);lot=r(jne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Yre=n(jne,"A",{href:!0});var WJt=s(Yre);iot=r(WJt,"from_pretrained()"),WJt.forEach(t),dot=r(jne," class method or the "),Kre=n(jne,"A",{href:!0});var QJt=s(Kre);cot=r(QJt,"from_config()"),QJt.forEach(t),fot=r(jne,` class
method.`),jne.forEach(t),mot=i(Mi),yk=n(Mi,"P",{});var XJe=s(yk);got=r(XJe,"This class cannot be instantiated directly using "),kAe=n(XJe,"CODE",{});var UJt=s(kAe);hot=r(UJt,"__init__()"),UJt.forEach(t),pot=r(XJe," (throws an error)."),XJe.forEach(t),_ot=i(Mi),oa=n(Mi,"DIV",{class:!0});var xL=s(oa);T(xk.$$.fragment,xL),uot=i(xL),SAe=n(xL,"P",{});var HJt=s(SAe);bot=r(HJt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),HJt.forEach(t),vot=i(xL),Ef=n(xL,"P",{});var Dne=s(Ef);Fot=r(Dne,`Note:
Loading a model from its configuration file does `),RAe=n(Dne,"STRONG",{});var JJt=s(RAe);Tot=r(JJt,"not"),JJt.forEach(t),Mot=r(Dne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zre=n(Dne,"A",{href:!0});var YJt=s(Zre);Eot=r(YJt,"from_pretrained()"),YJt.forEach(t),Cot=r(Dne," to load the model weights."),Dne.forEach(t),wot=i(xL),T(_6.$$.fragment,xL),xL.forEach(t),Aot=i(Mi),Yr=n(Mi,"DIV",{class:!0});var Ei=s(Yr);T($k.$$.fragment,Ei),Lot=i(Ei),PAe=n(Ei,"P",{});var KJt=s(PAe);yot=r(KJt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),KJt.forEach(t),xot=i(Ei),Sn=n(Ei,"P",{});var $L=s(Sn);$ot=r($L,"The model class to instantiate is selected based on the "),BAe=n($L,"CODE",{});var ZJt=s(BAe);kot=r(ZJt,"model_type"),ZJt.forEach(t),Sot=r($L,` property of the config object (either
passed as an argument or loaded from `),IAe=n($L,"CODE",{});var eYt=s(IAe);Rot=r(eYt,"pretrained_model_name_or_path"),eYt.forEach(t),Pot=r($L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NAe=n($L,"CODE",{});var oYt=s(NAe);Bot=r(oYt,"pretrained_model_name_or_path"),oYt.forEach(t),Iot=r($L,":"),$L.forEach(t),Not=i(Ei),Se=n(Ei,"UL",{});var De=s(Se);u6=n(De,"LI",{});var Zze=s(u6);qAe=n(Zze,"STRONG",{});var rYt=s(qAe);qot=r(rYt,"albert"),rYt.forEach(t),jot=r(Zze," \u2014 "),ete=n(Zze,"A",{href:!0});var tYt=s(ete);Dot=r(tYt,"FlaxAlbertForSequenceClassification"),tYt.forEach(t),Got=r(Zze," (ALBERT model)"),Zze.forEach(t),Oot=i(De),b6=n(De,"LI",{});var eWe=s(b6);jAe=n(eWe,"STRONG",{});var aYt=s(jAe);Vot=r(aYt,"bart"),aYt.forEach(t),Xot=r(eWe," \u2014 "),ote=n(eWe,"A",{href:!0});var nYt=s(ote);zot=r(nYt,"FlaxBartForSequenceClassification"),nYt.forEach(t),Wot=r(eWe," (BART model)"),eWe.forEach(t),Qot=i(De),v6=n(De,"LI",{});var oWe=s(v6);DAe=n(oWe,"STRONG",{});var sYt=s(DAe);Uot=r(sYt,"bert"),sYt.forEach(t),Hot=r(oWe," \u2014 "),rte=n(oWe,"A",{href:!0});var lYt=s(rte);Jot=r(lYt,"FlaxBertForSequenceClassification"),lYt.forEach(t),Yot=r(oWe," (BERT model)"),oWe.forEach(t),Kot=i(De),F6=n(De,"LI",{});var rWe=s(F6);GAe=n(rWe,"STRONG",{});var iYt=s(GAe);Zot=r(iYt,"big_bird"),iYt.forEach(t),ert=r(rWe," \u2014 "),tte=n(rWe,"A",{href:!0});var dYt=s(tte);ort=r(dYt,"FlaxBigBirdForSequenceClassification"),dYt.forEach(t),rrt=r(rWe," (BigBird model)"),rWe.forEach(t),trt=i(De),T6=n(De,"LI",{});var tWe=s(T6);OAe=n(tWe,"STRONG",{});var cYt=s(OAe);art=r(cYt,"distilbert"),cYt.forEach(t),nrt=r(tWe," \u2014 "),ate=n(tWe,"A",{href:!0});var fYt=s(ate);srt=r(fYt,"FlaxDistilBertForSequenceClassification"),fYt.forEach(t),lrt=r(tWe," (DistilBERT model)"),tWe.forEach(t),irt=i(De),M6=n(De,"LI",{});var aWe=s(M6);VAe=n(aWe,"STRONG",{});var mYt=s(VAe);drt=r(mYt,"electra"),mYt.forEach(t),crt=r(aWe," \u2014 "),nte=n(aWe,"A",{href:!0});var gYt=s(nte);frt=r(gYt,"FlaxElectraForSequenceClassification"),gYt.forEach(t),mrt=r(aWe," (ELECTRA model)"),aWe.forEach(t),grt=i(De),E6=n(De,"LI",{});var nWe=s(E6);XAe=n(nWe,"STRONG",{});var hYt=s(XAe);hrt=r(hYt,"mbart"),hYt.forEach(t),prt=r(nWe," \u2014 "),ste=n(nWe,"A",{href:!0});var pYt=s(ste);_rt=r(pYt,"FlaxMBartForSequenceClassification"),pYt.forEach(t),urt=r(nWe," (mBART model)"),nWe.forEach(t),brt=i(De),C6=n(De,"LI",{});var sWe=s(C6);zAe=n(sWe,"STRONG",{});var _Yt=s(zAe);vrt=r(_Yt,"roberta"),_Yt.forEach(t),Frt=r(sWe," \u2014 "),lte=n(sWe,"A",{href:!0});var uYt=s(lte);Trt=r(uYt,"FlaxRobertaForSequenceClassification"),uYt.forEach(t),Mrt=r(sWe," (RoBERTa model)"),sWe.forEach(t),Ert=i(De),w6=n(De,"LI",{});var lWe=s(w6);WAe=n(lWe,"STRONG",{});var bYt=s(WAe);Crt=r(bYt,"roformer"),bYt.forEach(t),wrt=r(lWe," \u2014 "),ite=n(lWe,"A",{href:!0});var vYt=s(ite);Art=r(vYt,"FlaxRoFormerForSequenceClassification"),vYt.forEach(t),Lrt=r(lWe," (RoFormer model)"),lWe.forEach(t),yrt=i(De),A6=n(De,"LI",{});var iWe=s(A6);QAe=n(iWe,"STRONG",{});var FYt=s(QAe);xrt=r(FYt,"xlm-roberta"),FYt.forEach(t),$rt=r(iWe," \u2014 "),dte=n(iWe,"A",{href:!0});var TYt=s(dte);krt=r(TYt,"FlaxXLMRobertaForSequenceClassification"),TYt.forEach(t),Srt=r(iWe," (XLM-RoBERTa model)"),iWe.forEach(t),De.forEach(t),Rrt=i(Ei),T(L6.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),PUe=i(f),Cf=n(f,"H2",{class:!0});var zJe=s(Cf);y6=n(zJe,"A",{id:!0,class:!0,href:!0});var MYt=s(y6);UAe=n(MYt,"SPAN",{});var EYt=s(UAe);T(kk.$$.fragment,EYt),EYt.forEach(t),MYt.forEach(t),Prt=i(zJe),HAe=n(zJe,"SPAN",{});var CYt=s(HAe);Brt=r(CYt,"FlaxAutoModelForQuestionAnswering"),CYt.forEach(t),zJe.forEach(t),BUe=i(f),Cr=n(f,"DIV",{class:!0});var Ci=s(Cr);T(Sk.$$.fragment,Ci),Irt=i(Ci),wf=n(Ci,"P",{});var Gne=s(wf);Nrt=r(Gne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),cte=n(Gne,"A",{href:!0});var wYt=s(cte);qrt=r(wYt,"from_pretrained()"),wYt.forEach(t),jrt=r(Gne," class method or the "),fte=n(Gne,"A",{href:!0});var AYt=s(fte);Drt=r(AYt,"from_config()"),AYt.forEach(t),Grt=r(Gne,` class
method.`),Gne.forEach(t),Ort=i(Ci),Rk=n(Ci,"P",{});var WJe=s(Rk);Vrt=r(WJe,"This class cannot be instantiated directly using "),JAe=n(WJe,"CODE",{});var LYt=s(JAe);Xrt=r(LYt,"__init__()"),LYt.forEach(t),zrt=r(WJe," (throws an error)."),WJe.forEach(t),Wrt=i(Ci),ra=n(Ci,"DIV",{class:!0});var kL=s(ra);T(Pk.$$.fragment,kL),Qrt=i(kL),YAe=n(kL,"P",{});var yYt=s(YAe);Urt=r(yYt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),yYt.forEach(t),Hrt=i(kL),Af=n(kL,"P",{});var One=s(Af);Jrt=r(One,`Note:
Loading a model from its configuration file does `),KAe=n(One,"STRONG",{});var xYt=s(KAe);Yrt=r(xYt,"not"),xYt.forEach(t),Krt=r(One,` load the model weights. It only affects the
model\u2019s configuration. Use `),mte=n(One,"A",{href:!0});var $Yt=s(mte);Zrt=r($Yt,"from_pretrained()"),$Yt.forEach(t),ett=r(One," to load the model weights."),One.forEach(t),ott=i(kL),T(x6.$$.fragment,kL),kL.forEach(t),rtt=i(Ci),Kr=n(Ci,"DIV",{class:!0});var wi=s(Kr);T(Bk.$$.fragment,wi),ttt=i(wi),ZAe=n(wi,"P",{});var kYt=s(ZAe);att=r(kYt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),kYt.forEach(t),ntt=i(wi),Rn=n(wi,"P",{});var SL=s(Rn);stt=r(SL,"The model class to instantiate is selected based on the "),e7e=n(SL,"CODE",{});var SYt=s(e7e);ltt=r(SYt,"model_type"),SYt.forEach(t),itt=r(SL,` property of the config object (either
passed as an argument or loaded from `),o7e=n(SL,"CODE",{});var RYt=s(o7e);dtt=r(RYt,"pretrained_model_name_or_path"),RYt.forEach(t),ctt=r(SL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),r7e=n(SL,"CODE",{});var PYt=s(r7e);ftt=r(PYt,"pretrained_model_name_or_path"),PYt.forEach(t),mtt=r(SL,":"),SL.forEach(t),gtt=i(wi),Re=n(wi,"UL",{});var Ge=s(Re);$6=n(Ge,"LI",{});var dWe=s($6);t7e=n(dWe,"STRONG",{});var BYt=s(t7e);htt=r(BYt,"albert"),BYt.forEach(t),ptt=r(dWe," \u2014 "),gte=n(dWe,"A",{href:!0});var IYt=s(gte);_tt=r(IYt,"FlaxAlbertForQuestionAnswering"),IYt.forEach(t),utt=r(dWe," (ALBERT model)"),dWe.forEach(t),btt=i(Ge),k6=n(Ge,"LI",{});var cWe=s(k6);a7e=n(cWe,"STRONG",{});var NYt=s(a7e);vtt=r(NYt,"bart"),NYt.forEach(t),Ftt=r(cWe," \u2014 "),hte=n(cWe,"A",{href:!0});var qYt=s(hte);Ttt=r(qYt,"FlaxBartForQuestionAnswering"),qYt.forEach(t),Mtt=r(cWe," (BART model)"),cWe.forEach(t),Ett=i(Ge),S6=n(Ge,"LI",{});var fWe=s(S6);n7e=n(fWe,"STRONG",{});var jYt=s(n7e);Ctt=r(jYt,"bert"),jYt.forEach(t),wtt=r(fWe," \u2014 "),pte=n(fWe,"A",{href:!0});var DYt=s(pte);Att=r(DYt,"FlaxBertForQuestionAnswering"),DYt.forEach(t),Ltt=r(fWe," (BERT model)"),fWe.forEach(t),ytt=i(Ge),R6=n(Ge,"LI",{});var mWe=s(R6);s7e=n(mWe,"STRONG",{});var GYt=s(s7e);xtt=r(GYt,"big_bird"),GYt.forEach(t),$tt=r(mWe," \u2014 "),_te=n(mWe,"A",{href:!0});var OYt=s(_te);ktt=r(OYt,"FlaxBigBirdForQuestionAnswering"),OYt.forEach(t),Stt=r(mWe," (BigBird model)"),mWe.forEach(t),Rtt=i(Ge),P6=n(Ge,"LI",{});var gWe=s(P6);l7e=n(gWe,"STRONG",{});var VYt=s(l7e);Ptt=r(VYt,"distilbert"),VYt.forEach(t),Btt=r(gWe," \u2014 "),ute=n(gWe,"A",{href:!0});var XYt=s(ute);Itt=r(XYt,"FlaxDistilBertForQuestionAnswering"),XYt.forEach(t),Ntt=r(gWe," (DistilBERT model)"),gWe.forEach(t),qtt=i(Ge),B6=n(Ge,"LI",{});var hWe=s(B6);i7e=n(hWe,"STRONG",{});var zYt=s(i7e);jtt=r(zYt,"electra"),zYt.forEach(t),Dtt=r(hWe," \u2014 "),bte=n(hWe,"A",{href:!0});var WYt=s(bte);Gtt=r(WYt,"FlaxElectraForQuestionAnswering"),WYt.forEach(t),Ott=r(hWe," (ELECTRA model)"),hWe.forEach(t),Vtt=i(Ge),I6=n(Ge,"LI",{});var pWe=s(I6);d7e=n(pWe,"STRONG",{});var QYt=s(d7e);Xtt=r(QYt,"mbart"),QYt.forEach(t),ztt=r(pWe," \u2014 "),vte=n(pWe,"A",{href:!0});var UYt=s(vte);Wtt=r(UYt,"FlaxMBartForQuestionAnswering"),UYt.forEach(t),Qtt=r(pWe," (mBART model)"),pWe.forEach(t),Utt=i(Ge),N6=n(Ge,"LI",{});var _We=s(N6);c7e=n(_We,"STRONG",{});var HYt=s(c7e);Htt=r(HYt,"roberta"),HYt.forEach(t),Jtt=r(_We," \u2014 "),Fte=n(_We,"A",{href:!0});var JYt=s(Fte);Ytt=r(JYt,"FlaxRobertaForQuestionAnswering"),JYt.forEach(t),Ktt=r(_We," (RoBERTa model)"),_We.forEach(t),Ztt=i(Ge),q6=n(Ge,"LI",{});var uWe=s(q6);f7e=n(uWe,"STRONG",{});var YYt=s(f7e);eat=r(YYt,"roformer"),YYt.forEach(t),oat=r(uWe," \u2014 "),Tte=n(uWe,"A",{href:!0});var KYt=s(Tte);rat=r(KYt,"FlaxRoFormerForQuestionAnswering"),KYt.forEach(t),tat=r(uWe," (RoFormer model)"),uWe.forEach(t),aat=i(Ge),j6=n(Ge,"LI",{});var bWe=s(j6);m7e=n(bWe,"STRONG",{});var ZYt=s(m7e);nat=r(ZYt,"xlm-roberta"),ZYt.forEach(t),sat=r(bWe," \u2014 "),Mte=n(bWe,"A",{href:!0});var eKt=s(Mte);lat=r(eKt,"FlaxXLMRobertaForQuestionAnswering"),eKt.forEach(t),iat=r(bWe," (XLM-RoBERTa model)"),bWe.forEach(t),Ge.forEach(t),dat=i(wi),T(D6.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),IUe=i(f),Lf=n(f,"H2",{class:!0});var QJe=s(Lf);G6=n(QJe,"A",{id:!0,class:!0,href:!0});var oKt=s(G6);g7e=n(oKt,"SPAN",{});var rKt=s(g7e);T(Ik.$$.fragment,rKt),rKt.forEach(t),oKt.forEach(t),cat=i(QJe),h7e=n(QJe,"SPAN",{});var tKt=s(h7e);fat=r(tKt,"FlaxAutoModelForTokenClassification"),tKt.forEach(t),QJe.forEach(t),NUe=i(f),wr=n(f,"DIV",{class:!0});var Ai=s(wr);T(Nk.$$.fragment,Ai),mat=i(Ai),yf=n(Ai,"P",{});var Vne=s(yf);gat=r(Vne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Ete=n(Vne,"A",{href:!0});var aKt=s(Ete);hat=r(aKt,"from_pretrained()"),aKt.forEach(t),pat=r(Vne," class method or the "),Cte=n(Vne,"A",{href:!0});var nKt=s(Cte);_at=r(nKt,"from_config()"),nKt.forEach(t),uat=r(Vne,` class
method.`),Vne.forEach(t),bat=i(Ai),qk=n(Ai,"P",{});var UJe=s(qk);vat=r(UJe,"This class cannot be instantiated directly using "),p7e=n(UJe,"CODE",{});var sKt=s(p7e);Fat=r(sKt,"__init__()"),sKt.forEach(t),Tat=r(UJe," (throws an error)."),UJe.forEach(t),Mat=i(Ai),ta=n(Ai,"DIV",{class:!0});var RL=s(ta);T(jk.$$.fragment,RL),Eat=i(RL),_7e=n(RL,"P",{});var lKt=s(_7e);Cat=r(lKt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),lKt.forEach(t),wat=i(RL),xf=n(RL,"P",{});var Xne=s(xf);Aat=r(Xne,`Note:
Loading a model from its configuration file does `),u7e=n(Xne,"STRONG",{});var iKt=s(u7e);Lat=r(iKt,"not"),iKt.forEach(t),yat=r(Xne,` load the model weights. It only affects the
model\u2019s configuration. Use `),wte=n(Xne,"A",{href:!0});var dKt=s(wte);xat=r(dKt,"from_pretrained()"),dKt.forEach(t),$at=r(Xne," to load the model weights."),Xne.forEach(t),kat=i(RL),T(O6.$$.fragment,RL),RL.forEach(t),Sat=i(Ai),Zr=n(Ai,"DIV",{class:!0});var Li=s(Zr);T(Dk.$$.fragment,Li),Rat=i(Li),b7e=n(Li,"P",{});var cKt=s(b7e);Pat=r(cKt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cKt.forEach(t),Bat=i(Li),Pn=n(Li,"P",{});var PL=s(Pn);Iat=r(PL,"The model class to instantiate is selected based on the "),v7e=n(PL,"CODE",{});var fKt=s(v7e);Nat=r(fKt,"model_type"),fKt.forEach(t),qat=r(PL,` property of the config object (either
passed as an argument or loaded from `),F7e=n(PL,"CODE",{});var mKt=s(F7e);jat=r(mKt,"pretrained_model_name_or_path"),mKt.forEach(t),Dat=r(PL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T7e=n(PL,"CODE",{});var gKt=s(T7e);Gat=r(gKt,"pretrained_model_name_or_path"),gKt.forEach(t),Oat=r(PL,":"),PL.forEach(t),Vat=i(Li),Xe=n(Li,"UL",{});var Co=s(Xe);V6=n(Co,"LI",{});var vWe=s(V6);M7e=n(vWe,"STRONG",{});var hKt=s(M7e);Xat=r(hKt,"albert"),hKt.forEach(t),zat=r(vWe," \u2014 "),Ate=n(vWe,"A",{href:!0});var pKt=s(Ate);Wat=r(pKt,"FlaxAlbertForTokenClassification"),pKt.forEach(t),Qat=r(vWe," (ALBERT model)"),vWe.forEach(t),Uat=i(Co),X6=n(Co,"LI",{});var FWe=s(X6);E7e=n(FWe,"STRONG",{});var _Kt=s(E7e);Hat=r(_Kt,"bert"),_Kt.forEach(t),Jat=r(FWe," \u2014 "),Lte=n(FWe,"A",{href:!0});var uKt=s(Lte);Yat=r(uKt,"FlaxBertForTokenClassification"),uKt.forEach(t),Kat=r(FWe," (BERT model)"),FWe.forEach(t),Zat=i(Co),z6=n(Co,"LI",{});var TWe=s(z6);C7e=n(TWe,"STRONG",{});var bKt=s(C7e);ent=r(bKt,"big_bird"),bKt.forEach(t),ont=r(TWe," \u2014 "),yte=n(TWe,"A",{href:!0});var vKt=s(yte);rnt=r(vKt,"FlaxBigBirdForTokenClassification"),vKt.forEach(t),tnt=r(TWe," (BigBird model)"),TWe.forEach(t),ant=i(Co),W6=n(Co,"LI",{});var MWe=s(W6);w7e=n(MWe,"STRONG",{});var FKt=s(w7e);nnt=r(FKt,"distilbert"),FKt.forEach(t),snt=r(MWe," \u2014 "),xte=n(MWe,"A",{href:!0});var TKt=s(xte);lnt=r(TKt,"FlaxDistilBertForTokenClassification"),TKt.forEach(t),int=r(MWe," (DistilBERT model)"),MWe.forEach(t),dnt=i(Co),Q6=n(Co,"LI",{});var EWe=s(Q6);A7e=n(EWe,"STRONG",{});var MKt=s(A7e);cnt=r(MKt,"electra"),MKt.forEach(t),fnt=r(EWe," \u2014 "),$te=n(EWe,"A",{href:!0});var EKt=s($te);mnt=r(EKt,"FlaxElectraForTokenClassification"),EKt.forEach(t),gnt=r(EWe," (ELECTRA model)"),EWe.forEach(t),hnt=i(Co),U6=n(Co,"LI",{});var CWe=s(U6);L7e=n(CWe,"STRONG",{});var CKt=s(L7e);pnt=r(CKt,"roberta"),CKt.forEach(t),_nt=r(CWe," \u2014 "),kte=n(CWe,"A",{href:!0});var wKt=s(kte);unt=r(wKt,"FlaxRobertaForTokenClassification"),wKt.forEach(t),bnt=r(CWe," (RoBERTa model)"),CWe.forEach(t),vnt=i(Co),H6=n(Co,"LI",{});var wWe=s(H6);y7e=n(wWe,"STRONG",{});var AKt=s(y7e);Fnt=r(AKt,"roformer"),AKt.forEach(t),Tnt=r(wWe," \u2014 "),Ste=n(wWe,"A",{href:!0});var LKt=s(Ste);Mnt=r(LKt,"FlaxRoFormerForTokenClassification"),LKt.forEach(t),Ent=r(wWe," (RoFormer model)"),wWe.forEach(t),Cnt=i(Co),J6=n(Co,"LI",{});var AWe=s(J6);x7e=n(AWe,"STRONG",{});var yKt=s(x7e);wnt=r(yKt,"xlm-roberta"),yKt.forEach(t),Ant=r(AWe," \u2014 "),Rte=n(AWe,"A",{href:!0});var xKt=s(Rte);Lnt=r(xKt,"FlaxXLMRobertaForTokenClassification"),xKt.forEach(t),ynt=r(AWe," (XLM-RoBERTa model)"),AWe.forEach(t),Co.forEach(t),xnt=i(Li),T(Y6.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),qUe=i(f),$f=n(f,"H2",{class:!0});var HJe=s($f);K6=n(HJe,"A",{id:!0,class:!0,href:!0});var $Kt=s(K6);$7e=n($Kt,"SPAN",{});var kKt=s($7e);T(Gk.$$.fragment,kKt),kKt.forEach(t),$Kt.forEach(t),$nt=i(HJe),k7e=n(HJe,"SPAN",{});var SKt=s(k7e);knt=r(SKt,"FlaxAutoModelForMultipleChoice"),SKt.forEach(t),HJe.forEach(t),jUe=i(f),Ar=n(f,"DIV",{class:!0});var yi=s(Ar);T(Ok.$$.fragment,yi),Snt=i(yi),kf=n(yi,"P",{});var zne=s(kf);Rnt=r(zne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Pte=n(zne,"A",{href:!0});var RKt=s(Pte);Pnt=r(RKt,"from_pretrained()"),RKt.forEach(t),Bnt=r(zne," class method or the "),Bte=n(zne,"A",{href:!0});var PKt=s(Bte);Int=r(PKt,"from_config()"),PKt.forEach(t),Nnt=r(zne,` class
method.`),zne.forEach(t),qnt=i(yi),Vk=n(yi,"P",{});var JJe=s(Vk);jnt=r(JJe,"This class cannot be instantiated directly using "),S7e=n(JJe,"CODE",{});var BKt=s(S7e);Dnt=r(BKt,"__init__()"),BKt.forEach(t),Gnt=r(JJe," (throws an error)."),JJe.forEach(t),Ont=i(yi),aa=n(yi,"DIV",{class:!0});var BL=s(aa);T(Xk.$$.fragment,BL),Vnt=i(BL),R7e=n(BL,"P",{});var IKt=s(R7e);Xnt=r(IKt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),IKt.forEach(t),znt=i(BL),Sf=n(BL,"P",{});var Wne=s(Sf);Wnt=r(Wne,`Note:
Loading a model from its configuration file does `),P7e=n(Wne,"STRONG",{});var NKt=s(P7e);Qnt=r(NKt,"not"),NKt.forEach(t),Unt=r(Wne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ite=n(Wne,"A",{href:!0});var qKt=s(Ite);Hnt=r(qKt,"from_pretrained()"),qKt.forEach(t),Jnt=r(Wne," to load the model weights."),Wne.forEach(t),Ynt=i(BL),T(Z6.$$.fragment,BL),BL.forEach(t),Knt=i(yi),et=n(yi,"DIV",{class:!0});var xi=s(et);T(zk.$$.fragment,xi),Znt=i(xi),B7e=n(xi,"P",{});var jKt=s(B7e);est=r(jKt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),jKt.forEach(t),ost=i(xi),Bn=n(xi,"P",{});var IL=s(Bn);rst=r(IL,"The model class to instantiate is selected based on the "),I7e=n(IL,"CODE",{});var DKt=s(I7e);tst=r(DKt,"model_type"),DKt.forEach(t),ast=r(IL,` property of the config object (either
passed as an argument or loaded from `),N7e=n(IL,"CODE",{});var GKt=s(N7e);nst=r(GKt,"pretrained_model_name_or_path"),GKt.forEach(t),sst=r(IL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q7e=n(IL,"CODE",{});var OKt=s(q7e);lst=r(OKt,"pretrained_model_name_or_path"),OKt.forEach(t),ist=r(IL,":"),IL.forEach(t),dst=i(xi),ze=n(xi,"UL",{});var wo=s(ze);eA=n(wo,"LI",{});var LWe=s(eA);j7e=n(LWe,"STRONG",{});var VKt=s(j7e);cst=r(VKt,"albert"),VKt.forEach(t),fst=r(LWe," \u2014 "),Nte=n(LWe,"A",{href:!0});var XKt=s(Nte);mst=r(XKt,"FlaxAlbertForMultipleChoice"),XKt.forEach(t),gst=r(LWe," (ALBERT model)"),LWe.forEach(t),hst=i(wo),oA=n(wo,"LI",{});var yWe=s(oA);D7e=n(yWe,"STRONG",{});var zKt=s(D7e);pst=r(zKt,"bert"),zKt.forEach(t),_st=r(yWe," \u2014 "),qte=n(yWe,"A",{href:!0});var WKt=s(qte);ust=r(WKt,"FlaxBertForMultipleChoice"),WKt.forEach(t),bst=r(yWe," (BERT model)"),yWe.forEach(t),vst=i(wo),rA=n(wo,"LI",{});var xWe=s(rA);G7e=n(xWe,"STRONG",{});var QKt=s(G7e);Fst=r(QKt,"big_bird"),QKt.forEach(t),Tst=r(xWe," \u2014 "),jte=n(xWe,"A",{href:!0});var UKt=s(jte);Mst=r(UKt,"FlaxBigBirdForMultipleChoice"),UKt.forEach(t),Est=r(xWe," (BigBird model)"),xWe.forEach(t),Cst=i(wo),tA=n(wo,"LI",{});var $We=s(tA);O7e=n($We,"STRONG",{});var HKt=s(O7e);wst=r(HKt,"distilbert"),HKt.forEach(t),Ast=r($We," \u2014 "),Dte=n($We,"A",{href:!0});var JKt=s(Dte);Lst=r(JKt,"FlaxDistilBertForMultipleChoice"),JKt.forEach(t),yst=r($We," (DistilBERT model)"),$We.forEach(t),xst=i(wo),aA=n(wo,"LI",{});var kWe=s(aA);V7e=n(kWe,"STRONG",{});var YKt=s(V7e);$st=r(YKt,"electra"),YKt.forEach(t),kst=r(kWe," \u2014 "),Gte=n(kWe,"A",{href:!0});var KKt=s(Gte);Sst=r(KKt,"FlaxElectraForMultipleChoice"),KKt.forEach(t),Rst=r(kWe," (ELECTRA model)"),kWe.forEach(t),Pst=i(wo),nA=n(wo,"LI",{});var SWe=s(nA);X7e=n(SWe,"STRONG",{});var ZKt=s(X7e);Bst=r(ZKt,"roberta"),ZKt.forEach(t),Ist=r(SWe," \u2014 "),Ote=n(SWe,"A",{href:!0});var eZt=s(Ote);Nst=r(eZt,"FlaxRobertaForMultipleChoice"),eZt.forEach(t),qst=r(SWe," (RoBERTa model)"),SWe.forEach(t),jst=i(wo),sA=n(wo,"LI",{});var RWe=s(sA);z7e=n(RWe,"STRONG",{});var oZt=s(z7e);Dst=r(oZt,"roformer"),oZt.forEach(t),Gst=r(RWe," \u2014 "),Vte=n(RWe,"A",{href:!0});var rZt=s(Vte);Ost=r(rZt,"FlaxRoFormerForMultipleChoice"),rZt.forEach(t),Vst=r(RWe," (RoFormer model)"),RWe.forEach(t),Xst=i(wo),lA=n(wo,"LI",{});var PWe=s(lA);W7e=n(PWe,"STRONG",{});var tZt=s(W7e);zst=r(tZt,"xlm-roberta"),tZt.forEach(t),Wst=r(PWe," \u2014 "),Xte=n(PWe,"A",{href:!0});var aZt=s(Xte);Qst=r(aZt,"FlaxXLMRobertaForMultipleChoice"),aZt.forEach(t),Ust=r(PWe," (XLM-RoBERTa model)"),PWe.forEach(t),wo.forEach(t),Hst=i(xi),T(iA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),DUe=i(f),Rf=n(f,"H2",{class:!0});var YJe=s(Rf);dA=n(YJe,"A",{id:!0,class:!0,href:!0});var nZt=s(dA);Q7e=n(nZt,"SPAN",{});var sZt=s(Q7e);T(Wk.$$.fragment,sZt),sZt.forEach(t),nZt.forEach(t),Jst=i(YJe),U7e=n(YJe,"SPAN",{});var lZt=s(U7e);Yst=r(lZt,"FlaxAutoModelForNextSentencePrediction"),lZt.forEach(t),YJe.forEach(t),GUe=i(f),Lr=n(f,"DIV",{class:!0});var $i=s(Lr);T(Qk.$$.fragment,$i),Kst=i($i),Pf=n($i,"P",{});var Qne=s(Pf);Zst=r(Qne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),zte=n(Qne,"A",{href:!0});var iZt=s(zte);elt=r(iZt,"from_pretrained()"),iZt.forEach(t),olt=r(Qne," class method or the "),Wte=n(Qne,"A",{href:!0});var dZt=s(Wte);rlt=r(dZt,"from_config()"),dZt.forEach(t),tlt=r(Qne,` class
method.`),Qne.forEach(t),alt=i($i),Uk=n($i,"P",{});var KJe=s(Uk);nlt=r(KJe,"This class cannot be instantiated directly using "),H7e=n(KJe,"CODE",{});var cZt=s(H7e);slt=r(cZt,"__init__()"),cZt.forEach(t),llt=r(KJe," (throws an error)."),KJe.forEach(t),ilt=i($i),na=n($i,"DIV",{class:!0});var NL=s(na);T(Hk.$$.fragment,NL),dlt=i(NL),J7e=n(NL,"P",{});var fZt=s(J7e);clt=r(fZt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),fZt.forEach(t),flt=i(NL),Bf=n(NL,"P",{});var Une=s(Bf);mlt=r(Une,`Note:
Loading a model from its configuration file does `),Y7e=n(Une,"STRONG",{});var mZt=s(Y7e);glt=r(mZt,"not"),mZt.forEach(t),hlt=r(Une,` load the model weights. It only affects the
model\u2019s configuration. Use `),Qte=n(Une,"A",{href:!0});var gZt=s(Qte);plt=r(gZt,"from_pretrained()"),gZt.forEach(t),_lt=r(Une," to load the model weights."),Une.forEach(t),ult=i(NL),T(cA.$$.fragment,NL),NL.forEach(t),blt=i($i),ot=n($i,"DIV",{class:!0});var ki=s(ot);T(Jk.$$.fragment,ki),vlt=i(ki),K7e=n(ki,"P",{});var hZt=s(K7e);Flt=r(hZt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),hZt.forEach(t),Tlt=i(ki),In=n(ki,"P",{});var qL=s(In);Mlt=r(qL,"The model class to instantiate is selected based on the "),Z7e=n(qL,"CODE",{});var pZt=s(Z7e);Elt=r(pZt,"model_type"),pZt.forEach(t),Clt=r(qL,` property of the config object (either
passed as an argument or loaded from `),eLe=n(qL,"CODE",{});var _Zt=s(eLe);wlt=r(_Zt,"pretrained_model_name_or_path"),_Zt.forEach(t),Alt=r(qL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=n(qL,"CODE",{});var uZt=s(oLe);Llt=r(uZt,"pretrained_model_name_or_path"),uZt.forEach(t),ylt=r(qL,":"),qL.forEach(t),xlt=i(ki),rLe=n(ki,"UL",{});var bZt=s(rLe);fA=n(bZt,"LI",{});var BWe=s(fA);tLe=n(BWe,"STRONG",{});var vZt=s(tLe);$lt=r(vZt,"bert"),vZt.forEach(t),klt=r(BWe," \u2014 "),Ute=n(BWe,"A",{href:!0});var FZt=s(Ute);Slt=r(FZt,"FlaxBertForNextSentencePrediction"),FZt.forEach(t),Rlt=r(BWe," (BERT model)"),BWe.forEach(t),bZt.forEach(t),Plt=i(ki),T(mA.$$.fragment,ki),ki.forEach(t),$i.forEach(t),OUe=i(f),If=n(f,"H2",{class:!0});var ZJe=s(If);gA=n(ZJe,"A",{id:!0,class:!0,href:!0});var TZt=s(gA);aLe=n(TZt,"SPAN",{});var MZt=s(aLe);T(Yk.$$.fragment,MZt),MZt.forEach(t),TZt.forEach(t),Blt=i(ZJe),nLe=n(ZJe,"SPAN",{});var EZt=s(nLe);Ilt=r(EZt,"FlaxAutoModelForImageClassification"),EZt.forEach(t),ZJe.forEach(t),VUe=i(f),yr=n(f,"DIV",{class:!0});var Si=s(yr);T(Kk.$$.fragment,Si),Nlt=i(Si),Nf=n(Si,"P",{});var Hne=s(Nf);qlt=r(Hne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Hte=n(Hne,"A",{href:!0});var CZt=s(Hte);jlt=r(CZt,"from_pretrained()"),CZt.forEach(t),Dlt=r(Hne," class method or the "),Jte=n(Hne,"A",{href:!0});var wZt=s(Jte);Glt=r(wZt,"from_config()"),wZt.forEach(t),Olt=r(Hne,` class
method.`),Hne.forEach(t),Vlt=i(Si),Zk=n(Si,"P",{});var eYe=s(Zk);Xlt=r(eYe,"This class cannot be instantiated directly using "),sLe=n(eYe,"CODE",{});var AZt=s(sLe);zlt=r(AZt,"__init__()"),AZt.forEach(t),Wlt=r(eYe," (throws an error)."),eYe.forEach(t),Qlt=i(Si),sa=n(Si,"DIV",{class:!0});var jL=s(sa);T(eS.$$.fragment,jL),Ult=i(jL),lLe=n(jL,"P",{});var LZt=s(lLe);Hlt=r(LZt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),LZt.forEach(t),Jlt=i(jL),qf=n(jL,"P",{});var Jne=s(qf);Ylt=r(Jne,`Note:
Loading a model from its configuration file does `),iLe=n(Jne,"STRONG",{});var yZt=s(iLe);Klt=r(yZt,"not"),yZt.forEach(t),Zlt=r(Jne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Yte=n(Jne,"A",{href:!0});var xZt=s(Yte);eit=r(xZt,"from_pretrained()"),xZt.forEach(t),oit=r(Jne," to load the model weights."),Jne.forEach(t),rit=i(jL),T(hA.$$.fragment,jL),jL.forEach(t),tit=i(Si),rt=n(Si,"DIV",{class:!0});var Ri=s(rt);T(oS.$$.fragment,Ri),ait=i(Ri),dLe=n(Ri,"P",{});var $Zt=s(dLe);nit=r($Zt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),$Zt.forEach(t),sit=i(Ri),Nn=n(Ri,"P",{});var DL=s(Nn);lit=r(DL,"The model class to instantiate is selected based on the "),cLe=n(DL,"CODE",{});var kZt=s(cLe);iit=r(kZt,"model_type"),kZt.forEach(t),dit=r(DL,` property of the config object (either
passed as an argument or loaded from `),fLe=n(DL,"CODE",{});var SZt=s(fLe);cit=r(SZt,"pretrained_model_name_or_path"),SZt.forEach(t),fit=r(DL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mLe=n(DL,"CODE",{});var RZt=s(mLe);mit=r(RZt,"pretrained_model_name_or_path"),RZt.forEach(t),git=r(DL,":"),DL.forEach(t),hit=i(Ri),rS=n(Ri,"UL",{});var oYe=s(rS);pA=n(oYe,"LI",{});var IWe=s(pA);gLe=n(IWe,"STRONG",{});var PZt=s(gLe);pit=r(PZt,"beit"),PZt.forEach(t),_it=r(IWe," \u2014 "),Kte=n(IWe,"A",{href:!0});var BZt=s(Kte);uit=r(BZt,"FlaxBeitForImageClassification"),BZt.forEach(t),bit=r(IWe," (BEiT model)"),IWe.forEach(t),vit=i(oYe),_A=n(oYe,"LI",{});var NWe=s(_A);hLe=n(NWe,"STRONG",{});var IZt=s(hLe);Fit=r(IZt,"vit"),IZt.forEach(t),Tit=r(NWe," \u2014 "),Zte=n(NWe,"A",{href:!0});var NZt=s(Zte);Mit=r(NZt,"FlaxViTForImageClassification"),NZt.forEach(t),Eit=r(NWe," (ViT model)"),NWe.forEach(t),oYe.forEach(t),Cit=i(Ri),T(uA.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),XUe=i(f),jf=n(f,"H2",{class:!0});var rYe=s(jf);bA=n(rYe,"A",{id:!0,class:!0,href:!0});var qZt=s(bA);pLe=n(qZt,"SPAN",{});var jZt=s(pLe);T(tS.$$.fragment,jZt),jZt.forEach(t),qZt.forEach(t),wit=i(rYe),_Le=n(rYe,"SPAN",{});var DZt=s(_Le);Ait=r(DZt,"FlaxAutoModelForVision2Seq"),DZt.forEach(t),rYe.forEach(t),zUe=i(f),xr=n(f,"DIV",{class:!0});var Pi=s(xr);T(aS.$$.fragment,Pi),Lit=i(Pi),Df=n(Pi,"P",{});var Yne=s(Df);yit=r(Yne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),eae=n(Yne,"A",{href:!0});var GZt=s(eae);xit=r(GZt,"from_pretrained()"),GZt.forEach(t),$it=r(Yne," class method or the "),oae=n(Yne,"A",{href:!0});var OZt=s(oae);kit=r(OZt,"from_config()"),OZt.forEach(t),Sit=r(Yne,` class
method.`),Yne.forEach(t),Rit=i(Pi),nS=n(Pi,"P",{});var tYe=s(nS);Pit=r(tYe,"This class cannot be instantiated directly using "),uLe=n(tYe,"CODE",{});var VZt=s(uLe);Bit=r(VZt,"__init__()"),VZt.forEach(t),Iit=r(tYe," (throws an error)."),tYe.forEach(t),Nit=i(Pi),la=n(Pi,"DIV",{class:!0});var GL=s(la);T(sS.$$.fragment,GL),qit=i(GL),bLe=n(GL,"P",{});var XZt=s(bLe);jit=r(XZt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),XZt.forEach(t),Dit=i(GL),Gf=n(GL,"P",{});var Kne=s(Gf);Git=r(Kne,`Note:
Loading a model from its configuration file does `),vLe=n(Kne,"STRONG",{});var zZt=s(vLe);Oit=r(zZt,"not"),zZt.forEach(t),Vit=r(Kne,` load the model weights. It only affects the
model\u2019s configuration. Use `),rae=n(Kne,"A",{href:!0});var WZt=s(rae);Xit=r(WZt,"from_pretrained()"),WZt.forEach(t),zit=r(Kne," to load the model weights."),Kne.forEach(t),Wit=i(GL),T(vA.$$.fragment,GL),GL.forEach(t),Qit=i(Pi),tt=n(Pi,"DIV",{class:!0});var Bi=s(tt);T(lS.$$.fragment,Bi),Uit=i(Bi),FLe=n(Bi,"P",{});var QZt=s(FLe);Hit=r(QZt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),QZt.forEach(t),Jit=i(Bi),qn=n(Bi,"P",{});var OL=s(qn);Yit=r(OL,"The model class to instantiate is selected based on the "),TLe=n(OL,"CODE",{});var UZt=s(TLe);Kit=r(UZt,"model_type"),UZt.forEach(t),Zit=r(OL,` property of the config object (either
passed as an argument or loaded from `),MLe=n(OL,"CODE",{});var HZt=s(MLe);edt=r(HZt,"pretrained_model_name_or_path"),HZt.forEach(t),odt=r(OL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ELe=n(OL,"CODE",{});var JZt=s(ELe);rdt=r(JZt,"pretrained_model_name_or_path"),JZt.forEach(t),tdt=r(OL,":"),OL.forEach(t),adt=i(Bi),CLe=n(Bi,"UL",{});var YZt=s(CLe);FA=n(YZt,"LI",{});var qWe=s(FA);wLe=n(qWe,"STRONG",{});var KZt=s(wLe);ndt=r(KZt,"vision-encoder-decoder"),KZt.forEach(t),sdt=r(qWe," \u2014 "),tae=n(qWe,"A",{href:!0});var ZZt=s(tae);ldt=r(ZZt,"FlaxVisionEncoderDecoderModel"),ZZt.forEach(t),idt=r(qWe," (Vision Encoder decoder model)"),qWe.forEach(t),YZt.forEach(t),ddt=i(Bi),T(TA.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(lra)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Dn,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoConfig"),c(On,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoModel"),c(Vn,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoTokenizer"),c(Oi,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertModel"),c(Hf,"id","extending-the-auto-classes"),c(Hf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hf,"href","#extending-the-auto-classes"),c(Vi,"class","relative group"),c(Yf,"id","transformers.AutoConfig"),c(Yf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yf,"href","#transformers.AutoConfig"),c(Xi,"class","relative group"),c(NR,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(qR,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertConfig"),c(jR,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartConfig"),c(DR,"href","/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitConfig"),c(GR,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertConfig"),c(OR,"href","/docs/transformers/pr_18524/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(VR,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdConfig"),c(XR,"href","/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(zR,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(WR,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(QR,"href","/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomConfig"),c(UR,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertConfig"),c(HR,"href","/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineConfig"),c(JR,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPConfig"),c(YR,"href","/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenConfig"),c(KR,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertConfig"),c(ZR,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextConfig"),c(eP,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLConfig"),c(oP,"href","/docs/transformers/pr_18524/en/model_doc/cvt#transformers.CvtConfig"),c(rP,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(tP,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(aP,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(nP,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaConfig"),c(sP,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(lP,"href","/docs/transformers/pr_18524/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(iP,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTConfig"),c(dP,"href","/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrConfig"),c(cP,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertConfig"),c(fP,"href","/docs/transformers/pr_18524/en/model_doc/dpr#transformers.DPRConfig"),c(mP,"href","/docs/transformers/pr_18524/en/model_doc/dpt#transformers.DPTConfig"),c(gP,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraConfig"),c(hP,"href","/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(pP,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertConfig"),c(_P,"href","/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaConfig"),c(uP,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetConfig"),c(bP,"href","/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTConfig"),c(vP,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelConfig"),c(FP,"href","/docs/transformers/pr_18524/en/model_doc/glpn#transformers.GLPNConfig"),c(TP,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Config"),c(MP,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(EP,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(CP,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJConfig"),c(wP,"href","/docs/transformers/pr_18524/en/model_doc/groupvit#transformers.GroupViTConfig"),c(AP,"href","/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertConfig"),c(LP,"href","/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertConfig"),c(yP,"href","/docs/transformers/pr_18524/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(xP,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c($P,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(kP,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(SP,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDConfig"),c(RP,"href","/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitConfig"),c(PP,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerConfig"),c(BP,"href","/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5Config"),c(IP,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeConfig"),c(NP,"href","/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertConfig"),c(qP,"href","/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100Config"),c(jP,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianConfig"),c(DP,"href","/docs/transformers/pr_18524/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(GP,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartConfig"),c(OP,"href","/docs/transformers/pr_18524/en/model_doc/mctct#transformers.MCTCTConfig"),c(VP,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(XP,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(zP,"href","/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(WP,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetConfig"),c(QP,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Config"),c(UP,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpConfig"),c(HP,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaConfig"),c(JP,"href","/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(YP,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(KP,"href","/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTConfig"),c(ZP,"href","/docs/transformers/pr_18524/en/model_doc/owlvit#transformers.OwlViTConfig"),c(eB,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusConfig"),c(oB,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverConfig"),c(rB,"href","/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartConfig"),c(tB,"href","/docs/transformers/pr_18524/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(aB,"href","/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(nB,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(sB,"href","/docs/transformers/pr_18524/en/model_doc/rag#transformers.RagConfig"),c(lB,"href","/docs/transformers/pr_18524/en/model_doc/realm#transformers.RealmConfig"),c(iB,"href","/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerConfig"),c(dB,"href","/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetConfig"),c(cB,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertConfig"),c(fB,"href","/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetConfig"),c(mB,"href","/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertConfig"),c(gB,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaConfig"),c(hB,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerConfig"),c(pB,"href","/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerConfig"),c(_B,"href","/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWConfig"),c(uB,"href","/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDConfig"),c(bB,"href","/docs/transformers/pr_18524/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(vB,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(FB,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(TB,"href","/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterConfig"),c(MB,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(EB,"href","/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinConfig"),c(CB,"href","/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2Config"),c(wB,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Config"),c(AB,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasConfig"),c(LB,"href","/docs/transformers/pr_18524/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(yB,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(xB,"href","/docs/transformers/pr_18524/en/model_doc/trocr#transformers.TrOCRConfig"),c($B,"href","/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(kB,"href","/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(SB,"href","/docs/transformers/pr_18524/en/model_doc/van#transformers.VanConfig"),c(RB,"href","/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEConfig"),c(PB,"href","/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltConfig"),c(BB,"href","/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(IB,"href","/docs/transformers/pr_18524/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(NB,"href","/docs/transformers/pr_18524/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(qB,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTConfig"),c(jB,"href","/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(DB,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(GB,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(OB,"href","/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMConfig"),c(VB,"href","/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMConfig"),c(XB,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMConfig"),c(zB,"href","/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(WB,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(QB,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(UB,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetConfig"),c(HB,"href","/docs/transformers/pr_18524/en/model_doc/yolos#transformers.YolosConfig"),c(JB,"href","/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoConfig"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gh,"id","transformers.AutoTokenizer"),c(gh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gh,"href","#transformers.AutoTokenizer"),c(Wi,"class","relative group"),c(YB,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(KB,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertTokenizer"),c(ZB,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(eI,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartTokenizer"),c(oI,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartTokenizerFast"),c(rI,"href","/docs/transformers/pr_18524/en/model_doc/barthez#transformers.BarthezTokenizer"),c(tI,"href","/docs/transformers/pr_18524/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(aI,"href","/docs/transformers/pr_18524/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(nI,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizer"),c(sI,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizerFast"),c(lI,"href","/docs/transformers/pr_18524/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(iI,"href","/docs/transformers/pr_18524/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(dI,"href","/docs/transformers/pr_18524/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(cI,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(fI,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(mI,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(gI,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(hI,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(pI,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(_I,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(uI,"href","/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(bI,"href","/docs/transformers/pr_18524/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(vI,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertTokenizer"),c(FI,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(TI,"href","/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineTokenizer"),c(MI,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPTokenizer"),c(EI,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(CI,"href","/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(wI,"href","/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(AI,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(LI,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(yI,"href","/docs/transformers/pr_18524/en/model_doc/cpm#transformers.CpmTokenizer"),c(xI,"href","/docs/transformers/pr_18524/en/model_doc/cpm#transformers.CpmTokenizerFast"),c($I,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(kI,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaTokenizer"),c(SI,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(RI,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaTokenizer"),c(PI,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(BI,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(II,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(NI,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(qI,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(jI,"href","/docs/transformers/pr_18524/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(DI,"href","/docs/transformers/pr_18524/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(GI,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraTokenizer"),c(OI,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(VI,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(XI,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetTokenizer"),c(zI,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(WI,"href","/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(QI,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelTokenizer"),c(UI,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(HI,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(JI,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(YI,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(KI,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(ZI,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(eN,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(oN,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(rN,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPTokenizer"),c(tN,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(aN,"href","/docs/transformers/pr_18524/en/model_doc/herbert#transformers.HerbertTokenizer"),c(nN,"href","/docs/transformers/pr_18524/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(sN,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(lN,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaTokenizer"),c(iN,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(dN,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(cN,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(fN,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(mN,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(gN,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(hN,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(pN,"href","/docs/transformers/pr_18524/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(_N,"href","/docs/transformers/pr_18524/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(uN,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDTokenizer"),c(bN,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDTokenizerFast"),c(vN,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerTokenizer"),c(FN,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(TN,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.T5Tokenizer"),c(MN,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.T5TokenizerFast"),c(EN,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeTokenizer"),c(CN,"href","/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(wN,"href","/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(AN,"href","/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(LN,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianTokenizer"),c(yN,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartTokenizer"),c(xN,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartTokenizerFast"),c($N,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(kN,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(SN,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizer"),c(RN,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizerFast"),c(PN,"href","/docs/transformers/pr_18524/en/model_doc/mluke#transformers.MLukeTokenizer"),c(BN,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(IN,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(NN,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(qN,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(jN,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.T5Tokenizer"),c(DN,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.T5TokenizerFast"),c(GN,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpTokenizer"),c(ON,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(VN,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizer"),c(XN,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizerFast"),c(zN,"href","/docs/transformers/pr_18524/en/model_doc/nllb#transformers.NllbTokenizer"),c(WN,"href","/docs/transformers/pr_18524/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(QN,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertTokenizer"),c(UN,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(HN,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(JN,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(YN,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(KN,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPTokenizer"),c(ZN,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(eq,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(oq,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(rq,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(tq,"href","/docs/transformers/pr_18524/en/model_doc/phobert#transformers.PhobertTokenizer"),c(aq,"href","/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartTokenizer"),c(nq,"href","/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(sq,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizer"),c(lq,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizerFast"),c(iq,"href","/docs/transformers/pr_18524/en/model_doc/rag#transformers.RagTokenizer"),c(dq,"href","/docs/transformers/pr_18524/en/model_doc/realm#transformers.RealmTokenizer"),c(cq,"href","/docs/transformers/pr_18524/en/model_doc/realm#transformers.RealmTokenizerFast"),c(fq,"href","/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerTokenizer"),c(mq,"href","/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(gq,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertTokenizer"),c(hq,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(pq,"href","/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(_q,"href","/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(uq,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaTokenizer"),c(bq,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(vq,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(Fq,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(Tq,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(Mq,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(Eq,"href","/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterTokenizer"),c(Cq,"href","/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(wq,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(Aq,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(Lq,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.T5Tokenizer"),c(yq,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.T5TokenizerFast"),c(xq,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasTokenizer"),c($q,"href","/docs/transformers/pr_18524/en/model_doc/tapex#transformers.TapexTokenizer"),c(kq,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(Sq,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizer"),c(Rq,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizerFast"),c(Pq,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizer"),c(Bq,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertTokenizerFast"),c(Iq,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(Nq,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(qq,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(jq,"href","/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMTokenizer"),c(Dq,"href","/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(Gq,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMTokenizer"),c(Oq,"href","/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(Vq,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(Xq,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(zq,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaTokenizer"),c(Wq,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Qq,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(Uq,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(Hq,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertTokenizer"),c(Jq,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hh,"id","transformers.AutoFeatureExtractor"),c(Hh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Hh,"href","#transformers.AutoFeatureExtractor"),c(Qi,"class","relative group"),c(Yq,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(Kq,"href","/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(Zq,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(ej,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(oj,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(rj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(tj,"href","/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(aj,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(nj,"href","/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(sj,"href","/docs/transformers/pr_18524/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(lj,"href","/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(ij,"href","/docs/transformers/pr_18524/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(dj,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(cj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(fj,"href","/docs/transformers/pr_18524/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(mj,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(gj,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(hj,"href","/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(pj,"href","/docs/transformers/pr_18524/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(_j,"href","/docs/transformers/pr_18524/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(uj,"href","/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(bj,"href","/docs/transformers/pr_18524/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(vj,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(Fj,"href","/docs/transformers/pr_18524/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(Tj,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(Mj,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(Ej,"href","/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(Cj,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(wj,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Aj,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Lj,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yj,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(xj,"href","/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c($j,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kj,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Sj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(Rj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(Pj,"href","/docs/transformers/pr_18524/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ip,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Np,"id","transformers.AutoProcessor"),c(Np,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Np,"href","#transformers.AutoProcessor"),c(Ui,"class","relative group"),c(Bj,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(Ij,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPProcessor"),c(Nj,"href","/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaProcessor"),c(qj,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPProcessor"),c(jj,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(Dj,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(Gj,"href","/docs/transformers/pr_18524/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(Oj,"href","/docs/transformers/pr_18524/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(Vj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Xj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zj,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(Wj,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(Qj,"href","/docs/transformers/pr_18524/en/model_doc/trocr#transformers.TrOCRProcessor"),c(Uj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Hj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Jj,"href","/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltProcessor"),c(Yj,"href","/docs/transformers/pr_18524/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(Kj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Zj,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eD,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s_,"id","transformers.AutoModel"),c(s_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s_,"href","#transformers.AutoModel"),c(Ji,"class","relative group"),c(oD,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rD,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tD,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aD,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertModel"),c(nD,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartModel"),c(sD,"href","/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitModel"),c(lD,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertModel"),c(iD,"href","/docs/transformers/pr_18524/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(dD,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdModel"),c(cD,"href","/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(fD,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(mD,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(gD,"href","/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomModel"),c(hD,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertModel"),c(pD,"href","/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineModel"),c(_D,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.CLIPModel"),c(uD,"href","/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenModel"),c(bD,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertModel"),c(vD,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextModel"),c(FD,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLModel"),c(TD,"href","/docs/transformers/pr_18524/en/model_doc/cvt#transformers.CvtModel"),c(MD,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(ED,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(CD,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(wD,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaModel"),c(AD,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(LD,"href","/docs/transformers/pr_18524/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(yD,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTModel"),c(xD,"href","/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrModel"),c($D,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertModel"),c(kD,"href","/docs/transformers/pr_18524/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(SD,"href","/docs/transformers/pr_18524/en/model_doc/dpt#transformers.DPTModel"),c(RD,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraModel"),c(PD,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertModel"),c(BD,"href","/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaModel"),c(ID,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetModel"),c(ND,"href","/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTModel"),c(qD,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelModel"),c(jD,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelBaseModel"),c(DD,"href","/docs/transformers/pr_18524/en/model_doc/glpn#transformers.GLPNModel"),c(GD,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2Model"),c(OD,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(VD,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(XD,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJModel"),c(zD,"href","/docs/transformers/pr_18524/en/model_doc/groupvit#transformers.GroupViTModel"),c(WD,"href","/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertModel"),c(QD,"href","/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertModel"),c(UD,"href","/docs/transformers/pr_18524/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(HD,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(JD,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(YD,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(KD,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDModel"),c(ZD,"href","/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitModel"),c(eG,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerModel"),c(oG,"href","/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5Model"),c(rG,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeModel"),c(tG,"href","/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertModel"),c(aG,"href","/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100Model"),c(nG,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianModel"),c(sG,"href","/docs/transformers/pr_18524/en/model_doc/maskformer#transformers.MaskFormerModel"),c(lG,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartModel"),c(iG,"href","/docs/transformers/pr_18524/en/model_doc/mctct#transformers.MCTCTModel"),c(dG,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(cG,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertModel"),c(fG,"href","/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTModel"),c(mG,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetModel"),c(gG,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5Model"),c(hG,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpModel"),c(pG,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaModel"),c(_G,"href","/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100Model"),c(uG,"href","/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerModel"),c(bG,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(vG,"href","/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTModel"),c(FG,"href","/docs/transformers/pr_18524/en/model_doc/owlvit#transformers.OwlViTModel"),c(TG,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusModel"),c(MG,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverModel"),c(EG,"href","/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartModel"),c(CG,"href","/docs/transformers/pr_18524/en/model_doc/poolformer#transformers.PoolFormerModel"),c(wG,"href","/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(AG,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertModel"),c(LG,"href","/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerModel"),c(yG,"href","/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetModel"),c(xG,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertModel"),c($G,"href","/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetModel"),c(kG,"href","/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertModel"),c(SG,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaModel"),c(RG,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerModel"),c(PG,"href","/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerModel"),c(BG,"href","/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWModel"),c(IG,"href","/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDModel"),c(NG,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(qG,"href","/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterModel"),c(jG,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(DG,"href","/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinModel"),c(GG,"href","/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2Model"),c(OG,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5Model"),c(VG,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasModel"),c(XG,"href","/docs/transformers/pr_18524/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(zG,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(WG,"href","/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechModel"),c(QG,"href","/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(UG,"href","/docs/transformers/pr_18524/en/model_doc/van#transformers.VanModel"),c(HG,"href","/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEModel"),c(JG,"href","/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltModel"),c(YG,"href","/docs/transformers/pr_18524/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(KG,"href","/docs/transformers/pr_18524/en/model_doc/visual_bert#transformers.VisualBertModel"),c(ZG,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTModel"),c(eO,"href","/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(oO,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(rO,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(tO,"href","/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMModel"),c(aO,"href","/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMModel"),c(nO,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMModel"),c(sO,"href","/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(lO,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(iO,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(dO,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetModel"),c(cO,"href","/docs/transformers/pr_18524/en/model_doc/yolos#transformers.YolosModel"),c(fO,"href","/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_2,"id","transformers.AutoModelForPreTraining"),c(_2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_2,"href","#transformers.AutoModelForPreTraining"),c(Zi,"class","relative group"),c(mO,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gO,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hO,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pO,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForPreTraining"),c(_O,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(uO,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForPreTraining"),c(bO,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(vO,"href","/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomForCausalLM"),c(FO,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(TO,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(MO,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(EO,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(CO,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(wO,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(AO,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForPreTraining"),c(LO,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(yO,"href","/docs/transformers/pr_18524/en/model_doc/flava#transformers.FlavaForPreTraining"),c(xO,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForPreTraining"),c($O,"href","/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(kO,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(SO,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(RO,"href","/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(PO,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(BO,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(IO,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForMaskedLM"),c(NO,"href","/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(qO,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(jO,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(DO,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(GO,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(OO,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(VO,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(XO,"href","/docs/transformers/pr_18524/en/model_doc/retribert#transformers.RetriBertModel"),c(zO,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(WO,"href","/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(QO,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(UO,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(HO,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(JO,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(YO,"href","/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(KO,"href","/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(ZO,"href","/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(eV,"href","/docs/transformers/pr_18524/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(oV,"href","/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(rV,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(tV,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(aV,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(nV,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(sV,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(lV,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g1,"id","transformers.AutoModelForCausalLM"),c(g1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g1,"href","#transformers.AutoModelForCausalLM"),c(rd,"class","relative group"),c(iV,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dV,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cV,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fV,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForCausalLM"),c(mV,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertLMHeadModel"),c(gV,"href","/docs/transformers/pr_18524/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(hV,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(pV,"href","/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(_V,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(uV,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(bV,"href","/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomForCausalLM"),c(vV,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(FV,"href","/docs/transformers/pr_18524/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(TV,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(MV,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(EV,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForCausalLM"),c(CV,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wV,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(AV,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(LV,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(yV,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianForCausalLM"),c(xV,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForCausalLM"),c($V,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(kV,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForCausalLM"),c(SV,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(RV,"href","/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTForCausalLM"),c(PV,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(BV,"href","/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(IV,"href","/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(NV,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(qV,"href","/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(jV,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(DV,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(GV,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(OV,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(VV,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(XV,"href","/docs/transformers/pr_18524/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(zV,"href","/docs/transformers/pr_18524/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(WV,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(QV,"href","/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(UV,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(HV,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(JV,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t4,"id","transformers.AutoModelForMaskedLM"),c(t4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t4,"href","#transformers.AutoModelForMaskedLM"),c(nd,"class","relative group"),c(YV,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KV,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZV,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eX,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(oX,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(rX,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForMaskedLM"),c(tX,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(aX,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(nX,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(sX,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(lX,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(iX,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(dX,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(cX,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(fX,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(mX,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(gX,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(hX,"href","/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(pX,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(_X,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(uX,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForMaskedLM"),c(bX,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(vX,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(FX,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(TX,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(MX,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(EX,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(CX,"href","/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(wX,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(AX,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(LX,"href","/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(yX,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(xX,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c($X,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(kX,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(SX,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(RX,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(PX,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(BX,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(IX,"href","/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z4,"id","transformers.AutoModelForSeq2SeqLM"),c(z4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z4,"href","#transformers.AutoModelForSeq2SeqLM"),c(id,"class","relative group"),c(NX,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qX,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jX,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DX,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(GX,"href","/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(OX,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(VX,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(XX,"href","/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(zX,"href","/docs/transformers/pr_18524/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(WX,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(QX,"href","/docs/transformers/pr_18524/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(UX,"href","/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(HX,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.MarianMTModel"),c(JX,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(YX,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(KX,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(ZX,"href","/docs/transformers/pr_18524/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(ez,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(oz,"href","/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(rz,"href","/docs/transformers/pr_18524/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(tz,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(az,"href","/docs/transformers/pr_18524/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hb,"id","transformers.AutoModelForSequenceClassification"),c(hb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hb,"href","#transformers.AutoModelForSequenceClassification"),c(fd,"class","relative group"),c(nz,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sz,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lz,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iz,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(dz,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForSequenceClassification"),c(cz,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForSequenceClassification"),c(fz,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(mz,"href","/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(gz,"href","/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(hz,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(pz,"href","/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(_z,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(uz,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(bz,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(vz,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(Fz,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(Tz,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(Mz,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(Ez,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(Cz,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(wz,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(Az,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(Lz,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(yz,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(xz,"href","/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c($z,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(kz,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(Sz,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(Rz,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDForSequenceClassification"),c(Pz,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(Bz,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(Iz,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(Nz,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(qz,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(jz,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(Dz,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(Gz,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(Oz,"href","/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(Vz,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(Xz,"href","/docs/transformers/pr_18524/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(zz,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(Wz,"href","/docs/transformers/pr_18524/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(Qz,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(Uz,"href","/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(Hz,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(Jz,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(Yz,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(Kz,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(Zz,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(eW,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(oW,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(rW,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(tW,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(aW,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(nW,"href","/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_v,"id","transformers.AutoModelForMultipleChoice"),c(_v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_v,"href","#transformers.AutoModelForMultipleChoice"),c(hd,"class","relative group"),c(sW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dW,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(cW,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForMultipleChoice"),c(fW,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(mW,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(gW,"href","/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(hW,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(pW,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(_W,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(uW,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(bW,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(vW,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(FW,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(TW,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(MW,"href","/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(EW,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(CW,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(wW,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(AW,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(LW,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(yW,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(xW,"href","/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c($W,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(kW,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(SW,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(RW,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(PW,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(BW,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(IW,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(NW,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(qW,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(jW,"href","/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yv,"id","transformers.AutoModelForNextSentencePrediction"),c(Yv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yv,"href","#transformers.AutoModelForNextSentencePrediction"),c(ud,"class","relative group"),c(DW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VW,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(XW,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(zW,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(WW,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(QW,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(UW,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l5,"id","transformers.AutoModelForTokenClassification"),c(l5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l5,"href","#transformers.AutoModelForTokenClassification"),c(Fd,"class","relative group"),c(HW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YW,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KW,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(ZW,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForTokenClassification"),c(eQ,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(oQ,"href","/docs/transformers/pr_18524/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(rQ,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(tQ,"href","/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineForTokenClassification"),c(aQ,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(nQ,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(sQ,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(lQ,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(iQ,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(dQ,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(cQ,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(fQ,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(mQ,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(gQ,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(hQ,"href","/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(pQ,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(_Q,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(uQ,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(bQ,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(vQ,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForTokenClassification"),c(FQ,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(TQ,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(MQ,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(EQ,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(CQ,"href","/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(wQ,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(AQ,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(LQ,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(yQ,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(xQ,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c($Q,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(kQ,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(SQ,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(RQ,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(PQ,"href","/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(U5,"id","transformers.AutoModelForQuestionAnswering"),c(U5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(U5,"href","#transformers.AutoModelForQuestionAnswering"),c(Ed,"class","relative group"),c(BQ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IQ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NQ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qQ,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(jQ,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(DQ,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(GQ,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(OQ,"href","/docs/transformers/pr_18524/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(VQ,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(XQ,"href","/docs/transformers/pr_18524/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(zQ,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(WQ,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(QQ,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(UQ,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(HQ,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(JQ,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(YQ,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(KQ,"href","/docs/transformers/pr_18524/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(ZQ,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(eU,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(oU,"href","/docs/transformers/pr_18524/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(rU,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(tU,"href","/docs/transformers/pr_18524/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(aU,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(nU,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(sU,"href","/docs/transformers/pr_18524/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(lU,"href","/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(iU,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(dU,"href","/docs/transformers/pr_18524/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(cU,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(fU,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(mU,"href","/docs/transformers/pr_18524/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(gU,"href","/docs/transformers/pr_18524/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(hU,"href","/docs/transformers/pr_18524/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(pU,"href","/docs/transformers/pr_18524/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(_U,"href","/docs/transformers/pr_18524/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(uU,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(bU,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(vU,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(FU,"href","/docs/transformers/pr_18524/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(TU,"href","/docs/transformers/pr_18524/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(MU,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(EU,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(CU,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(wU,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(AU,"href","/docs/transformers/pr_18524/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GF,"id","transformers.AutoModelForTableQuestionAnswering"),c(GF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(GF,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Ad,"class","relative group"),c(LU,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yU,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xU,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($U,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(WF,"id","transformers.AutoModelForImageClassification"),c(WF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(WF,"href","#transformers.AutoModelForImageClassification"),c(xd,"class","relative group"),c(kU,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SU,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RU,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PU,"href","/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitForImageClassification"),c(BU,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(IU,"href","/docs/transformers/pr_18524/en/model_doc/cvt#transformers.CvtForImageClassification"),c(NU,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(qU,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTForImageClassification"),c(jU,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(DU,"href","/docs/transformers/pr_18524/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(GU,"href","/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitForImageClassification"),c(OU,"href","/docs/transformers/pr_18524/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(VU,"href","/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(XU,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(zU,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(WU,"href","/docs/transformers/pr_18524/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(QU,"href","/docs/transformers/pr_18524/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(UU,"href","/docs/transformers/pr_18524/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(HU,"href","/docs/transformers/pr_18524/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(JU,"href","/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(YU,"href","/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinForImageClassification"),c(KU,"href","/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(ZU,"href","/docs/transformers/pr_18524/en/model_doc/van#transformers.VanForImageClassification"),c(eH,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTForImageClassification"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cT,"id","transformers.AutoModelForVideoClassification"),c(cT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cT,"href","#transformers.AutoModelForVideoClassification"),c(Sd,"class","relative group"),c(oH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aH,"href","/docs/transformers/pr_18524/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pT,"id","transformers.AutoModelForVision2Seq"),c(pT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pT,"href","#transformers.AutoModelForVision2Seq"),c(Bd,"class","relative group"),c(nH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iH,"href","/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FT,"id","transformers.AutoModelForVisualQuestionAnswering"),c(FT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FT,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(qd,"class","relative group"),c(dH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mH,"href","/docs/transformers/pr_18524/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wT,"id","transformers.AutoModelForAudioClassification"),c(wT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wT,"href","#transformers.AutoModelForAudioClassification"),c(Gd,"class","relative group"),c(gH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_H,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(uH,"href","/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(bH,"href","/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(vH,"href","/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(FH,"href","/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(TH,"href","/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(MH,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(EH,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(CH,"href","/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qT,"id","transformers.AutoModelForAudioFrameClassification"),c(qT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qT,"href","#transformers.AutoModelForAudioFrameClassification"),c(Xd,"class","relative group"),c(wH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yH,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(xH,"href","/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c($H,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(kH,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(SH,"href","/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QT,"id","transformers.AutoModelForCTC"),c(QT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QT,"href","#transformers.AutoModelForCTC"),c(Qd,"class","relative group"),c(RH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IH,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(NH,"href","/docs/transformers/pr_18524/en/model_doc/hubert#transformers.HubertForCTC"),c(qH,"href","/docs/transformers/pr_18524/en/model_doc/mctct#transformers.MCTCTForCTC"),c(jH,"href","/docs/transformers/pr_18524/en/model_doc/sew#transformers.SEWForCTC"),c(DH,"href","/docs/transformers/pr_18524/en/model_doc/sew-d#transformers.SEWDForCTC"),c(GH,"href","/docs/transformers/pr_18524/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(OH,"href","/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(VH,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(XH,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(zH,"href","/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMForCTC"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l8,"id","transformers.AutoModelForSpeechSeq2Seq"),c(l8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l8,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Jd,"class","relative group"),c(WH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HH,"href","/docs/transformers/pr_18524/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(JH,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g8,"id","transformers.AutoModelForAudioXVector"),c(g8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g8,"href","#transformers.AutoModelForAudioXVector"),c(Zd,"class","relative group"),c(YH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZH,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eJ,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(oJ,"href","/docs/transformers/pr_18524/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(rJ,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(tJ,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(aJ,"href","/docs/transformers/pr_18524/en/model_doc/wavlm#transformers.WavLMForXVector"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(M8,"id","transformers.AutoModelForMaskedImageModeling"),c(M8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(M8,"href","#transformers.AutoModelForMaskedImageModeling"),c(rc,"class","relative group"),c(nJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iJ,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(dJ,"href","/docs/transformers/pr_18524/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(cJ,"href","/docs/transformers/pr_18524/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(fJ,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($8,"id","transformers.AutoModelForObjectDetection"),c($8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($8,"href","#transformers.AutoModelForObjectDetection"),c(nc,"class","relative group"),c(mJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pJ,"href","/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrForObjectDetection"),c(_J,"href","/docs/transformers/pr_18524/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(I8,"id","transformers.AutoModelForImageSegmentation"),c(I8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(I8,"href","#transformers.AutoModelForImageSegmentation"),c(ic,"class","relative group"),c(uJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FJ,"href","/docs/transformers/pr_18524/en/model_doc/detr#transformers.DetrForSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G8,"id","transformers.AutoModelForSemanticSegmentation"),c(G8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G8,"href","#transformers.AutoModelForSemanticSegmentation"),c(fc,"class","relative group"),c(TJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CJ,"href","/docs/transformers/pr_18524/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(wJ,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(AJ,"href","/docs/transformers/pr_18524/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(LJ,"href","/docs/transformers/pr_18524/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(yJ,"href","/docs/transformers/pr_18524/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J8,"id","transformers.AutoModelForInstanceSegmentation"),c(J8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J8,"href","#transformers.AutoModelForInstanceSegmentation"),c(hc,"class","relative group"),c(xJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($J,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SJ,"href","/docs/transformers/pr_18524/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oM,"id","transformers.TFAutoModel"),c(oM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(oM,"href","#transformers.TFAutoModel"),c(uc,"class","relative group"),c(RJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BJ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IJ,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertModel"),c(NJ,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.TFBartModel"),c(qJ,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertModel"),c(jJ,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(DJ,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(GJ,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertModel"),c(OJ,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.TFCLIPModel"),c(VJ,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertModel"),c(XJ,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.TFConvNextModel"),c(zJ,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.TFCTRLModel"),c(WJ,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(QJ,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaModel"),c(UJ,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(HJ,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.TFDeiTModel"),c(JJ,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(YJ,"href","/docs/transformers/pr_18524/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(KJ,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraModel"),c(ZJ,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(eY,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelModel"),c(oY,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(rY,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.TFGPT2Model"),c(tY,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.TFGPTJModel"),c(aY,"href","/docs/transformers/pr_18524/en/model_doc/hubert#transformers.TFHubertModel"),c(nY,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(sY,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.TFLEDModel"),c(lY,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerModel"),c(iY,"href","/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.TFLxmertModel"),c(dY,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.TFMarianModel"),c(cY,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.TFMBartModel"),c(fY,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(mY,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetModel"),c(gY,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.TFMT5Model"),c(hY,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(pY,"href","/docs/transformers/pr_18524/en/model_doc/opt#transformers.TFOPTModel"),c(_Y,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.TFPegasusModel"),c(uY,"href","/docs/transformers/pr_18524/en/model_doc/regnet#transformers.TFRegNetModel"),c(bY,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertModel"),c(vY,"href","/docs/transformers/pr_18524/en/model_doc/resnet#transformers.TFResNetModel"),c(FY,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaModel"),c(TY,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerModel"),c(MY,"href","/docs/transformers/pr_18524/en/model_doc/segformer#transformers.TFSegformerModel"),c(EY,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(CY,"href","/docs/transformers/pr_18524/en/model_doc/swin#transformers.TFSwinModel"),c(wY,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.TFT5Model"),c(AY,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasModel"),c(LY,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(yY,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.TFViTModel"),c(xY,"href","/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c($Y,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(kY,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMModel"),c(SY,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(RY,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eE,"id","transformers.TFAutoModelForPreTraining"),c(eE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eE,"href","#transformers.TFAutoModelForPreTraining"),c(Fc,"class","relative group"),c(PY,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(qY,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(jY,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForPreTraining"),c(DY,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(GY,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(OY,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(VY,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(XY,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(zY,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(WY,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(QY,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(UY,"href","/docs/transformers/pr_18524/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(HY,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(JY,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(YY,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(KY,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(ZY,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(eK,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(oK,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(rK,"href","/docs/transformers/pr_18524/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(tK,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(aK,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(nK,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AE,"id","transformers.TFAutoModelForCausalLM"),c(AE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AE,"href","#transformers.TFAutoModelForCausalLM"),c(Ec,"class","relative group"),c(sK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dK,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(cK,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(fK,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(mK,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(gK,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(hK,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(pK,"href","/docs/transformers/pr_18524/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(_K,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(uK,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(bK,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(vK,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(FK,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(TK,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OE,"id","transformers.TFAutoModelForImageClassification"),c(OE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(OE,"href","#transformers.TFAutoModelForImageClassification"),c(Ac,"class","relative group"),c(MK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wK,"href","/docs/transformers/pr_18524/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(AK,"href","/docs/transformers/pr_18524/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(LK,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(yK,"href","/docs/transformers/pr_18524/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(xK,"href","/docs/transformers/pr_18524/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c($K,"href","/docs/transformers/pr_18524/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(kK,"href","/docs/transformers/pr_18524/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(SK,"href","/docs/transformers/pr_18524/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(RK,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KE,"id","transformers.TFAutoModelForMaskedLM"),c(KE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KE,"href","#transformers.TFAutoModelForMaskedLM"),c(xc,"class","relative group"),c(PK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(qK,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(jK,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(DK,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(GK,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(OK,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(VK,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(XK,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(zK,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(WK,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(QK,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(UK,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(HK,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(JK,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(YK,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(KK,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(ZK,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(eZ,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(oZ,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(rZ,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TC,"id","transformers.TFAutoModelForSeq2SeqLM"),c(TC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TC,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(Sc,"class","relative group"),c(tZ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aZ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nZ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sZ,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(lZ,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(iZ,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(dZ,"href","/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(cZ,"href","/docs/transformers/pr_18524/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(fZ,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.TFMarianMTModel"),c(mZ,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(gZ,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(hZ,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(pZ,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PC,"id","transformers.TFAutoModelForSequenceClassification"),c(PC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(PC,"href","#transformers.TFAutoModelForSequenceClassification"),c(Bc,"class","relative group"),c(_Z,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uZ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bZ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vZ,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(FZ,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(TZ,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(MZ,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(EZ,"href","/docs/transformers/pr_18524/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(CZ,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(wZ,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(AZ,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(LZ,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(yZ,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(xZ,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c($Z,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(kZ,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(SZ,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(RZ,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(PZ,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(BZ,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(IZ,"href","/docs/transformers/pr_18524/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(NZ,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(qZ,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(jZ,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(DZ,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(GZ,"href","/docs/transformers/pr_18524/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(OZ,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(VZ,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(XZ,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d3,"id","transformers.TFAutoModelForMultipleChoice"),c(d3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d3,"href","#transformers.TFAutoModelForMultipleChoice"),c(qc,"class","relative group"),c(zZ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WZ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QZ,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UZ,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(HZ,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(JZ,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(YZ,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(KZ,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(ZZ,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(eee,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(oee,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(ree,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(tee,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(aee,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(nee,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(see,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(lee,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(iee,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(dee,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(cee,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x3,"id","transformers.TFAutoModelForNextSentencePrediction"),c(x3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x3,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Gc,"class","relative group"),c(fee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hee,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(pee,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P3,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(P3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P3,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Xc,"class","relative group"),c(_ee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vee,"href","/docs/transformers/pr_18524/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q3,"id","transformers.TFAutoModelForTokenClassification"),c(q3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q3,"href","#transformers.TFAutoModelForTokenClassification"),c(Qc,"class","relative group"),c(Fee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eee,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(Cee,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(wee,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(Aee,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(Lee,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(yee,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(xee,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c($ee,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(kee,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(See,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(Ree,"href","/docs/transformers/pr_18524/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(Pee,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(Bee,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(Iee,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(Nee,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(qee,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(jee,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Dee,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(Gee,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(Oee,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(l0,"id","transformers.TFAutoModelForQuestionAnswering"),c(l0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(l0,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Jc,"class","relative group"),c(Vee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zee,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wee,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Qee,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(Uee,"href","/docs/transformers/pr_18524/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Hee,"href","/docs/transformers/pr_18524/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(Jee,"href","/docs/transformers/pr_18524/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(Yee,"href","/docs/transformers/pr_18524/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(Kee,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Zee,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(eoe,"href","/docs/transformers/pr_18524/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(ooe,"href","/docs/transformers/pr_18524/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(roe,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(toe,"href","/docs/transformers/pr_18524/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(aoe,"href","/docs/transformers/pr_18524/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(noe,"href","/docs/transformers/pr_18524/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(soe,"href","/docs/transformers/pr_18524/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(loe,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(ioe,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(doe,"href","/docs/transformers/pr_18524/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(coe,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(foe,"href","/docs/transformers/pr_18524/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($0,"id","transformers.TFAutoModelForVision2Seq"),c($0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($0,"href","#transformers.TFAutoModelForVision2Seq"),c(Zc,"class","relative group"),c(moe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(goe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hoe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(poe,"href","/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(P0,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(P0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(P0,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(rf,"class","relative group"),c(_oe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uoe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(boe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(voe,"href","/docs/transformers/pr_18524/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(q0,"id","transformers.FlaxAutoModel"),c(q0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(q0,"href","#transformers.FlaxAutoModel"),c(nf,"class","relative group"),c(Foe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Toe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Moe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eoe,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertModel"),c(Coe,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartModel"),c(woe,"href","/docs/transformers/pr_18524/en/model_doc/beit#transformers.FlaxBeitModel"),c(Aoe,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertModel"),c(Loe,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(yoe,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(xoe,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c($oe,"href","/docs/transformers/pr_18524/en/model_doc/clip#transformers.FlaxCLIPModel"),c(koe,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(Soe,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraModel"),c(Roe,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(Poe,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(Boe,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(Ioe,"href","/docs/transformers/pr_18524/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(Noe,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.FlaxMarianModel"),c(qoe,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartModel"),c(joe,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.FlaxMT5Model"),c(Doe,"href","/docs/transformers/pr_18524/en/model_doc/opt#transformers.FlaxOPTModel"),c(Goe,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(Ooe,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(Voe,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Xoe,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.FlaxT5Model"),c(zoe,"href","/docs/transformers/pr_18524/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Woe,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.FlaxViTModel"),c(Qoe,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Uoe,"href","/docs/transformers/pr_18524/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(Hoe,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hw,"id","transformers.FlaxAutoModelForCausalLM"),c(hw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hw,"href","#transformers.FlaxAutoModelForCausalLM"),c(df,"class","relative group"),c(Joe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yoe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Koe,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zoe,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(ere,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(ore,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(rre,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(tre,"href","/docs/transformers/pr_18524/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(are,"href","/docs/transformers/pr_18524/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(nre,"href","/docs/transformers/pr_18524/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(sre,"href","/docs/transformers/pr_18524/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(lre,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(ire,"href","/docs/transformers/pr_18524/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lw,"id","transformers.FlaxAutoModelForPreTraining"),c(Lw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Lw,"href","#transformers.FlaxAutoModelForPreTraining"),c(mf,"class","relative group"),c(dre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mre,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(gre,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(hre,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(pre,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(_re,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(ure,"href","/docs/transformers/pr_18524/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(bre,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(vre,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Fre,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Tre,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Mre,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Ere,"href","/docs/transformers/pr_18524/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(Cre,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vw,"id","transformers.FlaxAutoModelForMaskedLM"),c(Vw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vw,"href","#transformers.FlaxAutoModelForMaskedLM"),c(pf,"class","relative group"),c(wre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Are,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Lre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yre,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(xre,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c($re,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(kre,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Sre,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Rre,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Pre,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Bre,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Ire,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Nre,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r6,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(r6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r6,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(bf,"class","relative group"),c(qre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Dre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gre,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Ore,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Vre,"href","/docs/transformers/pr_18524/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Xre,"href","/docs/transformers/pr_18524/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(zre,"href","/docs/transformers/pr_18524/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Wre,"href","/docs/transformers/pr_18524/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Qre,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ure,"href","/docs/transformers/pr_18524/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Hre,"href","/docs/transformers/pr_18524/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(Jre,"href","/docs/transformers/pr_18524/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p6,"id","transformers.FlaxAutoModelForSequenceClassification"),c(p6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p6,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Tf,"class","relative group"),c(Yre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zre,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ete,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(ote,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(rte,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(tte,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(ate,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(nte,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(ste,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(lte,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(ite,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(dte,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y6,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(y6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y6,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Cf,"class","relative group"),c(cte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gte,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(hte,"href","/docs/transformers/pr_18524/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(pte,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(_te,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(ute,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(bte,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(vte,"href","/docs/transformers/pr_18524/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Fte,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Tte,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Mte,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G6,"id","transformers.FlaxAutoModelForTokenClassification"),c(G6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G6,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Lf,"class","relative group"),c(Ete,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Cte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ate,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Lte,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(yte,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(xte,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c($te,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(kte,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Ste,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Rte,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(K6,"id","transformers.FlaxAutoModelForMultipleChoice"),c(K6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(K6,"href","#transformers.FlaxAutoModelForMultipleChoice"),c($f,"class","relative group"),c(Pte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ite,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Nte,"href","/docs/transformers/pr_18524/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(qte,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(jte,"href","/docs/transformers/pr_18524/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Dte,"href","/docs/transformers/pr_18524/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Gte,"href","/docs/transformers/pr_18524/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Ote,"href","/docs/transformers/pr_18524/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Vte,"href","/docs/transformers/pr_18524/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Xte,"href","/docs/transformers/pr_18524/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dA,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(dA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dA,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Rf,"class","relative group"),c(zte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Qte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ute,"href","/docs/transformers/pr_18524/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gA,"id","transformers.FlaxAutoModelForImageClassification"),c(gA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gA,"href","#transformers.FlaxAutoModelForImageClassification"),c(If,"class","relative group"),c(Hte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Yte,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kte,"href","/docs/transformers/pr_18524/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(Zte,"href","/docs/transformers/pr_18524/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(bA,"id","transformers.FlaxAutoModelForVision2Seq"),c(bA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(bA,"href","#transformers.FlaxAutoModelForVision2Seq"),c(jf,"class","relative group"),c(eae,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oae,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rae,"href","/docs/transformers/pr_18524/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tae,"href","/docs/transformers/pr_18524/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Ao),e(Ao,Ii),b(f,zf,u),b(f,dt,u),e(dt,Ni),e(dt,qi),e(qi,VL),e(dt,Wf),b(f,Oe,u),b(f,Qe,u),e(Qe,ji),e(Qe,Dn),e(Dn,XL),e(Qe,Gn),e(Qe,On),e(On,zL),e(Qe,Di),e(Qe,Vn),e(Vn,WL),e(Qe,Gi),b(f,Qf,u),M(Ia,f,u),b(f,Ue,u),b(f,Ae,u),e(Ae,kR),e(Ae,Oi),e(Oi,SR),e(Ae,RR),b(f,Lo,u),b(f,Na,u),e(Na,PR),e(Na,Uf),e(Uf,BR),e(Na,aYe),b(f,jWe,u),b(f,Vi,u),e(Vi,Hf),e(Hf,Zne),M(QL,Zne,null),e(Vi,nYe),e(Vi,ese),e(ese,sYe),b(f,DWe,u),b(f,Xn,u),e(Xn,lYe),e(Xn,ose),e(ose,iYe),e(Xn,dYe),e(Xn,rse),e(rse,cYe),e(Xn,fYe),b(f,GWe,u),M(UL,f,u),b(f,OWe,u),b(f,IR,u),e(IR,mYe),b(f,VWe,u),M(Jf,f,u),b(f,XWe,u),b(f,Xi,u),e(Xi,Yf),e(Yf,tse),M(HL,tse,null),e(Xi,gYe),e(Xi,ase),e(ase,hYe),b(f,zWe,u),b(f,yo,u),M(JL,yo,null),e(yo,pYe),e(yo,YL),e(YL,_Ye),e(YL,NR),e(NR,uYe),e(YL,bYe),e(yo,vYe),e(yo,KL),e(KL,FYe),e(KL,nse),e(nse,TYe),e(KL,MYe),e(yo,EYe),e(yo,$r),M(ZL,$r,null),e($r,CYe),e($r,sse),e(sse,wYe),e($r,AYe),e($r,zi),e(zi,LYe),e(zi,lse),e(lse,yYe),e(zi,xYe),e(zi,ise),e(ise,$Ye),e(zi,kYe),e($r,SYe),e($r,A),e(A,Kf),e(Kf,dse),e(dse,RYe),e(Kf,PYe),e(Kf,qR),e(qR,BYe),e(Kf,IYe),e(A,NYe),e(A,Zf),e(Zf,cse),e(cse,qYe),e(Zf,jYe),e(Zf,jR),e(jR,DYe),e(Zf,GYe),e(A,OYe),e(A,em),e(em,fse),e(fse,VYe),e(em,XYe),e(em,DR),e(DR,zYe),e(em,WYe),e(A,QYe),e(A,om),e(om,mse),e(mse,UYe),e(om,HYe),e(om,GR),e(GR,JYe),e(om,YYe),e(A,KYe),e(A,rm),e(rm,gse),e(gse,ZYe),e(rm,eKe),e(rm,OR),e(OR,oKe),e(rm,rKe),e(A,tKe),e(A,tm),e(tm,hse),e(hse,aKe),e(tm,nKe),e(tm,VR),e(VR,sKe),e(tm,lKe),e(A,iKe),e(A,am),e(am,pse),e(pse,dKe),e(am,cKe),e(am,XR),e(XR,fKe),e(am,mKe),e(A,gKe),e(A,nm),e(nm,_se),e(_se,hKe),e(nm,pKe),e(nm,zR),e(zR,_Ke),e(nm,uKe),e(A,bKe),e(A,sm),e(sm,use),e(use,vKe),e(sm,FKe),e(sm,WR),e(WR,TKe),e(sm,MKe),e(A,EKe),e(A,lm),e(lm,bse),e(bse,CKe),e(lm,wKe),e(lm,QR),e(QR,AKe),e(lm,LKe),e(A,yKe),e(A,im),e(im,vse),e(vse,xKe),e(im,$Ke),e(im,UR),e(UR,kKe),e(im,SKe),e(A,RKe),e(A,dm),e(dm,Fse),e(Fse,PKe),e(dm,BKe),e(dm,HR),e(HR,IKe),e(dm,NKe),e(A,qKe),e(A,cm),e(cm,Tse),e(Tse,jKe),e(cm,DKe),e(cm,JR),e(JR,GKe),e(cm,OKe),e(A,VKe),e(A,fm),e(fm,Mse),e(Mse,XKe),e(fm,zKe),e(fm,YR),e(YR,WKe),e(fm,QKe),e(A,UKe),e(A,mm),e(mm,Ese),e(Ese,HKe),e(mm,JKe),e(mm,KR),e(KR,YKe),e(mm,KKe),e(A,ZKe),e(A,gm),e(gm,Cse),e(Cse,eZe),e(gm,oZe),e(gm,ZR),e(ZR,rZe),e(gm,tZe),e(A,aZe),e(A,hm),e(hm,wse),e(wse,nZe),e(hm,sZe),e(hm,eP),e(eP,lZe),e(hm,iZe),e(A,dZe),e(A,pm),e(pm,Ase),e(Ase,cZe),e(pm,fZe),e(pm,oP),e(oP,mZe),e(pm,gZe),e(A,hZe),e(A,_m),e(_m,Lse),e(Lse,pZe),e(_m,_Ze),e(_m,rP),e(rP,uZe),e(_m,bZe),e(A,vZe),e(A,um),e(um,yse),e(yse,FZe),e(um,TZe),e(um,tP),e(tP,MZe),e(um,EZe),e(A,CZe),e(A,bm),e(bm,xse),e(xse,wZe),e(bm,AZe),e(bm,aP),e(aP,LZe),e(bm,yZe),e(A,xZe),e(A,vm),e(vm,$se),e($se,$Ze),e(vm,kZe),e(vm,nP),e(nP,SZe),e(vm,RZe),e(A,PZe),e(A,Fm),e(Fm,kse),e(kse,BZe),e(Fm,IZe),e(Fm,sP),e(sP,NZe),e(Fm,qZe),e(A,jZe),e(A,Tm),e(Tm,Sse),e(Sse,DZe),e(Tm,GZe),e(Tm,lP),e(lP,OZe),e(Tm,VZe),e(A,XZe),e(A,Mm),e(Mm,Rse),e(Rse,zZe),e(Mm,WZe),e(Mm,iP),e(iP,QZe),e(Mm,UZe),e(A,HZe),e(A,Em),e(Em,Pse),e(Pse,JZe),e(Em,YZe),e(Em,dP),e(dP,KZe),e(Em,ZZe),e(A,eeo),e(A,Cm),e(Cm,Bse),e(Bse,oeo),e(Cm,reo),e(Cm,cP),e(cP,teo),e(Cm,aeo),e(A,neo),e(A,wm),e(wm,Ise),e(Ise,seo),e(wm,leo),e(wm,fP),e(fP,ieo),e(wm,deo),e(A,ceo),e(A,Am),e(Am,Nse),e(Nse,feo),e(Am,meo),e(Am,mP),e(mP,geo),e(Am,heo),e(A,peo),e(A,Lm),e(Lm,qse),e(qse,_eo),e(Lm,ueo),e(Lm,gP),e(gP,beo),e(Lm,veo),e(A,Feo),e(A,ym),e(ym,jse),e(jse,Teo),e(ym,Meo),e(ym,hP),e(hP,Eeo),e(ym,Ceo),e(A,weo),e(A,xm),e(xm,Dse),e(Dse,Aeo),e(xm,Leo),e(xm,pP),e(pP,yeo),e(xm,xeo),e(A,$eo),e(A,$m),e($m,Gse),e(Gse,keo),e($m,Seo),e($m,_P),e(_P,Reo),e($m,Peo),e(A,Beo),e(A,km),e(km,Ose),e(Ose,Ieo),e(km,Neo),e(km,uP),e(uP,qeo),e(km,jeo),e(A,Deo),e(A,Sm),e(Sm,Vse),e(Vse,Geo),e(Sm,Oeo),e(Sm,bP),e(bP,Veo),e(Sm,Xeo),e(A,zeo),e(A,Rm),e(Rm,Xse),e(Xse,Weo),e(Rm,Qeo),e(Rm,vP),e(vP,Ueo),e(Rm,Heo),e(A,Jeo),e(A,Pm),e(Pm,zse),e(zse,Yeo),e(Pm,Keo),e(Pm,FP),e(FP,Zeo),e(Pm,eoo),e(A,ooo),e(A,Bm),e(Bm,Wse),e(Wse,roo),e(Bm,too),e(Bm,TP),e(TP,aoo),e(Bm,noo),e(A,soo),e(A,Im),e(Im,Qse),e(Qse,loo),e(Im,ioo),e(Im,MP),e(MP,doo),e(Im,coo),e(A,foo),e(A,Nm),e(Nm,Use),e(Use,moo),e(Nm,goo),e(Nm,EP),e(EP,hoo),e(Nm,poo),e(A,_oo),e(A,qm),e(qm,Hse),e(Hse,uoo),e(qm,boo),e(qm,CP),e(CP,voo),e(qm,Foo),e(A,Too),e(A,jm),e(jm,Jse),e(Jse,Moo),e(jm,Eoo),e(jm,wP),e(wP,Coo),e(jm,woo),e(A,Aoo),e(A,Dm),e(Dm,Yse),e(Yse,Loo),e(Dm,yoo),e(Dm,AP),e(AP,xoo),e(Dm,$oo),e(A,koo),e(A,Gm),e(Gm,Kse),e(Kse,Soo),e(Gm,Roo),e(Gm,LP),e(LP,Poo),e(Gm,Boo),e(A,Ioo),e(A,Om),e(Om,Zse),e(Zse,Noo),e(Om,qoo),e(Om,yP),e(yP,joo),e(Om,Doo),e(A,Goo),e(A,Vm),e(Vm,ele),e(ele,Ooo),e(Vm,Voo),e(Vm,xP),e(xP,Xoo),e(Vm,zoo),e(A,Woo),e(A,Xm),e(Xm,ole),e(ole,Qoo),e(Xm,Uoo),e(Xm,$P),e($P,Hoo),e(Xm,Joo),e(A,Yoo),e(A,zm),e(zm,rle),e(rle,Koo),e(zm,Zoo),e(zm,kP),e(kP,ero),e(zm,oro),e(A,rro),e(A,Wm),e(Wm,tle),e(tle,tro),e(Wm,aro),e(Wm,SP),e(SP,nro),e(Wm,sro),e(A,lro),e(A,Qm),e(Qm,ale),e(ale,iro),e(Qm,dro),e(Qm,RP),e(RP,cro),e(Qm,fro),e(A,mro),e(A,Um),e(Um,nle),e(nle,gro),e(Um,hro),e(Um,PP),e(PP,pro),e(Um,_ro),e(A,uro),e(A,Hm),e(Hm,sle),e(sle,bro),e(Hm,vro),e(Hm,BP),e(BP,Fro),e(Hm,Tro),e(A,Mro),e(A,Jm),e(Jm,lle),e(lle,Ero),e(Jm,Cro),e(Jm,IP),e(IP,wro),e(Jm,Aro),e(A,Lro),e(A,Ym),e(Ym,ile),e(ile,yro),e(Ym,xro),e(Ym,NP),e(NP,$ro),e(Ym,kro),e(A,Sro),e(A,Km),e(Km,dle),e(dle,Rro),e(Km,Pro),e(Km,qP),e(qP,Bro),e(Km,Iro),e(A,Nro),e(A,Zm),e(Zm,cle),e(cle,qro),e(Zm,jro),e(Zm,jP),e(jP,Dro),e(Zm,Gro),e(A,Oro),e(A,eg),e(eg,fle),e(fle,Vro),e(eg,Xro),e(eg,DP),e(DP,zro),e(eg,Wro),e(A,Qro),e(A,og),e(og,mle),e(mle,Uro),e(og,Hro),e(og,GP),e(GP,Jro),e(og,Yro),e(A,Kro),e(A,rg),e(rg,gle),e(gle,Zro),e(rg,eto),e(rg,OP),e(OP,oto),e(rg,rto),e(A,tto),e(A,tg),e(tg,hle),e(hle,ato),e(tg,nto),e(tg,VP),e(VP,sto),e(tg,lto),e(A,ito),e(A,ag),e(ag,ple),e(ple,dto),e(ag,cto),e(ag,XP),e(XP,fto),e(ag,mto),e(A,gto),e(A,ng),e(ng,_le),e(_le,hto),e(ng,pto),e(ng,zP),e(zP,_to),e(ng,uto),e(A,bto),e(A,sg),e(sg,ule),e(ule,vto),e(sg,Fto),e(sg,WP),e(WP,Tto),e(sg,Mto),e(A,Eto),e(A,lg),e(lg,ble),e(ble,Cto),e(lg,wto),e(lg,QP),e(QP,Ato),e(lg,Lto),e(A,yto),e(A,ig),e(ig,vle),e(vle,xto),e(ig,$to),e(ig,UP),e(UP,kto),e(ig,Sto),e(A,Rto),e(A,dg),e(dg,Fle),e(Fle,Pto),e(dg,Bto),e(dg,HP),e(HP,Ito),e(dg,Nto),e(A,qto),e(A,cg),e(cg,Tle),e(Tle,jto),e(cg,Dto),e(cg,JP),e(JP,Gto),e(cg,Oto),e(A,Vto),e(A,fg),e(fg,Mle),e(Mle,Xto),e(fg,zto),e(fg,YP),e(YP,Wto),e(fg,Qto),e(A,Uto),e(A,mg),e(mg,Ele),e(Ele,Hto),e(mg,Jto),e(mg,KP),e(KP,Yto),e(mg,Kto),e(A,Zto),e(A,gg),e(gg,Cle),e(Cle,eao),e(gg,oao),e(gg,ZP),e(ZP,rao),e(gg,tao),e(A,aao),e(A,hg),e(hg,wle),e(wle,nao),e(hg,sao),e(hg,eB),e(eB,lao),e(hg,iao),e(A,dao),e(A,pg),e(pg,Ale),e(Ale,cao),e(pg,fao),e(pg,oB),e(oB,mao),e(pg,gao),e(A,hao),e(A,_g),e(_g,Lle),e(Lle,pao),e(_g,_ao),e(_g,rB),e(rB,uao),e(_g,bao),e(A,vao),e(A,ug),e(ug,yle),e(yle,Fao),e(ug,Tao),e(ug,tB),e(tB,Mao),e(ug,Eao),e(A,Cao),e(A,bg),e(bg,xle),e(xle,wao),e(bg,Aao),e(bg,aB),e(aB,Lao),e(bg,yao),e(A,xao),e(A,vg),e(vg,$le),e($le,$ao),e(vg,kao),e(vg,nB),e(nB,Sao),e(vg,Rao),e(A,Pao),e(A,Fg),e(Fg,kle),e(kle,Bao),e(Fg,Iao),e(Fg,sB),e(sB,Nao),e(Fg,qao),e(A,jao),e(A,Tg),e(Tg,Sle),e(Sle,Dao),e(Tg,Gao),e(Tg,lB),e(lB,Oao),e(Tg,Vao),e(A,Xao),e(A,Mg),e(Mg,Rle),e(Rle,zao),e(Mg,Wao),e(Mg,iB),e(iB,Qao),e(Mg,Uao),e(A,Hao),e(A,Eg),e(Eg,Ple),e(Ple,Jao),e(Eg,Yao),e(Eg,dB),e(dB,Kao),e(Eg,Zao),e(A,eno),e(A,Cg),e(Cg,Ble),e(Ble,ono),e(Cg,rno),e(Cg,cB),e(cB,tno),e(Cg,ano),e(A,nno),e(A,wg),e(wg,Ile),e(Ile,sno),e(wg,lno),e(wg,fB),e(fB,ino),e(wg,dno),e(A,cno),e(A,Ag),e(Ag,Nle),e(Nle,fno),e(Ag,mno),e(Ag,mB),e(mB,gno),e(Ag,hno),e(A,pno),e(A,Lg),e(Lg,qle),e(qle,_no),e(Lg,uno),e(Lg,gB),e(gB,bno),e(Lg,vno),e(A,Fno),e(A,yg),e(yg,jle),e(jle,Tno),e(yg,Mno),e(yg,hB),e(hB,Eno),e(yg,Cno),e(A,wno),e(A,xg),e(xg,Dle),e(Dle,Ano),e(xg,Lno),e(xg,pB),e(pB,yno),e(xg,xno),e(A,$no),e(A,$g),e($g,Gle),e(Gle,kno),e($g,Sno),e($g,_B),e(_B,Rno),e($g,Pno),e(A,Bno),e(A,kg),e(kg,Ole),e(Ole,Ino),e(kg,Nno),e(kg,uB),e(uB,qno),e(kg,jno),e(A,Dno),e(A,Sg),e(Sg,Vle),e(Vle,Gno),e(Sg,Ono),e(Sg,bB),e(bB,Vno),e(Sg,Xno),e(A,zno),e(A,Rg),e(Rg,Xle),e(Xle,Wno),e(Rg,Qno),e(Rg,vB),e(vB,Uno),e(Rg,Hno),e(A,Jno),e(A,Pg),e(Pg,zle),e(zle,Yno),e(Pg,Kno),e(Pg,FB),e(FB,Zno),e(Pg,eso),e(A,oso),e(A,Bg),e(Bg,Wle),e(Wle,rso),e(Bg,tso),e(Bg,TB),e(TB,aso),e(Bg,nso),e(A,sso),e(A,Ig),e(Ig,Qle),e(Qle,lso),e(Ig,iso),e(Ig,MB),e(MB,dso),e(Ig,cso),e(A,fso),e(A,Ng),e(Ng,Ule),e(Ule,mso),e(Ng,gso),e(Ng,EB),e(EB,hso),e(Ng,pso),e(A,_so),e(A,qg),e(qg,Hle),e(Hle,uso),e(qg,bso),e(qg,CB),e(CB,vso),e(qg,Fso),e(A,Tso),e(A,jg),e(jg,Jle),e(Jle,Mso),e(jg,Eso),e(jg,wB),e(wB,Cso),e(jg,wso),e(A,Aso),e(A,Dg),e(Dg,Yle),e(Yle,Lso),e(Dg,yso),e(Dg,AB),e(AB,xso),e(Dg,$so),e(A,kso),e(A,Gg),e(Gg,Kle),e(Kle,Sso),e(Gg,Rso),e(Gg,LB),e(LB,Pso),e(Gg,Bso),e(A,Iso),e(A,Og),e(Og,Zle),e(Zle,Nso),e(Og,qso),e(Og,yB),e(yB,jso),e(Og,Dso),e(A,Gso),e(A,Vg),e(Vg,eie),e(eie,Oso),e(Vg,Vso),e(Vg,xB),e(xB,Xso),e(Vg,zso),e(A,Wso),e(A,Xg),e(Xg,oie),e(oie,Qso),e(Xg,Uso),e(Xg,$B),e($B,Hso),e(Xg,Jso),e(A,Yso),e(A,zg),e(zg,rie),e(rie,Kso),e(zg,Zso),e(zg,kB),e(kB,elo),e(zg,olo),e(A,rlo),e(A,Wg),e(Wg,tie),e(tie,tlo),e(Wg,alo),e(Wg,SB),e(SB,nlo),e(Wg,slo),e(A,llo),e(A,Qg),e(Qg,aie),e(aie,ilo),e(Qg,dlo),e(Qg,RB),e(RB,clo),e(Qg,flo),e(A,mlo),e(A,Ug),e(Ug,nie),e(nie,glo),e(Ug,hlo),e(Ug,PB),e(PB,plo),e(Ug,_lo),e(A,ulo),e(A,Hg),e(Hg,sie),e(sie,blo),e(Hg,vlo),e(Hg,BB),e(BB,Flo),e(Hg,Tlo),e(A,Mlo),e(A,Jg),e(Jg,lie),e(lie,Elo),e(Jg,Clo),e(Jg,IB),e(IB,wlo),e(Jg,Alo),e(A,Llo),e(A,Yg),e(Yg,iie),e(iie,ylo),e(Yg,xlo),e(Yg,NB),e(NB,$lo),e(Yg,klo),e(A,Slo),e(A,Kg),e(Kg,die),e(die,Rlo),e(Kg,Plo),e(Kg,qB),e(qB,Blo),e(Kg,Ilo),e(A,Nlo),e(A,Zg),e(Zg,cie),e(cie,qlo),e(Zg,jlo),e(Zg,jB),e(jB,Dlo),e(Zg,Glo),e(A,Olo),e(A,eh),e(eh,fie),e(fie,Vlo),e(eh,Xlo),e(eh,DB),e(DB,zlo),e(eh,Wlo),e(A,Qlo),e(A,oh),e(oh,mie),e(mie,Ulo),e(oh,Hlo),e(oh,GB),e(GB,Jlo),e(oh,Ylo),e(A,Klo),e(A,rh),e(rh,gie),e(gie,Zlo),e(rh,eio),e(rh,OB),e(OB,oio),e(rh,rio),e(A,tio),e(A,th),e(th,hie),e(hie,aio),e(th,nio),e(th,VB),e(VB,sio),e(th,lio),e(A,iio),e(A,ah),e(ah,pie),e(pie,dio),e(ah,cio),e(ah,XB),e(XB,fio),e(ah,mio),e(A,gio),e(A,nh),e(nh,_ie),e(_ie,hio),e(nh,pio),e(nh,zB),e(zB,_io),e(nh,uio),e(A,bio),e(A,sh),e(sh,uie),e(uie,vio),e(sh,Fio),e(sh,WB),e(WB,Tio),e(sh,Mio),e(A,Eio),e(A,lh),e(lh,bie),e(bie,Cio),e(lh,wio),e(lh,QB),e(QB,Aio),e(lh,Lio),e(A,yio),e(A,ih),e(ih,vie),e(vie,xio),e(ih,$io),e(ih,UB),e(UB,kio),e(ih,Sio),e(A,Rio),e(A,dh),e(dh,Fie),e(Fie,Pio),e(dh,Bio),e(dh,HB),e(HB,Iio),e(dh,Nio),e(A,qio),e(A,ch),e(ch,Tie),e(Tie,jio),e(ch,Dio),e(ch,JB),e(JB,Gio),e(ch,Oio),e($r,Vio),M(fh,$r,null),e(yo,Xio),e(yo,mh),M(ey,mh,null),e(mh,zio),e(mh,Mie),e(Mie,Wio),b(f,WWe,u),b(f,Wi,u),e(Wi,gh),e(gh,Eie),M(oy,Eie,null),e(Wi,Qio),e(Wi,Cie),e(Cie,Uio),b(f,QWe,u),b(f,xo,u),M(ry,xo,null),e(xo,Hio),e(xo,ty),e(ty,Jio),e(ty,YB),e(YB,Yio),e(ty,Kio),e(xo,Zio),e(xo,ay),e(ay,edo),e(ay,wie),e(wie,odo),e(ay,rdo),e(xo,tdo),e(xo,kr),M(ny,kr,null),e(kr,ado),e(kr,Aie),e(Aie,ndo),e(kr,sdo),e(kr,qa),e(qa,ldo),e(qa,Lie),e(Lie,ido),e(qa,ddo),e(qa,yie),e(yie,cdo),e(qa,fdo),e(qa,xie),e(xie,mdo),e(qa,gdo),e(kr,hdo),e(kr,k),e(k,zn),e(zn,$ie),e($ie,pdo),e(zn,_do),e(zn,KB),e(KB,udo),e(zn,bdo),e(zn,ZB),e(ZB,vdo),e(zn,Fdo),e(k,Tdo),e(k,Wn),e(Wn,kie),e(kie,Mdo),e(Wn,Edo),e(Wn,eI),e(eI,Cdo),e(Wn,wdo),e(Wn,oI),e(oI,Ado),e(Wn,Ldo),e(k,ydo),e(k,Qn),e(Qn,Sie),e(Sie,xdo),e(Qn,$do),e(Qn,rI),e(rI,kdo),e(Qn,Sdo),e(Qn,tI),e(tI,Rdo),e(Qn,Pdo),e(k,Bdo),e(k,hh),e(hh,Rie),e(Rie,Ido),e(hh,Ndo),e(hh,aI),e(aI,qdo),e(hh,jdo),e(k,Ddo),e(k,Un),e(Un,Pie),e(Pie,Gdo),e(Un,Odo),e(Un,nI),e(nI,Vdo),e(Un,Xdo),e(Un,sI),e(sI,zdo),e(Un,Wdo),e(k,Qdo),e(k,ph),e(ph,Bie),e(Bie,Udo),e(ph,Hdo),e(ph,lI),e(lI,Jdo),e(ph,Ydo),e(k,Kdo),e(k,_h),e(_h,Iie),e(Iie,Zdo),e(_h,eco),e(_h,iI),e(iI,oco),e(_h,rco),e(k,tco),e(k,uh),e(uh,Nie),e(Nie,aco),e(uh,nco),e(uh,dI),e(dI,sco),e(uh,lco),e(k,ico),e(k,Hn),e(Hn,qie),e(qie,dco),e(Hn,cco),e(Hn,cI),e(cI,fco),e(Hn,mco),e(Hn,fI),e(fI,gco),e(Hn,hco),e(k,pco),e(k,Jn),e(Jn,jie),e(jie,_co),e(Jn,uco),e(Jn,mI),e(mI,bco),e(Jn,vco),e(Jn,gI),e(gI,Fco),e(Jn,Tco),e(k,Mco),e(k,Yn),e(Yn,Die),e(Die,Eco),e(Yn,Cco),e(Yn,hI),e(hI,wco),e(Yn,Aco),e(Yn,pI),e(pI,Lco),e(Yn,yco),e(k,xco),e(k,bh),e(bh,Gie),e(Gie,$co),e(bh,kco),e(bh,_I),e(_I,Sco),e(bh,Rco),e(k,Pco),e(k,vh),e(vh,Oie),e(Oie,Bco),e(vh,Ico),e(vh,uI),e(uI,Nco),e(vh,qco),e(k,jco),e(k,Fh),e(Fh,Vie),e(Vie,Dco),e(Fh,Gco),e(Fh,bI),e(bI,Oco),e(Fh,Vco),e(k,Xco),e(k,Kn),e(Kn,Xie),e(Xie,zco),e(Kn,Wco),e(Kn,vI),e(vI,Qco),e(Kn,Uco),e(Kn,FI),e(FI,Hco),e(Kn,Jco),e(k,Yco),e(k,Th),e(Th,zie),e(zie,Kco),e(Th,Zco),e(Th,TI),e(TI,efo),e(Th,ofo),e(k,rfo),e(k,Zn),e(Zn,Wie),e(Wie,tfo),e(Zn,afo),e(Zn,MI),e(MI,nfo),e(Zn,sfo),e(Zn,EI),e(EI,lfo),e(Zn,ifo),e(k,dfo),e(k,es),e(es,Qie),e(Qie,cfo),e(es,ffo),e(es,CI),e(CI,mfo),e(es,gfo),e(es,wI),e(wI,hfo),e(es,pfo),e(k,_fo),e(k,os),e(os,Uie),e(Uie,ufo),e(os,bfo),e(os,AI),e(AI,vfo),e(os,Ffo),e(os,LI),e(LI,Tfo),e(os,Mfo),e(k,Efo),e(k,rs),e(rs,Hie),e(Hie,Cfo),e(rs,wfo),e(rs,yI),e(yI,Afo),e(rs,Lfo),e(rs,xI),e(xI,yfo),e(rs,xfo),e(k,$fo),e(k,Mh),e(Mh,Jie),e(Jie,kfo),e(Mh,Sfo),e(Mh,$I),e($I,Rfo),e(Mh,Pfo),e(k,Bfo),e(k,ts),e(ts,Yie),e(Yie,Ifo),e(ts,Nfo),e(ts,kI),e(kI,qfo),e(ts,jfo),e(ts,SI),e(SI,Dfo),e(ts,Gfo),e(k,Ofo),e(k,as),e(as,Kie),e(Kie,Vfo),e(as,Xfo),e(as,RI),e(RI,zfo),e(as,Wfo),e(as,PI),e(PI,Qfo),e(as,Ufo),e(k,Hfo),e(k,ns),e(ns,Zie),e(Zie,Jfo),e(ns,Yfo),e(ns,BI),e(BI,Kfo),e(ns,Zfo),e(ns,II),e(II,emo),e(ns,omo),e(k,rmo),e(k,ss),e(ss,ede),e(ede,tmo),e(ss,amo),e(ss,NI),e(NI,nmo),e(ss,smo),e(ss,qI),e(qI,lmo),e(ss,imo),e(k,dmo),e(k,ls),e(ls,ode),e(ode,cmo),e(ls,fmo),e(ls,jI),e(jI,mmo),e(ls,gmo),e(ls,DI),e(DI,hmo),e(ls,pmo),e(k,_mo),e(k,is),e(is,rde),e(rde,umo),e(is,bmo),e(is,GI),e(GI,vmo),e(is,Fmo),e(is,OI),e(OI,Tmo),e(is,Mmo),e(k,Emo),e(k,Eh),e(Eh,tde),e(tde,Cmo),e(Eh,wmo),e(Eh,VI),e(VI,Amo),e(Eh,Lmo),e(k,ymo),e(k,ds),e(ds,ade),e(ade,xmo),e(ds,$mo),e(ds,XI),e(XI,kmo),e(ds,Smo),e(ds,zI),e(zI,Rmo),e(ds,Pmo),e(k,Bmo),e(k,Ch),e(Ch,nde),e(nde,Imo),e(Ch,Nmo),e(Ch,WI),e(WI,qmo),e(Ch,jmo),e(k,Dmo),e(k,cs),e(cs,sde),e(sde,Gmo),e(cs,Omo),e(cs,QI),e(QI,Vmo),e(cs,Xmo),e(cs,UI),e(UI,zmo),e(cs,Wmo),e(k,Qmo),e(k,fs),e(fs,lde),e(lde,Umo),e(fs,Hmo),e(fs,HI),e(HI,Jmo),e(fs,Ymo),e(fs,JI),e(JI,Kmo),e(fs,Zmo),e(k,ego),e(k,ms),e(ms,ide),e(ide,ogo),e(ms,rgo),e(ms,YI),e(YI,tgo),e(ms,ago),e(ms,KI),e(KI,ngo),e(ms,sgo),e(k,lgo),e(k,wh),e(wh,dde),e(dde,igo),e(wh,dgo),e(wh,ZI),e(ZI,cgo),e(wh,fgo),e(k,mgo),e(k,gs),e(gs,cde),e(cde,ggo),e(gs,hgo),e(gs,eN),e(eN,pgo),e(gs,_go),e(gs,oN),e(oN,ugo),e(gs,bgo),e(k,vgo),e(k,hs),e(hs,fde),e(fde,Fgo),e(hs,Tgo),e(hs,rN),e(rN,Mgo),e(hs,Ego),e(hs,tN),e(tN,Cgo),e(hs,wgo),e(k,Ago),e(k,ps),e(ps,mde),e(mde,Lgo),e(ps,ygo),e(ps,aN),e(aN,xgo),e(ps,$go),e(ps,nN),e(nN,kgo),e(ps,Sgo),e(k,Rgo),e(k,Ah),e(Ah,gde),e(gde,Pgo),e(Ah,Bgo),e(Ah,sN),e(sN,Igo),e(Ah,Ngo),e(k,qgo),e(k,_s),e(_s,hde),e(hde,jgo),e(_s,Dgo),e(_s,lN),e(lN,Ggo),e(_s,Ogo),e(_s,iN),e(iN,Vgo),e(_s,Xgo),e(k,zgo),e(k,us),e(us,pde),e(pde,Wgo),e(us,Qgo),e(us,dN),e(dN,Ugo),e(us,Hgo),e(us,cN),e(cN,Jgo),e(us,Ygo),e(k,Kgo),e(k,bs),e(bs,_de),e(_de,Zgo),e(bs,eho),e(bs,fN),e(fN,oho),e(bs,rho),e(bs,mN),e(mN,tho),e(bs,aho),e(k,nho),e(k,vs),e(vs,ude),e(ude,sho),e(vs,lho),e(vs,gN),e(gN,iho),e(vs,dho),e(vs,hN),e(hN,cho),e(vs,fho),e(k,mho),e(k,Fs),e(Fs,bde),e(bde,gho),e(Fs,hho),e(Fs,pN),e(pN,pho),e(Fs,_ho),e(Fs,_N),e(_N,uho),e(Fs,bho),e(k,vho),e(k,Ts),e(Ts,vde),e(vde,Fho),e(Ts,Tho),e(Ts,uN),e(uN,Mho),e(Ts,Eho),e(Ts,bN),e(bN,Cho),e(Ts,who),e(k,Aho),e(k,Ms),e(Ms,Fde),e(Fde,Lho),e(Ms,yho),e(Ms,vN),e(vN,xho),e(Ms,$ho),e(Ms,FN),e(FN,kho),e(Ms,Sho),e(k,Rho),e(k,Es),e(Es,Tde),e(Tde,Pho),e(Es,Bho),e(Es,TN),e(TN,Iho),e(Es,Nho),e(Es,MN),e(MN,qho),e(Es,jho),e(k,Dho),e(k,Lh),e(Lh,Mde),e(Mde,Gho),e(Lh,Oho),e(Lh,EN),e(EN,Vho),e(Lh,Xho),e(k,zho),e(k,Cs),e(Cs,Ede),e(Ede,Who),e(Cs,Qho),e(Cs,CN),e(CN,Uho),e(Cs,Hho),e(Cs,wN),e(wN,Jho),e(Cs,Yho),e(k,Kho),e(k,yh),e(yh,Cde),e(Cde,Zho),e(yh,epo),e(yh,AN),e(AN,opo),e(yh,rpo),e(k,tpo),e(k,xh),e(xh,wde),e(wde,apo),e(xh,npo),e(xh,LN),e(LN,spo),e(xh,lpo),e(k,ipo),e(k,ws),e(ws,Ade),e(Ade,dpo),e(ws,cpo),e(ws,yN),e(yN,fpo),e(ws,mpo),e(ws,xN),e(xN,gpo),e(ws,hpo),e(k,ppo),e(k,As),e(As,Lde),e(Lde,_po),e(As,upo),e(As,$N),e($N,bpo),e(As,vpo),e(As,kN),e(kN,Fpo),e(As,Tpo),e(k,Mpo),e(k,Ls),e(Ls,yde),e(yde,Epo),e(Ls,Cpo),e(Ls,SN),e(SN,wpo),e(Ls,Apo),e(Ls,RN),e(RN,Lpo),e(Ls,ypo),e(k,xpo),e(k,$h),e($h,xde),e(xde,$po),e($h,kpo),e($h,PN),e(PN,Spo),e($h,Rpo),e(k,Ppo),e(k,ys),e(ys,$de),e($de,Bpo),e(ys,Ipo),e(ys,BN),e(BN,Npo),e(ys,qpo),e(ys,IN),e(IN,jpo),e(ys,Dpo),e(k,Gpo),e(k,xs),e(xs,kde),e(kde,Opo),e(xs,Vpo),e(xs,NN),e(NN,Xpo),e(xs,zpo),e(xs,qN),e(qN,Wpo),e(xs,Qpo),e(k,Upo),e(k,$s),e($s,Sde),e(Sde,Hpo),e($s,Jpo),e($s,jN),e(jN,Ypo),e($s,Kpo),e($s,DN),e(DN,Zpo),e($s,e_o),e(k,o_o),e(k,ks),e(ks,Rde),e(Rde,r_o),e(ks,t_o),e(ks,GN),e(GN,a_o),e(ks,n_o),e(ks,ON),e(ON,s_o),e(ks,l_o),e(k,i_o),e(k,Ss),e(Ss,Pde),e(Pde,d_o),e(Ss,c_o),e(Ss,VN),e(VN,f_o),e(Ss,m_o),e(Ss,XN),e(XN,g_o),e(Ss,h_o),e(k,p_o),e(k,Rs),e(Rs,Bde),e(Bde,__o),e(Rs,u_o),e(Rs,zN),e(zN,b_o),e(Rs,v_o),e(Rs,WN),e(WN,F_o),e(Rs,T_o),e(k,M_o),e(k,Ps),e(Ps,Ide),e(Ide,E_o),e(Ps,C_o),e(Ps,QN),e(QN,w_o),e(Ps,A_o),e(Ps,UN),e(UN,L_o),e(Ps,y_o),e(k,x_o),e(k,Bs),e(Bs,Nde),e(Nde,$_o),e(Bs,k_o),e(Bs,HN),e(HN,S_o),e(Bs,R_o),e(Bs,JN),e(JN,P_o),e(Bs,B_o),e(k,I_o),e(k,kh),e(kh,qde),e(qde,N_o),e(kh,q_o),e(kh,YN),e(YN,j_o),e(kh,D_o),e(k,G_o),e(k,Is),e(Is,jde),e(jde,O_o),e(Is,V_o),e(Is,KN),e(KN,X_o),e(Is,z_o),e(Is,ZN),e(ZN,W_o),e(Is,Q_o),e(k,U_o),e(k,Ns),e(Ns,Dde),e(Dde,H_o),e(Ns,J_o),e(Ns,eq),e(eq,Y_o),e(Ns,K_o),e(Ns,oq),e(oq,Z_o),e(Ns,euo),e(k,ouo),e(k,Sh),e(Sh,Gde),e(Gde,ruo),e(Sh,tuo),e(Sh,rq),e(rq,auo),e(Sh,nuo),e(k,suo),e(k,Rh),e(Rh,Ode),e(Ode,luo),e(Rh,iuo),e(Rh,tq),e(tq,duo),e(Rh,cuo),e(k,fuo),e(k,Ph),e(Ph,Vde),e(Vde,muo),e(Ph,guo),e(Ph,aq),e(aq,huo),e(Ph,puo),e(k,_uo),e(k,Bh),e(Bh,Xde),e(Xde,uuo),e(Bh,buo),e(Bh,nq),e(nq,vuo),e(Bh,Fuo),e(k,Tuo),e(k,qs),e(qs,zde),e(zde,Muo),e(qs,Euo),e(qs,sq),e(sq,Cuo),e(qs,wuo),e(qs,lq),e(lq,Auo),e(qs,Luo),e(k,yuo),e(k,Ih),e(Ih,Wde),e(Wde,xuo),e(Ih,$uo),e(Ih,iq),e(iq,kuo),e(Ih,Suo),e(k,Ruo),e(k,js),e(js,Qde),e(Qde,Puo),e(js,Buo),e(js,dq),e(dq,Iuo),e(js,Nuo),e(js,cq),e(cq,quo),e(js,juo),e(k,Duo),e(k,Ds),e(Ds,Ude),e(Ude,Guo),e(Ds,Ouo),e(Ds,fq),e(fq,Vuo),e(Ds,Xuo),e(Ds,mq),e(mq,zuo),e(Ds,Wuo),e(k,Quo),e(k,Gs),e(Gs,Hde),e(Hde,Uuo),e(Gs,Huo),e(Gs,gq),e(gq,Juo),e(Gs,Yuo),e(Gs,hq),e(hq,Kuo),e(Gs,Zuo),e(k,e2o),e(k,Os),e(Os,Jde),e(Jde,o2o),e(Os,r2o),e(Os,pq),e(pq,t2o),e(Os,a2o),e(Os,_q),e(_q,n2o),e(Os,s2o),e(k,l2o),e(k,Vs),e(Vs,Yde),e(Yde,i2o),e(Vs,d2o),e(Vs,uq),e(uq,c2o),e(Vs,f2o),e(Vs,bq),e(bq,m2o),e(Vs,g2o),e(k,h2o),e(k,Xs),e(Xs,Kde),e(Kde,p2o),e(Xs,_2o),e(Xs,vq),e(vq,u2o),e(Xs,b2o),e(Xs,Fq),e(Fq,v2o),e(Xs,F2o),e(k,T2o),e(k,Nh),e(Nh,Zde),e(Zde,M2o),e(Nh,E2o),e(Nh,Tq),e(Tq,C2o),e(Nh,w2o),e(k,A2o),e(k,qh),e(qh,ece),e(ece,L2o),e(qh,y2o),e(qh,Mq),e(Mq,x2o),e(qh,$2o),e(k,k2o),e(k,zs),e(zs,oce),e(oce,S2o),e(zs,R2o),e(zs,Eq),e(Eq,P2o),e(zs,B2o),e(zs,Cq),e(Cq,I2o),e(zs,N2o),e(k,q2o),e(k,Ws),e(Ws,rce),e(rce,j2o),e(Ws,D2o),e(Ws,wq),e(wq,G2o),e(Ws,O2o),e(Ws,Aq),e(Aq,V2o),e(Ws,X2o),e(k,z2o),e(k,Qs),e(Qs,tce),e(tce,W2o),e(Qs,Q2o),e(Qs,Lq),e(Lq,U2o),e(Qs,H2o),e(Qs,yq),e(yq,J2o),e(Qs,Y2o),e(k,K2o),e(k,jh),e(jh,ace),e(ace,Z2o),e(jh,e1o),e(jh,xq),e(xq,o1o),e(jh,r1o),e(k,t1o),e(k,Dh),e(Dh,nce),e(nce,a1o),e(Dh,n1o),e(Dh,$q),e($q,s1o),e(Dh,l1o),e(k,i1o),e(k,Gh),e(Gh,sce),e(sce,d1o),e(Gh,c1o),e(Gh,kq),e(kq,f1o),e(Gh,m1o),e(k,g1o),e(k,Us),e(Us,lce),e(lce,h1o),e(Us,p1o),e(Us,Sq),e(Sq,_1o),e(Us,u1o),e(Us,Rq),e(Rq,b1o),e(Us,v1o),e(k,F1o),e(k,Hs),e(Hs,ice),e(ice,T1o),e(Hs,M1o),e(Hs,Pq),e(Pq,E1o),e(Hs,C1o),e(Hs,Bq),e(Bq,w1o),e(Hs,A1o),e(k,L1o),e(k,Oh),e(Oh,dce),e(dce,y1o),e(Oh,x1o),e(Oh,Iq),e(Iq,$1o),e(Oh,k1o),e(k,S1o),e(k,Vh),e(Vh,cce),e(cce,R1o),e(Vh,P1o),e(Vh,Nq),e(Nq,B1o),e(Vh,I1o),e(k,N1o),e(k,Xh),e(Xh,fce),e(fce,q1o),e(Xh,j1o),e(Xh,qq),e(qq,D1o),e(Xh,G1o),e(k,O1o),e(k,Js),e(Js,mce),e(mce,V1o),e(Js,X1o),e(Js,jq),e(jq,z1o),e(Js,W1o),e(Js,Dq),e(Dq,Q1o),e(Js,U1o),e(k,H1o),e(k,zh),e(zh,gce),e(gce,J1o),e(zh,Y1o),e(zh,Gq),e(Gq,K1o),e(zh,Z1o),e(k,e4o),e(k,Wh),e(Wh,hce),e(hce,o4o),e(Wh,r4o),e(Wh,Oq),e(Oq,t4o),e(Wh,a4o),e(k,n4o),e(k,Ys),e(Ys,pce),e(pce,s4o),e(Ys,l4o),e(Ys,Vq),e(Vq,i4o),e(Ys,d4o),e(Ys,Xq),e(Xq,c4o),e(Ys,f4o),e(k,m4o),e(k,Ks),e(Ks,_ce),e(_ce,g4o),e(Ks,h4o),e(Ks,zq),e(zq,p4o),e(Ks,_4o),e(Ks,Wq),e(Wq,u4o),e(Ks,b4o),e(k,v4o),e(k,Zs),e(Zs,uce),e(uce,F4o),e(Zs,T4o),e(Zs,Qq),e(Qq,M4o),e(Zs,E4o),e(Zs,Uq),e(Uq,C4o),e(Zs,w4o),e(k,A4o),e(k,el),e(el,bce),e(bce,L4o),e(el,y4o),e(el,Hq),e(Hq,x4o),e(el,$4o),e(el,Jq),e(Jq,k4o),e(el,S4o),e(kr,R4o),M(Qh,kr,null),e(xo,P4o),e(xo,Uh),M(sy,Uh,null),e(Uh,B4o),e(Uh,vce),e(vce,I4o),b(f,UWe,u),b(f,Qi,u),e(Qi,Hh),e(Hh,Fce),M(ly,Fce,null),e(Qi,N4o),e(Qi,Tce),e(Tce,q4o),b(f,HWe,u),b(f,$o,u),M(iy,$o,null),e($o,j4o),e($o,dy),e(dy,D4o),e(dy,Yq),e(Yq,G4o),e(dy,O4o),e($o,V4o),e($o,cy),e(cy,X4o),e(cy,Mce),e(Mce,z4o),e(cy,W4o),e($o,Q4o),e($o,He),M(fy,He,null),e(He,U4o),e(He,Ece),e(Ece,H4o),e(He,J4o),e(He,ja),e(ja,Y4o),e(ja,Cce),e(Cce,K4o),e(ja,Z4o),e(ja,wce),e(wce,ebo),e(ja,obo),e(ja,Ace),e(Ace,rbo),e(ja,tbo),e(He,abo),e(He,Q),e(Q,Jh),e(Jh,Lce),e(Lce,nbo),e(Jh,sbo),e(Jh,Kq),e(Kq,lbo),e(Jh,ibo),e(Q,dbo),e(Q,Yh),e(Yh,yce),e(yce,cbo),e(Yh,fbo),e(Yh,Zq),e(Zq,mbo),e(Yh,gbo),e(Q,hbo),e(Q,Kh),e(Kh,xce),e(xce,pbo),e(Kh,_bo),e(Kh,ej),e(ej,ubo),e(Kh,bbo),e(Q,vbo),e(Q,Zh),e(Zh,$ce),e($ce,Fbo),e(Zh,Tbo),e(Zh,oj),e(oj,Mbo),e(Zh,Ebo),e(Q,Cbo),e(Q,ep),e(ep,kce),e(kce,wbo),e(ep,Abo),e(ep,rj),e(rj,Lbo),e(ep,ybo),e(Q,xbo),e(Q,op),e(op,Sce),e(Sce,$bo),e(op,kbo),e(op,tj),e(tj,Sbo),e(op,Rbo),e(Q,Pbo),e(Q,rp),e(rp,Rce),e(Rce,Bbo),e(rp,Ibo),e(rp,aj),e(aj,Nbo),e(rp,qbo),e(Q,jbo),e(Q,tp),e(tp,Pce),e(Pce,Dbo),e(tp,Gbo),e(tp,nj),e(nj,Obo),e(tp,Vbo),e(Q,Xbo),e(Q,ap),e(ap,Bce),e(Bce,zbo),e(ap,Wbo),e(ap,sj),e(sj,Qbo),e(ap,Ubo),e(Q,Hbo),e(Q,np),e(np,Ice),e(Ice,Jbo),e(np,Ybo),e(np,lj),e(lj,Kbo),e(np,Zbo),e(Q,evo),e(Q,sp),e(sp,Nce),e(Nce,ovo),e(sp,rvo),e(sp,ij),e(ij,tvo),e(sp,avo),e(Q,nvo),e(Q,lp),e(lp,qce),e(qce,svo),e(lp,lvo),e(lp,dj),e(dj,ivo),e(lp,dvo),e(Q,cvo),e(Q,ip),e(ip,jce),e(jce,fvo),e(ip,mvo),e(ip,cj),e(cj,gvo),e(ip,hvo),e(Q,pvo),e(Q,dp),e(dp,Dce),e(Dce,_vo),e(dp,uvo),e(dp,fj),e(fj,bvo),e(dp,vvo),e(Q,Fvo),e(Q,cp),e(cp,Gce),e(Gce,Tvo),e(cp,Mvo),e(cp,mj),e(mj,Evo),e(cp,Cvo),e(Q,wvo),e(Q,fp),e(fp,Oce),e(Oce,Avo),e(fp,Lvo),e(fp,gj),e(gj,yvo),e(fp,xvo),e(Q,$vo),e(Q,mp),e(mp,Vce),e(Vce,kvo),e(mp,Svo),e(mp,hj),e(hj,Rvo),e(mp,Pvo),e(Q,Bvo),e(Q,gp),e(gp,Xce),e(Xce,Ivo),e(gp,Nvo),e(gp,zce),e(zce,qvo),e(gp,jvo),e(Q,Dvo),e(Q,hp),e(hp,Wce),e(Wce,Gvo),e(hp,Ovo),e(hp,pj),e(pj,Vvo),e(hp,Xvo),e(Q,zvo),e(Q,pp),e(pp,Qce),e(Qce,Wvo),e(pp,Qvo),e(pp,_j),e(_j,Uvo),e(pp,Hvo),e(Q,Jvo),e(Q,_p),e(_p,Uce),e(Uce,Yvo),e(_p,Kvo),e(_p,uj),e(uj,Zvo),e(_p,e5o),e(Q,o5o),e(Q,up),e(up,Hce),e(Hce,r5o),e(up,t5o),e(up,bj),e(bj,a5o),e(up,n5o),e(Q,s5o),e(Q,bp),e(bp,Jce),e(Jce,l5o),e(bp,i5o),e(bp,vj),e(vj,d5o),e(bp,c5o),e(Q,f5o),e(Q,vp),e(vp,Yce),e(Yce,m5o),e(vp,g5o),e(vp,Fj),e(Fj,h5o),e(vp,p5o),e(Q,_5o),e(Q,Fp),e(Fp,Kce),e(Kce,u5o),e(Fp,b5o),e(Fp,Tj),e(Tj,v5o),e(Fp,F5o),e(Q,T5o),e(Q,Tp),e(Tp,Zce),e(Zce,M5o),e(Tp,E5o),e(Tp,Mj),e(Mj,C5o),e(Tp,w5o),e(Q,A5o),e(Q,Mp),e(Mp,efe),e(efe,L5o),e(Mp,y5o),e(Mp,Ej),e(Ej,x5o),e(Mp,$5o),e(Q,k5o),e(Q,Ep),e(Ep,ofe),e(ofe,S5o),e(Ep,R5o),e(Ep,Cj),e(Cj,P5o),e(Ep,B5o),e(Q,I5o),e(Q,Cp),e(Cp,rfe),e(rfe,N5o),e(Cp,q5o),e(Cp,wj),e(wj,j5o),e(Cp,D5o),e(Q,G5o),e(Q,wp),e(wp,tfe),e(tfe,O5o),e(wp,V5o),e(wp,Aj),e(Aj,X5o),e(wp,z5o),e(Q,W5o),e(Q,Ap),e(Ap,afe),e(afe,Q5o),e(Ap,U5o),e(Ap,Lj),e(Lj,H5o),e(Ap,J5o),e(Q,Y5o),e(Q,Lp),e(Lp,nfe),e(nfe,K5o),e(Lp,Z5o),e(Lp,yj),e(yj,eFo),e(Lp,oFo),e(Q,rFo),e(Q,yp),e(yp,sfe),e(sfe,tFo),e(yp,aFo),e(yp,xj),e(xj,nFo),e(yp,sFo),e(Q,lFo),e(Q,xp),e(xp,lfe),e(lfe,iFo),e(xp,dFo),e(xp,$j),e($j,cFo),e(xp,fFo),e(Q,mFo),e(Q,$p),e($p,ife),e(ife,gFo),e($p,hFo),e($p,kj),e(kj,pFo),e($p,_Fo),e(Q,uFo),e(Q,kp),e(kp,dfe),e(dfe,bFo),e(kp,vFo),e(kp,Sj),e(Sj,FFo),e(kp,TFo),e(Q,MFo),e(Q,Sp),e(Sp,cfe),e(cfe,EFo),e(Sp,CFo),e(Sp,Rj),e(Rj,wFo),e(Sp,AFo),e(Q,LFo),e(Q,Rp),e(Rp,ffe),e(ffe,yFo),e(Rp,xFo),e(Rp,Pj),e(Pj,$Fo),e(Rp,kFo),e(He,SFo),M(Pp,He,null),e(He,RFo),M(Bp,He,null),e($o,PFo),e($o,Ip),M(my,Ip,null),e(Ip,BFo),e(Ip,mfe),e(mfe,IFo),b(f,JWe,u),b(f,Ui,u),e(Ui,Np),e(Np,gfe),M(gy,gfe,null),e(Ui,NFo),e(Ui,hfe),e(hfe,qFo),b(f,YWe,u),b(f,ko,u),M(hy,ko,null),e(ko,jFo),e(ko,py),e(py,DFo),e(py,Bj),e(Bj,GFo),e(py,OFo),e(ko,VFo),e(ko,_y),e(_y,XFo),e(_y,pfe),e(pfe,zFo),e(_y,WFo),e(ko,QFo),e(ko,Je),M(uy,Je,null),e(Je,UFo),e(Je,_fe),e(_fe,HFo),e(Je,JFo),e(Je,Hi),e(Hi,YFo),e(Hi,ufe),e(ufe,KFo),e(Hi,ZFo),e(Hi,bfe),e(bfe,eTo),e(Hi,oTo),e(Je,rTo),e(Je,fe),e(fe,qp),e(qp,vfe),e(vfe,tTo),e(qp,aTo),e(qp,Ij),e(Ij,nTo),e(qp,sTo),e(fe,lTo),e(fe,jp),e(jp,Ffe),e(Ffe,iTo),e(jp,dTo),e(jp,Nj),e(Nj,cTo),e(jp,fTo),e(fe,mTo),e(fe,Dp),e(Dp,Tfe),e(Tfe,gTo),e(Dp,hTo),e(Dp,qj),e(qj,pTo),e(Dp,_To),e(fe,uTo),e(fe,Gp),e(Gp,Mfe),e(Mfe,bTo),e(Gp,vTo),e(Gp,jj),e(jj,FTo),e(Gp,TTo),e(fe,MTo),e(fe,Op),e(Op,Efe),e(Efe,ETo),e(Op,CTo),e(Op,Dj),e(Dj,wTo),e(Op,ATo),e(fe,LTo),e(fe,Vp),e(Vp,Cfe),e(Cfe,yTo),e(Vp,xTo),e(Vp,Gj),e(Gj,$To),e(Vp,kTo),e(fe,STo),e(fe,Xp),e(Xp,wfe),e(wfe,RTo),e(Xp,PTo),e(Xp,Oj),e(Oj,BTo),e(Xp,ITo),e(fe,NTo),e(fe,zp),e(zp,Afe),e(Afe,qTo),e(zp,jTo),e(zp,Vj),e(Vj,DTo),e(zp,GTo),e(fe,OTo),e(fe,Wp),e(Wp,Lfe),e(Lfe,VTo),e(Wp,XTo),e(Wp,Xj),e(Xj,zTo),e(Wp,WTo),e(fe,QTo),e(fe,Qp),e(Qp,yfe),e(yfe,UTo),e(Qp,HTo),e(Qp,zj),e(zj,JTo),e(Qp,YTo),e(fe,KTo),e(fe,Up),e(Up,xfe),e(xfe,ZTo),e(Up,e8o),e(Up,Wj),e(Wj,o8o),e(Up,r8o),e(fe,t8o),e(fe,Hp),e(Hp,$fe),e($fe,a8o),e(Hp,n8o),e(Hp,Qj),e(Qj,s8o),e(Hp,l8o),e(fe,i8o),e(fe,Jp),e(Jp,kfe),e(kfe,d8o),e(Jp,c8o),e(Jp,Uj),e(Uj,f8o),e(Jp,m8o),e(fe,g8o),e(fe,Yp),e(Yp,Sfe),e(Sfe,h8o),e(Yp,p8o),e(Yp,Hj),e(Hj,_8o),e(Yp,u8o),e(fe,b8o),e(fe,Kp),e(Kp,Rfe),e(Rfe,v8o),e(Kp,F8o),e(Kp,Jj),e(Jj,T8o),e(Kp,M8o),e(fe,E8o),e(fe,Zp),e(Zp,Pfe),e(Pfe,C8o),e(Zp,w8o),e(Zp,Yj),e(Yj,A8o),e(Zp,L8o),e(fe,y8o),e(fe,e_),e(e_,Bfe),e(Bfe,x8o),e(e_,$8o),e(e_,Kj),e(Kj,k8o),e(e_,S8o),e(fe,R8o),e(fe,o_),e(o_,Ife),e(Ife,P8o),e(o_,B8o),e(o_,Zj),e(Zj,I8o),e(o_,N8o),e(fe,q8o),e(fe,r_),e(r_,Nfe),e(Nfe,j8o),e(r_,D8o),e(r_,eD),e(eD,G8o),e(r_,O8o),e(Je,V8o),M(t_,Je,null),e(Je,X8o),M(a_,Je,null),e(ko,z8o),e(ko,n_),M(by,n_,null),e(n_,W8o),e(n_,qfe),e(qfe,Q8o),b(f,KWe,u),b(f,Ji,u),e(Ji,s_),e(s_,jfe),M(vy,jfe,null),e(Ji,U8o),e(Ji,Dfe),e(Dfe,H8o),b(f,ZWe,u),b(f,So,u),M(Fy,So,null),e(So,J8o),e(So,Yi),e(Yi,Y8o),e(Yi,oD),e(oD,K8o),e(Yi,Z8o),e(Yi,rD),e(rD,eMo),e(Yi,oMo),e(So,rMo),e(So,Ty),e(Ty,tMo),e(Ty,Gfe),e(Gfe,aMo),e(Ty,nMo),e(So,sMo),e(So,ct),M(My,ct,null),e(ct,lMo),e(ct,Ofe),e(Ofe,iMo),e(ct,dMo),e(ct,Ki),e(Ki,cMo),e(Ki,Vfe),e(Vfe,fMo),e(Ki,mMo),e(Ki,tD),e(tD,gMo),e(Ki,hMo),e(ct,pMo),M(l_,ct,null),e(So,_Mo),e(So,Ye),M(Ey,Ye,null),e(Ye,uMo),e(Ye,Xfe),e(Xfe,bMo),e(Ye,vMo),e(Ye,Da),e(Da,FMo),e(Da,zfe),e(zfe,TMo),e(Da,MMo),e(Da,Wfe),e(Wfe,EMo),e(Da,CMo),e(Da,Qfe),e(Qfe,wMo),e(Da,AMo),e(Ye,LMo),e(Ye,y),e(y,i_),e(i_,Ufe),e(Ufe,yMo),e(i_,xMo),e(i_,aD),e(aD,$Mo),e(i_,kMo),e(y,SMo),e(y,d_),e(d_,Hfe),e(Hfe,RMo),e(d_,PMo),e(d_,nD),e(nD,BMo),e(d_,IMo),e(y,NMo),e(y,c_),e(c_,Jfe),e(Jfe,qMo),e(c_,jMo),e(c_,sD),e(sD,DMo),e(c_,GMo),e(y,OMo),e(y,f_),e(f_,Yfe),e(Yfe,VMo),e(f_,XMo),e(f_,lD),e(lD,zMo),e(f_,WMo),e(y,QMo),e(y,m_),e(m_,Kfe),e(Kfe,UMo),e(m_,HMo),e(m_,iD),e(iD,JMo),e(m_,YMo),e(y,KMo),e(y,g_),e(g_,Zfe),e(Zfe,ZMo),e(g_,eEo),e(g_,dD),e(dD,oEo),e(g_,rEo),e(y,tEo),e(y,h_),e(h_,eme),e(eme,aEo),e(h_,nEo),e(h_,cD),e(cD,sEo),e(h_,lEo),e(y,iEo),e(y,p_),e(p_,ome),e(ome,dEo),e(p_,cEo),e(p_,fD),e(fD,fEo),e(p_,mEo),e(y,gEo),e(y,__),e(__,rme),e(rme,hEo),e(__,pEo),e(__,mD),e(mD,_Eo),e(__,uEo),e(y,bEo),e(y,u_),e(u_,tme),e(tme,vEo),e(u_,FEo),e(u_,gD),e(gD,TEo),e(u_,MEo),e(y,EEo),e(y,b_),e(b_,ame),e(ame,CEo),e(b_,wEo),e(b_,hD),e(hD,AEo),e(b_,LEo),e(y,yEo),e(y,v_),e(v_,nme),e(nme,xEo),e(v_,$Eo),e(v_,pD),e(pD,kEo),e(v_,SEo),e(y,REo),e(y,F_),e(F_,sme),e(sme,PEo),e(F_,BEo),e(F_,_D),e(_D,IEo),e(F_,NEo),e(y,qEo),e(y,T_),e(T_,lme),e(lme,jEo),e(T_,DEo),e(T_,uD),e(uD,GEo),e(T_,OEo),e(y,VEo),e(y,M_),e(M_,ime),e(ime,XEo),e(M_,zEo),e(M_,bD),e(bD,WEo),e(M_,QEo),e(y,UEo),e(y,E_),e(E_,dme),e(dme,HEo),e(E_,JEo),e(E_,vD),e(vD,YEo),e(E_,KEo),e(y,ZEo),e(y,C_),e(C_,cme),e(cme,eCo),e(C_,oCo),e(C_,FD),e(FD,rCo),e(C_,tCo),e(y,aCo),e(y,w_),e(w_,fme),e(fme,nCo),e(w_,sCo),e(w_,TD),e(TD,lCo),e(w_,iCo),e(y,dCo),e(y,A_),e(A_,mme),e(mme,cCo),e(A_,fCo),e(A_,MD),e(MD,mCo),e(A_,gCo),e(y,hCo),e(y,L_),e(L_,gme),e(gme,pCo),e(L_,_Co),e(L_,ED),e(ED,uCo),e(L_,bCo),e(y,vCo),e(y,y_),e(y_,hme),e(hme,FCo),e(y_,TCo),e(y_,CD),e(CD,MCo),e(y_,ECo),e(y,CCo),e(y,x_),e(x_,pme),e(pme,wCo),e(x_,ACo),e(x_,wD),e(wD,LCo),e(x_,yCo),e(y,xCo),e(y,$_),e($_,_me),e(_me,$Co),e($_,kCo),e($_,AD),e(AD,SCo),e($_,RCo),e(y,PCo),e(y,k_),e(k_,ume),e(ume,BCo),e(k_,ICo),e(k_,LD),e(LD,NCo),e(k_,qCo),e(y,jCo),e(y,S_),e(S_,bme),e(bme,DCo),e(S_,GCo),e(S_,yD),e(yD,OCo),e(S_,VCo),e(y,XCo),e(y,R_),e(R_,vme),e(vme,zCo),e(R_,WCo),e(R_,xD),e(xD,QCo),e(R_,UCo),e(y,HCo),e(y,P_),e(P_,Fme),e(Fme,JCo),e(P_,YCo),e(P_,$D),e($D,KCo),e(P_,ZCo),e(y,e3o),e(y,B_),e(B_,Tme),e(Tme,o3o),e(B_,r3o),e(B_,kD),e(kD,t3o),e(B_,a3o),e(y,n3o),e(y,I_),e(I_,Mme),e(Mme,s3o),e(I_,l3o),e(I_,SD),e(SD,i3o),e(I_,d3o),e(y,c3o),e(y,N_),e(N_,Eme),e(Eme,f3o),e(N_,m3o),e(N_,RD),e(RD,g3o),e(N_,h3o),e(y,p3o),e(y,q_),e(q_,Cme),e(Cme,_3o),e(q_,u3o),e(q_,PD),e(PD,b3o),e(q_,v3o),e(y,F3o),e(y,j_),e(j_,wme),e(wme,T3o),e(j_,M3o),e(j_,BD),e(BD,E3o),e(j_,C3o),e(y,w3o),e(y,D_),e(D_,Ame),e(Ame,A3o),e(D_,L3o),e(D_,ID),e(ID,y3o),e(D_,x3o),e(y,$3o),e(y,G_),e(G_,Lme),e(Lme,k3o),e(G_,S3o),e(G_,ND),e(ND,R3o),e(G_,P3o),e(y,B3o),e(y,ol),e(ol,yme),e(yme,I3o),e(ol,N3o),e(ol,qD),e(qD,q3o),e(ol,j3o),e(ol,jD),e(jD,D3o),e(ol,G3o),e(y,O3o),e(y,O_),e(O_,xme),e(xme,V3o),e(O_,X3o),e(O_,DD),e(DD,z3o),e(O_,W3o),e(y,Q3o),e(y,V_),e(V_,$me),e($me,U3o),e(V_,H3o),e(V_,GD),e(GD,J3o),e(V_,Y3o),e(y,K3o),e(y,X_),e(X_,kme),e(kme,Z3o),e(X_,e0o),e(X_,OD),e(OD,o0o),e(X_,r0o),e(y,t0o),e(y,z_),e(z_,Sme),e(Sme,a0o),e(z_,n0o),e(z_,VD),e(VD,s0o),e(z_,l0o),e(y,i0o),e(y,W_),e(W_,Rme),e(Rme,d0o),e(W_,c0o),e(W_,XD),e(XD,f0o),e(W_,m0o),e(y,g0o),e(y,Q_),e(Q_,Pme),e(Pme,h0o),e(Q_,p0o),e(Q_,zD),e(zD,_0o),e(Q_,u0o),e(y,b0o),e(y,U_),e(U_,Bme),e(Bme,v0o),e(U_,F0o),e(U_,WD),e(WD,T0o),e(U_,M0o),e(y,E0o),e(y,H_),e(H_,Ime),e(Ime,C0o),e(H_,w0o),e(H_,QD),e(QD,A0o),e(H_,L0o),e(y,y0o),e(y,J_),e(J_,Nme),e(Nme,x0o),e(J_,$0o),e(J_,UD),e(UD,k0o),e(J_,S0o),e(y,R0o),e(y,Y_),e(Y_,qme),e(qme,P0o),e(Y_,B0o),e(Y_,HD),e(HD,I0o),e(Y_,N0o),e(y,q0o),e(y,K_),e(K_,jme),e(jme,j0o),e(K_,D0o),e(K_,JD),e(JD,G0o),e(K_,O0o),e(y,V0o),e(y,Z_),e(Z_,Dme),e(Dme,X0o),e(Z_,z0o),e(Z_,YD),e(YD,W0o),e(Z_,Q0o),e(y,U0o),e(y,eu),e(eu,Gme),e(Gme,H0o),e(eu,J0o),e(eu,KD),e(KD,Y0o),e(eu,K0o),e(y,Z0o),e(y,ou),e(ou,Ome),e(Ome,ewo),e(ou,owo),e(ou,ZD),e(ZD,rwo),e(ou,two),e(y,awo),e(y,ru),e(ru,Vme),e(Vme,nwo),e(ru,swo),e(ru,eG),e(eG,lwo),e(ru,iwo),e(y,dwo),e(y,tu),e(tu,Xme),e(Xme,cwo),e(tu,fwo),e(tu,oG),e(oG,mwo),e(tu,gwo),e(y,hwo),e(y,au),e(au,zme),e(zme,pwo),e(au,_wo),e(au,rG),e(rG,uwo),e(au,bwo),e(y,vwo),e(y,nu),e(nu,Wme),e(Wme,Fwo),e(nu,Two),e(nu,tG),e(tG,Mwo),e(nu,Ewo),e(y,Cwo),e(y,su),e(su,Qme),e(Qme,wwo),e(su,Awo),e(su,aG),e(aG,Lwo),e(su,ywo),e(y,xwo),e(y,lu),e(lu,Ume),e(Ume,$wo),e(lu,kwo),e(lu,nG),e(nG,Swo),e(lu,Rwo),e(y,Pwo),e(y,iu),e(iu,Hme),e(Hme,Bwo),e(iu,Iwo),e(iu,sG),e(sG,Nwo),e(iu,qwo),e(y,jwo),e(y,du),e(du,Jme),e(Jme,Dwo),e(du,Gwo),e(du,lG),e(lG,Owo),e(du,Vwo),e(y,Xwo),e(y,cu),e(cu,Yme),e(Yme,zwo),e(cu,Wwo),e(cu,iG),e(iG,Qwo),e(cu,Uwo),e(y,Hwo),e(y,fu),e(fu,Kme),e(Kme,Jwo),e(fu,Ywo),e(fu,dG),e(dG,Kwo),e(fu,Zwo),e(y,e6o),e(y,mu),e(mu,Zme),e(Zme,o6o),e(mu,r6o),e(mu,cG),e(cG,t6o),e(mu,a6o),e(y,n6o),e(y,gu),e(gu,ege),e(ege,s6o),e(gu,l6o),e(gu,fG),e(fG,i6o),e(gu,d6o),e(y,c6o),e(y,hu),e(hu,oge),e(oge,f6o),e(hu,m6o),e(hu,mG),e(mG,g6o),e(hu,h6o),e(y,p6o),e(y,pu),e(pu,rge),e(rge,_6o),e(pu,u6o),e(pu,gG),e(gG,b6o),e(pu,v6o),e(y,F6o),e(y,_u),e(_u,tge),e(tge,T6o),e(_u,M6o),e(_u,hG),e(hG,E6o),e(_u,C6o),e(y,w6o),e(y,uu),e(uu,age),e(age,A6o),e(uu,L6o),e(uu,pG),e(pG,y6o),e(uu,x6o),e(y,$6o),e(y,bu),e(bu,nge),e(nge,k6o),e(bu,S6o),e(bu,_G),e(_G,R6o),e(bu,P6o),e(y,B6o),e(y,vu),e(vu,sge),e(sge,I6o),e(vu,N6o),e(vu,uG),e(uG,q6o),e(vu,j6o),e(y,D6o),e(y,Fu),e(Fu,lge),e(lge,G6o),e(Fu,O6o),e(Fu,bG),e(bG,V6o),e(Fu,X6o),e(y,z6o),e(y,Tu),e(Tu,ige),e(ige,W6o),e(Tu,Q6o),e(Tu,vG),e(vG,U6o),e(Tu,H6o),e(y,J6o),e(y,Mu),e(Mu,dge),e(dge,Y6o),e(Mu,K6o),e(Mu,FG),e(FG,Z6o),e(Mu,eAo),e(y,oAo),e(y,Eu),e(Eu,cge),e(cge,rAo),e(Eu,tAo),e(Eu,TG),e(TG,aAo),e(Eu,nAo),e(y,sAo),e(y,Cu),e(Cu,fge),e(fge,lAo),e(Cu,iAo),e(Cu,MG),e(MG,dAo),e(Cu,cAo),e(y,fAo),e(y,wu),e(wu,mge),e(mge,mAo),e(wu,gAo),e(wu,EG),e(EG,hAo),e(wu,pAo),e(y,_Ao),e(y,Au),e(Au,gge),e(gge,uAo),e(Au,bAo),e(Au,CG),e(CG,vAo),e(Au,FAo),e(y,TAo),e(y,Lu),e(Lu,hge),e(hge,MAo),e(Lu,EAo),e(Lu,wG),e(wG,CAo),e(Lu,wAo),e(y,AAo),e(y,yu),e(yu,pge),e(pge,LAo),e(yu,yAo),e(yu,AG),e(AG,xAo),e(yu,$Ao),e(y,kAo),e(y,xu),e(xu,_ge),e(_ge,SAo),e(xu,RAo),e(xu,LG),e(LG,PAo),e(xu,BAo),e(y,IAo),e(y,$u),e($u,uge),e(uge,NAo),e($u,qAo),e($u,yG),e(yG,jAo),e($u,DAo),e(y,GAo),e(y,ku),e(ku,bge),e(bge,OAo),e(ku,VAo),e(ku,xG),e(xG,XAo),e(ku,zAo),e(y,WAo),e(y,Su),e(Su,vge),e(vge,QAo),e(Su,UAo),e(Su,$G),e($G,HAo),e(Su,JAo),e(y,YAo),e(y,Ru),e(Ru,Fge),e(Fge,KAo),e(Ru,ZAo),e(Ru,kG),e(kG,e7o),e(Ru,o7o),e(y,r7o),e(y,Pu),e(Pu,Tge),e(Tge,t7o),e(Pu,a7o),e(Pu,SG),e(SG,n7o),e(Pu,s7o),e(y,l7o),e(y,Bu),e(Bu,Mge),e(Mge,i7o),e(Bu,d7o),e(Bu,RG),e(RG,c7o),e(Bu,f7o),e(y,m7o),e(y,Iu),e(Iu,Ege),e(Ege,g7o),e(Iu,h7o),e(Iu,PG),e(PG,p7o),e(Iu,_7o),e(y,u7o),e(y,Nu),e(Nu,Cge),e(Cge,b7o),e(Nu,v7o),e(Nu,BG),e(BG,F7o),e(Nu,T7o),e(y,M7o),e(y,qu),e(qu,wge),e(wge,E7o),e(qu,C7o),e(qu,IG),e(IG,w7o),e(qu,A7o),e(y,L7o),e(y,ju),e(ju,Age),e(Age,y7o),e(ju,x7o),e(ju,NG),e(NG,$7o),e(ju,k7o),e(y,S7o),e(y,Du),e(Du,Lge),e(Lge,R7o),e(Du,P7o),e(Du,qG),e(qG,B7o),e(Du,I7o),e(y,N7o),e(y,Gu),e(Gu,yge),e(yge,q7o),e(Gu,j7o),e(Gu,jG),e(jG,D7o),e(Gu,G7o),e(y,O7o),e(y,Ou),e(Ou,xge),e(xge,V7o),e(Ou,X7o),e(Ou,DG),e(DG,z7o),e(Ou,W7o),e(y,Q7o),e(y,Vu),e(Vu,$ge),e($ge,U7o),e(Vu,H7o),e(Vu,GG),e(GG,J7o),e(Vu,Y7o),e(y,K7o),e(y,Xu),e(Xu,kge),e(kge,Z7o),e(Xu,eLo),e(Xu,OG),e(OG,oLo),e(Xu,rLo),e(y,tLo),e(y,zu),e(zu,Sge),e(Sge,aLo),e(zu,nLo),e(zu,VG),e(VG,sLo),e(zu,lLo),e(y,iLo),e(y,Wu),e(Wu,Rge),e(Rge,dLo),e(Wu,cLo),e(Wu,XG),e(XG,fLo),e(Wu,mLo),e(y,gLo),e(y,Qu),e(Qu,Pge),e(Pge,hLo),e(Qu,pLo),e(Qu,zG),e(zG,_Lo),e(Qu,uLo),e(y,bLo),e(y,Uu),e(Uu,Bge),e(Bge,vLo),e(Uu,FLo),e(Uu,WG),e(WG,TLo),e(Uu,MLo),e(y,ELo),e(y,Hu),e(Hu,Ige),e(Ige,CLo),e(Hu,wLo),e(Hu,QG),e(QG,ALo),e(Hu,LLo),e(y,yLo),e(y,Ju),e(Ju,Nge),e(Nge,xLo),e(Ju,$Lo),e(Ju,UG),e(UG,kLo),e(Ju,SLo),e(y,RLo),e(y,Yu),e(Yu,qge),e(qge,PLo),e(Yu,BLo),e(Yu,HG),e(HG,ILo),e(Yu,NLo),e(y,qLo),e(y,Ku),e(Ku,jge),e(jge,jLo),e(Ku,DLo),e(Ku,JG),e(JG,GLo),e(Ku,OLo),e(y,VLo),e(y,Zu),e(Zu,Dge),e(Dge,XLo),e(Zu,zLo),e(Zu,YG),e(YG,WLo),e(Zu,QLo),e(y,ULo),e(y,e2),e(e2,Gge),e(Gge,HLo),e(e2,JLo),e(e2,KG),e(KG,YLo),e(e2,KLo),e(y,ZLo),e(y,o2),e(o2,Oge),e(Oge,eyo),e(o2,oyo),e(o2,ZG),e(ZG,ryo),e(o2,tyo),e(y,ayo),e(y,r2),e(r2,Vge),e(Vge,nyo),e(r2,syo),e(r2,eO),e(eO,lyo),e(r2,iyo),e(y,dyo),e(y,t2),e(t2,Xge),e(Xge,cyo),e(t2,fyo),e(t2,oO),e(oO,myo),e(t2,gyo),e(y,hyo),e(y,a2),e(a2,zge),e(zge,pyo),e(a2,_yo),e(a2,rO),e(rO,uyo),e(a2,byo),e(y,vyo),e(y,n2),e(n2,Wge),e(Wge,Fyo),e(n2,Tyo),e(n2,tO),e(tO,Myo),e(n2,Eyo),e(y,Cyo),e(y,s2),e(s2,Qge),e(Qge,wyo),e(s2,Ayo),e(s2,aO),e(aO,Lyo),e(s2,yyo),e(y,xyo),e(y,l2),e(l2,Uge),e(Uge,$yo),e(l2,kyo),e(l2,nO),e(nO,Syo),e(l2,Ryo),e(y,Pyo),e(y,i2),e(i2,Hge),e(Hge,Byo),e(i2,Iyo),e(i2,sO),e(sO,Nyo),e(i2,qyo),e(y,jyo),e(y,d2),e(d2,Jge),e(Jge,Dyo),e(d2,Gyo),e(d2,lO),e(lO,Oyo),e(d2,Vyo),e(y,Xyo),e(y,c2),e(c2,Yge),e(Yge,zyo),e(c2,Wyo),e(c2,iO),e(iO,Qyo),e(c2,Uyo),e(y,Hyo),e(y,f2),e(f2,Kge),e(Kge,Jyo),e(f2,Yyo),e(f2,dO),e(dO,Kyo),e(f2,Zyo),e(y,e9o),e(y,m2),e(m2,Zge),e(Zge,o9o),e(m2,r9o),e(m2,cO),e(cO,t9o),e(m2,a9o),e(y,n9o),e(y,g2),e(g2,ehe),e(ehe,s9o),e(g2,l9o),e(g2,fO),e(fO,i9o),e(g2,d9o),e(Ye,c9o),e(Ye,h2),e(h2,f9o),e(h2,ohe),e(ohe,m9o),e(h2,g9o),e(h2,rhe),e(rhe,h9o),e(Ye,p9o),M(p2,Ye,null),b(f,eQe,u),b(f,Zi,u),e(Zi,_2),e(_2,the),M(Cy,the,null),e(Zi,_9o),e(Zi,ahe),e(ahe,u9o),b(f,oQe,u),b(f,Ro,u),M(wy,Ro,null),e(Ro,b9o),e(Ro,ed),e(ed,v9o),e(ed,mO),e(mO,F9o),e(ed,T9o),e(ed,gO),e(gO,M9o),e(ed,E9o),e(Ro,C9o),e(Ro,Ay),e(Ay,w9o),e(Ay,nhe),e(nhe,A9o),e(Ay,L9o),e(Ro,y9o),e(Ro,ft),M(Ly,ft,null),e(ft,x9o),e(ft,she),e(she,$9o),e(ft,k9o),e(ft,od),e(od,S9o),e(od,lhe),e(lhe,R9o),e(od,P9o),e(od,hO),e(hO,B9o),e(od,I9o),e(ft,N9o),M(u2,ft,null),e(Ro,q9o),e(Ro,Ke),M(yy,Ke,null),e(Ke,j9o),e(Ke,ihe),e(ihe,D9o),e(Ke,G9o),e(Ke,Ga),e(Ga,O9o),e(Ga,dhe),e(dhe,V9o),e(Ga,X9o),e(Ga,che),e(che,z9o),e(Ga,W9o),e(Ga,fhe),e(fhe,Q9o),e(Ga,U9o),e(Ke,H9o),e(Ke,G),e(G,b2),e(b2,mhe),e(mhe,J9o),e(b2,Y9o),e(b2,pO),e(pO,K9o),e(b2,Z9o),e(G,exo),e(G,v2),e(v2,ghe),e(ghe,oxo),e(v2,rxo),e(v2,_O),e(_O,txo),e(v2,axo),e(G,nxo),e(G,F2),e(F2,hhe),e(hhe,sxo),e(F2,lxo),e(F2,uO),e(uO,ixo),e(F2,dxo),e(G,cxo),e(G,T2),e(T2,phe),e(phe,fxo),e(T2,mxo),e(T2,bO),e(bO,gxo),e(T2,hxo),e(G,pxo),e(G,M2),e(M2,_he),e(_he,_xo),e(M2,uxo),e(M2,vO),e(vO,bxo),e(M2,vxo),e(G,Fxo),e(G,E2),e(E2,uhe),e(uhe,Txo),e(E2,Mxo),e(E2,FO),e(FO,Exo),e(E2,Cxo),e(G,wxo),e(G,C2),e(C2,bhe),e(bhe,Axo),e(C2,Lxo),e(C2,TO),e(TO,yxo),e(C2,xxo),e(G,$xo),e(G,w2),e(w2,vhe),e(vhe,kxo),e(w2,Sxo),e(w2,MO),e(MO,Rxo),e(w2,Pxo),e(G,Bxo),e(G,A2),e(A2,Fhe),e(Fhe,Ixo),e(A2,Nxo),e(A2,EO),e(EO,qxo),e(A2,jxo),e(G,Dxo),e(G,L2),e(L2,The),e(The,Gxo),e(L2,Oxo),e(L2,CO),e(CO,Vxo),e(L2,Xxo),e(G,zxo),e(G,y2),e(y2,Mhe),e(Mhe,Wxo),e(y2,Qxo),e(y2,wO),e(wO,Uxo),e(y2,Hxo),e(G,Jxo),e(G,x2),e(x2,Ehe),e(Ehe,Yxo),e(x2,Kxo),e(x2,AO),e(AO,Zxo),e(x2,e$o),e(G,o$o),e(G,$2),e($2,Che),e(Che,r$o),e($2,t$o),e($2,LO),e(LO,a$o),e($2,n$o),e(G,s$o),e(G,k2),e(k2,whe),e(whe,l$o),e(k2,i$o),e(k2,yO),e(yO,d$o),e(k2,c$o),e(G,f$o),e(G,S2),e(S2,Ahe),e(Ahe,m$o),e(S2,g$o),e(S2,xO),e(xO,h$o),e(S2,p$o),e(G,_$o),e(G,R2),e(R2,Lhe),e(Lhe,u$o),e(R2,b$o),e(R2,$O),e($O,v$o),e(R2,F$o),e(G,T$o),e(G,P2),e(P2,yhe),e(yhe,M$o),e(P2,E$o),e(P2,kO),e(kO,C$o),e(P2,w$o),e(G,A$o),e(G,B2),e(B2,xhe),e(xhe,L$o),e(B2,y$o),e(B2,SO),e(SO,x$o),e(B2,$$o),e(G,k$o),e(G,I2),e(I2,$he),e($he,S$o),e(I2,R$o),e(I2,RO),e(RO,P$o),e(I2,B$o),e(G,I$o),e(G,N2),e(N2,khe),e(khe,N$o),e(N2,q$o),e(N2,PO),e(PO,j$o),e(N2,D$o),e(G,G$o),e(G,q2),e(q2,She),e(She,O$o),e(q2,V$o),e(q2,BO),e(BO,X$o),e(q2,z$o),e(G,W$o),e(G,j2),e(j2,Rhe),e(Rhe,Q$o),e(j2,U$o),e(j2,IO),e(IO,H$o),e(j2,J$o),e(G,Y$o),e(G,D2),e(D2,Phe),e(Phe,K$o),e(D2,Z$o),e(D2,NO),e(NO,eko),e(D2,oko),e(G,rko),e(G,G2),e(G2,Bhe),e(Bhe,tko),e(G2,ako),e(G2,qO),e(qO,nko),e(G2,sko),e(G,lko),e(G,O2),e(O2,Ihe),e(Ihe,iko),e(O2,dko),e(O2,jO),e(jO,cko),e(O2,fko),e(G,mko),e(G,V2),e(V2,Nhe),e(Nhe,gko),e(V2,hko),e(V2,DO),e(DO,pko),e(V2,_ko),e(G,uko),e(G,X2),e(X2,qhe),e(qhe,bko),e(X2,vko),e(X2,GO),e(GO,Fko),e(X2,Tko),e(G,Mko),e(G,z2),e(z2,jhe),e(jhe,Eko),e(z2,Cko),e(z2,OO),e(OO,wko),e(z2,Ako),e(G,Lko),e(G,W2),e(W2,Dhe),e(Dhe,yko),e(W2,xko),e(W2,VO),e(VO,$ko),e(W2,kko),e(G,Sko),e(G,Q2),e(Q2,Ghe),e(Ghe,Rko),e(Q2,Pko),e(Q2,XO),e(XO,Bko),e(Q2,Iko),e(G,Nko),e(G,U2),e(U2,Ohe),e(Ohe,qko),e(U2,jko),e(U2,zO),e(zO,Dko),e(U2,Gko),e(G,Oko),e(G,H2),e(H2,Vhe),e(Vhe,Vko),e(H2,Xko),e(H2,WO),e(WO,zko),e(H2,Wko),e(G,Qko),e(G,J2),e(J2,Xhe),e(Xhe,Uko),e(J2,Hko),e(J2,QO),e(QO,Jko),e(J2,Yko),e(G,Kko),e(G,Y2),e(Y2,zhe),e(zhe,Zko),e(Y2,eSo),e(Y2,UO),e(UO,oSo),e(Y2,rSo),e(G,tSo),e(G,K2),e(K2,Whe),e(Whe,aSo),e(K2,nSo),e(K2,HO),e(HO,sSo),e(K2,lSo),e(G,iSo),e(G,Z2),e(Z2,Qhe),e(Qhe,dSo),e(Z2,cSo),e(Z2,JO),e(JO,fSo),e(Z2,mSo),e(G,gSo),e(G,e1),e(e1,Uhe),e(Uhe,hSo),e(e1,pSo),e(e1,YO),e(YO,_So),e(e1,uSo),e(G,bSo),e(G,o1),e(o1,Hhe),e(Hhe,vSo),e(o1,FSo),e(o1,KO),e(KO,TSo),e(o1,MSo),e(G,ESo),e(G,r1),e(r1,Jhe),e(Jhe,CSo),e(r1,wSo),e(r1,ZO),e(ZO,ASo),e(r1,LSo),e(G,ySo),e(G,t1),e(t1,Yhe),e(Yhe,xSo),e(t1,$So),e(t1,eV),e(eV,kSo),e(t1,SSo),e(G,RSo),e(G,a1),e(a1,Khe),e(Khe,PSo),e(a1,BSo),e(a1,oV),e(oV,ISo),e(a1,NSo),e(G,qSo),e(G,n1),e(n1,Zhe),e(Zhe,jSo),e(n1,DSo),e(n1,rV),e(rV,GSo),e(n1,OSo),e(G,VSo),e(G,s1),e(s1,epe),e(epe,XSo),e(s1,zSo),e(s1,tV),e(tV,WSo),e(s1,QSo),e(G,USo),e(G,l1),e(l1,ope),e(ope,HSo),e(l1,JSo),e(l1,aV),e(aV,YSo),e(l1,KSo),e(G,ZSo),e(G,i1),e(i1,rpe),e(rpe,eRo),e(i1,oRo),e(i1,nV),e(nV,rRo),e(i1,tRo),e(G,aRo),e(G,d1),e(d1,tpe),e(tpe,nRo),e(d1,sRo),e(d1,sV),e(sV,lRo),e(d1,iRo),e(G,dRo),e(G,c1),e(c1,ape),e(ape,cRo),e(c1,fRo),e(c1,lV),e(lV,mRo),e(c1,gRo),e(Ke,hRo),e(Ke,f1),e(f1,pRo),e(f1,npe),e(npe,_Ro),e(f1,uRo),e(f1,spe),e(spe,bRo),e(Ke,vRo),M(m1,Ke,null),b(f,rQe,u),b(f,rd,u),e(rd,g1),e(g1,lpe),M(xy,lpe,null),e(rd,FRo),e(rd,ipe),e(ipe,TRo),b(f,tQe,u),b(f,Po,u),M($y,Po,null),e(Po,MRo),e(Po,td),e(td,ERo),e(td,iV),e(iV,CRo),e(td,wRo),e(td,dV),e(dV,ARo),e(td,LRo),e(Po,yRo),e(Po,ky),e(ky,xRo),e(ky,dpe),e(dpe,$Ro),e(ky,kRo),e(Po,SRo),e(Po,mt),M(Sy,mt,null),e(mt,RRo),e(mt,cpe),e(cpe,PRo),e(mt,BRo),e(mt,ad),e(ad,IRo),e(ad,fpe),e(fpe,NRo),e(ad,qRo),e(ad,cV),e(cV,jRo),e(ad,DRo),e(mt,GRo),M(h1,mt,null),e(Po,ORo),e(Po,Ze),M(Ry,Ze,null),e(Ze,VRo),e(Ze,mpe),e(mpe,XRo),e(Ze,zRo),e(Ze,Oa),e(Oa,WRo),e(Oa,gpe),e(gpe,QRo),e(Oa,URo),e(Oa,hpe),e(hpe,HRo),e(Oa,JRo),e(Oa,ppe),e(ppe,YRo),e(Oa,KRo),e(Ze,ZRo),e(Ze,z),e(z,p1),e(p1,_pe),e(_pe,ePo),e(p1,oPo),e(p1,fV),e(fV,rPo),e(p1,tPo),e(z,aPo),e(z,_1),e(_1,upe),e(upe,nPo),e(_1,sPo),e(_1,mV),e(mV,lPo),e(_1,iPo),e(z,dPo),e(z,u1),e(u1,bpe),e(bpe,cPo),e(u1,fPo),e(u1,gV),e(gV,mPo),e(u1,gPo),e(z,hPo),e(z,b1),e(b1,vpe),e(vpe,pPo),e(b1,_Po),e(b1,hV),e(hV,uPo),e(b1,bPo),e(z,vPo),e(z,v1),e(v1,Fpe),e(Fpe,FPo),e(v1,TPo),e(v1,pV),e(pV,MPo),e(v1,EPo),e(z,CPo),e(z,F1),e(F1,Tpe),e(Tpe,wPo),e(F1,APo),e(F1,_V),e(_V,LPo),e(F1,yPo),e(z,xPo),e(z,T1),e(T1,Mpe),e(Mpe,$Po),e(T1,kPo),e(T1,uV),e(uV,SPo),e(T1,RPo),e(z,PPo),e(z,M1),e(M1,Epe),e(Epe,BPo),e(M1,IPo),e(M1,bV),e(bV,NPo),e(M1,qPo),e(z,jPo),e(z,E1),e(E1,Cpe),e(Cpe,DPo),e(E1,GPo),e(E1,vV),e(vV,OPo),e(E1,VPo),e(z,XPo),e(z,C1),e(C1,wpe),e(wpe,zPo),e(C1,WPo),e(C1,FV),e(FV,QPo),e(C1,UPo),e(z,HPo),e(z,w1),e(w1,Ape),e(Ape,JPo),e(w1,YPo),e(w1,TV),e(TV,KPo),e(w1,ZPo),e(z,eBo),e(z,A1),e(A1,Lpe),e(Lpe,oBo),e(A1,rBo),e(A1,MV),e(MV,tBo),e(A1,aBo),e(z,nBo),e(z,L1),e(L1,ype),e(ype,sBo),e(L1,lBo),e(L1,EV),e(EV,iBo),e(L1,dBo),e(z,cBo),e(z,y1),e(y1,xpe),e(xpe,fBo),e(y1,mBo),e(y1,CV),e(CV,gBo),e(y1,hBo),e(z,pBo),e(z,x1),e(x1,$pe),e($pe,_Bo),e(x1,uBo),e(x1,wV),e(wV,bBo),e(x1,vBo),e(z,FBo),e(z,$1),e($1,kpe),e(kpe,TBo),e($1,MBo),e($1,AV),e(AV,EBo),e($1,CBo),e(z,wBo),e(z,k1),e(k1,Spe),e(Spe,ABo),e(k1,LBo),e(k1,LV),e(LV,yBo),e(k1,xBo),e(z,$Bo),e(z,S1),e(S1,Rpe),e(Rpe,kBo),e(S1,SBo),e(S1,yV),e(yV,RBo),e(S1,PBo),e(z,BBo),e(z,R1),e(R1,Ppe),e(Ppe,IBo),e(R1,NBo),e(R1,xV),e(xV,qBo),e(R1,jBo),e(z,DBo),e(z,P1),e(P1,Bpe),e(Bpe,GBo),e(P1,OBo),e(P1,$V),e($V,VBo),e(P1,XBo),e(z,zBo),e(z,B1),e(B1,Ipe),e(Ipe,WBo),e(B1,QBo),e(B1,kV),e(kV,UBo),e(B1,HBo),e(z,JBo),e(z,I1),e(I1,Npe),e(Npe,YBo),e(I1,KBo),e(I1,SV),e(SV,ZBo),e(I1,eIo),e(z,oIo),e(z,N1),e(N1,qpe),e(qpe,rIo),e(N1,tIo),e(N1,RV),e(RV,aIo),e(N1,nIo),e(z,sIo),e(z,q1),e(q1,jpe),e(jpe,lIo),e(q1,iIo),e(q1,PV),e(PV,dIo),e(q1,cIo),e(z,fIo),e(z,j1),e(j1,Dpe),e(Dpe,mIo),e(j1,gIo),e(j1,BV),e(BV,hIo),e(j1,pIo),e(z,_Io),e(z,D1),e(D1,Gpe),e(Gpe,uIo),e(D1,bIo),e(D1,IV),e(IV,vIo),e(D1,FIo),e(z,TIo),e(z,G1),e(G1,Ope),e(Ope,MIo),e(G1,EIo),e(G1,NV),e(NV,CIo),e(G1,wIo),e(z,AIo),e(z,O1),e(O1,Vpe),e(Vpe,LIo),e(O1,yIo),e(O1,qV),e(qV,xIo),e(O1,$Io),e(z,kIo),e(z,V1),e(V1,Xpe),e(Xpe,SIo),e(V1,RIo),e(V1,jV),e(jV,PIo),e(V1,BIo),e(z,IIo),e(z,X1),e(X1,zpe),e(zpe,NIo),e(X1,qIo),e(X1,DV),e(DV,jIo),e(X1,DIo),e(z,GIo),e(z,z1),e(z1,Wpe),e(Wpe,OIo),e(z1,VIo),e(z1,GV),e(GV,XIo),e(z1,zIo),e(z,WIo),e(z,W1),e(W1,Qpe),e(Qpe,QIo),e(W1,UIo),e(W1,OV),e(OV,HIo),e(W1,JIo),e(z,YIo),e(z,Q1),e(Q1,Upe),e(Upe,KIo),e(Q1,ZIo),e(Q1,VV),e(VV,eNo),e(Q1,oNo),e(z,rNo),e(z,U1),e(U1,Hpe),e(Hpe,tNo),e(U1,aNo),e(U1,XV),e(XV,nNo),e(U1,sNo),e(z,lNo),e(z,H1),e(H1,Jpe),e(Jpe,iNo),e(H1,dNo),e(H1,zV),e(zV,cNo),e(H1,fNo),e(z,mNo),e(z,J1),e(J1,Ype),e(Ype,gNo),e(J1,hNo),e(J1,WV),e(WV,pNo),e(J1,_No),e(z,uNo),e(z,Y1),e(Y1,Kpe),e(Kpe,bNo),e(Y1,vNo),e(Y1,QV),e(QV,FNo),e(Y1,TNo),e(z,MNo),e(z,K1),e(K1,Zpe),e(Zpe,ENo),e(K1,CNo),e(K1,UV),e(UV,wNo),e(K1,ANo),e(z,LNo),e(z,Z1),e(Z1,e_e),e(e_e,yNo),e(Z1,xNo),e(Z1,HV),e(HV,$No),e(Z1,kNo),e(z,SNo),e(z,e4),e(e4,o_e),e(o_e,RNo),e(e4,PNo),e(e4,JV),e(JV,BNo),e(e4,INo),e(Ze,NNo),e(Ze,o4),e(o4,qNo),e(o4,r_e),e(r_e,jNo),e(o4,DNo),e(o4,t_e),e(t_e,GNo),e(Ze,ONo),M(r4,Ze,null),b(f,aQe,u),b(f,nd,u),e(nd,t4),e(t4,a_e),M(Py,a_e,null),e(nd,VNo),e(nd,n_e),e(n_e,XNo),b(f,nQe,u),b(f,Bo,u),M(By,Bo,null),e(Bo,zNo),e(Bo,sd),e(sd,WNo),e(sd,YV),e(YV,QNo),e(sd,UNo),e(sd,KV),e(KV,HNo),e(sd,JNo),e(Bo,YNo),e(Bo,Iy),e(Iy,KNo),e(Iy,s_e),e(s_e,ZNo),e(Iy,eqo),e(Bo,oqo),e(Bo,gt),M(Ny,gt,null),e(gt,rqo),e(gt,l_e),e(l_e,tqo),e(gt,aqo),e(gt,ld),e(ld,nqo),e(ld,i_e),e(i_e,sqo),e(ld,lqo),e(ld,ZV),e(ZV,iqo),e(ld,dqo),e(gt,cqo),M(a4,gt,null),e(Bo,fqo),e(Bo,eo),M(qy,eo,null),e(eo,mqo),e(eo,d_e),e(d_e,gqo),e(eo,hqo),e(eo,Va),e(Va,pqo),e(Va,c_e),e(c_e,_qo),e(Va,uqo),e(Va,f_e),e(f_e,bqo),e(Va,vqo),e(Va,m_e),e(m_e,Fqo),e(Va,Tqo),e(eo,Mqo),e(eo,U),e(U,n4),e(n4,g_e),e(g_e,Eqo),e(n4,Cqo),e(n4,eX),e(eX,wqo),e(n4,Aqo),e(U,Lqo),e(U,s4),e(s4,h_e),e(h_e,yqo),e(s4,xqo),e(s4,oX),e(oX,$qo),e(s4,kqo),e(U,Sqo),e(U,l4),e(l4,p_e),e(p_e,Rqo),e(l4,Pqo),e(l4,rX),e(rX,Bqo),e(l4,Iqo),e(U,Nqo),e(U,i4),e(i4,__e),e(__e,qqo),e(i4,jqo),e(i4,tX),e(tX,Dqo),e(i4,Gqo),e(U,Oqo),e(U,d4),e(d4,u_e),e(u_e,Vqo),e(d4,Xqo),e(d4,aX),e(aX,zqo),e(d4,Wqo),e(U,Qqo),e(U,c4),e(c4,b_e),e(b_e,Uqo),e(c4,Hqo),e(c4,nX),e(nX,Jqo),e(c4,Yqo),e(U,Kqo),e(U,f4),e(f4,v_e),e(v_e,Zqo),e(f4,ejo),e(f4,sX),e(sX,ojo),e(f4,rjo),e(U,tjo),e(U,m4),e(m4,F_e),e(F_e,ajo),e(m4,njo),e(m4,lX),e(lX,sjo),e(m4,ljo),e(U,ijo),e(U,g4),e(g4,T_e),e(T_e,djo),e(g4,cjo),e(g4,iX),e(iX,fjo),e(g4,mjo),e(U,gjo),e(U,h4),e(h4,M_e),e(M_e,hjo),e(h4,pjo),e(h4,dX),e(dX,_jo),e(h4,ujo),e(U,bjo),e(U,p4),e(p4,E_e),e(E_e,vjo),e(p4,Fjo),e(p4,cX),e(cX,Tjo),e(p4,Mjo),e(U,Ejo),e(U,_4),e(_4,C_e),e(C_e,Cjo),e(_4,wjo),e(_4,fX),e(fX,Ajo),e(_4,Ljo),e(U,yjo),e(U,u4),e(u4,w_e),e(w_e,xjo),e(u4,$jo),e(u4,mX),e(mX,kjo),e(u4,Sjo),e(U,Rjo),e(U,b4),e(b4,A_e),e(A_e,Pjo),e(b4,Bjo),e(b4,gX),e(gX,Ijo),e(b4,Njo),e(U,qjo),e(U,v4),e(v4,L_e),e(L_e,jjo),e(v4,Djo),e(v4,hX),e(hX,Gjo),e(v4,Ojo),e(U,Vjo),e(U,F4),e(F4,y_e),e(y_e,Xjo),e(F4,zjo),e(F4,pX),e(pX,Wjo),e(F4,Qjo),e(U,Ujo),e(U,T4),e(T4,x_e),e(x_e,Hjo),e(T4,Jjo),e(T4,_X),e(_X,Yjo),e(T4,Kjo),e(U,Zjo),e(U,M4),e(M4,$_e),e($_e,eDo),e(M4,oDo),e(M4,uX),e(uX,rDo),e(M4,tDo),e(U,aDo),e(U,E4),e(E4,k_e),e(k_e,nDo),e(E4,sDo),e(E4,bX),e(bX,lDo),e(E4,iDo),e(U,dDo),e(U,C4),e(C4,S_e),e(S_e,cDo),e(C4,fDo),e(C4,vX),e(vX,mDo),e(C4,gDo),e(U,hDo),e(U,w4),e(w4,R_e),e(R_e,pDo),e(w4,_Do),e(w4,FX),e(FX,uDo),e(w4,bDo),e(U,vDo),e(U,A4),e(A4,P_e),e(P_e,FDo),e(A4,TDo),e(A4,TX),e(TX,MDo),e(A4,EDo),e(U,CDo),e(U,L4),e(L4,B_e),e(B_e,wDo),e(L4,ADo),e(L4,MX),e(MX,LDo),e(L4,yDo),e(U,xDo),e(U,y4),e(y4,I_e),e(I_e,$Do),e(y4,kDo),e(y4,EX),e(EX,SDo),e(y4,RDo),e(U,PDo),e(U,x4),e(x4,N_e),e(N_e,BDo),e(x4,IDo),e(x4,CX),e(CX,NDo),e(x4,qDo),e(U,jDo),e(U,$4),e($4,q_e),e(q_e,DDo),e($4,GDo),e($4,wX),e(wX,ODo),e($4,VDo),e(U,XDo),e(U,k4),e(k4,j_e),e(j_e,zDo),e(k4,WDo),e(k4,AX),e(AX,QDo),e(k4,UDo),e(U,HDo),e(U,S4),e(S4,D_e),e(D_e,JDo),e(S4,YDo),e(S4,LX),e(LX,KDo),e(S4,ZDo),e(U,eGo),e(U,R4),e(R4,G_e),e(G_e,oGo),e(R4,rGo),e(R4,yX),e(yX,tGo),e(R4,aGo),e(U,nGo),e(U,P4),e(P4,O_e),e(O_e,sGo),e(P4,lGo),e(P4,xX),e(xX,iGo),e(P4,dGo),e(U,cGo),e(U,B4),e(B4,V_e),e(V_e,fGo),e(B4,mGo),e(B4,$X),e($X,gGo),e(B4,hGo),e(U,pGo),e(U,I4),e(I4,X_e),e(X_e,_Go),e(I4,uGo),e(I4,kX),e(kX,bGo),e(I4,vGo),e(U,FGo),e(U,N4),e(N4,z_e),e(z_e,TGo),e(N4,MGo),e(N4,SX),e(SX,EGo),e(N4,CGo),e(U,wGo),e(U,q4),e(q4,W_e),e(W_e,AGo),e(q4,LGo),e(q4,Q_e),e(Q_e,yGo),e(q4,xGo),e(U,$Go),e(U,j4),e(j4,U_e),e(U_e,kGo),e(j4,SGo),e(j4,RX),e(RX,RGo),e(j4,PGo),e(U,BGo),e(U,D4),e(D4,H_e),e(H_e,IGo),e(D4,NGo),e(D4,PX),e(PX,qGo),e(D4,jGo),e(U,DGo),e(U,G4),e(G4,J_e),e(J_e,GGo),e(G4,OGo),e(G4,BX),e(BX,VGo),e(G4,XGo),e(U,zGo),e(U,O4),e(O4,Y_e),e(Y_e,WGo),e(O4,QGo),e(O4,IX),e(IX,UGo),e(O4,HGo),e(eo,JGo),e(eo,V4),e(V4,YGo),e(V4,K_e),e(K_e,KGo),e(V4,ZGo),e(V4,Z_e),e(Z_e,eOo),e(eo,oOo),M(X4,eo,null),b(f,sQe,u),b(f,id,u),e(id,z4),e(z4,eue),M(jy,eue,null),e(id,rOo),e(id,oue),e(oue,tOo),b(f,lQe,u),b(f,Io,u),M(Dy,Io,null),e(Io,aOo),e(Io,dd),e(dd,nOo),e(dd,NX),e(NX,sOo),e(dd,lOo),e(dd,qX),e(qX,iOo),e(dd,dOo),e(Io,cOo),e(Io,Gy),e(Gy,fOo),e(Gy,rue),e(rue,mOo),e(Gy,gOo),e(Io,hOo),e(Io,ht),M(Oy,ht,null),e(ht,pOo),e(ht,tue),e(tue,_Oo),e(ht,uOo),e(ht,cd),e(cd,bOo),e(cd,aue),e(aue,vOo),e(cd,FOo),e(cd,jX),e(jX,TOo),e(cd,MOo),e(ht,EOo),M(W4,ht,null),e(Io,COo),e(Io,oo),M(Vy,oo,null),e(oo,wOo),e(oo,nue),e(nue,AOo),e(oo,LOo),e(oo,Xa),e(Xa,yOo),e(Xa,sue),e(sue,xOo),e(Xa,$Oo),e(Xa,lue),e(lue,kOo),e(Xa,SOo),e(Xa,iue),e(iue,ROo),e(Xa,POo),e(oo,BOo),e(oo,me),e(me,Q4),e(Q4,due),e(due,IOo),e(Q4,NOo),e(Q4,DX),e(DX,qOo),e(Q4,jOo),e(me,DOo),e(me,U4),e(U4,cue),e(cue,GOo),e(U4,OOo),e(U4,GX),e(GX,VOo),e(U4,XOo),e(me,zOo),e(me,H4),e(H4,fue),e(fue,WOo),e(H4,QOo),e(H4,OX),e(OX,UOo),e(H4,HOo),e(me,JOo),e(me,J4),e(J4,mue),e(mue,YOo),e(J4,KOo),e(J4,VX),e(VX,ZOo),e(J4,eVo),e(me,oVo),e(me,Y4),e(Y4,gue),e(gue,rVo),e(Y4,tVo),e(Y4,XX),e(XX,aVo),e(Y4,nVo),e(me,sVo),e(me,K4),e(K4,hue),e(hue,lVo),e(K4,iVo),e(K4,zX),e(zX,dVo),e(K4,cVo),e(me,fVo),e(me,Z4),e(Z4,pue),e(pue,mVo),e(Z4,gVo),e(Z4,WX),e(WX,hVo),e(Z4,pVo),e(me,_Vo),e(me,eb),e(eb,_ue),e(_ue,uVo),e(eb,bVo),e(eb,QX),e(QX,vVo),e(eb,FVo),e(me,TVo),e(me,ob),e(ob,uue),e(uue,MVo),e(ob,EVo),e(ob,UX),e(UX,CVo),e(ob,wVo),e(me,AVo),e(me,rb),e(rb,bue),e(bue,LVo),e(rb,yVo),e(rb,HX),e(HX,xVo),e(rb,$Vo),e(me,kVo),e(me,tb),e(tb,vue),e(vue,SVo),e(tb,RVo),e(tb,JX),e(JX,PVo),e(tb,BVo),e(me,IVo),e(me,ab),e(ab,Fue),e(Fue,NVo),e(ab,qVo),e(ab,YX),e(YX,jVo),e(ab,DVo),e(me,GVo),e(me,nb),e(nb,Tue),e(Tue,OVo),e(nb,VVo),e(nb,KX),e(KX,XVo),e(nb,zVo),e(me,WVo),e(me,sb),e(sb,Mue),e(Mue,QVo),e(sb,UVo),e(sb,ZX),e(ZX,HVo),e(sb,JVo),e(me,YVo),e(me,lb),e(lb,Eue),e(Eue,KVo),e(lb,ZVo),e(lb,ez),e(ez,eXo),e(lb,oXo),e(me,rXo),e(me,ib),e(ib,Cue),e(Cue,tXo),e(ib,aXo),e(ib,oz),e(oz,nXo),e(ib,sXo),e(me,lXo),e(me,db),e(db,wue),e(wue,iXo),e(db,dXo),e(db,rz),e(rz,cXo),e(db,fXo),e(me,mXo),e(me,cb),e(cb,Aue),e(Aue,gXo),e(cb,hXo),e(cb,tz),e(tz,pXo),e(cb,_Xo),e(me,uXo),e(me,fb),e(fb,Lue),e(Lue,bXo),e(fb,vXo),e(fb,az),e(az,FXo),e(fb,TXo),e(oo,MXo),e(oo,mb),e(mb,EXo),e(mb,yue),e(yue,CXo),e(mb,wXo),e(mb,xue),e(xue,AXo),e(oo,LXo),M(gb,oo,null),b(f,iQe,u),b(f,fd,u),e(fd,hb),e(hb,$ue),M(Xy,$ue,null),e(fd,yXo),e(fd,kue),e(kue,xXo),b(f,dQe,u),b(f,No,u),M(zy,No,null),e(No,$Xo),e(No,md),e(md,kXo),e(md,nz),e(nz,SXo),e(md,RXo),e(md,sz),e(sz,PXo),e(md,BXo),e(No,IXo),e(No,Wy),e(Wy,NXo),e(Wy,Sue),e(Sue,qXo),e(Wy,jXo),e(No,DXo),e(No,pt),M(Qy,pt,null),e(pt,GXo),e(pt,Rue),e(Rue,OXo),e(pt,VXo),e(pt,gd),e(gd,XXo),e(gd,Pue),e(Pue,zXo),e(gd,WXo),e(gd,lz),e(lz,QXo),e(gd,UXo),e(pt,HXo),M(pb,pt,null),e(No,JXo),e(No,ro),M(Uy,ro,null),e(ro,YXo),e(ro,Bue),e(Bue,KXo),e(ro,ZXo),e(ro,za),e(za,ezo),e(za,Iue),e(Iue,ozo),e(za,rzo),e(za,Nue),e(Nue,tzo),e(za,azo),e(za,que),e(que,nzo),e(za,szo),e(ro,lzo),e(ro,B),e(B,_b),e(_b,jue),e(jue,izo),e(_b,dzo),e(_b,iz),e(iz,czo),e(_b,fzo),e(B,mzo),e(B,ub),e(ub,Due),e(Due,gzo),e(ub,hzo),e(ub,dz),e(dz,pzo),e(ub,_zo),e(B,uzo),e(B,bb),e(bb,Gue),e(Gue,bzo),e(bb,vzo),e(bb,cz),e(cz,Fzo),e(bb,Tzo),e(B,Mzo),e(B,vb),e(vb,Oue),e(Oue,Ezo),e(vb,Czo),e(vb,fz),e(fz,wzo),e(vb,Azo),e(B,Lzo),e(B,Fb),e(Fb,Vue),e(Vue,yzo),e(Fb,xzo),e(Fb,mz),e(mz,$zo),e(Fb,kzo),e(B,Szo),e(B,Tb),e(Tb,Xue),e(Xue,Rzo),e(Tb,Pzo),e(Tb,gz),e(gz,Bzo),e(Tb,Izo),e(B,Nzo),e(B,Mb),e(Mb,zue),e(zue,qzo),e(Mb,jzo),e(Mb,hz),e(hz,Dzo),e(Mb,Gzo),e(B,Ozo),e(B,Eb),e(Eb,Wue),e(Wue,Vzo),e(Eb,Xzo),e(Eb,pz),e(pz,zzo),e(Eb,Wzo),e(B,Qzo),e(B,Cb),e(Cb,Que),e(Que,Uzo),e(Cb,Hzo),e(Cb,_z),e(_z,Jzo),e(Cb,Yzo),e(B,Kzo),e(B,wb),e(wb,Uue),e(Uue,Zzo),e(wb,eWo),e(wb,uz),e(uz,oWo),e(wb,rWo),e(B,tWo),e(B,Ab),e(Ab,Hue),e(Hue,aWo),e(Ab,nWo),e(Ab,bz),e(bz,sWo),e(Ab,lWo),e(B,iWo),e(B,Lb),e(Lb,Jue),e(Jue,dWo),e(Lb,cWo),e(Lb,vz),e(vz,fWo),e(Lb,mWo),e(B,gWo),e(B,yb),e(yb,Yue),e(Yue,hWo),e(yb,pWo),e(yb,Fz),e(Fz,_Wo),e(yb,uWo),e(B,bWo),e(B,xb),e(xb,Kue),e(Kue,vWo),e(xb,FWo),e(xb,Tz),e(Tz,TWo),e(xb,MWo),e(B,EWo),e(B,$b),e($b,Zue),e(Zue,CWo),e($b,wWo),e($b,Mz),e(Mz,AWo),e($b,LWo),e(B,yWo),e(B,kb),e(kb,e2e),e(e2e,xWo),e(kb,$Wo),e(kb,Ez),e(Ez,kWo),e(kb,SWo),e(B,RWo),e(B,Sb),e(Sb,o2e),e(o2e,PWo),e(Sb,BWo),e(Sb,Cz),e(Cz,IWo),e(Sb,NWo),e(B,qWo),e(B,Rb),e(Rb,r2e),e(r2e,jWo),e(Rb,DWo),e(Rb,wz),e(wz,GWo),e(Rb,OWo),e(B,VWo),e(B,Pb),e(Pb,t2e),e(t2e,XWo),e(Pb,zWo),e(Pb,Az),e(Az,WWo),e(Pb,QWo),e(B,UWo),e(B,Bb),e(Bb,a2e),e(a2e,HWo),e(Bb,JWo),e(Bb,Lz),e(Lz,YWo),e(Bb,KWo),e(B,ZWo),e(B,Ib),e(Ib,n2e),e(n2e,eQo),e(Ib,oQo),e(Ib,yz),e(yz,rQo),e(Ib,tQo),e(B,aQo),e(B,Nb),e(Nb,s2e),e(s2e,nQo),e(Nb,sQo),e(Nb,xz),e(xz,lQo),e(Nb,iQo),e(B,dQo),e(B,qb),e(qb,l2e),e(l2e,cQo),e(qb,fQo),e(qb,$z),e($z,mQo),e(qb,gQo),e(B,hQo),e(B,jb),e(jb,i2e),e(i2e,pQo),e(jb,_Qo),e(jb,kz),e(kz,uQo),e(jb,bQo),e(B,vQo),e(B,Db),e(Db,d2e),e(d2e,FQo),e(Db,TQo),e(Db,Sz),e(Sz,MQo),e(Db,EQo),e(B,CQo),e(B,Gb),e(Gb,c2e),e(c2e,wQo),e(Gb,AQo),e(Gb,Rz),e(Rz,LQo),e(Gb,yQo),e(B,xQo),e(B,Ob),e(Ob,f2e),e(f2e,$Qo),e(Ob,kQo),e(Ob,Pz),e(Pz,SQo),e(Ob,RQo),e(B,PQo),e(B,Vb),e(Vb,m2e),e(m2e,BQo),e(Vb,IQo),e(Vb,Bz),e(Bz,NQo),e(Vb,qQo),e(B,jQo),e(B,Xb),e(Xb,g2e),e(g2e,DQo),e(Xb,GQo),e(Xb,Iz),e(Iz,OQo),e(Xb,VQo),e(B,XQo),e(B,zb),e(zb,h2e),e(h2e,zQo),e(zb,WQo),e(zb,Nz),e(Nz,QQo),e(zb,UQo),e(B,HQo),e(B,Wb),e(Wb,p2e),e(p2e,JQo),e(Wb,YQo),e(Wb,qz),e(qz,KQo),e(Wb,ZQo),e(B,eUo),e(B,Qb),e(Qb,_2e),e(_2e,oUo),e(Qb,rUo),e(Qb,jz),e(jz,tUo),e(Qb,aUo),e(B,nUo),e(B,Ub),e(Ub,u2e),e(u2e,sUo),e(Ub,lUo),e(Ub,Dz),e(Dz,iUo),e(Ub,dUo),e(B,cUo),e(B,Hb),e(Hb,b2e),e(b2e,fUo),e(Hb,mUo),e(Hb,Gz),e(Gz,gUo),e(Hb,hUo),e(B,pUo),e(B,Jb),e(Jb,v2e),e(v2e,_Uo),e(Jb,uUo),e(Jb,Oz),e(Oz,bUo),e(Jb,vUo),e(B,FUo),e(B,Yb),e(Yb,F2e),e(F2e,TUo),e(Yb,MUo),e(Yb,Vz),e(Vz,EUo),e(Yb,CUo),e(B,wUo),e(B,Kb),e(Kb,T2e),e(T2e,AUo),e(Kb,LUo),e(Kb,Xz),e(Xz,yUo),e(Kb,xUo),e(B,$Uo),e(B,Zb),e(Zb,M2e),e(M2e,kUo),e(Zb,SUo),e(Zb,zz),e(zz,RUo),e(Zb,PUo),e(B,BUo),e(B,ev),e(ev,E2e),e(E2e,IUo),e(ev,NUo),e(ev,Wz),e(Wz,qUo),e(ev,jUo),e(B,DUo),e(B,ov),e(ov,C2e),e(C2e,GUo),e(ov,OUo),e(ov,Qz),e(Qz,VUo),e(ov,XUo),e(B,zUo),e(B,rv),e(rv,w2e),e(w2e,WUo),e(rv,QUo),e(rv,Uz),e(Uz,UUo),e(rv,HUo),e(B,JUo),e(B,tv),e(tv,A2e),e(A2e,YUo),e(tv,KUo),e(tv,Hz),e(Hz,ZUo),e(tv,eHo),e(B,oHo),e(B,av),e(av,L2e),e(L2e,rHo),e(av,tHo),e(av,Jz),e(Jz,aHo),e(av,nHo),e(B,sHo),e(B,nv),e(nv,y2e),e(y2e,lHo),e(nv,iHo),e(nv,Yz),e(Yz,dHo),e(nv,cHo),e(B,fHo),e(B,sv),e(sv,x2e),e(x2e,mHo),e(sv,gHo),e(sv,Kz),e(Kz,hHo),e(sv,pHo),e(B,_Ho),e(B,lv),e(lv,$2e),e($2e,uHo),e(lv,bHo),e(lv,Zz),e(Zz,vHo),e(lv,FHo),e(B,THo),e(B,iv),e(iv,k2e),e(k2e,MHo),e(iv,EHo),e(iv,eW),e(eW,CHo),e(iv,wHo),e(B,AHo),e(B,dv),e(dv,S2e),e(S2e,LHo),e(dv,yHo),e(dv,oW),e(oW,xHo),e(dv,$Ho),e(B,kHo),e(B,cv),e(cv,R2e),e(R2e,SHo),e(cv,RHo),e(cv,rW),e(rW,PHo),e(cv,BHo),e(B,IHo),e(B,fv),e(fv,P2e),e(P2e,NHo),e(fv,qHo),e(fv,tW),e(tW,jHo),e(fv,DHo),e(B,GHo),e(B,mv),e(mv,B2e),e(B2e,OHo),e(mv,VHo),e(mv,aW),e(aW,XHo),e(mv,zHo),e(B,WHo),e(B,gv),e(gv,I2e),e(I2e,QHo),e(gv,UHo),e(gv,nW),e(nW,HHo),e(gv,JHo),e(ro,YHo),e(ro,hv),e(hv,KHo),e(hv,N2e),e(N2e,ZHo),e(hv,eJo),e(hv,q2e),e(q2e,oJo),e(ro,rJo),M(pv,ro,null),b(f,cQe,u),b(f,hd,u),e(hd,_v),e(_v,j2e),M(Hy,j2e,null),e(hd,tJo),e(hd,D2e),e(D2e,aJo),b(f,fQe,u),b(f,qo,u),M(Jy,qo,null),e(qo,nJo),e(qo,pd),e(pd,sJo),e(pd,sW),e(sW,lJo),e(pd,iJo),e(pd,lW),e(lW,dJo),e(pd,cJo),e(qo,fJo),e(qo,Yy),e(Yy,mJo),e(Yy,G2e),e(G2e,gJo),e(Yy,hJo),e(qo,pJo),e(qo,_t),M(Ky,_t,null),e(_t,_Jo),e(_t,O2e),e(O2e,uJo),e(_t,bJo),e(_t,_d),e(_d,vJo),e(_d,V2e),e(V2e,FJo),e(_d,TJo),e(_d,iW),e(iW,MJo),e(_d,EJo),e(_t,CJo),M(uv,_t,null),e(qo,wJo),e(qo,to),M(Zy,to,null),e(to,AJo),e(to,X2e),e(X2e,LJo),e(to,yJo),e(to,Wa),e(Wa,xJo),e(Wa,z2e),e(z2e,$Jo),e(Wa,kJo),e(Wa,W2e),e(W2e,SJo),e(Wa,RJo),e(Wa,Q2e),e(Q2e,PJo),e(Wa,BJo),e(to,IJo),e(to,Z),e(Z,bv),e(bv,U2e),e(U2e,NJo),e(bv,qJo),e(bv,dW),e(dW,jJo),e(bv,DJo),e(Z,GJo),e(Z,vv),e(vv,H2e),e(H2e,OJo),e(vv,VJo),e(vv,cW),e(cW,XJo),e(vv,zJo),e(Z,WJo),e(Z,Fv),e(Fv,J2e),e(J2e,QJo),e(Fv,UJo),e(Fv,fW),e(fW,HJo),e(Fv,JJo),e(Z,YJo),e(Z,Tv),e(Tv,Y2e),e(Y2e,KJo),e(Tv,ZJo),e(Tv,mW),e(mW,eYo),e(Tv,oYo),e(Z,rYo),e(Z,Mv),e(Mv,K2e),e(K2e,tYo),e(Mv,aYo),e(Mv,gW),e(gW,nYo),e(Mv,sYo),e(Z,lYo),e(Z,Ev),e(Ev,Z2e),e(Z2e,iYo),e(Ev,dYo),e(Ev,hW),e(hW,cYo),e(Ev,fYo),e(Z,mYo),e(Z,Cv),e(Cv,e1e),e(e1e,gYo),e(Cv,hYo),e(Cv,pW),e(pW,pYo),e(Cv,_Yo),e(Z,uYo),e(Z,wv),e(wv,o1e),e(o1e,bYo),e(wv,vYo),e(wv,_W),e(_W,FYo),e(wv,TYo),e(Z,MYo),e(Z,Av),e(Av,r1e),e(r1e,EYo),e(Av,CYo),e(Av,uW),e(uW,wYo),e(Av,AYo),e(Z,LYo),e(Z,Lv),e(Lv,t1e),e(t1e,yYo),e(Lv,xYo),e(Lv,bW),e(bW,$Yo),e(Lv,kYo),e(Z,SYo),e(Z,yv),e(yv,a1e),e(a1e,RYo),e(yv,PYo),e(yv,vW),e(vW,BYo),e(yv,IYo),e(Z,NYo),e(Z,xv),e(xv,n1e),e(n1e,qYo),e(xv,jYo),e(xv,FW),e(FW,DYo),e(xv,GYo),e(Z,OYo),e(Z,$v),e($v,s1e),e(s1e,VYo),e($v,XYo),e($v,TW),e(TW,zYo),e($v,WYo),e(Z,QYo),e(Z,kv),e(kv,l1e),e(l1e,UYo),e(kv,HYo),e(kv,MW),e(MW,JYo),e(kv,YYo),e(Z,KYo),e(Z,Sv),e(Sv,i1e),e(i1e,ZYo),e(Sv,eKo),e(Sv,EW),e(EW,oKo),e(Sv,rKo),e(Z,tKo),e(Z,Rv),e(Rv,d1e),e(d1e,aKo),e(Rv,nKo),e(Rv,CW),e(CW,sKo),e(Rv,lKo),e(Z,iKo),e(Z,Pv),e(Pv,c1e),e(c1e,dKo),e(Pv,cKo),e(Pv,wW),e(wW,fKo),e(Pv,mKo),e(Z,gKo),e(Z,Bv),e(Bv,f1e),e(f1e,hKo),e(Bv,pKo),e(Bv,AW),e(AW,_Ko),e(Bv,uKo),e(Z,bKo),e(Z,Iv),e(Iv,m1e),e(m1e,vKo),e(Iv,FKo),e(Iv,LW),e(LW,TKo),e(Iv,MKo),e(Z,EKo),e(Z,Nv),e(Nv,g1e),e(g1e,CKo),e(Nv,wKo),e(Nv,yW),e(yW,AKo),e(Nv,LKo),e(Z,yKo),e(Z,qv),e(qv,h1e),e(h1e,xKo),e(qv,$Ko),e(qv,xW),e(xW,kKo),e(qv,SKo),e(Z,RKo),e(Z,jv),e(jv,p1e),e(p1e,PKo),e(jv,BKo),e(jv,$W),e($W,IKo),e(jv,NKo),e(Z,qKo),e(Z,Dv),e(Dv,_1e),e(_1e,jKo),e(Dv,DKo),e(Dv,kW),e(kW,GKo),e(Dv,OKo),e(Z,VKo),e(Z,Gv),e(Gv,u1e),e(u1e,XKo),e(Gv,zKo),e(Gv,SW),e(SW,WKo),e(Gv,QKo),e(Z,UKo),e(Z,Ov),e(Ov,b1e),e(b1e,HKo),e(Ov,JKo),e(Ov,RW),e(RW,YKo),e(Ov,KKo),e(Z,ZKo),e(Z,Vv),e(Vv,v1e),e(v1e,eZo),e(Vv,oZo),e(Vv,PW),e(PW,rZo),e(Vv,tZo),e(Z,aZo),e(Z,Xv),e(Xv,F1e),e(F1e,nZo),e(Xv,sZo),e(Xv,BW),e(BW,lZo),e(Xv,iZo),e(Z,dZo),e(Z,zv),e(zv,T1e),e(T1e,cZo),e(zv,fZo),e(zv,IW),e(IW,mZo),e(zv,gZo),e(Z,hZo),e(Z,Wv),e(Wv,M1e),e(M1e,pZo),e(Wv,_Zo),e(Wv,NW),e(NW,uZo),e(Wv,bZo),e(Z,vZo),e(Z,Qv),e(Qv,E1e),e(E1e,FZo),e(Qv,TZo),e(Qv,qW),e(qW,MZo),e(Qv,EZo),e(Z,CZo),e(Z,Uv),e(Uv,C1e),e(C1e,wZo),e(Uv,AZo),e(Uv,jW),e(jW,LZo),e(Uv,yZo),e(to,xZo),e(to,Hv),e(Hv,$Zo),e(Hv,w1e),e(w1e,kZo),e(Hv,SZo),e(Hv,A1e),e(A1e,RZo),e(to,PZo),M(Jv,to,null),b(f,mQe,u),b(f,ud,u),e(ud,Yv),e(Yv,L1e),M(e9,L1e,null),e(ud,BZo),e(ud,y1e),e(y1e,IZo),b(f,gQe,u),b(f,jo,u),M(o9,jo,null),e(jo,NZo),e(jo,bd),e(bd,qZo),e(bd,DW),e(DW,jZo),e(bd,DZo),e(bd,GW),e(GW,GZo),e(bd,OZo),e(jo,VZo),e(jo,r9),e(r9,XZo),e(r9,x1e),e(x1e,zZo),e(r9,WZo),e(jo,QZo),e(jo,ut),M(t9,ut,null),e(ut,UZo),e(ut,$1e),e($1e,HZo),e(ut,JZo),e(ut,vd),e(vd,YZo),e(vd,k1e),e(k1e,KZo),e(vd,ZZo),e(vd,OW),e(OW,eer),e(vd,oer),e(ut,rer),M(Kv,ut,null),e(jo,ter),e(jo,ao),M(a9,ao,null),e(ao,aer),e(ao,S1e),e(S1e,ner),e(ao,ser),e(ao,Qa),e(Qa,ler),e(Qa,R1e),e(R1e,ier),e(Qa,der),e(Qa,P1e),e(P1e,cer),e(Qa,fer),e(Qa,B1e),e(B1e,mer),e(Qa,ger),e(ao,her),e(ao,Do),e(Do,Zv),e(Zv,I1e),e(I1e,per),e(Zv,_er),e(Zv,VW),e(VW,uer),e(Zv,ber),e(Do,ver),e(Do,e5),e(e5,N1e),e(N1e,Fer),e(e5,Ter),e(e5,XW),e(XW,Mer),e(e5,Eer),e(Do,Cer),e(Do,o5),e(o5,q1e),e(q1e,wer),e(o5,Aer),e(o5,zW),e(zW,Ler),e(o5,yer),e(Do,xer),e(Do,r5),e(r5,j1e),e(j1e,$er),e(r5,ker),e(r5,WW),e(WW,Ser),e(r5,Rer),e(Do,Per),e(Do,t5),e(t5,D1e),e(D1e,Ber),e(t5,Ier),e(t5,QW),e(QW,Ner),e(t5,qer),e(Do,jer),e(Do,a5),e(a5,G1e),e(G1e,Der),e(a5,Ger),e(a5,UW),e(UW,Oer),e(a5,Ver),e(ao,Xer),e(ao,n5),e(n5,zer),e(n5,O1e),e(O1e,Wer),e(n5,Qer),e(n5,V1e),e(V1e,Uer),e(ao,Her),M(s5,ao,null),b(f,hQe,u),b(f,Fd,u),e(Fd,l5),e(l5,X1e),M(n9,X1e,null),e(Fd,Jer),e(Fd,z1e),e(z1e,Yer),b(f,pQe,u),b(f,Go,u),M(s9,Go,null),e(Go,Ker),e(Go,Td),e(Td,Zer),e(Td,HW),e(HW,eor),e(Td,oor),e(Td,JW),e(JW,ror),e(Td,tor),e(Go,aor),e(Go,l9),e(l9,nor),e(l9,W1e),e(W1e,sor),e(l9,lor),e(Go,ior),e(Go,bt),M(i9,bt,null),e(bt,dor),e(bt,Q1e),e(Q1e,cor),e(bt,mor),e(bt,Md),e(Md,gor),e(Md,U1e),e(U1e,hor),e(Md,por),e(Md,YW),e(YW,_or),e(Md,uor),e(bt,bor),M(i5,bt,null),e(Go,vor),e(Go,no),M(d9,no,null),e(no,For),e(no,H1e),e(H1e,Tor),e(no,Mor),e(no,Ua),e(Ua,Eor),e(Ua,J1e),e(J1e,Cor),e(Ua,wor),e(Ua,Y1e),e(Y1e,Aor),e(Ua,Lor),e(Ua,K1e),e(K1e,yor),e(Ua,xor),e(no,$or),e(no,H),e(H,d5),e(d5,Z1e),e(Z1e,kor),e(d5,Sor),e(d5,KW),e(KW,Ror),e(d5,Por),e(H,Bor),e(H,c5),e(c5,e4e),e(e4e,Ior),e(c5,Nor),e(c5,ZW),e(ZW,qor),e(c5,jor),e(H,Dor),e(H,f5),e(f5,o4e),e(o4e,Gor),e(f5,Oor),e(f5,eQ),e(eQ,Vor),e(f5,Xor),e(H,zor),e(H,m5),e(m5,r4e),e(r4e,Wor),e(m5,Qor),e(m5,oQ),e(oQ,Uor),e(m5,Hor),e(H,Jor),e(H,g5),e(g5,t4e),e(t4e,Yor),e(g5,Kor),e(g5,rQ),e(rQ,Zor),e(g5,err),e(H,orr),e(H,h5),e(h5,a4e),e(a4e,rrr),e(h5,trr),e(h5,tQ),e(tQ,arr),e(h5,nrr),e(H,srr),e(H,p5),e(p5,n4e),e(n4e,lrr),e(p5,irr),e(p5,aQ),e(aQ,drr),e(p5,crr),e(H,frr),e(H,_5),e(_5,s4e),e(s4e,mrr),e(_5,grr),e(_5,nQ),e(nQ,hrr),e(_5,prr),e(H,_rr),e(H,u5),e(u5,l4e),e(l4e,urr),e(u5,brr),e(u5,sQ),e(sQ,vrr),e(u5,Frr),e(H,Trr),e(H,b5),e(b5,i4e),e(i4e,Mrr),e(b5,Err),e(b5,lQ),e(lQ,Crr),e(b5,wrr),e(H,Arr),e(H,v5),e(v5,d4e),e(d4e,Lrr),e(v5,yrr),e(v5,iQ),e(iQ,xrr),e(v5,$rr),e(H,krr),e(H,F5),e(F5,c4e),e(c4e,Srr),e(F5,Rrr),e(F5,dQ),e(dQ,Prr),e(F5,Brr),e(H,Irr),e(H,T5),e(T5,f4e),e(f4e,Nrr),e(T5,qrr),e(T5,cQ),e(cQ,jrr),e(T5,Drr),e(H,Grr),e(H,M5),e(M5,m4e),e(m4e,Orr),e(M5,Vrr),e(M5,fQ),e(fQ,Xrr),e(M5,zrr),e(H,Wrr),e(H,E5),e(E5,g4e),e(g4e,Qrr),e(E5,Urr),e(E5,mQ),e(mQ,Hrr),e(E5,Jrr),e(H,Yrr),e(H,C5),e(C5,h4e),e(h4e,Krr),e(C5,Zrr),e(C5,gQ),e(gQ,etr),e(C5,otr),e(H,rtr),e(H,w5),e(w5,p4e),e(p4e,ttr),e(w5,atr),e(w5,hQ),e(hQ,ntr),e(w5,str),e(H,ltr),e(H,A5),e(A5,_4e),e(_4e,itr),e(A5,dtr),e(A5,pQ),e(pQ,ctr),e(A5,ftr),e(H,mtr),e(H,L5),e(L5,u4e),e(u4e,gtr),e(L5,htr),e(L5,_Q),e(_Q,ptr),e(L5,_tr),e(H,utr),e(H,y5),e(y5,b4e),e(b4e,btr),e(y5,vtr),e(y5,uQ),e(uQ,Ftr),e(y5,Ttr),e(H,Mtr),e(H,x5),e(x5,v4e),e(v4e,Etr),e(x5,Ctr),e(x5,bQ),e(bQ,wtr),e(x5,Atr),e(H,Ltr),e(H,$5),e($5,F4e),e(F4e,ytr),e($5,xtr),e($5,vQ),e(vQ,$tr),e($5,ktr),e(H,Str),e(H,k5),e(k5,T4e),e(T4e,Rtr),e(k5,Ptr),e(k5,FQ),e(FQ,Btr),e(k5,Itr),e(H,Ntr),e(H,S5),e(S5,M4e),e(M4e,qtr),e(S5,jtr),e(S5,TQ),e(TQ,Dtr),e(S5,Gtr),e(H,Otr),e(H,R5),e(R5,E4e),e(E4e,Vtr),e(R5,Xtr),e(R5,MQ),e(MQ,ztr),e(R5,Wtr),e(H,Qtr),e(H,P5),e(P5,C4e),e(C4e,Utr),e(P5,Htr),e(P5,EQ),e(EQ,Jtr),e(P5,Ytr),e(H,Ktr),e(H,B5),e(B5,w4e),e(w4e,Ztr),e(B5,ear),e(B5,CQ),e(CQ,oar),e(B5,rar),e(H,tar),e(H,I5),e(I5,A4e),e(A4e,aar),e(I5,nar),e(I5,wQ),e(wQ,sar),e(I5,lar),e(H,iar),e(H,N5),e(N5,L4e),e(L4e,dar),e(N5,car),e(N5,AQ),e(AQ,far),e(N5,mar),e(H,gar),e(H,q5),e(q5,y4e),e(y4e,har),e(q5,par),e(q5,LQ),e(LQ,_ar),e(q5,uar),e(H,bar),e(H,j5),e(j5,x4e),e(x4e,Far),e(j5,Tar),e(j5,yQ),e(yQ,Mar),e(j5,Ear),e(H,Car),e(H,D5),e(D5,$4e),e($4e,war),e(D5,Aar),e(D5,xQ),e(xQ,Lar),e(D5,yar),e(H,xar),e(H,G5),e(G5,k4e),e(k4e,$ar),e(G5,kar),e(G5,$Q),e($Q,Sar),e(G5,Rar),e(H,Par),e(H,O5),e(O5,S4e),e(S4e,Bar),e(O5,Iar),e(O5,kQ),e(kQ,Nar),e(O5,qar),e(H,jar),e(H,V5),e(V5,R4e),e(R4e,Dar),e(V5,Gar),e(V5,SQ),e(SQ,Oar),e(V5,Var),e(H,Xar),e(H,X5),e(X5,P4e),e(P4e,zar),e(X5,War),e(X5,RQ),e(RQ,Qar),e(X5,Uar),e(H,Har),e(H,z5),e(z5,B4e),e(B4e,Jar),e(z5,Yar),e(z5,PQ),e(PQ,Kar),e(z5,Zar),e(no,enr),e(no,W5),e(W5,onr),e(W5,I4e),e(I4e,rnr),e(W5,tnr),e(W5,N4e),e(N4e,anr),e(no,nnr),M(Q5,no,null),b(f,_Qe,u),b(f,Ed,u),e(Ed,U5),e(U5,q4e),M(c9,q4e,null),e(Ed,snr),e(Ed,j4e),e(j4e,lnr),b(f,uQe,u),b(f,Oo,u),M(f9,Oo,null),e(Oo,inr),e(Oo,Cd),e(Cd,dnr),e(Cd,BQ),e(BQ,cnr),e(Cd,fnr),e(Cd,IQ),e(IQ,mnr),e(Cd,gnr),e(Oo,hnr),e(Oo,m9),e(m9,pnr),e(m9,D4e),e(D4e,_nr),e(m9,unr),e(Oo,bnr),e(Oo,vt),M(g9,vt,null),e(vt,vnr),e(vt,G4e),e(G4e,Fnr),e(vt,Tnr),e(vt,wd),e(wd,Mnr),e(wd,O4e),e(O4e,Enr),e(wd,Cnr),e(wd,NQ),e(NQ,wnr),e(wd,Anr),e(vt,Lnr),M(H5,vt,null),e(Oo,ynr),e(Oo,so),M(h9,so,null),e(so,xnr),e(so,V4e),e(V4e,$nr),e(so,knr),e(so,Ha),e(Ha,Snr),e(Ha,X4e),e(X4e,Rnr),e(Ha,Pnr),e(Ha,z4e),e(z4e,Bnr),e(Ha,Inr),e(Ha,W4e),e(W4e,Nnr),e(Ha,qnr),e(so,jnr),e(so,V),e(V,J5),e(J5,Q4e),e(Q4e,Dnr),e(J5,Gnr),e(J5,qQ),e(qQ,Onr),e(J5,Vnr),e(V,Xnr),e(V,Y5),e(Y5,U4e),e(U4e,znr),e(Y5,Wnr),e(Y5,jQ),e(jQ,Qnr),e(Y5,Unr),e(V,Hnr),e(V,K5),e(K5,H4e),e(H4e,Jnr),e(K5,Ynr),e(K5,DQ),e(DQ,Knr),e(K5,Znr),e(V,esr),e(V,Z5),e(Z5,J4e),e(J4e,osr),e(Z5,rsr),e(Z5,GQ),e(GQ,tsr),e(Z5,asr),e(V,nsr),e(V,eF),e(eF,Y4e),e(Y4e,ssr),e(eF,lsr),e(eF,OQ),e(OQ,isr),e(eF,dsr),e(V,csr),e(V,oF),e(oF,K4e),e(K4e,fsr),e(oF,msr),e(oF,VQ),e(VQ,gsr),e(oF,hsr),e(V,psr),e(V,rF),e(rF,Z4e),e(Z4e,_sr),e(rF,usr),e(rF,XQ),e(XQ,bsr),e(rF,vsr),e(V,Fsr),e(V,tF),e(tF,ebe),e(ebe,Tsr),e(tF,Msr),e(tF,zQ),e(zQ,Esr),e(tF,Csr),e(V,wsr),e(V,aF),e(aF,obe),e(obe,Asr),e(aF,Lsr),e(aF,WQ),e(WQ,ysr),e(aF,xsr),e(V,$sr),e(V,nF),e(nF,rbe),e(rbe,ksr),e(nF,Ssr),e(nF,QQ),e(QQ,Rsr),e(nF,Psr),e(V,Bsr),e(V,sF),e(sF,tbe),e(tbe,Isr),e(sF,Nsr),e(sF,UQ),e(UQ,qsr),e(sF,jsr),e(V,Dsr),e(V,lF),e(lF,abe),e(abe,Gsr),e(lF,Osr),e(lF,HQ),e(HQ,Vsr),e(lF,Xsr),e(V,zsr),e(V,iF),e(iF,nbe),e(nbe,Wsr),e(iF,Qsr),e(iF,JQ),e(JQ,Usr),e(iF,Hsr),e(V,Jsr),e(V,dF),e(dF,sbe),e(sbe,Ysr),e(dF,Ksr),e(dF,YQ),e(YQ,Zsr),e(dF,elr),e(V,olr),e(V,cF),e(cF,lbe),e(lbe,rlr),e(cF,tlr),e(cF,KQ),e(KQ,alr),e(cF,nlr),e(V,slr),e(V,fF),e(fF,ibe),e(ibe,llr),e(fF,ilr),e(fF,ZQ),e(ZQ,dlr),e(fF,clr),e(V,flr),e(V,mF),e(mF,dbe),e(dbe,mlr),e(mF,glr),e(mF,eU),e(eU,hlr),e(mF,plr),e(V,_lr),e(V,gF),e(gF,cbe),e(cbe,ulr),e(gF,blr),e(gF,oU),e(oU,vlr),e(gF,Flr),e(V,Tlr),e(V,hF),e(hF,fbe),e(fbe,Mlr),e(hF,Elr),e(hF,rU),e(rU,Clr),e(hF,wlr),e(V,Alr),e(V,pF),e(pF,mbe),e(mbe,Llr),e(pF,ylr),e(pF,tU),e(tU,xlr),e(pF,$lr),e(V,klr),e(V,_F),e(_F,gbe),e(gbe,Slr),e(_F,Rlr),e(_F,aU),e(aU,Plr),e(_F,Blr),e(V,Ilr),e(V,uF),e(uF,hbe),e(hbe,Nlr),e(uF,qlr),e(uF,nU),e(nU,jlr),e(uF,Dlr),e(V,Glr),e(V,bF),e(bF,pbe),e(pbe,Olr),e(bF,Vlr),e(bF,sU),e(sU,Xlr),e(bF,zlr),e(V,Wlr),e(V,vF),e(vF,_be),e(_be,Qlr),e(vF,Ulr),e(vF,lU),e(lU,Hlr),e(vF,Jlr),e(V,Ylr),e(V,FF),e(FF,ube),e(ube,Klr),e(FF,Zlr),e(FF,iU),e(iU,eir),e(FF,oir),e(V,rir),e(V,TF),e(TF,bbe),e(bbe,tir),e(TF,air),e(TF,dU),e(dU,nir),e(TF,sir),e(V,lir),e(V,MF),e(MF,vbe),e(vbe,iir),e(MF,dir),e(MF,cU),e(cU,cir),e(MF,fir),e(V,mir),e(V,EF),e(EF,Fbe),e(Fbe,gir),e(EF,hir),e(EF,fU),e(fU,pir),e(EF,_ir),e(V,uir),e(V,CF),e(CF,Tbe),e(Tbe,bir),e(CF,vir),e(CF,mU),e(mU,Fir),e(CF,Tir),e(V,Mir),e(V,wF),e(wF,Mbe),e(Mbe,Eir),e(wF,Cir),e(wF,gU),e(gU,wir),e(wF,Air),e(V,Lir),e(V,AF),e(AF,Ebe),e(Ebe,yir),e(AF,xir),e(AF,hU),e(hU,$ir),e(AF,kir),e(V,Sir),e(V,LF),e(LF,Cbe),e(Cbe,Rir),e(LF,Pir),e(LF,pU),e(pU,Bir),e(LF,Iir),e(V,Nir),e(V,yF),e(yF,wbe),e(wbe,qir),e(yF,jir),e(yF,_U),e(_U,Dir),e(yF,Gir),e(V,Oir),e(V,xF),e(xF,Abe),e(Abe,Vir),e(xF,Xir),e(xF,uU),e(uU,zir),e(xF,Wir),e(V,Qir),e(V,$F),e($F,Lbe),e(Lbe,Uir),e($F,Hir),e($F,bU),e(bU,Jir),e($F,Yir),e(V,Kir),e(V,kF),e(kF,ybe),e(ybe,Zir),e(kF,edr),e(kF,vU),e(vU,odr),e(kF,rdr),e(V,tdr),e(V,SF),e(SF,xbe),e(xbe,adr),e(SF,ndr),e(SF,FU),e(FU,sdr),e(SF,ldr),e(V,idr),e(V,RF),e(RF,$be),e($be,ddr),e(RF,cdr),e(RF,TU),e(TU,fdr),e(RF,mdr),e(V,gdr),e(V,PF),e(PF,kbe),e(kbe,hdr),e(PF,pdr),e(PF,MU),e(MU,_dr),e(PF,udr),e(V,bdr),e(V,BF),e(BF,Sbe),e(Sbe,vdr),e(BF,Fdr),e(BF,EU),e(EU,Tdr),e(BF,Mdr),e(V,Edr),e(V,IF),e(IF,Rbe),e(Rbe,Cdr),e(IF,wdr),e(IF,CU),e(CU,Adr),e(IF,Ldr),e(V,ydr),e(V,NF),e(NF,Pbe),e(Pbe,xdr),e(NF,$dr),e(NF,wU),e(wU,kdr),e(NF,Sdr),e(V,Rdr),e(V,qF),e(qF,Bbe),e(Bbe,Pdr),e(qF,Bdr),e(qF,AU),e(AU,Idr),e(qF,Ndr),e(so,qdr),e(so,jF),e(jF,jdr),e(jF,Ibe),e(Ibe,Ddr),e(jF,Gdr),e(jF,Nbe),e(Nbe,Odr),e(so,Vdr),M(DF,so,null),b(f,bQe,u),b(f,Ad,u),e(Ad,GF),e(GF,qbe),M(p9,qbe,null),e(Ad,Xdr),e(Ad,jbe),e(jbe,zdr),b(f,vQe,u),b(f,Vo,u),M(_9,Vo,null),e(Vo,Wdr),e(Vo,Ld),e(Ld,Qdr),e(Ld,LU),e(LU,Udr),e(Ld,Hdr),e(Ld,yU),e(yU,Jdr),e(Ld,Ydr),e(Vo,Kdr),e(Vo,u9),e(u9,Zdr),e(u9,Dbe),e(Dbe,ecr),e(u9,ocr),e(Vo,rcr),e(Vo,Ft),M(b9,Ft,null),e(Ft,tcr),e(Ft,Gbe),e(Gbe,acr),e(Ft,ncr),e(Ft,yd),e(yd,scr),e(yd,Obe),e(Obe,lcr),e(yd,icr),e(yd,xU),e(xU,dcr),e(yd,ccr),e(Ft,fcr),M(OF,Ft,null),e(Vo,mcr),e(Vo,lo),M(v9,lo,null),e(lo,gcr),e(lo,Vbe),e(Vbe,hcr),e(lo,pcr),e(lo,Ja),e(Ja,_cr),e(Ja,Xbe),e(Xbe,ucr),e(Ja,bcr),e(Ja,zbe),e(zbe,vcr),e(Ja,Fcr),e(Ja,Wbe),e(Wbe,Tcr),e(Ja,Mcr),e(lo,Ecr),e(lo,Qbe),e(Qbe,VF),e(VF,Ube),e(Ube,Ccr),e(VF,wcr),e(VF,$U),e($U,Acr),e(VF,Lcr),e(lo,ycr),e(lo,XF),e(XF,xcr),e(XF,Hbe),e(Hbe,$cr),e(XF,kcr),e(XF,Jbe),e(Jbe,Scr),e(lo,Rcr),M(zF,lo,null),b(f,FQe,u),b(f,xd,u),e(xd,WF),e(WF,Ybe),M(F9,Ybe,null),e(xd,Pcr),e(xd,Kbe),e(Kbe,Bcr),b(f,TQe,u),b(f,Xo,u),M(T9,Xo,null),e(Xo,Icr),e(Xo,$d),e($d,Ncr),e($d,kU),e(kU,qcr),e($d,jcr),e($d,SU),e(SU,Dcr),e($d,Gcr),e(Xo,Ocr),e(Xo,M9),e(M9,Vcr),e(M9,Zbe),e(Zbe,Xcr),e(M9,zcr),e(Xo,Wcr),e(Xo,Tt),M(E9,Tt,null),e(Tt,Qcr),e(Tt,eve),e(eve,Ucr),e(Tt,Hcr),e(Tt,kd),e(kd,Jcr),e(kd,ove),e(ove,Ycr),e(kd,Kcr),e(kd,RU),e(RU,Zcr),e(kd,efr),e(Tt,ofr),M(QF,Tt,null),e(Xo,rfr),e(Xo,io),M(C9,io,null),e(io,tfr),e(io,rve),e(rve,afr),e(io,nfr),e(io,Ya),e(Ya,sfr),e(Ya,tve),e(tve,lfr),e(Ya,ifr),e(Ya,ave),e(ave,dfr),e(Ya,cfr),e(Ya,nve),e(nve,ffr),e(Ya,mfr),e(io,gfr),e(io,be),e(be,UF),e(UF,sve),e(sve,hfr),e(UF,pfr),e(UF,PU),e(PU,_fr),e(UF,ufr),e(be,bfr),e(be,HF),e(HF,lve),e(lve,vfr),e(HF,Ffr),e(HF,BU),e(BU,Tfr),e(HF,Mfr),e(be,Efr),e(be,JF),e(JF,ive),e(ive,Cfr),e(JF,wfr),e(JF,IU),e(IU,Afr),e(JF,Lfr),e(be,yfr),e(be,YF),e(YF,dve),e(dve,xfr),e(YF,$fr),e(YF,NU),e(NU,kfr),e(YF,Sfr),e(be,Rfr),e(be,rl),e(rl,cve),e(cve,Pfr),e(rl,Bfr),e(rl,qU),e(qU,Ifr),e(rl,Nfr),e(rl,jU),e(jU,qfr),e(rl,jfr),e(be,Dfr),e(be,KF),e(KF,fve),e(fve,Gfr),e(KF,Ofr),e(KF,DU),e(DU,Vfr),e(KF,Xfr),e(be,zfr),e(be,tl),e(tl,mve),e(mve,Wfr),e(tl,Qfr),e(tl,GU),e(GU,Ufr),e(tl,Hfr),e(tl,OU),e(OU,Jfr),e(tl,Yfr),e(be,Kfr),e(be,ZF),e(ZF,gve),e(gve,Zfr),e(ZF,emr),e(ZF,VU),e(VU,omr),e(ZF,rmr),e(be,tmr),e(be,Mt),e(Mt,hve),e(hve,amr),e(Mt,nmr),e(Mt,XU),e(XU,smr),e(Mt,lmr),e(Mt,zU),e(zU,imr),e(Mt,dmr),e(Mt,WU),e(WU,cmr),e(Mt,fmr),e(be,mmr),e(be,eT),e(eT,pve),e(pve,gmr),e(eT,hmr),e(eT,QU),e(QU,pmr),e(eT,_mr),e(be,umr),e(be,oT),e(oT,_ve),e(_ve,bmr),e(oT,vmr),e(oT,UU),e(UU,Fmr),e(oT,Tmr),e(be,Mmr),e(be,rT),e(rT,uve),e(uve,Emr),e(rT,Cmr),e(rT,HU),e(HU,wmr),e(rT,Amr),e(be,Lmr),e(be,tT),e(tT,bve),e(bve,ymr),e(tT,xmr),e(tT,JU),e(JU,$mr),e(tT,kmr),e(be,Smr),e(be,aT),e(aT,vve),e(vve,Rmr),e(aT,Pmr),e(aT,YU),e(YU,Bmr),e(aT,Imr),e(be,Nmr),e(be,nT),e(nT,Fve),e(Fve,qmr),e(nT,jmr),e(nT,KU),e(KU,Dmr),e(nT,Gmr),e(be,Omr),e(be,sT),e(sT,Tve),e(Tve,Vmr),e(sT,Xmr),e(sT,ZU),e(ZU,zmr),e(sT,Wmr),e(be,Qmr),e(be,lT),e(lT,Mve),e(Mve,Umr),e(lT,Hmr),e(lT,eH),e(eH,Jmr),e(lT,Ymr),e(io,Kmr),e(io,iT),e(iT,Zmr),e(iT,Eve),e(Eve,egr),e(iT,ogr),e(iT,Cve),e(Cve,rgr),e(io,tgr),M(dT,io,null),b(f,MQe,u),b(f,Sd,u),e(Sd,cT),e(cT,wve),M(w9,wve,null),e(Sd,agr),e(Sd,Ave),e(Ave,ngr),b(f,EQe,u),b(f,zo,u),M(A9,zo,null),e(zo,sgr),e(zo,Rd),e(Rd,lgr),e(Rd,oH),e(oH,igr),e(Rd,dgr),e(Rd,rH),e(rH,cgr),e(Rd,fgr),e(zo,mgr),e(zo,L9),e(L9,ggr),e(L9,Lve),e(Lve,hgr),e(L9,pgr),e(zo,_gr),e(zo,Et),M(y9,Et,null),e(Et,ugr),e(Et,yve),e(yve,bgr),e(Et,vgr),e(Et,Pd),e(Pd,Fgr),e(Pd,xve),e(xve,Tgr),e(Pd,Mgr),e(Pd,tH),e(tH,Egr),e(Pd,Cgr),e(Et,wgr),M(fT,Et,null),e(zo,Agr),e(zo,co),M(x9,co,null),e(co,Lgr),e(co,$ve),e($ve,ygr),e(co,xgr),e(co,Ka),e(Ka,$gr),e(Ka,kve),e(kve,kgr),e(Ka,Sgr),e(Ka,Sve),e(Sve,Rgr),e(Ka,Pgr),e(Ka,Rve),e(Rve,Bgr),e(Ka,Igr),e(co,Ngr),e(co,Pve),e(Pve,mT),e(mT,Bve),e(Bve,qgr),e(mT,jgr),e(mT,aH),e(aH,Dgr),e(mT,Ggr),e(co,Ogr),e(co,gT),e(gT,Vgr),e(gT,Ive),e(Ive,Xgr),e(gT,zgr),e(gT,Nve),e(Nve,Wgr),e(co,Qgr),M(hT,co,null),b(f,CQe,u),b(f,Bd,u),e(Bd,pT),e(pT,qve),M($9,qve,null),e(Bd,Ugr),e(Bd,jve),e(jve,Hgr),b(f,wQe,u),b(f,Wo,u),M(k9,Wo,null),e(Wo,Jgr),e(Wo,Id),e(Id,Ygr),e(Id,nH),e(nH,Kgr),e(Id,Zgr),e(Id,sH),e(sH,ehr),e(Id,ohr),e(Wo,rhr),e(Wo,S9),e(S9,thr),e(S9,Dve),e(Dve,ahr),e(S9,nhr),e(Wo,shr),e(Wo,Ct),M(R9,Ct,null),e(Ct,lhr),e(Ct,Gve),e(Gve,ihr),e(Ct,dhr),e(Ct,Nd),e(Nd,chr),e(Nd,Ove),e(Ove,fhr),e(Nd,mhr),e(Nd,lH),e(lH,ghr),e(Nd,hhr),e(Ct,phr),M(_T,Ct,null),e(Wo,_hr),e(Wo,fo),M(P9,fo,null),e(fo,uhr),e(fo,Vve),e(Vve,bhr),e(fo,vhr),e(fo,Za),e(Za,Fhr),e(Za,Xve),e(Xve,Thr),e(Za,Mhr),e(Za,zve),e(zve,Ehr),e(Za,Chr),e(Za,Wve),e(Wve,whr),e(Za,Ahr),e(fo,Lhr),e(fo,Qve),e(Qve,uT),e(uT,Uve),e(Uve,yhr),e(uT,xhr),e(uT,iH),e(iH,$hr),e(uT,khr),e(fo,Shr),e(fo,bT),e(bT,Rhr),e(bT,Hve),e(Hve,Phr),e(bT,Bhr),e(bT,Jve),e(Jve,Ihr),e(fo,Nhr),M(vT,fo,null),b(f,AQe,u),b(f,qd,u),e(qd,FT),e(FT,Yve),M(B9,Yve,null),e(qd,qhr),e(qd,Kve),e(Kve,jhr),b(f,LQe,u),b(f,Qo,u),M(I9,Qo,null),e(Qo,Dhr),e(Qo,jd),e(jd,Ghr),e(jd,dH),e(dH,Ohr),e(jd,Vhr),e(jd,cH),e(cH,Xhr),e(jd,zhr),e(Qo,Whr),e(Qo,N9),e(N9,Qhr),e(N9,Zve),e(Zve,Uhr),e(N9,Hhr),e(Qo,Jhr),e(Qo,wt),M(q9,wt,null),e(wt,Yhr),e(wt,e5e),e(e5e,Khr),e(wt,Zhr),e(wt,Dd),e(Dd,epr),e(Dd,o5e),e(o5e,opr),e(Dd,rpr),e(Dd,fH),e(fH,tpr),e(Dd,apr),e(wt,npr),M(TT,wt,null),e(Qo,spr),e(Qo,mo),M(j9,mo,null),e(mo,lpr),e(mo,r5e),e(r5e,ipr),e(mo,dpr),e(mo,en),e(en,cpr),e(en,t5e),e(t5e,fpr),e(en,mpr),e(en,a5e),e(a5e,gpr),e(en,hpr),e(en,n5e),e(n5e,ppr),e(en,_pr),e(mo,upr),e(mo,s5e),e(s5e,MT),e(MT,l5e),e(l5e,bpr),e(MT,vpr),e(MT,mH),e(mH,Fpr),e(MT,Tpr),e(mo,Mpr),e(mo,ET),e(ET,Epr),e(ET,i5e),e(i5e,Cpr),e(ET,wpr),e(ET,d5e),e(d5e,Apr),e(mo,Lpr),M(CT,mo,null),b(f,yQe,u),b(f,Gd,u),e(Gd,wT),e(wT,c5e),M(D9,c5e,null),e(Gd,ypr),e(Gd,f5e),e(f5e,xpr),b(f,xQe,u),b(f,Uo,u),M(G9,Uo,null),e(Uo,$pr),e(Uo,Od),e(Od,kpr),e(Od,gH),e(gH,Spr),e(Od,Rpr),e(Od,hH),e(hH,Ppr),e(Od,Bpr),e(Uo,Ipr),e(Uo,O9),e(O9,Npr),e(O9,m5e),e(m5e,qpr),e(O9,jpr),e(Uo,Dpr),e(Uo,At),M(V9,At,null),e(At,Gpr),e(At,g5e),e(g5e,Opr),e(At,Vpr),e(At,Vd),e(Vd,Xpr),e(Vd,h5e),e(h5e,zpr),e(Vd,Wpr),e(Vd,pH),e(pH,Qpr),e(Vd,Upr),e(At,Hpr),M(AT,At,null),e(Uo,Jpr),e(Uo,go),M(X9,go,null),e(go,Ypr),e(go,p5e),e(p5e,Kpr),e(go,Zpr),e(go,on),e(on,e_r),e(on,_5e),e(_5e,o_r),e(on,r_r),e(on,u5e),e(u5e,t_r),e(on,a_r),e(on,b5e),e(b5e,n_r),e(on,s_r),e(go,l_r),e(go,Pe),e(Pe,LT),e(LT,v5e),e(v5e,i_r),e(LT,d_r),e(LT,_H),e(_H,c_r),e(LT,f_r),e(Pe,m_r),e(Pe,yT),e(yT,F5e),e(F5e,g_r),e(yT,h_r),e(yT,uH),e(uH,p_r),e(yT,__r),e(Pe,u_r),e(Pe,xT),e(xT,T5e),e(T5e,b_r),e(xT,v_r),e(xT,bH),e(bH,F_r),e(xT,T_r),e(Pe,M_r),e(Pe,$T),e($T,M5e),e(M5e,E_r),e($T,C_r),e($T,vH),e(vH,w_r),e($T,A_r),e(Pe,L_r),e(Pe,kT),e(kT,E5e),e(E5e,y_r),e(kT,x_r),e(kT,FH),e(FH,$_r),e(kT,k_r),e(Pe,S_r),e(Pe,ST),e(ST,C5e),e(C5e,R_r),e(ST,P_r),e(ST,TH),e(TH,B_r),e(ST,I_r),e(Pe,N_r),e(Pe,RT),e(RT,w5e),e(w5e,q_r),e(RT,j_r),e(RT,MH),e(MH,D_r),e(RT,G_r),e(Pe,O_r),e(Pe,PT),e(PT,A5e),e(A5e,V_r),e(PT,X_r),e(PT,EH),e(EH,z_r),e(PT,W_r),e(Pe,Q_r),e(Pe,BT),e(BT,L5e),e(L5e,U_r),e(BT,H_r),e(BT,CH),e(CH,J_r),e(BT,Y_r),e(go,K_r),e(go,IT),e(IT,Z_r),e(IT,y5e),e(y5e,eur),e(IT,our),e(IT,x5e),e(x5e,rur),e(go,tur),M(NT,go,null),b(f,$Qe,u),b(f,Xd,u),e(Xd,qT),e(qT,$5e),M(z9,$5e,null),e(Xd,aur),e(Xd,k5e),e(k5e,nur),b(f,kQe,u),b(f,Ho,u),M(W9,Ho,null),e(Ho,sur),e(Ho,zd),e(zd,lur),e(zd,wH),e(wH,iur),e(zd,dur),e(zd,AH),e(AH,cur),e(zd,fur),e(Ho,mur),e(Ho,Q9),e(Q9,gur),e(Q9,S5e),e(S5e,hur),e(Q9,pur),e(Ho,_ur),e(Ho,Lt),M(U9,Lt,null),e(Lt,uur),e(Lt,R5e),e(R5e,bur),e(Lt,vur),e(Lt,Wd),e(Wd,Fur),e(Wd,P5e),e(P5e,Tur),e(Wd,Mur),e(Wd,LH),e(LH,Eur),e(Wd,Cur),e(Lt,wur),M(jT,Lt,null),e(Ho,Aur),e(Ho,ho),M(H9,ho,null),e(ho,Lur),e(ho,B5e),e(B5e,yur),e(ho,xur),e(ho,rn),e(rn,$ur),e(rn,I5e),e(I5e,kur),e(rn,Sur),e(rn,N5e),e(N5e,Rur),e(rn,Pur),e(rn,q5e),e(q5e,Bur),e(rn,Iur),e(ho,Nur),e(ho,at),e(at,DT),e(DT,j5e),e(j5e,qur),e(DT,jur),e(DT,yH),e(yH,Dur),e(DT,Gur),e(at,Our),e(at,GT),e(GT,D5e),e(D5e,Vur),e(GT,Xur),e(GT,xH),e(xH,zur),e(GT,Wur),e(at,Qur),e(at,OT),e(OT,G5e),e(G5e,Uur),e(OT,Hur),e(OT,$H),e($H,Jur),e(OT,Yur),e(at,Kur),e(at,VT),e(VT,O5e),e(O5e,Zur),e(VT,e2r),e(VT,kH),e(kH,o2r),e(VT,r2r),e(at,t2r),e(at,XT),e(XT,V5e),e(V5e,a2r),e(XT,n2r),e(XT,SH),e(SH,s2r),e(XT,l2r),e(ho,i2r),e(ho,zT),e(zT,d2r),e(zT,X5e),e(X5e,c2r),e(zT,f2r),e(zT,z5e),e(z5e,m2r),e(ho,g2r),M(WT,ho,null),b(f,SQe,u),b(f,Qd,u),e(Qd,QT),e(QT,W5e),M(J9,W5e,null),e(Qd,h2r),e(Qd,Q5e),e(Q5e,p2r),b(f,RQe,u),b(f,Jo,u),M(Y9,Jo,null),e(Jo,_2r),e(Jo,Ud),e(Ud,u2r),e(Ud,RH),e(RH,b2r),e(Ud,v2r),e(Ud,PH),e(PH,F2r),e(Ud,T2r),e(Jo,M2r),e(Jo,K9),e(K9,E2r),e(K9,U5e),e(U5e,C2r),e(K9,w2r),e(Jo,A2r),e(Jo,yt),M(Z9,yt,null),e(yt,L2r),e(yt,H5e),e(H5e,y2r),e(yt,x2r),e(yt,Hd),e(Hd,$2r),e(Hd,J5e),e(J5e,k2r),e(Hd,S2r),e(Hd,BH),e(BH,R2r),e(Hd,P2r),e(yt,B2r),M(UT,yt,null),e(Jo,I2r),e(Jo,po),M(ex,po,null),e(po,N2r),e(po,Y5e),e(Y5e,q2r),e(po,j2r),e(po,tn),e(tn,D2r),e(tn,K5e),e(K5e,G2r),e(tn,O2r),e(tn,Z5e),e(Z5e,V2r),e(tn,X2r),e(tn,eFe),e(eFe,z2r),e(tn,W2r),e(po,Q2r),e(po,Le),e(Le,HT),e(HT,oFe),e(oFe,U2r),e(HT,H2r),e(HT,IH),e(IH,J2r),e(HT,Y2r),e(Le,K2r),e(Le,JT),e(JT,rFe),e(rFe,Z2r),e(JT,e1r),e(JT,NH),e(NH,o1r),e(JT,r1r),e(Le,t1r),e(Le,YT),e(YT,tFe),e(tFe,a1r),e(YT,n1r),e(YT,qH),e(qH,s1r),e(YT,l1r),e(Le,i1r),e(Le,KT),e(KT,aFe),e(aFe,d1r),e(KT,c1r),e(KT,jH),e(jH,f1r),e(KT,m1r),e(Le,g1r),e(Le,ZT),e(ZT,nFe),e(nFe,h1r),e(ZT,p1r),e(ZT,DH),e(DH,_1r),e(ZT,u1r),e(Le,b1r),e(Le,e8),e(e8,sFe),e(sFe,v1r),e(e8,F1r),e(e8,GH),e(GH,T1r),e(e8,M1r),e(Le,E1r),e(Le,o8),e(o8,lFe),e(lFe,C1r),e(o8,w1r),e(o8,OH),e(OH,A1r),e(o8,L1r),e(Le,y1r),e(Le,r8),e(r8,iFe),e(iFe,x1r),e(r8,$1r),e(r8,VH),e(VH,k1r),e(r8,S1r),e(Le,R1r),e(Le,t8),e(t8,dFe),e(dFe,P1r),e(t8,B1r),e(t8,XH),e(XH,I1r),e(t8,N1r),e(Le,q1r),e(Le,a8),e(a8,cFe),e(cFe,j1r),e(a8,D1r),e(a8,zH),e(zH,G1r),e(a8,O1r),e(po,V1r),e(po,n8),e(n8,X1r),e(n8,fFe),e(fFe,z1r),e(n8,W1r),e(n8,mFe),e(mFe,Q1r),e(po,U1r),M(s8,po,null),b(f,PQe,u),b(f,Jd,u),e(Jd,l8),e(l8,gFe),M(ox,gFe,null),e(Jd,H1r),e(Jd,hFe),e(hFe,J1r),b(f,BQe,u),b(f,Yo,u),M(rx,Yo,null),e(Yo,Y1r),e(Yo,Yd),e(Yd,K1r),e(Yd,WH),e(WH,Z1r),e(Yd,e4r),e(Yd,QH),e(QH,o4r),e(Yd,r4r),e(Yo,t4r),e(Yo,tx),e(tx,a4r),e(tx,pFe),e(pFe,n4r),e(tx,s4r),e(Yo,l4r),e(Yo,xt),M(ax,xt,null),e(xt,i4r),e(xt,_Fe),e(_Fe,d4r),e(xt,c4r),e(xt,Kd),e(Kd,f4r),e(Kd,uFe),e(uFe,m4r),e(Kd,g4r),e(Kd,UH),e(UH,h4r),e(Kd,p4r),e(xt,_4r),M(i8,xt,null),e(Yo,u4r),e(Yo,_o),M(nx,_o,null),e(_o,b4r),e(_o,bFe),e(bFe,v4r),e(_o,F4r),e(_o,an),e(an,T4r),e(an,vFe),e(vFe,M4r),e(an,E4r),e(an,FFe),e(FFe,C4r),e(an,w4r),e(an,TFe),e(TFe,A4r),e(an,L4r),e(_o,y4r),e(_o,sx),e(sx,d8),e(d8,MFe),e(MFe,x4r),e(d8,$4r),e(d8,HH),e(HH,k4r),e(d8,S4r),e(sx,R4r),e(sx,c8),e(c8,EFe),e(EFe,P4r),e(c8,B4r),e(c8,JH),e(JH,I4r),e(c8,N4r),e(_o,q4r),e(_o,f8),e(f8,j4r),e(f8,CFe),e(CFe,D4r),e(f8,G4r),e(f8,wFe),e(wFe,O4r),e(_o,V4r),M(m8,_o,null),b(f,IQe,u),b(f,Zd,u),e(Zd,g8),e(g8,AFe),M(lx,AFe,null),e(Zd,X4r),e(Zd,LFe),e(LFe,z4r),b(f,NQe,u),b(f,Ko,u),M(ix,Ko,null),e(Ko,W4r),e(Ko,ec),e(ec,Q4r),e(ec,YH),e(YH,U4r),e(ec,H4r),e(ec,KH),e(KH,J4r),e(ec,Y4r),e(Ko,K4r),e(Ko,dx),e(dx,Z4r),e(dx,yFe),e(yFe,ebr),e(dx,obr),e(Ko,rbr),e(Ko,$t),M(cx,$t,null),e($t,tbr),e($t,xFe),e(xFe,abr),e($t,nbr),e($t,oc),e(oc,sbr),e(oc,$Fe),e($Fe,lbr),e(oc,ibr),e(oc,ZH),e(ZH,dbr),e(oc,cbr),e($t,fbr),M(h8,$t,null),e(Ko,mbr),e(Ko,uo),M(fx,uo,null),e(uo,gbr),e(uo,kFe),e(kFe,hbr),e(uo,pbr),e(uo,nn),e(nn,_br),e(nn,SFe),e(SFe,ubr),e(nn,bbr),e(nn,RFe),e(RFe,vbr),e(nn,Fbr),e(nn,PFe),e(PFe,Tbr),e(nn,Mbr),e(uo,Ebr),e(uo,nt),e(nt,p8),e(p8,BFe),e(BFe,Cbr),e(p8,wbr),e(p8,eJ),e(eJ,Abr),e(p8,Lbr),e(nt,ybr),e(nt,_8),e(_8,IFe),e(IFe,xbr),e(_8,$br),e(_8,oJ),e(oJ,kbr),e(_8,Sbr),e(nt,Rbr),e(nt,u8),e(u8,NFe),e(NFe,Pbr),e(u8,Bbr),e(u8,rJ),e(rJ,Ibr),e(u8,Nbr),e(nt,qbr),e(nt,b8),e(b8,qFe),e(qFe,jbr),e(b8,Dbr),e(b8,tJ),e(tJ,Gbr),e(b8,Obr),e(nt,Vbr),e(nt,v8),e(v8,jFe),e(jFe,Xbr),e(v8,zbr),e(v8,aJ),e(aJ,Wbr),e(v8,Qbr),e(uo,Ubr),e(uo,F8),e(F8,Hbr),e(F8,DFe),e(DFe,Jbr),e(F8,Ybr),e(F8,GFe),e(GFe,Kbr),e(uo,Zbr),M(T8,uo,null),b(f,qQe,u),b(f,rc,u),e(rc,M8),e(M8,OFe),M(mx,OFe,null),e(rc,evr),e(rc,VFe),e(VFe,ovr),b(f,jQe,u),b(f,Zo,u),M(gx,Zo,null),e(Zo,rvr),e(Zo,tc),e(tc,tvr),e(tc,nJ),e(nJ,avr),e(tc,nvr),e(tc,sJ),e(sJ,svr),e(tc,lvr),e(Zo,ivr),e(Zo,hx),e(hx,dvr),e(hx,XFe),e(XFe,cvr),e(hx,fvr),e(Zo,mvr),e(Zo,kt),M(px,kt,null),e(kt,gvr),e(kt,zFe),e(zFe,hvr),e(kt,pvr),e(kt,ac),e(ac,_vr),e(ac,WFe),e(WFe,uvr),e(ac,bvr),e(ac,lJ),e(lJ,vvr),e(ac,Fvr),e(kt,Tvr),M(E8,kt,null),e(Zo,Mvr),e(Zo,bo),M(_x,bo,null),e(bo,Evr),e(bo,QFe),e(QFe,Cvr),e(bo,wvr),e(bo,sn),e(sn,Avr),e(sn,UFe),e(UFe,Lvr),e(sn,yvr),e(sn,HFe),e(HFe,xvr),e(sn,$vr),e(sn,JFe),e(JFe,kvr),e(sn,Svr),e(bo,Rvr),e(bo,ln),e(ln,C8),e(C8,YFe),e(YFe,Pvr),e(C8,Bvr),e(C8,iJ),e(iJ,Ivr),e(C8,Nvr),e(ln,qvr),e(ln,w8),e(w8,KFe),e(KFe,jvr),e(w8,Dvr),e(w8,dJ),e(dJ,Gvr),e(w8,Ovr),e(ln,Vvr),e(ln,A8),e(A8,ZFe),e(ZFe,Xvr),e(A8,zvr),e(A8,cJ),e(cJ,Wvr),e(A8,Qvr),e(ln,Uvr),e(ln,L8),e(L8,eTe),e(eTe,Hvr),e(L8,Jvr),e(L8,fJ),e(fJ,Yvr),e(L8,Kvr),e(bo,Zvr),e(bo,y8),e(y8,e5r),e(y8,oTe),e(oTe,o5r),e(y8,r5r),e(y8,rTe),e(rTe,t5r),e(bo,a5r),M(x8,bo,null),b(f,DQe,u),b(f,nc,u),e(nc,$8),e($8,tTe),M(ux,tTe,null),e(nc,n5r),e(nc,aTe),e(aTe,s5r),b(f,GQe,u),b(f,er,u),M(bx,er,null),e(er,l5r),e(er,sc),e(sc,i5r),e(sc,mJ),e(mJ,d5r),e(sc,c5r),e(sc,gJ),e(gJ,f5r),e(sc,m5r),e(er,g5r),e(er,vx),e(vx,h5r),e(vx,nTe),e(nTe,p5r),e(vx,_5r),e(er,u5r),e(er,St),M(Fx,St,null),e(St,b5r),e(St,sTe),e(sTe,v5r),e(St,F5r),e(St,lc),e(lc,T5r),e(lc,lTe),e(lTe,M5r),e(lc,E5r),e(lc,hJ),e(hJ,C5r),e(lc,w5r),e(St,A5r),M(k8,St,null),e(er,L5r),e(er,vo),M(Tx,vo,null),e(vo,y5r),e(vo,iTe),e(iTe,x5r),e(vo,$5r),e(vo,dn),e(dn,k5r),e(dn,dTe),e(dTe,S5r),e(dn,R5r),e(dn,cTe),e(cTe,P5r),e(dn,B5r),e(dn,fTe),e(fTe,I5r),e(dn,N5r),e(vo,q5r),e(vo,Mx),e(Mx,S8),e(S8,mTe),e(mTe,j5r),e(S8,D5r),e(S8,pJ),e(pJ,G5r),e(S8,O5r),e(Mx,V5r),e(Mx,R8),e(R8,gTe),e(gTe,X5r),e(R8,z5r),e(R8,_J),e(_J,W5r),e(R8,Q5r),e(vo,U5r),e(vo,P8),e(P8,H5r),e(P8,hTe),e(hTe,J5r),e(P8,Y5r),e(P8,pTe),e(pTe,K5r),e(vo,Z5r),M(B8,vo,null),b(f,OQe,u),b(f,ic,u),e(ic,I8),e(I8,_Te),M(Ex,_Te,null),e(ic,eFr),e(ic,uTe),e(uTe,oFr),b(f,VQe,u),b(f,or,u),M(Cx,or,null),e(or,rFr),e(or,dc),e(dc,tFr),e(dc,uJ),e(uJ,aFr),e(dc,nFr),e(dc,bJ),e(bJ,sFr),e(dc,lFr),e(or,iFr),e(or,wx),e(wx,dFr),e(wx,bTe),e(bTe,cFr),e(wx,fFr),e(or,mFr),e(or,Rt),M(Ax,Rt,null),e(Rt,gFr),e(Rt,vTe),e(vTe,hFr),e(Rt,pFr),e(Rt,cc),e(cc,_Fr),e(cc,FTe),e(FTe,uFr),e(cc,bFr),e(cc,vJ),e(vJ,vFr),e(cc,FFr),e(Rt,TFr),M(N8,Rt,null),e(or,MFr),e(or,Fo),M(Lx,Fo,null),e(Fo,EFr),e(Fo,TTe),e(TTe,CFr),e(Fo,wFr),e(Fo,cn),e(cn,AFr),e(cn,MTe),e(MTe,LFr),e(cn,yFr),e(cn,ETe),e(ETe,xFr),e(cn,$Fr),e(cn,CTe),e(CTe,kFr),e(cn,SFr),e(Fo,RFr),e(Fo,wTe),e(wTe,q8),e(q8,ATe),e(ATe,PFr),e(q8,BFr),e(q8,FJ),e(FJ,IFr),e(q8,NFr),e(Fo,qFr),e(Fo,j8),e(j8,jFr),e(j8,LTe),e(LTe,DFr),e(j8,GFr),e(j8,yTe),e(yTe,OFr),e(Fo,VFr),M(D8,Fo,null),b(f,XQe,u),b(f,fc,u),e(fc,G8),e(G8,xTe),M(yx,xTe,null),e(fc,XFr),e(fc,$Te),e($Te,zFr),b(f,zQe,u),b(f,rr,u),M(xx,rr,null),e(rr,WFr),e(rr,mc),e(mc,QFr),e(mc,TJ),e(TJ,UFr),e(mc,HFr),e(mc,MJ),e(MJ,JFr),e(mc,YFr),e(rr,KFr),e(rr,$x),e($x,ZFr),e($x,kTe),e(kTe,eTr),e($x,oTr),e(rr,rTr),e(rr,Pt),M(kx,Pt,null),e(Pt,tTr),e(Pt,STe),e(STe,aTr),e(Pt,nTr),e(Pt,gc),e(gc,sTr),e(gc,RTe),e(RTe,lTr),e(gc,iTr),e(gc,EJ),e(EJ,dTr),e(gc,cTr),e(Pt,fTr),M(O8,Pt,null),e(rr,mTr),e(rr,To),M(Sx,To,null),e(To,gTr),e(To,PTe),e(PTe,hTr),e(To,pTr),e(To,fn),e(fn,_Tr),e(fn,BTe),e(BTe,uTr),e(fn,bTr),e(fn,ITe),e(ITe,vTr),e(fn,FTr),e(fn,NTe),e(NTe,TTr),e(fn,MTr),e(To,ETr),e(To,st),e(st,V8),e(V8,qTe),e(qTe,CTr),e(V8,wTr),e(V8,CJ),e(CJ,ATr),e(V8,LTr),e(st,yTr),e(st,X8),e(X8,jTe),e(jTe,xTr),e(X8,$Tr),e(X8,wJ),e(wJ,kTr),e(X8,STr),e(st,RTr),e(st,z8),e(z8,DTe),e(DTe,PTr),e(z8,BTr),e(z8,AJ),e(AJ,ITr),e(z8,NTr),e(st,qTr),e(st,W8),e(W8,GTe),e(GTe,jTr),e(W8,DTr),e(W8,LJ),e(LJ,GTr),e(W8,OTr),e(st,VTr),e(st,Q8),e(Q8,OTe),e(OTe,XTr),e(Q8,zTr),e(Q8,yJ),e(yJ,WTr),e(Q8,QTr),e(To,UTr),e(To,U8),e(U8,HTr),e(U8,VTe),e(VTe,JTr),e(U8,YTr),e(U8,XTe),e(XTe,KTr),e(To,ZTr),M(H8,To,null),b(f,WQe,u),b(f,hc,u),e(hc,J8),e(J8,zTe),M(Rx,zTe,null),e(hc,e8r),e(hc,WTe),e(WTe,o8r),b(f,QQe,u),b(f,tr,u),M(Px,tr,null),e(tr,r8r),e(tr,pc),e(pc,t8r),e(pc,xJ),e(xJ,a8r),e(pc,n8r),e(pc,$J),e($J,s8r),e(pc,l8r),e(tr,i8r),e(tr,Bx),e(Bx,d8r),e(Bx,QTe),e(QTe,c8r),e(Bx,f8r),e(tr,m8r),e(tr,Bt),M(Ix,Bt,null),e(Bt,g8r),e(Bt,UTe),e(UTe,h8r),e(Bt,p8r),e(Bt,_c),e(_c,_8r),e(_c,HTe),e(HTe,u8r),e(_c,b8r),e(_c,kJ),e(kJ,v8r),e(_c,F8r),e(Bt,T8r),M(Y8,Bt,null),e(tr,M8r),e(tr,Mo),M(Nx,Mo,null),e(Mo,E8r),e(Mo,JTe),e(JTe,C8r),e(Mo,w8r),e(Mo,mn),e(mn,A8r),e(mn,YTe),e(YTe,L8r),e(mn,y8r),e(mn,KTe),e(KTe,x8r),e(mn,$8r),e(mn,ZTe),e(ZTe,k8r),e(mn,S8r),e(Mo,R8r),e(Mo,e8e),e(e8e,K8),e(K8,o8e),e(o8e,P8r),e(K8,B8r),e(K8,SJ),e(SJ,I8r),e(K8,N8r),e(Mo,q8r),e(Mo,Z8),e(Z8,j8r),e(Z8,r8e),e(r8e,D8r),e(Z8,G8r),e(Z8,t8e),e(t8e,O8r),e(Mo,V8r),M(eM,Mo,null),b(f,UQe,u),b(f,uc,u),e(uc,oM),e(oM,a8e),M(qx,a8e,null),e(uc,X8r),e(uc,n8e),e(n8e,z8r),b(f,HQe,u),b(f,ar,u),M(jx,ar,null),e(ar,W8r),e(ar,bc),e(bc,Q8r),e(bc,RJ),e(RJ,U8r),e(bc,H8r),e(bc,PJ),e(PJ,J8r),e(bc,Y8r),e(ar,K8r),e(ar,Dx),e(Dx,Z8r),e(Dx,s8e),e(s8e,eMr),e(Dx,oMr),e(ar,rMr),e(ar,It),M(Gx,It,null),e(It,tMr),e(It,l8e),e(l8e,aMr),e(It,nMr),e(It,vc),e(vc,sMr),e(vc,i8e),e(i8e,lMr),e(vc,iMr),e(vc,BJ),e(BJ,dMr),e(vc,cMr),e(It,fMr),M(rM,It,null),e(ar,mMr),e(ar,Sr),M(Ox,Sr,null),e(Sr,gMr),e(Sr,d8e),e(d8e,hMr),e(Sr,pMr),e(Sr,gn),e(gn,_Mr),e(gn,c8e),e(c8e,uMr),e(gn,bMr),e(gn,f8e),e(f8e,vMr),e(gn,FMr),e(gn,m8e),e(m8e,TMr),e(gn,MMr),e(Sr,EMr),e(Sr,q),e(q,tM),e(tM,g8e),e(g8e,CMr),e(tM,wMr),e(tM,IJ),e(IJ,AMr),e(tM,LMr),e(q,yMr),e(q,aM),e(aM,h8e),e(h8e,xMr),e(aM,$Mr),e(aM,NJ),e(NJ,kMr),e(aM,SMr),e(q,RMr),e(q,nM),e(nM,p8e),e(p8e,PMr),e(nM,BMr),e(nM,qJ),e(qJ,IMr),e(nM,NMr),e(q,qMr),e(q,sM),e(sM,_8e),e(_8e,jMr),e(sM,DMr),e(sM,jJ),e(jJ,GMr),e(sM,OMr),e(q,VMr),e(q,lM),e(lM,u8e),e(u8e,XMr),e(lM,zMr),e(lM,DJ),e(DJ,WMr),e(lM,QMr),e(q,UMr),e(q,iM),e(iM,b8e),e(b8e,HMr),e(iM,JMr),e(iM,GJ),e(GJ,YMr),e(iM,KMr),e(q,ZMr),e(q,dM),e(dM,v8e),e(v8e,eEr),e(dM,oEr),e(dM,OJ),e(OJ,rEr),e(dM,tEr),e(q,aEr),e(q,cM),e(cM,F8e),e(F8e,nEr),e(cM,sEr),e(cM,VJ),e(VJ,lEr),e(cM,iEr),e(q,dEr),e(q,fM),e(fM,T8e),e(T8e,cEr),e(fM,fEr),e(fM,XJ),e(XJ,mEr),e(fM,gEr),e(q,hEr),e(q,mM),e(mM,M8e),e(M8e,pEr),e(mM,_Er),e(mM,zJ),e(zJ,uEr),e(mM,bEr),e(q,vEr),e(q,gM),e(gM,E8e),e(E8e,FEr),e(gM,TEr),e(gM,WJ),e(WJ,MEr),e(gM,EEr),e(q,CEr),e(q,hM),e(hM,C8e),e(C8e,wEr),e(hM,AEr),e(hM,QJ),e(QJ,LEr),e(hM,yEr),e(q,xEr),e(q,pM),e(pM,w8e),e(w8e,$Er),e(pM,kEr),e(pM,UJ),e(UJ,SEr),e(pM,REr),e(q,PEr),e(q,_M),e(_M,A8e),e(A8e,BEr),e(_M,IEr),e(_M,HJ),e(HJ,NEr),e(_M,qEr),e(q,jEr),e(q,uM),e(uM,L8e),e(L8e,DEr),e(uM,GEr),e(uM,JJ),e(JJ,OEr),e(uM,VEr),e(q,XEr),e(q,bM),e(bM,y8e),e(y8e,zEr),e(bM,WEr),e(bM,YJ),e(YJ,QEr),e(bM,UEr),e(q,HEr),e(q,vM),e(vM,x8e),e(x8e,JEr),e(vM,YEr),e(vM,KJ),e(KJ,KEr),e(vM,ZEr),e(q,eCr),e(q,FM),e(FM,$8e),e($8e,oCr),e(FM,rCr),e(FM,ZJ),e(ZJ,tCr),e(FM,aCr),e(q,nCr),e(q,al),e(al,k8e),e(k8e,sCr),e(al,lCr),e(al,eY),e(eY,iCr),e(al,dCr),e(al,oY),e(oY,cCr),e(al,fCr),e(q,mCr),e(q,TM),e(TM,S8e),e(S8e,gCr),e(TM,hCr),e(TM,rY),e(rY,pCr),e(TM,_Cr),e(q,uCr),e(q,MM),e(MM,R8e),e(R8e,bCr),e(MM,vCr),e(MM,tY),e(tY,FCr),e(MM,TCr),e(q,MCr),e(q,EM),e(EM,P8e),e(P8e,ECr),e(EM,CCr),e(EM,aY),e(aY,wCr),e(EM,ACr),e(q,LCr),e(q,CM),e(CM,B8e),e(B8e,yCr),e(CM,xCr),e(CM,nY),e(nY,$Cr),e(CM,kCr),e(q,SCr),e(q,wM),e(wM,I8e),e(I8e,RCr),e(wM,PCr),e(wM,sY),e(sY,BCr),e(wM,ICr),e(q,NCr),e(q,AM),e(AM,N8e),e(N8e,qCr),e(AM,jCr),e(AM,lY),e(lY,DCr),e(AM,GCr),e(q,OCr),e(q,LM),e(LM,q8e),e(q8e,VCr),e(LM,XCr),e(LM,iY),e(iY,zCr),e(LM,WCr),e(q,QCr),e(q,yM),e(yM,j8e),e(j8e,UCr),e(yM,HCr),e(yM,dY),e(dY,JCr),e(yM,YCr),e(q,KCr),e(q,xM),e(xM,D8e),e(D8e,ZCr),e(xM,e3r),e(xM,cY),e(cY,o3r),e(xM,r3r),e(q,t3r),e(q,$M),e($M,G8e),e(G8e,a3r),e($M,n3r),e($M,fY),e(fY,s3r),e($M,l3r),e(q,i3r),e(q,kM),e(kM,O8e),e(O8e,d3r),e(kM,c3r),e(kM,mY),e(mY,f3r),e(kM,m3r),e(q,g3r),e(q,SM),e(SM,V8e),e(V8e,h3r),e(SM,p3r),e(SM,gY),e(gY,_3r),e(SM,u3r),e(q,b3r),e(q,RM),e(RM,X8e),e(X8e,v3r),e(RM,F3r),e(RM,hY),e(hY,T3r),e(RM,M3r),e(q,E3r),e(q,PM),e(PM,z8e),e(z8e,C3r),e(PM,w3r),e(PM,pY),e(pY,A3r),e(PM,L3r),e(q,y3r),e(q,BM),e(BM,W8e),e(W8e,x3r),e(BM,$3r),e(BM,_Y),e(_Y,k3r),e(BM,S3r),e(q,R3r),e(q,IM),e(IM,Q8e),e(Q8e,P3r),e(IM,B3r),e(IM,uY),e(uY,I3r),e(IM,N3r),e(q,q3r),e(q,NM),e(NM,U8e),e(U8e,j3r),e(NM,D3r),e(NM,bY),e(bY,G3r),e(NM,O3r),e(q,V3r),e(q,qM),e(qM,H8e),e(H8e,X3r),e(qM,z3r),e(qM,vY),e(vY,W3r),e(qM,Q3r),e(q,U3r),e(q,jM),e(jM,J8e),e(J8e,H3r),e(jM,J3r),e(jM,FY),e(FY,Y3r),e(jM,K3r),e(q,Z3r),e(q,DM),e(DM,Y8e),e(Y8e,e0r),e(DM,o0r),e(DM,TY),e(TY,r0r),e(DM,t0r),e(q,a0r),e(q,GM),e(GM,K8e),e(K8e,n0r),e(GM,s0r),e(GM,MY),e(MY,l0r),e(GM,i0r),e(q,d0r),e(q,OM),e(OM,Z8e),e(Z8e,c0r),e(OM,f0r),e(OM,EY),e(EY,m0r),e(OM,g0r),e(q,h0r),e(q,VM),e(VM,eMe),e(eMe,p0r),e(VM,_0r),e(VM,CY),e(CY,u0r),e(VM,b0r),e(q,v0r),e(q,XM),e(XM,oMe),e(oMe,F0r),e(XM,T0r),e(XM,wY),e(wY,M0r),e(XM,E0r),e(q,C0r),e(q,zM),e(zM,rMe),e(rMe,w0r),e(zM,A0r),e(zM,AY),e(AY,L0r),e(zM,y0r),e(q,x0r),e(q,WM),e(WM,tMe),e(tMe,$0r),e(WM,k0r),e(WM,LY),e(LY,S0r),e(WM,R0r),e(q,P0r),e(q,QM),e(QM,aMe),e(aMe,B0r),e(QM,I0r),e(QM,yY),e(yY,N0r),e(QM,q0r),e(q,j0r),e(q,UM),e(UM,nMe),e(nMe,D0r),e(UM,G0r),e(UM,xY),e(xY,O0r),e(UM,V0r),e(q,X0r),e(q,HM),e(HM,sMe),e(sMe,z0r),e(HM,W0r),e(HM,$Y),e($Y,Q0r),e(HM,U0r),e(q,H0r),e(q,JM),e(JM,lMe),e(lMe,J0r),e(JM,Y0r),e(JM,kY),e(kY,K0r),e(JM,Z0r),e(q,ewr),e(q,YM),e(YM,iMe),e(iMe,owr),e(YM,rwr),e(YM,SY),e(SY,twr),e(YM,awr),e(q,nwr),e(q,KM),e(KM,dMe),e(dMe,swr),e(KM,lwr),e(KM,RY),e(RY,iwr),e(KM,dwr),e(Sr,cwr),M(ZM,Sr,null),b(f,JQe,u),b(f,Fc,u),e(Fc,eE),e(eE,cMe),M(Vx,cMe,null),e(Fc,fwr),e(Fc,fMe),e(fMe,mwr),b(f,YQe,u),b(f,nr,u),M(Xx,nr,null),e(nr,gwr),e(nr,Tc),e(Tc,hwr),e(Tc,PY),e(PY,pwr),e(Tc,_wr),e(Tc,BY),e(BY,uwr),e(Tc,bwr),e(nr,vwr),e(nr,zx),e(zx,Fwr),e(zx,mMe),e(mMe,Twr),e(zx,Mwr),e(nr,Ewr),e(nr,Nt),M(Wx,Nt,null),e(Nt,Cwr),e(Nt,gMe),e(gMe,wwr),e(Nt,Awr),e(Nt,Mc),e(Mc,Lwr),e(Mc,hMe),e(hMe,ywr),e(Mc,xwr),e(Mc,IY),e(IY,$wr),e(Mc,kwr),e(Nt,Swr),M(oE,Nt,null),e(nr,Rwr),e(nr,Rr),M(Qx,Rr,null),e(Rr,Pwr),e(Rr,pMe),e(pMe,Bwr),e(Rr,Iwr),e(Rr,hn),e(hn,Nwr),e(hn,_Me),e(_Me,qwr),e(hn,jwr),e(hn,uMe),e(uMe,Dwr),e(hn,Gwr),e(hn,bMe),e(bMe,Owr),e(hn,Vwr),e(Rr,Xwr),e(Rr,se),e(se,rE),e(rE,vMe),e(vMe,zwr),e(rE,Wwr),e(rE,NY),e(NY,Qwr),e(rE,Uwr),e(se,Hwr),e(se,tE),e(tE,FMe),e(FMe,Jwr),e(tE,Ywr),e(tE,qY),e(qY,Kwr),e(tE,Zwr),e(se,e6r),e(se,aE),e(aE,TMe),e(TMe,o6r),e(aE,r6r),e(aE,jY),e(jY,t6r),e(aE,a6r),e(se,n6r),e(se,nE),e(nE,MMe),e(MMe,s6r),e(nE,l6r),e(nE,DY),e(DY,i6r),e(nE,d6r),e(se,c6r),e(se,sE),e(sE,EMe),e(EMe,f6r),e(sE,m6r),e(sE,GY),e(GY,g6r),e(sE,h6r),e(se,p6r),e(se,lE),e(lE,CMe),e(CMe,_6r),e(lE,u6r),e(lE,OY),e(OY,b6r),e(lE,v6r),e(se,F6r),e(se,iE),e(iE,wMe),e(wMe,T6r),e(iE,M6r),e(iE,VY),e(VY,E6r),e(iE,C6r),e(se,w6r),e(se,dE),e(dE,AMe),e(AMe,A6r),e(dE,L6r),e(dE,XY),e(XY,y6r),e(dE,x6r),e(se,$6r),e(se,cE),e(cE,LMe),e(LMe,k6r),e(cE,S6r),e(cE,zY),e(zY,R6r),e(cE,P6r),e(se,B6r),e(se,fE),e(fE,yMe),e(yMe,I6r),e(fE,N6r),e(fE,WY),e(WY,q6r),e(fE,j6r),e(se,D6r),e(se,mE),e(mE,xMe),e(xMe,G6r),e(mE,O6r),e(mE,QY),e(QY,V6r),e(mE,X6r),e(se,z6r),e(se,gE),e(gE,$Me),e($Me,W6r),e(gE,Q6r),e(gE,UY),e(UY,U6r),e(gE,H6r),e(se,J6r),e(se,hE),e(hE,kMe),e(kMe,Y6r),e(hE,K6r),e(hE,HY),e(HY,Z6r),e(hE,eAr),e(se,oAr),e(se,pE),e(pE,SMe),e(SMe,rAr),e(pE,tAr),e(pE,JY),e(JY,aAr),e(pE,nAr),e(se,sAr),e(se,_E),e(_E,RMe),e(RMe,lAr),e(_E,iAr),e(_E,YY),e(YY,dAr),e(_E,cAr),e(se,fAr),e(se,uE),e(uE,PMe),e(PMe,mAr),e(uE,gAr),e(uE,KY),e(KY,hAr),e(uE,pAr),e(se,_Ar),e(se,bE),e(bE,BMe),e(BMe,uAr),e(bE,bAr),e(bE,ZY),e(ZY,vAr),e(bE,FAr),e(se,TAr),e(se,vE),e(vE,IMe),e(IMe,MAr),e(vE,EAr),e(vE,eK),e(eK,CAr),e(vE,wAr),e(se,AAr),e(se,FE),e(FE,NMe),e(NMe,LAr),e(FE,yAr),e(FE,oK),e(oK,xAr),e(FE,$Ar),e(se,kAr),e(se,TE),e(TE,qMe),e(qMe,SAr),e(TE,RAr),e(TE,rK),e(rK,PAr),e(TE,BAr),e(se,IAr),e(se,ME),e(ME,jMe),e(jMe,NAr),e(ME,qAr),e(ME,tK),e(tK,jAr),e(ME,DAr),e(se,GAr),e(se,EE),e(EE,DMe),e(DMe,OAr),e(EE,VAr),e(EE,aK),e(aK,XAr),e(EE,zAr),e(se,WAr),e(se,CE),e(CE,GMe),e(GMe,QAr),e(CE,UAr),e(CE,nK),e(nK,HAr),e(CE,JAr),e(Rr,YAr),M(wE,Rr,null),b(f,KQe,u),b(f,Ec,u),e(Ec,AE),e(AE,OMe),M(Ux,OMe,null),e(Ec,KAr),e(Ec,VMe),e(VMe,ZAr),b(f,ZQe,u),b(f,sr,u),M(Hx,sr,null),e(sr,e7r),e(sr,Cc),e(Cc,o7r),e(Cc,sK),e(sK,r7r),e(Cc,t7r),e(Cc,lK),e(lK,a7r),e(Cc,n7r),e(sr,s7r),e(sr,Jx),e(Jx,l7r),e(Jx,XMe),e(XMe,i7r),e(Jx,d7r),e(sr,c7r),e(sr,qt),M(Yx,qt,null),e(qt,f7r),e(qt,zMe),e(zMe,m7r),e(qt,g7r),e(qt,wc),e(wc,h7r),e(wc,WMe),e(WMe,p7r),e(wc,_7r),e(wc,iK),e(iK,u7r),e(wc,b7r),e(qt,v7r),M(LE,qt,null),e(sr,F7r),e(sr,Pr),M(Kx,Pr,null),e(Pr,T7r),e(Pr,QMe),e(QMe,M7r),e(Pr,E7r),e(Pr,pn),e(pn,C7r),e(pn,UMe),e(UMe,w7r),e(pn,A7r),e(pn,HMe),e(HMe,L7r),e(pn,y7r),e(pn,JMe),e(JMe,x7r),e(pn,$7r),e(Pr,k7r),e(Pr,Me),e(Me,yE),e(yE,YMe),e(YMe,S7r),e(yE,R7r),e(yE,dK),e(dK,P7r),e(yE,B7r),e(Me,I7r),e(Me,xE),e(xE,KMe),e(KMe,N7r),e(xE,q7r),e(xE,cK),e(cK,j7r),e(xE,D7r),e(Me,G7r),e(Me,$E),e($E,ZMe),e(ZMe,O7r),e($E,V7r),e($E,fK),e(fK,X7r),e($E,z7r),e(Me,W7r),e(Me,kE),e(kE,eEe),e(eEe,Q7r),e(kE,U7r),e(kE,mK),e(mK,H7r),e(kE,J7r),e(Me,Y7r),e(Me,SE),e(SE,oEe),e(oEe,K7r),e(SE,Z7r),e(SE,gK),e(gK,eLr),e(SE,oLr),e(Me,rLr),e(Me,RE),e(RE,rEe),e(rEe,tLr),e(RE,aLr),e(RE,hK),e(hK,nLr),e(RE,sLr),e(Me,lLr),e(Me,PE),e(PE,tEe),e(tEe,iLr),e(PE,dLr),e(PE,pK),e(pK,cLr),e(PE,fLr),e(Me,mLr),e(Me,BE),e(BE,aEe),e(aEe,gLr),e(BE,hLr),e(BE,_K),e(_K,pLr),e(BE,_Lr),e(Me,uLr),e(Me,IE),e(IE,nEe),e(nEe,bLr),e(IE,vLr),e(IE,uK),e(uK,FLr),e(IE,TLr),e(Me,MLr),e(Me,NE),e(NE,sEe),e(sEe,ELr),e(NE,CLr),e(NE,bK),e(bK,wLr),e(NE,ALr),e(Me,LLr),e(Me,qE),e(qE,lEe),e(lEe,yLr),e(qE,xLr),e(qE,vK),e(vK,$Lr),e(qE,kLr),e(Me,SLr),e(Me,jE),e(jE,iEe),e(iEe,RLr),e(jE,PLr),e(jE,FK),e(FK,BLr),e(jE,ILr),e(Me,NLr),e(Me,DE),e(DE,dEe),e(dEe,qLr),e(DE,jLr),e(DE,TK),e(TK,DLr),e(DE,GLr),e(Pr,OLr),M(GE,Pr,null),b(f,eUe,u),b(f,Ac,u),e(Ac,OE),e(OE,cEe),M(Zx,cEe,null),e(Ac,VLr),e(Ac,fEe),e(fEe,XLr),b(f,oUe,u),b(f,lr,u),M(e$,lr,null),e(lr,zLr),e(lr,Lc),e(Lc,WLr),e(Lc,MK),e(MK,QLr),e(Lc,ULr),e(Lc,EK),e(EK,HLr),e(Lc,JLr),e(lr,YLr),e(lr,o$),e(o$,KLr),e(o$,mEe),e(mEe,ZLr),e(o$,eyr),e(lr,oyr),e(lr,jt),M(r$,jt,null),e(jt,ryr),e(jt,gEe),e(gEe,tyr),e(jt,ayr),e(jt,yc),e(yc,nyr),e(yc,hEe),e(hEe,syr),e(yc,lyr),e(yc,CK),e(CK,iyr),e(yc,dyr),e(jt,cyr),M(VE,jt,null),e(lr,fyr),e(lr,Br),M(t$,Br,null),e(Br,myr),e(Br,pEe),e(pEe,gyr),e(Br,hyr),e(Br,_n),e(_n,pyr),e(_n,_Ee),e(_Ee,_yr),e(_n,uyr),e(_n,uEe),e(uEe,byr),e(_n,vyr),e(_n,bEe),e(bEe,Fyr),e(_n,Tyr),e(Br,Myr),e(Br,Ve),e(Ve,XE),e(XE,vEe),e(vEe,Eyr),e(XE,Cyr),e(XE,wK),e(wK,wyr),e(XE,Ayr),e(Ve,Lyr),e(Ve,zE),e(zE,FEe),e(FEe,yyr),e(zE,xyr),e(zE,AK),e(AK,$yr),e(zE,kyr),e(Ve,Syr),e(Ve,nl),e(nl,TEe),e(TEe,Ryr),e(nl,Pyr),e(nl,LK),e(LK,Byr),e(nl,Iyr),e(nl,yK),e(yK,Nyr),e(nl,qyr),e(Ve,jyr),e(Ve,WE),e(WE,MEe),e(MEe,Dyr),e(WE,Gyr),e(WE,xK),e(xK,Oyr),e(WE,Vyr),e(Ve,Xyr),e(Ve,QE),e(QE,EEe),e(EEe,zyr),e(QE,Wyr),e(QE,$K),e($K,Qyr),e(QE,Uyr),e(Ve,Hyr),e(Ve,UE),e(UE,CEe),e(CEe,Jyr),e(UE,Yyr),e(UE,kK),e(kK,Kyr),e(UE,Zyr),e(Ve,e9r),e(Ve,HE),e(HE,wEe),e(wEe,o9r),e(HE,r9r),e(HE,SK),e(SK,t9r),e(HE,a9r),e(Ve,n9r),e(Ve,JE),e(JE,AEe),e(AEe,s9r),e(JE,l9r),e(JE,RK),e(RK,i9r),e(JE,d9r),e(Br,c9r),M(YE,Br,null),b(f,rUe,u),b(f,xc,u),e(xc,KE),e(KE,LEe),M(a$,LEe,null),e(xc,f9r),e(xc,yEe),e(yEe,m9r),b(f,tUe,u),b(f,ir,u),M(n$,ir,null),e(ir,g9r),e(ir,$c),e($c,h9r),e($c,PK),e(PK,p9r),e($c,_9r),e($c,BK),e(BK,u9r),e($c,b9r),e(ir,v9r),e(ir,s$),e(s$,F9r),e(s$,xEe),e(xEe,T9r),e(s$,M9r),e(ir,E9r),e(ir,Dt),M(l$,Dt,null),e(Dt,C9r),e(Dt,$Ee),e($Ee,w9r),e(Dt,A9r),e(Dt,kc),e(kc,L9r),e(kc,kEe),e(kEe,y9r),e(kc,x9r),e(kc,IK),e(IK,$9r),e(kc,k9r),e(Dt,S9r),M(ZE,Dt,null),e(ir,R9r),e(ir,Ir),M(i$,Ir,null),e(Ir,P9r),e(Ir,SEe),e(SEe,B9r),e(Ir,I9r),e(Ir,un),e(un,N9r),e(un,REe),e(REe,q9r),e(un,j9r),e(un,PEe),e(PEe,D9r),e(un,G9r),e(un,BEe),e(BEe,O9r),e(un,V9r),e(Ir,X9r),e(Ir,ie),e(ie,eC),e(eC,IEe),e(IEe,z9r),e(eC,W9r),e(eC,NK),e(NK,Q9r),e(eC,U9r),e(ie,H9r),e(ie,oC),e(oC,NEe),e(NEe,J9r),e(oC,Y9r),e(oC,qK),e(qK,K9r),e(oC,Z9r),e(ie,exr),e(ie,rC),e(rC,qEe),e(qEe,oxr),e(rC,rxr),e(rC,jK),e(jK,txr),e(rC,axr),e(ie,nxr),e(ie,tC),e(tC,jEe),e(jEe,sxr),e(tC,lxr),e(tC,DK),e(DK,ixr),e(tC,dxr),e(ie,cxr),e(ie,aC),e(aC,DEe),e(DEe,fxr),e(aC,mxr),e(aC,GK),e(GK,gxr),e(aC,hxr),e(ie,pxr),e(ie,nC),e(nC,GEe),e(GEe,_xr),e(nC,uxr),e(nC,OK),e(OK,bxr),e(nC,vxr),e(ie,Fxr),e(ie,sC),e(sC,OEe),e(OEe,Txr),e(sC,Mxr),e(sC,VK),e(VK,Exr),e(sC,Cxr),e(ie,wxr),e(ie,lC),e(lC,VEe),e(VEe,Axr),e(lC,Lxr),e(lC,XK),e(XK,yxr),e(lC,xxr),e(ie,$xr),e(ie,iC),e(iC,XEe),e(XEe,kxr),e(iC,Sxr),e(iC,zK),e(zK,Rxr),e(iC,Pxr),e(ie,Bxr),e(ie,dC),e(dC,zEe),e(zEe,Ixr),e(dC,Nxr),e(dC,WK),e(WK,qxr),e(dC,jxr),e(ie,Dxr),e(ie,cC),e(cC,WEe),e(WEe,Gxr),e(cC,Oxr),e(cC,QK),e(QK,Vxr),e(cC,Xxr),e(ie,zxr),e(ie,fC),e(fC,QEe),e(QEe,Wxr),e(fC,Qxr),e(fC,UK),e(UK,Uxr),e(fC,Hxr),e(ie,Jxr),e(ie,mC),e(mC,UEe),e(UEe,Yxr),e(mC,Kxr),e(mC,HK),e(HK,Zxr),e(mC,e$r),e(ie,o$r),e(ie,gC),e(gC,HEe),e(HEe,r$r),e(gC,t$r),e(gC,JK),e(JK,a$r),e(gC,n$r),e(ie,s$r),e(ie,hC),e(hC,JEe),e(JEe,l$r),e(hC,i$r),e(hC,YK),e(YK,d$r),e(hC,c$r),e(ie,f$r),e(ie,pC),e(pC,YEe),e(YEe,m$r),e(pC,g$r),e(pC,KK),e(KK,h$r),e(pC,p$r),e(ie,_$r),e(ie,_C),e(_C,KEe),e(KEe,u$r),e(_C,b$r),e(_C,ZK),e(ZK,v$r),e(_C,F$r),e(ie,T$r),e(ie,uC),e(uC,ZEe),e(ZEe,M$r),e(uC,E$r),e(uC,eZ),e(eZ,C$r),e(uC,w$r),e(ie,A$r),e(ie,bC),e(bC,eCe),e(eCe,L$r),e(bC,y$r),e(bC,oZ),e(oZ,x$r),e(bC,$$r),e(ie,k$r),e(ie,vC),e(vC,oCe),e(oCe,S$r),e(vC,R$r),e(vC,rZ),e(rZ,P$r),e(vC,B$r),e(Ir,I$r),M(FC,Ir,null),b(f,aUe,u),b(f,Sc,u),e(Sc,TC),e(TC,rCe),M(d$,rCe,null),e(Sc,N$r),e(Sc,tCe),e(tCe,q$r),b(f,nUe,u),b(f,dr,u),M(c$,dr,null),e(dr,j$r),e(dr,Rc),e(Rc,D$r),e(Rc,tZ),e(tZ,G$r),e(Rc,O$r),e(Rc,aZ),e(aZ,V$r),e(Rc,X$r),e(dr,z$r),e(dr,f$),e(f$,W$r),e(f$,aCe),e(aCe,Q$r),e(f$,U$r),e(dr,H$r),e(dr,Gt),M(m$,Gt,null),e(Gt,J$r),e(Gt,nCe),e(nCe,Y$r),e(Gt,K$r),e(Gt,Pc),e(Pc,Z$r),e(Pc,sCe),e(sCe,ekr),e(Pc,okr),e(Pc,nZ),e(nZ,rkr),e(Pc,tkr),e(Gt,akr),M(MC,Gt,null),e(dr,nkr),e(dr,Nr),M(g$,Nr,null),e(Nr,skr),e(Nr,lCe),e(lCe,lkr),e(Nr,ikr),e(Nr,bn),e(bn,dkr),e(bn,iCe),e(iCe,ckr),e(bn,fkr),e(bn,dCe),e(dCe,mkr),e(bn,gkr),e(bn,cCe),e(cCe,hkr),e(bn,pkr),e(Nr,_kr),e(Nr,ye),e(ye,EC),e(EC,fCe),e(fCe,ukr),e(EC,bkr),e(EC,sZ),e(sZ,vkr),e(EC,Fkr),e(ye,Tkr),e(ye,CC),e(CC,mCe),e(mCe,Mkr),e(CC,Ekr),e(CC,lZ),e(lZ,Ckr),e(CC,wkr),e(ye,Akr),e(ye,wC),e(wC,gCe),e(gCe,Lkr),e(wC,ykr),e(wC,iZ),e(iZ,xkr),e(wC,$kr),e(ye,kkr),e(ye,AC),e(AC,hCe),e(hCe,Skr),e(AC,Rkr),e(AC,dZ),e(dZ,Pkr),e(AC,Bkr),e(ye,Ikr),e(ye,LC),e(LC,pCe),e(pCe,Nkr),e(LC,qkr),e(LC,cZ),e(cZ,jkr),e(LC,Dkr),e(ye,Gkr),e(ye,yC),e(yC,_Ce),e(_Ce,Okr),e(yC,Vkr),e(yC,fZ),e(fZ,Xkr),e(yC,zkr),e(ye,Wkr),e(ye,xC),e(xC,uCe),e(uCe,Qkr),e(xC,Ukr),e(xC,mZ),e(mZ,Hkr),e(xC,Jkr),e(ye,Ykr),e(ye,$C),e($C,bCe),e(bCe,Kkr),e($C,Zkr),e($C,gZ),e(gZ,eSr),e($C,oSr),e(ye,rSr),e(ye,kC),e(kC,vCe),e(vCe,tSr),e(kC,aSr),e(kC,hZ),e(hZ,nSr),e(kC,sSr),e(ye,lSr),e(ye,SC),e(SC,FCe),e(FCe,iSr),e(SC,dSr),e(SC,pZ),e(pZ,cSr),e(SC,fSr),e(Nr,mSr),M(RC,Nr,null),b(f,sUe,u),b(f,Bc,u),e(Bc,PC),e(PC,TCe),M(h$,TCe,null),e(Bc,gSr),e(Bc,MCe),e(MCe,hSr),b(f,lUe,u),b(f,cr,u),M(p$,cr,null),e(cr,pSr),e(cr,Ic),e(Ic,_Sr),e(Ic,_Z),e(_Z,uSr),e(Ic,bSr),e(Ic,uZ),e(uZ,vSr),e(Ic,FSr),e(cr,TSr),e(cr,_$),e(_$,MSr),e(_$,ECe),e(ECe,ESr),e(_$,CSr),e(cr,wSr),e(cr,Ot),M(u$,Ot,null),e(Ot,ASr),e(Ot,CCe),e(CCe,LSr),e(Ot,ySr),e(Ot,Nc),e(Nc,xSr),e(Nc,wCe),e(wCe,$Sr),e(Nc,kSr),e(Nc,bZ),e(bZ,SSr),e(Nc,RSr),e(Ot,PSr),M(BC,Ot,null),e(cr,BSr),e(cr,qr),M(b$,qr,null),e(qr,ISr),e(qr,ACe),e(ACe,NSr),e(qr,qSr),e(qr,vn),e(vn,jSr),e(vn,LCe),e(LCe,DSr),e(vn,GSr),e(vn,yCe),e(yCe,OSr),e(vn,VSr),e(vn,xCe),e(xCe,XSr),e(vn,zSr),e(qr,WSr),e(qr,te),e(te,IC),e(IC,$Ce),e($Ce,QSr),e(IC,USr),e(IC,vZ),e(vZ,HSr),e(IC,JSr),e(te,YSr),e(te,NC),e(NC,kCe),e(kCe,KSr),e(NC,ZSr),e(NC,FZ),e(FZ,eRr),e(NC,oRr),e(te,rRr),e(te,qC),e(qC,SCe),e(SCe,tRr),e(qC,aRr),e(qC,TZ),e(TZ,nRr),e(qC,sRr),e(te,lRr),e(te,jC),e(jC,RCe),e(RCe,iRr),e(jC,dRr),e(jC,MZ),e(MZ,cRr),e(jC,fRr),e(te,mRr),e(te,DC),e(DC,PCe),e(PCe,gRr),e(DC,hRr),e(DC,EZ),e(EZ,pRr),e(DC,_Rr),e(te,uRr),e(te,GC),e(GC,BCe),e(BCe,bRr),e(GC,vRr),e(GC,CZ),e(CZ,FRr),e(GC,TRr),e(te,MRr),e(te,OC),e(OC,ICe),e(ICe,ERr),e(OC,CRr),e(OC,wZ),e(wZ,wRr),e(OC,ARr),e(te,LRr),e(te,VC),e(VC,NCe),e(NCe,yRr),e(VC,xRr),e(VC,AZ),e(AZ,$Rr),e(VC,kRr),e(te,SRr),e(te,XC),e(XC,qCe),e(qCe,RRr),e(XC,PRr),e(XC,LZ),e(LZ,BRr),e(XC,IRr),e(te,NRr),e(te,zC),e(zC,jCe),e(jCe,qRr),e(zC,jRr),e(zC,yZ),e(yZ,DRr),e(zC,GRr),e(te,ORr),e(te,WC),e(WC,DCe),e(DCe,VRr),e(WC,XRr),e(WC,xZ),e(xZ,zRr),e(WC,WRr),e(te,QRr),e(te,QC),e(QC,GCe),e(GCe,URr),e(QC,HRr),e(QC,$Z),e($Z,JRr),e(QC,YRr),e(te,KRr),e(te,UC),e(UC,OCe),e(OCe,ZRr),e(UC,ePr),e(UC,kZ),e(kZ,oPr),e(UC,rPr),e(te,tPr),e(te,HC),e(HC,VCe),e(VCe,aPr),e(HC,nPr),e(HC,SZ),e(SZ,sPr),e(HC,lPr),e(te,iPr),e(te,JC),e(JC,XCe),e(XCe,dPr),e(JC,cPr),e(JC,RZ),e(RZ,fPr),e(JC,mPr),e(te,gPr),e(te,YC),e(YC,zCe),e(zCe,hPr),e(YC,pPr),e(YC,PZ),e(PZ,_Pr),e(YC,uPr),e(te,bPr),e(te,KC),e(KC,WCe),e(WCe,vPr),e(KC,FPr),e(KC,BZ),e(BZ,TPr),e(KC,MPr),e(te,EPr),e(te,ZC),e(ZC,QCe),e(QCe,CPr),e(ZC,wPr),e(ZC,IZ),e(IZ,APr),e(ZC,LPr),e(te,yPr),e(te,e3),e(e3,UCe),e(UCe,xPr),e(e3,$Pr),e(e3,NZ),e(NZ,kPr),e(e3,SPr),e(te,RPr),e(te,o3),e(o3,HCe),e(HCe,PPr),e(o3,BPr),e(o3,qZ),e(qZ,IPr),e(o3,NPr),e(te,qPr),e(te,r3),e(r3,JCe),e(JCe,jPr),e(r3,DPr),e(r3,jZ),e(jZ,GPr),e(r3,OPr),e(te,VPr),e(te,t3),e(t3,YCe),e(YCe,XPr),e(t3,zPr),e(t3,DZ),e(DZ,WPr),e(t3,QPr),e(te,UPr),e(te,a3),e(a3,KCe),e(KCe,HPr),e(a3,JPr),e(a3,GZ),e(GZ,YPr),e(a3,KPr),e(te,ZPr),e(te,n3),e(n3,ZCe),e(ZCe,eBr),e(n3,oBr),e(n3,OZ),e(OZ,rBr),e(n3,tBr),e(te,aBr),e(te,s3),e(s3,e3e),e(e3e,nBr),e(s3,sBr),e(s3,VZ),e(VZ,lBr),e(s3,iBr),e(te,dBr),e(te,l3),e(l3,o3e),e(o3e,cBr),e(l3,fBr),e(l3,XZ),e(XZ,mBr),e(l3,gBr),e(qr,hBr),M(i3,qr,null),b(f,iUe,u),b(f,qc,u),e(qc,d3),e(d3,r3e),M(v$,r3e,null),e(qc,pBr),e(qc,t3e),e(t3e,_Br),b(f,dUe,u),b(f,fr,u),M(F$,fr,null),e(fr,uBr),e(fr,jc),e(jc,bBr),e(jc,zZ),e(zZ,vBr),e(jc,FBr),e(jc,WZ),e(WZ,TBr),e(jc,MBr),e(fr,EBr),e(fr,T$),e(T$,CBr),e(T$,a3e),e(a3e,wBr),e(T$,ABr),e(fr,LBr),e(fr,Vt),M(M$,Vt,null),e(Vt,yBr),e(Vt,n3e),e(n3e,xBr),e(Vt,$Br),e(Vt,Dc),e(Dc,kBr),e(Dc,s3e),e(s3e,SBr),e(Dc,RBr),e(Dc,QZ),e(QZ,PBr),e(Dc,BBr),e(Vt,IBr),M(c3,Vt,null),e(fr,NBr),e(fr,jr),M(E$,jr,null),e(jr,qBr),e(jr,l3e),e(l3e,jBr),e(jr,DBr),e(jr,Fn),e(Fn,GBr),e(Fn,i3e),e(i3e,OBr),e(Fn,VBr),e(Fn,d3e),e(d3e,XBr),e(Fn,zBr),e(Fn,c3e),e(c3e,WBr),e(Fn,QBr),e(jr,UBr),e(jr,ve),e(ve,f3),e(f3,f3e),e(f3e,HBr),e(f3,JBr),e(f3,UZ),e(UZ,YBr),e(f3,KBr),e(ve,ZBr),e(ve,m3),e(m3,m3e),e(m3e,eIr),e(m3,oIr),e(m3,HZ),e(HZ,rIr),e(m3,tIr),e(ve,aIr),e(ve,g3),e(g3,g3e),e(g3e,nIr),e(g3,sIr),e(g3,JZ),e(JZ,lIr),e(g3,iIr),e(ve,dIr),e(ve,h3),e(h3,h3e),e(h3e,cIr),e(h3,fIr),e(h3,YZ),e(YZ,mIr),e(h3,gIr),e(ve,hIr),e(ve,p3),e(p3,p3e),e(p3e,pIr),e(p3,_Ir),e(p3,KZ),e(KZ,uIr),e(p3,bIr),e(ve,vIr),e(ve,_3),e(_3,_3e),e(_3e,FIr),e(_3,TIr),e(_3,ZZ),e(ZZ,MIr),e(_3,EIr),e(ve,CIr),e(ve,u3),e(u3,u3e),e(u3e,wIr),e(u3,AIr),e(u3,eee),e(eee,LIr),e(u3,yIr),e(ve,xIr),e(ve,b3),e(b3,b3e),e(b3e,$Ir),e(b3,kIr),e(b3,oee),e(oee,SIr),e(b3,RIr),e(ve,PIr),e(ve,v3),e(v3,v3e),e(v3e,BIr),e(v3,IIr),e(v3,ree),e(ree,NIr),e(v3,qIr),e(ve,jIr),e(ve,F3),e(F3,F3e),e(F3e,DIr),e(F3,GIr),e(F3,tee),e(tee,OIr),e(F3,VIr),e(ve,XIr),e(ve,T3),e(T3,T3e),e(T3e,zIr),e(T3,WIr),e(T3,aee),e(aee,QIr),e(T3,UIr),e(ve,HIr),e(ve,M3),e(M3,M3e),e(M3e,JIr),e(M3,YIr),e(M3,nee),e(nee,KIr),e(M3,ZIr),e(ve,eNr),e(ve,E3),e(E3,E3e),e(E3e,oNr),e(E3,rNr),e(E3,see),e(see,tNr),e(E3,aNr),e(ve,nNr),e(ve,C3),e(C3,C3e),e(C3e,sNr),e(C3,lNr),e(C3,lee),e(lee,iNr),e(C3,dNr),e(ve,cNr),e(ve,w3),e(w3,w3e),e(w3e,fNr),e(w3,mNr),e(w3,iee),e(iee,gNr),e(w3,hNr),e(ve,pNr),e(ve,A3),e(A3,A3e),e(A3e,_Nr),e(A3,uNr),e(A3,dee),e(dee,bNr),e(A3,vNr),e(ve,FNr),e(ve,L3),e(L3,L3e),e(L3e,TNr),e(L3,MNr),e(L3,cee),e(cee,ENr),e(L3,CNr),e(jr,wNr),M(y3,jr,null),b(f,cUe,u),b(f,Gc,u),e(Gc,x3),e(x3,y3e),M(C$,y3e,null),e(Gc,ANr),e(Gc,x3e),e(x3e,LNr),b(f,fUe,u),b(f,mr,u),M(w$,mr,null),e(mr,yNr),e(mr,Oc),e(Oc,xNr),e(Oc,fee),e(fee,$Nr),e(Oc,kNr),e(Oc,mee),e(mee,SNr),e(Oc,RNr),e(mr,PNr),e(mr,A$),e(A$,BNr),e(A$,$3e),e($3e,INr),e(A$,NNr),e(mr,qNr),e(mr,Xt),M(L$,Xt,null),e(Xt,jNr),e(Xt,k3e),e(k3e,DNr),e(Xt,GNr),e(Xt,Vc),e(Vc,ONr),e(Vc,S3e),e(S3e,VNr),e(Vc,XNr),e(Vc,gee),e(gee,zNr),e(Vc,WNr),e(Xt,QNr),M($3,Xt,null),e(mr,UNr),e(mr,Dr),M(y$,Dr,null),e(Dr,HNr),e(Dr,R3e),e(R3e,JNr),e(Dr,YNr),e(Dr,Tn),e(Tn,KNr),e(Tn,P3e),e(P3e,ZNr),e(Tn,eqr),e(Tn,B3e),e(B3e,oqr),e(Tn,rqr),e(Tn,I3e),e(I3e,tqr),e(Tn,aqr),e(Dr,nqr),e(Dr,x$),e(x$,k3),e(k3,N3e),e(N3e,sqr),e(k3,lqr),e(k3,hee),e(hee,iqr),e(k3,dqr),e(x$,cqr),e(x$,S3),e(S3,q3e),e(q3e,fqr),e(S3,mqr),e(S3,pee),e(pee,gqr),e(S3,hqr),e(Dr,pqr),M(R3,Dr,null),b(f,mUe,u),b(f,Xc,u),e(Xc,P3),e(P3,j3e),M($$,j3e,null),e(Xc,_qr),e(Xc,D3e),e(D3e,uqr),b(f,gUe,u),b(f,gr,u),M(k$,gr,null),e(gr,bqr),e(gr,zc),e(zc,vqr),e(zc,_ee),e(_ee,Fqr),e(zc,Tqr),e(zc,uee),e(uee,Mqr),e(zc,Eqr),e(gr,Cqr),e(gr,S$),e(S$,wqr),e(S$,G3e),e(G3e,Aqr),e(S$,Lqr),e(gr,yqr),e(gr,zt),M(R$,zt,null),e(zt,xqr),e(zt,O3e),e(O3e,$qr),e(zt,kqr),e(zt,Wc),e(Wc,Sqr),e(Wc,V3e),e(V3e,Rqr),e(Wc,Pqr),e(Wc,bee),e(bee,Bqr),e(Wc,Iqr),e(zt,Nqr),M(B3,zt,null),e(gr,qqr),e(gr,Gr),M(P$,Gr,null),e(Gr,jqr),e(Gr,X3e),e(X3e,Dqr),e(Gr,Gqr),e(Gr,Mn),e(Mn,Oqr),e(Mn,z3e),e(z3e,Vqr),e(Mn,Xqr),e(Mn,W3e),e(W3e,zqr),e(Mn,Wqr),e(Mn,Q3e),e(Q3e,Qqr),e(Mn,Uqr),e(Gr,Hqr),e(Gr,U3e),e(U3e,I3),e(I3,H3e),e(H3e,Jqr),e(I3,Yqr),e(I3,vee),e(vee,Kqr),e(I3,Zqr),e(Gr,ejr),M(N3,Gr,null),b(f,hUe,u),b(f,Qc,u),e(Qc,q3),e(q3,J3e),M(B$,J3e,null),e(Qc,ojr),e(Qc,Y3e),e(Y3e,rjr),b(f,pUe,u),b(f,hr,u),M(I$,hr,null),e(hr,tjr),e(hr,Uc),e(Uc,ajr),e(Uc,Fee),e(Fee,njr),e(Uc,sjr),e(Uc,Tee),e(Tee,ljr),e(Uc,ijr),e(hr,djr),e(hr,N$),e(N$,cjr),e(N$,K3e),e(K3e,fjr),e(N$,mjr),e(hr,gjr),e(hr,Wt),M(q$,Wt,null),e(Wt,hjr),e(Wt,Z3e),e(Z3e,pjr),e(Wt,_jr),e(Wt,Hc),e(Hc,ujr),e(Hc,e0e),e(e0e,bjr),e(Hc,vjr),e(Hc,Mee),e(Mee,Fjr),e(Hc,Tjr),e(Wt,Mjr),M(j3,Wt,null),e(hr,Ejr),e(hr,Or),M(j$,Or,null),e(Or,Cjr),e(Or,o0e),e(o0e,wjr),e(Or,Ajr),e(Or,En),e(En,Ljr),e(En,r0e),e(r0e,yjr),e(En,xjr),e(En,t0e),e(t0e,$jr),e(En,kjr),e(En,a0e),e(a0e,Sjr),e(En,Rjr),e(Or,Pjr),e(Or,de),e(de,D3),e(D3,n0e),e(n0e,Bjr),e(D3,Ijr),e(D3,Eee),e(Eee,Njr),e(D3,qjr),e(de,jjr),e(de,G3),e(G3,s0e),e(s0e,Djr),e(G3,Gjr),e(G3,Cee),e(Cee,Ojr),e(G3,Vjr),e(de,Xjr),e(de,O3),e(O3,l0e),e(l0e,zjr),e(O3,Wjr),e(O3,wee),e(wee,Qjr),e(O3,Ujr),e(de,Hjr),e(de,V3),e(V3,i0e),e(i0e,Jjr),e(V3,Yjr),e(V3,Aee),e(Aee,Kjr),e(V3,Zjr),e(de,eDr),e(de,X3),e(X3,d0e),e(d0e,oDr),e(X3,rDr),e(X3,Lee),e(Lee,tDr),e(X3,aDr),e(de,nDr),e(de,z3),e(z3,c0e),e(c0e,sDr),e(z3,lDr),e(z3,yee),e(yee,iDr),e(z3,dDr),e(de,cDr),e(de,W3),e(W3,f0e),e(f0e,fDr),e(W3,mDr),e(W3,xee),e(xee,gDr),e(W3,hDr),e(de,pDr),e(de,Q3),e(Q3,m0e),e(m0e,_Dr),e(Q3,uDr),e(Q3,$ee),e($ee,bDr),e(Q3,vDr),e(de,FDr),e(de,U3),e(U3,g0e),e(g0e,TDr),e(U3,MDr),e(U3,kee),e(kee,EDr),e(U3,CDr),e(de,wDr),e(de,H3),e(H3,h0e),e(h0e,ADr),e(H3,LDr),e(H3,See),e(See,yDr),e(H3,xDr),e(de,$Dr),e(de,J3),e(J3,p0e),e(p0e,kDr),e(J3,SDr),e(J3,Ree),e(Ree,RDr),e(J3,PDr),e(de,BDr),e(de,Y3),e(Y3,_0e),e(_0e,IDr),e(Y3,NDr),e(Y3,Pee),e(Pee,qDr),e(Y3,jDr),e(de,DDr),e(de,K3),e(K3,u0e),e(u0e,GDr),e(K3,ODr),e(K3,Bee),e(Bee,VDr),e(K3,XDr),e(de,zDr),e(de,Z3),e(Z3,b0e),e(b0e,WDr),e(Z3,QDr),e(Z3,Iee),e(Iee,UDr),e(Z3,HDr),e(de,JDr),e(de,e0),e(e0,v0e),e(v0e,YDr),e(e0,KDr),e(e0,Nee),e(Nee,ZDr),e(e0,eGr),e(de,oGr),e(de,o0),e(o0,F0e),e(F0e,rGr),e(o0,tGr),e(o0,qee),e(qee,aGr),e(o0,nGr),e(de,sGr),e(de,r0),e(r0,T0e),e(T0e,lGr),e(r0,iGr),e(r0,jee),e(jee,dGr),e(r0,cGr),e(de,fGr),e(de,t0),e(t0,M0e),e(M0e,mGr),e(t0,gGr),e(t0,Dee),e(Dee,hGr),e(t0,pGr),e(de,_Gr),e(de,a0),e(a0,E0e),e(E0e,uGr),e(a0,bGr),e(a0,Gee),e(Gee,vGr),e(a0,FGr),e(de,TGr),e(de,n0),e(n0,C0e),e(C0e,MGr),e(n0,EGr),e(n0,Oee),e(Oee,CGr),e(n0,wGr),e(Or,AGr),M(s0,Or,null),b(f,_Ue,u),b(f,Jc,u),e(Jc,l0),e(l0,w0e),M(D$,w0e,null),e(Jc,LGr),e(Jc,A0e),e(A0e,yGr),b(f,uUe,u),b(f,pr,u),M(G$,pr,null),e(pr,xGr),e(pr,Yc),e(Yc,$Gr),e(Yc,Vee),e(Vee,kGr),e(Yc,SGr),e(Yc,Xee),e(Xee,RGr),e(Yc,PGr),e(pr,BGr),e(pr,O$),e(O$,IGr),e(O$,L0e),e(L0e,NGr),e(O$,qGr),e(pr,jGr),e(pr,Qt),M(V$,Qt,null),e(Qt,DGr),e(Qt,y0e),e(y0e,GGr),e(Qt,OGr),e(Qt,Kc),e(Kc,VGr),e(Kc,x0e),e(x0e,XGr),e(Kc,zGr),e(Kc,zee),e(zee,WGr),e(Kc,QGr),e(Qt,UGr),M(i0,Qt,null),e(pr,HGr),e(pr,Vr),M(X$,Vr,null),e(Vr,JGr),e(Vr,$0e),e($0e,YGr),e(Vr,KGr),e(Vr,Cn),e(Cn,ZGr),e(Cn,k0e),e(k0e,eOr),e(Cn,oOr),e(Cn,S0e),e(S0e,rOr),e(Cn,tOr),e(Cn,R0e),e(R0e,aOr),e(Cn,nOr),e(Vr,sOr),e(Vr,ce),e(ce,d0),e(d0,P0e),e(P0e,lOr),e(d0,iOr),e(d0,Wee),e(Wee,dOr),e(d0,cOr),e(ce,fOr),e(ce,c0),e(c0,B0e),e(B0e,mOr),e(c0,gOr),e(c0,Qee),e(Qee,hOr),e(c0,pOr),e(ce,_Or),e(ce,f0),e(f0,I0e),e(I0e,uOr),e(f0,bOr),e(f0,Uee),e(Uee,vOr),e(f0,FOr),e(ce,TOr),e(ce,m0),e(m0,N0e),e(N0e,MOr),e(m0,EOr),e(m0,Hee),e(Hee,COr),e(m0,wOr),e(ce,AOr),e(ce,g0),e(g0,q0e),e(q0e,LOr),e(g0,yOr),e(g0,Jee),e(Jee,xOr),e(g0,$Or),e(ce,kOr),e(ce,h0),e(h0,j0e),e(j0e,SOr),e(h0,ROr),e(h0,Yee),e(Yee,POr),e(h0,BOr),e(ce,IOr),e(ce,p0),e(p0,D0e),e(D0e,NOr),e(p0,qOr),e(p0,Kee),e(Kee,jOr),e(p0,DOr),e(ce,GOr),e(ce,_0),e(_0,G0e),e(G0e,OOr),e(_0,VOr),e(_0,Zee),e(Zee,XOr),e(_0,zOr),e(ce,WOr),e(ce,u0),e(u0,O0e),e(O0e,QOr),e(u0,UOr),e(u0,eoe),e(eoe,HOr),e(u0,JOr),e(ce,YOr),e(ce,b0),e(b0,V0e),e(V0e,KOr),e(b0,ZOr),e(b0,ooe),e(ooe,eVr),e(b0,oVr),e(ce,rVr),e(ce,v0),e(v0,X0e),e(X0e,tVr),e(v0,aVr),e(v0,roe),e(roe,nVr),e(v0,sVr),e(ce,lVr),e(ce,F0),e(F0,z0e),e(z0e,iVr),e(F0,dVr),e(F0,toe),e(toe,cVr),e(F0,fVr),e(ce,mVr),e(ce,T0),e(T0,W0e),e(W0e,gVr),e(T0,hVr),e(T0,aoe),e(aoe,pVr),e(T0,_Vr),e(ce,uVr),e(ce,M0),e(M0,Q0e),e(Q0e,bVr),e(M0,vVr),e(M0,noe),e(noe,FVr),e(M0,TVr),e(ce,MVr),e(ce,E0),e(E0,U0e),e(U0e,EVr),e(E0,CVr),e(E0,soe),e(soe,wVr),e(E0,AVr),e(ce,LVr),e(ce,C0),e(C0,H0e),e(H0e,yVr),e(C0,xVr),e(C0,loe),e(loe,$Vr),e(C0,kVr),e(ce,SVr),e(ce,w0),e(w0,J0e),e(J0e,RVr),e(w0,PVr),e(w0,ioe),e(ioe,BVr),e(w0,IVr),e(ce,NVr),e(ce,A0),e(A0,Y0e),e(Y0e,qVr),e(A0,jVr),e(A0,doe),e(doe,DVr),e(A0,GVr),e(ce,OVr),e(ce,L0),e(L0,K0e),e(K0e,VVr),e(L0,XVr),e(L0,coe),e(coe,zVr),e(L0,WVr),e(ce,QVr),e(ce,y0),e(y0,Z0e),e(Z0e,UVr),e(y0,HVr),e(y0,foe),e(foe,JVr),e(y0,YVr),e(Vr,KVr),M(x0,Vr,null),b(f,bUe,u),b(f,Zc,u),e(Zc,$0),e($0,ewe),M(z$,ewe,null),e(Zc,ZVr),e(Zc,owe),e(owe,eXr),b(f,vUe,u),b(f,_r,u),M(W$,_r,null),e(_r,oXr),e(_r,ef),e(ef,rXr),e(ef,moe),e(moe,tXr),e(ef,aXr),e(ef,goe),e(goe,nXr),e(ef,sXr),e(_r,lXr),e(_r,Q$),e(Q$,iXr),e(Q$,rwe),e(rwe,dXr),e(Q$,cXr),e(_r,fXr),e(_r,Ut),M(U$,Ut,null),e(Ut,mXr),e(Ut,twe),e(twe,gXr),e(Ut,hXr),e(Ut,of),e(of,pXr),e(of,awe),e(awe,_Xr),e(of,uXr),e(of,hoe),e(hoe,bXr),e(of,vXr),e(Ut,FXr),M(k0,Ut,null),e(_r,TXr),e(_r,Xr),M(H$,Xr,null),e(Xr,MXr),e(Xr,nwe),e(nwe,EXr),e(Xr,CXr),e(Xr,wn),e(wn,wXr),e(wn,swe),e(swe,AXr),e(wn,LXr),e(wn,lwe),e(lwe,yXr),e(wn,xXr),e(wn,iwe),e(iwe,$Xr),e(wn,kXr),e(Xr,SXr),e(Xr,dwe),e(dwe,S0),e(S0,cwe),e(cwe,RXr),e(S0,PXr),e(S0,poe),e(poe,BXr),e(S0,IXr),e(Xr,NXr),M(R0,Xr,null),b(f,FUe,u),b(f,rf,u),e(rf,P0),e(P0,fwe),M(J$,fwe,null),e(rf,qXr),e(rf,mwe),e(mwe,jXr),b(f,TUe,u),b(f,ur,u),M(Y$,ur,null),e(ur,DXr),e(ur,tf),e(tf,GXr),e(tf,_oe),e(_oe,OXr),e(tf,VXr),e(tf,uoe),e(uoe,XXr),e(tf,zXr),e(ur,WXr),e(ur,K$),e(K$,QXr),e(K$,gwe),e(gwe,UXr),e(K$,HXr),e(ur,JXr),e(ur,Ht),M(Z$,Ht,null),e(Ht,YXr),e(Ht,hwe),e(hwe,KXr),e(Ht,ZXr),e(Ht,af),e(af,ezr),e(af,pwe),e(pwe,ozr),e(af,rzr),e(af,boe),e(boe,tzr),e(af,azr),e(Ht,nzr),M(B0,Ht,null),e(ur,szr),e(ur,zr),M(ek,zr,null),e(zr,lzr),e(zr,_we),e(_we,izr),e(zr,dzr),e(zr,An),e(An,czr),e(An,uwe),e(uwe,fzr),e(An,mzr),e(An,bwe),e(bwe,gzr),e(An,hzr),e(An,vwe),e(vwe,pzr),e(An,_zr),e(zr,uzr),e(zr,Fwe),e(Fwe,I0),e(I0,Twe),e(Twe,bzr),e(I0,vzr),e(I0,voe),e(voe,Fzr),e(I0,Tzr),e(zr,Mzr),M(N0,zr,null),b(f,MUe,u),b(f,nf,u),e(nf,q0),e(q0,Mwe),M(ok,Mwe,null),e(nf,Ezr),e(nf,Ewe),e(Ewe,Czr),b(f,EUe,u),b(f,br,u),M(rk,br,null),e(br,wzr),e(br,sf),e(sf,Azr),e(sf,Foe),e(Foe,Lzr),e(sf,yzr),e(sf,Toe),e(Toe,xzr),e(sf,$zr),e(br,kzr),e(br,tk),e(tk,Szr),e(tk,Cwe),e(Cwe,Rzr),e(tk,Pzr),e(br,Bzr),e(br,Jt),M(ak,Jt,null),e(Jt,Izr),e(Jt,wwe),e(wwe,Nzr),e(Jt,qzr),e(Jt,lf),e(lf,jzr),e(lf,Awe),e(Awe,Dzr),e(lf,Gzr),e(lf,Moe),e(Moe,Ozr),e(lf,Vzr),e(Jt,Xzr),M(j0,Jt,null),e(br,zzr),e(br,Wr),M(nk,Wr,null),e(Wr,Wzr),e(Wr,Lwe),e(Lwe,Qzr),e(Wr,Uzr),e(Wr,Ln),e(Ln,Hzr),e(Ln,ywe),e(ywe,Jzr),e(Ln,Yzr),e(Ln,xwe),e(xwe,Kzr),e(Ln,Zzr),e(Ln,$we),e($we,eWr),e(Ln,oWr),e(Wr,rWr),e(Wr,oe),e(oe,D0),e(D0,kwe),e(kwe,tWr),e(D0,aWr),e(D0,Eoe),e(Eoe,nWr),e(D0,sWr),e(oe,lWr),e(oe,G0),e(G0,Swe),e(Swe,iWr),e(G0,dWr),e(G0,Coe),e(Coe,cWr),e(G0,fWr),e(oe,mWr),e(oe,O0),e(O0,Rwe),e(Rwe,gWr),e(O0,hWr),e(O0,woe),e(woe,pWr),e(O0,_Wr),e(oe,uWr),e(oe,V0),e(V0,Pwe),e(Pwe,bWr),e(V0,vWr),e(V0,Aoe),e(Aoe,FWr),e(V0,TWr),e(oe,MWr),e(oe,X0),e(X0,Bwe),e(Bwe,EWr),e(X0,CWr),e(X0,Loe),e(Loe,wWr),e(X0,AWr),e(oe,LWr),e(oe,z0),e(z0,Iwe),e(Iwe,yWr),e(z0,xWr),e(z0,yoe),e(yoe,$Wr),e(z0,kWr),e(oe,SWr),e(oe,W0),e(W0,Nwe),e(Nwe,RWr),e(W0,PWr),e(W0,xoe),e(xoe,BWr),e(W0,IWr),e(oe,NWr),e(oe,Q0),e(Q0,qwe),e(qwe,qWr),e(Q0,jWr),e(Q0,$oe),e($oe,DWr),e(Q0,GWr),e(oe,OWr),e(oe,U0),e(U0,jwe),e(jwe,VWr),e(U0,XWr),e(U0,koe),e(koe,zWr),e(U0,WWr),e(oe,QWr),e(oe,H0),e(H0,Dwe),e(Dwe,UWr),e(H0,HWr),e(H0,Soe),e(Soe,JWr),e(H0,YWr),e(oe,KWr),e(oe,J0),e(J0,Gwe),e(Gwe,ZWr),e(J0,eQr),e(J0,Roe),e(Roe,oQr),e(J0,rQr),e(oe,tQr),e(oe,Y0),e(Y0,Owe),e(Owe,aQr),e(Y0,nQr),e(Y0,Poe),e(Poe,sQr),e(Y0,lQr),e(oe,iQr),e(oe,K0),e(K0,Vwe),e(Vwe,dQr),e(K0,cQr),e(K0,Boe),e(Boe,fQr),e(K0,mQr),e(oe,gQr),e(oe,Z0),e(Z0,Xwe),e(Xwe,hQr),e(Z0,pQr),e(Z0,Ioe),e(Ioe,_Qr),e(Z0,uQr),e(oe,bQr),e(oe,ew),e(ew,zwe),e(zwe,vQr),e(ew,FQr),e(ew,Noe),e(Noe,TQr),e(ew,MQr),e(oe,EQr),e(oe,ow),e(ow,Wwe),e(Wwe,CQr),e(ow,wQr),e(ow,qoe),e(qoe,AQr),e(ow,LQr),e(oe,yQr),e(oe,rw),e(rw,Qwe),e(Qwe,xQr),e(rw,$Qr),e(rw,joe),e(joe,kQr),e(rw,SQr),e(oe,RQr),e(oe,tw),e(tw,Uwe),e(Uwe,PQr),e(tw,BQr),e(tw,Doe),e(Doe,IQr),e(tw,NQr),e(oe,qQr),e(oe,aw),e(aw,Hwe),e(Hwe,jQr),e(aw,DQr),e(aw,Goe),e(Goe,GQr),e(aw,OQr),e(oe,VQr),e(oe,nw),e(nw,Jwe),e(Jwe,XQr),e(nw,zQr),e(nw,Ooe),e(Ooe,WQr),e(nw,QQr),e(oe,UQr),e(oe,sw),e(sw,Ywe),e(Ywe,HQr),e(sw,JQr),e(sw,Voe),e(Voe,YQr),e(sw,KQr),e(oe,ZQr),e(oe,lw),e(lw,Kwe),e(Kwe,eUr),e(lw,oUr),e(lw,Xoe),e(Xoe,rUr),e(lw,tUr),e(oe,aUr),e(oe,iw),e(iw,Zwe),e(Zwe,nUr),e(iw,sUr),e(iw,zoe),e(zoe,lUr),e(iw,iUr),e(oe,dUr),e(oe,dw),e(dw,e6e),e(e6e,cUr),e(dw,fUr),e(dw,Woe),e(Woe,mUr),e(dw,gUr),e(oe,hUr),e(oe,cw),e(cw,o6e),e(o6e,pUr),e(cw,_Ur),e(cw,Qoe),e(Qoe,uUr),e(cw,bUr),e(oe,vUr),e(oe,fw),e(fw,r6e),e(r6e,FUr),e(fw,TUr),e(fw,Uoe),e(Uoe,MUr),e(fw,EUr),e(oe,CUr),e(oe,mw),e(mw,t6e),e(t6e,wUr),e(mw,AUr),e(mw,Hoe),e(Hoe,LUr),e(mw,yUr),e(Wr,xUr),M(gw,Wr,null),b(f,CUe,u),b(f,df,u),e(df,hw),e(hw,a6e),M(sk,a6e,null),e(df,$Ur),e(df,n6e),e(n6e,kUr),b(f,wUe,u),b(f,vr,u),M(lk,vr,null),e(vr,SUr),e(vr,cf),e(cf,RUr),e(cf,Joe),e(Joe,PUr),e(cf,BUr),e(cf,Yoe),e(Yoe,IUr),e(cf,NUr),e(vr,qUr),e(vr,ik),e(ik,jUr),e(ik,s6e),e(s6e,DUr),e(ik,GUr),e(vr,OUr),e(vr,Yt),M(dk,Yt,null),e(Yt,VUr),e(Yt,l6e),e(l6e,XUr),e(Yt,zUr),e(Yt,ff),e(ff,WUr),e(ff,i6e),e(i6e,QUr),e(ff,UUr),e(ff,Koe),e(Koe,HUr),e(ff,JUr),e(Yt,YUr),M(pw,Yt,null),e(vr,KUr),e(vr,Qr),M(ck,Qr,null),e(Qr,ZUr),e(Qr,d6e),e(d6e,eHr),e(Qr,oHr),e(Qr,yn),e(yn,rHr),e(yn,c6e),e(c6e,tHr),e(yn,aHr),e(yn,f6e),e(f6e,nHr),e(yn,sHr),e(yn,m6e),e(m6e,lHr),e(yn,iHr),e(Qr,dHr),e(Qr,xe),e(xe,_w),e(_w,g6e),e(g6e,cHr),e(_w,fHr),e(_w,Zoe),e(Zoe,mHr),e(_w,gHr),e(xe,hHr),e(xe,uw),e(uw,h6e),e(h6e,pHr),e(uw,_Hr),e(uw,ere),e(ere,uHr),e(uw,bHr),e(xe,vHr),e(xe,bw),e(bw,p6e),e(p6e,FHr),e(bw,THr),e(bw,ore),e(ore,MHr),e(bw,EHr),e(xe,CHr),e(xe,vw),e(vw,_6e),e(_6e,wHr),e(vw,AHr),e(vw,rre),e(rre,LHr),e(vw,yHr),e(xe,xHr),e(xe,Fw),e(Fw,u6e),e(u6e,$Hr),e(Fw,kHr),e(Fw,tre),e(tre,SHr),e(Fw,RHr),e(xe,PHr),e(xe,Tw),e(Tw,b6e),e(b6e,BHr),e(Tw,IHr),e(Tw,are),e(are,NHr),e(Tw,qHr),e(xe,jHr),e(xe,Mw),e(Mw,v6e),e(v6e,DHr),e(Mw,GHr),e(Mw,nre),e(nre,OHr),e(Mw,VHr),e(xe,XHr),e(xe,Ew),e(Ew,F6e),e(F6e,zHr),e(Ew,WHr),e(Ew,sre),e(sre,QHr),e(Ew,UHr),e(xe,HHr),e(xe,Cw),e(Cw,T6e),e(T6e,JHr),e(Cw,YHr),e(Cw,lre),e(lre,KHr),e(Cw,ZHr),e(xe,eJr),e(xe,ww),e(ww,M6e),e(M6e,oJr),e(ww,rJr),e(ww,ire),e(ire,tJr),e(ww,aJr),e(Qr,nJr),M(Aw,Qr,null),b(f,AUe,u),b(f,mf,u),e(mf,Lw),e(Lw,E6e),M(fk,E6e,null),e(mf,sJr),e(mf,C6e),e(C6e,lJr),b(f,LUe,u),b(f,Fr,u),M(mk,Fr,null),e(Fr,iJr),e(Fr,gf),e(gf,dJr),e(gf,dre),e(dre,cJr),e(gf,fJr),e(gf,cre),e(cre,mJr),e(gf,gJr),e(Fr,hJr),e(Fr,gk),e(gk,pJr),e(gk,w6e),e(w6e,_Jr),e(gk,uJr),e(Fr,bJr),e(Fr,Kt),M(hk,Kt,null),e(Kt,vJr),e(Kt,A6e),e(A6e,FJr),e(Kt,TJr),e(Kt,hf),e(hf,MJr),e(hf,L6e),e(L6e,EJr),e(hf,CJr),e(hf,fre),e(fre,wJr),e(hf,AJr),e(Kt,LJr),M(yw,Kt,null),e(Fr,yJr),e(Fr,Ur),M(pk,Ur,null),e(Ur,xJr),e(Ur,y6e),e(y6e,$Jr),e(Ur,kJr),e(Ur,xn),e(xn,SJr),e(xn,x6e),e(x6e,RJr),e(xn,PJr),e(xn,$6e),e($6e,BJr),e(xn,IJr),e(xn,k6e),e(k6e,NJr),e(xn,qJr),e(Ur,jJr),e(Ur,Ee),e(Ee,xw),e(xw,S6e),e(S6e,DJr),e(xw,GJr),e(xw,mre),e(mre,OJr),e(xw,VJr),e(Ee,XJr),e(Ee,$w),e($w,R6e),e(R6e,zJr),e($w,WJr),e($w,gre),e(gre,QJr),e($w,UJr),e(Ee,HJr),e(Ee,kw),e(kw,P6e),e(P6e,JJr),e(kw,YJr),e(kw,hre),e(hre,KJr),e(kw,ZJr),e(Ee,eYr),e(Ee,Sw),e(Sw,B6e),e(B6e,oYr),e(Sw,rYr),e(Sw,pre),e(pre,tYr),e(Sw,aYr),e(Ee,nYr),e(Ee,Rw),e(Rw,I6e),e(I6e,sYr),e(Rw,lYr),e(Rw,_re),e(_re,iYr),e(Rw,dYr),e(Ee,cYr),e(Ee,Pw),e(Pw,N6e),e(N6e,fYr),e(Pw,mYr),e(Pw,ure),e(ure,gYr),e(Pw,hYr),e(Ee,pYr),e(Ee,Bw),e(Bw,q6e),e(q6e,_Yr),e(Bw,uYr),e(Bw,bre),e(bre,bYr),e(Bw,vYr),e(Ee,FYr),e(Ee,Iw),e(Iw,j6e),e(j6e,TYr),e(Iw,MYr),e(Iw,vre),e(vre,EYr),e(Iw,CYr),e(Ee,wYr),e(Ee,Nw),e(Nw,D6e),e(D6e,AYr),e(Nw,LYr),e(Nw,Fre),e(Fre,yYr),e(Nw,xYr),e(Ee,$Yr),e(Ee,qw),e(qw,G6e),e(G6e,kYr),e(qw,SYr),e(qw,Tre),e(Tre,RYr),e(qw,PYr),e(Ee,BYr),e(Ee,jw),e(jw,O6e),e(O6e,IYr),e(jw,NYr),e(jw,Mre),e(Mre,qYr),e(jw,jYr),e(Ee,DYr),e(Ee,Dw),e(Dw,V6e),e(V6e,GYr),e(Dw,OYr),e(Dw,Ere),e(Ere,VYr),e(Dw,XYr),e(Ee,zYr),e(Ee,Gw),e(Gw,X6e),e(X6e,WYr),e(Gw,QYr),e(Gw,Cre),e(Cre,UYr),e(Gw,HYr),e(Ur,JYr),M(Ow,Ur,null),b(f,yUe,u),b(f,pf,u),e(pf,Vw),e(Vw,z6e),M(_k,z6e,null),e(pf,YYr),e(pf,W6e),e(W6e,KYr),b(f,xUe,u),b(f,Tr,u),M(uk,Tr,null),e(Tr,ZYr),e(Tr,_f),e(_f,eKr),e(_f,wre),e(wre,oKr),e(_f,rKr),e(_f,Are),e(Are,tKr),e(_f,aKr),e(Tr,nKr),e(Tr,bk),e(bk,sKr),e(bk,Q6e),e(Q6e,lKr),e(bk,iKr),e(Tr,dKr),e(Tr,Zt),M(vk,Zt,null),e(Zt,cKr),e(Zt,U6e),e(U6e,fKr),e(Zt,mKr),e(Zt,uf),e(uf,gKr),e(uf,H6e),e(H6e,hKr),e(uf,pKr),e(uf,Lre),e(Lre,_Kr),e(uf,uKr),e(Zt,bKr),M(Xw,Zt,null),e(Tr,vKr),e(Tr,Hr),M(Fk,Hr,null),e(Hr,FKr),e(Hr,J6e),e(J6e,TKr),e(Hr,MKr),e(Hr,$n),e($n,EKr),e($n,Y6e),e(Y6e,CKr),e($n,wKr),e($n,K6e),e(K6e,AKr),e($n,LKr),e($n,Z6e),e(Z6e,yKr),e($n,xKr),e(Hr,$Kr),e(Hr,$e),e($e,zw),e(zw,eAe),e(eAe,kKr),e(zw,SKr),e(zw,yre),e(yre,RKr),e(zw,PKr),e($e,BKr),e($e,Ww),e(Ww,oAe),e(oAe,IKr),e(Ww,NKr),e(Ww,xre),e(xre,qKr),e(Ww,jKr),e($e,DKr),e($e,Qw),e(Qw,rAe),e(rAe,GKr),e(Qw,OKr),e(Qw,$re),e($re,VKr),e(Qw,XKr),e($e,zKr),e($e,Uw),e(Uw,tAe),e(tAe,WKr),e(Uw,QKr),e(Uw,kre),e(kre,UKr),e(Uw,HKr),e($e,JKr),e($e,Hw),e(Hw,aAe),e(aAe,YKr),e(Hw,KKr),e(Hw,Sre),e(Sre,ZKr),e(Hw,eZr),e($e,oZr),e($e,Jw),e(Jw,nAe),e(nAe,rZr),e(Jw,tZr),e(Jw,Rre),e(Rre,aZr),e(Jw,nZr),e($e,sZr),e($e,Yw),e(Yw,sAe),e(sAe,lZr),e(Yw,iZr),e(Yw,Pre),e(Pre,dZr),e(Yw,cZr),e($e,fZr),e($e,Kw),e(Kw,lAe),e(lAe,mZr),e(Kw,gZr),e(Kw,Bre),e(Bre,hZr),e(Kw,pZr),e($e,_Zr),e($e,Zw),e(Zw,iAe),e(iAe,uZr),e(Zw,bZr),e(Zw,Ire),e(Ire,vZr),e(Zw,FZr),e($e,TZr),e($e,e6),e(e6,dAe),e(dAe,MZr),e(e6,EZr),e(e6,Nre),e(Nre,CZr),e(e6,wZr),e(Hr,AZr),M(o6,Hr,null),b(f,$Ue,u),b(f,bf,u),e(bf,r6),e(r6,cAe),M(Tk,cAe,null),e(bf,LZr),e(bf,fAe),e(fAe,yZr),b(f,kUe,u),b(f,Mr,u),M(Mk,Mr,null),e(Mr,xZr),e(Mr,vf),e(vf,$Zr),e(vf,qre),e(qre,kZr),e(vf,SZr),e(vf,jre),e(jre,RZr),e(vf,PZr),e(Mr,BZr),e(Mr,Ek),e(Ek,IZr),e(Ek,mAe),e(mAe,NZr),e(Ek,qZr),e(Mr,jZr),e(Mr,ea),M(Ck,ea,null),e(ea,DZr),e(ea,gAe),e(gAe,GZr),e(ea,OZr),e(ea,Ff),e(Ff,VZr),e(Ff,hAe),e(hAe,XZr),e(Ff,zZr),e(Ff,Dre),e(Dre,WZr),e(Ff,QZr),e(ea,UZr),M(t6,ea,null),e(Mr,HZr),e(Mr,Jr),M(wk,Jr,null),e(Jr,JZr),e(Jr,pAe),e(pAe,YZr),e(Jr,KZr),e(Jr,kn),e(kn,ZZr),e(kn,_Ae),e(_Ae,eet),e(kn,oet),e(kn,uAe),e(uAe,ret),e(kn,tet),e(kn,bAe),e(bAe,aet),e(kn,net),e(Jr,set),e(Jr,ke),e(ke,a6),e(a6,vAe),e(vAe,iet),e(a6,det),e(a6,Gre),e(Gre,cet),e(a6,fet),e(ke,met),e(ke,n6),e(n6,FAe),e(FAe,get),e(n6,het),e(n6,Ore),e(Ore,pet),e(n6,_et),e(ke,uet),e(ke,s6),e(s6,TAe),e(TAe,bet),e(s6,vet),e(s6,Vre),e(Vre,Fet),e(s6,Tet),e(ke,Met),e(ke,l6),e(l6,MAe),e(MAe,Eet),e(l6,Cet),e(l6,Xre),e(Xre,wet),e(l6,Aet),e(ke,Let),e(ke,i6),e(i6,EAe),e(EAe,yet),e(i6,xet),e(i6,zre),e(zre,$et),e(i6,ket),e(ke,Set),e(ke,d6),e(d6,CAe),e(CAe,Ret),e(d6,Pet),e(d6,Wre),e(Wre,Bet),e(d6,Iet),e(ke,Net),e(ke,c6),e(c6,wAe),e(wAe,qet),e(c6,jet),e(c6,Qre),e(Qre,Det),e(c6,Get),e(ke,Oet),e(ke,f6),e(f6,AAe),e(AAe,Vet),e(f6,Xet),e(f6,Ure),e(Ure,zet),e(f6,Wet),e(ke,Qet),e(ke,m6),e(m6,LAe),e(LAe,Uet),e(m6,Het),e(m6,Hre),e(Hre,Jet),e(m6,Yet),e(ke,Ket),e(ke,g6),e(g6,yAe),e(yAe,Zet),e(g6,eot),e(g6,Jre),e(Jre,oot),e(g6,rot),e(Jr,tot),M(h6,Jr,null),b(f,SUe,u),b(f,Tf,u),e(Tf,p6),e(p6,xAe),M(Ak,xAe,null),e(Tf,aot),e(Tf,$Ae),e($Ae,not),b(f,RUe,u),b(f,Er,u),M(Lk,Er,null),e(Er,sot),e(Er,Mf),e(Mf,lot),e(Mf,Yre),e(Yre,iot),e(Mf,dot),e(Mf,Kre),e(Kre,cot),e(Mf,fot),e(Er,mot),e(Er,yk),e(yk,got),e(yk,kAe),e(kAe,hot),e(yk,pot),e(Er,_ot),e(Er,oa),M(xk,oa,null),e(oa,uot),e(oa,SAe),e(SAe,bot),e(oa,vot),e(oa,Ef),e(Ef,Fot),e(Ef,RAe),e(RAe,Tot),e(Ef,Mot),e(Ef,Zre),e(Zre,Eot),e(Ef,Cot),e(oa,wot),M(_6,oa,null),e(Er,Aot),e(Er,Yr),M($k,Yr,null),e(Yr,Lot),e(Yr,PAe),e(PAe,yot),e(Yr,xot),e(Yr,Sn),e(Sn,$ot),e(Sn,BAe),e(BAe,kot),e(Sn,Sot),e(Sn,IAe),e(IAe,Rot),e(Sn,Pot),e(Sn,NAe),e(NAe,Bot),e(Sn,Iot),e(Yr,Not),e(Yr,Se),e(Se,u6),e(u6,qAe),e(qAe,qot),e(u6,jot),e(u6,ete),e(ete,Dot),e(u6,Got),e(Se,Oot),e(Se,b6),e(b6,jAe),e(jAe,Vot),e(b6,Xot),e(b6,ote),e(ote,zot),e(b6,Wot),e(Se,Qot),e(Se,v6),e(v6,DAe),e(DAe,Uot),e(v6,Hot),e(v6,rte),e(rte,Jot),e(v6,Yot),e(Se,Kot),e(Se,F6),e(F6,GAe),e(GAe,Zot),e(F6,ert),e(F6,tte),e(tte,ort),e(F6,rrt),e(Se,trt),e(Se,T6),e(T6,OAe),e(OAe,art),e(T6,nrt),e(T6,ate),e(ate,srt),e(T6,lrt),e(Se,irt),e(Se,M6),e(M6,VAe),e(VAe,drt),e(M6,crt),e(M6,nte),e(nte,frt),e(M6,mrt),e(Se,grt),e(Se,E6),e(E6,XAe),e(XAe,hrt),e(E6,prt),e(E6,ste),e(ste,_rt),e(E6,urt),e(Se,brt),e(Se,C6),e(C6,zAe),e(zAe,vrt),e(C6,Frt),e(C6,lte),e(lte,Trt),e(C6,Mrt),e(Se,Ert),e(Se,w6),e(w6,WAe),e(WAe,Crt),e(w6,wrt),e(w6,ite),e(ite,Art),e(w6,Lrt),e(Se,yrt),e(Se,A6),e(A6,QAe),e(QAe,xrt),e(A6,$rt),e(A6,dte),e(dte,krt),e(A6,Srt),e(Yr,Rrt),M(L6,Yr,null),b(f,PUe,u),b(f,Cf,u),e(Cf,y6),e(y6,UAe),M(kk,UAe,null),e(Cf,Prt),e(Cf,HAe),e(HAe,Brt),b(f,BUe,u),b(f,Cr,u),M(Sk,Cr,null),e(Cr,Irt),e(Cr,wf),e(wf,Nrt),e(wf,cte),e(cte,qrt),e(wf,jrt),e(wf,fte),e(fte,Drt),e(wf,Grt),e(Cr,Ort),e(Cr,Rk),e(Rk,Vrt),e(Rk,JAe),e(JAe,Xrt),e(Rk,zrt),e(Cr,Wrt),e(Cr,ra),M(Pk,ra,null),e(ra,Qrt),e(ra,YAe),e(YAe,Urt),e(ra,Hrt),e(ra,Af),e(Af,Jrt),e(Af,KAe),e(KAe,Yrt),e(Af,Krt),e(Af,mte),e(mte,Zrt),e(Af,ett),e(ra,ott),M(x6,ra,null),e(Cr,rtt),e(Cr,Kr),M(Bk,Kr,null),e(Kr,ttt),e(Kr,ZAe),e(ZAe,att),e(Kr,ntt),e(Kr,Rn),e(Rn,stt),e(Rn,e7e),e(e7e,ltt),e(Rn,itt),e(Rn,o7e),e(o7e,dtt),e(Rn,ctt),e(Rn,r7e),e(r7e,ftt),e(Rn,mtt),e(Kr,gtt),e(Kr,Re),e(Re,$6),e($6,t7e),e(t7e,htt),e($6,ptt),e($6,gte),e(gte,_tt),e($6,utt),e(Re,btt),e(Re,k6),e(k6,a7e),e(a7e,vtt),e(k6,Ftt),e(k6,hte),e(hte,Ttt),e(k6,Mtt),e(Re,Ett),e(Re,S6),e(S6,n7e),e(n7e,Ctt),e(S6,wtt),e(S6,pte),e(pte,Att),e(S6,Ltt),e(Re,ytt),e(Re,R6),e(R6,s7e),e(s7e,xtt),e(R6,$tt),e(R6,_te),e(_te,ktt),e(R6,Stt),e(Re,Rtt),e(Re,P6),e(P6,l7e),e(l7e,Ptt),e(P6,Btt),e(P6,ute),e(ute,Itt),e(P6,Ntt),e(Re,qtt),e(Re,B6),e(B6,i7e),e(i7e,jtt),e(B6,Dtt),e(B6,bte),e(bte,Gtt),e(B6,Ott),e(Re,Vtt),e(Re,I6),e(I6,d7e),e(d7e,Xtt),e(I6,ztt),e(I6,vte),e(vte,Wtt),e(I6,Qtt),e(Re,Utt),e(Re,N6),e(N6,c7e),e(c7e,Htt),e(N6,Jtt),e(N6,Fte),e(Fte,Ytt),e(N6,Ktt),e(Re,Ztt),e(Re,q6),e(q6,f7e),e(f7e,eat),e(q6,oat),e(q6,Tte),e(Tte,rat),e(q6,tat),e(Re,aat),e(Re,j6),e(j6,m7e),e(m7e,nat),e(j6,sat),e(j6,Mte),e(Mte,lat),e(j6,iat),e(Kr,dat),M(D6,Kr,null),b(f,IUe,u),b(f,Lf,u),e(Lf,G6),e(G6,g7e),M(Ik,g7e,null),e(Lf,cat),e(Lf,h7e),e(h7e,fat),b(f,NUe,u),b(f,wr,u),M(Nk,wr,null),e(wr,mat),e(wr,yf),e(yf,gat),e(yf,Ete),e(Ete,hat),e(yf,pat),e(yf,Cte),e(Cte,_at),e(yf,uat),e(wr,bat),e(wr,qk),e(qk,vat),e(qk,p7e),e(p7e,Fat),e(qk,Tat),e(wr,Mat),e(wr,ta),M(jk,ta,null),e(ta,Eat),e(ta,_7e),e(_7e,Cat),e(ta,wat),e(ta,xf),e(xf,Aat),e(xf,u7e),e(u7e,Lat),e(xf,yat),e(xf,wte),e(wte,xat),e(xf,$at),e(ta,kat),M(O6,ta,null),e(wr,Sat),e(wr,Zr),M(Dk,Zr,null),e(Zr,Rat),e(Zr,b7e),e(b7e,Pat),e(Zr,Bat),e(Zr,Pn),e(Pn,Iat),e(Pn,v7e),e(v7e,Nat),e(Pn,qat),e(Pn,F7e),e(F7e,jat),e(Pn,Dat),e(Pn,T7e),e(T7e,Gat),e(Pn,Oat),e(Zr,Vat),e(Zr,Xe),e(Xe,V6),e(V6,M7e),e(M7e,Xat),e(V6,zat),e(V6,Ate),e(Ate,Wat),e(V6,Qat),e(Xe,Uat),e(Xe,X6),e(X6,E7e),e(E7e,Hat),e(X6,Jat),e(X6,Lte),e(Lte,Yat),e(X6,Kat),e(Xe,Zat),e(Xe,z6),e(z6,C7e),e(C7e,ent),e(z6,ont),e(z6,yte),e(yte,rnt),e(z6,tnt),e(Xe,ant),e(Xe,W6),e(W6,w7e),e(w7e,nnt),e(W6,snt),e(W6,xte),e(xte,lnt),e(W6,int),e(Xe,dnt),e(Xe,Q6),e(Q6,A7e),e(A7e,cnt),e(Q6,fnt),e(Q6,$te),e($te,mnt),e(Q6,gnt),e(Xe,hnt),e(Xe,U6),e(U6,L7e),e(L7e,pnt),e(U6,_nt),e(U6,kte),e(kte,unt),e(U6,bnt),e(Xe,vnt),e(Xe,H6),e(H6,y7e),e(y7e,Fnt),e(H6,Tnt),e(H6,Ste),e(Ste,Mnt),e(H6,Ent),e(Xe,Cnt),e(Xe,J6),e(J6,x7e),e(x7e,wnt),e(J6,Ant),e(J6,Rte),e(Rte,Lnt),e(J6,ynt),e(Zr,xnt),M(Y6,Zr,null),b(f,qUe,u),b(f,$f,u),e($f,K6),e(K6,$7e),M(Gk,$7e,null),e($f,$nt),e($f,k7e),e(k7e,knt),b(f,jUe,u),b(f,Ar,u),M(Ok,Ar,null),e(Ar,Snt),e(Ar,kf),e(kf,Rnt),e(kf,Pte),e(Pte,Pnt),e(kf,Bnt),e(kf,Bte),e(Bte,Int),e(kf,Nnt),e(Ar,qnt),e(Ar,Vk),e(Vk,jnt),e(Vk,S7e),e(S7e,Dnt),e(Vk,Gnt),e(Ar,Ont),e(Ar,aa),M(Xk,aa,null),e(aa,Vnt),e(aa,R7e),e(R7e,Xnt),e(aa,znt),e(aa,Sf),e(Sf,Wnt),e(Sf,P7e),e(P7e,Qnt),e(Sf,Unt),e(Sf,Ite),e(Ite,Hnt),e(Sf,Jnt),e(aa,Ynt),M(Z6,aa,null),e(Ar,Knt),e(Ar,et),M(zk,et,null),e(et,Znt),e(et,B7e),e(B7e,est),e(et,ost),e(et,Bn),e(Bn,rst),e(Bn,I7e),e(I7e,tst),e(Bn,ast),e(Bn,N7e),e(N7e,nst),e(Bn,sst),e(Bn,q7e),e(q7e,lst),e(Bn,ist),e(et,dst),e(et,ze),e(ze,eA),e(eA,j7e),e(j7e,cst),e(eA,fst),e(eA,Nte),e(Nte,mst),e(eA,gst),e(ze,hst),e(ze,oA),e(oA,D7e),e(D7e,pst),e(oA,_st),e(oA,qte),e(qte,ust),e(oA,bst),e(ze,vst),e(ze,rA),e(rA,G7e),e(G7e,Fst),e(rA,Tst),e(rA,jte),e(jte,Mst),e(rA,Est),e(ze,Cst),e(ze,tA),e(tA,O7e),e(O7e,wst),e(tA,Ast),e(tA,Dte),e(Dte,Lst),e(tA,yst),e(ze,xst),e(ze,aA),e(aA,V7e),e(V7e,$st),e(aA,kst),e(aA,Gte),e(Gte,Sst),e(aA,Rst),e(ze,Pst),e(ze,nA),e(nA,X7e),e(X7e,Bst),e(nA,Ist),e(nA,Ote),e(Ote,Nst),e(nA,qst),e(ze,jst),e(ze,sA),e(sA,z7e),e(z7e,Dst),e(sA,Gst),e(sA,Vte),e(Vte,Ost),e(sA,Vst),e(ze,Xst),e(ze,lA),e(lA,W7e),e(W7e,zst),e(lA,Wst),e(lA,Xte),e(Xte,Qst),e(lA,Ust),e(et,Hst),M(iA,et,null),b(f,DUe,u),b(f,Rf,u),e(Rf,dA),e(dA,Q7e),M(Wk,Q7e,null),e(Rf,Jst),e(Rf,U7e),e(U7e,Yst),b(f,GUe,u),b(f,Lr,u),M(Qk,Lr,null),e(Lr,Kst),e(Lr,Pf),e(Pf,Zst),e(Pf,zte),e(zte,elt),e(Pf,olt),e(Pf,Wte),e(Wte,rlt),e(Pf,tlt),e(Lr,alt),e(Lr,Uk),e(Uk,nlt),e(Uk,H7e),e(H7e,slt),e(Uk,llt),e(Lr,ilt),e(Lr,na),M(Hk,na,null),e(na,dlt),e(na,J7e),e(J7e,clt),e(na,flt),e(na,Bf),e(Bf,mlt),e(Bf,Y7e),e(Y7e,glt),e(Bf,hlt),e(Bf,Qte),e(Qte,plt),e(Bf,_lt),e(na,ult),M(cA,na,null),e(Lr,blt),e(Lr,ot),M(Jk,ot,null),e(ot,vlt),e(ot,K7e),e(K7e,Flt),e(ot,Tlt),e(ot,In),e(In,Mlt),e(In,Z7e),e(Z7e,Elt),e(In,Clt),e(In,eLe),e(eLe,wlt),e(In,Alt),e(In,oLe),e(oLe,Llt),e(In,ylt),e(ot,xlt),e(ot,rLe),e(rLe,fA),e(fA,tLe),e(tLe,$lt),e(fA,klt),e(fA,Ute),e(Ute,Slt),e(fA,Rlt),e(ot,Plt),M(mA,ot,null),b(f,OUe,u),b(f,If,u),e(If,gA),e(gA,aLe),M(Yk,aLe,null),e(If,Blt),e(If,nLe),e(nLe,Ilt),b(f,VUe,u),b(f,yr,u),M(Kk,yr,null),e(yr,Nlt),e(yr,Nf),e(Nf,qlt),e(Nf,Hte),e(Hte,jlt),e(Nf,Dlt),e(Nf,Jte),e(Jte,Glt),e(Nf,Olt),e(yr,Vlt),e(yr,Zk),e(Zk,Xlt),e(Zk,sLe),e(sLe,zlt),e(Zk,Wlt),e(yr,Qlt),e(yr,sa),M(eS,sa,null),e(sa,Ult),e(sa,lLe),e(lLe,Hlt),e(sa,Jlt),e(sa,qf),e(qf,Ylt),e(qf,iLe),e(iLe,Klt),e(qf,Zlt),e(qf,Yte),e(Yte,eit),e(qf,oit),e(sa,rit),M(hA,sa,null),e(yr,tit),e(yr,rt),M(oS,rt,null),e(rt,ait),e(rt,dLe),e(dLe,nit),e(rt,sit),e(rt,Nn),e(Nn,lit),e(Nn,cLe),e(cLe,iit),e(Nn,dit),e(Nn,fLe),e(fLe,cit),e(Nn,fit),e(Nn,mLe),e(mLe,mit),e(Nn,git),e(rt,hit),e(rt,rS),e(rS,pA),e(pA,gLe),e(gLe,pit),e(pA,_it),e(pA,Kte),e(Kte,uit),e(pA,bit),e(rS,vit),e(rS,_A),e(_A,hLe),e(hLe,Fit),e(_A,Tit),e(_A,Zte),e(Zte,Mit),e(_A,Eit),e(rt,Cit),M(uA,rt,null),b(f,XUe,u),b(f,jf,u),e(jf,bA),e(bA,pLe),M(tS,pLe,null),e(jf,wit),e(jf,_Le),e(_Le,Ait),b(f,zUe,u),b(f,xr,u),M(aS,xr,null),e(xr,Lit),e(xr,Df),e(Df,yit),e(Df,eae),e(eae,xit),e(Df,$it),e(Df,oae),e(oae,kit),e(Df,Sit),e(xr,Rit),e(xr,nS),e(nS,Pit),e(nS,uLe),e(uLe,Bit),e(nS,Iit),e(xr,Nit),e(xr,la),M(sS,la,null),e(la,qit),e(la,bLe),e(bLe,jit),e(la,Dit),e(la,Gf),e(Gf,Git),e(Gf,vLe),e(vLe,Oit),e(Gf,Vit),e(Gf,rae),e(rae,Xit),e(Gf,zit),e(la,Wit),M(vA,la,null),e(xr,Qit),e(xr,tt),M(lS,tt,null),e(tt,Uit),e(tt,FLe),e(FLe,Hit),e(tt,Jit),e(tt,qn),e(qn,Yit),e(qn,TLe),e(TLe,Kit),e(qn,Zit),e(qn,MLe),e(MLe,edt),e(qn,odt),e(qn,ELe),e(ELe,rdt),e(qn,tdt),e(tt,adt),e(tt,CLe),e(CLe,FA),e(FA,wLe),e(wLe,ndt),e(FA,sdt),e(FA,tae),e(tae,ldt),e(FA,idt),e(tt,ddt),M(TA,tt,null),WUe=!0},p(f,[u]){const iS={};u&2&&(iS.$$scope={dirty:u,ctx:f}),Jf.$set(iS);const ALe={};u&2&&(ALe.$$scope={dirty:u,ctx:f}),fh.$set(ALe);const LLe={};u&2&&(LLe.$$scope={dirty:u,ctx:f}),Qh.$set(LLe);const yLe={};u&2&&(yLe.$$scope={dirty:u,ctx:f}),Pp.$set(yLe);const dS={};u&2&&(dS.$$scope={dirty:u,ctx:f}),Bp.$set(dS);const xLe={};u&2&&(xLe.$$scope={dirty:u,ctx:f}),t_.$set(xLe);const jn={};u&2&&(jn.$$scope={dirty:u,ctx:f}),a_.$set(jn);const $Le={};u&2&&($Le.$$scope={dirty:u,ctx:f}),l_.$set($Le);const kLe={};u&2&&(kLe.$$scope={dirty:u,ctx:f}),p2.$set(kLe);const SLe={};u&2&&(SLe.$$scope={dirty:u,ctx:f}),u2.$set(SLe);const cS={};u&2&&(cS.$$scope={dirty:u,ctx:f}),m1.$set(cS);const RLe={};u&2&&(RLe.$$scope={dirty:u,ctx:f}),h1.$set(RLe);const fS={};u&2&&(fS.$$scope={dirty:u,ctx:f}),r4.$set(fS);const PLe={};u&2&&(PLe.$$scope={dirty:u,ctx:f}),a4.$set(PLe);const mS={};u&2&&(mS.$$scope={dirty:u,ctx:f}),X4.$set(mS);const BLe={};u&2&&(BLe.$$scope={dirty:u,ctx:f}),W4.$set(BLe);const ILe={};u&2&&(ILe.$$scope={dirty:u,ctx:f}),gb.$set(ILe);const NLe={};u&2&&(NLe.$$scope={dirty:u,ctx:f}),pb.$set(NLe);const Of={};u&2&&(Of.$$scope={dirty:u,ctx:f}),pv.$set(Of);const qLe={};u&2&&(qLe.$$scope={dirty:u,ctx:f}),uv.$set(qLe);const jLe={};u&2&&(jLe.$$scope={dirty:u,ctx:f}),Jv.$set(jLe);const DLe={};u&2&&(DLe.$$scope={dirty:u,ctx:f}),Kv.$set(DLe);const gS={};u&2&&(gS.$$scope={dirty:u,ctx:f}),s5.$set(gS);const GLe={};u&2&&(GLe.$$scope={dirty:u,ctx:f}),i5.$set(GLe);const OLe={};u&2&&(OLe.$$scope={dirty:u,ctx:f}),Q5.$set(OLe);const VLe={};u&2&&(VLe.$$scope={dirty:u,ctx:f}),H5.$set(VLe);const lt={};u&2&&(lt.$$scope={dirty:u,ctx:f}),DF.$set(lt);const hS={};u&2&&(hS.$$scope={dirty:u,ctx:f}),OF.$set(hS);const XLe={};u&2&&(XLe.$$scope={dirty:u,ctx:f}),zF.$set(XLe);const pS={};u&2&&(pS.$$scope={dirty:u,ctx:f}),QF.$set(pS);const zLe={};u&2&&(zLe.$$scope={dirty:u,ctx:f}),dT.$set(zLe);const it={};u&2&&(it.$$scope={dirty:u,ctx:f}),fT.$set(it);const WLe={};u&2&&(WLe.$$scope={dirty:u,ctx:f}),hT.$set(WLe);const Vf={};u&2&&(Vf.$$scope={dirty:u,ctx:f}),_T.$set(Vf);const QLe={};u&2&&(QLe.$$scope={dirty:u,ctx:f}),vT.$set(QLe);const ULe={};u&2&&(ULe.$$scope={dirty:u,ctx:f}),TT.$set(ULe);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),CT.$set(L);const MA={};u&2&&(MA.$$scope={dirty:u,ctx:f}),AT.$set(MA);const HLe={};u&2&&(HLe.$$scope={dirty:u,ctx:f}),NT.$set(HLe);const JLe={};u&2&&(JLe.$$scope={dirty:u,ctx:f}),jT.$set(JLe);const EA={};u&2&&(EA.$$scope={dirty:u,ctx:f}),WT.$set(EA);const YLe={};u&2&&(YLe.$$scope={dirty:u,ctx:f}),UT.$set(YLe);const KLe={};u&2&&(KLe.$$scope={dirty:u,ctx:f}),s8.$set(KLe);const CA={};u&2&&(CA.$$scope={dirty:u,ctx:f}),i8.$set(CA);const ZLe={};u&2&&(ZLe.$$scope={dirty:u,ctx:f}),m8.$set(ZLe);const eye={};u&2&&(eye.$$scope={dirty:u,ctx:f}),h8.$set(eye);const wA={};u&2&&(wA.$$scope={dirty:u,ctx:f}),T8.$set(wA);const oye={};u&2&&(oye.$$scope={dirty:u,ctx:f}),E8.$set(oye);const rye={};u&2&&(rye.$$scope={dirty:u,ctx:f}),x8.$set(rye);const AA={};u&2&&(AA.$$scope={dirty:u,ctx:f}),k8.$set(AA);const tye={};u&2&&(tye.$$scope={dirty:u,ctx:f}),B8.$set(tye);const aye={};u&2&&(aye.$$scope={dirty:u,ctx:f}),N8.$set(aye);const LA={};u&2&&(LA.$$scope={dirty:u,ctx:f}),D8.$set(LA);const nye={};u&2&&(nye.$$scope={dirty:u,ctx:f}),O8.$set(nye);const sye={};u&2&&(sye.$$scope={dirty:u,ctx:f}),H8.$set(sye);const yA={};u&2&&(yA.$$scope={dirty:u,ctx:f}),Y8.$set(yA);const lye={};u&2&&(lye.$$scope={dirty:u,ctx:f}),eM.$set(lye);const iye={};u&2&&(iye.$$scope={dirty:u,ctx:f}),rM.$set(iye);const xA={};u&2&&(xA.$$scope={dirty:u,ctx:f}),ZM.$set(xA);const dye={};u&2&&(dye.$$scope={dirty:u,ctx:f}),oE.$set(dye);const cye={};u&2&&(cye.$$scope={dirty:u,ctx:f}),wE.$set(cye);const $A={};u&2&&($A.$$scope={dirty:u,ctx:f}),LE.$set($A);const fye={};u&2&&(fye.$$scope={dirty:u,ctx:f}),GE.$set(fye);const mye={};u&2&&(mye.$$scope={dirty:u,ctx:f}),VE.$set(mye);const kA={};u&2&&(kA.$$scope={dirty:u,ctx:f}),YE.$set(kA);const gye={};u&2&&(gye.$$scope={dirty:u,ctx:f}),ZE.$set(gye);const hye={};u&2&&(hye.$$scope={dirty:u,ctx:f}),FC.$set(hye);const SA={};u&2&&(SA.$$scope={dirty:u,ctx:f}),MC.$set(SA);const pye={};u&2&&(pye.$$scope={dirty:u,ctx:f}),RC.$set(pye);const _ye={};u&2&&(_ye.$$scope={dirty:u,ctx:f}),BC.$set(_ye);const RA={};u&2&&(RA.$$scope={dirty:u,ctx:f}),i3.$set(RA);const uye={};u&2&&(uye.$$scope={dirty:u,ctx:f}),c3.$set(uye);const bye={};u&2&&(bye.$$scope={dirty:u,ctx:f}),y3.$set(bye);const PA={};u&2&&(PA.$$scope={dirty:u,ctx:f}),$3.$set(PA);const vye={};u&2&&(vye.$$scope={dirty:u,ctx:f}),R3.$set(vye);const Fye={};u&2&&(Fye.$$scope={dirty:u,ctx:f}),B3.$set(Fye);const BA={};u&2&&(BA.$$scope={dirty:u,ctx:f}),N3.$set(BA);const Tye={};u&2&&(Tye.$$scope={dirty:u,ctx:f}),j3.$set(Tye);const Mye={};u&2&&(Mye.$$scope={dirty:u,ctx:f}),s0.$set(Mye);const IA={};u&2&&(IA.$$scope={dirty:u,ctx:f}),i0.$set(IA);const Eye={};u&2&&(Eye.$$scope={dirty:u,ctx:f}),x0.$set(Eye);const Cye={};u&2&&(Cye.$$scope={dirty:u,ctx:f}),k0.$set(Cye);const NA={};u&2&&(NA.$$scope={dirty:u,ctx:f}),R0.$set(NA);const wye={};u&2&&(wye.$$scope={dirty:u,ctx:f}),B0.$set(wye);const Aye={};u&2&&(Aye.$$scope={dirty:u,ctx:f}),N0.$set(Aye);const qA={};u&2&&(qA.$$scope={dirty:u,ctx:f}),j0.$set(qA);const Lye={};u&2&&(Lye.$$scope={dirty:u,ctx:f}),gw.$set(Lye);const yye={};u&2&&(yye.$$scope={dirty:u,ctx:f}),pw.$set(yye);const jA={};u&2&&(jA.$$scope={dirty:u,ctx:f}),Aw.$set(jA);const xye={};u&2&&(xye.$$scope={dirty:u,ctx:f}),yw.$set(xye);const $ye={};u&2&&($ye.$$scope={dirty:u,ctx:f}),Ow.$set($ye);const DA={};u&2&&(DA.$$scope={dirty:u,ctx:f}),Xw.$set(DA);const kye={};u&2&&(kye.$$scope={dirty:u,ctx:f}),o6.$set(kye);const Sye={};u&2&&(Sye.$$scope={dirty:u,ctx:f}),t6.$set(Sye);const GA={};u&2&&(GA.$$scope={dirty:u,ctx:f}),h6.$set(GA);const Rye={};u&2&&(Rye.$$scope={dirty:u,ctx:f}),_6.$set(Rye);const Pye={};u&2&&(Pye.$$scope={dirty:u,ctx:f}),L6.$set(Pye);const OA={};u&2&&(OA.$$scope={dirty:u,ctx:f}),x6.$set(OA);const Bye={};u&2&&(Bye.$$scope={dirty:u,ctx:f}),D6.$set(Bye);const Iye={};u&2&&(Iye.$$scope={dirty:u,ctx:f}),O6.$set(Iye);const VA={};u&2&&(VA.$$scope={dirty:u,ctx:f}),Y6.$set(VA);const Nye={};u&2&&(Nye.$$scope={dirty:u,ctx:f}),Z6.$set(Nye);const qye={};u&2&&(qye.$$scope={dirty:u,ctx:f}),iA.$set(qye);const XA={};u&2&&(XA.$$scope={dirty:u,ctx:f}),cA.$set(XA);const jye={};u&2&&(jye.$$scope={dirty:u,ctx:f}),mA.$set(jye);const Dye={};u&2&&(Dye.$$scope={dirty:u,ctx:f}),hA.$set(Dye);const zA={};u&2&&(zA.$$scope={dirty:u,ctx:f}),uA.$set(zA);const Gye={};u&2&&(Gye.$$scope={dirty:u,ctx:f}),vA.$set(Gye);const Oye={};u&2&&(Oye.$$scope={dirty:u,ctx:f}),TA.$set(Oye)},i(f){WUe||(E(d.$$.fragment,f),E(Ia.$$.fragment,f),E(QL.$$.fragment,f),E(UL.$$.fragment,f),E(Jf.$$.fragment,f),E(HL.$$.fragment,f),E(JL.$$.fragment,f),E(ZL.$$.fragment,f),E(fh.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ry.$$.fragment,f),E(ny.$$.fragment,f),E(Qh.$$.fragment,f),E(sy.$$.fragment,f),E(ly.$$.fragment,f),E(iy.$$.fragment,f),E(fy.$$.fragment,f),E(Pp.$$.fragment,f),E(Bp.$$.fragment,f),E(my.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(uy.$$.fragment,f),E(t_.$$.fragment,f),E(a_.$$.fragment,f),E(by.$$.fragment,f),E(vy.$$.fragment,f),E(Fy.$$.fragment,f),E(My.$$.fragment,f),E(l_.$$.fragment,f),E(Ey.$$.fragment,f),E(p2.$$.fragment,f),E(Cy.$$.fragment,f),E(wy.$$.fragment,f),E(Ly.$$.fragment,f),E(u2.$$.fragment,f),E(yy.$$.fragment,f),E(m1.$$.fragment,f),E(xy.$$.fragment,f),E($y.$$.fragment,f),E(Sy.$$.fragment,f),E(h1.$$.fragment,f),E(Ry.$$.fragment,f),E(r4.$$.fragment,f),E(Py.$$.fragment,f),E(By.$$.fragment,f),E(Ny.$$.fragment,f),E(a4.$$.fragment,f),E(qy.$$.fragment,f),E(X4.$$.fragment,f),E(jy.$$.fragment,f),E(Dy.$$.fragment,f),E(Oy.$$.fragment,f),E(W4.$$.fragment,f),E(Vy.$$.fragment,f),E(gb.$$.fragment,f),E(Xy.$$.fragment,f),E(zy.$$.fragment,f),E(Qy.$$.fragment,f),E(pb.$$.fragment,f),E(Uy.$$.fragment,f),E(pv.$$.fragment,f),E(Hy.$$.fragment,f),E(Jy.$$.fragment,f),E(Ky.$$.fragment,f),E(uv.$$.fragment,f),E(Zy.$$.fragment,f),E(Jv.$$.fragment,f),E(e9.$$.fragment,f),E(o9.$$.fragment,f),E(t9.$$.fragment,f),E(Kv.$$.fragment,f),E(a9.$$.fragment,f),E(s5.$$.fragment,f),E(n9.$$.fragment,f),E(s9.$$.fragment,f),E(i9.$$.fragment,f),E(i5.$$.fragment,f),E(d9.$$.fragment,f),E(Q5.$$.fragment,f),E(c9.$$.fragment,f),E(f9.$$.fragment,f),E(g9.$$.fragment,f),E(H5.$$.fragment,f),E(h9.$$.fragment,f),E(DF.$$.fragment,f),E(p9.$$.fragment,f),E(_9.$$.fragment,f),E(b9.$$.fragment,f),E(OF.$$.fragment,f),E(v9.$$.fragment,f),E(zF.$$.fragment,f),E(F9.$$.fragment,f),E(T9.$$.fragment,f),E(E9.$$.fragment,f),E(QF.$$.fragment,f),E(C9.$$.fragment,f),E(dT.$$.fragment,f),E(w9.$$.fragment,f),E(A9.$$.fragment,f),E(y9.$$.fragment,f),E(fT.$$.fragment,f),E(x9.$$.fragment,f),E(hT.$$.fragment,f),E($9.$$.fragment,f),E(k9.$$.fragment,f),E(R9.$$.fragment,f),E(_T.$$.fragment,f),E(P9.$$.fragment,f),E(vT.$$.fragment,f),E(B9.$$.fragment,f),E(I9.$$.fragment,f),E(q9.$$.fragment,f),E(TT.$$.fragment,f),E(j9.$$.fragment,f),E(CT.$$.fragment,f),E(D9.$$.fragment,f),E(G9.$$.fragment,f),E(V9.$$.fragment,f),E(AT.$$.fragment,f),E(X9.$$.fragment,f),E(NT.$$.fragment,f),E(z9.$$.fragment,f),E(W9.$$.fragment,f),E(U9.$$.fragment,f),E(jT.$$.fragment,f),E(H9.$$.fragment,f),E(WT.$$.fragment,f),E(J9.$$.fragment,f),E(Y9.$$.fragment,f),E(Z9.$$.fragment,f),E(UT.$$.fragment,f),E(ex.$$.fragment,f),E(s8.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(i8.$$.fragment,f),E(nx.$$.fragment,f),E(m8.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(h8.$$.fragment,f),E(fx.$$.fragment,f),E(T8.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(E8.$$.fragment,f),E(_x.$$.fragment,f),E(x8.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E(k8.$$.fragment,f),E(Tx.$$.fragment,f),E(B8.$$.fragment,f),E(Ex.$$.fragment,f),E(Cx.$$.fragment,f),E(Ax.$$.fragment,f),E(N8.$$.fragment,f),E(Lx.$$.fragment,f),E(D8.$$.fragment,f),E(yx.$$.fragment,f),E(xx.$$.fragment,f),E(kx.$$.fragment,f),E(O8.$$.fragment,f),E(Sx.$$.fragment,f),E(H8.$$.fragment,f),E(Rx.$$.fragment,f),E(Px.$$.fragment,f),E(Ix.$$.fragment,f),E(Y8.$$.fragment,f),E(Nx.$$.fragment,f),E(eM.$$.fragment,f),E(qx.$$.fragment,f),E(jx.$$.fragment,f),E(Gx.$$.fragment,f),E(rM.$$.fragment,f),E(Ox.$$.fragment,f),E(ZM.$$.fragment,f),E(Vx.$$.fragment,f),E(Xx.$$.fragment,f),E(Wx.$$.fragment,f),E(oE.$$.fragment,f),E(Qx.$$.fragment,f),E(wE.$$.fragment,f),E(Ux.$$.fragment,f),E(Hx.$$.fragment,f),E(Yx.$$.fragment,f),E(LE.$$.fragment,f),E(Kx.$$.fragment,f),E(GE.$$.fragment,f),E(Zx.$$.fragment,f),E(e$.$$.fragment,f),E(r$.$$.fragment,f),E(VE.$$.fragment,f),E(t$.$$.fragment,f),E(YE.$$.fragment,f),E(a$.$$.fragment,f),E(n$.$$.fragment,f),E(l$.$$.fragment,f),E(ZE.$$.fragment,f),E(i$.$$.fragment,f),E(FC.$$.fragment,f),E(d$.$$.fragment,f),E(c$.$$.fragment,f),E(m$.$$.fragment,f),E(MC.$$.fragment,f),E(g$.$$.fragment,f),E(RC.$$.fragment,f),E(h$.$$.fragment,f),E(p$.$$.fragment,f),E(u$.$$.fragment,f),E(BC.$$.fragment,f),E(b$.$$.fragment,f),E(i3.$$.fragment,f),E(v$.$$.fragment,f),E(F$.$$.fragment,f),E(M$.$$.fragment,f),E(c3.$$.fragment,f),E(E$.$$.fragment,f),E(y3.$$.fragment,f),E(C$.$$.fragment,f),E(w$.$$.fragment,f),E(L$.$$.fragment,f),E($3.$$.fragment,f),E(y$.$$.fragment,f),E(R3.$$.fragment,f),E($$.$$.fragment,f),E(k$.$$.fragment,f),E(R$.$$.fragment,f),E(B3.$$.fragment,f),E(P$.$$.fragment,f),E(N3.$$.fragment,f),E(B$.$$.fragment,f),E(I$.$$.fragment,f),E(q$.$$.fragment,f),E(j3.$$.fragment,f),E(j$.$$.fragment,f),E(s0.$$.fragment,f),E(D$.$$.fragment,f),E(G$.$$.fragment,f),E(V$.$$.fragment,f),E(i0.$$.fragment,f),E(X$.$$.fragment,f),E(x0.$$.fragment,f),E(z$.$$.fragment,f),E(W$.$$.fragment,f),E(U$.$$.fragment,f),E(k0.$$.fragment,f),E(H$.$$.fragment,f),E(R0.$$.fragment,f),E(J$.$$.fragment,f),E(Y$.$$.fragment,f),E(Z$.$$.fragment,f),E(B0.$$.fragment,f),E(ek.$$.fragment,f),E(N0.$$.fragment,f),E(ok.$$.fragment,f),E(rk.$$.fragment,f),E(ak.$$.fragment,f),E(j0.$$.fragment,f),E(nk.$$.fragment,f),E(gw.$$.fragment,f),E(sk.$$.fragment,f),E(lk.$$.fragment,f),E(dk.$$.fragment,f),E(pw.$$.fragment,f),E(ck.$$.fragment,f),E(Aw.$$.fragment,f),E(fk.$$.fragment,f),E(mk.$$.fragment,f),E(hk.$$.fragment,f),E(yw.$$.fragment,f),E(pk.$$.fragment,f),E(Ow.$$.fragment,f),E(_k.$$.fragment,f),E(uk.$$.fragment,f),E(vk.$$.fragment,f),E(Xw.$$.fragment,f),E(Fk.$$.fragment,f),E(o6.$$.fragment,f),E(Tk.$$.fragment,f),E(Mk.$$.fragment,f),E(Ck.$$.fragment,f),E(t6.$$.fragment,f),E(wk.$$.fragment,f),E(h6.$$.fragment,f),E(Ak.$$.fragment,f),E(Lk.$$.fragment,f),E(xk.$$.fragment,f),E(_6.$$.fragment,f),E($k.$$.fragment,f),E(L6.$$.fragment,f),E(kk.$$.fragment,f),E(Sk.$$.fragment,f),E(Pk.$$.fragment,f),E(x6.$$.fragment,f),E(Bk.$$.fragment,f),E(D6.$$.fragment,f),E(Ik.$$.fragment,f),E(Nk.$$.fragment,f),E(jk.$$.fragment,f),E(O6.$$.fragment,f),E(Dk.$$.fragment,f),E(Y6.$$.fragment,f),E(Gk.$$.fragment,f),E(Ok.$$.fragment,f),E(Xk.$$.fragment,f),E(Z6.$$.fragment,f),E(zk.$$.fragment,f),E(iA.$$.fragment,f),E(Wk.$$.fragment,f),E(Qk.$$.fragment,f),E(Hk.$$.fragment,f),E(cA.$$.fragment,f),E(Jk.$$.fragment,f),E(mA.$$.fragment,f),E(Yk.$$.fragment,f),E(Kk.$$.fragment,f),E(eS.$$.fragment,f),E(hA.$$.fragment,f),E(oS.$$.fragment,f),E(uA.$$.fragment,f),E(tS.$$.fragment,f),E(aS.$$.fragment,f),E(sS.$$.fragment,f),E(vA.$$.fragment,f),E(lS.$$.fragment,f),E(TA.$$.fragment,f),WUe=!0)},o(f){C(d.$$.fragment,f),C(Ia.$$.fragment,f),C(QL.$$.fragment,f),C(UL.$$.fragment,f),C(Jf.$$.fragment,f),C(HL.$$.fragment,f),C(JL.$$.fragment,f),C(ZL.$$.fragment,f),C(fh.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ry.$$.fragment,f),C(ny.$$.fragment,f),C(Qh.$$.fragment,f),C(sy.$$.fragment,f),C(ly.$$.fragment,f),C(iy.$$.fragment,f),C(fy.$$.fragment,f),C(Pp.$$.fragment,f),C(Bp.$$.fragment,f),C(my.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(uy.$$.fragment,f),C(t_.$$.fragment,f),C(a_.$$.fragment,f),C(by.$$.fragment,f),C(vy.$$.fragment,f),C(Fy.$$.fragment,f),C(My.$$.fragment,f),C(l_.$$.fragment,f),C(Ey.$$.fragment,f),C(p2.$$.fragment,f),C(Cy.$$.fragment,f),C(wy.$$.fragment,f),C(Ly.$$.fragment,f),C(u2.$$.fragment,f),C(yy.$$.fragment,f),C(m1.$$.fragment,f),C(xy.$$.fragment,f),C($y.$$.fragment,f),C(Sy.$$.fragment,f),C(h1.$$.fragment,f),C(Ry.$$.fragment,f),C(r4.$$.fragment,f),C(Py.$$.fragment,f),C(By.$$.fragment,f),C(Ny.$$.fragment,f),C(a4.$$.fragment,f),C(qy.$$.fragment,f),C(X4.$$.fragment,f),C(jy.$$.fragment,f),C(Dy.$$.fragment,f),C(Oy.$$.fragment,f),C(W4.$$.fragment,f),C(Vy.$$.fragment,f),C(gb.$$.fragment,f),C(Xy.$$.fragment,f),C(zy.$$.fragment,f),C(Qy.$$.fragment,f),C(pb.$$.fragment,f),C(Uy.$$.fragment,f),C(pv.$$.fragment,f),C(Hy.$$.fragment,f),C(Jy.$$.fragment,f),C(Ky.$$.fragment,f),C(uv.$$.fragment,f),C(Zy.$$.fragment,f),C(Jv.$$.fragment,f),C(e9.$$.fragment,f),C(o9.$$.fragment,f),C(t9.$$.fragment,f),C(Kv.$$.fragment,f),C(a9.$$.fragment,f),C(s5.$$.fragment,f),C(n9.$$.fragment,f),C(s9.$$.fragment,f),C(i9.$$.fragment,f),C(i5.$$.fragment,f),C(d9.$$.fragment,f),C(Q5.$$.fragment,f),C(c9.$$.fragment,f),C(f9.$$.fragment,f),C(g9.$$.fragment,f),C(H5.$$.fragment,f),C(h9.$$.fragment,f),C(DF.$$.fragment,f),C(p9.$$.fragment,f),C(_9.$$.fragment,f),C(b9.$$.fragment,f),C(OF.$$.fragment,f),C(v9.$$.fragment,f),C(zF.$$.fragment,f),C(F9.$$.fragment,f),C(T9.$$.fragment,f),C(E9.$$.fragment,f),C(QF.$$.fragment,f),C(C9.$$.fragment,f),C(dT.$$.fragment,f),C(w9.$$.fragment,f),C(A9.$$.fragment,f),C(y9.$$.fragment,f),C(fT.$$.fragment,f),C(x9.$$.fragment,f),C(hT.$$.fragment,f),C($9.$$.fragment,f),C(k9.$$.fragment,f),C(R9.$$.fragment,f),C(_T.$$.fragment,f),C(P9.$$.fragment,f),C(vT.$$.fragment,f),C(B9.$$.fragment,f),C(I9.$$.fragment,f),C(q9.$$.fragment,f),C(TT.$$.fragment,f),C(j9.$$.fragment,f),C(CT.$$.fragment,f),C(D9.$$.fragment,f),C(G9.$$.fragment,f),C(V9.$$.fragment,f),C(AT.$$.fragment,f),C(X9.$$.fragment,f),C(NT.$$.fragment,f),C(z9.$$.fragment,f),C(W9.$$.fragment,f),C(U9.$$.fragment,f),C(jT.$$.fragment,f),C(H9.$$.fragment,f),C(WT.$$.fragment,f),C(J9.$$.fragment,f),C(Y9.$$.fragment,f),C(Z9.$$.fragment,f),C(UT.$$.fragment,f),C(ex.$$.fragment,f),C(s8.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(i8.$$.fragment,f),C(nx.$$.fragment,f),C(m8.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(h8.$$.fragment,f),C(fx.$$.fragment,f),C(T8.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(E8.$$.fragment,f),C(_x.$$.fragment,f),C(x8.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C(k8.$$.fragment,f),C(Tx.$$.fragment,f),C(B8.$$.fragment,f),C(Ex.$$.fragment,f),C(Cx.$$.fragment,f),C(Ax.$$.fragment,f),C(N8.$$.fragment,f),C(Lx.$$.fragment,f),C(D8.$$.fragment,f),C(yx.$$.fragment,f),C(xx.$$.fragment,f),C(kx.$$.fragment,f),C(O8.$$.fragment,f),C(Sx.$$.fragment,f),C(H8.$$.fragment,f),C(Rx.$$.fragment,f),C(Px.$$.fragment,f),C(Ix.$$.fragment,f),C(Y8.$$.fragment,f),C(Nx.$$.fragment,f),C(eM.$$.fragment,f),C(qx.$$.fragment,f),C(jx.$$.fragment,f),C(Gx.$$.fragment,f),C(rM.$$.fragment,f),C(Ox.$$.fragment,f),C(ZM.$$.fragment,f),C(Vx.$$.fragment,f),C(Xx.$$.fragment,f),C(Wx.$$.fragment,f),C(oE.$$.fragment,f),C(Qx.$$.fragment,f),C(wE.$$.fragment,f),C(Ux.$$.fragment,f),C(Hx.$$.fragment,f),C(Yx.$$.fragment,f),C(LE.$$.fragment,f),C(Kx.$$.fragment,f),C(GE.$$.fragment,f),C(Zx.$$.fragment,f),C(e$.$$.fragment,f),C(r$.$$.fragment,f),C(VE.$$.fragment,f),C(t$.$$.fragment,f),C(YE.$$.fragment,f),C(a$.$$.fragment,f),C(n$.$$.fragment,f),C(l$.$$.fragment,f),C(ZE.$$.fragment,f),C(i$.$$.fragment,f),C(FC.$$.fragment,f),C(d$.$$.fragment,f),C(c$.$$.fragment,f),C(m$.$$.fragment,f),C(MC.$$.fragment,f),C(g$.$$.fragment,f),C(RC.$$.fragment,f),C(h$.$$.fragment,f),C(p$.$$.fragment,f),C(u$.$$.fragment,f),C(BC.$$.fragment,f),C(b$.$$.fragment,f),C(i3.$$.fragment,f),C(v$.$$.fragment,f),C(F$.$$.fragment,f),C(M$.$$.fragment,f),C(c3.$$.fragment,f),C(E$.$$.fragment,f),C(y3.$$.fragment,f),C(C$.$$.fragment,f),C(w$.$$.fragment,f),C(L$.$$.fragment,f),C($3.$$.fragment,f),C(y$.$$.fragment,f),C(R3.$$.fragment,f),C($$.$$.fragment,f),C(k$.$$.fragment,f),C(R$.$$.fragment,f),C(B3.$$.fragment,f),C(P$.$$.fragment,f),C(N3.$$.fragment,f),C(B$.$$.fragment,f),C(I$.$$.fragment,f),C(q$.$$.fragment,f),C(j3.$$.fragment,f),C(j$.$$.fragment,f),C(s0.$$.fragment,f),C(D$.$$.fragment,f),C(G$.$$.fragment,f),C(V$.$$.fragment,f),C(i0.$$.fragment,f),C(X$.$$.fragment,f),C(x0.$$.fragment,f),C(z$.$$.fragment,f),C(W$.$$.fragment,f),C(U$.$$.fragment,f),C(k0.$$.fragment,f),C(H$.$$.fragment,f),C(R0.$$.fragment,f),C(J$.$$.fragment,f),C(Y$.$$.fragment,f),C(Z$.$$.fragment,f),C(B0.$$.fragment,f),C(ek.$$.fragment,f),C(N0.$$.fragment,f),C(ok.$$.fragment,f),C(rk.$$.fragment,f),C(ak.$$.fragment,f),C(j0.$$.fragment,f),C(nk.$$.fragment,f),C(gw.$$.fragment,f),C(sk.$$.fragment,f),C(lk.$$.fragment,f),C(dk.$$.fragment,f),C(pw.$$.fragment,f),C(ck.$$.fragment,f),C(Aw.$$.fragment,f),C(fk.$$.fragment,f),C(mk.$$.fragment,f),C(hk.$$.fragment,f),C(yw.$$.fragment,f),C(pk.$$.fragment,f),C(Ow.$$.fragment,f),C(_k.$$.fragment,f),C(uk.$$.fragment,f),C(vk.$$.fragment,f),C(Xw.$$.fragment,f),C(Fk.$$.fragment,f),C(o6.$$.fragment,f),C(Tk.$$.fragment,f),C(Mk.$$.fragment,f),C(Ck.$$.fragment,f),C(t6.$$.fragment,f),C(wk.$$.fragment,f),C(h6.$$.fragment,f),C(Ak.$$.fragment,f),C(Lk.$$.fragment,f),C(xk.$$.fragment,f),C(_6.$$.fragment,f),C($k.$$.fragment,f),C(L6.$$.fragment,f),C(kk.$$.fragment,f),C(Sk.$$.fragment,f),C(Pk.$$.fragment,f),C(x6.$$.fragment,f),C(Bk.$$.fragment,f),C(D6.$$.fragment,f),C(Ik.$$.fragment,f),C(Nk.$$.fragment,f),C(jk.$$.fragment,f),C(O6.$$.fragment,f),C(Dk.$$.fragment,f),C(Y6.$$.fragment,f),C(Gk.$$.fragment,f),C(Ok.$$.fragment,f),C(Xk.$$.fragment,f),C(Z6.$$.fragment,f),C(zk.$$.fragment,f),C(iA.$$.fragment,f),C(Wk.$$.fragment,f),C(Qk.$$.fragment,f),C(Hk.$$.fragment,f),C(cA.$$.fragment,f),C(Jk.$$.fragment,f),C(mA.$$.fragment,f),C(Yk.$$.fragment,f),C(Kk.$$.fragment,f),C(eS.$$.fragment,f),C(hA.$$.fragment,f),C(oS.$$.fragment,f),C(uA.$$.fragment,f),C(tS.$$.fragment,f),C(aS.$$.fragment,f),C(sS.$$.fragment,f),C(vA.$$.fragment,f),C(lS.$$.fragment,f),C(TA.$$.fragment,f),WUe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(zf),f&&t(dt),f&&t(Oe),f&&t(Qe),f&&t(Qf),w(Ia,f),f&&t(Ue),f&&t(Ae),f&&t(Lo),f&&t(Na),f&&t(jWe),f&&t(Vi),w(QL),f&&t(DWe),f&&t(Xn),f&&t(GWe),w(UL,f),f&&t(OWe),f&&t(IR),f&&t(VWe),w(Jf,f),f&&t(XWe),f&&t(Xi),w(HL),f&&t(zWe),f&&t(yo),w(JL),w(ZL),w(fh),w(ey),f&&t(WWe),f&&t(Wi),w(oy),f&&t(QWe),f&&t(xo),w(ry),w(ny),w(Qh),w(sy),f&&t(UWe),f&&t(Qi),w(ly),f&&t(HWe),f&&t($o),w(iy),w(fy),w(Pp),w(Bp),w(my),f&&t(JWe),f&&t(Ui),w(gy),f&&t(YWe),f&&t(ko),w(hy),w(uy),w(t_),w(a_),w(by),f&&t(KWe),f&&t(Ji),w(vy),f&&t(ZWe),f&&t(So),w(Fy),w(My),w(l_),w(Ey),w(p2),f&&t(eQe),f&&t(Zi),w(Cy),f&&t(oQe),f&&t(Ro),w(wy),w(Ly),w(u2),w(yy),w(m1),f&&t(rQe),f&&t(rd),w(xy),f&&t(tQe),f&&t(Po),w($y),w(Sy),w(h1),w(Ry),w(r4),f&&t(aQe),f&&t(nd),w(Py),f&&t(nQe),f&&t(Bo),w(By),w(Ny),w(a4),w(qy),w(X4),f&&t(sQe),f&&t(id),w(jy),f&&t(lQe),f&&t(Io),w(Dy),w(Oy),w(W4),w(Vy),w(gb),f&&t(iQe),f&&t(fd),w(Xy),f&&t(dQe),f&&t(No),w(zy),w(Qy),w(pb),w(Uy),w(pv),f&&t(cQe),f&&t(hd),w(Hy),f&&t(fQe),f&&t(qo),w(Jy),w(Ky),w(uv),w(Zy),w(Jv),f&&t(mQe),f&&t(ud),w(e9),f&&t(gQe),f&&t(jo),w(o9),w(t9),w(Kv),w(a9),w(s5),f&&t(hQe),f&&t(Fd),w(n9),f&&t(pQe),f&&t(Go),w(s9),w(i9),w(i5),w(d9),w(Q5),f&&t(_Qe),f&&t(Ed),w(c9),f&&t(uQe),f&&t(Oo),w(f9),w(g9),w(H5),w(h9),w(DF),f&&t(bQe),f&&t(Ad),w(p9),f&&t(vQe),f&&t(Vo),w(_9),w(b9),w(OF),w(v9),w(zF),f&&t(FQe),f&&t(xd),w(F9),f&&t(TQe),f&&t(Xo),w(T9),w(E9),w(QF),w(C9),w(dT),f&&t(MQe),f&&t(Sd),w(w9),f&&t(EQe),f&&t(zo),w(A9),w(y9),w(fT),w(x9),w(hT),f&&t(CQe),f&&t(Bd),w($9),f&&t(wQe),f&&t(Wo),w(k9),w(R9),w(_T),w(P9),w(vT),f&&t(AQe),f&&t(qd),w(B9),f&&t(LQe),f&&t(Qo),w(I9),w(q9),w(TT),w(j9),w(CT),f&&t(yQe),f&&t(Gd),w(D9),f&&t(xQe),f&&t(Uo),w(G9),w(V9),w(AT),w(X9),w(NT),f&&t($Qe),f&&t(Xd),w(z9),f&&t(kQe),f&&t(Ho),w(W9),w(U9),w(jT),w(H9),w(WT),f&&t(SQe),f&&t(Qd),w(J9),f&&t(RQe),f&&t(Jo),w(Y9),w(Z9),w(UT),w(ex),w(s8),f&&t(PQe),f&&t(Jd),w(ox),f&&t(BQe),f&&t(Yo),w(rx),w(ax),w(i8),w(nx),w(m8),f&&t(IQe),f&&t(Zd),w(lx),f&&t(NQe),f&&t(Ko),w(ix),w(cx),w(h8),w(fx),w(T8),f&&t(qQe),f&&t(rc),w(mx),f&&t(jQe),f&&t(Zo),w(gx),w(px),w(E8),w(_x),w(x8),f&&t(DQe),f&&t(nc),w(ux),f&&t(GQe),f&&t(er),w(bx),w(Fx),w(k8),w(Tx),w(B8),f&&t(OQe),f&&t(ic),w(Ex),f&&t(VQe),f&&t(or),w(Cx),w(Ax),w(N8),w(Lx),w(D8),f&&t(XQe),f&&t(fc),w(yx),f&&t(zQe),f&&t(rr),w(xx),w(kx),w(O8),w(Sx),w(H8),f&&t(WQe),f&&t(hc),w(Rx),f&&t(QQe),f&&t(tr),w(Px),w(Ix),w(Y8),w(Nx),w(eM),f&&t(UQe),f&&t(uc),w(qx),f&&t(HQe),f&&t(ar),w(jx),w(Gx),w(rM),w(Ox),w(ZM),f&&t(JQe),f&&t(Fc),w(Vx),f&&t(YQe),f&&t(nr),w(Xx),w(Wx),w(oE),w(Qx),w(wE),f&&t(KQe),f&&t(Ec),w(Ux),f&&t(ZQe),f&&t(sr),w(Hx),w(Yx),w(LE),w(Kx),w(GE),f&&t(eUe),f&&t(Ac),w(Zx),f&&t(oUe),f&&t(lr),w(e$),w(r$),w(VE),w(t$),w(YE),f&&t(rUe),f&&t(xc),w(a$),f&&t(tUe),f&&t(ir),w(n$),w(l$),w(ZE),w(i$),w(FC),f&&t(aUe),f&&t(Sc),w(d$),f&&t(nUe),f&&t(dr),w(c$),w(m$),w(MC),w(g$),w(RC),f&&t(sUe),f&&t(Bc),w(h$),f&&t(lUe),f&&t(cr),w(p$),w(u$),w(BC),w(b$),w(i3),f&&t(iUe),f&&t(qc),w(v$),f&&t(dUe),f&&t(fr),w(F$),w(M$),w(c3),w(E$),w(y3),f&&t(cUe),f&&t(Gc),w(C$),f&&t(fUe),f&&t(mr),w(w$),w(L$),w($3),w(y$),w(R3),f&&t(mUe),f&&t(Xc),w($$),f&&t(gUe),f&&t(gr),w(k$),w(R$),w(B3),w(P$),w(N3),f&&t(hUe),f&&t(Qc),w(B$),f&&t(pUe),f&&t(hr),w(I$),w(q$),w(j3),w(j$),w(s0),f&&t(_Ue),f&&t(Jc),w(D$),f&&t(uUe),f&&t(pr),w(G$),w(V$),w(i0),w(X$),w(x0),f&&t(bUe),f&&t(Zc),w(z$),f&&t(vUe),f&&t(_r),w(W$),w(U$),w(k0),w(H$),w(R0),f&&t(FUe),f&&t(rf),w(J$),f&&t(TUe),f&&t(ur),w(Y$),w(Z$),w(B0),w(ek),w(N0),f&&t(MUe),f&&t(nf),w(ok),f&&t(EUe),f&&t(br),w(rk),w(ak),w(j0),w(nk),w(gw),f&&t(CUe),f&&t(df),w(sk),f&&t(wUe),f&&t(vr),w(lk),w(dk),w(pw),w(ck),w(Aw),f&&t(AUe),f&&t(mf),w(fk),f&&t(LUe),f&&t(Fr),w(mk),w(hk),w(yw),w(pk),w(Ow),f&&t(yUe),f&&t(pf),w(_k),f&&t(xUe),f&&t(Tr),w(uk),w(vk),w(Xw),w(Fk),w(o6),f&&t($Ue),f&&t(bf),w(Tk),f&&t(kUe),f&&t(Mr),w(Mk),w(Ck),w(t6),w(wk),w(h6),f&&t(SUe),f&&t(Tf),w(Ak),f&&t(RUe),f&&t(Er),w(Lk),w(xk),w(_6),w($k),w(L6),f&&t(PUe),f&&t(Cf),w(kk),f&&t(BUe),f&&t(Cr),w(Sk),w(Pk),w(x6),w(Bk),w(D6),f&&t(IUe),f&&t(Lf),w(Ik),f&&t(NUe),f&&t(wr),w(Nk),w(jk),w(O6),w(Dk),w(Y6),f&&t(qUe),f&&t($f),w(Gk),f&&t(jUe),f&&t(Ar),w(Ok),w(Xk),w(Z6),w(zk),w(iA),f&&t(DUe),f&&t(Rf),w(Wk),f&&t(GUe),f&&t(Lr),w(Qk),w(Hk),w(cA),w(Jk),w(mA),f&&t(OUe),f&&t(If),w(Yk),f&&t(VUe),f&&t(yr),w(Kk),w(eS),w(hA),w(oS),w(uA),f&&t(XUe),f&&t(jf),w(tS),f&&t(zUe),f&&t(xr),w(aS),w(sS),w(vA),w(lS),w(TA)}}}const lra={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function ira($){return aea(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class pra extends eea{constructor(g){super();oea(this,g,ira,sra,rea,{})}}export{pra as default,lra as metadata};
