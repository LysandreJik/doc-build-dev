import{S as eea,i as oea,s as rea,e as a,k as l,w as F,t as o,M as tea,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as aea,L as N}from"../../chunks/vendor-hf-doc-builder.js";import{T as cdt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as I}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function nea($){let g,v,p,m,_,d,h,Ao,Ii,zf,dt,Ni,qi,VL,Wf,Oe,Qe,ji,Dn,XL,Gn,On,zL,Di,Vn,WL,Gi,Qf,Ia;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Ao=o(`, make sure its
`),Ii=a("code"),zf=o("model_type"),dt=o(" attribute is set to the same key you use when registering the config (here "),Ni=a("code"),qi=o('"new-model"'),VL=o(")."),Wf=l(),Oe=a("p"),Qe=o("Likewise, if your "),ji=a("code"),Dn=o("NewModel"),XL=o(" is a subclass of "),Gn=a("a"),On=o("PreTrainedModel"),zL=o(`, make sure its
`),Di=a("code"),Vn=o("config_class"),WL=o(` attribute is set to the same class you use when registering the model (here
`),Gi=a("code"),Qf=o("NewModelConfig"),Ia=o(")."),this.h()},l(He){g=n(He,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var kR=s(p);m=r(kR,"NewModelConfig"),kR.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Oi=s(d);h=r(Oi,"PretrainedConfig"),Oi.forEach(t),Ao=r(Ae,`, make sure its
`),Ii=n(Ae,"CODE",{});var SR=s(Ii);zf=r(SR,"model_type"),SR.forEach(t),dt=r(Ae," attribute is set to the same key you use when registering the config (here "),Ni=n(Ae,"CODE",{});var RR=s(Ni);qi=r(RR,'"new-model"'),RR.forEach(t),VL=r(Ae,")."),Ae.forEach(t),Wf=i(He),Oe=n(He,"P",{});var Lo=s(Oe);Qe=r(Lo,"Likewise, if your "),ji=n(Lo,"CODE",{});var Na=s(ji);Dn=r(Na,"NewModel"),Na.forEach(t),XL=r(Lo," is a subclass of "),Gn=n(Lo,"A",{href:!0});var PR=s(Gn);On=r(PR,"PreTrainedModel"),PR.forEach(t),zL=r(Lo,`, make sure its
`),Di=n(Lo,"CODE",{});var Hf=s(Di);Vn=r(Hf,"config_class"),Hf.forEach(t),WL=r(Lo,` attribute is set to the same class you use when registering the model (here
`),Gi=n(Lo,"CODE",{});var BR=s(Gi);Qf=r(BR,"NewModelConfig"),BR.forEach(t),Ia=r(Lo,")."),Lo.forEach(t),this.h()},h(){c(Gn,"href","/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel")},m(He,Ae){b(He,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Ao),e(g,Ii),e(Ii,zf),e(g,dt),e(g,Ni),e(Ni,qi),e(g,VL),b(He,Wf,Ae),b(He,Oe,Ae),e(Oe,Qe),e(Oe,ji),e(ji,Dn),e(Oe,XL),e(Oe,Gn),e(Gn,On),e(Oe,zL),e(Oe,Di),e(Di,Vn),e(Oe,WL),e(Oe,Gi),e(Gi,Qf),e(Oe,Ia)},d(He){He&&t(g),He&&t(Wf),He&&t(Oe)}}}function sea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iea($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Ao=s(p);m=r(Ao,"use_auth_token=True"),Ao.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function dea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cea($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Ao=s(p);m=r(Ao,"use_auth_token=True"),Ao.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function fea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _ea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Fea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Mea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Eea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Aea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $ea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Iea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Oea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ooa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function roa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function toa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function noa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function soa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function loa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ioa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function doa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function coa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function foa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function moa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function goa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function poa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _oa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function boa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function voa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Foa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Toa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Moa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Eoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Coa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function woa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Aoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Loa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $oa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function koa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Soa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Roa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Poa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Boa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ioa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Noa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function joa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Doa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Goa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ooa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Voa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Woa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Joa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Koa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function era($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ora($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ara($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sra($){let g,v,p,m,_,d,h,Ao,Ii,zf,dt,Ni,qi,VL,Wf,Oe,Qe,ji,Dn,XL,Gn,On,zL,Di,Vn,WL,Gi,Qf,Ia,He,Ae,kR,Oi,SR,RR,Lo,Na,PR,Hf,BR,aYe,jWe,Vi,Uf,ese,QL,nYe,ose,sYe,DWe,Xn,lYe,rse,iYe,dYe,tse,cYe,fYe,GWe,HL,OWe,IR,mYe,VWe,Jf,XWe,Xi,Yf,ase,UL,gYe,nse,hYe,zWe,yo,JL,pYe,YL,_Ye,NR,uYe,bYe,vYe,KL,FYe,sse,TYe,MYe,EYe,$r,ZL,CYe,lse,wYe,AYe,zi,LYe,ise,yYe,xYe,dse,$Ye,kYe,SYe,A,Kf,cse,RYe,PYe,qR,BYe,IYe,NYe,Zf,fse,qYe,jYe,jR,DYe,GYe,OYe,em,mse,VYe,XYe,DR,zYe,WYe,QYe,om,gse,HYe,UYe,GR,JYe,YYe,KYe,rm,hse,ZYe,eKe,OR,oKe,rKe,tKe,tm,pse,aKe,nKe,VR,sKe,lKe,iKe,am,_se,dKe,cKe,XR,fKe,mKe,gKe,nm,use,hKe,pKe,zR,_Ke,uKe,bKe,sm,bse,vKe,FKe,WR,TKe,MKe,EKe,lm,vse,CKe,wKe,QR,AKe,LKe,yKe,im,Fse,xKe,$Ke,HR,kKe,SKe,RKe,dm,Tse,PKe,BKe,UR,IKe,NKe,qKe,cm,Mse,jKe,DKe,JR,GKe,OKe,VKe,fm,Ese,XKe,zKe,YR,WKe,QKe,HKe,mm,Cse,UKe,JKe,KR,YKe,KKe,ZKe,gm,wse,eZe,oZe,ZR,rZe,tZe,aZe,hm,Ase,nZe,sZe,eP,lZe,iZe,dZe,pm,Lse,cZe,fZe,oP,mZe,gZe,hZe,_m,yse,pZe,_Ze,rP,uZe,bZe,vZe,um,xse,FZe,TZe,tP,MZe,EZe,CZe,bm,$se,wZe,AZe,aP,LZe,yZe,xZe,vm,kse,$Ze,kZe,nP,SZe,RZe,PZe,Fm,Sse,BZe,IZe,sP,NZe,qZe,jZe,Tm,Rse,DZe,GZe,lP,OZe,VZe,XZe,Mm,Pse,zZe,WZe,iP,QZe,HZe,UZe,Em,Bse,JZe,YZe,dP,KZe,ZZe,eeo,Cm,Ise,oeo,reo,cP,teo,aeo,neo,wm,Nse,seo,leo,fP,ieo,deo,ceo,Am,qse,feo,meo,mP,geo,heo,peo,Lm,jse,_eo,ueo,gP,beo,veo,Feo,ym,Dse,Teo,Meo,hP,Eeo,Ceo,weo,xm,Gse,Aeo,Leo,pP,yeo,xeo,$eo,$m,Ose,keo,Seo,_P,Reo,Peo,Beo,km,Vse,Ieo,Neo,uP,qeo,jeo,Deo,Sm,Xse,Geo,Oeo,bP,Veo,Xeo,zeo,Rm,zse,Weo,Qeo,vP,Heo,Ueo,Jeo,Pm,Wse,Yeo,Keo,FP,Zeo,eoo,ooo,Bm,Qse,roo,too,TP,aoo,noo,soo,Im,Hse,loo,ioo,MP,doo,coo,foo,Nm,Use,moo,goo,EP,hoo,poo,_oo,qm,Jse,uoo,boo,CP,voo,Foo,Too,jm,Yse,Moo,Eoo,wP,Coo,woo,Aoo,Dm,Kse,Loo,yoo,AP,xoo,$oo,koo,Gm,Zse,Soo,Roo,LP,Poo,Boo,Ioo,Om,ele,Noo,qoo,yP,joo,Doo,Goo,Vm,ole,Ooo,Voo,xP,Xoo,zoo,Woo,Xm,rle,Qoo,Hoo,$P,Uoo,Joo,Yoo,zm,tle,Koo,Zoo,kP,ero,oro,rro,Wm,ale,tro,aro,SP,nro,sro,lro,Qm,nle,iro,dro,RP,cro,fro,mro,Hm,sle,gro,hro,PP,pro,_ro,uro,Um,lle,bro,vro,BP,Fro,Tro,Mro,Jm,ile,Ero,Cro,IP,wro,Aro,Lro,Ym,dle,yro,xro,NP,$ro,kro,Sro,Km,cle,Rro,Pro,qP,Bro,Iro,Nro,Zm,fle,qro,jro,jP,Dro,Gro,Oro,eg,mle,Vro,Xro,DP,zro,Wro,Qro,og,gle,Hro,Uro,GP,Jro,Yro,Kro,rg,hle,Zro,eto,OP,oto,rto,tto,tg,ple,ato,nto,VP,sto,lto,ito,ag,_le,dto,cto,XP,fto,mto,gto,ng,ule,hto,pto,zP,_to,uto,bto,sg,ble,vto,Fto,WP,Tto,Mto,Eto,lg,vle,Cto,wto,QP,Ato,Lto,yto,ig,Fle,xto,$to,HP,kto,Sto,Rto,dg,Tle,Pto,Bto,UP,Ito,Nto,qto,cg,Mle,jto,Dto,JP,Gto,Oto,Vto,fg,Ele,Xto,zto,YP,Wto,Qto,Hto,mg,Cle,Uto,Jto,KP,Yto,Kto,Zto,gg,wle,eao,oao,ZP,rao,tao,aao,hg,Ale,nao,sao,eB,lao,iao,dao,pg,Lle,cao,fao,oB,mao,gao,hao,_g,yle,pao,_ao,rB,uao,bao,vao,ug,xle,Fao,Tao,tB,Mao,Eao,Cao,bg,$le,wao,Aao,aB,Lao,yao,xao,vg,kle,$ao,kao,nB,Sao,Rao,Pao,Fg,Sle,Bao,Iao,sB,Nao,qao,jao,Tg,Rle,Dao,Gao,lB,Oao,Vao,Xao,Mg,Ple,zao,Wao,iB,Qao,Hao,Uao,Eg,Ble,Jao,Yao,dB,Kao,Zao,eno,Cg,Ile,ono,rno,cB,tno,ano,nno,wg,Nle,sno,lno,fB,ino,dno,cno,Ag,qle,fno,mno,mB,gno,hno,pno,Lg,jle,_no,uno,gB,bno,vno,Fno,yg,Dle,Tno,Mno,hB,Eno,Cno,wno,xg,Gle,Ano,Lno,pB,yno,xno,$no,$g,Ole,kno,Sno,_B,Rno,Pno,Bno,kg,Vle,Ino,Nno,uB,qno,jno,Dno,Sg,Xle,Gno,Ono,bB,Vno,Xno,zno,Rg,zle,Wno,Qno,vB,Hno,Uno,Jno,Pg,Wle,Yno,Kno,FB,Zno,eso,oso,Bg,Qle,rso,tso,TB,aso,nso,sso,Ig,Hle,lso,iso,MB,dso,cso,fso,Ng,Ule,mso,gso,EB,hso,pso,_so,qg,Jle,uso,bso,CB,vso,Fso,Tso,jg,Yle,Mso,Eso,wB,Cso,wso,Aso,Dg,Kle,Lso,yso,AB,xso,$so,kso,Gg,Zle,Sso,Rso,LB,Pso,Bso,Iso,Og,eie,Nso,qso,yB,jso,Dso,Gso,Vg,oie,Oso,Vso,xB,Xso,zso,Wso,Xg,rie,Qso,Hso,$B,Uso,Jso,Yso,zg,tie,Kso,Zso,kB,elo,olo,rlo,Wg,aie,tlo,alo,SB,nlo,slo,llo,Qg,nie,ilo,dlo,RB,clo,flo,mlo,Hg,sie,glo,hlo,PB,plo,_lo,ulo,Ug,lie,blo,vlo,BB,Flo,Tlo,Mlo,Jg,iie,Elo,Clo,IB,wlo,Alo,Llo,Yg,die,ylo,xlo,NB,$lo,klo,Slo,Kg,cie,Rlo,Plo,qB,Blo,Ilo,Nlo,Zg,fie,qlo,jlo,jB,Dlo,Glo,Olo,eh,mie,Vlo,Xlo,DB,zlo,Wlo,Qlo,oh,gie,Hlo,Ulo,GB,Jlo,Ylo,Klo,rh,hie,Zlo,eio,OB,oio,rio,tio,th,pie,aio,nio,VB,sio,lio,iio,ah,_ie,dio,cio,XB,fio,mio,gio,nh,uie,hio,pio,zB,_io,uio,bio,sh,bie,vio,Fio,WB,Tio,Mio,Eio,lh,vie,Cio,wio,QB,Aio,Lio,yio,ih,Fie,xio,$io,HB,kio,Sio,Rio,dh,Tie,Pio,Bio,UB,Iio,Nio,qio,ch,Mie,jio,Dio,JB,Gio,Oio,Vio,fh,Xio,mh,ey,zio,Eie,Wio,WWe,Wi,gh,Cie,oy,Qio,wie,Hio,QWe,xo,ry,Uio,ty,Jio,YB,Yio,Kio,Zio,ay,edo,Aie,odo,rdo,tdo,kr,ny,ado,Lie,ndo,sdo,qa,ldo,yie,ido,ddo,xie,cdo,fdo,$ie,mdo,gdo,hdo,k,zn,kie,pdo,_do,KB,udo,bdo,ZB,vdo,Fdo,Tdo,Wn,Sie,Mdo,Edo,eI,Cdo,wdo,oI,Ado,Ldo,ydo,Qn,Rie,xdo,$do,rI,kdo,Sdo,tI,Rdo,Pdo,Bdo,hh,Pie,Ido,Ndo,aI,qdo,jdo,Ddo,Hn,Bie,Gdo,Odo,nI,Vdo,Xdo,sI,zdo,Wdo,Qdo,ph,Iie,Hdo,Udo,lI,Jdo,Ydo,Kdo,_h,Nie,Zdo,eco,iI,oco,rco,tco,uh,qie,aco,nco,dI,sco,lco,ico,Un,jie,dco,cco,cI,fco,mco,fI,gco,hco,pco,Jn,Die,_co,uco,mI,bco,vco,gI,Fco,Tco,Mco,Yn,Gie,Eco,Cco,hI,wco,Aco,pI,Lco,yco,xco,bh,Oie,$co,kco,_I,Sco,Rco,Pco,vh,Vie,Bco,Ico,uI,Nco,qco,jco,Fh,Xie,Dco,Gco,bI,Oco,Vco,Xco,Kn,zie,zco,Wco,vI,Qco,Hco,FI,Uco,Jco,Yco,Th,Wie,Kco,Zco,TI,efo,ofo,rfo,Zn,Qie,tfo,afo,MI,nfo,sfo,EI,lfo,ifo,dfo,es,Hie,cfo,ffo,CI,mfo,gfo,wI,hfo,pfo,_fo,os,Uie,ufo,bfo,AI,vfo,Ffo,LI,Tfo,Mfo,Efo,rs,Jie,Cfo,wfo,yI,Afo,Lfo,xI,yfo,xfo,$fo,Mh,Yie,kfo,Sfo,$I,Rfo,Pfo,Bfo,ts,Kie,Ifo,Nfo,kI,qfo,jfo,SI,Dfo,Gfo,Ofo,as,Zie,Vfo,Xfo,RI,zfo,Wfo,PI,Qfo,Hfo,Ufo,ns,ede,Jfo,Yfo,BI,Kfo,Zfo,II,emo,omo,rmo,ss,ode,tmo,amo,NI,nmo,smo,qI,lmo,imo,dmo,ls,rde,cmo,fmo,jI,mmo,gmo,DI,hmo,pmo,_mo,is,tde,umo,bmo,GI,vmo,Fmo,OI,Tmo,Mmo,Emo,Eh,ade,Cmo,wmo,VI,Amo,Lmo,ymo,ds,nde,xmo,$mo,XI,kmo,Smo,zI,Rmo,Pmo,Bmo,Ch,sde,Imo,Nmo,WI,qmo,jmo,Dmo,cs,lde,Gmo,Omo,QI,Vmo,Xmo,HI,zmo,Wmo,Qmo,fs,ide,Hmo,Umo,UI,Jmo,Ymo,JI,Kmo,Zmo,ego,ms,dde,ogo,rgo,YI,tgo,ago,KI,ngo,sgo,lgo,wh,cde,igo,dgo,ZI,cgo,fgo,mgo,gs,fde,ggo,hgo,eN,pgo,_go,oN,ugo,bgo,vgo,hs,mde,Fgo,Tgo,rN,Mgo,Ego,tN,Cgo,wgo,Ago,ps,gde,Lgo,ygo,aN,xgo,$go,nN,kgo,Sgo,Rgo,Ah,hde,Pgo,Bgo,sN,Igo,Ngo,qgo,_s,pde,jgo,Dgo,lN,Ggo,Ogo,iN,Vgo,Xgo,zgo,us,_de,Wgo,Qgo,dN,Hgo,Ugo,cN,Jgo,Ygo,Kgo,bs,ude,Zgo,eho,fN,oho,rho,mN,tho,aho,nho,vs,bde,sho,lho,gN,iho,dho,hN,cho,fho,mho,Fs,vde,gho,hho,pN,pho,_ho,_N,uho,bho,vho,Ts,Fde,Fho,Tho,uN,Mho,Eho,bN,Cho,who,Aho,Ms,Tde,Lho,yho,vN,xho,$ho,FN,kho,Sho,Rho,Es,Mde,Pho,Bho,TN,Iho,Nho,MN,qho,jho,Dho,Lh,Ede,Gho,Oho,EN,Vho,Xho,zho,Cs,Cde,Who,Qho,CN,Hho,Uho,wN,Jho,Yho,Kho,yh,wde,Zho,epo,AN,opo,rpo,tpo,xh,Ade,apo,npo,LN,spo,lpo,ipo,ws,Lde,dpo,cpo,yN,fpo,mpo,xN,gpo,hpo,ppo,As,yde,_po,upo,$N,bpo,vpo,kN,Fpo,Tpo,Mpo,Ls,xde,Epo,Cpo,SN,wpo,Apo,RN,Lpo,ypo,xpo,$h,$de,$po,kpo,PN,Spo,Rpo,Ppo,ys,kde,Bpo,Ipo,BN,Npo,qpo,IN,jpo,Dpo,Gpo,xs,Sde,Opo,Vpo,NN,Xpo,zpo,qN,Wpo,Qpo,Hpo,$s,Rde,Upo,Jpo,jN,Ypo,Kpo,DN,Zpo,e_o,o_o,ks,Pde,r_o,t_o,GN,a_o,n_o,ON,s_o,l_o,i_o,Ss,Bde,d_o,c_o,VN,f_o,m_o,XN,g_o,h_o,p_o,Rs,Ide,__o,u_o,zN,b_o,v_o,WN,F_o,T_o,M_o,Ps,Nde,E_o,C_o,QN,w_o,A_o,HN,L_o,y_o,x_o,Bs,qde,$_o,k_o,UN,S_o,R_o,JN,P_o,B_o,I_o,kh,jde,N_o,q_o,YN,j_o,D_o,G_o,Is,Dde,O_o,V_o,KN,X_o,z_o,ZN,W_o,Q_o,H_o,Ns,Gde,U_o,J_o,eq,Y_o,K_o,oq,Z_o,euo,ouo,Sh,Ode,ruo,tuo,rq,auo,nuo,suo,Rh,Vde,luo,iuo,tq,duo,cuo,fuo,Ph,Xde,muo,guo,aq,huo,puo,_uo,Bh,zde,uuo,buo,nq,vuo,Fuo,Tuo,qs,Wde,Muo,Euo,sq,Cuo,wuo,lq,Auo,Luo,yuo,Ih,Qde,xuo,$uo,iq,kuo,Suo,Ruo,js,Hde,Puo,Buo,dq,Iuo,Nuo,cq,quo,juo,Duo,Ds,Ude,Guo,Ouo,fq,Vuo,Xuo,mq,zuo,Wuo,Quo,Gs,Jde,Huo,Uuo,gq,Juo,Yuo,hq,Kuo,Zuo,e7o,Os,Yde,o7o,r7o,pq,t7o,a7o,_q,n7o,s7o,l7o,Vs,Kde,i7o,d7o,uq,c7o,f7o,bq,m7o,g7o,h7o,Xs,Zde,p7o,_7o,vq,u7o,b7o,Fq,v7o,F7o,T7o,Nh,ece,M7o,E7o,Tq,C7o,w7o,A7o,qh,oce,L7o,y7o,Mq,x7o,$7o,k7o,zs,rce,S7o,R7o,Eq,P7o,B7o,Cq,I7o,N7o,q7o,Ws,tce,j7o,D7o,wq,G7o,O7o,Aq,V7o,X7o,z7o,Qs,ace,W7o,Q7o,Lq,H7o,U7o,yq,J7o,Y7o,K7o,jh,nce,Z7o,e1o,xq,o1o,r1o,t1o,Dh,sce,a1o,n1o,$q,s1o,l1o,i1o,Gh,lce,d1o,c1o,kq,f1o,m1o,g1o,Hs,ice,h1o,p1o,Sq,_1o,u1o,Rq,b1o,v1o,F1o,Us,dce,T1o,M1o,Pq,E1o,C1o,Bq,w1o,A1o,L1o,Oh,cce,y1o,x1o,Iq,$1o,k1o,S1o,Vh,fce,R1o,P1o,Nq,B1o,I1o,N1o,Xh,mce,q1o,j1o,qq,D1o,G1o,O1o,Js,gce,V1o,X1o,jq,z1o,W1o,Dq,Q1o,H1o,U1o,zh,hce,J1o,Y1o,Gq,K1o,Z1o,e2o,Wh,pce,o2o,r2o,Oq,t2o,a2o,n2o,Ys,_ce,s2o,l2o,Vq,i2o,d2o,Xq,c2o,f2o,m2o,Ks,uce,g2o,h2o,zq,p2o,_2o,Wq,u2o,b2o,v2o,Zs,bce,F2o,T2o,Qq,M2o,E2o,Hq,C2o,w2o,A2o,el,vce,L2o,y2o,Uq,x2o,$2o,Jq,k2o,S2o,R2o,Qh,P2o,Hh,sy,B2o,Fce,I2o,HWe,Qi,Uh,Tce,ly,N2o,Mce,q2o,UWe,$o,iy,j2o,dy,D2o,Yq,G2o,O2o,V2o,cy,X2o,Ece,z2o,W2o,Q2o,Ue,fy,H2o,Cce,U2o,J2o,ja,Y2o,wce,K2o,Z2o,Ace,ebo,obo,Lce,rbo,tbo,abo,H,Jh,yce,nbo,sbo,Kq,lbo,ibo,dbo,Yh,xce,cbo,fbo,Zq,mbo,gbo,hbo,Kh,$ce,pbo,_bo,ej,ubo,bbo,vbo,Zh,kce,Fbo,Tbo,oj,Mbo,Ebo,Cbo,ep,Sce,wbo,Abo,rj,Lbo,ybo,xbo,op,Rce,$bo,kbo,tj,Sbo,Rbo,Pbo,rp,Pce,Bbo,Ibo,aj,Nbo,qbo,jbo,tp,Bce,Dbo,Gbo,nj,Obo,Vbo,Xbo,ap,Ice,zbo,Wbo,sj,Qbo,Hbo,Ubo,np,Nce,Jbo,Ybo,lj,Kbo,Zbo,evo,sp,qce,ovo,rvo,ij,tvo,avo,nvo,lp,jce,svo,lvo,dj,ivo,dvo,cvo,ip,Dce,fvo,mvo,cj,gvo,hvo,pvo,dp,Gce,_vo,uvo,fj,bvo,vvo,Fvo,cp,Oce,Tvo,Mvo,mj,Evo,Cvo,wvo,fp,Vce,Avo,Lvo,gj,yvo,xvo,$vo,mp,Xce,kvo,Svo,hj,Rvo,Pvo,Bvo,gp,zce,Ivo,Nvo,pj,qvo,jvo,Dvo,hp,Wce,Gvo,Ovo,_j,Vvo,Xvo,zvo,pp,Qce,Wvo,Qvo,uj,Hvo,Uvo,Jvo,_p,Hce,Yvo,Kvo,bj,Zvo,eFo,oFo,up,Uce,rFo,tFo,vj,aFo,nFo,sFo,bp,Jce,lFo,iFo,Fj,dFo,cFo,fFo,vp,Yce,mFo,gFo,Tj,hFo,pFo,_Fo,Fp,Kce,uFo,bFo,Mj,vFo,FFo,TFo,Tp,Zce,MFo,EFo,Ej,CFo,wFo,AFo,Mp,efe,LFo,yFo,Cj,xFo,$Fo,kFo,Ep,ofe,SFo,RFo,wj,PFo,BFo,IFo,Cp,rfe,NFo,qFo,Aj,jFo,DFo,GFo,wp,tfe,OFo,VFo,Lj,XFo,zFo,WFo,Ap,afe,QFo,HFo,yj,UFo,JFo,YFo,Lp,nfe,KFo,ZFo,xj,eTo,oTo,rTo,yp,sfe,tTo,aTo,$j,nTo,sTo,lTo,xp,lfe,iTo,dTo,kj,cTo,fTo,mTo,$p,ife,gTo,hTo,Sj,pTo,_To,uTo,kp,dfe,bTo,vTo,Rj,FTo,TTo,MTo,Sp,cfe,ETo,CTo,Pj,wTo,ATo,LTo,Rp,yTo,Pp,xTo,Bp,my,$To,ffe,kTo,JWe,Hi,Ip,mfe,gy,STo,gfe,RTo,YWe,ko,hy,PTo,py,BTo,Bj,ITo,NTo,qTo,_y,jTo,hfe,DTo,GTo,OTo,Je,uy,VTo,pfe,XTo,zTo,Ui,WTo,_fe,QTo,HTo,ufe,UTo,JTo,YTo,fe,Np,bfe,KTo,ZTo,Ij,e9o,o9o,r9o,qp,vfe,t9o,a9o,Nj,n9o,s9o,l9o,jp,Ffe,i9o,d9o,qj,c9o,f9o,m9o,Dp,Tfe,g9o,h9o,jj,p9o,_9o,u9o,Gp,Mfe,b9o,v9o,Dj,F9o,T9o,M9o,Op,Efe,E9o,C9o,Gj,w9o,A9o,L9o,Vp,Cfe,y9o,x9o,Oj,$9o,k9o,S9o,Xp,wfe,R9o,P9o,Vj,B9o,I9o,N9o,zp,Afe,q9o,j9o,Xj,D9o,G9o,O9o,Wp,Lfe,V9o,X9o,zj,z9o,W9o,Q9o,Qp,yfe,H9o,U9o,Wj,J9o,Y9o,K9o,Hp,xfe,Z9o,eMo,Qj,oMo,rMo,tMo,Up,$fe,aMo,nMo,Hj,sMo,lMo,iMo,Jp,kfe,dMo,cMo,Uj,fMo,mMo,gMo,Yp,Sfe,hMo,pMo,Jj,_Mo,uMo,bMo,Kp,Rfe,vMo,FMo,Yj,TMo,MMo,EMo,Zp,Pfe,CMo,wMo,Kj,AMo,LMo,yMo,e_,Bfe,xMo,$Mo,Zj,kMo,SMo,RMo,o_,Ife,PMo,BMo,eD,IMo,NMo,qMo,r_,jMo,t_,DMo,a_,by,GMo,Nfe,OMo,KWe,Ji,n_,qfe,vy,VMo,jfe,XMo,ZWe,So,Fy,zMo,Yi,WMo,oD,QMo,HMo,rD,UMo,JMo,YMo,Ty,KMo,Dfe,ZMo,eEo,oEo,ct,My,rEo,Gfe,tEo,aEo,Ki,nEo,Ofe,sEo,lEo,tD,iEo,dEo,cEo,s_,fEo,Ye,Ey,mEo,Vfe,gEo,hEo,Da,pEo,Xfe,_Eo,uEo,zfe,bEo,vEo,Wfe,FEo,TEo,MEo,y,l_,Qfe,EEo,CEo,aD,wEo,AEo,LEo,i_,Hfe,yEo,xEo,nD,$Eo,kEo,SEo,d_,Ufe,REo,PEo,sD,BEo,IEo,NEo,c_,Jfe,qEo,jEo,lD,DEo,GEo,OEo,f_,Yfe,VEo,XEo,iD,zEo,WEo,QEo,m_,Kfe,HEo,UEo,dD,JEo,YEo,KEo,g_,Zfe,ZEo,e4o,cD,o4o,r4o,t4o,h_,eme,a4o,n4o,fD,s4o,l4o,i4o,p_,ome,d4o,c4o,mD,f4o,m4o,g4o,__,rme,h4o,p4o,gD,_4o,u4o,b4o,u_,tme,v4o,F4o,hD,T4o,M4o,E4o,b_,ame,C4o,w4o,pD,A4o,L4o,y4o,v_,nme,x4o,$4o,_D,k4o,S4o,R4o,F_,sme,P4o,B4o,uD,I4o,N4o,q4o,T_,lme,j4o,D4o,bD,G4o,O4o,V4o,M_,ime,X4o,z4o,vD,W4o,Q4o,H4o,E_,dme,U4o,J4o,FD,Y4o,K4o,Z4o,C_,cme,eCo,oCo,TD,rCo,tCo,aCo,w_,fme,nCo,sCo,MD,lCo,iCo,dCo,A_,mme,cCo,fCo,ED,mCo,gCo,hCo,L_,gme,pCo,_Co,CD,uCo,bCo,vCo,y_,hme,FCo,TCo,wD,MCo,ECo,CCo,x_,pme,wCo,ACo,AD,LCo,yCo,xCo,$_,_me,$Co,kCo,LD,SCo,RCo,PCo,k_,ume,BCo,ICo,yD,NCo,qCo,jCo,S_,bme,DCo,GCo,xD,OCo,VCo,XCo,R_,vme,zCo,WCo,$D,QCo,HCo,UCo,P_,Fme,JCo,YCo,kD,KCo,ZCo,e3o,B_,Tme,o3o,r3o,SD,t3o,a3o,n3o,I_,Mme,s3o,l3o,RD,i3o,d3o,c3o,N_,Eme,f3o,m3o,PD,g3o,h3o,p3o,q_,Cme,_3o,u3o,BD,b3o,v3o,F3o,j_,wme,T3o,M3o,ID,E3o,C3o,w3o,D_,Ame,A3o,L3o,ND,y3o,x3o,$3o,ol,Lme,k3o,S3o,qD,R3o,P3o,jD,B3o,I3o,N3o,G_,yme,q3o,j3o,DD,D3o,G3o,O3o,O_,xme,V3o,X3o,GD,z3o,W3o,Q3o,V_,$me,H3o,U3o,OD,J3o,Y3o,K3o,X_,kme,Z3o,e5o,VD,o5o,r5o,t5o,z_,Sme,a5o,n5o,XD,s5o,l5o,i5o,W_,Rme,d5o,c5o,zD,f5o,m5o,g5o,Q_,Pme,h5o,p5o,WD,_5o,u5o,b5o,H_,Bme,v5o,F5o,QD,T5o,M5o,E5o,U_,Ime,C5o,w5o,HD,A5o,L5o,y5o,J_,Nme,x5o,$5o,UD,k5o,S5o,R5o,Y_,qme,P5o,B5o,JD,I5o,N5o,q5o,K_,jme,j5o,D5o,YD,G5o,O5o,V5o,Z_,Dme,X5o,z5o,KD,W5o,Q5o,H5o,eu,Gme,U5o,J5o,ZD,Y5o,K5o,Z5o,ou,Ome,e0o,o0o,eG,r0o,t0o,a0o,ru,Vme,n0o,s0o,oG,l0o,i0o,d0o,tu,Xme,c0o,f0o,rG,m0o,g0o,h0o,au,zme,p0o,_0o,tG,u0o,b0o,v0o,nu,Wme,F0o,T0o,aG,M0o,E0o,C0o,su,Qme,w0o,A0o,nG,L0o,y0o,x0o,lu,Hme,$0o,k0o,sG,S0o,R0o,P0o,iu,Ume,B0o,I0o,lG,N0o,q0o,j0o,du,Jme,D0o,G0o,iG,O0o,V0o,X0o,cu,Yme,z0o,W0o,dG,Q0o,H0o,U0o,fu,Kme,J0o,Y0o,cG,K0o,Z0o,ewo,mu,Zme,owo,rwo,fG,two,awo,nwo,gu,ege,swo,lwo,mG,iwo,dwo,cwo,hu,oge,fwo,mwo,gG,gwo,hwo,pwo,pu,rge,_wo,uwo,hG,bwo,vwo,Fwo,_u,tge,Two,Mwo,pG,Ewo,Cwo,wwo,uu,age,Awo,Lwo,_G,ywo,xwo,$wo,bu,nge,kwo,Swo,uG,Rwo,Pwo,Bwo,vu,sge,Iwo,Nwo,bG,qwo,jwo,Dwo,Fu,lge,Gwo,Owo,vG,Vwo,Xwo,zwo,Tu,ige,Wwo,Qwo,FG,Hwo,Uwo,Jwo,Mu,dge,Ywo,Kwo,TG,Zwo,e6o,o6o,Eu,cge,r6o,t6o,MG,a6o,n6o,s6o,Cu,fge,l6o,i6o,EG,d6o,c6o,f6o,wu,mge,m6o,g6o,CG,h6o,p6o,_6o,Au,gge,u6o,b6o,wG,v6o,F6o,T6o,Lu,hge,M6o,E6o,AG,C6o,w6o,A6o,yu,pge,L6o,y6o,LG,x6o,$6o,k6o,xu,_ge,S6o,R6o,yG,P6o,B6o,I6o,$u,uge,N6o,q6o,xG,j6o,D6o,G6o,ku,bge,O6o,V6o,$G,X6o,z6o,W6o,Su,vge,Q6o,H6o,kG,U6o,J6o,Y6o,Ru,Fge,K6o,Z6o,SG,eAo,oAo,rAo,Pu,Tge,tAo,aAo,RG,nAo,sAo,lAo,Bu,Mge,iAo,dAo,PG,cAo,fAo,mAo,Iu,Ege,gAo,hAo,BG,pAo,_Ao,uAo,Nu,Cge,bAo,vAo,IG,FAo,TAo,MAo,qu,wge,EAo,CAo,NG,wAo,AAo,LAo,ju,Age,yAo,xAo,qG,$Ao,kAo,SAo,Du,Lge,RAo,PAo,jG,BAo,IAo,NAo,Gu,yge,qAo,jAo,DG,DAo,GAo,OAo,Ou,xge,VAo,XAo,GG,zAo,WAo,QAo,Vu,$ge,HAo,UAo,OG,JAo,YAo,KAo,Xu,kge,ZAo,eLo,VG,oLo,rLo,tLo,zu,Sge,aLo,nLo,XG,sLo,lLo,iLo,Wu,Rge,dLo,cLo,zG,fLo,mLo,gLo,Qu,Pge,hLo,pLo,WG,_Lo,uLo,bLo,Hu,Bge,vLo,FLo,QG,TLo,MLo,ELo,Uu,Ige,CLo,wLo,HG,ALo,LLo,yLo,Ju,Nge,xLo,$Lo,UG,kLo,SLo,RLo,Yu,qge,PLo,BLo,JG,ILo,NLo,qLo,Ku,jge,jLo,DLo,YG,GLo,OLo,VLo,Zu,Dge,XLo,zLo,KG,WLo,QLo,HLo,e7,Gge,ULo,JLo,ZG,YLo,KLo,ZLo,o7,Oge,eyo,oyo,eO,ryo,tyo,ayo,r7,Vge,nyo,syo,oO,lyo,iyo,dyo,t7,Xge,cyo,fyo,rO,myo,gyo,hyo,a7,zge,pyo,_yo,tO,uyo,byo,vyo,n7,Wge,Fyo,Tyo,aO,Myo,Eyo,Cyo,s7,Qge,wyo,Ayo,nO,Lyo,yyo,xyo,l7,Hge,$yo,kyo,sO,Syo,Ryo,Pyo,i7,Uge,Byo,Iyo,lO,Nyo,qyo,jyo,d7,Jge,Dyo,Gyo,iO,Oyo,Vyo,Xyo,c7,Yge,zyo,Wyo,dO,Qyo,Hyo,Uyo,f7,Kge,Jyo,Yyo,cO,Kyo,Zyo,e8o,m7,Zge,o8o,r8o,fO,t8o,a8o,n8o,g7,s8o,ehe,l8o,i8o,ohe,d8o,c8o,h7,eQe,Zi,p7,rhe,Cy,f8o,the,m8o,oQe,Ro,wy,g8o,ed,h8o,mO,p8o,_8o,gO,u8o,b8o,v8o,Ay,F8o,ahe,T8o,M8o,E8o,ft,Ly,C8o,nhe,w8o,A8o,od,L8o,she,y8o,x8o,hO,$8o,k8o,S8o,_7,R8o,Ke,yy,P8o,lhe,B8o,I8o,Ga,N8o,ihe,q8o,j8o,dhe,D8o,G8o,che,O8o,V8o,X8o,G,u7,fhe,z8o,W8o,pO,Q8o,H8o,U8o,b7,mhe,J8o,Y8o,_O,K8o,Z8o,exo,v7,ghe,oxo,rxo,uO,txo,axo,nxo,F7,hhe,sxo,lxo,bO,ixo,dxo,cxo,T7,phe,fxo,mxo,vO,gxo,hxo,pxo,M7,_he,_xo,uxo,FO,bxo,vxo,Fxo,E7,uhe,Txo,Mxo,TO,Exo,Cxo,wxo,C7,bhe,Axo,Lxo,MO,yxo,xxo,$xo,w7,vhe,kxo,Sxo,EO,Rxo,Pxo,Bxo,A7,Fhe,Ixo,Nxo,CO,qxo,jxo,Dxo,L7,The,Gxo,Oxo,wO,Vxo,Xxo,zxo,y7,Mhe,Wxo,Qxo,AO,Hxo,Uxo,Jxo,x7,Ehe,Yxo,Kxo,LO,Zxo,e$o,o$o,$7,Che,r$o,t$o,yO,a$o,n$o,s$o,k7,whe,l$o,i$o,xO,d$o,c$o,f$o,S7,Ahe,m$o,g$o,$O,h$o,p$o,_$o,R7,Lhe,u$o,b$o,kO,v$o,F$o,T$o,P7,yhe,M$o,E$o,SO,C$o,w$o,A$o,B7,xhe,L$o,y$o,RO,x$o,$$o,k$o,I7,$he,S$o,R$o,PO,P$o,B$o,I$o,N7,khe,N$o,q$o,BO,j$o,D$o,G$o,q7,She,O$o,V$o,IO,X$o,z$o,W$o,j7,Rhe,Q$o,H$o,NO,U$o,J$o,Y$o,D7,Phe,K$o,Z$o,qO,eko,oko,rko,G7,Bhe,tko,ako,jO,nko,sko,lko,O7,Ihe,iko,dko,DO,cko,fko,mko,V7,Nhe,gko,hko,GO,pko,_ko,uko,X7,qhe,bko,vko,OO,Fko,Tko,Mko,z7,jhe,Eko,Cko,VO,wko,Ako,Lko,W7,Dhe,yko,xko,XO,$ko,kko,Sko,Q7,Ghe,Rko,Pko,zO,Bko,Iko,Nko,H7,Ohe,qko,jko,WO,Dko,Gko,Oko,U7,Vhe,Vko,Xko,QO,zko,Wko,Qko,J7,Xhe,Hko,Uko,HO,Jko,Yko,Kko,Y7,zhe,Zko,eSo,UO,oSo,rSo,tSo,K7,Whe,aSo,nSo,JO,sSo,lSo,iSo,Z7,Qhe,dSo,cSo,YO,fSo,mSo,gSo,e1,Hhe,hSo,pSo,KO,_So,uSo,bSo,o1,Uhe,vSo,FSo,ZO,TSo,MSo,ESo,r1,Jhe,CSo,wSo,eV,ASo,LSo,ySo,t1,Yhe,xSo,$So,oV,kSo,SSo,RSo,a1,Khe,PSo,BSo,rV,ISo,NSo,qSo,n1,Zhe,jSo,DSo,tV,GSo,OSo,VSo,s1,epe,XSo,zSo,aV,WSo,QSo,HSo,l1,ope,USo,JSo,nV,YSo,KSo,ZSo,i1,rpe,eRo,oRo,sV,rRo,tRo,aRo,d1,tpe,nRo,sRo,lV,lRo,iRo,dRo,c1,cRo,ape,fRo,mRo,npe,gRo,hRo,f1,rQe,rd,m1,spe,xy,pRo,lpe,_Ro,tQe,Po,$y,uRo,td,bRo,iV,vRo,FRo,dV,TRo,MRo,ERo,ky,CRo,ipe,wRo,ARo,LRo,mt,Sy,yRo,dpe,xRo,$Ro,ad,kRo,cpe,SRo,RRo,cV,PRo,BRo,IRo,g1,NRo,Ze,Ry,qRo,fpe,jRo,DRo,Oa,GRo,mpe,ORo,VRo,gpe,XRo,zRo,hpe,WRo,QRo,HRo,z,h1,ppe,URo,JRo,fV,YRo,KRo,ZRo,p1,_pe,ePo,oPo,mV,rPo,tPo,aPo,_1,upe,nPo,sPo,gV,lPo,iPo,dPo,u1,bpe,cPo,fPo,hV,mPo,gPo,hPo,b1,vpe,pPo,_Po,pV,uPo,bPo,vPo,v1,Fpe,FPo,TPo,_V,MPo,EPo,CPo,F1,Tpe,wPo,APo,uV,LPo,yPo,xPo,T1,Mpe,$Po,kPo,bV,SPo,RPo,PPo,M1,Epe,BPo,IPo,vV,NPo,qPo,jPo,E1,Cpe,DPo,GPo,FV,OPo,VPo,XPo,C1,wpe,zPo,WPo,TV,QPo,HPo,UPo,w1,Ape,JPo,YPo,MV,KPo,ZPo,eBo,A1,Lpe,oBo,rBo,EV,tBo,aBo,nBo,L1,ype,sBo,lBo,CV,iBo,dBo,cBo,y1,xpe,fBo,mBo,wV,gBo,hBo,pBo,x1,$pe,_Bo,uBo,AV,bBo,vBo,FBo,$1,kpe,TBo,MBo,LV,EBo,CBo,wBo,k1,Spe,ABo,LBo,yV,yBo,xBo,$Bo,S1,Rpe,kBo,SBo,xV,RBo,PBo,BBo,R1,Ppe,IBo,NBo,$V,qBo,jBo,DBo,P1,Bpe,GBo,OBo,kV,VBo,XBo,zBo,B1,Ipe,WBo,QBo,SV,HBo,UBo,JBo,I1,Npe,YBo,KBo,RV,ZBo,eIo,oIo,N1,qpe,rIo,tIo,PV,aIo,nIo,sIo,q1,jpe,lIo,iIo,BV,dIo,cIo,fIo,j1,Dpe,mIo,gIo,IV,hIo,pIo,_Io,D1,Gpe,uIo,bIo,NV,vIo,FIo,TIo,G1,Ope,MIo,EIo,qV,CIo,wIo,AIo,O1,Vpe,LIo,yIo,jV,xIo,$Io,kIo,V1,Xpe,SIo,RIo,DV,PIo,BIo,IIo,X1,zpe,NIo,qIo,GV,jIo,DIo,GIo,z1,Wpe,OIo,VIo,OV,XIo,zIo,WIo,W1,Qpe,QIo,HIo,VV,UIo,JIo,YIo,Q1,Hpe,KIo,ZIo,XV,eNo,oNo,rNo,H1,Upe,tNo,aNo,zV,nNo,sNo,lNo,U1,Jpe,iNo,dNo,WV,cNo,fNo,mNo,J1,Ype,gNo,hNo,QV,pNo,_No,uNo,Y1,Kpe,bNo,vNo,HV,FNo,TNo,MNo,K1,Zpe,ENo,CNo,UV,wNo,ANo,LNo,Z1,e_e,yNo,xNo,JV,$No,kNo,SNo,e2,RNo,o_e,PNo,BNo,r_e,INo,NNo,o2,aQe,nd,r2,t_e,Py,qNo,a_e,jNo,nQe,Bo,By,DNo,sd,GNo,YV,ONo,VNo,KV,XNo,zNo,WNo,Iy,QNo,n_e,HNo,UNo,JNo,gt,Ny,YNo,s_e,KNo,ZNo,ld,eqo,l_e,oqo,rqo,ZV,tqo,aqo,nqo,t2,sqo,eo,qy,lqo,i_e,iqo,dqo,Va,cqo,d_e,fqo,mqo,c_e,gqo,hqo,f_e,pqo,_qo,uqo,Q,a2,m_e,bqo,vqo,eX,Fqo,Tqo,Mqo,n2,g_e,Eqo,Cqo,oX,wqo,Aqo,Lqo,s2,h_e,yqo,xqo,rX,$qo,kqo,Sqo,l2,p_e,Rqo,Pqo,tX,Bqo,Iqo,Nqo,i2,__e,qqo,jqo,aX,Dqo,Gqo,Oqo,d2,u_e,Vqo,Xqo,nX,zqo,Wqo,Qqo,c2,b_e,Hqo,Uqo,sX,Jqo,Yqo,Kqo,f2,v_e,Zqo,ejo,lX,ojo,rjo,tjo,m2,F_e,ajo,njo,iX,sjo,ljo,ijo,g2,T_e,djo,cjo,dX,fjo,mjo,gjo,h2,M_e,hjo,pjo,cX,_jo,ujo,bjo,p2,E_e,vjo,Fjo,fX,Tjo,Mjo,Ejo,_2,C_e,Cjo,wjo,mX,Ajo,Ljo,yjo,u2,w_e,xjo,$jo,gX,kjo,Sjo,Rjo,b2,A_e,Pjo,Bjo,hX,Ijo,Njo,qjo,v2,L_e,jjo,Djo,pX,Gjo,Ojo,Vjo,F2,y_e,Xjo,zjo,_X,Wjo,Qjo,Hjo,T2,x_e,Ujo,Jjo,uX,Yjo,Kjo,Zjo,M2,$_e,eDo,oDo,bX,rDo,tDo,aDo,E2,k_e,nDo,sDo,vX,lDo,iDo,dDo,C2,S_e,cDo,fDo,FX,mDo,gDo,hDo,w2,R_e,pDo,_Do,TX,uDo,bDo,vDo,A2,P_e,FDo,TDo,MX,MDo,EDo,CDo,L2,B_e,wDo,ADo,EX,LDo,yDo,xDo,y2,I_e,$Do,kDo,CX,SDo,RDo,PDo,x2,N_e,BDo,IDo,wX,NDo,qDo,jDo,$2,q_e,DDo,GDo,AX,ODo,VDo,XDo,k2,j_e,zDo,WDo,LX,QDo,HDo,UDo,S2,D_e,JDo,YDo,yX,KDo,ZDo,eGo,R2,G_e,oGo,rGo,xX,tGo,aGo,nGo,P2,O_e,sGo,lGo,$X,iGo,dGo,cGo,B2,V_e,fGo,mGo,kX,gGo,hGo,pGo,I2,X_e,_Go,uGo,SX,bGo,vGo,FGo,N2,z_e,TGo,MGo,W_e,EGo,CGo,wGo,q2,Q_e,AGo,LGo,RX,yGo,xGo,$Go,j2,H_e,kGo,SGo,PX,RGo,PGo,BGo,D2,U_e,IGo,NGo,BX,qGo,jGo,DGo,G2,J_e,GGo,OGo,IX,VGo,XGo,zGo,O2,WGo,Y_e,QGo,HGo,K_e,UGo,JGo,V2,sQe,id,X2,Z_e,jy,YGo,eue,KGo,lQe,Io,Dy,ZGo,dd,eOo,NX,oOo,rOo,qX,tOo,aOo,nOo,Gy,sOo,oue,lOo,iOo,dOo,ht,Oy,cOo,rue,fOo,mOo,cd,gOo,tue,hOo,pOo,jX,_Oo,uOo,bOo,z2,vOo,oo,Vy,FOo,aue,TOo,MOo,Xa,EOo,nue,COo,wOo,sue,AOo,LOo,lue,yOo,xOo,$Oo,me,W2,iue,kOo,SOo,DX,ROo,POo,BOo,Q2,due,IOo,NOo,GX,qOo,jOo,DOo,H2,cue,GOo,OOo,OX,VOo,XOo,zOo,U2,fue,WOo,QOo,VX,HOo,UOo,JOo,J2,mue,YOo,KOo,XX,ZOo,eVo,oVo,Y2,gue,rVo,tVo,zX,aVo,nVo,sVo,K2,hue,lVo,iVo,WX,dVo,cVo,fVo,Z2,pue,mVo,gVo,QX,hVo,pVo,_Vo,eb,_ue,uVo,bVo,HX,vVo,FVo,TVo,ob,uue,MVo,EVo,UX,CVo,wVo,AVo,rb,bue,LVo,yVo,JX,xVo,$Vo,kVo,tb,vue,SVo,RVo,YX,PVo,BVo,IVo,ab,Fue,NVo,qVo,KX,jVo,DVo,GVo,nb,Tue,OVo,VVo,ZX,XVo,zVo,WVo,sb,Mue,QVo,HVo,ez,UVo,JVo,YVo,lb,Eue,KVo,ZVo,oz,eXo,oXo,rXo,ib,Cue,tXo,aXo,rz,nXo,sXo,lXo,db,wue,iXo,dXo,tz,cXo,fXo,mXo,cb,Aue,gXo,hXo,az,pXo,_Xo,uXo,fb,bXo,Lue,vXo,FXo,yue,TXo,MXo,mb,iQe,fd,gb,xue,Xy,EXo,$ue,CXo,dQe,No,zy,wXo,md,AXo,nz,LXo,yXo,sz,xXo,$Xo,kXo,Wy,SXo,kue,RXo,PXo,BXo,pt,Qy,IXo,Sue,NXo,qXo,gd,jXo,Rue,DXo,GXo,lz,OXo,VXo,XXo,hb,zXo,ro,Hy,WXo,Pue,QXo,HXo,za,UXo,Bue,JXo,YXo,Iue,KXo,ZXo,Nue,ezo,ozo,rzo,B,pb,que,tzo,azo,iz,nzo,szo,lzo,_b,jue,izo,dzo,dz,czo,fzo,mzo,ub,Due,gzo,hzo,cz,pzo,_zo,uzo,bb,Gue,bzo,vzo,fz,Fzo,Tzo,Mzo,vb,Oue,Ezo,Czo,mz,wzo,Azo,Lzo,Fb,Vue,yzo,xzo,gz,$zo,kzo,Szo,Tb,Xue,Rzo,Pzo,hz,Bzo,Izo,Nzo,Mb,zue,qzo,jzo,pz,Dzo,Gzo,Ozo,Eb,Wue,Vzo,Xzo,_z,zzo,Wzo,Qzo,Cb,Que,Hzo,Uzo,uz,Jzo,Yzo,Kzo,wb,Hue,Zzo,eWo,bz,oWo,rWo,tWo,Ab,Uue,aWo,nWo,vz,sWo,lWo,iWo,Lb,Jue,dWo,cWo,Fz,fWo,mWo,gWo,yb,Yue,hWo,pWo,Tz,_Wo,uWo,bWo,xb,Kue,vWo,FWo,Mz,TWo,MWo,EWo,$b,Zue,CWo,wWo,Ez,AWo,LWo,yWo,kb,e7e,xWo,$Wo,Cz,kWo,SWo,RWo,Sb,o7e,PWo,BWo,wz,IWo,NWo,qWo,Rb,r7e,jWo,DWo,Az,GWo,OWo,VWo,Pb,t7e,XWo,zWo,Lz,WWo,QWo,HWo,Bb,a7e,UWo,JWo,yz,YWo,KWo,ZWo,Ib,n7e,eQo,oQo,xz,rQo,tQo,aQo,Nb,s7e,nQo,sQo,$z,lQo,iQo,dQo,qb,l7e,cQo,fQo,kz,mQo,gQo,hQo,jb,i7e,pQo,_Qo,Sz,uQo,bQo,vQo,Db,d7e,FQo,TQo,Rz,MQo,EQo,CQo,Gb,c7e,wQo,AQo,Pz,LQo,yQo,xQo,Ob,f7e,$Qo,kQo,Bz,SQo,RQo,PQo,Vb,m7e,BQo,IQo,Iz,NQo,qQo,jQo,Xb,g7e,DQo,GQo,Nz,OQo,VQo,XQo,zb,h7e,zQo,WQo,qz,QQo,HQo,UQo,Wb,p7e,JQo,YQo,jz,KQo,ZQo,eHo,Qb,_7e,oHo,rHo,Dz,tHo,aHo,nHo,Hb,u7e,sHo,lHo,Gz,iHo,dHo,cHo,Ub,b7e,fHo,mHo,Oz,gHo,hHo,pHo,Jb,v7e,_Ho,uHo,Vz,bHo,vHo,FHo,Yb,F7e,THo,MHo,Xz,EHo,CHo,wHo,Kb,T7e,AHo,LHo,zz,yHo,xHo,$Ho,Zb,M7e,kHo,SHo,Wz,RHo,PHo,BHo,ev,E7e,IHo,NHo,Qz,qHo,jHo,DHo,ov,C7e,GHo,OHo,Hz,VHo,XHo,zHo,rv,w7e,WHo,QHo,Uz,HHo,UHo,JHo,tv,A7e,YHo,KHo,Jz,ZHo,eUo,oUo,av,L7e,rUo,tUo,Yz,aUo,nUo,sUo,nv,y7e,lUo,iUo,Kz,dUo,cUo,fUo,sv,x7e,mUo,gUo,Zz,hUo,pUo,_Uo,lv,$7e,uUo,bUo,eW,vUo,FUo,TUo,iv,k7e,MUo,EUo,oW,CUo,wUo,AUo,dv,S7e,LUo,yUo,rW,xUo,$Uo,kUo,cv,R7e,SUo,RUo,tW,PUo,BUo,IUo,fv,P7e,NUo,qUo,aW,jUo,DUo,GUo,mv,B7e,OUo,VUo,nW,XUo,zUo,WUo,gv,QUo,I7e,HUo,UUo,N7e,JUo,YUo,hv,cQe,hd,pv,q7e,Uy,KUo,j7e,ZUo,fQe,qo,Jy,eJo,pd,oJo,sW,rJo,tJo,lW,aJo,nJo,sJo,Yy,lJo,D7e,iJo,dJo,cJo,_t,Ky,fJo,G7e,mJo,gJo,_d,hJo,O7e,pJo,_Jo,iW,uJo,bJo,vJo,_v,FJo,to,Zy,TJo,V7e,MJo,EJo,Wa,CJo,X7e,wJo,AJo,z7e,LJo,yJo,W7e,xJo,$Jo,kJo,Z,uv,Q7e,SJo,RJo,dW,PJo,BJo,IJo,bv,H7e,NJo,qJo,cW,jJo,DJo,GJo,vv,U7e,OJo,VJo,fW,XJo,zJo,WJo,Fv,J7e,QJo,HJo,mW,UJo,JJo,YJo,Tv,Y7e,KJo,ZJo,gW,eYo,oYo,rYo,Mv,K7e,tYo,aYo,hW,nYo,sYo,lYo,Ev,Z7e,iYo,dYo,pW,cYo,fYo,mYo,Cv,e1e,gYo,hYo,_W,pYo,_Yo,uYo,wv,o1e,bYo,vYo,uW,FYo,TYo,MYo,Av,r1e,EYo,CYo,bW,wYo,AYo,LYo,Lv,t1e,yYo,xYo,vW,$Yo,kYo,SYo,yv,a1e,RYo,PYo,FW,BYo,IYo,NYo,xv,n1e,qYo,jYo,TW,DYo,GYo,OYo,$v,s1e,VYo,XYo,MW,zYo,WYo,QYo,kv,l1e,HYo,UYo,EW,JYo,YYo,KYo,Sv,i1e,ZYo,eKo,CW,oKo,rKo,tKo,Rv,d1e,aKo,nKo,wW,sKo,lKo,iKo,Pv,c1e,dKo,cKo,AW,fKo,mKo,gKo,Bv,f1e,hKo,pKo,LW,_Ko,uKo,bKo,Iv,m1e,vKo,FKo,yW,TKo,MKo,EKo,Nv,g1e,CKo,wKo,xW,AKo,LKo,yKo,qv,h1e,xKo,$Ko,$W,kKo,SKo,RKo,jv,p1e,PKo,BKo,kW,IKo,NKo,qKo,Dv,_1e,jKo,DKo,SW,GKo,OKo,VKo,Gv,u1e,XKo,zKo,RW,WKo,QKo,HKo,Ov,b1e,UKo,JKo,PW,YKo,KKo,ZKo,Vv,v1e,eZo,oZo,BW,rZo,tZo,aZo,Xv,F1e,nZo,sZo,IW,lZo,iZo,dZo,zv,T1e,cZo,fZo,NW,mZo,gZo,hZo,Wv,M1e,pZo,_Zo,qW,uZo,bZo,vZo,Qv,E1e,FZo,TZo,jW,MZo,EZo,CZo,Hv,wZo,C1e,AZo,LZo,w1e,yZo,xZo,Uv,mQe,ud,Jv,A1e,e8,$Zo,L1e,kZo,gQe,jo,o8,SZo,bd,RZo,DW,PZo,BZo,GW,IZo,NZo,qZo,r8,jZo,y1e,DZo,GZo,OZo,ut,t8,VZo,x1e,XZo,zZo,vd,WZo,$1e,QZo,HZo,OW,UZo,JZo,YZo,Yv,KZo,ao,a8,ZZo,k1e,eer,oer,Qa,rer,S1e,ter,aer,R1e,ner,ser,P1e,ler,ier,der,Do,Kv,B1e,cer,fer,VW,mer,ger,her,Zv,I1e,per,_er,XW,uer,ber,ver,eF,N1e,Fer,Ter,zW,Mer,Eer,Cer,oF,q1e,wer,Aer,WW,Ler,yer,xer,rF,j1e,$er,ker,QW,Ser,Rer,Per,tF,D1e,Ber,Ier,HW,Ner,qer,jer,aF,Der,G1e,Ger,Oer,O1e,Ver,Xer,nF,hQe,Fd,sF,V1e,n8,zer,X1e,Wer,pQe,Go,s8,Qer,Td,Her,UW,Uer,Jer,JW,Yer,Ker,Zer,l8,eor,z1e,oor,ror,tor,bt,i8,aor,W1e,nor,sor,Md,lor,Q1e,ior,dor,YW,cor,mor,gor,lF,hor,no,d8,por,H1e,_or,uor,Ha,bor,U1e,vor,For,J1e,Tor,Mor,Y1e,Eor,Cor,wor,U,iF,K1e,Aor,Lor,KW,yor,xor,$or,dF,Z1e,kor,Sor,ZW,Ror,Por,Bor,cF,e2e,Ior,Nor,eQ,qor,jor,Dor,fF,o2e,Gor,Oor,oQ,Vor,Xor,zor,mF,r2e,Wor,Qor,rQ,Hor,Uor,Jor,gF,t2e,Yor,Kor,tQ,Zor,err,orr,hF,a2e,rrr,trr,aQ,arr,nrr,srr,pF,n2e,lrr,irr,nQ,drr,crr,frr,_F,s2e,mrr,grr,sQ,hrr,prr,_rr,uF,l2e,urr,brr,lQ,vrr,Frr,Trr,bF,i2e,Mrr,Err,iQ,Crr,wrr,Arr,vF,d2e,Lrr,yrr,dQ,xrr,$rr,krr,FF,c2e,Srr,Rrr,cQ,Prr,Brr,Irr,TF,f2e,Nrr,qrr,fQ,jrr,Drr,Grr,MF,m2e,Orr,Vrr,mQ,Xrr,zrr,Wrr,EF,g2e,Qrr,Hrr,gQ,Urr,Jrr,Yrr,CF,h2e,Krr,Zrr,hQ,etr,otr,rtr,wF,p2e,ttr,atr,pQ,ntr,str,ltr,AF,_2e,itr,dtr,_Q,ctr,ftr,mtr,LF,u2e,gtr,htr,uQ,ptr,_tr,utr,yF,b2e,btr,vtr,bQ,Ftr,Ttr,Mtr,xF,v2e,Etr,Ctr,vQ,wtr,Atr,Ltr,$F,F2e,ytr,xtr,FQ,$tr,ktr,Str,kF,T2e,Rtr,Ptr,TQ,Btr,Itr,Ntr,SF,M2e,qtr,jtr,MQ,Dtr,Gtr,Otr,RF,E2e,Vtr,Xtr,EQ,ztr,Wtr,Qtr,PF,C2e,Htr,Utr,CQ,Jtr,Ytr,Ktr,BF,w2e,Ztr,ear,wQ,oar,rar,tar,IF,A2e,aar,nar,AQ,sar,lar,iar,NF,L2e,dar,car,LQ,far,mar,gar,qF,y2e,har,par,yQ,_ar,uar,bar,jF,x2e,Far,Tar,xQ,Mar,Ear,Car,DF,$2e,war,Aar,$Q,Lar,yar,xar,GF,k2e,$ar,kar,kQ,Sar,Rar,Par,OF,S2e,Bar,Iar,SQ,Nar,qar,jar,VF,R2e,Dar,Gar,RQ,Oar,Var,Xar,XF,P2e,zar,War,PQ,Qar,Har,Uar,zF,Jar,B2e,Yar,Kar,I2e,Zar,enr,WF,_Qe,Ed,QF,N2e,c8,onr,q2e,rnr,uQe,Oo,f8,tnr,Cd,anr,BQ,nnr,snr,IQ,lnr,inr,dnr,m8,cnr,j2e,fnr,mnr,gnr,vt,g8,hnr,D2e,pnr,_nr,wd,unr,G2e,bnr,vnr,NQ,Fnr,Tnr,Mnr,HF,Enr,so,h8,Cnr,O2e,wnr,Anr,Ua,Lnr,V2e,ynr,xnr,X2e,$nr,knr,z2e,Snr,Rnr,Pnr,V,UF,W2e,Bnr,Inr,qQ,Nnr,qnr,jnr,JF,Q2e,Dnr,Gnr,jQ,Onr,Vnr,Xnr,YF,H2e,znr,Wnr,DQ,Qnr,Hnr,Unr,KF,U2e,Jnr,Ynr,GQ,Knr,Znr,esr,ZF,J2e,osr,rsr,OQ,tsr,asr,nsr,eT,Y2e,ssr,lsr,VQ,isr,dsr,csr,oT,K2e,fsr,msr,XQ,gsr,hsr,psr,rT,Z2e,_sr,usr,zQ,bsr,vsr,Fsr,tT,ebe,Tsr,Msr,WQ,Esr,Csr,wsr,aT,obe,Asr,Lsr,QQ,ysr,xsr,$sr,nT,rbe,ksr,Ssr,HQ,Rsr,Psr,Bsr,sT,tbe,Isr,Nsr,UQ,qsr,jsr,Dsr,lT,abe,Gsr,Osr,JQ,Vsr,Xsr,zsr,iT,nbe,Wsr,Qsr,YQ,Hsr,Usr,Jsr,dT,sbe,Ysr,Ksr,KQ,Zsr,elr,olr,cT,lbe,rlr,tlr,ZQ,alr,nlr,slr,fT,ibe,llr,ilr,eH,dlr,clr,flr,mT,dbe,mlr,glr,oH,hlr,plr,_lr,gT,cbe,ulr,blr,rH,vlr,Flr,Tlr,hT,fbe,Mlr,Elr,tH,Clr,wlr,Alr,pT,mbe,Llr,ylr,aH,xlr,$lr,klr,_T,gbe,Slr,Rlr,nH,Plr,Blr,Ilr,uT,hbe,Nlr,qlr,sH,jlr,Dlr,Glr,bT,pbe,Olr,Vlr,lH,Xlr,zlr,Wlr,vT,_be,Qlr,Hlr,iH,Ulr,Jlr,Ylr,FT,ube,Klr,Zlr,dH,eir,oir,rir,TT,bbe,tir,air,cH,nir,sir,lir,MT,vbe,iir,dir,fH,cir,fir,mir,ET,Fbe,gir,hir,mH,pir,_ir,uir,CT,Tbe,bir,vir,gH,Fir,Tir,Mir,wT,Mbe,Eir,Cir,hH,wir,Air,Lir,AT,Ebe,yir,xir,pH,$ir,kir,Sir,LT,Cbe,Rir,Pir,_H,Bir,Iir,Nir,yT,wbe,qir,jir,uH,Dir,Gir,Oir,xT,Abe,Vir,Xir,bH,zir,Wir,Qir,$T,Lbe,Hir,Uir,vH,Jir,Yir,Kir,kT,ybe,Zir,edr,FH,odr,rdr,tdr,ST,xbe,adr,ndr,TH,sdr,ldr,idr,RT,$be,ddr,cdr,MH,fdr,mdr,gdr,PT,kbe,hdr,pdr,EH,_dr,udr,bdr,BT,Sbe,vdr,Fdr,CH,Tdr,Mdr,Edr,IT,Rbe,Cdr,wdr,wH,Adr,Ldr,ydr,NT,Pbe,xdr,$dr,AH,kdr,Sdr,Rdr,qT,Pdr,Bbe,Bdr,Idr,Ibe,Ndr,qdr,jT,bQe,Ad,DT,Nbe,p8,jdr,qbe,Ddr,vQe,Vo,_8,Gdr,Ld,Odr,LH,Vdr,Xdr,yH,zdr,Wdr,Qdr,u8,Hdr,jbe,Udr,Jdr,Ydr,Ft,b8,Kdr,Dbe,Zdr,ecr,yd,ocr,Gbe,rcr,tcr,xH,acr,ncr,scr,GT,lcr,lo,v8,icr,Obe,dcr,ccr,Ja,fcr,Vbe,mcr,gcr,Xbe,hcr,pcr,zbe,_cr,ucr,bcr,Wbe,OT,Qbe,vcr,Fcr,$H,Tcr,Mcr,Ecr,VT,Ccr,Hbe,wcr,Acr,Ube,Lcr,ycr,XT,FQe,xd,zT,Jbe,F8,xcr,Ybe,$cr,TQe,Xo,T8,kcr,$d,Scr,kH,Rcr,Pcr,SH,Bcr,Icr,Ncr,M8,qcr,Kbe,jcr,Dcr,Gcr,Tt,E8,Ocr,Zbe,Vcr,Xcr,kd,zcr,eve,Wcr,Qcr,RH,Hcr,Ucr,Jcr,WT,Ycr,io,C8,Kcr,ove,Zcr,efr,Ya,ofr,rve,rfr,tfr,tve,afr,nfr,ave,sfr,lfr,ifr,be,QT,nve,dfr,cfr,PH,ffr,mfr,gfr,HT,sve,hfr,pfr,BH,_fr,ufr,bfr,UT,lve,vfr,Ffr,IH,Tfr,Mfr,Efr,JT,ive,Cfr,wfr,NH,Afr,Lfr,yfr,rl,dve,xfr,$fr,qH,kfr,Sfr,jH,Rfr,Pfr,Bfr,YT,cve,Ifr,Nfr,DH,qfr,jfr,Dfr,tl,fve,Gfr,Ofr,GH,Vfr,Xfr,OH,zfr,Wfr,Qfr,KT,mve,Hfr,Ufr,VH,Jfr,Yfr,Kfr,Mt,gve,Zfr,emr,XH,omr,rmr,zH,tmr,amr,WH,nmr,smr,lmr,ZT,hve,imr,dmr,QH,cmr,fmr,mmr,e9,pve,gmr,hmr,HH,pmr,_mr,umr,o9,_ve,bmr,vmr,UH,Fmr,Tmr,Mmr,r9,uve,Emr,Cmr,JH,wmr,Amr,Lmr,t9,bve,ymr,xmr,YH,$mr,kmr,Smr,a9,vve,Rmr,Pmr,KH,Bmr,Imr,Nmr,n9,Fve,qmr,jmr,ZH,Dmr,Gmr,Omr,s9,Tve,Vmr,Xmr,eU,zmr,Wmr,Qmr,l9,Hmr,Mve,Umr,Jmr,Eve,Ymr,Kmr,i9,MQe,Sd,d9,Cve,w8,Zmr,wve,egr,EQe,zo,A8,ogr,Rd,rgr,oU,tgr,agr,rU,ngr,sgr,lgr,L8,igr,Ave,dgr,cgr,fgr,Et,y8,mgr,Lve,ggr,hgr,Pd,pgr,yve,_gr,ugr,tU,bgr,vgr,Fgr,c9,Tgr,co,x8,Mgr,xve,Egr,Cgr,Ka,wgr,$ve,Agr,Lgr,kve,ygr,xgr,Sve,$gr,kgr,Sgr,Rve,f9,Pve,Rgr,Pgr,aU,Bgr,Igr,Ngr,m9,qgr,Bve,jgr,Dgr,Ive,Ggr,Ogr,g9,CQe,Bd,h9,Nve,$8,Vgr,qve,Xgr,wQe,Wo,k8,zgr,Id,Wgr,nU,Qgr,Hgr,sU,Ugr,Jgr,Ygr,S8,Kgr,jve,Zgr,ehr,ohr,Ct,R8,rhr,Dve,thr,ahr,Nd,nhr,Gve,shr,lhr,lU,ihr,dhr,chr,p9,fhr,fo,P8,mhr,Ove,ghr,hhr,Za,phr,Vve,_hr,uhr,Xve,bhr,vhr,zve,Fhr,Thr,Mhr,Wve,_9,Qve,Ehr,Chr,iU,whr,Ahr,Lhr,u9,yhr,Hve,xhr,$hr,Uve,khr,Shr,b9,AQe,qd,v9,Jve,B8,Rhr,Yve,Phr,LQe,Qo,I8,Bhr,jd,Ihr,dU,Nhr,qhr,cU,jhr,Dhr,Ghr,N8,Ohr,Kve,Vhr,Xhr,zhr,wt,q8,Whr,Zve,Qhr,Hhr,Dd,Uhr,eFe,Jhr,Yhr,fU,Khr,Zhr,epr,F9,opr,mo,j8,rpr,oFe,tpr,apr,en,npr,rFe,spr,lpr,tFe,ipr,dpr,aFe,cpr,fpr,mpr,nFe,T9,sFe,gpr,hpr,mU,ppr,_pr,upr,M9,bpr,lFe,vpr,Fpr,iFe,Tpr,Mpr,E9,yQe,Gd,C9,dFe,D8,Epr,cFe,Cpr,xQe,Ho,G8,wpr,Od,Apr,gU,Lpr,ypr,hU,xpr,$pr,kpr,O8,Spr,fFe,Rpr,Ppr,Bpr,At,V8,Ipr,mFe,Npr,qpr,Vd,jpr,gFe,Dpr,Gpr,pU,Opr,Vpr,Xpr,w9,zpr,go,X8,Wpr,hFe,Qpr,Hpr,on,Upr,pFe,Jpr,Ypr,_Fe,Kpr,Zpr,uFe,e_r,o_r,r_r,Pe,A9,bFe,t_r,a_r,_U,n_r,s_r,l_r,L9,vFe,i_r,d_r,uU,c_r,f_r,m_r,y9,FFe,g_r,h_r,bU,p_r,__r,u_r,x9,TFe,b_r,v_r,vU,F_r,T_r,M_r,$9,MFe,E_r,C_r,FU,w_r,A_r,L_r,k9,EFe,y_r,x_r,TU,$_r,k_r,S_r,S9,CFe,R_r,P_r,MU,B_r,I_r,N_r,R9,wFe,q_r,j_r,EU,D_r,G_r,O_r,P9,AFe,V_r,X_r,CU,z_r,W_r,Q_r,B9,H_r,LFe,U_r,J_r,yFe,Y_r,K_r,I9,$Qe,Xd,N9,xFe,z8,Z_r,$Fe,eur,kQe,Uo,W8,our,zd,rur,wU,tur,aur,AU,nur,sur,lur,Q8,iur,kFe,dur,cur,fur,Lt,H8,mur,SFe,gur,hur,Wd,pur,RFe,_ur,uur,LU,bur,vur,Fur,q9,Tur,ho,U8,Mur,PFe,Eur,Cur,rn,wur,BFe,Aur,Lur,IFe,yur,xur,NFe,$ur,kur,Sur,at,j9,qFe,Rur,Pur,yU,Bur,Iur,Nur,D9,jFe,qur,jur,xU,Dur,Gur,Our,G9,DFe,Vur,Xur,$U,zur,Wur,Qur,O9,GFe,Hur,Uur,kU,Jur,Yur,Kur,V9,OFe,Zur,e7r,SU,o7r,r7r,t7r,X9,a7r,VFe,n7r,s7r,XFe,l7r,i7r,z9,SQe,Qd,W9,zFe,J8,d7r,WFe,c7r,RQe,Jo,Y8,f7r,Hd,m7r,RU,g7r,h7r,PU,p7r,_7r,u7r,K8,b7r,QFe,v7r,F7r,T7r,yt,Z8,M7r,HFe,E7r,C7r,Ud,w7r,UFe,A7r,L7r,BU,y7r,x7r,$7r,Q9,k7r,po,ex,S7r,JFe,R7r,P7r,tn,B7r,YFe,I7r,N7r,KFe,q7r,j7r,ZFe,D7r,G7r,O7r,Le,H9,eTe,V7r,X7r,IU,z7r,W7r,Q7r,U9,oTe,H7r,U7r,NU,J7r,Y7r,K7r,J9,rTe,Z7r,e1r,qU,o1r,r1r,t1r,Y9,tTe,a1r,n1r,jU,s1r,l1r,i1r,K9,aTe,d1r,c1r,DU,f1r,m1r,g1r,Z9,nTe,h1r,p1r,GU,_1r,u1r,b1r,eM,sTe,v1r,F1r,OU,T1r,M1r,E1r,oM,lTe,C1r,w1r,VU,A1r,L1r,y1r,rM,iTe,x1r,$1r,XU,k1r,S1r,R1r,tM,dTe,P1r,B1r,zU,I1r,N1r,q1r,aM,j1r,cTe,D1r,G1r,fTe,O1r,V1r,nM,PQe,Jd,sM,mTe,ox,X1r,gTe,z1r,BQe,Yo,rx,W1r,Yd,Q1r,WU,H1r,U1r,QU,J1r,Y1r,K1r,tx,Z1r,hTe,e2r,o2r,r2r,xt,ax,t2r,pTe,a2r,n2r,Kd,s2r,_Te,l2r,i2r,HU,d2r,c2r,f2r,lM,m2r,_o,nx,g2r,uTe,h2r,p2r,an,_2r,bTe,u2r,b2r,vTe,v2r,F2r,FTe,T2r,M2r,E2r,sx,iM,TTe,C2r,w2r,UU,A2r,L2r,y2r,dM,MTe,x2r,$2r,JU,k2r,S2r,R2r,cM,P2r,ETe,B2r,I2r,CTe,N2r,q2r,fM,IQe,Zd,mM,wTe,lx,j2r,ATe,D2r,NQe,Ko,ix,G2r,ec,O2r,YU,V2r,X2r,KU,z2r,W2r,Q2r,dx,H2r,LTe,U2r,J2r,Y2r,$t,cx,K2r,yTe,Z2r,ebr,oc,obr,xTe,rbr,tbr,ZU,abr,nbr,sbr,gM,lbr,uo,fx,ibr,$Te,dbr,cbr,nn,fbr,kTe,mbr,gbr,STe,hbr,pbr,RTe,_br,ubr,bbr,nt,hM,PTe,vbr,Fbr,eJ,Tbr,Mbr,Ebr,pM,BTe,Cbr,wbr,oJ,Abr,Lbr,ybr,_M,ITe,xbr,$br,rJ,kbr,Sbr,Rbr,uM,NTe,Pbr,Bbr,tJ,Ibr,Nbr,qbr,bM,qTe,jbr,Dbr,aJ,Gbr,Obr,Vbr,vM,Xbr,jTe,zbr,Wbr,DTe,Qbr,Hbr,FM,qQe,rc,TM,GTe,mx,Ubr,OTe,Jbr,jQe,Zo,gx,Ybr,tc,Kbr,nJ,Zbr,evr,sJ,ovr,rvr,tvr,hx,avr,VTe,nvr,svr,lvr,kt,px,ivr,XTe,dvr,cvr,ac,fvr,zTe,mvr,gvr,lJ,hvr,pvr,_vr,MM,uvr,bo,_x,bvr,WTe,vvr,Fvr,sn,Tvr,QTe,Mvr,Evr,HTe,Cvr,wvr,UTe,Avr,Lvr,yvr,ln,EM,JTe,xvr,$vr,iJ,kvr,Svr,Rvr,CM,YTe,Pvr,Bvr,dJ,Ivr,Nvr,qvr,wM,KTe,jvr,Dvr,cJ,Gvr,Ovr,Vvr,AM,ZTe,Xvr,zvr,fJ,Wvr,Qvr,Hvr,LM,Uvr,e9e,Jvr,Yvr,o9e,Kvr,Zvr,yM,DQe,nc,xM,r9e,ux,eFr,t9e,oFr,GQe,er,bx,rFr,sc,tFr,mJ,aFr,nFr,gJ,sFr,lFr,iFr,vx,dFr,a9e,cFr,fFr,mFr,St,Fx,gFr,n9e,hFr,pFr,lc,_Fr,s9e,uFr,bFr,hJ,vFr,FFr,TFr,$M,MFr,vo,Tx,EFr,l9e,CFr,wFr,dn,AFr,i9e,LFr,yFr,d9e,xFr,$Fr,c9e,kFr,SFr,RFr,Mx,kM,f9e,PFr,BFr,pJ,IFr,NFr,qFr,SM,m9e,jFr,DFr,_J,GFr,OFr,VFr,RM,XFr,g9e,zFr,WFr,h9e,QFr,HFr,PM,OQe,ic,BM,p9e,Ex,UFr,_9e,JFr,VQe,or,Cx,YFr,dc,KFr,uJ,ZFr,eTr,bJ,oTr,rTr,tTr,wx,aTr,u9e,nTr,sTr,lTr,Rt,Ax,iTr,b9e,dTr,cTr,cc,fTr,v9e,mTr,gTr,vJ,hTr,pTr,_Tr,IM,uTr,Fo,Lx,bTr,F9e,vTr,FTr,cn,TTr,T9e,MTr,ETr,M9e,CTr,wTr,E9e,ATr,LTr,yTr,C9e,NM,w9e,xTr,$Tr,FJ,kTr,STr,RTr,qM,PTr,A9e,BTr,ITr,L9e,NTr,qTr,jM,XQe,fc,DM,y9e,yx,jTr,x9e,DTr,zQe,rr,xx,GTr,mc,OTr,TJ,VTr,XTr,MJ,zTr,WTr,QTr,$x,HTr,$9e,UTr,JTr,YTr,Pt,kx,KTr,k9e,ZTr,e9r,gc,o9r,S9e,r9r,t9r,EJ,a9r,n9r,s9r,GM,l9r,To,Sx,i9r,R9e,d9r,c9r,fn,f9r,P9e,m9r,g9r,B9e,h9r,p9r,I9e,_9r,u9r,b9r,st,OM,N9e,v9r,F9r,CJ,T9r,M9r,E9r,VM,q9e,C9r,w9r,wJ,A9r,L9r,y9r,XM,j9e,x9r,$9r,AJ,k9r,S9r,R9r,zM,D9e,P9r,B9r,LJ,I9r,N9r,q9r,WM,G9e,j9r,D9r,yJ,G9r,O9r,V9r,QM,X9r,O9e,z9r,W9r,V9e,Q9r,H9r,HM,WQe,hc,UM,X9e,Rx,U9r,z9e,J9r,QQe,tr,Px,Y9r,pc,K9r,xJ,Z9r,eMr,$J,oMr,rMr,tMr,Bx,aMr,W9e,nMr,sMr,lMr,Bt,Ix,iMr,Q9e,dMr,cMr,_c,fMr,H9e,mMr,gMr,kJ,hMr,pMr,_Mr,JM,uMr,Mo,Nx,bMr,U9e,vMr,FMr,mn,TMr,J9e,MMr,EMr,Y9e,CMr,wMr,K9e,AMr,LMr,yMr,Z9e,YM,eMe,xMr,$Mr,SJ,kMr,SMr,RMr,KM,PMr,oMe,BMr,IMr,rMe,NMr,qMr,ZM,HQe,uc,eE,tMe,qx,jMr,aMe,DMr,UQe,ar,jx,GMr,bc,OMr,RJ,VMr,XMr,PJ,zMr,WMr,QMr,Dx,HMr,nMe,UMr,JMr,YMr,It,Gx,KMr,sMe,ZMr,eEr,vc,oEr,lMe,rEr,tEr,BJ,aEr,nEr,sEr,oE,lEr,Sr,Ox,iEr,iMe,dEr,cEr,gn,fEr,dMe,mEr,gEr,cMe,hEr,pEr,fMe,_Er,uEr,bEr,q,rE,mMe,vEr,FEr,IJ,TEr,MEr,EEr,tE,gMe,CEr,wEr,NJ,AEr,LEr,yEr,aE,hMe,xEr,$Er,qJ,kEr,SEr,REr,nE,pMe,PEr,BEr,jJ,IEr,NEr,qEr,sE,_Me,jEr,DEr,DJ,GEr,OEr,VEr,lE,uMe,XEr,zEr,GJ,WEr,QEr,HEr,iE,bMe,UEr,JEr,OJ,YEr,KEr,ZEr,dE,vMe,e4r,o4r,VJ,r4r,t4r,a4r,cE,FMe,n4r,s4r,XJ,l4r,i4r,d4r,fE,TMe,c4r,f4r,zJ,m4r,g4r,h4r,mE,MMe,p4r,_4r,WJ,u4r,b4r,v4r,gE,EMe,F4r,T4r,QJ,M4r,E4r,C4r,hE,CMe,w4r,A4r,HJ,L4r,y4r,x4r,pE,wMe,$4r,k4r,UJ,S4r,R4r,P4r,_E,AMe,B4r,I4r,JJ,N4r,q4r,j4r,uE,LMe,D4r,G4r,YJ,O4r,V4r,X4r,bE,yMe,z4r,W4r,KJ,Q4r,H4r,U4r,vE,xMe,J4r,Y4r,ZJ,K4r,Z4r,eCr,al,$Me,oCr,rCr,eY,tCr,aCr,oY,nCr,sCr,lCr,FE,kMe,iCr,dCr,rY,cCr,fCr,mCr,TE,SMe,gCr,hCr,tY,pCr,_Cr,uCr,ME,RMe,bCr,vCr,aY,FCr,TCr,MCr,EE,PMe,ECr,CCr,nY,wCr,ACr,LCr,CE,BMe,yCr,xCr,sY,$Cr,kCr,SCr,wE,IMe,RCr,PCr,lY,BCr,ICr,NCr,AE,NMe,qCr,jCr,iY,DCr,GCr,OCr,LE,qMe,VCr,XCr,dY,zCr,WCr,QCr,yE,jMe,HCr,UCr,cY,JCr,YCr,KCr,xE,DMe,ZCr,e3r,fY,o3r,r3r,t3r,$E,GMe,a3r,n3r,mY,s3r,l3r,i3r,kE,OMe,d3r,c3r,gY,f3r,m3r,g3r,SE,VMe,h3r,p3r,hY,_3r,u3r,b3r,RE,XMe,v3r,F3r,pY,T3r,M3r,E3r,PE,zMe,C3r,w3r,_Y,A3r,L3r,y3r,BE,WMe,x3r,$3r,uY,k3r,S3r,R3r,IE,QMe,P3r,B3r,bY,I3r,N3r,q3r,NE,HMe,j3r,D3r,vY,G3r,O3r,V3r,qE,UMe,X3r,z3r,FY,W3r,Q3r,H3r,jE,JMe,U3r,J3r,TY,Y3r,K3r,Z3r,DE,YMe,e5r,o5r,MY,r5r,t5r,a5r,GE,KMe,n5r,s5r,EY,l5r,i5r,d5r,OE,ZMe,c5r,f5r,CY,m5r,g5r,h5r,VE,eEe,p5r,_5r,wY,u5r,b5r,v5r,XE,oEe,F5r,T5r,AY,M5r,E5r,C5r,zE,rEe,w5r,A5r,LY,L5r,y5r,x5r,WE,tEe,$5r,k5r,yY,S5r,R5r,P5r,QE,aEe,B5r,I5r,xY,N5r,q5r,j5r,HE,nEe,D5r,G5r,$Y,O5r,V5r,X5r,UE,sEe,z5r,W5r,kY,Q5r,H5r,U5r,JE,lEe,J5r,Y5r,SY,K5r,Z5r,e0r,YE,iEe,o0r,r0r,RY,t0r,a0r,n0r,KE,JQe,Fc,ZE,dEe,Vx,s0r,cEe,l0r,YQe,nr,Xx,i0r,Tc,d0r,PY,c0r,f0r,BY,m0r,g0r,h0r,zx,p0r,fEe,_0r,u0r,b0r,Nt,Wx,v0r,mEe,F0r,T0r,Mc,M0r,gEe,E0r,C0r,IY,w0r,A0r,L0r,e4,y0r,Rr,Qx,x0r,hEe,$0r,k0r,hn,S0r,pEe,R0r,P0r,_Ee,B0r,I0r,uEe,N0r,q0r,j0r,se,o4,bEe,D0r,G0r,NY,O0r,V0r,X0r,r4,vEe,z0r,W0r,qY,Q0r,H0r,U0r,t4,FEe,J0r,Y0r,jY,K0r,Z0r,ewr,a4,TEe,owr,rwr,DY,twr,awr,nwr,n4,MEe,swr,lwr,GY,iwr,dwr,cwr,s4,EEe,fwr,mwr,OY,gwr,hwr,pwr,l4,CEe,_wr,uwr,VY,bwr,vwr,Fwr,i4,wEe,Twr,Mwr,XY,Ewr,Cwr,wwr,d4,AEe,Awr,Lwr,zY,ywr,xwr,$wr,c4,LEe,kwr,Swr,WY,Rwr,Pwr,Bwr,f4,yEe,Iwr,Nwr,QY,qwr,jwr,Dwr,m4,xEe,Gwr,Owr,HY,Vwr,Xwr,zwr,g4,$Ee,Wwr,Qwr,UY,Hwr,Uwr,Jwr,h4,kEe,Ywr,Kwr,JY,Zwr,e6r,o6r,p4,SEe,r6r,t6r,YY,a6r,n6r,s6r,_4,REe,l6r,i6r,KY,d6r,c6r,f6r,u4,PEe,m6r,g6r,ZY,h6r,p6r,_6r,b4,BEe,u6r,b6r,eK,v6r,F6r,T6r,v4,IEe,M6r,E6r,oK,C6r,w6r,A6r,F4,NEe,L6r,y6r,rK,x6r,$6r,k6r,T4,qEe,S6r,R6r,tK,P6r,B6r,I6r,M4,jEe,N6r,q6r,aK,j6r,D6r,G6r,E4,DEe,O6r,V6r,nK,X6r,z6r,W6r,C4,KQe,Ec,w4,GEe,Hx,Q6r,OEe,H6r,ZQe,sr,Ux,U6r,Cc,J6r,sK,Y6r,K6r,lK,Z6r,eAr,oAr,Jx,rAr,VEe,tAr,aAr,nAr,qt,Yx,sAr,XEe,lAr,iAr,wc,dAr,zEe,cAr,fAr,iK,mAr,gAr,hAr,A4,pAr,Pr,Kx,_Ar,WEe,uAr,bAr,pn,vAr,QEe,FAr,TAr,HEe,MAr,EAr,UEe,CAr,wAr,AAr,Me,L4,JEe,LAr,yAr,dK,xAr,$Ar,kAr,y4,YEe,SAr,RAr,cK,PAr,BAr,IAr,x4,KEe,NAr,qAr,fK,jAr,DAr,GAr,$4,ZEe,OAr,VAr,mK,XAr,zAr,WAr,k4,e4e,QAr,HAr,gK,UAr,JAr,YAr,S4,o4e,KAr,ZAr,hK,eLr,oLr,rLr,R4,r4e,tLr,aLr,pK,nLr,sLr,lLr,P4,t4e,iLr,dLr,_K,cLr,fLr,mLr,B4,a4e,gLr,hLr,uK,pLr,_Lr,uLr,I4,n4e,bLr,vLr,bK,FLr,TLr,MLr,N4,s4e,ELr,CLr,vK,wLr,ALr,LLr,q4,l4e,yLr,xLr,FK,$Lr,kLr,SLr,j4,i4e,RLr,PLr,TK,BLr,ILr,NLr,D4,eHe,Ac,G4,d4e,Zx,qLr,c4e,jLr,oHe,lr,e$,DLr,Lc,GLr,MK,OLr,VLr,EK,XLr,zLr,WLr,o$,QLr,f4e,HLr,ULr,JLr,jt,r$,YLr,m4e,KLr,ZLr,yc,eyr,g4e,oyr,ryr,CK,tyr,ayr,nyr,O4,syr,Br,t$,lyr,h4e,iyr,dyr,_n,cyr,p4e,fyr,myr,_4e,gyr,hyr,u4e,pyr,_yr,uyr,Ve,V4,b4e,byr,vyr,wK,Fyr,Tyr,Myr,X4,v4e,Eyr,Cyr,AK,wyr,Ayr,Lyr,nl,F4e,yyr,xyr,LK,$yr,kyr,yK,Syr,Ryr,Pyr,z4,T4e,Byr,Iyr,xK,Nyr,qyr,jyr,W4,M4e,Dyr,Gyr,$K,Oyr,Vyr,Xyr,Q4,E4e,zyr,Wyr,kK,Qyr,Hyr,Uyr,H4,C4e,Jyr,Yyr,SK,Kyr,Zyr,e8r,U4,w4e,o8r,r8r,RK,t8r,a8r,n8r,J4,rHe,xc,Y4,A4e,a$,s8r,L4e,l8r,tHe,ir,n$,i8r,$c,d8r,PK,c8r,f8r,BK,m8r,g8r,h8r,s$,p8r,y4e,_8r,u8r,b8r,Dt,l$,v8r,x4e,F8r,T8r,kc,M8r,$4e,E8r,C8r,IK,w8r,A8r,L8r,K4,y8r,Ir,i$,x8r,k4e,$8r,k8r,un,S8r,S4e,R8r,P8r,R4e,B8r,I8r,P4e,N8r,q8r,j8r,ie,Z4,B4e,D8r,G8r,NK,O8r,V8r,X8r,eC,I4e,z8r,W8r,qK,Q8r,H8r,U8r,oC,N4e,J8r,Y8r,jK,K8r,Z8r,exr,rC,q4e,oxr,rxr,DK,txr,axr,nxr,tC,j4e,sxr,lxr,GK,ixr,dxr,cxr,aC,D4e,fxr,mxr,OK,gxr,hxr,pxr,nC,G4e,_xr,uxr,VK,bxr,vxr,Fxr,sC,O4e,Txr,Mxr,XK,Exr,Cxr,wxr,lC,V4e,Axr,Lxr,zK,yxr,xxr,$xr,iC,X4e,kxr,Sxr,WK,Rxr,Pxr,Bxr,dC,z4e,Ixr,Nxr,QK,qxr,jxr,Dxr,cC,W4e,Gxr,Oxr,HK,Vxr,Xxr,zxr,fC,Q4e,Wxr,Qxr,UK,Hxr,Uxr,Jxr,mC,H4e,Yxr,Kxr,JK,Zxr,e$r,o$r,gC,U4e,r$r,t$r,YK,a$r,n$r,s$r,hC,J4e,l$r,i$r,KK,d$r,c$r,f$r,pC,Y4e,m$r,g$r,ZK,h$r,p$r,_$r,_C,K4e,u$r,b$r,eZ,v$r,F$r,T$r,uC,Z4e,M$r,E$r,oZ,C$r,w$r,A$r,bC,eCe,L$r,y$r,rZ,x$r,$$r,k$r,vC,aHe,Sc,FC,oCe,d$,S$r,rCe,R$r,nHe,dr,c$,P$r,Rc,B$r,tZ,I$r,N$r,aZ,q$r,j$r,D$r,f$,G$r,tCe,O$r,V$r,X$r,Gt,m$,z$r,aCe,W$r,Q$r,Pc,H$r,nCe,U$r,J$r,nZ,Y$r,K$r,Z$r,TC,ekr,Nr,g$,okr,sCe,rkr,tkr,bn,akr,lCe,nkr,skr,iCe,lkr,ikr,dCe,dkr,ckr,fkr,ye,MC,cCe,mkr,gkr,sZ,hkr,pkr,_kr,EC,fCe,ukr,bkr,lZ,vkr,Fkr,Tkr,CC,mCe,Mkr,Ekr,iZ,Ckr,wkr,Akr,wC,gCe,Lkr,ykr,dZ,xkr,$kr,kkr,AC,hCe,Skr,Rkr,cZ,Pkr,Bkr,Ikr,LC,pCe,Nkr,qkr,fZ,jkr,Dkr,Gkr,yC,_Ce,Okr,Vkr,mZ,Xkr,zkr,Wkr,xC,uCe,Qkr,Hkr,gZ,Ukr,Jkr,Ykr,$C,bCe,Kkr,Zkr,hZ,eSr,oSr,rSr,kC,vCe,tSr,aSr,pZ,nSr,sSr,lSr,SC,sHe,Bc,RC,FCe,h$,iSr,TCe,dSr,lHe,cr,p$,cSr,Ic,fSr,_Z,mSr,gSr,uZ,hSr,pSr,_Sr,_$,uSr,MCe,bSr,vSr,FSr,Ot,u$,TSr,ECe,MSr,ESr,Nc,CSr,CCe,wSr,ASr,bZ,LSr,ySr,xSr,PC,$Sr,qr,b$,kSr,wCe,SSr,RSr,vn,PSr,ACe,BSr,ISr,LCe,NSr,qSr,yCe,jSr,DSr,GSr,ae,BC,xCe,OSr,VSr,vZ,XSr,zSr,WSr,IC,$Ce,QSr,HSr,FZ,USr,JSr,YSr,NC,kCe,KSr,ZSr,TZ,eRr,oRr,rRr,qC,SCe,tRr,aRr,MZ,nRr,sRr,lRr,jC,RCe,iRr,dRr,EZ,cRr,fRr,mRr,DC,PCe,gRr,hRr,CZ,pRr,_Rr,uRr,GC,BCe,bRr,vRr,wZ,FRr,TRr,MRr,OC,ICe,ERr,CRr,AZ,wRr,ARr,LRr,VC,NCe,yRr,xRr,LZ,$Rr,kRr,SRr,XC,qCe,RRr,PRr,yZ,BRr,IRr,NRr,zC,jCe,qRr,jRr,xZ,DRr,GRr,ORr,WC,DCe,VRr,XRr,$Z,zRr,WRr,QRr,QC,GCe,HRr,URr,kZ,JRr,YRr,KRr,HC,OCe,ZRr,ePr,SZ,oPr,rPr,tPr,UC,VCe,aPr,nPr,RZ,sPr,lPr,iPr,JC,XCe,dPr,cPr,PZ,fPr,mPr,gPr,YC,zCe,hPr,pPr,BZ,_Pr,uPr,bPr,KC,WCe,vPr,FPr,IZ,TPr,MPr,EPr,ZC,QCe,CPr,wPr,NZ,APr,LPr,yPr,e3,HCe,xPr,$Pr,qZ,kPr,SPr,RPr,o3,UCe,PPr,BPr,jZ,IPr,NPr,qPr,r3,JCe,jPr,DPr,DZ,GPr,OPr,VPr,t3,YCe,XPr,zPr,GZ,WPr,QPr,HPr,a3,KCe,UPr,JPr,OZ,YPr,KPr,ZPr,n3,ZCe,eBr,oBr,VZ,rBr,tBr,aBr,s3,e3e,nBr,sBr,XZ,lBr,iBr,dBr,l3,iHe,qc,i3,o3e,v$,cBr,r3e,fBr,dHe,fr,F$,mBr,jc,gBr,zZ,hBr,pBr,WZ,_Br,uBr,bBr,T$,vBr,t3e,FBr,TBr,MBr,Vt,M$,EBr,a3e,CBr,wBr,Dc,ABr,n3e,LBr,yBr,QZ,xBr,$Br,kBr,d3,SBr,jr,E$,RBr,s3e,PBr,BBr,Fn,IBr,l3e,NBr,qBr,i3e,jBr,DBr,d3e,GBr,OBr,VBr,ve,c3,c3e,XBr,zBr,HZ,WBr,QBr,HBr,f3,f3e,UBr,JBr,UZ,YBr,KBr,ZBr,m3,m3e,eIr,oIr,JZ,rIr,tIr,aIr,g3,g3e,nIr,sIr,YZ,lIr,iIr,dIr,h3,h3e,cIr,fIr,KZ,mIr,gIr,hIr,p3,p3e,pIr,_Ir,ZZ,uIr,bIr,vIr,_3,_3e,FIr,TIr,eee,MIr,EIr,CIr,u3,u3e,wIr,AIr,oee,LIr,yIr,xIr,b3,b3e,$Ir,kIr,ree,SIr,RIr,PIr,v3,v3e,BIr,IIr,tee,NIr,qIr,jIr,F3,F3e,DIr,GIr,aee,OIr,VIr,XIr,T3,T3e,zIr,WIr,nee,QIr,HIr,UIr,M3,M3e,JIr,YIr,see,KIr,ZIr,eNr,E3,E3e,oNr,rNr,lee,tNr,aNr,nNr,C3,C3e,sNr,lNr,iee,iNr,dNr,cNr,w3,w3e,fNr,mNr,dee,gNr,hNr,pNr,A3,A3e,_Nr,uNr,cee,bNr,vNr,FNr,L3,cHe,Gc,y3,L3e,C$,TNr,y3e,MNr,fHe,mr,w$,ENr,Oc,CNr,fee,wNr,ANr,mee,LNr,yNr,xNr,A$,$Nr,x3e,kNr,SNr,RNr,Xt,L$,PNr,$3e,BNr,INr,Vc,NNr,k3e,qNr,jNr,gee,DNr,GNr,ONr,x3,VNr,Dr,y$,XNr,S3e,zNr,WNr,Tn,QNr,R3e,HNr,UNr,P3e,JNr,YNr,B3e,KNr,ZNr,eqr,x$,$3,I3e,oqr,rqr,hee,tqr,aqr,nqr,k3,N3e,sqr,lqr,pee,iqr,dqr,cqr,S3,mHe,Xc,R3,q3e,$$,fqr,j3e,mqr,gHe,gr,k$,gqr,zc,hqr,_ee,pqr,_qr,uee,uqr,bqr,vqr,S$,Fqr,D3e,Tqr,Mqr,Eqr,zt,R$,Cqr,G3e,wqr,Aqr,Wc,Lqr,O3e,yqr,xqr,bee,$qr,kqr,Sqr,P3,Rqr,Gr,P$,Pqr,V3e,Bqr,Iqr,Mn,Nqr,X3e,qqr,jqr,z3e,Dqr,Gqr,W3e,Oqr,Vqr,Xqr,Q3e,B3,H3e,zqr,Wqr,vee,Qqr,Hqr,Uqr,I3,hHe,Qc,N3,U3e,B$,Jqr,J3e,Yqr,pHe,hr,I$,Kqr,Hc,Zqr,Fee,ejr,ojr,Tee,rjr,tjr,ajr,N$,njr,Y3e,sjr,ljr,ijr,Wt,q$,djr,K3e,cjr,fjr,Uc,mjr,Z3e,gjr,hjr,Mee,pjr,_jr,ujr,q3,bjr,Or,j$,vjr,e5e,Fjr,Tjr,En,Mjr,o5e,Ejr,Cjr,r5e,wjr,Ajr,t5e,Ljr,yjr,xjr,de,j3,a5e,$jr,kjr,Eee,Sjr,Rjr,Pjr,D3,n5e,Bjr,Ijr,Cee,Njr,qjr,jjr,G3,s5e,Djr,Gjr,wee,Ojr,Vjr,Xjr,O3,l5e,zjr,Wjr,Aee,Qjr,Hjr,Ujr,V3,i5e,Jjr,Yjr,Lee,Kjr,Zjr,eDr,X3,d5e,oDr,rDr,yee,tDr,aDr,nDr,z3,c5e,sDr,lDr,xee,iDr,dDr,cDr,W3,f5e,fDr,mDr,$ee,gDr,hDr,pDr,Q3,m5e,_Dr,uDr,kee,bDr,vDr,FDr,H3,g5e,TDr,MDr,See,EDr,CDr,wDr,U3,h5e,ADr,LDr,Ree,yDr,xDr,$Dr,J3,p5e,kDr,SDr,Pee,RDr,PDr,BDr,Y3,_5e,IDr,NDr,Bee,qDr,jDr,DDr,K3,u5e,GDr,ODr,Iee,VDr,XDr,zDr,Z3,b5e,WDr,QDr,Nee,HDr,UDr,JDr,e5,v5e,YDr,KDr,qee,ZDr,eGr,oGr,o5,F5e,rGr,tGr,jee,aGr,nGr,sGr,r5,T5e,lGr,iGr,Dee,dGr,cGr,fGr,t5,M5e,mGr,gGr,Gee,hGr,pGr,_Gr,a5,E5e,uGr,bGr,Oee,vGr,FGr,TGr,n5,_He,Jc,s5,C5e,D$,MGr,w5e,EGr,uHe,pr,G$,CGr,Yc,wGr,Vee,AGr,LGr,Xee,yGr,xGr,$Gr,O$,kGr,A5e,SGr,RGr,PGr,Qt,V$,BGr,L5e,IGr,NGr,Kc,qGr,y5e,jGr,DGr,zee,GGr,OGr,VGr,l5,XGr,Vr,X$,zGr,x5e,WGr,QGr,Cn,HGr,$5e,UGr,JGr,k5e,YGr,KGr,S5e,ZGr,eOr,oOr,ce,i5,R5e,rOr,tOr,Wee,aOr,nOr,sOr,d5,P5e,lOr,iOr,Qee,dOr,cOr,fOr,c5,B5e,mOr,gOr,Hee,hOr,pOr,_Or,f5,I5e,uOr,bOr,Uee,vOr,FOr,TOr,m5,N5e,MOr,EOr,Jee,COr,wOr,AOr,g5,q5e,LOr,yOr,Yee,xOr,$Or,kOr,h5,j5e,SOr,ROr,Kee,POr,BOr,IOr,p5,D5e,NOr,qOr,Zee,jOr,DOr,GOr,_5,G5e,OOr,VOr,eoe,XOr,zOr,WOr,u5,O5e,QOr,HOr,ooe,UOr,JOr,YOr,b5,V5e,KOr,ZOr,roe,eVr,oVr,rVr,v5,X5e,tVr,aVr,toe,nVr,sVr,lVr,F5,z5e,iVr,dVr,aoe,cVr,fVr,mVr,T5,W5e,gVr,hVr,noe,pVr,_Vr,uVr,M5,Q5e,bVr,vVr,soe,FVr,TVr,MVr,E5,H5e,EVr,CVr,loe,wVr,AVr,LVr,C5,U5e,yVr,xVr,ioe,$Vr,kVr,SVr,w5,J5e,RVr,PVr,doe,BVr,IVr,NVr,A5,Y5e,qVr,jVr,coe,DVr,GVr,OVr,L5,K5e,VVr,XVr,foe,zVr,WVr,QVr,y5,bHe,Zc,x5,Z5e,z$,HVr,e0e,UVr,vHe,_r,W$,JVr,ef,YVr,moe,KVr,ZVr,goe,eXr,oXr,rXr,Q$,tXr,o0e,aXr,nXr,sXr,Ht,H$,lXr,r0e,iXr,dXr,of,cXr,t0e,fXr,mXr,hoe,gXr,hXr,pXr,$5,_Xr,Xr,U$,uXr,a0e,bXr,vXr,wn,FXr,n0e,TXr,MXr,s0e,EXr,CXr,l0e,wXr,AXr,LXr,i0e,k5,d0e,yXr,xXr,poe,$Xr,kXr,SXr,S5,FHe,rf,R5,c0e,J$,RXr,f0e,PXr,THe,ur,Y$,BXr,tf,IXr,_oe,NXr,qXr,uoe,jXr,DXr,GXr,K$,OXr,m0e,VXr,XXr,zXr,Ut,Z$,WXr,g0e,QXr,HXr,af,UXr,h0e,JXr,YXr,boe,KXr,ZXr,ezr,P5,ozr,zr,ek,rzr,p0e,tzr,azr,An,nzr,_0e,szr,lzr,u0e,izr,dzr,b0e,czr,fzr,mzr,v0e,B5,F0e,gzr,hzr,voe,pzr,_zr,uzr,I5,MHe,nf,N5,T0e,ok,bzr,M0e,vzr,EHe,br,rk,Fzr,sf,Tzr,Foe,Mzr,Ezr,Toe,Czr,wzr,Azr,tk,Lzr,E0e,yzr,xzr,$zr,Jt,ak,kzr,C0e,Szr,Rzr,lf,Pzr,w0e,Bzr,Izr,Moe,Nzr,qzr,jzr,q5,Dzr,Wr,nk,Gzr,A0e,Ozr,Vzr,Ln,Xzr,L0e,zzr,Wzr,y0e,Qzr,Hzr,x0e,Uzr,Jzr,Yzr,oe,j5,$0e,Kzr,Zzr,Eoe,eWr,oWr,rWr,D5,k0e,tWr,aWr,Coe,nWr,sWr,lWr,G5,S0e,iWr,dWr,woe,cWr,fWr,mWr,O5,R0e,gWr,hWr,Aoe,pWr,_Wr,uWr,V5,P0e,bWr,vWr,Loe,FWr,TWr,MWr,X5,B0e,EWr,CWr,yoe,wWr,AWr,LWr,z5,I0e,yWr,xWr,xoe,$Wr,kWr,SWr,W5,N0e,RWr,PWr,$oe,BWr,IWr,NWr,Q5,q0e,qWr,jWr,koe,DWr,GWr,OWr,H5,j0e,VWr,XWr,Soe,zWr,WWr,QWr,U5,D0e,HWr,UWr,Roe,JWr,YWr,KWr,J5,G0e,ZWr,eQr,Poe,oQr,rQr,tQr,Y5,O0e,aQr,nQr,Boe,sQr,lQr,iQr,K5,V0e,dQr,cQr,Ioe,fQr,mQr,gQr,Z5,X0e,hQr,pQr,Noe,_Qr,uQr,bQr,e0,z0e,vQr,FQr,qoe,TQr,MQr,EQr,o0,W0e,CQr,wQr,joe,AQr,LQr,yQr,r0,Q0e,xQr,$Qr,Doe,kQr,SQr,RQr,t0,H0e,PQr,BQr,Goe,IQr,NQr,qQr,a0,U0e,jQr,DQr,Ooe,GQr,OQr,VQr,n0,J0e,XQr,zQr,Voe,WQr,QQr,HQr,s0,Y0e,UQr,JQr,Xoe,YQr,KQr,ZQr,l0,K0e,eHr,oHr,zoe,rHr,tHr,aHr,i0,Z0e,nHr,sHr,Woe,lHr,iHr,dHr,d0,ewe,cHr,fHr,Qoe,mHr,gHr,hHr,c0,owe,pHr,_Hr,Hoe,uHr,bHr,vHr,f0,rwe,FHr,THr,Uoe,MHr,EHr,CHr,m0,twe,wHr,AHr,Joe,LHr,yHr,xHr,g0,CHe,df,h0,awe,sk,$Hr,nwe,kHr,wHe,vr,lk,SHr,cf,RHr,Yoe,PHr,BHr,Koe,IHr,NHr,qHr,ik,jHr,swe,DHr,GHr,OHr,Yt,dk,VHr,lwe,XHr,zHr,ff,WHr,iwe,QHr,HHr,Zoe,UHr,JHr,YHr,p0,KHr,Qr,ck,ZHr,dwe,eUr,oUr,yn,rUr,cwe,tUr,aUr,fwe,nUr,sUr,mwe,lUr,iUr,dUr,xe,_0,gwe,cUr,fUr,ere,mUr,gUr,hUr,u0,hwe,pUr,_Ur,ore,uUr,bUr,vUr,b0,pwe,FUr,TUr,rre,MUr,EUr,CUr,v0,_we,wUr,AUr,tre,LUr,yUr,xUr,F0,uwe,$Ur,kUr,are,SUr,RUr,PUr,T0,bwe,BUr,IUr,nre,NUr,qUr,jUr,M0,vwe,DUr,GUr,sre,OUr,VUr,XUr,E0,Fwe,zUr,WUr,lre,QUr,HUr,UUr,C0,Twe,JUr,YUr,ire,KUr,ZUr,eJr,w0,Mwe,oJr,rJr,dre,tJr,aJr,nJr,A0,AHe,mf,L0,Ewe,fk,sJr,Cwe,lJr,LHe,Fr,mk,iJr,gf,dJr,cre,cJr,fJr,fre,mJr,gJr,hJr,gk,pJr,wwe,_Jr,uJr,bJr,Kt,hk,vJr,Awe,FJr,TJr,hf,MJr,Lwe,EJr,CJr,mre,wJr,AJr,LJr,y0,yJr,Hr,pk,xJr,ywe,$Jr,kJr,xn,SJr,xwe,RJr,PJr,$we,BJr,IJr,kwe,NJr,qJr,jJr,Ee,x0,Swe,DJr,GJr,gre,OJr,VJr,XJr,$0,Rwe,zJr,WJr,hre,QJr,HJr,UJr,k0,Pwe,JJr,YJr,pre,KJr,ZJr,eYr,S0,Bwe,oYr,rYr,_re,tYr,aYr,nYr,R0,Iwe,sYr,lYr,ure,iYr,dYr,cYr,P0,Nwe,fYr,mYr,bre,gYr,hYr,pYr,B0,qwe,_Yr,uYr,vre,bYr,vYr,FYr,I0,jwe,TYr,MYr,Fre,EYr,CYr,wYr,N0,Dwe,AYr,LYr,Tre,yYr,xYr,$Yr,q0,Gwe,kYr,SYr,Mre,RYr,PYr,BYr,j0,Owe,IYr,NYr,Ere,qYr,jYr,DYr,D0,Vwe,GYr,OYr,Cre,VYr,XYr,zYr,G0,Xwe,WYr,QYr,wre,HYr,UYr,JYr,O0,yHe,pf,V0,zwe,_k,YYr,Wwe,KYr,xHe,Tr,uk,ZYr,_f,eKr,Are,oKr,rKr,Lre,tKr,aKr,nKr,bk,sKr,Qwe,lKr,iKr,dKr,Zt,vk,cKr,Hwe,fKr,mKr,uf,gKr,Uwe,hKr,pKr,yre,_Kr,uKr,bKr,X0,vKr,Ur,Fk,FKr,Jwe,TKr,MKr,$n,EKr,Ywe,CKr,wKr,Kwe,AKr,LKr,Zwe,yKr,xKr,$Kr,$e,z0,e6e,kKr,SKr,xre,RKr,PKr,BKr,W0,o6e,IKr,NKr,$re,qKr,jKr,DKr,Q0,r6e,GKr,OKr,kre,VKr,XKr,zKr,H0,t6e,WKr,QKr,Sre,HKr,UKr,JKr,U0,a6e,YKr,KKr,Rre,ZKr,eZr,oZr,J0,n6e,rZr,tZr,Pre,aZr,nZr,sZr,Y0,s6e,lZr,iZr,Bre,dZr,cZr,fZr,K0,l6e,mZr,gZr,Ire,hZr,pZr,_Zr,Z0,i6e,uZr,bZr,Nre,vZr,FZr,TZr,ew,d6e,MZr,EZr,qre,CZr,wZr,AZr,ow,$He,bf,rw,c6e,Tk,LZr,f6e,yZr,kHe,Mr,Mk,xZr,vf,$Zr,jre,kZr,SZr,Dre,RZr,PZr,BZr,Ek,IZr,m6e,NZr,qZr,jZr,ea,Ck,DZr,g6e,GZr,OZr,Ff,VZr,h6e,XZr,zZr,Gre,WZr,QZr,HZr,tw,UZr,Jr,wk,JZr,p6e,YZr,KZr,kn,ZZr,_6e,eet,oet,u6e,ret,tet,b6e,aet,net,set,ke,aw,v6e,iet,det,Ore,cet,fet,met,nw,F6e,get,het,Vre,pet,_et,uet,sw,T6e,bet,vet,Xre,Fet,Tet,Met,lw,M6e,Eet,Cet,zre,wet,Aet,Let,iw,E6e,yet,xet,Wre,$et,ket,Set,dw,C6e,Ret,Pet,Qre,Bet,Iet,Net,cw,w6e,qet,jet,Hre,Det,Get,Oet,fw,A6e,Vet,Xet,Ure,zet,Wet,Qet,mw,L6e,Het,Uet,Jre,Jet,Yet,Ket,gw,y6e,Zet,eot,Yre,oot,rot,tot,hw,SHe,Tf,pw,x6e,Ak,aot,$6e,not,RHe,Er,Lk,sot,Mf,lot,Kre,iot,dot,Zre,cot,fot,mot,yk,got,k6e,hot,pot,_ot,oa,xk,uot,S6e,bot,vot,Ef,Fot,R6e,Tot,Mot,ete,Eot,Cot,wot,_w,Aot,Yr,$k,Lot,P6e,yot,xot,Sn,$ot,B6e,kot,Sot,I6e,Rot,Pot,N6e,Bot,Iot,Not,Se,uw,q6e,qot,jot,ote,Dot,Got,Oot,bw,j6e,Vot,Xot,rte,zot,Wot,Qot,vw,D6e,Hot,Uot,tte,Jot,Yot,Kot,Fw,G6e,Zot,ert,ate,ort,rrt,trt,Tw,O6e,art,nrt,nte,srt,lrt,irt,Mw,V6e,drt,crt,ste,frt,mrt,grt,Ew,X6e,hrt,prt,lte,_rt,urt,brt,Cw,z6e,vrt,Frt,ite,Trt,Mrt,Ert,ww,W6e,Crt,wrt,dte,Art,Lrt,yrt,Aw,Q6e,xrt,$rt,cte,krt,Srt,Rrt,Lw,PHe,Cf,yw,H6e,kk,Prt,U6e,Brt,BHe,Cr,Sk,Irt,wf,Nrt,fte,qrt,jrt,mte,Drt,Grt,Ort,Rk,Vrt,J6e,Xrt,zrt,Wrt,ra,Pk,Qrt,Y6e,Hrt,Urt,Af,Jrt,K6e,Yrt,Krt,gte,Zrt,ett,ott,xw,rtt,Kr,Bk,ttt,Z6e,att,ntt,Rn,stt,eAe,ltt,itt,oAe,dtt,ctt,rAe,ftt,mtt,gtt,Re,$w,tAe,htt,ptt,hte,_tt,utt,btt,kw,aAe,vtt,Ftt,pte,Ttt,Mtt,Ett,Sw,nAe,Ctt,wtt,_te,Att,Ltt,ytt,Rw,sAe,xtt,$tt,ute,ktt,Stt,Rtt,Pw,lAe,Ptt,Btt,bte,Itt,Ntt,qtt,Bw,iAe,jtt,Dtt,vte,Gtt,Ott,Vtt,Iw,dAe,Xtt,ztt,Fte,Wtt,Qtt,Htt,Nw,cAe,Utt,Jtt,Tte,Ytt,Ktt,Ztt,qw,fAe,eat,oat,Mte,rat,tat,aat,jw,mAe,nat,sat,Ete,lat,iat,dat,Dw,IHe,Lf,Gw,gAe,Ik,cat,hAe,fat,NHe,wr,Nk,mat,yf,gat,Cte,hat,pat,wte,_at,uat,bat,qk,vat,pAe,Fat,Tat,Mat,ta,jk,Eat,_Ae,Cat,wat,xf,Aat,uAe,Lat,yat,Ate,xat,$at,kat,Ow,Sat,Zr,Dk,Rat,bAe,Pat,Bat,Pn,Iat,vAe,Nat,qat,FAe,jat,Dat,TAe,Gat,Oat,Vat,Xe,Vw,MAe,Xat,zat,Lte,Wat,Qat,Hat,Xw,EAe,Uat,Jat,yte,Yat,Kat,Zat,zw,CAe,ent,ont,xte,rnt,tnt,ant,Ww,wAe,nnt,snt,$te,lnt,int,dnt,Qw,AAe,cnt,fnt,kte,mnt,gnt,hnt,Hw,LAe,pnt,_nt,Ste,unt,bnt,vnt,Uw,yAe,Fnt,Tnt,Rte,Mnt,Ent,Cnt,Jw,xAe,wnt,Ant,Pte,Lnt,ynt,xnt,Yw,qHe,$f,Kw,$Ae,Gk,$nt,kAe,knt,jHe,Ar,Ok,Snt,kf,Rnt,Bte,Pnt,Bnt,Ite,Int,Nnt,qnt,Vk,jnt,SAe,Dnt,Gnt,Ont,aa,Xk,Vnt,RAe,Xnt,znt,Sf,Wnt,PAe,Qnt,Hnt,Nte,Unt,Jnt,Ynt,Zw,Knt,et,zk,Znt,BAe,est,ost,Bn,rst,IAe,tst,ast,NAe,nst,sst,qAe,lst,ist,dst,ze,e6,jAe,cst,fst,qte,mst,gst,hst,o6,DAe,pst,_st,jte,ust,bst,vst,r6,GAe,Fst,Tst,Dte,Mst,Est,Cst,t6,OAe,wst,Ast,Gte,Lst,yst,xst,a6,VAe,$st,kst,Ote,Sst,Rst,Pst,n6,XAe,Bst,Ist,Vte,Nst,qst,jst,s6,zAe,Dst,Gst,Xte,Ost,Vst,Xst,l6,WAe,zst,Wst,zte,Qst,Hst,Ust,i6,DHe,Rf,d6,QAe,Wk,Jst,HAe,Yst,GHe,Lr,Qk,Kst,Pf,Zst,Wte,elt,olt,Qte,rlt,tlt,alt,Hk,nlt,UAe,slt,llt,ilt,na,Uk,dlt,JAe,clt,flt,Bf,mlt,YAe,glt,hlt,Hte,plt,_lt,ult,c6,blt,ot,Jk,vlt,KAe,Flt,Tlt,In,Mlt,ZAe,Elt,Clt,eLe,wlt,Alt,oLe,Llt,ylt,xlt,rLe,f6,tLe,$lt,klt,Ute,Slt,Rlt,Plt,m6,OHe,If,g6,aLe,Yk,Blt,nLe,Ilt,VHe,yr,Kk,Nlt,Nf,qlt,Jte,jlt,Dlt,Yte,Glt,Olt,Vlt,Zk,Xlt,sLe,zlt,Wlt,Qlt,sa,eS,Hlt,lLe,Ult,Jlt,qf,Ylt,iLe,Klt,Zlt,Kte,eit,oit,rit,h6,tit,rt,oS,ait,dLe,nit,sit,Nn,lit,cLe,iit,dit,fLe,cit,fit,mLe,mit,git,hit,rS,p6,gLe,pit,_it,Zte,uit,bit,vit,_6,hLe,Fit,Tit,eae,Mit,Eit,Cit,u6,XHe,jf,b6,pLe,tS,wit,_Le,Ait,zHe,xr,aS,Lit,Df,yit,oae,xit,$it,rae,kit,Sit,Rit,nS,Pit,uLe,Bit,Iit,Nit,la,sS,qit,bLe,jit,Dit,Gf,Git,vLe,Oit,Vit,tae,Xit,zit,Wit,v6,Qit,tt,lS,Hit,FLe,Uit,Jit,qn,Yit,TLe,Kit,Zit,MLe,edt,odt,ELe,rdt,tdt,adt,CLe,F6,wLe,ndt,sdt,aae,ldt,idt,ddt,T6,WHe;return d=new re({}),Ia=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),QL=new re({}),HL=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Jf=new cdt({props:{warning:!0,$$slots:{default:[nea]},$$scope:{ctx:$}}}),UL=new re({}),JL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/configuration_auto.py#L620"}}),ZL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/configuration_auto.py#L643"}}),fh=new I({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[sea]},$$scope:{ctx:$}}}),ey=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/configuration_auto.py#L766"}}),oy=new re({}),ry=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/tokenization_auto.py#L418"}}),ny=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17779/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/tokenization_auto.py#L432"}}),Qh=new I({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[lea]},$$scope:{ctx:$}}}),sy=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/tokenization_auto.py#L633"}}),ly=new re({}),iy=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/feature_extraction_auto.py#L198"}}),fy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17779/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/feature_extraction_auto.py#L212"}}),Rp=new cdt({props:{$$slots:{default:[iea]},$$scope:{ctx:$}}}),Pp=new I({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[dea]},$$scope:{ctx:$}}}),my=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/feature_extraction_auto.py#L339"}}),gy=new re({}),hy=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/processing_auto.py#L90"}}),uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/processing_auto.py#L104"}}),r_=new cdt({props:{$$slots:{default:[cea]},$$scope:{ctx:$}}}),t_=new I({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[fea]},$$scope:{ctx:$}}}),by=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/processing_auto.py#L257"}}),vy=new re({}),Fy=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L807"}}),My=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),s_=new I({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[mea]},$$scope:{ctx:$}}}),Ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),h7=new I({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[gea]},$$scope:{ctx:$}}}),Cy=new re({}),wy=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L814"}}),Ly=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),_7=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[hea]},$$scope:{ctx:$}}}),yy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),f1=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[pea]},$$scope:{ctx:$}}}),xy=new re({}),$y=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L829"}}),Sy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),g1=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[_ea]},$$scope:{ctx:$}}}),Ry=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),o2=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[uea]},$$scope:{ctx:$}}}),Py=new re({}),By=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L836"}}),Ny=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),t2=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[bea]},$$scope:{ctx:$}}}),qy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),V2=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[vea]},$$scope:{ctx:$}}}),jy=new re({}),Dy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L843"}}),Oy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),z2=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Fea]},$$scope:{ctx:$}}}),Vy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),mb=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Tea]},$$scope:{ctx:$}}}),Xy=new re({}),zy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L852"}}),Qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),hb=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Mea]},$$scope:{ctx:$}}}),Hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),hv=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Eea]},$$scope:{ctx:$}}}),Uy=new re({}),Jy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L897"}}),Ky=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),_v=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Cea]},$$scope:{ctx:$}}}),Zy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),Uv=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[wea]},$$scope:{ctx:$}}}),e8=new re({}),o8=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L904"}}),t8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),Yv=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Aea]},$$scope:{ctx:$}}}),a8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),nF=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Lea]},$$scope:{ctx:$}}}),n8=new re({}),s8=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L890"}}),i8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),lF=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[yea]},$$scope:{ctx:$}}}),d8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),WF=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xea]},$$scope:{ctx:$}}}),c8=new re({}),f8=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L861"}}),g8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),HF=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[$ea]},$$scope:{ctx:$}}}),h8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),jT=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[kea]},$$scope:{ctx:$}}}),p8=new re({}),_8=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L868"}}),b8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),GT=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Sea]},$$scope:{ctx:$}}}),v8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),XT=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Rea]},$$scope:{ctx:$}}}),F8=new re({}),T8=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L913"}}),E8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),WT=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[Pea]},$$scope:{ctx:$}}}),C8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),i9=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Bea]},$$scope:{ctx:$}}}),w8=new re({}),A8=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L952"}}),y8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),c9=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[Iea]},$$scope:{ctx:$}}}),x8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),g9=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[Nea]},$$scope:{ctx:$}}}),$8=new re({}),k8=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L959"}}),R8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),p9=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[qea]},$$scope:{ctx:$}}}),P8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),b9=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[jea]},$$scope:{ctx:$}}}),B8=new re({}),I8=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L879"}}),q8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),F9=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Dea]},$$scope:{ctx:$}}}),j8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),E9=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[Gea]},$$scope:{ctx:$}}}),D8=new re({}),G8=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L966"}}),V8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),w9=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Oea]},$$scope:{ctx:$}}}),X8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),I9=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[Vea]},$$scope:{ctx:$}}}),z8=new re({}),W8=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L989"}}),H8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),q9=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[Xea]},$$scope:{ctx:$}}}),U8=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),z9=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[zea]},$$scope:{ctx:$}}}),J8=new re({}),Y8=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L973"}}),Z8=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),Q9=new I({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[Wea]},$$scope:{ctx:$}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),nM=new I({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[Qea]},$$scope:{ctx:$}}}),ox=new re({}),rx=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L980"}}),ax=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),lM=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Hea]},$$scope:{ctx:$}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),fM=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Uea]},$$scope:{ctx:$}}}),lx=new re({}),ix=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L998"}}),cx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),gM=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[Jea]},$$scope:{ctx:$}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),FM=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[Yea]},$$scope:{ctx:$}}}),mx=new re({}),gx=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L1005"}}),px=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),MM=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[Kea]},$$scope:{ctx:$}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),yM=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[Zea]},$$scope:{ctx:$}}}),ux=new re({}),bx=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L945"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),$M=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[eoa]},$$scope:{ctx:$}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),PM=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[ooa]},$$scope:{ctx:$}}}),Ex=new re({}),Cx=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L920"}}),Ax=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),IM=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[roa]},$$scope:{ctx:$}}}),Lx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),jM=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[toa]},$$scope:{ctx:$}}}),yx=new re({}),xx=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L927"}}),kx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),GM=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[aoa]},$$scope:{ctx:$}}}),Sx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),HM=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[noa]},$$scope:{ctx:$}}}),Rx=new re({}),Px=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_auto.py#L936"}}),Ix=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),JM=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[soa]},$$scope:{ctx:$}}}),Nx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),ZM=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[loa]},$$scope:{ctx:$}}}),qx=new re({}),jx=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),Gx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),oE=new I({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[ioa]},$$scope:{ctx:$}}}),Ox=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),KE=new I({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[doa]},$$scope:{ctx:$}}}),Vx=new re({}),Xx=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L423"}}),Wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),e4=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[coa]},$$scope:{ctx:$}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),C4=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[foa]},$$scope:{ctx:$}}}),Hx=new re({}),Ux=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L438"}}),Yx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),A4=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[moa]},$$scope:{ctx:$}}}),Kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),D4=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[goa]},$$scope:{ctx:$}}}),Zx=new re({}),e$=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L454"}}),r$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/pr_17779/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),O4=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[hoa]},$$scope:{ctx:$}}}),t$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),J4=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[poa]},$$scope:{ctx:$}}}),a$=new re({}),n$=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L479"}}),l$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),K4=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[_oa]},$$scope:{ctx:$}}}),i$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),vC=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[uoa]},$$scope:{ctx:$}}}),d$=new re({}),c$=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L486"}}),m$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),TC=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[boa]},$$scope:{ctx:$}}}),g$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),SC=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[voa]},$$scope:{ctx:$}}}),h$=new re({}),p$=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L495"}}),u$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),PC=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Foa]},$$scope:{ctx:$}}}),b$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),l3=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Toa]},$$scope:{ctx:$}}}),v$=new re({}),F$=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L531"}}),M$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),d3=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Moa]},$$scope:{ctx:$}}}),E$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),L3=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Eoa]},$$scope:{ctx:$}}}),C$=new re({}),w$=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L538"}}),L$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),x3=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Coa]},$$scope:{ctx:$}}}),y$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),S3=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[woa]},$$scope:{ctx:$}}}),$$=new re({}),k$=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L511"}}),R$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),P3=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Aoa]},$$scope:{ctx:$}}}),P$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),I3=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Loa]},$$scope:{ctx:$}}}),B$=new re({}),I$=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L522"}}),q$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),q3=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[yoa]},$$scope:{ctx:$}}}),j$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),n5=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[xoa]},$$scope:{ctx:$}}}),D$=new re({}),G$=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L504"}}),V$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),l5=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[$oa]},$$scope:{ctx:$}}}),X$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),y5=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[koa]},$$scope:{ctx:$}}}),z$=new re({}),W$=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L472"}}),H$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),$5=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[Soa]},$$scope:{ctx:$}}}),U$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),S5=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Roa]},$$scope:{ctx:$}}}),J$=new re({}),Y$=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_tf_auto.py#L547"}}),Z$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),P5=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[Poa]},$$scope:{ctx:$}}}),ek=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),I5=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Boa]},$$scope:{ctx:$}}}),ok=new re({}),rk=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L264"}}),ak=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/dpt#transformers.FlaxDPTModel">FlaxDPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),q5=new I({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Ioa]},$$scope:{ctx:$}}}),nk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),g0=new I({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Noa]},$$scope:{ctx:$}}}),sk=new re({}),lk=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L278"}}),dk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),p0=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[qoa]},$$scope:{ctx:$}}}),ck=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),A0=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[joa]},$$scope:{ctx:$}}}),fk=new re({}),mk=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L271"}}),hk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),y0=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[Doa]},$$scope:{ctx:$}}}),pk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),O0=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Goa]},$$scope:{ctx:$}}}),_k=new re({}),uk=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L285"}}),vk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),X0=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Ooa]},$$scope:{ctx:$}}}),Fk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),ow=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[Voa]},$$scope:{ctx:$}}}),Tk=new re({}),Mk=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),Ck=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),tw=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[Xoa]},$$scope:{ctx:$}}}),wk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),hw=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[zoa]},$$scope:{ctx:$}}}),Ak=new re({}),Lk=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L301"}}),xk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),_w=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[Woa]},$$scope:{ctx:$}}}),$k=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),Lw=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Qoa]},$$scope:{ctx:$}}}),kk=new re({}),Sk=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L310"}}),Pk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),xw=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Hoa]},$$scope:{ctx:$}}}),Bk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),Dw=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Uoa]},$$scope:{ctx:$}}}),Ik=new re({}),Nk=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L317"}}),jk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),Ow=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[Joa]},$$scope:{ctx:$}}}),Dk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),Yw=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Yoa]},$$scope:{ctx:$}}}),Gk=new re({}),Ok=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L326"}}),Xk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),Zw=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Koa]},$$scope:{ctx:$}}}),zk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),i6=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Zoa]},$$scope:{ctx:$}}}),Wk=new re({}),Qk=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),Uk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),c6=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[era]},$$scope:{ctx:$}}}),Jk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),m6=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[ora]},$$scope:{ctx:$}}}),Yk=new re({}),Kk=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L342"}}),eS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),h6=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[rra]},$$scope:{ctx:$}}}),oS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),u6=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[tra]},$$scope:{ctx:$}}}),tS=new re({}),aS=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/modeling_flax_auto.py#L351"}}),sS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L389"}}),v6=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[ara]},$$scope:{ctx:$}}}),lS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17779/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17779/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17779/src/transformers/models/auto/auto_factory.py#L417"}}),T6=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[nra]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Ao=a("span"),Ii=o("Auto Classes"),zf=l(),dt=a("p"),Ni=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),qi=a("code"),VL=o("from_pretrained()"),Wf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),ji=o("Instantiating one of "),Dn=a("a"),XL=o("AutoConfig"),Gn=o(", "),On=a("a"),zL=o("AutoModel"),Di=o(`, and
`),Vn=a("a"),WL=o("AutoTokenizer"),Gi=o(" will directly create a class of the relevant architecture. For instance"),Qf=l(),F(Ia.$$.fragment),He=l(),Ae=a("p"),kR=o("will create a model that is an instance of "),Oi=a("a"),SR=o("BertModel"),RR=o("."),Lo=l(),Na=a("p"),PR=o("There is one class of "),Hf=a("code"),BR=o("AutoModel"),aYe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jWe=l(),Vi=a("h2"),Uf=a("a"),ese=a("span"),F(QL.$$.fragment),nYe=l(),ose=a("span"),sYe=o("Extending the Auto Classes"),DWe=l(),Xn=a("p"),lYe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),rse=a("code"),iYe=o("NewModel"),dYe=o(", make sure you have a "),tse=a("code"),cYe=o("NewModelConfig"),fYe=o(` then you can add those to the auto
classes like this:`),GWe=l(),F(HL.$$.fragment),OWe=l(),IR=a("p"),mYe=o("You will then be able to use the auto classes like you would usually do!"),VWe=l(),F(Jf.$$.fragment),XWe=l(),Xi=a("h2"),Yf=a("a"),ase=a("span"),F(UL.$$.fragment),gYe=l(),nse=a("span"),hYe=o("AutoConfig"),zWe=l(),yo=a("div"),F(JL.$$.fragment),pYe=l(),YL=a("p"),_Ye=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),NR=a("a"),uYe=o("from_pretrained()"),bYe=o(" class method."),vYe=l(),KL=a("p"),FYe=o("This class cannot be instantiated directly using "),sse=a("code"),TYe=o("__init__()"),MYe=o(" (throws an error)."),EYe=l(),$r=a("div"),F(ZL.$$.fragment),CYe=l(),lse=a("p"),wYe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),AYe=l(),zi=a("p"),LYe=o("The configuration class to instantiate is selected based on the "),ise=a("code"),yYe=o("model_type"),xYe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),dse=a("code"),$Ye=o("pretrained_model_name_or_path"),kYe=o(":"),SYe=l(),A=a("ul"),Kf=a("li"),cse=a("strong"),RYe=o("albert"),PYe=o(" \u2014 "),qR=a("a"),BYe=o("AlbertConfig"),IYe=o(" (ALBERT model)"),NYe=l(),Zf=a("li"),fse=a("strong"),qYe=o("bart"),jYe=o(" \u2014 "),jR=a("a"),DYe=o("BartConfig"),GYe=o(" (BART model)"),OYe=l(),em=a("li"),mse=a("strong"),VYe=o("beit"),XYe=o(" \u2014 "),DR=a("a"),zYe=o("BeitConfig"),WYe=o(" (BEiT model)"),QYe=l(),om=a("li"),gse=a("strong"),HYe=o("bert"),UYe=o(" \u2014 "),GR=a("a"),JYe=o("BertConfig"),YYe=o(" (BERT model)"),KYe=l(),rm=a("li"),hse=a("strong"),ZYe=o("bert-generation"),eKe=o(" \u2014 "),OR=a("a"),oKe=o("BertGenerationConfig"),rKe=o(" (Bert Generation model)"),tKe=l(),tm=a("li"),pse=a("strong"),aKe=o("big_bird"),nKe=o(" \u2014 "),VR=a("a"),sKe=o("BigBirdConfig"),lKe=o(" (BigBird model)"),iKe=l(),am=a("li"),_se=a("strong"),dKe=o("bigbird_pegasus"),cKe=o(" \u2014 "),XR=a("a"),fKe=o("BigBirdPegasusConfig"),mKe=o(" (BigBird-Pegasus model)"),gKe=l(),nm=a("li"),use=a("strong"),hKe=o("blenderbot"),pKe=o(" \u2014 "),zR=a("a"),_Ke=o("BlenderbotConfig"),uKe=o(" (Blenderbot model)"),bKe=l(),sm=a("li"),bse=a("strong"),vKe=o("blenderbot-small"),FKe=o(" \u2014 "),WR=a("a"),TKe=o("BlenderbotSmallConfig"),MKe=o(" (BlenderbotSmall model)"),EKe=l(),lm=a("li"),vse=a("strong"),CKe=o("bloom"),wKe=o(" \u2014 "),QR=a("a"),AKe=o("BloomConfig"),LKe=o(" (BLOOM model)"),yKe=l(),im=a("li"),Fse=a("strong"),xKe=o("camembert"),$Ke=o(" \u2014 "),HR=a("a"),kKe=o("CamembertConfig"),SKe=o(" (CamemBERT model)"),RKe=l(),dm=a("li"),Tse=a("strong"),PKe=o("canine"),BKe=o(" \u2014 "),UR=a("a"),IKe=o("CanineConfig"),NKe=o(" (CANINE model)"),qKe=l(),cm=a("li"),Mse=a("strong"),jKe=o("clip"),DKe=o(" \u2014 "),JR=a("a"),GKe=o("CLIPConfig"),OKe=o(" (CLIP model)"),VKe=l(),fm=a("li"),Ese=a("strong"),XKe=o("codegen"),zKe=o(" \u2014 "),YR=a("a"),WKe=o("CodeGenConfig"),QKe=o(" (CodeGen model)"),HKe=l(),mm=a("li"),Cse=a("strong"),UKe=o("convbert"),JKe=o(" \u2014 "),KR=a("a"),YKe=o("ConvBertConfig"),KKe=o(" (ConvBERT model)"),ZKe=l(),gm=a("li"),wse=a("strong"),eZe=o("convnext"),oZe=o(" \u2014 "),ZR=a("a"),rZe=o("ConvNextConfig"),tZe=o(" (ConvNeXT model)"),aZe=l(),hm=a("li"),Ase=a("strong"),nZe=o("ctrl"),sZe=o(" \u2014 "),eP=a("a"),lZe=o("CTRLConfig"),iZe=o(" (CTRL model)"),dZe=l(),pm=a("li"),Lse=a("strong"),cZe=o("cvt"),fZe=o(" \u2014 "),oP=a("a"),mZe=o("CvtConfig"),gZe=o(" (CvT model)"),hZe=l(),_m=a("li"),yse=a("strong"),pZe=o("data2vec-audio"),_Ze=o(" \u2014 "),rP=a("a"),uZe=o("Data2VecAudioConfig"),bZe=o(" (Data2VecAudio model)"),vZe=l(),um=a("li"),xse=a("strong"),FZe=o("data2vec-text"),TZe=o(" \u2014 "),tP=a("a"),MZe=o("Data2VecTextConfig"),EZe=o(" (Data2VecText model)"),CZe=l(),bm=a("li"),$se=a("strong"),wZe=o("data2vec-vision"),AZe=o(" \u2014 "),aP=a("a"),LZe=o("Data2VecVisionConfig"),yZe=o(" (Data2VecVision model)"),xZe=l(),vm=a("li"),kse=a("strong"),$Ze=o("deberta"),kZe=o(" \u2014 "),nP=a("a"),SZe=o("DebertaConfig"),RZe=o(" (DeBERTa model)"),PZe=l(),Fm=a("li"),Sse=a("strong"),BZe=o("deberta-v2"),IZe=o(" \u2014 "),sP=a("a"),NZe=o("DebertaV2Config"),qZe=o(" (DeBERTa-v2 model)"),jZe=l(),Tm=a("li"),Rse=a("strong"),DZe=o("decision_transformer"),GZe=o(" \u2014 "),lP=a("a"),OZe=o("DecisionTransformerConfig"),VZe=o(" (Decision Transformer model)"),XZe=l(),Mm=a("li"),Pse=a("strong"),zZe=o("deit"),WZe=o(" \u2014 "),iP=a("a"),QZe=o("DeiTConfig"),HZe=o(" (DeiT model)"),UZe=l(),Em=a("li"),Bse=a("strong"),JZe=o("detr"),YZe=o(" \u2014 "),dP=a("a"),KZe=o("DetrConfig"),ZZe=o(" (DETR model)"),eeo=l(),Cm=a("li"),Ise=a("strong"),oeo=o("distilbert"),reo=o(" \u2014 "),cP=a("a"),teo=o("DistilBertConfig"),aeo=o(" (DistilBERT model)"),neo=l(),wm=a("li"),Nse=a("strong"),seo=o("dpr"),leo=o(" \u2014 "),fP=a("a"),ieo=o("DPRConfig"),deo=o(" (DPR model)"),ceo=l(),Am=a("li"),qse=a("strong"),feo=o("dpt"),meo=o(" \u2014 "),mP=a("a"),geo=o("DPTConfig"),heo=o(" (DPT model)"),peo=l(),Lm=a("li"),jse=a("strong"),_eo=o("electra"),ueo=o(" \u2014 "),gP=a("a"),beo=o("ElectraConfig"),veo=o(" (ELECTRA model)"),Feo=l(),ym=a("li"),Dse=a("strong"),Teo=o("encoder-decoder"),Meo=o(" \u2014 "),hP=a("a"),Eeo=o("EncoderDecoderConfig"),Ceo=o(" (Encoder decoder model)"),weo=l(),xm=a("li"),Gse=a("strong"),Aeo=o("flaubert"),Leo=o(" \u2014 "),pP=a("a"),yeo=o("FlaubertConfig"),xeo=o(" (FlauBERT model)"),$eo=l(),$m=a("li"),Ose=a("strong"),keo=o("flava"),Seo=o(" \u2014 "),_P=a("a"),Reo=o("FlavaConfig"),Peo=o(" (FLAVA model)"),Beo=l(),km=a("li"),Vse=a("strong"),Ieo=o("fnet"),Neo=o(" \u2014 "),uP=a("a"),qeo=o("FNetConfig"),jeo=o(" (FNet model)"),Deo=l(),Sm=a("li"),Xse=a("strong"),Geo=o("fsmt"),Oeo=o(" \u2014 "),bP=a("a"),Veo=o("FSMTConfig"),Xeo=o(" (FairSeq Machine-Translation model)"),zeo=l(),Rm=a("li"),zse=a("strong"),Weo=o("funnel"),Qeo=o(" \u2014 "),vP=a("a"),Heo=o("FunnelConfig"),Ueo=o(" (Funnel Transformer model)"),Jeo=l(),Pm=a("li"),Wse=a("strong"),Yeo=o("glpn"),Keo=o(" \u2014 "),FP=a("a"),Zeo=o("GLPNConfig"),eoo=o(" (GLPN model)"),ooo=l(),Bm=a("li"),Qse=a("strong"),roo=o("gpt2"),too=o(" \u2014 "),TP=a("a"),aoo=o("GPT2Config"),noo=o(" (OpenAI GPT-2 model)"),soo=l(),Im=a("li"),Hse=a("strong"),loo=o("gpt_neo"),ioo=o(" \u2014 "),MP=a("a"),doo=o("GPTNeoConfig"),coo=o(" (GPT Neo model)"),foo=l(),Nm=a("li"),Use=a("strong"),moo=o("gpt_neox"),goo=o(" \u2014 "),EP=a("a"),hoo=o("GPTNeoXConfig"),poo=o(" (GPT NeoX model)"),_oo=l(),qm=a("li"),Jse=a("strong"),uoo=o("gptj"),boo=o(" \u2014 "),CP=a("a"),voo=o("GPTJConfig"),Foo=o(" (GPT-J model)"),Too=l(),jm=a("li"),Yse=a("strong"),Moo=o("groupvit"),Eoo=o(" \u2014 "),wP=a("a"),Coo=o("GroupViTConfig"),woo=o(" (GroupViT model)"),Aoo=l(),Dm=a("li"),Kse=a("strong"),Loo=o("hubert"),yoo=o(" \u2014 "),AP=a("a"),xoo=o("HubertConfig"),$oo=o(" (Hubert model)"),koo=l(),Gm=a("li"),Zse=a("strong"),Soo=o("ibert"),Roo=o(" \u2014 "),LP=a("a"),Poo=o("IBertConfig"),Boo=o(" (I-BERT model)"),Ioo=l(),Om=a("li"),ele=a("strong"),Noo=o("imagegpt"),qoo=o(" \u2014 "),yP=a("a"),joo=o("ImageGPTConfig"),Doo=o(" (ImageGPT model)"),Goo=l(),Vm=a("li"),ole=a("strong"),Ooo=o("layoutlm"),Voo=o(" \u2014 "),xP=a("a"),Xoo=o("LayoutLMConfig"),zoo=o(" (LayoutLM model)"),Woo=l(),Xm=a("li"),rle=a("strong"),Qoo=o("layoutlmv2"),Hoo=o(" \u2014 "),$P=a("a"),Uoo=o("LayoutLMv2Config"),Joo=o(" (LayoutLMv2 model)"),Yoo=l(),zm=a("li"),tle=a("strong"),Koo=o("layoutlmv3"),Zoo=o(" \u2014 "),kP=a("a"),ero=o("LayoutLMv3Config"),oro=o(" (LayoutLMv3 model)"),rro=l(),Wm=a("li"),ale=a("strong"),tro=o("led"),aro=o(" \u2014 "),SP=a("a"),nro=o("LEDConfig"),sro=o(" (LED model)"),lro=l(),Qm=a("li"),nle=a("strong"),iro=o("levit"),dro=o(" \u2014 "),RP=a("a"),cro=o("LevitConfig"),fro=o(" (LeViT model)"),mro=l(),Hm=a("li"),sle=a("strong"),gro=o("longformer"),hro=o(" \u2014 "),PP=a("a"),pro=o("LongformerConfig"),_ro=o(" (Longformer model)"),uro=l(),Um=a("li"),lle=a("strong"),bro=o("longt5"),vro=o(" \u2014 "),BP=a("a"),Fro=o("LongT5Config"),Tro=o(" (LongT5 model)"),Mro=l(),Jm=a("li"),ile=a("strong"),Ero=o("luke"),Cro=o(" \u2014 "),IP=a("a"),wro=o("LukeConfig"),Aro=o(" (LUKE model)"),Lro=l(),Ym=a("li"),dle=a("strong"),yro=o("lxmert"),xro=o(" \u2014 "),NP=a("a"),$ro=o("LxmertConfig"),kro=o(" (LXMERT model)"),Sro=l(),Km=a("li"),cle=a("strong"),Rro=o("m2m_100"),Pro=o(" \u2014 "),qP=a("a"),Bro=o("M2M100Config"),Iro=o(" (M2M100 model)"),Nro=l(),Zm=a("li"),fle=a("strong"),qro=o("marian"),jro=o(" \u2014 "),jP=a("a"),Dro=o("MarianConfig"),Gro=o(" (Marian model)"),Oro=l(),eg=a("li"),mle=a("strong"),Vro=o("maskformer"),Xro=o(" \u2014 "),DP=a("a"),zro=o("MaskFormerConfig"),Wro=o(" (MaskFormer model)"),Qro=l(),og=a("li"),gle=a("strong"),Hro=o("mbart"),Uro=o(" \u2014 "),GP=a("a"),Jro=o("MBartConfig"),Yro=o(" (mBART model)"),Kro=l(),rg=a("li"),hle=a("strong"),Zro=o("mctct"),eto=o(" \u2014 "),OP=a("a"),oto=o("MCTCTConfig"),rto=o(" (M-CTC-T model)"),tto=l(),tg=a("li"),ple=a("strong"),ato=o("megatron-bert"),nto=o(" \u2014 "),VP=a("a"),sto=o("MegatronBertConfig"),lto=o(" (Megatron-BERT model)"),ito=l(),ag=a("li"),_le=a("strong"),dto=o("mobilebert"),cto=o(" \u2014 "),XP=a("a"),fto=o("MobileBertConfig"),mto=o(" (MobileBERT model)"),gto=l(),ng=a("li"),ule=a("strong"),hto=o("mobilevit"),pto=o(" \u2014 "),zP=a("a"),_to=o("MobileViTConfig"),uto=o(" (MobileViT model)"),bto=l(),sg=a("li"),ble=a("strong"),vto=o("mpnet"),Fto=o(" \u2014 "),WP=a("a"),Tto=o("MPNetConfig"),Mto=o(" (MPNet model)"),Eto=l(),lg=a("li"),vle=a("strong"),Cto=o("mt5"),wto=o(" \u2014 "),QP=a("a"),Ato=o("MT5Config"),Lto=o(" (MT5 model)"),yto=l(),ig=a("li"),Fle=a("strong"),xto=o("mvp"),$to=o(" \u2014 "),HP=a("a"),kto=o("MvpConfig"),Sto=o(" (MVP model)"),Rto=l(),dg=a("li"),Tle=a("strong"),Pto=o("nezha"),Bto=o(" \u2014 "),UP=a("a"),Ito=o("NezhaConfig"),Nto=o(" (Nezha model)"),qto=l(),cg=a("li"),Mle=a("strong"),jto=o("nystromformer"),Dto=o(" \u2014 "),JP=a("a"),Gto=o("NystromformerConfig"),Oto=o(" (Nystr\xF6mformer model)"),Vto=l(),fg=a("li"),Ele=a("strong"),Xto=o("openai-gpt"),zto=o(" \u2014 "),YP=a("a"),Wto=o("OpenAIGPTConfig"),Qto=o(" (OpenAI GPT model)"),Hto=l(),mg=a("li"),Cle=a("strong"),Uto=o("opt"),Jto=o(" \u2014 "),KP=a("a"),Yto=o("OPTConfig"),Kto=o(" (OPT model)"),Zto=l(),gg=a("li"),wle=a("strong"),eao=o("owlvit"),oao=o(" \u2014 "),ZP=a("a"),rao=o("OwlViTConfig"),tao=o(" (OWL-ViT model)"),aao=l(),hg=a("li"),Ale=a("strong"),nao=o("pegasus"),sao=o(" \u2014 "),eB=a("a"),lao=o("PegasusConfig"),iao=o(" (Pegasus model)"),dao=l(),pg=a("li"),Lle=a("strong"),cao=o("perceiver"),fao=o(" \u2014 "),oB=a("a"),mao=o("PerceiverConfig"),gao=o(" (Perceiver model)"),hao=l(),_g=a("li"),yle=a("strong"),pao=o("plbart"),_ao=o(" \u2014 "),rB=a("a"),uao=o("PLBartConfig"),bao=o(" (PLBart model)"),vao=l(),ug=a("li"),xle=a("strong"),Fao=o("poolformer"),Tao=o(" \u2014 "),tB=a("a"),Mao=o("PoolFormerConfig"),Eao=o(" (PoolFormer model)"),Cao=l(),bg=a("li"),$le=a("strong"),wao=o("prophetnet"),Aao=o(" \u2014 "),aB=a("a"),Lao=o("ProphetNetConfig"),yao=o(" (ProphetNet model)"),xao=l(),vg=a("li"),kle=a("strong"),$ao=o("qdqbert"),kao=o(" \u2014 "),nB=a("a"),Sao=o("QDQBertConfig"),Rao=o(" (QDQBert model)"),Pao=l(),Fg=a("li"),Sle=a("strong"),Bao=o("rag"),Iao=o(" \u2014 "),sB=a("a"),Nao=o("RagConfig"),qao=o(" (RAG model)"),jao=l(),Tg=a("li"),Rle=a("strong"),Dao=o("realm"),Gao=o(" \u2014 "),lB=a("a"),Oao=o("RealmConfig"),Vao=o(" (REALM model)"),Xao=l(),Mg=a("li"),Ple=a("strong"),zao=o("reformer"),Wao=o(" \u2014 "),iB=a("a"),Qao=o("ReformerConfig"),Hao=o(" (Reformer model)"),Uao=l(),Eg=a("li"),Ble=a("strong"),Jao=o("regnet"),Yao=o(" \u2014 "),dB=a("a"),Kao=o("RegNetConfig"),Zao=o(" (RegNet model)"),eno=l(),Cg=a("li"),Ile=a("strong"),ono=o("rembert"),rno=o(" \u2014 "),cB=a("a"),tno=o("RemBertConfig"),ano=o(" (RemBERT model)"),nno=l(),wg=a("li"),Nle=a("strong"),sno=o("resnet"),lno=o(" \u2014 "),fB=a("a"),ino=o("ResNetConfig"),dno=o(" (ResNet model)"),cno=l(),Ag=a("li"),qle=a("strong"),fno=o("retribert"),mno=o(" \u2014 "),mB=a("a"),gno=o("RetriBertConfig"),hno=o(" (RetriBERT model)"),pno=l(),Lg=a("li"),jle=a("strong"),_no=o("roberta"),uno=o(" \u2014 "),gB=a("a"),bno=o("RobertaConfig"),vno=o(" (RoBERTa model)"),Fno=l(),yg=a("li"),Dle=a("strong"),Tno=o("roformer"),Mno=o(" \u2014 "),hB=a("a"),Eno=o("RoFormerConfig"),Cno=o(" (RoFormer model)"),wno=l(),xg=a("li"),Gle=a("strong"),Ano=o("segformer"),Lno=o(" \u2014 "),pB=a("a"),yno=o("SegformerConfig"),xno=o(" (SegFormer model)"),$no=l(),$g=a("li"),Ole=a("strong"),kno=o("sew"),Sno=o(" \u2014 "),_B=a("a"),Rno=o("SEWConfig"),Pno=o(" (SEW model)"),Bno=l(),kg=a("li"),Vle=a("strong"),Ino=o("sew-d"),Nno=o(" \u2014 "),uB=a("a"),qno=o("SEWDConfig"),jno=o(" (SEW-D model)"),Dno=l(),Sg=a("li"),Xle=a("strong"),Gno=o("speech-encoder-decoder"),Ono=o(" \u2014 "),bB=a("a"),Vno=o("SpeechEncoderDecoderConfig"),Xno=o(" (Speech Encoder decoder model)"),zno=l(),Rg=a("li"),zle=a("strong"),Wno=o("speech_to_text"),Qno=o(" \u2014 "),vB=a("a"),Hno=o("Speech2TextConfig"),Uno=o(" (Speech2Text model)"),Jno=l(),Pg=a("li"),Wle=a("strong"),Yno=o("speech_to_text_2"),Kno=o(" \u2014 "),FB=a("a"),Zno=o("Speech2Text2Config"),eso=o(" (Speech2Text2 model)"),oso=l(),Bg=a("li"),Qle=a("strong"),rso=o("splinter"),tso=o(" \u2014 "),TB=a("a"),aso=o("SplinterConfig"),nso=o(" (Splinter model)"),sso=l(),Ig=a("li"),Hle=a("strong"),lso=o("squeezebert"),iso=o(" \u2014 "),MB=a("a"),dso=o("SqueezeBertConfig"),cso=o(" (SqueezeBERT model)"),fso=l(),Ng=a("li"),Ule=a("strong"),mso=o("swin"),gso=o(" \u2014 "),EB=a("a"),hso=o("SwinConfig"),pso=o(" (Swin Transformer model)"),_so=l(),qg=a("li"),Jle=a("strong"),uso=o("swinv2"),bso=o(" \u2014 "),CB=a("a"),vso=o("Swinv2Config"),Fso=o(" (Swin Transformer V2 model)"),Tso=l(),jg=a("li"),Yle=a("strong"),Mso=o("t5"),Eso=o(" \u2014 "),wB=a("a"),Cso=o("T5Config"),wso=o(" (T5 model)"),Aso=l(),Dg=a("li"),Kle=a("strong"),Lso=o("tapas"),yso=o(" \u2014 "),AB=a("a"),xso=o("TapasConfig"),$so=o(" (TAPAS model)"),kso=l(),Gg=a("li"),Zle=a("strong"),Sso=o("trajectory_transformer"),Rso=o(" \u2014 "),LB=a("a"),Pso=o("TrajectoryTransformerConfig"),Bso=o(" (Trajectory Transformer model)"),Iso=l(),Og=a("li"),eie=a("strong"),Nso=o("transfo-xl"),qso=o(" \u2014 "),yB=a("a"),jso=o("TransfoXLConfig"),Dso=o(" (Transformer-XL model)"),Gso=l(),Vg=a("li"),oie=a("strong"),Oso=o("trocr"),Vso=o(" \u2014 "),xB=a("a"),Xso=o("TrOCRConfig"),zso=o(" (TrOCR model)"),Wso=l(),Xg=a("li"),rie=a("strong"),Qso=o("unispeech"),Hso=o(" \u2014 "),$B=a("a"),Uso=o("UniSpeechConfig"),Jso=o(" (UniSpeech model)"),Yso=l(),zg=a("li"),tie=a("strong"),Kso=o("unispeech-sat"),Zso=o(" \u2014 "),kB=a("a"),elo=o("UniSpeechSatConfig"),olo=o(" (UniSpeechSat model)"),rlo=l(),Wg=a("li"),aie=a("strong"),tlo=o("van"),alo=o(" \u2014 "),SB=a("a"),nlo=o("VanConfig"),slo=o(" (VAN model)"),llo=l(),Qg=a("li"),nie=a("strong"),ilo=o("videomae"),dlo=o(" \u2014 "),RB=a("a"),clo=o("VideoMAEConfig"),flo=o(" (VideoMAE model)"),mlo=l(),Hg=a("li"),sie=a("strong"),glo=o("vilt"),hlo=o(" \u2014 "),PB=a("a"),plo=o("ViltConfig"),_lo=o(" (ViLT model)"),ulo=l(),Ug=a("li"),lie=a("strong"),blo=o("vision-encoder-decoder"),vlo=o(" \u2014 "),BB=a("a"),Flo=o("VisionEncoderDecoderConfig"),Tlo=o(" (Vision Encoder decoder model)"),Mlo=l(),Jg=a("li"),iie=a("strong"),Elo=o("vision-text-dual-encoder"),Clo=o(" \u2014 "),IB=a("a"),wlo=o("VisionTextDualEncoderConfig"),Alo=o(" (VisionTextDualEncoder model)"),Llo=l(),Yg=a("li"),die=a("strong"),ylo=o("visual_bert"),xlo=o(" \u2014 "),NB=a("a"),$lo=o("VisualBertConfig"),klo=o(" (VisualBERT model)"),Slo=l(),Kg=a("li"),cie=a("strong"),Rlo=o("vit"),Plo=o(" \u2014 "),qB=a("a"),Blo=o("ViTConfig"),Ilo=o(" (ViT model)"),Nlo=l(),Zg=a("li"),fie=a("strong"),qlo=o("vit_mae"),jlo=o(" \u2014 "),jB=a("a"),Dlo=o("ViTMAEConfig"),Glo=o(" (ViTMAE model)"),Olo=l(),eh=a("li"),mie=a("strong"),Vlo=o("wav2vec2"),Xlo=o(" \u2014 "),DB=a("a"),zlo=o("Wav2Vec2Config"),Wlo=o(" (Wav2Vec2 model)"),Qlo=l(),oh=a("li"),gie=a("strong"),Hlo=o("wav2vec2-conformer"),Ulo=o(" \u2014 "),GB=a("a"),Jlo=o("Wav2Vec2ConformerConfig"),Ylo=o(" (Wav2Vec2-Conformer model)"),Klo=l(),rh=a("li"),hie=a("strong"),Zlo=o("wavlm"),eio=o(" \u2014 "),OB=a("a"),oio=o("WavLMConfig"),rio=o(" (WavLM model)"),tio=l(),th=a("li"),pie=a("strong"),aio=o("xglm"),nio=o(" \u2014 "),VB=a("a"),sio=o("XGLMConfig"),lio=o(" (XGLM model)"),iio=l(),ah=a("li"),_ie=a("strong"),dio=o("xlm"),cio=o(" \u2014 "),XB=a("a"),fio=o("XLMConfig"),mio=o(" (XLM model)"),gio=l(),nh=a("li"),uie=a("strong"),hio=o("xlm-prophetnet"),pio=o(" \u2014 "),zB=a("a"),_io=o("XLMProphetNetConfig"),uio=o(" (XLM-ProphetNet model)"),bio=l(),sh=a("li"),bie=a("strong"),vio=o("xlm-roberta"),Fio=o(" \u2014 "),WB=a("a"),Tio=o("XLMRobertaConfig"),Mio=o(" (XLM-RoBERTa model)"),Eio=l(),lh=a("li"),vie=a("strong"),Cio=o("xlm-roberta-xl"),wio=o(" \u2014 "),QB=a("a"),Aio=o("XLMRobertaXLConfig"),Lio=o(" (XLM-RoBERTa-XL model)"),yio=l(),ih=a("li"),Fie=a("strong"),xio=o("xlnet"),$io=o(" \u2014 "),HB=a("a"),kio=o("XLNetConfig"),Sio=o(" (XLNet model)"),Rio=l(),dh=a("li"),Tie=a("strong"),Pio=o("yolos"),Bio=o(" \u2014 "),UB=a("a"),Iio=o("YolosConfig"),Nio=o(" (YOLOS model)"),qio=l(),ch=a("li"),Mie=a("strong"),jio=o("yoso"),Dio=o(" \u2014 "),JB=a("a"),Gio=o("YosoConfig"),Oio=o(" (YOSO model)"),Vio=l(),F(fh.$$.fragment),Xio=l(),mh=a("div"),F(ey.$$.fragment),zio=l(),Eie=a("p"),Wio=o("Register a new configuration for this class."),WWe=l(),Wi=a("h2"),gh=a("a"),Cie=a("span"),F(oy.$$.fragment),Qio=l(),wie=a("span"),Hio=o("AutoTokenizer"),QWe=l(),xo=a("div"),F(ry.$$.fragment),Uio=l(),ty=a("p"),Jio=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),YB=a("a"),Yio=o("AutoTokenizer.from_pretrained()"),Kio=o(" class method."),Zio=l(),ay=a("p"),edo=o("This class cannot be instantiated directly using "),Aie=a("code"),odo=o("__init__()"),rdo=o(" (throws an error)."),tdo=l(),kr=a("div"),F(ny.$$.fragment),ado=l(),Lie=a("p"),ndo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),sdo=l(),qa=a("p"),ldo=o("The tokenizer class to instantiate is selected based on the "),yie=a("code"),ido=o("model_type"),ddo=o(` property of the config object (either
passed as an argument or loaded from `),xie=a("code"),cdo=o("pretrained_model_name_or_path"),fdo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ie=a("code"),mdo=o("pretrained_model_name_or_path"),gdo=o(":"),hdo=l(),k=a("ul"),zn=a("li"),kie=a("strong"),pdo=o("albert"),_do=o(" \u2014 "),KB=a("a"),udo=o("AlbertTokenizer"),bdo=o(" or "),ZB=a("a"),vdo=o("AlbertTokenizerFast"),Fdo=o(" (ALBERT model)"),Tdo=l(),Wn=a("li"),Sie=a("strong"),Mdo=o("bart"),Edo=o(" \u2014 "),eI=a("a"),Cdo=o("BartTokenizer"),wdo=o(" or "),oI=a("a"),Ado=o("BartTokenizerFast"),Ldo=o(" (BART model)"),ydo=l(),Qn=a("li"),Rie=a("strong"),xdo=o("barthez"),$do=o(" \u2014 "),rI=a("a"),kdo=o("BarthezTokenizer"),Sdo=o(" or "),tI=a("a"),Rdo=o("BarthezTokenizerFast"),Pdo=o(" (BARThez model)"),Bdo=l(),hh=a("li"),Pie=a("strong"),Ido=o("bartpho"),Ndo=o(" \u2014 "),aI=a("a"),qdo=o("BartphoTokenizer"),jdo=o(" (BARTpho model)"),Ddo=l(),Hn=a("li"),Bie=a("strong"),Gdo=o("bert"),Odo=o(" \u2014 "),nI=a("a"),Vdo=o("BertTokenizer"),Xdo=o(" or "),sI=a("a"),zdo=o("BertTokenizerFast"),Wdo=o(" (BERT model)"),Qdo=l(),ph=a("li"),Iie=a("strong"),Hdo=o("bert-generation"),Udo=o(" \u2014 "),lI=a("a"),Jdo=o("BertGenerationTokenizer"),Ydo=o(" (Bert Generation model)"),Kdo=l(),_h=a("li"),Nie=a("strong"),Zdo=o("bert-japanese"),eco=o(" \u2014 "),iI=a("a"),oco=o("BertJapaneseTokenizer"),rco=o(" (BertJapanese model)"),tco=l(),uh=a("li"),qie=a("strong"),aco=o("bertweet"),nco=o(" \u2014 "),dI=a("a"),sco=o("BertweetTokenizer"),lco=o(" (BERTweet model)"),ico=l(),Un=a("li"),jie=a("strong"),dco=o("big_bird"),cco=o(" \u2014 "),cI=a("a"),fco=o("BigBirdTokenizer"),mco=o(" or "),fI=a("a"),gco=o("BigBirdTokenizerFast"),hco=o(" (BigBird model)"),pco=l(),Jn=a("li"),Die=a("strong"),_co=o("bigbird_pegasus"),uco=o(" \u2014 "),mI=a("a"),bco=o("PegasusTokenizer"),vco=o(" or "),gI=a("a"),Fco=o("PegasusTokenizerFast"),Tco=o(" (BigBird-Pegasus model)"),Mco=l(),Yn=a("li"),Gie=a("strong"),Eco=o("blenderbot"),Cco=o(" \u2014 "),hI=a("a"),wco=o("BlenderbotTokenizer"),Aco=o(" or "),pI=a("a"),Lco=o("BlenderbotTokenizerFast"),yco=o(" (Blenderbot model)"),xco=l(),bh=a("li"),Oie=a("strong"),$co=o("blenderbot-small"),kco=o(" \u2014 "),_I=a("a"),Sco=o("BlenderbotSmallTokenizer"),Rco=o(" (BlenderbotSmall model)"),Pco=l(),vh=a("li"),Vie=a("strong"),Bco=o("bloom"),Ico=o(" \u2014 "),uI=a("a"),Nco=o("BloomTokenizerFast"),qco=o(" (BLOOM model)"),jco=l(),Fh=a("li"),Xie=a("strong"),Dco=o("byt5"),Gco=o(" \u2014 "),bI=a("a"),Oco=o("ByT5Tokenizer"),Vco=o(" (ByT5 model)"),Xco=l(),Kn=a("li"),zie=a("strong"),zco=o("camembert"),Wco=o(" \u2014 "),vI=a("a"),Qco=o("CamembertTokenizer"),Hco=o(" or "),FI=a("a"),Uco=o("CamembertTokenizerFast"),Jco=o(" (CamemBERT model)"),Yco=l(),Th=a("li"),Wie=a("strong"),Kco=o("canine"),Zco=o(" \u2014 "),TI=a("a"),efo=o("CanineTokenizer"),ofo=o(" (CANINE model)"),rfo=l(),Zn=a("li"),Qie=a("strong"),tfo=o("clip"),afo=o(" \u2014 "),MI=a("a"),nfo=o("CLIPTokenizer"),sfo=o(" or "),EI=a("a"),lfo=o("CLIPTokenizerFast"),ifo=o(" (CLIP model)"),dfo=l(),es=a("li"),Hie=a("strong"),cfo=o("codegen"),ffo=o(" \u2014 "),CI=a("a"),mfo=o("CodeGenTokenizer"),gfo=o(" or "),wI=a("a"),hfo=o("CodeGenTokenizerFast"),pfo=o(" (CodeGen model)"),_fo=l(),os=a("li"),Uie=a("strong"),ufo=o("convbert"),bfo=o(" \u2014 "),AI=a("a"),vfo=o("ConvBertTokenizer"),Ffo=o(" or "),LI=a("a"),Tfo=o("ConvBertTokenizerFast"),Mfo=o(" (ConvBERT model)"),Efo=l(),rs=a("li"),Jie=a("strong"),Cfo=o("cpm"),wfo=o(" \u2014 "),yI=a("a"),Afo=o("CpmTokenizer"),Lfo=o(" or "),xI=a("a"),yfo=o("CpmTokenizerFast"),xfo=o(" (CPM model)"),$fo=l(),Mh=a("li"),Yie=a("strong"),kfo=o("ctrl"),Sfo=o(" \u2014 "),$I=a("a"),Rfo=o("CTRLTokenizer"),Pfo=o(" (CTRL model)"),Bfo=l(),ts=a("li"),Kie=a("strong"),Ifo=o("data2vec-text"),Nfo=o(" \u2014 "),kI=a("a"),qfo=o("RobertaTokenizer"),jfo=o(" or "),SI=a("a"),Dfo=o("RobertaTokenizerFast"),Gfo=o(" (Data2VecText model)"),Ofo=l(),as=a("li"),Zie=a("strong"),Vfo=o("deberta"),Xfo=o(" \u2014 "),RI=a("a"),zfo=o("DebertaTokenizer"),Wfo=o(" or "),PI=a("a"),Qfo=o("DebertaTokenizerFast"),Hfo=o(" (DeBERTa model)"),Ufo=l(),ns=a("li"),ede=a("strong"),Jfo=o("deberta-v2"),Yfo=o(" \u2014 "),BI=a("a"),Kfo=o("DebertaV2Tokenizer"),Zfo=o(" or "),II=a("a"),emo=o("DebertaV2TokenizerFast"),omo=o(" (DeBERTa-v2 model)"),rmo=l(),ss=a("li"),ode=a("strong"),tmo=o("distilbert"),amo=o(" \u2014 "),NI=a("a"),nmo=o("DistilBertTokenizer"),smo=o(" or "),qI=a("a"),lmo=o("DistilBertTokenizerFast"),imo=o(" (DistilBERT model)"),dmo=l(),ls=a("li"),rde=a("strong"),cmo=o("dpr"),fmo=o(" \u2014 "),jI=a("a"),mmo=o("DPRQuestionEncoderTokenizer"),gmo=o(" or "),DI=a("a"),hmo=o("DPRQuestionEncoderTokenizerFast"),pmo=o(" (DPR model)"),_mo=l(),is=a("li"),tde=a("strong"),umo=o("electra"),bmo=o(" \u2014 "),GI=a("a"),vmo=o("ElectraTokenizer"),Fmo=o(" or "),OI=a("a"),Tmo=o("ElectraTokenizerFast"),Mmo=o(" (ELECTRA model)"),Emo=l(),Eh=a("li"),ade=a("strong"),Cmo=o("flaubert"),wmo=o(" \u2014 "),VI=a("a"),Amo=o("FlaubertTokenizer"),Lmo=o(" (FlauBERT model)"),ymo=l(),ds=a("li"),nde=a("strong"),xmo=o("fnet"),$mo=o(" \u2014 "),XI=a("a"),kmo=o("FNetTokenizer"),Smo=o(" or "),zI=a("a"),Rmo=o("FNetTokenizerFast"),Pmo=o(" (FNet model)"),Bmo=l(),Ch=a("li"),sde=a("strong"),Imo=o("fsmt"),Nmo=o(" \u2014 "),WI=a("a"),qmo=o("FSMTTokenizer"),jmo=o(" (FairSeq Machine-Translation model)"),Dmo=l(),cs=a("li"),lde=a("strong"),Gmo=o("funnel"),Omo=o(" \u2014 "),QI=a("a"),Vmo=o("FunnelTokenizer"),Xmo=o(" or "),HI=a("a"),zmo=o("FunnelTokenizerFast"),Wmo=o(" (Funnel Transformer model)"),Qmo=l(),fs=a("li"),ide=a("strong"),Hmo=o("gpt2"),Umo=o(" \u2014 "),UI=a("a"),Jmo=o("GPT2Tokenizer"),Ymo=o(" or "),JI=a("a"),Kmo=o("GPT2TokenizerFast"),Zmo=o(" (OpenAI GPT-2 model)"),ego=l(),ms=a("li"),dde=a("strong"),ogo=o("gpt_neo"),rgo=o(" \u2014 "),YI=a("a"),tgo=o("GPT2Tokenizer"),ago=o(" or "),KI=a("a"),ngo=o("GPT2TokenizerFast"),sgo=o(" (GPT Neo model)"),lgo=l(),wh=a("li"),cde=a("strong"),igo=o("gpt_neox"),dgo=o(" \u2014 "),ZI=a("a"),cgo=o("GPTNeoXTokenizerFast"),fgo=o(" (GPT NeoX model)"),mgo=l(),gs=a("li"),fde=a("strong"),ggo=o("gptj"),hgo=o(" \u2014 "),eN=a("a"),pgo=o("GPT2Tokenizer"),_go=o(" or "),oN=a("a"),ugo=o("GPT2TokenizerFast"),bgo=o(" (GPT-J model)"),vgo=l(),hs=a("li"),mde=a("strong"),Fgo=o("groupvit"),Tgo=o(" \u2014 "),rN=a("a"),Mgo=o("CLIPTokenizer"),Ego=o(" or "),tN=a("a"),Cgo=o("CLIPTokenizerFast"),wgo=o(" (GroupViT model)"),Ago=l(),ps=a("li"),gde=a("strong"),Lgo=o("herbert"),ygo=o(" \u2014 "),aN=a("a"),xgo=o("HerbertTokenizer"),$go=o(" or "),nN=a("a"),kgo=o("HerbertTokenizerFast"),Sgo=o(" (HerBERT model)"),Rgo=l(),Ah=a("li"),hde=a("strong"),Pgo=o("hubert"),Bgo=o(" \u2014 "),sN=a("a"),Igo=o("Wav2Vec2CTCTokenizer"),Ngo=o(" (Hubert model)"),qgo=l(),_s=a("li"),pde=a("strong"),jgo=o("ibert"),Dgo=o(" \u2014 "),lN=a("a"),Ggo=o("RobertaTokenizer"),Ogo=o(" or "),iN=a("a"),Vgo=o("RobertaTokenizerFast"),Xgo=o(" (I-BERT model)"),zgo=l(),us=a("li"),_de=a("strong"),Wgo=o("layoutlm"),Qgo=o(" \u2014 "),dN=a("a"),Hgo=o("LayoutLMTokenizer"),Ugo=o(" or "),cN=a("a"),Jgo=o("LayoutLMTokenizerFast"),Ygo=o(" (LayoutLM model)"),Kgo=l(),bs=a("li"),ude=a("strong"),Zgo=o("layoutlmv2"),eho=o(" \u2014 "),fN=a("a"),oho=o("LayoutLMv2Tokenizer"),rho=o(" or "),mN=a("a"),tho=o("LayoutLMv2TokenizerFast"),aho=o(" (LayoutLMv2 model)"),nho=l(),vs=a("li"),bde=a("strong"),sho=o("layoutlmv3"),lho=o(" \u2014 "),gN=a("a"),iho=o("LayoutLMv3Tokenizer"),dho=o(" or "),hN=a("a"),cho=o("LayoutLMv3TokenizerFast"),fho=o(" (LayoutLMv3 model)"),mho=l(),Fs=a("li"),vde=a("strong"),gho=o("layoutxlm"),hho=o(" \u2014 "),pN=a("a"),pho=o("LayoutXLMTokenizer"),_ho=o(" or "),_N=a("a"),uho=o("LayoutXLMTokenizerFast"),bho=o(" (LayoutXLM model)"),vho=l(),Ts=a("li"),Fde=a("strong"),Fho=o("led"),Tho=o(" \u2014 "),uN=a("a"),Mho=o("LEDTokenizer"),Eho=o(" or "),bN=a("a"),Cho=o("LEDTokenizerFast"),who=o(" (LED model)"),Aho=l(),Ms=a("li"),Tde=a("strong"),Lho=o("longformer"),yho=o(" \u2014 "),vN=a("a"),xho=o("LongformerTokenizer"),$ho=o(" or "),FN=a("a"),kho=o("LongformerTokenizerFast"),Sho=o(" (Longformer model)"),Rho=l(),Es=a("li"),Mde=a("strong"),Pho=o("longt5"),Bho=o(" \u2014 "),TN=a("a"),Iho=o("T5Tokenizer"),Nho=o(" or "),MN=a("a"),qho=o("T5TokenizerFast"),jho=o(" (LongT5 model)"),Dho=l(),Lh=a("li"),Ede=a("strong"),Gho=o("luke"),Oho=o(" \u2014 "),EN=a("a"),Vho=o("LukeTokenizer"),Xho=o(" (LUKE model)"),zho=l(),Cs=a("li"),Cde=a("strong"),Who=o("lxmert"),Qho=o(" \u2014 "),CN=a("a"),Hho=o("LxmertTokenizer"),Uho=o(" or "),wN=a("a"),Jho=o("LxmertTokenizerFast"),Yho=o(" (LXMERT model)"),Kho=l(),yh=a("li"),wde=a("strong"),Zho=o("m2m_100"),epo=o(" \u2014 "),AN=a("a"),opo=o("M2M100Tokenizer"),rpo=o(" (M2M100 model)"),tpo=l(),xh=a("li"),Ade=a("strong"),apo=o("marian"),npo=o(" \u2014 "),LN=a("a"),spo=o("MarianTokenizer"),lpo=o(" (Marian model)"),ipo=l(),ws=a("li"),Lde=a("strong"),dpo=o("mbart"),cpo=o(" \u2014 "),yN=a("a"),fpo=o("MBartTokenizer"),mpo=o(" or "),xN=a("a"),gpo=o("MBartTokenizerFast"),hpo=o(" (mBART model)"),ppo=l(),As=a("li"),yde=a("strong"),_po=o("mbart50"),upo=o(" \u2014 "),$N=a("a"),bpo=o("MBart50Tokenizer"),vpo=o(" or "),kN=a("a"),Fpo=o("MBart50TokenizerFast"),Tpo=o(" (mBART-50 model)"),Mpo=l(),Ls=a("li"),xde=a("strong"),Epo=o("megatron-bert"),Cpo=o(" \u2014 "),SN=a("a"),wpo=o("BertTokenizer"),Apo=o(" or "),RN=a("a"),Lpo=o("BertTokenizerFast"),ypo=o(" (Megatron-BERT model)"),xpo=l(),$h=a("li"),$de=a("strong"),$po=o("mluke"),kpo=o(" \u2014 "),PN=a("a"),Spo=o("MLukeTokenizer"),Rpo=o(" (mLUKE model)"),Ppo=l(),ys=a("li"),kde=a("strong"),Bpo=o("mobilebert"),Ipo=o(" \u2014 "),BN=a("a"),Npo=o("MobileBertTokenizer"),qpo=o(" or "),IN=a("a"),jpo=o("MobileBertTokenizerFast"),Dpo=o(" (MobileBERT model)"),Gpo=l(),xs=a("li"),Sde=a("strong"),Opo=o("mpnet"),Vpo=o(" \u2014 "),NN=a("a"),Xpo=o("MPNetTokenizer"),zpo=o(" or "),qN=a("a"),Wpo=o("MPNetTokenizerFast"),Qpo=o(" (MPNet model)"),Hpo=l(),$s=a("li"),Rde=a("strong"),Upo=o("mt5"),Jpo=o(" \u2014 "),jN=a("a"),Ypo=o("MT5Tokenizer"),Kpo=o(" or "),DN=a("a"),Zpo=o("MT5TokenizerFast"),e_o=o(" (MT5 model)"),o_o=l(),ks=a("li"),Pde=a("strong"),r_o=o("mvp"),t_o=o(" \u2014 "),GN=a("a"),a_o=o("MvpTokenizer"),n_o=o(" or "),ON=a("a"),s_o=o("MvpTokenizerFast"),l_o=o(" (MVP model)"),i_o=l(),Ss=a("li"),Bde=a("strong"),d_o=o("nezha"),c_o=o(" \u2014 "),VN=a("a"),f_o=o("BertTokenizer"),m_o=o(" or "),XN=a("a"),g_o=o("BertTokenizerFast"),h_o=o(" (Nezha model)"),p_o=l(),Rs=a("li"),Ide=a("strong"),__o=o("nllb"),u_o=o(" \u2014 "),zN=a("a"),b_o=o("NllbTokenizer"),v_o=o(" or "),WN=a("a"),F_o=o("NllbTokenizerFast"),T_o=o(" (NLLB model)"),M_o=l(),Ps=a("li"),Nde=a("strong"),E_o=o("nystromformer"),C_o=o(" \u2014 "),QN=a("a"),w_o=o("AlbertTokenizer"),A_o=o(" or "),HN=a("a"),L_o=o("AlbertTokenizerFast"),y_o=o(" (Nystr\xF6mformer model)"),x_o=l(),Bs=a("li"),qde=a("strong"),$_o=o("openai-gpt"),k_o=o(" \u2014 "),UN=a("a"),S_o=o("OpenAIGPTTokenizer"),R_o=o(" or "),JN=a("a"),P_o=o("OpenAIGPTTokenizerFast"),B_o=o(" (OpenAI GPT model)"),I_o=l(),kh=a("li"),jde=a("strong"),N_o=o("opt"),q_o=o(" \u2014 "),YN=a("a"),j_o=o("GPT2Tokenizer"),D_o=o(" (OPT model)"),G_o=l(),Is=a("li"),Dde=a("strong"),O_o=o("owlvit"),V_o=o(" \u2014 "),KN=a("a"),X_o=o("CLIPTokenizer"),z_o=o(" or "),ZN=a("a"),W_o=o("CLIPTokenizerFast"),Q_o=o(" (OWL-ViT model)"),H_o=l(),Ns=a("li"),Gde=a("strong"),U_o=o("pegasus"),J_o=o(" \u2014 "),eq=a("a"),Y_o=o("PegasusTokenizer"),K_o=o(" or "),oq=a("a"),Z_o=o("PegasusTokenizerFast"),euo=o(" (Pegasus model)"),ouo=l(),Sh=a("li"),Ode=a("strong"),ruo=o("perceiver"),tuo=o(" \u2014 "),rq=a("a"),auo=o("PerceiverTokenizer"),nuo=o(" (Perceiver model)"),suo=l(),Rh=a("li"),Vde=a("strong"),luo=o("phobert"),iuo=o(" \u2014 "),tq=a("a"),duo=o("PhobertTokenizer"),cuo=o(" (PhoBERT model)"),fuo=l(),Ph=a("li"),Xde=a("strong"),muo=o("plbart"),guo=o(" \u2014 "),aq=a("a"),huo=o("PLBartTokenizer"),puo=o(" (PLBart model)"),_uo=l(),Bh=a("li"),zde=a("strong"),uuo=o("prophetnet"),buo=o(" \u2014 "),nq=a("a"),vuo=o("ProphetNetTokenizer"),Fuo=o(" (ProphetNet model)"),Tuo=l(),qs=a("li"),Wde=a("strong"),Muo=o("qdqbert"),Euo=o(" \u2014 "),sq=a("a"),Cuo=o("BertTokenizer"),wuo=o(" or "),lq=a("a"),Auo=o("BertTokenizerFast"),Luo=o(" (QDQBert model)"),yuo=l(),Ih=a("li"),Qde=a("strong"),xuo=o("rag"),$uo=o(" \u2014 "),iq=a("a"),kuo=o("RagTokenizer"),Suo=o(" (RAG model)"),Ruo=l(),js=a("li"),Hde=a("strong"),Puo=o("realm"),Buo=o(" \u2014 "),dq=a("a"),Iuo=o("RealmTokenizer"),Nuo=o(" or "),cq=a("a"),quo=o("RealmTokenizerFast"),juo=o(" (REALM model)"),Duo=l(),Ds=a("li"),Ude=a("strong"),Guo=o("reformer"),Ouo=o(" \u2014 "),fq=a("a"),Vuo=o("ReformerTokenizer"),Xuo=o(" or "),mq=a("a"),zuo=o("ReformerTokenizerFast"),Wuo=o(" (Reformer model)"),Quo=l(),Gs=a("li"),Jde=a("strong"),Huo=o("rembert"),Uuo=o(" \u2014 "),gq=a("a"),Juo=o("RemBertTokenizer"),Yuo=o(" or "),hq=a("a"),Kuo=o("RemBertTokenizerFast"),Zuo=o(" (RemBERT model)"),e7o=l(),Os=a("li"),Yde=a("strong"),o7o=o("retribert"),r7o=o(" \u2014 "),pq=a("a"),t7o=o("RetriBertTokenizer"),a7o=o(" or "),_q=a("a"),n7o=o("RetriBertTokenizerFast"),s7o=o(" (RetriBERT model)"),l7o=l(),Vs=a("li"),Kde=a("strong"),i7o=o("roberta"),d7o=o(" \u2014 "),uq=a("a"),c7o=o("RobertaTokenizer"),f7o=o(" or "),bq=a("a"),m7o=o("RobertaTokenizerFast"),g7o=o(" (RoBERTa model)"),h7o=l(),Xs=a("li"),Zde=a("strong"),p7o=o("roformer"),_7o=o(" \u2014 "),vq=a("a"),u7o=o("RoFormerTokenizer"),b7o=o(" or "),Fq=a("a"),v7o=o("RoFormerTokenizerFast"),F7o=o(" (RoFormer model)"),T7o=l(),Nh=a("li"),ece=a("strong"),M7o=o("speech_to_text"),E7o=o(" \u2014 "),Tq=a("a"),C7o=o("Speech2TextTokenizer"),w7o=o(" (Speech2Text model)"),A7o=l(),qh=a("li"),oce=a("strong"),L7o=o("speech_to_text_2"),y7o=o(" \u2014 "),Mq=a("a"),x7o=o("Speech2Text2Tokenizer"),$7o=o(" (Speech2Text2 model)"),k7o=l(),zs=a("li"),rce=a("strong"),S7o=o("splinter"),R7o=o(" \u2014 "),Eq=a("a"),P7o=o("SplinterTokenizer"),B7o=o(" or "),Cq=a("a"),I7o=o("SplinterTokenizerFast"),N7o=o(" (Splinter model)"),q7o=l(),Ws=a("li"),tce=a("strong"),j7o=o("squeezebert"),D7o=o(" \u2014 "),wq=a("a"),G7o=o("SqueezeBertTokenizer"),O7o=o(" or "),Aq=a("a"),V7o=o("SqueezeBertTokenizerFast"),X7o=o(" (SqueezeBERT model)"),z7o=l(),Qs=a("li"),ace=a("strong"),W7o=o("t5"),Q7o=o(" \u2014 "),Lq=a("a"),H7o=o("T5Tokenizer"),U7o=o(" or "),yq=a("a"),J7o=o("T5TokenizerFast"),Y7o=o(" (T5 model)"),K7o=l(),jh=a("li"),nce=a("strong"),Z7o=o("tapas"),e1o=o(" \u2014 "),xq=a("a"),o1o=o("TapasTokenizer"),r1o=o(" (TAPAS model)"),t1o=l(),Dh=a("li"),sce=a("strong"),a1o=o("tapex"),n1o=o(" \u2014 "),$q=a("a"),s1o=o("TapexTokenizer"),l1o=o(" (TAPEX model)"),i1o=l(),Gh=a("li"),lce=a("strong"),d1o=o("transfo-xl"),c1o=o(" \u2014 "),kq=a("a"),f1o=o("TransfoXLTokenizer"),m1o=o(" (Transformer-XL model)"),g1o=l(),Hs=a("li"),ice=a("strong"),h1o=o("vilt"),p1o=o(" \u2014 "),Sq=a("a"),_1o=o("BertTokenizer"),u1o=o(" or "),Rq=a("a"),b1o=o("BertTokenizerFast"),v1o=o(" (ViLT model)"),F1o=l(),Us=a("li"),dce=a("strong"),T1o=o("visual_bert"),M1o=o(" \u2014 "),Pq=a("a"),E1o=o("BertTokenizer"),C1o=o(" or "),Bq=a("a"),w1o=o("BertTokenizerFast"),A1o=o(" (VisualBERT model)"),L1o=l(),Oh=a("li"),cce=a("strong"),y1o=o("wav2vec2"),x1o=o(" \u2014 "),Iq=a("a"),$1o=o("Wav2Vec2CTCTokenizer"),k1o=o(" (Wav2Vec2 model)"),S1o=l(),Vh=a("li"),fce=a("strong"),R1o=o("wav2vec2-conformer"),P1o=o(" \u2014 "),Nq=a("a"),B1o=o("Wav2Vec2CTCTokenizer"),I1o=o(" (Wav2Vec2-Conformer model)"),N1o=l(),Xh=a("li"),mce=a("strong"),q1o=o("wav2vec2_phoneme"),j1o=o(" \u2014 "),qq=a("a"),D1o=o("Wav2Vec2PhonemeCTCTokenizer"),G1o=o(" (Wav2Vec2Phoneme model)"),O1o=l(),Js=a("li"),gce=a("strong"),V1o=o("xglm"),X1o=o(" \u2014 "),jq=a("a"),z1o=o("XGLMTokenizer"),W1o=o(" or "),Dq=a("a"),Q1o=o("XGLMTokenizerFast"),H1o=o(" (XGLM model)"),U1o=l(),zh=a("li"),hce=a("strong"),J1o=o("xlm"),Y1o=o(" \u2014 "),Gq=a("a"),K1o=o("XLMTokenizer"),Z1o=o(" (XLM model)"),e2o=l(),Wh=a("li"),pce=a("strong"),o2o=o("xlm-prophetnet"),r2o=o(" \u2014 "),Oq=a("a"),t2o=o("XLMProphetNetTokenizer"),a2o=o(" (XLM-ProphetNet model)"),n2o=l(),Ys=a("li"),_ce=a("strong"),s2o=o("xlm-roberta"),l2o=o(" \u2014 "),Vq=a("a"),i2o=o("XLMRobertaTokenizer"),d2o=o(" or "),Xq=a("a"),c2o=o("XLMRobertaTokenizerFast"),f2o=o(" (XLM-RoBERTa model)"),m2o=l(),Ks=a("li"),uce=a("strong"),g2o=o("xlm-roberta-xl"),h2o=o(" \u2014 "),zq=a("a"),p2o=o("RobertaTokenizer"),_2o=o(" or "),Wq=a("a"),u2o=o("RobertaTokenizerFast"),b2o=o(" (XLM-RoBERTa-XL model)"),v2o=l(),Zs=a("li"),bce=a("strong"),F2o=o("xlnet"),T2o=o(" \u2014 "),Qq=a("a"),M2o=o("XLNetTokenizer"),E2o=o(" or "),Hq=a("a"),C2o=o("XLNetTokenizerFast"),w2o=o(" (XLNet model)"),A2o=l(),el=a("li"),vce=a("strong"),L2o=o("yoso"),y2o=o(" \u2014 "),Uq=a("a"),x2o=o("AlbertTokenizer"),$2o=o(" or "),Jq=a("a"),k2o=o("AlbertTokenizerFast"),S2o=o(" (YOSO model)"),R2o=l(),F(Qh.$$.fragment),P2o=l(),Hh=a("div"),F(sy.$$.fragment),B2o=l(),Fce=a("p"),I2o=o("Register a new tokenizer in this mapping."),HWe=l(),Qi=a("h2"),Uh=a("a"),Tce=a("span"),F(ly.$$.fragment),N2o=l(),Mce=a("span"),q2o=o("AutoFeatureExtractor"),UWe=l(),$o=a("div"),F(iy.$$.fragment),j2o=l(),dy=a("p"),D2o=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),Yq=a("a"),G2o=o("AutoFeatureExtractor.from_pretrained()"),O2o=o(" class method."),V2o=l(),cy=a("p"),X2o=o("This class cannot be instantiated directly using "),Ece=a("code"),z2o=o("__init__()"),W2o=o(" (throws an error)."),Q2o=l(),Ue=a("div"),F(fy.$$.fragment),H2o=l(),Cce=a("p"),U2o=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),J2o=l(),ja=a("p"),Y2o=o("The feature extractor class to instantiate is selected based on the "),wce=a("code"),K2o=o("model_type"),Z2o=o(` property of the config object
(either passed as an argument or loaded from `),Ace=a("code"),ebo=o("pretrained_model_name_or_path"),obo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lce=a("code"),rbo=o("pretrained_model_name_or_path"),tbo=o(":"),abo=l(),H=a("ul"),Jh=a("li"),yce=a("strong"),nbo=o("beit"),sbo=o(" \u2014 "),Kq=a("a"),lbo=o("BeitFeatureExtractor"),ibo=o(" (BEiT model)"),dbo=l(),Yh=a("li"),xce=a("strong"),cbo=o("clip"),fbo=o(" \u2014 "),Zq=a("a"),mbo=o("CLIPFeatureExtractor"),gbo=o(" (CLIP model)"),hbo=l(),Kh=a("li"),$ce=a("strong"),pbo=o("convnext"),_bo=o(" \u2014 "),ej=a("a"),ubo=o("ConvNextFeatureExtractor"),bbo=o(" (ConvNeXT model)"),vbo=l(),Zh=a("li"),kce=a("strong"),Fbo=o("cvt"),Tbo=o(" \u2014 "),oj=a("a"),Mbo=o("ConvNextFeatureExtractor"),Ebo=o(" (CvT model)"),Cbo=l(),ep=a("li"),Sce=a("strong"),wbo=o("data2vec-audio"),Abo=o(" \u2014 "),rj=a("a"),Lbo=o("Wav2Vec2FeatureExtractor"),ybo=o(" (Data2VecAudio model)"),xbo=l(),op=a("li"),Rce=a("strong"),$bo=o("data2vec-vision"),kbo=o(" \u2014 "),tj=a("a"),Sbo=o("BeitFeatureExtractor"),Rbo=o(" (Data2VecVision model)"),Pbo=l(),rp=a("li"),Pce=a("strong"),Bbo=o("deit"),Ibo=o(" \u2014 "),aj=a("a"),Nbo=o("DeiTFeatureExtractor"),qbo=o(" (DeiT model)"),jbo=l(),tp=a("li"),Bce=a("strong"),Dbo=o("detr"),Gbo=o(" \u2014 "),nj=a("a"),Obo=o("DetrFeatureExtractor"),Vbo=o(" (DETR model)"),Xbo=l(),ap=a("li"),Ice=a("strong"),zbo=o("dpt"),Wbo=o(" \u2014 "),sj=a("a"),Qbo=o("DPTFeatureExtractor"),Hbo=o(" (DPT model)"),Ubo=l(),np=a("li"),Nce=a("strong"),Jbo=o("flava"),Ybo=o(" \u2014 "),lj=a("a"),Kbo=o("FlavaFeatureExtractor"),Zbo=o(" (FLAVA model)"),evo=l(),sp=a("li"),qce=a("strong"),ovo=o("glpn"),rvo=o(" \u2014 "),ij=a("a"),tvo=o("GLPNFeatureExtractor"),avo=o(" (GLPN model)"),nvo=l(),lp=a("li"),jce=a("strong"),svo=o("groupvit"),lvo=o(" \u2014 "),dj=a("a"),ivo=o("CLIPFeatureExtractor"),dvo=o(" (GroupViT model)"),cvo=l(),ip=a("li"),Dce=a("strong"),fvo=o("hubert"),mvo=o(" \u2014 "),cj=a("a"),gvo=o("Wav2Vec2FeatureExtractor"),hvo=o(" (Hubert model)"),pvo=l(),dp=a("li"),Gce=a("strong"),_vo=o("imagegpt"),uvo=o(" \u2014 "),fj=a("a"),bvo=o("ImageGPTFeatureExtractor"),vvo=o(" (ImageGPT model)"),Fvo=l(),cp=a("li"),Oce=a("strong"),Tvo=o("layoutlmv2"),Mvo=o(" \u2014 "),mj=a("a"),Evo=o("LayoutLMv2FeatureExtractor"),Cvo=o(" (LayoutLMv2 model)"),wvo=l(),fp=a("li"),Vce=a("strong"),Avo=o("layoutlmv3"),Lvo=o(" \u2014 "),gj=a("a"),yvo=o("LayoutLMv3FeatureExtractor"),xvo=o(" (LayoutLMv3 model)"),$vo=l(),mp=a("li"),Xce=a("strong"),kvo=o("levit"),Svo=o(" \u2014 "),hj=a("a"),Rvo=o("LevitFeatureExtractor"),Pvo=o(" (LeViT model)"),Bvo=l(),gp=a("li"),zce=a("strong"),Ivo=o("maskformer"),Nvo=o(" \u2014 "),pj=a("a"),qvo=o("MaskFormerFeatureExtractor"),jvo=o(" (MaskFormer model)"),Dvo=l(),hp=a("li"),Wce=a("strong"),Gvo=o("mctct"),Ovo=o(" \u2014 "),_j=a("a"),Vvo=o("MCTCTFeatureExtractor"),Xvo=o(" (M-CTC-T model)"),zvo=l(),pp=a("li"),Qce=a("strong"),Wvo=o("mobilevit"),Qvo=o(" \u2014 "),uj=a("a"),Hvo=o("MobileViTFeatureExtractor"),Uvo=o(" (MobileViT model)"),Jvo=l(),_p=a("li"),Hce=a("strong"),Yvo=o("owlvit"),Kvo=o(" \u2014 "),bj=a("a"),Zvo=o("OwlViTFeatureExtractor"),eFo=o(" (OWL-ViT model)"),oFo=l(),up=a("li"),Uce=a("strong"),rFo=o("perceiver"),tFo=o(" \u2014 "),vj=a("a"),aFo=o("PerceiverFeatureExtractor"),nFo=o(" (Perceiver model)"),sFo=l(),bp=a("li"),Jce=a("strong"),lFo=o("poolformer"),iFo=o(" \u2014 "),Fj=a("a"),dFo=o("PoolFormerFeatureExtractor"),cFo=o(" (PoolFormer model)"),fFo=l(),vp=a("li"),Yce=a("strong"),mFo=o("regnet"),gFo=o(" \u2014 "),Tj=a("a"),hFo=o("ConvNextFeatureExtractor"),pFo=o(" (RegNet model)"),_Fo=l(),Fp=a("li"),Kce=a("strong"),uFo=o("resnet"),bFo=o(" \u2014 "),Mj=a("a"),vFo=o("ConvNextFeatureExtractor"),FFo=o(" (ResNet model)"),TFo=l(),Tp=a("li"),Zce=a("strong"),MFo=o("segformer"),EFo=o(" \u2014 "),Ej=a("a"),CFo=o("SegformerFeatureExtractor"),wFo=o(" (SegFormer model)"),AFo=l(),Mp=a("li"),efe=a("strong"),LFo=o("speech_to_text"),yFo=o(" \u2014 "),Cj=a("a"),xFo=o("Speech2TextFeatureExtractor"),$Fo=o(" (Speech2Text model)"),kFo=l(),Ep=a("li"),ofe=a("strong"),SFo=o("swin"),RFo=o(" \u2014 "),wj=a("a"),PFo=o("ViTFeatureExtractor"),BFo=o(" (Swin Transformer model)"),IFo=l(),Cp=a("li"),rfe=a("strong"),NFo=o("swinv2"),qFo=o(" \u2014 "),Aj=a("a"),jFo=o("ViTFeatureExtractor"),DFo=o(" (Swin Transformer V2 model)"),GFo=l(),wp=a("li"),tfe=a("strong"),OFo=o("van"),VFo=o(" \u2014 "),Lj=a("a"),XFo=o("ConvNextFeatureExtractor"),zFo=o(" (VAN model)"),WFo=l(),Ap=a("li"),afe=a("strong"),QFo=o("videomae"),HFo=o(" \u2014 "),yj=a("a"),UFo=o("ViTFeatureExtractor"),JFo=o(" (VideoMAE model)"),YFo=l(),Lp=a("li"),nfe=a("strong"),KFo=o("vilt"),ZFo=o(" \u2014 "),xj=a("a"),eTo=o("ViltFeatureExtractor"),oTo=o(" (ViLT model)"),rTo=l(),yp=a("li"),sfe=a("strong"),tTo=o("vit"),aTo=o(" \u2014 "),$j=a("a"),nTo=o("ViTFeatureExtractor"),sTo=o(" (ViT model)"),lTo=l(),xp=a("li"),lfe=a("strong"),iTo=o("vit_mae"),dTo=o(" \u2014 "),kj=a("a"),cTo=o("ViTFeatureExtractor"),fTo=o(" (ViTMAE model)"),mTo=l(),$p=a("li"),ife=a("strong"),gTo=o("wav2vec2"),hTo=o(" \u2014 "),Sj=a("a"),pTo=o("Wav2Vec2FeatureExtractor"),_To=o(" (Wav2Vec2 model)"),uTo=l(),kp=a("li"),dfe=a("strong"),bTo=o("wav2vec2-conformer"),vTo=o(" \u2014 "),Rj=a("a"),FTo=o("Wav2Vec2FeatureExtractor"),TTo=o(" (Wav2Vec2-Conformer model)"),MTo=l(),Sp=a("li"),cfe=a("strong"),ETo=o("yolos"),CTo=o(" \u2014 "),Pj=a("a"),wTo=o("YolosFeatureExtractor"),ATo=o(" (YOLOS model)"),LTo=l(),F(Rp.$$.fragment),yTo=l(),F(Pp.$$.fragment),xTo=l(),Bp=a("div"),F(my.$$.fragment),$To=l(),ffe=a("p"),kTo=o("Register a new feature extractor for this class."),JWe=l(),Hi=a("h2"),Ip=a("a"),mfe=a("span"),F(gy.$$.fragment),STo=l(),gfe=a("span"),RTo=o("AutoProcessor"),YWe=l(),ko=a("div"),F(hy.$$.fragment),PTo=l(),py=a("p"),BTo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Bj=a("a"),ITo=o("AutoProcessor.from_pretrained()"),NTo=o(" class method."),qTo=l(),_y=a("p"),jTo=o("This class cannot be instantiated directly using "),hfe=a("code"),DTo=o("__init__()"),GTo=o(" (throws an error)."),OTo=l(),Je=a("div"),F(uy.$$.fragment),VTo=l(),pfe=a("p"),XTo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),zTo=l(),Ui=a("p"),WTo=o("The processor class to instantiate is selected based on the "),_fe=a("code"),QTo=o("model_type"),HTo=o(` property of the config object (either
passed as an argument or loaded from `),ufe=a("code"),UTo=o("pretrained_model_name_or_path"),JTo=o(" if possible):"),YTo=l(),fe=a("ul"),Np=a("li"),bfe=a("strong"),KTo=o("clip"),ZTo=o(" \u2014 "),Ij=a("a"),e9o=o("CLIPProcessor"),o9o=o(" (CLIP model)"),r9o=l(),qp=a("li"),vfe=a("strong"),t9o=o("flava"),a9o=o(" \u2014 "),Nj=a("a"),n9o=o("FlavaProcessor"),s9o=o(" (FLAVA model)"),l9o=l(),jp=a("li"),Ffe=a("strong"),i9o=o("groupvit"),d9o=o(" \u2014 "),qj=a("a"),c9o=o("CLIPProcessor"),f9o=o(" (GroupViT model)"),m9o=l(),Dp=a("li"),Tfe=a("strong"),g9o=o("layoutlmv2"),h9o=o(" \u2014 "),jj=a("a"),p9o=o("LayoutLMv2Processor"),_9o=o(" (LayoutLMv2 model)"),u9o=l(),Gp=a("li"),Mfe=a("strong"),b9o=o("layoutlmv3"),v9o=o(" \u2014 "),Dj=a("a"),F9o=o("LayoutLMv3Processor"),T9o=o(" (LayoutLMv3 model)"),M9o=l(),Op=a("li"),Efe=a("strong"),E9o=o("layoutxlm"),C9o=o(" \u2014 "),Gj=a("a"),w9o=o("LayoutXLMProcessor"),A9o=o(" (LayoutXLM model)"),L9o=l(),Vp=a("li"),Cfe=a("strong"),y9o=o("owlvit"),x9o=o(" \u2014 "),Oj=a("a"),$9o=o("OwlViTProcessor"),k9o=o(" (OWL-ViT model)"),S9o=l(),Xp=a("li"),wfe=a("strong"),R9o=o("sew"),P9o=o(" \u2014 "),Vj=a("a"),B9o=o("Wav2Vec2Processor"),I9o=o(" (SEW model)"),N9o=l(),zp=a("li"),Afe=a("strong"),q9o=o("sew-d"),j9o=o(" \u2014 "),Xj=a("a"),D9o=o("Wav2Vec2Processor"),G9o=o(" (SEW-D model)"),O9o=l(),Wp=a("li"),Lfe=a("strong"),V9o=o("speech_to_text"),X9o=o(" \u2014 "),zj=a("a"),z9o=o("Speech2TextProcessor"),W9o=o(" (Speech2Text model)"),Q9o=l(),Qp=a("li"),yfe=a("strong"),H9o=o("speech_to_text_2"),U9o=o(" \u2014 "),Wj=a("a"),J9o=o("Speech2Text2Processor"),Y9o=o(" (Speech2Text2 model)"),K9o=l(),Hp=a("li"),xfe=a("strong"),Z9o=o("trocr"),eMo=o(" \u2014 "),Qj=a("a"),oMo=o("TrOCRProcessor"),rMo=o(" (TrOCR model)"),tMo=l(),Up=a("li"),$fe=a("strong"),aMo=o("unispeech"),nMo=o(" \u2014 "),Hj=a("a"),sMo=o("Wav2Vec2Processor"),lMo=o(" (UniSpeech model)"),iMo=l(),Jp=a("li"),kfe=a("strong"),dMo=o("unispeech-sat"),cMo=o(" \u2014 "),Uj=a("a"),fMo=o("Wav2Vec2Processor"),mMo=o(" (UniSpeechSat model)"),gMo=l(),Yp=a("li"),Sfe=a("strong"),hMo=o("vilt"),pMo=o(" \u2014 "),Jj=a("a"),_Mo=o("ViltProcessor"),uMo=o(" (ViLT model)"),bMo=l(),Kp=a("li"),Rfe=a("strong"),vMo=o("vision-text-dual-encoder"),FMo=o(" \u2014 "),Yj=a("a"),TMo=o("VisionTextDualEncoderProcessor"),MMo=o(" (VisionTextDualEncoder model)"),EMo=l(),Zp=a("li"),Pfe=a("strong"),CMo=o("wav2vec2"),wMo=o(" \u2014 "),Kj=a("a"),AMo=o("Wav2Vec2Processor"),LMo=o(" (Wav2Vec2 model)"),yMo=l(),e_=a("li"),Bfe=a("strong"),xMo=o("wav2vec2-conformer"),$Mo=o(" \u2014 "),Zj=a("a"),kMo=o("Wav2Vec2Processor"),SMo=o(" (Wav2Vec2-Conformer model)"),RMo=l(),o_=a("li"),Ife=a("strong"),PMo=o("wavlm"),BMo=o(" \u2014 "),eD=a("a"),IMo=o("Wav2Vec2Processor"),NMo=o(" (WavLM model)"),qMo=l(),F(r_.$$.fragment),jMo=l(),F(t_.$$.fragment),DMo=l(),a_=a("div"),F(by.$$.fragment),GMo=l(),Nfe=a("p"),OMo=o("Register a new processor for this class."),KWe=l(),Ji=a("h2"),n_=a("a"),qfe=a("span"),F(vy.$$.fragment),VMo=l(),jfe=a("span"),XMo=o("AutoModel"),ZWe=l(),So=a("div"),F(Fy.$$.fragment),zMo=l(),Yi=a("p"),WMo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oD=a("a"),QMo=o("from_pretrained()"),HMo=o(" class method or the "),rD=a("a"),UMo=o("from_config()"),JMo=o(` class
method.`),YMo=l(),Ty=a("p"),KMo=o("This class cannot be instantiated directly using "),Dfe=a("code"),ZMo=o("__init__()"),eEo=o(" (throws an error)."),oEo=l(),ct=a("div"),F(My.$$.fragment),rEo=l(),Gfe=a("p"),tEo=o("Instantiates one of the base model classes of the library from a configuration."),aEo=l(),Ki=a("p"),nEo=o(`Note:
Loading a model from its configuration file does `),Ofe=a("strong"),sEo=o("not"),lEo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tD=a("a"),iEo=o("from_pretrained()"),dEo=o(" to load the model weights."),cEo=l(),F(s_.$$.fragment),fEo=l(),Ye=a("div"),F(Ey.$$.fragment),mEo=l(),Vfe=a("p"),gEo=o("Instantiate one of the base model classes of the library from a pretrained model."),hEo=l(),Da=a("p"),pEo=o("The model class to instantiate is selected based on the "),Xfe=a("code"),_Eo=o("model_type"),uEo=o(` property of the config object (either
passed as an argument or loaded from `),zfe=a("code"),bEo=o("pretrained_model_name_or_path"),vEo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wfe=a("code"),FEo=o("pretrained_model_name_or_path"),TEo=o(":"),MEo=l(),y=a("ul"),l_=a("li"),Qfe=a("strong"),EEo=o("albert"),CEo=o(" \u2014 "),aD=a("a"),wEo=o("AlbertModel"),AEo=o(" (ALBERT model)"),LEo=l(),i_=a("li"),Hfe=a("strong"),yEo=o("bart"),xEo=o(" \u2014 "),nD=a("a"),$Eo=o("BartModel"),kEo=o(" (BART model)"),SEo=l(),d_=a("li"),Ufe=a("strong"),REo=o("beit"),PEo=o(" \u2014 "),sD=a("a"),BEo=o("BeitModel"),IEo=o(" (BEiT model)"),NEo=l(),c_=a("li"),Jfe=a("strong"),qEo=o("bert"),jEo=o(" \u2014 "),lD=a("a"),DEo=o("BertModel"),GEo=o(" (BERT model)"),OEo=l(),f_=a("li"),Yfe=a("strong"),VEo=o("bert-generation"),XEo=o(" \u2014 "),iD=a("a"),zEo=o("BertGenerationEncoder"),WEo=o(" (Bert Generation model)"),QEo=l(),m_=a("li"),Kfe=a("strong"),HEo=o("big_bird"),UEo=o(" \u2014 "),dD=a("a"),JEo=o("BigBirdModel"),YEo=o(" (BigBird model)"),KEo=l(),g_=a("li"),Zfe=a("strong"),ZEo=o("bigbird_pegasus"),e4o=o(" \u2014 "),cD=a("a"),o4o=o("BigBirdPegasusModel"),r4o=o(" (BigBird-Pegasus model)"),t4o=l(),h_=a("li"),eme=a("strong"),a4o=o("blenderbot"),n4o=o(" \u2014 "),fD=a("a"),s4o=o("BlenderbotModel"),l4o=o(" (Blenderbot model)"),i4o=l(),p_=a("li"),ome=a("strong"),d4o=o("blenderbot-small"),c4o=o(" \u2014 "),mD=a("a"),f4o=o("BlenderbotSmallModel"),m4o=o(" (BlenderbotSmall model)"),g4o=l(),__=a("li"),rme=a("strong"),h4o=o("bloom"),p4o=o(" \u2014 "),gD=a("a"),_4o=o("BloomModel"),u4o=o(" (BLOOM model)"),b4o=l(),u_=a("li"),tme=a("strong"),v4o=o("camembert"),F4o=o(" \u2014 "),hD=a("a"),T4o=o("CamembertModel"),M4o=o(" (CamemBERT model)"),E4o=l(),b_=a("li"),ame=a("strong"),C4o=o("canine"),w4o=o(" \u2014 "),pD=a("a"),A4o=o("CanineModel"),L4o=o(" (CANINE model)"),y4o=l(),v_=a("li"),nme=a("strong"),x4o=o("clip"),$4o=o(" \u2014 "),_D=a("a"),k4o=o("CLIPModel"),S4o=o(" (CLIP model)"),R4o=l(),F_=a("li"),sme=a("strong"),P4o=o("codegen"),B4o=o(" \u2014 "),uD=a("a"),I4o=o("CodeGenModel"),N4o=o(" (CodeGen model)"),q4o=l(),T_=a("li"),lme=a("strong"),j4o=o("convbert"),D4o=o(" \u2014 "),bD=a("a"),G4o=o("ConvBertModel"),O4o=o(" (ConvBERT model)"),V4o=l(),M_=a("li"),ime=a("strong"),X4o=o("convnext"),z4o=o(" \u2014 "),vD=a("a"),W4o=o("ConvNextModel"),Q4o=o(" (ConvNeXT model)"),H4o=l(),E_=a("li"),dme=a("strong"),U4o=o("ctrl"),J4o=o(" \u2014 "),FD=a("a"),Y4o=o("CTRLModel"),K4o=o(" (CTRL model)"),Z4o=l(),C_=a("li"),cme=a("strong"),eCo=o("cvt"),oCo=o(" \u2014 "),TD=a("a"),rCo=o("CvtModel"),tCo=o(" (CvT model)"),aCo=l(),w_=a("li"),fme=a("strong"),nCo=o("data2vec-audio"),sCo=o(" \u2014 "),MD=a("a"),lCo=o("Data2VecAudioModel"),iCo=o(" (Data2VecAudio model)"),dCo=l(),A_=a("li"),mme=a("strong"),cCo=o("data2vec-text"),fCo=o(" \u2014 "),ED=a("a"),mCo=o("Data2VecTextModel"),gCo=o(" (Data2VecText model)"),hCo=l(),L_=a("li"),gme=a("strong"),pCo=o("data2vec-vision"),_Co=o(" \u2014 "),CD=a("a"),uCo=o("Data2VecVisionModel"),bCo=o(" (Data2VecVision model)"),vCo=l(),y_=a("li"),hme=a("strong"),FCo=o("deberta"),TCo=o(" \u2014 "),wD=a("a"),MCo=o("DebertaModel"),ECo=o(" (DeBERTa model)"),CCo=l(),x_=a("li"),pme=a("strong"),wCo=o("deberta-v2"),ACo=o(" \u2014 "),AD=a("a"),LCo=o("DebertaV2Model"),yCo=o(" (DeBERTa-v2 model)"),xCo=l(),$_=a("li"),_me=a("strong"),$Co=o("decision_transformer"),kCo=o(" \u2014 "),LD=a("a"),SCo=o("DecisionTransformerModel"),RCo=o(" (Decision Transformer model)"),PCo=l(),k_=a("li"),ume=a("strong"),BCo=o("deit"),ICo=o(" \u2014 "),yD=a("a"),NCo=o("DeiTModel"),qCo=o(" (DeiT model)"),jCo=l(),S_=a("li"),bme=a("strong"),DCo=o("detr"),GCo=o(" \u2014 "),xD=a("a"),OCo=o("DetrModel"),VCo=o(" (DETR model)"),XCo=l(),R_=a("li"),vme=a("strong"),zCo=o("distilbert"),WCo=o(" \u2014 "),$D=a("a"),QCo=o("DistilBertModel"),HCo=o(" (DistilBERT model)"),UCo=l(),P_=a("li"),Fme=a("strong"),JCo=o("dpr"),YCo=o(" \u2014 "),kD=a("a"),KCo=o("DPRQuestionEncoder"),ZCo=o(" (DPR model)"),e3o=l(),B_=a("li"),Tme=a("strong"),o3o=o("dpt"),r3o=o(" \u2014 "),SD=a("a"),t3o=o("DPTModel"),a3o=o(" (DPT model)"),n3o=l(),I_=a("li"),Mme=a("strong"),s3o=o("electra"),l3o=o(" \u2014 "),RD=a("a"),i3o=o("ElectraModel"),d3o=o(" (ELECTRA model)"),c3o=l(),N_=a("li"),Eme=a("strong"),f3o=o("flaubert"),m3o=o(" \u2014 "),PD=a("a"),g3o=o("FlaubertModel"),h3o=o(" (FlauBERT model)"),p3o=l(),q_=a("li"),Cme=a("strong"),_3o=o("flava"),u3o=o(" \u2014 "),BD=a("a"),b3o=o("FlavaModel"),v3o=o(" (FLAVA model)"),F3o=l(),j_=a("li"),wme=a("strong"),T3o=o("fnet"),M3o=o(" \u2014 "),ID=a("a"),E3o=o("FNetModel"),C3o=o(" (FNet model)"),w3o=l(),D_=a("li"),Ame=a("strong"),A3o=o("fsmt"),L3o=o(" \u2014 "),ND=a("a"),y3o=o("FSMTModel"),x3o=o(" (FairSeq Machine-Translation model)"),$3o=l(),ol=a("li"),Lme=a("strong"),k3o=o("funnel"),S3o=o(" \u2014 "),qD=a("a"),R3o=o("FunnelModel"),P3o=o(" or "),jD=a("a"),B3o=o("FunnelBaseModel"),I3o=o(" (Funnel Transformer model)"),N3o=l(),G_=a("li"),yme=a("strong"),q3o=o("glpn"),j3o=o(" \u2014 "),DD=a("a"),D3o=o("GLPNModel"),G3o=o(" (GLPN model)"),O3o=l(),O_=a("li"),xme=a("strong"),V3o=o("gpt2"),X3o=o(" \u2014 "),GD=a("a"),z3o=o("GPT2Model"),W3o=o(" (OpenAI GPT-2 model)"),Q3o=l(),V_=a("li"),$me=a("strong"),H3o=o("gpt_neo"),U3o=o(" \u2014 "),OD=a("a"),J3o=o("GPTNeoModel"),Y3o=o(" (GPT Neo model)"),K3o=l(),X_=a("li"),kme=a("strong"),Z3o=o("gpt_neox"),e5o=o(" \u2014 "),VD=a("a"),o5o=o("GPTNeoXModel"),r5o=o(" (GPT NeoX model)"),t5o=l(),z_=a("li"),Sme=a("strong"),a5o=o("gptj"),n5o=o(" \u2014 "),XD=a("a"),s5o=o("GPTJModel"),l5o=o(" (GPT-J model)"),i5o=l(),W_=a("li"),Rme=a("strong"),d5o=o("groupvit"),c5o=o(" \u2014 "),zD=a("a"),f5o=o("GroupViTModel"),m5o=o(" (GroupViT model)"),g5o=l(),Q_=a("li"),Pme=a("strong"),h5o=o("hubert"),p5o=o(" \u2014 "),WD=a("a"),_5o=o("HubertModel"),u5o=o(" (Hubert model)"),b5o=l(),H_=a("li"),Bme=a("strong"),v5o=o("ibert"),F5o=o(" \u2014 "),QD=a("a"),T5o=o("IBertModel"),M5o=o(" (I-BERT model)"),E5o=l(),U_=a("li"),Ime=a("strong"),C5o=o("imagegpt"),w5o=o(" \u2014 "),HD=a("a"),A5o=o("ImageGPTModel"),L5o=o(" (ImageGPT model)"),y5o=l(),J_=a("li"),Nme=a("strong"),x5o=o("layoutlm"),$5o=o(" \u2014 "),UD=a("a"),k5o=o("LayoutLMModel"),S5o=o(" (LayoutLM model)"),R5o=l(),Y_=a("li"),qme=a("strong"),P5o=o("layoutlmv2"),B5o=o(" \u2014 "),JD=a("a"),I5o=o("LayoutLMv2Model"),N5o=o(" (LayoutLMv2 model)"),q5o=l(),K_=a("li"),jme=a("strong"),j5o=o("layoutlmv3"),D5o=o(" \u2014 "),YD=a("a"),G5o=o("LayoutLMv3Model"),O5o=o(" (LayoutLMv3 model)"),V5o=l(),Z_=a("li"),Dme=a("strong"),X5o=o("led"),z5o=o(" \u2014 "),KD=a("a"),W5o=o("LEDModel"),Q5o=o(" (LED model)"),H5o=l(),eu=a("li"),Gme=a("strong"),U5o=o("levit"),J5o=o(" \u2014 "),ZD=a("a"),Y5o=o("LevitModel"),K5o=o(" (LeViT model)"),Z5o=l(),ou=a("li"),Ome=a("strong"),e0o=o("longformer"),o0o=o(" \u2014 "),eG=a("a"),r0o=o("LongformerModel"),t0o=o(" (Longformer model)"),a0o=l(),ru=a("li"),Vme=a("strong"),n0o=o("longt5"),s0o=o(" \u2014 "),oG=a("a"),l0o=o("LongT5Model"),i0o=o(" (LongT5 model)"),d0o=l(),tu=a("li"),Xme=a("strong"),c0o=o("luke"),f0o=o(" \u2014 "),rG=a("a"),m0o=o("LukeModel"),g0o=o(" (LUKE model)"),h0o=l(),au=a("li"),zme=a("strong"),p0o=o("lxmert"),_0o=o(" \u2014 "),tG=a("a"),u0o=o("LxmertModel"),b0o=o(" (LXMERT model)"),v0o=l(),nu=a("li"),Wme=a("strong"),F0o=o("m2m_100"),T0o=o(" \u2014 "),aG=a("a"),M0o=o("M2M100Model"),E0o=o(" (M2M100 model)"),C0o=l(),su=a("li"),Qme=a("strong"),w0o=o("marian"),A0o=o(" \u2014 "),nG=a("a"),L0o=o("MarianModel"),y0o=o(" (Marian model)"),x0o=l(),lu=a("li"),Hme=a("strong"),$0o=o("maskformer"),k0o=o(" \u2014 "),sG=a("a"),S0o=o("MaskFormerModel"),R0o=o(" (MaskFormer model)"),P0o=l(),iu=a("li"),Ume=a("strong"),B0o=o("mbart"),I0o=o(" \u2014 "),lG=a("a"),N0o=o("MBartModel"),q0o=o(" (mBART model)"),j0o=l(),du=a("li"),Jme=a("strong"),D0o=o("mctct"),G0o=o(" \u2014 "),iG=a("a"),O0o=o("MCTCTModel"),V0o=o(" (M-CTC-T model)"),X0o=l(),cu=a("li"),Yme=a("strong"),z0o=o("megatron-bert"),W0o=o(" \u2014 "),dG=a("a"),Q0o=o("MegatronBertModel"),H0o=o(" (Megatron-BERT model)"),U0o=l(),fu=a("li"),Kme=a("strong"),J0o=o("mobilebert"),Y0o=o(" \u2014 "),cG=a("a"),K0o=o("MobileBertModel"),Z0o=o(" (MobileBERT model)"),ewo=l(),mu=a("li"),Zme=a("strong"),owo=o("mobilevit"),rwo=o(" \u2014 "),fG=a("a"),two=o("MobileViTModel"),awo=o(" (MobileViT model)"),nwo=l(),gu=a("li"),ege=a("strong"),swo=o("mpnet"),lwo=o(" \u2014 "),mG=a("a"),iwo=o("MPNetModel"),dwo=o(" (MPNet model)"),cwo=l(),hu=a("li"),oge=a("strong"),fwo=o("mt5"),mwo=o(" \u2014 "),gG=a("a"),gwo=o("MT5Model"),hwo=o(" (MT5 model)"),pwo=l(),pu=a("li"),rge=a("strong"),_wo=o("mvp"),uwo=o(" \u2014 "),hG=a("a"),bwo=o("MvpModel"),vwo=o(" (MVP model)"),Fwo=l(),_u=a("li"),tge=a("strong"),Two=o("nezha"),Mwo=o(" \u2014 "),pG=a("a"),Ewo=o("NezhaModel"),Cwo=o(" (Nezha model)"),wwo=l(),uu=a("li"),age=a("strong"),Awo=o("nllb"),Lwo=o(" \u2014 "),_G=a("a"),ywo=o("M2M100Model"),xwo=o(" (NLLB model)"),$wo=l(),bu=a("li"),nge=a("strong"),kwo=o("nystromformer"),Swo=o(" \u2014 "),uG=a("a"),Rwo=o("NystromformerModel"),Pwo=o(" (Nystr\xF6mformer model)"),Bwo=l(),vu=a("li"),sge=a("strong"),Iwo=o("openai-gpt"),Nwo=o(" \u2014 "),bG=a("a"),qwo=o("OpenAIGPTModel"),jwo=o(" (OpenAI GPT model)"),Dwo=l(),Fu=a("li"),lge=a("strong"),Gwo=o("opt"),Owo=o(" \u2014 "),vG=a("a"),Vwo=o("OPTModel"),Xwo=o(" (OPT model)"),zwo=l(),Tu=a("li"),ige=a("strong"),Wwo=o("owlvit"),Qwo=o(" \u2014 "),FG=a("a"),Hwo=o("OwlViTModel"),Uwo=o(" (OWL-ViT model)"),Jwo=l(),Mu=a("li"),dge=a("strong"),Ywo=o("pegasus"),Kwo=o(" \u2014 "),TG=a("a"),Zwo=o("PegasusModel"),e6o=o(" (Pegasus model)"),o6o=l(),Eu=a("li"),cge=a("strong"),r6o=o("perceiver"),t6o=o(" \u2014 "),MG=a("a"),a6o=o("PerceiverModel"),n6o=o(" (Perceiver model)"),s6o=l(),Cu=a("li"),fge=a("strong"),l6o=o("plbart"),i6o=o(" \u2014 "),EG=a("a"),d6o=o("PLBartModel"),c6o=o(" (PLBart model)"),f6o=l(),wu=a("li"),mge=a("strong"),m6o=o("poolformer"),g6o=o(" \u2014 "),CG=a("a"),h6o=o("PoolFormerModel"),p6o=o(" (PoolFormer model)"),_6o=l(),Au=a("li"),gge=a("strong"),u6o=o("prophetnet"),b6o=o(" \u2014 "),wG=a("a"),v6o=o("ProphetNetModel"),F6o=o(" (ProphetNet model)"),T6o=l(),Lu=a("li"),hge=a("strong"),M6o=o("qdqbert"),E6o=o(" \u2014 "),AG=a("a"),C6o=o("QDQBertModel"),w6o=o(" (QDQBert model)"),A6o=l(),yu=a("li"),pge=a("strong"),L6o=o("reformer"),y6o=o(" \u2014 "),LG=a("a"),x6o=o("ReformerModel"),$6o=o(" (Reformer model)"),k6o=l(),xu=a("li"),_ge=a("strong"),S6o=o("regnet"),R6o=o(" \u2014 "),yG=a("a"),P6o=o("RegNetModel"),B6o=o(" (RegNet model)"),I6o=l(),$u=a("li"),uge=a("strong"),N6o=o("rembert"),q6o=o(" \u2014 "),xG=a("a"),j6o=o("RemBertModel"),D6o=o(" (RemBERT model)"),G6o=l(),ku=a("li"),bge=a("strong"),O6o=o("resnet"),V6o=o(" \u2014 "),$G=a("a"),X6o=o("ResNetModel"),z6o=o(" (ResNet model)"),W6o=l(),Su=a("li"),vge=a("strong"),Q6o=o("retribert"),H6o=o(" \u2014 "),kG=a("a"),U6o=o("RetriBertModel"),J6o=o(" (RetriBERT model)"),Y6o=l(),Ru=a("li"),Fge=a("strong"),K6o=o("roberta"),Z6o=o(" \u2014 "),SG=a("a"),eAo=o("RobertaModel"),oAo=o(" (RoBERTa model)"),rAo=l(),Pu=a("li"),Tge=a("strong"),tAo=o("roformer"),aAo=o(" \u2014 "),RG=a("a"),nAo=o("RoFormerModel"),sAo=o(" (RoFormer model)"),lAo=l(),Bu=a("li"),Mge=a("strong"),iAo=o("segformer"),dAo=o(" \u2014 "),PG=a("a"),cAo=o("SegformerModel"),fAo=o(" (SegFormer model)"),mAo=l(),Iu=a("li"),Ege=a("strong"),gAo=o("sew"),hAo=o(" \u2014 "),BG=a("a"),pAo=o("SEWModel"),_Ao=o(" (SEW model)"),uAo=l(),Nu=a("li"),Cge=a("strong"),bAo=o("sew-d"),vAo=o(" \u2014 "),IG=a("a"),FAo=o("SEWDModel"),TAo=o(" (SEW-D model)"),MAo=l(),qu=a("li"),wge=a("strong"),EAo=o("speech_to_text"),CAo=o(" \u2014 "),NG=a("a"),wAo=o("Speech2TextModel"),AAo=o(" (Speech2Text model)"),LAo=l(),ju=a("li"),Age=a("strong"),yAo=o("splinter"),xAo=o(" \u2014 "),qG=a("a"),$Ao=o("SplinterModel"),kAo=o(" (Splinter model)"),SAo=l(),Du=a("li"),Lge=a("strong"),RAo=o("squeezebert"),PAo=o(" \u2014 "),jG=a("a"),BAo=o("SqueezeBertModel"),IAo=o(" (SqueezeBERT model)"),NAo=l(),Gu=a("li"),yge=a("strong"),qAo=o("swin"),jAo=o(" \u2014 "),DG=a("a"),DAo=o("SwinModel"),GAo=o(" (Swin Transformer model)"),OAo=l(),Ou=a("li"),xge=a("strong"),VAo=o("swinv2"),XAo=o(" \u2014 "),GG=a("a"),zAo=o("Swinv2Model"),WAo=o(" (Swin Transformer V2 model)"),QAo=l(),Vu=a("li"),$ge=a("strong"),HAo=o("t5"),UAo=o(" \u2014 "),OG=a("a"),JAo=o("T5Model"),YAo=o(" (T5 model)"),KAo=l(),Xu=a("li"),kge=a("strong"),ZAo=o("tapas"),eLo=o(" \u2014 "),VG=a("a"),oLo=o("TapasModel"),rLo=o(" (TAPAS model)"),tLo=l(),zu=a("li"),Sge=a("strong"),aLo=o("trajectory_transformer"),nLo=o(" \u2014 "),XG=a("a"),sLo=o("TrajectoryTransformerModel"),lLo=o(" (Trajectory Transformer model)"),iLo=l(),Wu=a("li"),Rge=a("strong"),dLo=o("transfo-xl"),cLo=o(" \u2014 "),zG=a("a"),fLo=o("TransfoXLModel"),mLo=o(" (Transformer-XL model)"),gLo=l(),Qu=a("li"),Pge=a("strong"),hLo=o("unispeech"),pLo=o(" \u2014 "),WG=a("a"),_Lo=o("UniSpeechModel"),uLo=o(" (UniSpeech model)"),bLo=l(),Hu=a("li"),Bge=a("strong"),vLo=o("unispeech-sat"),FLo=o(" \u2014 "),QG=a("a"),TLo=o("UniSpeechSatModel"),MLo=o(" (UniSpeechSat model)"),ELo=l(),Uu=a("li"),Ige=a("strong"),CLo=o("van"),wLo=o(" \u2014 "),HG=a("a"),ALo=o("VanModel"),LLo=o(" (VAN model)"),yLo=l(),Ju=a("li"),Nge=a("strong"),xLo=o("videomae"),$Lo=o(" \u2014 "),UG=a("a"),kLo=o("VideoMAEModel"),SLo=o(" (VideoMAE model)"),RLo=l(),Yu=a("li"),qge=a("strong"),PLo=o("vilt"),BLo=o(" \u2014 "),JG=a("a"),ILo=o("ViltModel"),NLo=o(" (ViLT model)"),qLo=l(),Ku=a("li"),jge=a("strong"),jLo=o("vision-text-dual-encoder"),DLo=o(" \u2014 "),YG=a("a"),GLo=o("VisionTextDualEncoderModel"),OLo=o(" (VisionTextDualEncoder model)"),VLo=l(),Zu=a("li"),Dge=a("strong"),XLo=o("visual_bert"),zLo=o(" \u2014 "),KG=a("a"),WLo=o("VisualBertModel"),QLo=o(" (VisualBERT model)"),HLo=l(),e7=a("li"),Gge=a("strong"),ULo=o("vit"),JLo=o(" \u2014 "),ZG=a("a"),YLo=o("ViTModel"),KLo=o(" (ViT model)"),ZLo=l(),o7=a("li"),Oge=a("strong"),eyo=o("vit_mae"),oyo=o(" \u2014 "),eO=a("a"),ryo=o("ViTMAEModel"),tyo=o(" (ViTMAE model)"),ayo=l(),r7=a("li"),Vge=a("strong"),nyo=o("wav2vec2"),syo=o(" \u2014 "),oO=a("a"),lyo=o("Wav2Vec2Model"),iyo=o(" (Wav2Vec2 model)"),dyo=l(),t7=a("li"),Xge=a("strong"),cyo=o("wav2vec2-conformer"),fyo=o(" \u2014 "),rO=a("a"),myo=o("Wav2Vec2ConformerModel"),gyo=o(" (Wav2Vec2-Conformer model)"),hyo=l(),a7=a("li"),zge=a("strong"),pyo=o("wavlm"),_yo=o(" \u2014 "),tO=a("a"),uyo=o("WavLMModel"),byo=o(" (WavLM model)"),vyo=l(),n7=a("li"),Wge=a("strong"),Fyo=o("xglm"),Tyo=o(" \u2014 "),aO=a("a"),Myo=o("XGLMModel"),Eyo=o(" (XGLM model)"),Cyo=l(),s7=a("li"),Qge=a("strong"),wyo=o("xlm"),Ayo=o(" \u2014 "),nO=a("a"),Lyo=o("XLMModel"),yyo=o(" (XLM model)"),xyo=l(),l7=a("li"),Hge=a("strong"),$yo=o("xlm-prophetnet"),kyo=o(" \u2014 "),sO=a("a"),Syo=o("XLMProphetNetModel"),Ryo=o(" (XLM-ProphetNet model)"),Pyo=l(),i7=a("li"),Uge=a("strong"),Byo=o("xlm-roberta"),Iyo=o(" \u2014 "),lO=a("a"),Nyo=o("XLMRobertaModel"),qyo=o(" (XLM-RoBERTa model)"),jyo=l(),d7=a("li"),Jge=a("strong"),Dyo=o("xlm-roberta-xl"),Gyo=o(" \u2014 "),iO=a("a"),Oyo=o("XLMRobertaXLModel"),Vyo=o(" (XLM-RoBERTa-XL model)"),Xyo=l(),c7=a("li"),Yge=a("strong"),zyo=o("xlnet"),Wyo=o(" \u2014 "),dO=a("a"),Qyo=o("XLNetModel"),Hyo=o(" (XLNet model)"),Uyo=l(),f7=a("li"),Kge=a("strong"),Jyo=o("yolos"),Yyo=o(" \u2014 "),cO=a("a"),Kyo=o("YolosModel"),Zyo=o(" (YOLOS model)"),e8o=l(),m7=a("li"),Zge=a("strong"),o8o=o("yoso"),r8o=o(" \u2014 "),fO=a("a"),t8o=o("YosoModel"),a8o=o(" (YOSO model)"),n8o=l(),g7=a("p"),s8o=o("The model is set in evaluation mode by default using "),ehe=a("code"),l8o=o("model.eval()"),i8o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ohe=a("code"),d8o=o("model.train()"),c8o=l(),F(h7.$$.fragment),eQe=l(),Zi=a("h2"),p7=a("a"),rhe=a("span"),F(Cy.$$.fragment),f8o=l(),the=a("span"),m8o=o("AutoModelForPreTraining"),oQe=l(),Ro=a("div"),F(wy.$$.fragment),g8o=l(),ed=a("p"),h8o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mO=a("a"),p8o=o("from_pretrained()"),_8o=o(" class method or the "),gO=a("a"),u8o=o("from_config()"),b8o=o(` class
method.`),v8o=l(),Ay=a("p"),F8o=o("This class cannot be instantiated directly using "),ahe=a("code"),T8o=o("__init__()"),M8o=o(" (throws an error)."),E8o=l(),ft=a("div"),F(Ly.$$.fragment),C8o=l(),nhe=a("p"),w8o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),A8o=l(),od=a("p"),L8o=o(`Note:
Loading a model from its configuration file does `),she=a("strong"),y8o=o("not"),x8o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=a("a"),$8o=o("from_pretrained()"),k8o=o(" to load the model weights."),S8o=l(),F(_7.$$.fragment),R8o=l(),Ke=a("div"),F(yy.$$.fragment),P8o=l(),lhe=a("p"),B8o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),I8o=l(),Ga=a("p"),N8o=o("The model class to instantiate is selected based on the "),ihe=a("code"),q8o=o("model_type"),j8o=o(` property of the config object (either
passed as an argument or loaded from `),dhe=a("code"),D8o=o("pretrained_model_name_or_path"),G8o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),che=a("code"),O8o=o("pretrained_model_name_or_path"),V8o=o(":"),X8o=l(),G=a("ul"),u7=a("li"),fhe=a("strong"),z8o=o("albert"),W8o=o(" \u2014 "),pO=a("a"),Q8o=o("AlbertForPreTraining"),H8o=o(" (ALBERT model)"),U8o=l(),b7=a("li"),mhe=a("strong"),J8o=o("bart"),Y8o=o(" \u2014 "),_O=a("a"),K8o=o("BartForConditionalGeneration"),Z8o=o(" (BART model)"),exo=l(),v7=a("li"),ghe=a("strong"),oxo=o("bert"),rxo=o(" \u2014 "),uO=a("a"),txo=o("BertForPreTraining"),axo=o(" (BERT model)"),nxo=l(),F7=a("li"),hhe=a("strong"),sxo=o("big_bird"),lxo=o(" \u2014 "),bO=a("a"),ixo=o("BigBirdForPreTraining"),dxo=o(" (BigBird model)"),cxo=l(),T7=a("li"),phe=a("strong"),fxo=o("bloom"),mxo=o(" \u2014 "),vO=a("a"),gxo=o("BloomForCausalLM"),hxo=o(" (BLOOM model)"),pxo=l(),M7=a("li"),_he=a("strong"),_xo=o("camembert"),uxo=o(" \u2014 "),FO=a("a"),bxo=o("CamembertForMaskedLM"),vxo=o(" (CamemBERT model)"),Fxo=l(),E7=a("li"),uhe=a("strong"),Txo=o("ctrl"),Mxo=o(" \u2014 "),TO=a("a"),Exo=o("CTRLLMHeadModel"),Cxo=o(" (CTRL model)"),wxo=l(),C7=a("li"),bhe=a("strong"),Axo=o("data2vec-text"),Lxo=o(" \u2014 "),MO=a("a"),yxo=o("Data2VecTextForMaskedLM"),xxo=o(" (Data2VecText model)"),$xo=l(),w7=a("li"),vhe=a("strong"),kxo=o("deberta"),Sxo=o(" \u2014 "),EO=a("a"),Rxo=o("DebertaForMaskedLM"),Pxo=o(" (DeBERTa model)"),Bxo=l(),A7=a("li"),Fhe=a("strong"),Ixo=o("deberta-v2"),Nxo=o(" \u2014 "),CO=a("a"),qxo=o("DebertaV2ForMaskedLM"),jxo=o(" (DeBERTa-v2 model)"),Dxo=l(),L7=a("li"),The=a("strong"),Gxo=o("distilbert"),Oxo=o(" \u2014 "),wO=a("a"),Vxo=o("DistilBertForMaskedLM"),Xxo=o(" (DistilBERT model)"),zxo=l(),y7=a("li"),Mhe=a("strong"),Wxo=o("electra"),Qxo=o(" \u2014 "),AO=a("a"),Hxo=o("ElectraForPreTraining"),Uxo=o(" (ELECTRA model)"),Jxo=l(),x7=a("li"),Ehe=a("strong"),Yxo=o("flaubert"),Kxo=o(" \u2014 "),LO=a("a"),Zxo=o("FlaubertWithLMHeadModel"),e$o=o(" (FlauBERT model)"),o$o=l(),$7=a("li"),Che=a("strong"),r$o=o("flava"),t$o=o(" \u2014 "),yO=a("a"),a$o=o("FlavaForPreTraining"),n$o=o(" (FLAVA model)"),s$o=l(),k7=a("li"),whe=a("strong"),l$o=o("fnet"),i$o=o(" \u2014 "),xO=a("a"),d$o=o("FNetForPreTraining"),c$o=o(" (FNet model)"),f$o=l(),S7=a("li"),Ahe=a("strong"),m$o=o("fsmt"),g$o=o(" \u2014 "),$O=a("a"),h$o=o("FSMTForConditionalGeneration"),p$o=o(" (FairSeq Machine-Translation model)"),_$o=l(),R7=a("li"),Lhe=a("strong"),u$o=o("funnel"),b$o=o(" \u2014 "),kO=a("a"),v$o=o("FunnelForPreTraining"),F$o=o(" (Funnel Transformer model)"),T$o=l(),P7=a("li"),yhe=a("strong"),M$o=o("gpt2"),E$o=o(" \u2014 "),SO=a("a"),C$o=o("GPT2LMHeadModel"),w$o=o(" (OpenAI GPT-2 model)"),A$o=l(),B7=a("li"),xhe=a("strong"),L$o=o("ibert"),y$o=o(" \u2014 "),RO=a("a"),x$o=o("IBertForMaskedLM"),$$o=o(" (I-BERT model)"),k$o=l(),I7=a("li"),$he=a("strong"),S$o=o("layoutlm"),R$o=o(" \u2014 "),PO=a("a"),P$o=o("LayoutLMForMaskedLM"),B$o=o(" (LayoutLM model)"),I$o=l(),N7=a("li"),khe=a("strong"),N$o=o("longformer"),q$o=o(" \u2014 "),BO=a("a"),j$o=o("LongformerForMaskedLM"),D$o=o(" (Longformer model)"),G$o=l(),q7=a("li"),She=a("strong"),O$o=o("luke"),V$o=o(" \u2014 "),IO=a("a"),X$o=o("LukeForMaskedLM"),z$o=o(" (LUKE model)"),W$o=l(),j7=a("li"),Rhe=a("strong"),Q$o=o("lxmert"),H$o=o(" \u2014 "),NO=a("a"),U$o=o("LxmertForPreTraining"),J$o=o(" (LXMERT model)"),Y$o=l(),D7=a("li"),Phe=a("strong"),K$o=o("megatron-bert"),Z$o=o(" \u2014 "),qO=a("a"),eko=o("MegatronBertForPreTraining"),oko=o(" (Megatron-BERT model)"),rko=l(),G7=a("li"),Bhe=a("strong"),tko=o("mobilebert"),ako=o(" \u2014 "),jO=a("a"),nko=o("MobileBertForPreTraining"),sko=o(" (MobileBERT model)"),lko=l(),O7=a("li"),Ihe=a("strong"),iko=o("mpnet"),dko=o(" \u2014 "),DO=a("a"),cko=o("MPNetForMaskedLM"),fko=o(" (MPNet model)"),mko=l(),V7=a("li"),Nhe=a("strong"),gko=o("mvp"),hko=o(" \u2014 "),GO=a("a"),pko=o("MvpForConditionalGeneration"),_ko=o(" (MVP model)"),uko=l(),X7=a("li"),qhe=a("strong"),bko=o("nezha"),vko=o(" \u2014 "),OO=a("a"),Fko=o("NezhaForPreTraining"),Tko=o(" (Nezha model)"),Mko=l(),z7=a("li"),jhe=a("strong"),Eko=o("openai-gpt"),Cko=o(" \u2014 "),VO=a("a"),wko=o("OpenAIGPTLMHeadModel"),Ako=o(" (OpenAI GPT model)"),Lko=l(),W7=a("li"),Dhe=a("strong"),yko=o("retribert"),xko=o(" \u2014 "),XO=a("a"),$ko=o("RetriBertModel"),kko=o(" (RetriBERT model)"),Sko=l(),Q7=a("li"),Ghe=a("strong"),Rko=o("roberta"),Pko=o(" \u2014 "),zO=a("a"),Bko=o("RobertaForMaskedLM"),Iko=o(" (RoBERTa model)"),Nko=l(),H7=a("li"),Ohe=a("strong"),qko=o("splinter"),jko=o(" \u2014 "),WO=a("a"),Dko=o("SplinterForPreTraining"),Gko=o(" (Splinter model)"),Oko=l(),U7=a("li"),Vhe=a("strong"),Vko=o("squeezebert"),Xko=o(" \u2014 "),QO=a("a"),zko=o("SqueezeBertForMaskedLM"),Wko=o(" (SqueezeBERT model)"),Qko=l(),J7=a("li"),Xhe=a("strong"),Hko=o("t5"),Uko=o(" \u2014 "),HO=a("a"),Jko=o("T5ForConditionalGeneration"),Yko=o(" (T5 model)"),Kko=l(),Y7=a("li"),zhe=a("strong"),Zko=o("tapas"),eSo=o(" \u2014 "),UO=a("a"),oSo=o("TapasForMaskedLM"),rSo=o(" (TAPAS model)"),tSo=l(),K7=a("li"),Whe=a("strong"),aSo=o("transfo-xl"),nSo=o(" \u2014 "),JO=a("a"),sSo=o("TransfoXLLMHeadModel"),lSo=o(" (Transformer-XL model)"),iSo=l(),Z7=a("li"),Qhe=a("strong"),dSo=o("unispeech"),cSo=o(" \u2014 "),YO=a("a"),fSo=o("UniSpeechForPreTraining"),mSo=o(" (UniSpeech model)"),gSo=l(),e1=a("li"),Hhe=a("strong"),hSo=o("unispeech-sat"),pSo=o(" \u2014 "),KO=a("a"),_So=o("UniSpeechSatForPreTraining"),uSo=o(" (UniSpeechSat model)"),bSo=l(),o1=a("li"),Uhe=a("strong"),vSo=o("videomae"),FSo=o(" \u2014 "),ZO=a("a"),TSo=o("VideoMAEForPreTraining"),MSo=o(" (VideoMAE model)"),ESo=l(),r1=a("li"),Jhe=a("strong"),CSo=o("visual_bert"),wSo=o(" \u2014 "),eV=a("a"),ASo=o("VisualBertForPreTraining"),LSo=o(" (VisualBERT model)"),ySo=l(),t1=a("li"),Yhe=a("strong"),xSo=o("vit_mae"),$So=o(" \u2014 "),oV=a("a"),kSo=o("ViTMAEForPreTraining"),SSo=o(" (ViTMAE model)"),RSo=l(),a1=a("li"),Khe=a("strong"),PSo=o("wav2vec2"),BSo=o(" \u2014 "),rV=a("a"),ISo=o("Wav2Vec2ForPreTraining"),NSo=o(" (Wav2Vec2 model)"),qSo=l(),n1=a("li"),Zhe=a("strong"),jSo=o("wav2vec2-conformer"),DSo=o(" \u2014 "),tV=a("a"),GSo=o("Wav2Vec2ConformerForPreTraining"),OSo=o(" (Wav2Vec2-Conformer model)"),VSo=l(),s1=a("li"),epe=a("strong"),XSo=o("xlm"),zSo=o(" \u2014 "),aV=a("a"),WSo=o("XLMWithLMHeadModel"),QSo=o(" (XLM model)"),HSo=l(),l1=a("li"),ope=a("strong"),USo=o("xlm-roberta"),JSo=o(" \u2014 "),nV=a("a"),YSo=o("XLMRobertaForMaskedLM"),KSo=o(" (XLM-RoBERTa model)"),ZSo=l(),i1=a("li"),rpe=a("strong"),eRo=o("xlm-roberta-xl"),oRo=o(" \u2014 "),sV=a("a"),rRo=o("XLMRobertaXLForMaskedLM"),tRo=o(" (XLM-RoBERTa-XL model)"),aRo=l(),d1=a("li"),tpe=a("strong"),nRo=o("xlnet"),sRo=o(" \u2014 "),lV=a("a"),lRo=o("XLNetLMHeadModel"),iRo=o(" (XLNet model)"),dRo=l(),c1=a("p"),cRo=o("The model is set in evaluation mode by default using "),ape=a("code"),fRo=o("model.eval()"),mRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),npe=a("code"),gRo=o("model.train()"),hRo=l(),F(f1.$$.fragment),rQe=l(),rd=a("h2"),m1=a("a"),spe=a("span"),F(xy.$$.fragment),pRo=l(),lpe=a("span"),_Ro=o("AutoModelForCausalLM"),tQe=l(),Po=a("div"),F($y.$$.fragment),uRo=l(),td=a("p"),bRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),iV=a("a"),vRo=o("from_pretrained()"),FRo=o(" class method or the "),dV=a("a"),TRo=o("from_config()"),MRo=o(` class
method.`),ERo=l(),ky=a("p"),CRo=o("This class cannot be instantiated directly using "),ipe=a("code"),wRo=o("__init__()"),ARo=o(" (throws an error)."),LRo=l(),mt=a("div"),F(Sy.$$.fragment),yRo=l(),dpe=a("p"),xRo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),$Ro=l(),ad=a("p"),kRo=o(`Note:
Loading a model from its configuration file does `),cpe=a("strong"),SRo=o("not"),RRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cV=a("a"),PRo=o("from_pretrained()"),BRo=o(" to load the model weights."),IRo=l(),F(g1.$$.fragment),NRo=l(),Ze=a("div"),F(Ry.$$.fragment),qRo=l(),fpe=a("p"),jRo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),DRo=l(),Oa=a("p"),GRo=o("The model class to instantiate is selected based on the "),mpe=a("code"),ORo=o("model_type"),VRo=o(` property of the config object (either
passed as an argument or loaded from `),gpe=a("code"),XRo=o("pretrained_model_name_or_path"),zRo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hpe=a("code"),WRo=o("pretrained_model_name_or_path"),QRo=o(":"),HRo=l(),z=a("ul"),h1=a("li"),ppe=a("strong"),URo=o("bart"),JRo=o(" \u2014 "),fV=a("a"),YRo=o("BartForCausalLM"),KRo=o(" (BART model)"),ZRo=l(),p1=a("li"),_pe=a("strong"),ePo=o("bert"),oPo=o(" \u2014 "),mV=a("a"),rPo=o("BertLMHeadModel"),tPo=o(" (BERT model)"),aPo=l(),_1=a("li"),upe=a("strong"),nPo=o("bert-generation"),sPo=o(" \u2014 "),gV=a("a"),lPo=o("BertGenerationDecoder"),iPo=o(" (Bert Generation model)"),dPo=l(),u1=a("li"),bpe=a("strong"),cPo=o("big_bird"),fPo=o(" \u2014 "),hV=a("a"),mPo=o("BigBirdForCausalLM"),gPo=o(" (BigBird model)"),hPo=l(),b1=a("li"),vpe=a("strong"),pPo=o("bigbird_pegasus"),_Po=o(" \u2014 "),pV=a("a"),uPo=o("BigBirdPegasusForCausalLM"),bPo=o(" (BigBird-Pegasus model)"),vPo=l(),v1=a("li"),Fpe=a("strong"),FPo=o("blenderbot"),TPo=o(" \u2014 "),_V=a("a"),MPo=o("BlenderbotForCausalLM"),EPo=o(" (Blenderbot model)"),CPo=l(),F1=a("li"),Tpe=a("strong"),wPo=o("blenderbot-small"),APo=o(" \u2014 "),uV=a("a"),LPo=o("BlenderbotSmallForCausalLM"),yPo=o(" (BlenderbotSmall model)"),xPo=l(),T1=a("li"),Mpe=a("strong"),$Po=o("bloom"),kPo=o(" \u2014 "),bV=a("a"),SPo=o("BloomForCausalLM"),RPo=o(" (BLOOM model)"),PPo=l(),M1=a("li"),Epe=a("strong"),BPo=o("camembert"),IPo=o(" \u2014 "),vV=a("a"),NPo=o("CamembertForCausalLM"),qPo=o(" (CamemBERT model)"),jPo=l(),E1=a("li"),Cpe=a("strong"),DPo=o("codegen"),GPo=o(" \u2014 "),FV=a("a"),OPo=o("CodeGenForCausalLM"),VPo=o(" (CodeGen model)"),XPo=l(),C1=a("li"),wpe=a("strong"),zPo=o("ctrl"),WPo=o(" \u2014 "),TV=a("a"),QPo=o("CTRLLMHeadModel"),HPo=o(" (CTRL model)"),UPo=l(),w1=a("li"),Ape=a("strong"),JPo=o("data2vec-text"),YPo=o(" \u2014 "),MV=a("a"),KPo=o("Data2VecTextForCausalLM"),ZPo=o(" (Data2VecText model)"),eBo=l(),A1=a("li"),Lpe=a("strong"),oBo=o("electra"),rBo=o(" \u2014 "),EV=a("a"),tBo=o("ElectraForCausalLM"),aBo=o(" (ELECTRA model)"),nBo=l(),L1=a("li"),ype=a("strong"),sBo=o("gpt2"),lBo=o(" \u2014 "),CV=a("a"),iBo=o("GPT2LMHeadModel"),dBo=o(" (OpenAI GPT-2 model)"),cBo=l(),y1=a("li"),xpe=a("strong"),fBo=o("gpt_neo"),mBo=o(" \u2014 "),wV=a("a"),gBo=o("GPTNeoForCausalLM"),hBo=o(" (GPT Neo model)"),pBo=l(),x1=a("li"),$pe=a("strong"),_Bo=o("gpt_neox"),uBo=o(" \u2014 "),AV=a("a"),bBo=o("GPTNeoXForCausalLM"),vBo=o(" (GPT NeoX model)"),FBo=l(),$1=a("li"),kpe=a("strong"),TBo=o("gptj"),MBo=o(" \u2014 "),LV=a("a"),EBo=o("GPTJForCausalLM"),CBo=o(" (GPT-J model)"),wBo=l(),k1=a("li"),Spe=a("strong"),ABo=o("marian"),LBo=o(" \u2014 "),yV=a("a"),yBo=o("MarianForCausalLM"),xBo=o(" (Marian model)"),$Bo=l(),S1=a("li"),Rpe=a("strong"),kBo=o("mbart"),SBo=o(" \u2014 "),xV=a("a"),RBo=o("MBartForCausalLM"),PBo=o(" (mBART model)"),BBo=l(),R1=a("li"),Ppe=a("strong"),IBo=o("megatron-bert"),NBo=o(" \u2014 "),$V=a("a"),qBo=o("MegatronBertForCausalLM"),jBo=o(" (Megatron-BERT model)"),DBo=l(),P1=a("li"),Bpe=a("strong"),GBo=o("mvp"),OBo=o(" \u2014 "),kV=a("a"),VBo=o("MvpForCausalLM"),XBo=o(" (MVP model)"),zBo=l(),B1=a("li"),Ipe=a("strong"),WBo=o("openai-gpt"),QBo=o(" \u2014 "),SV=a("a"),HBo=o("OpenAIGPTLMHeadModel"),UBo=o(" (OpenAI GPT model)"),JBo=l(),I1=a("li"),Npe=a("strong"),YBo=o("opt"),KBo=o(" \u2014 "),RV=a("a"),ZBo=o("OPTForCausalLM"),eIo=o(" (OPT model)"),oIo=l(),N1=a("li"),qpe=a("strong"),rIo=o("pegasus"),tIo=o(" \u2014 "),PV=a("a"),aIo=o("PegasusForCausalLM"),nIo=o(" (Pegasus model)"),sIo=l(),q1=a("li"),jpe=a("strong"),lIo=o("plbart"),iIo=o(" \u2014 "),BV=a("a"),dIo=o("PLBartForCausalLM"),cIo=o(" (PLBart model)"),fIo=l(),j1=a("li"),Dpe=a("strong"),mIo=o("prophetnet"),gIo=o(" \u2014 "),IV=a("a"),hIo=o("ProphetNetForCausalLM"),pIo=o(" (ProphetNet model)"),_Io=l(),D1=a("li"),Gpe=a("strong"),uIo=o("qdqbert"),bIo=o(" \u2014 "),NV=a("a"),vIo=o("QDQBertLMHeadModel"),FIo=o(" (QDQBert model)"),TIo=l(),G1=a("li"),Ope=a("strong"),MIo=o("reformer"),EIo=o(" \u2014 "),qV=a("a"),CIo=o("ReformerModelWithLMHead"),wIo=o(" (Reformer model)"),AIo=l(),O1=a("li"),Vpe=a("strong"),LIo=o("rembert"),yIo=o(" \u2014 "),jV=a("a"),xIo=o("RemBertForCausalLM"),$Io=o(" (RemBERT model)"),kIo=l(),V1=a("li"),Xpe=a("strong"),SIo=o("roberta"),RIo=o(" \u2014 "),DV=a("a"),PIo=o("RobertaForCausalLM"),BIo=o(" (RoBERTa model)"),IIo=l(),X1=a("li"),zpe=a("strong"),NIo=o("roformer"),qIo=o(" \u2014 "),GV=a("a"),jIo=o("RoFormerForCausalLM"),DIo=o(" (RoFormer model)"),GIo=l(),z1=a("li"),Wpe=a("strong"),OIo=o("speech_to_text_2"),VIo=o(" \u2014 "),OV=a("a"),XIo=o("Speech2Text2ForCausalLM"),zIo=o(" (Speech2Text2 model)"),WIo=l(),W1=a("li"),Qpe=a("strong"),QIo=o("transfo-xl"),HIo=o(" \u2014 "),VV=a("a"),UIo=o("TransfoXLLMHeadModel"),JIo=o(" (Transformer-XL model)"),YIo=l(),Q1=a("li"),Hpe=a("strong"),KIo=o("trocr"),ZIo=o(" \u2014 "),XV=a("a"),eNo=o("TrOCRForCausalLM"),oNo=o(" (TrOCR model)"),rNo=l(),H1=a("li"),Upe=a("strong"),tNo=o("xglm"),aNo=o(" \u2014 "),zV=a("a"),nNo=o("XGLMForCausalLM"),sNo=o(" (XGLM model)"),lNo=l(),U1=a("li"),Jpe=a("strong"),iNo=o("xlm"),dNo=o(" \u2014 "),WV=a("a"),cNo=o("XLMWithLMHeadModel"),fNo=o(" (XLM model)"),mNo=l(),J1=a("li"),Ype=a("strong"),gNo=o("xlm-prophetnet"),hNo=o(" \u2014 "),QV=a("a"),pNo=o("XLMProphetNetForCausalLM"),_No=o(" (XLM-ProphetNet model)"),uNo=l(),Y1=a("li"),Kpe=a("strong"),bNo=o("xlm-roberta"),vNo=o(" \u2014 "),HV=a("a"),FNo=o("XLMRobertaForCausalLM"),TNo=o(" (XLM-RoBERTa model)"),MNo=l(),K1=a("li"),Zpe=a("strong"),ENo=o("xlm-roberta-xl"),CNo=o(" \u2014 "),UV=a("a"),wNo=o("XLMRobertaXLForCausalLM"),ANo=o(" (XLM-RoBERTa-XL model)"),LNo=l(),Z1=a("li"),e_e=a("strong"),yNo=o("xlnet"),xNo=o(" \u2014 "),JV=a("a"),$No=o("XLNetLMHeadModel"),kNo=o(" (XLNet model)"),SNo=l(),e2=a("p"),RNo=o("The model is set in evaluation mode by default using "),o_e=a("code"),PNo=o("model.eval()"),BNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r_e=a("code"),INo=o("model.train()"),NNo=l(),F(o2.$$.fragment),aQe=l(),nd=a("h2"),r2=a("a"),t_e=a("span"),F(Py.$$.fragment),qNo=l(),a_e=a("span"),jNo=o("AutoModelForMaskedLM"),nQe=l(),Bo=a("div"),F(By.$$.fragment),DNo=l(),sd=a("p"),GNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),YV=a("a"),ONo=o("from_pretrained()"),VNo=o(" class method or the "),KV=a("a"),XNo=o("from_config()"),zNo=o(` class
method.`),WNo=l(),Iy=a("p"),QNo=o("This class cannot be instantiated directly using "),n_e=a("code"),HNo=o("__init__()"),UNo=o(" (throws an error)."),JNo=l(),gt=a("div"),F(Ny.$$.fragment),YNo=l(),s_e=a("p"),KNo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),ZNo=l(),ld=a("p"),eqo=o(`Note:
Loading a model from its configuration file does `),l_e=a("strong"),oqo=o("not"),rqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZV=a("a"),tqo=o("from_pretrained()"),aqo=o(" to load the model weights."),nqo=l(),F(t2.$$.fragment),sqo=l(),eo=a("div"),F(qy.$$.fragment),lqo=l(),i_e=a("p"),iqo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),dqo=l(),Va=a("p"),cqo=o("The model class to instantiate is selected based on the "),d_e=a("code"),fqo=o("model_type"),mqo=o(` property of the config object (either
passed as an argument or loaded from `),c_e=a("code"),gqo=o("pretrained_model_name_or_path"),hqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f_e=a("code"),pqo=o("pretrained_model_name_or_path"),_qo=o(":"),uqo=l(),Q=a("ul"),a2=a("li"),m_e=a("strong"),bqo=o("albert"),vqo=o(" \u2014 "),eX=a("a"),Fqo=o("AlbertForMaskedLM"),Tqo=o(" (ALBERT model)"),Mqo=l(),n2=a("li"),g_e=a("strong"),Eqo=o("bart"),Cqo=o(" \u2014 "),oX=a("a"),wqo=o("BartForConditionalGeneration"),Aqo=o(" (BART model)"),Lqo=l(),s2=a("li"),h_e=a("strong"),yqo=o("bert"),xqo=o(" \u2014 "),rX=a("a"),$qo=o("BertForMaskedLM"),kqo=o(" (BERT model)"),Sqo=l(),l2=a("li"),p_e=a("strong"),Rqo=o("big_bird"),Pqo=o(" \u2014 "),tX=a("a"),Bqo=o("BigBirdForMaskedLM"),Iqo=o(" (BigBird model)"),Nqo=l(),i2=a("li"),__e=a("strong"),qqo=o("camembert"),jqo=o(" \u2014 "),aX=a("a"),Dqo=o("CamembertForMaskedLM"),Gqo=o(" (CamemBERT model)"),Oqo=l(),d2=a("li"),u_e=a("strong"),Vqo=o("convbert"),Xqo=o(" \u2014 "),nX=a("a"),zqo=o("ConvBertForMaskedLM"),Wqo=o(" (ConvBERT model)"),Qqo=l(),c2=a("li"),b_e=a("strong"),Hqo=o("data2vec-text"),Uqo=o(" \u2014 "),sX=a("a"),Jqo=o("Data2VecTextForMaskedLM"),Yqo=o(" (Data2VecText model)"),Kqo=l(),f2=a("li"),v_e=a("strong"),Zqo=o("deberta"),ejo=o(" \u2014 "),lX=a("a"),ojo=o("DebertaForMaskedLM"),rjo=o(" (DeBERTa model)"),tjo=l(),m2=a("li"),F_e=a("strong"),ajo=o("deberta-v2"),njo=o(" \u2014 "),iX=a("a"),sjo=o("DebertaV2ForMaskedLM"),ljo=o(" (DeBERTa-v2 model)"),ijo=l(),g2=a("li"),T_e=a("strong"),djo=o("distilbert"),cjo=o(" \u2014 "),dX=a("a"),fjo=o("DistilBertForMaskedLM"),mjo=o(" (DistilBERT model)"),gjo=l(),h2=a("li"),M_e=a("strong"),hjo=o("electra"),pjo=o(" \u2014 "),cX=a("a"),_jo=o("ElectraForMaskedLM"),ujo=o(" (ELECTRA model)"),bjo=l(),p2=a("li"),E_e=a("strong"),vjo=o("flaubert"),Fjo=o(" \u2014 "),fX=a("a"),Tjo=o("FlaubertWithLMHeadModel"),Mjo=o(" (FlauBERT model)"),Ejo=l(),_2=a("li"),C_e=a("strong"),Cjo=o("fnet"),wjo=o(" \u2014 "),mX=a("a"),Ajo=o("FNetForMaskedLM"),Ljo=o(" (FNet model)"),yjo=l(),u2=a("li"),w_e=a("strong"),xjo=o("funnel"),$jo=o(" \u2014 "),gX=a("a"),kjo=o("FunnelForMaskedLM"),Sjo=o(" (Funnel Transformer model)"),Rjo=l(),b2=a("li"),A_e=a("strong"),Pjo=o("ibert"),Bjo=o(" \u2014 "),hX=a("a"),Ijo=o("IBertForMaskedLM"),Njo=o(" (I-BERT model)"),qjo=l(),v2=a("li"),L_e=a("strong"),jjo=o("layoutlm"),Djo=o(" \u2014 "),pX=a("a"),Gjo=o("LayoutLMForMaskedLM"),Ojo=o(" (LayoutLM model)"),Vjo=l(),F2=a("li"),y_e=a("strong"),Xjo=o("longformer"),zjo=o(" \u2014 "),_X=a("a"),Wjo=o("LongformerForMaskedLM"),Qjo=o(" (Longformer model)"),Hjo=l(),T2=a("li"),x_e=a("strong"),Ujo=o("luke"),Jjo=o(" \u2014 "),uX=a("a"),Yjo=o("LukeForMaskedLM"),Kjo=o(" (LUKE model)"),Zjo=l(),M2=a("li"),$_e=a("strong"),eDo=o("mbart"),oDo=o(" \u2014 "),bX=a("a"),rDo=o("MBartForConditionalGeneration"),tDo=o(" (mBART model)"),aDo=l(),E2=a("li"),k_e=a("strong"),nDo=o("megatron-bert"),sDo=o(" \u2014 "),vX=a("a"),lDo=o("MegatronBertForMaskedLM"),iDo=o(" (Megatron-BERT model)"),dDo=l(),C2=a("li"),S_e=a("strong"),cDo=o("mobilebert"),fDo=o(" \u2014 "),FX=a("a"),mDo=o("MobileBertForMaskedLM"),gDo=o(" (MobileBERT model)"),hDo=l(),w2=a("li"),R_e=a("strong"),pDo=o("mpnet"),_Do=o(" \u2014 "),TX=a("a"),uDo=o("MPNetForMaskedLM"),bDo=o(" (MPNet model)"),vDo=l(),A2=a("li"),P_e=a("strong"),FDo=o("mvp"),TDo=o(" \u2014 "),MX=a("a"),MDo=o("MvpForConditionalGeneration"),EDo=o(" (MVP model)"),CDo=l(),L2=a("li"),B_e=a("strong"),wDo=o("nezha"),ADo=o(" \u2014 "),EX=a("a"),LDo=o("NezhaForMaskedLM"),yDo=o(" (Nezha model)"),xDo=l(),y2=a("li"),I_e=a("strong"),$Do=o("nystromformer"),kDo=o(" \u2014 "),CX=a("a"),SDo=o("NystromformerForMaskedLM"),RDo=o(" (Nystr\xF6mformer model)"),PDo=l(),x2=a("li"),N_e=a("strong"),BDo=o("perceiver"),IDo=o(" \u2014 "),wX=a("a"),NDo=o("PerceiverForMaskedLM"),qDo=o(" (Perceiver model)"),jDo=l(),$2=a("li"),q_e=a("strong"),DDo=o("qdqbert"),GDo=o(" \u2014 "),AX=a("a"),ODo=o("QDQBertForMaskedLM"),VDo=o(" (QDQBert model)"),XDo=l(),k2=a("li"),j_e=a("strong"),zDo=o("reformer"),WDo=o(" \u2014 "),LX=a("a"),QDo=o("ReformerForMaskedLM"),HDo=o(" (Reformer model)"),UDo=l(),S2=a("li"),D_e=a("strong"),JDo=o("rembert"),YDo=o(" \u2014 "),yX=a("a"),KDo=o("RemBertForMaskedLM"),ZDo=o(" (RemBERT model)"),eGo=l(),R2=a("li"),G_e=a("strong"),oGo=o("roberta"),rGo=o(" \u2014 "),xX=a("a"),tGo=o("RobertaForMaskedLM"),aGo=o(" (RoBERTa model)"),nGo=l(),P2=a("li"),O_e=a("strong"),sGo=o("roformer"),lGo=o(" \u2014 "),$X=a("a"),iGo=o("RoFormerForMaskedLM"),dGo=o(" (RoFormer model)"),cGo=l(),B2=a("li"),V_e=a("strong"),fGo=o("squeezebert"),mGo=o(" \u2014 "),kX=a("a"),gGo=o("SqueezeBertForMaskedLM"),hGo=o(" (SqueezeBERT model)"),pGo=l(),I2=a("li"),X_e=a("strong"),_Go=o("tapas"),uGo=o(" \u2014 "),SX=a("a"),bGo=o("TapasForMaskedLM"),vGo=o(" (TAPAS model)"),FGo=l(),N2=a("li"),z_e=a("strong"),TGo=o("wav2vec2"),MGo=o(" \u2014 "),W_e=a("code"),EGo=o("Wav2Vec2ForMaskedLM"),CGo=o(" (Wav2Vec2 model)"),wGo=l(),q2=a("li"),Q_e=a("strong"),AGo=o("xlm"),LGo=o(" \u2014 "),RX=a("a"),yGo=o("XLMWithLMHeadModel"),xGo=o(" (XLM model)"),$Go=l(),j2=a("li"),H_e=a("strong"),kGo=o("xlm-roberta"),SGo=o(" \u2014 "),PX=a("a"),RGo=o("XLMRobertaForMaskedLM"),PGo=o(" (XLM-RoBERTa model)"),BGo=l(),D2=a("li"),U_e=a("strong"),IGo=o("xlm-roberta-xl"),NGo=o(" \u2014 "),BX=a("a"),qGo=o("XLMRobertaXLForMaskedLM"),jGo=o(" (XLM-RoBERTa-XL model)"),DGo=l(),G2=a("li"),J_e=a("strong"),GGo=o("yoso"),OGo=o(" \u2014 "),IX=a("a"),VGo=o("YosoForMaskedLM"),XGo=o(" (YOSO model)"),zGo=l(),O2=a("p"),WGo=o("The model is set in evaluation mode by default using "),Y_e=a("code"),QGo=o("model.eval()"),HGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K_e=a("code"),UGo=o("model.train()"),JGo=l(),F(V2.$$.fragment),sQe=l(),id=a("h2"),X2=a("a"),Z_e=a("span"),F(jy.$$.fragment),YGo=l(),eue=a("span"),KGo=o("AutoModelForSeq2SeqLM"),lQe=l(),Io=a("div"),F(Dy.$$.fragment),ZGo=l(),dd=a("p"),eOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),NX=a("a"),oOo=o("from_pretrained()"),rOo=o(" class method or the "),qX=a("a"),tOo=o("from_config()"),aOo=o(` class
method.`),nOo=l(),Gy=a("p"),sOo=o("This class cannot be instantiated directly using "),oue=a("code"),lOo=o("__init__()"),iOo=o(" (throws an error)."),dOo=l(),ht=a("div"),F(Oy.$$.fragment),cOo=l(),rue=a("p"),fOo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),mOo=l(),cd=a("p"),gOo=o(`Note:
Loading a model from its configuration file does `),tue=a("strong"),hOo=o("not"),pOo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jX=a("a"),_Oo=o("from_pretrained()"),uOo=o(" to load the model weights."),bOo=l(),F(z2.$$.fragment),vOo=l(),oo=a("div"),F(Vy.$$.fragment),FOo=l(),aue=a("p"),TOo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),MOo=l(),Xa=a("p"),EOo=o("The model class to instantiate is selected based on the "),nue=a("code"),COo=o("model_type"),wOo=o(` property of the config object (either
passed as an argument or loaded from `),sue=a("code"),AOo=o("pretrained_model_name_or_path"),LOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lue=a("code"),yOo=o("pretrained_model_name_or_path"),xOo=o(":"),$Oo=l(),me=a("ul"),W2=a("li"),iue=a("strong"),kOo=o("bart"),SOo=o(" \u2014 "),DX=a("a"),ROo=o("BartForConditionalGeneration"),POo=o(" (BART model)"),BOo=l(),Q2=a("li"),due=a("strong"),IOo=o("bigbird_pegasus"),NOo=o(" \u2014 "),GX=a("a"),qOo=o("BigBirdPegasusForConditionalGeneration"),jOo=o(" (BigBird-Pegasus model)"),DOo=l(),H2=a("li"),cue=a("strong"),GOo=o("blenderbot"),OOo=o(" \u2014 "),OX=a("a"),VOo=o("BlenderbotForConditionalGeneration"),XOo=o(" (Blenderbot model)"),zOo=l(),U2=a("li"),fue=a("strong"),WOo=o("blenderbot-small"),QOo=o(" \u2014 "),VX=a("a"),HOo=o("BlenderbotSmallForConditionalGeneration"),UOo=o(" (BlenderbotSmall model)"),JOo=l(),J2=a("li"),mue=a("strong"),YOo=o("encoder-decoder"),KOo=o(" \u2014 "),XX=a("a"),ZOo=o("EncoderDecoderModel"),eVo=o(" (Encoder decoder model)"),oVo=l(),Y2=a("li"),gue=a("strong"),rVo=o("fsmt"),tVo=o(" \u2014 "),zX=a("a"),aVo=o("FSMTForConditionalGeneration"),nVo=o(" (FairSeq Machine-Translation model)"),sVo=l(),K2=a("li"),hue=a("strong"),lVo=o("led"),iVo=o(" \u2014 "),WX=a("a"),dVo=o("LEDForConditionalGeneration"),cVo=o(" (LED model)"),fVo=l(),Z2=a("li"),pue=a("strong"),mVo=o("longt5"),gVo=o(" \u2014 "),QX=a("a"),hVo=o("LongT5ForConditionalGeneration"),pVo=o(" (LongT5 model)"),_Vo=l(),eb=a("li"),_ue=a("strong"),uVo=o("m2m_100"),bVo=o(" \u2014 "),HX=a("a"),vVo=o("M2M100ForConditionalGeneration"),FVo=o(" (M2M100 model)"),TVo=l(),ob=a("li"),uue=a("strong"),MVo=o("marian"),EVo=o(" \u2014 "),UX=a("a"),CVo=o("MarianMTModel"),wVo=o(" (Marian model)"),AVo=l(),rb=a("li"),bue=a("strong"),LVo=o("mbart"),yVo=o(" \u2014 "),JX=a("a"),xVo=o("MBartForConditionalGeneration"),$Vo=o(" (mBART model)"),kVo=l(),tb=a("li"),vue=a("strong"),SVo=o("mt5"),RVo=o(" \u2014 "),YX=a("a"),PVo=o("MT5ForConditionalGeneration"),BVo=o(" (MT5 model)"),IVo=l(),ab=a("li"),Fue=a("strong"),NVo=o("mvp"),qVo=o(" \u2014 "),KX=a("a"),jVo=o("MvpForConditionalGeneration"),DVo=o(" (MVP model)"),GVo=l(),nb=a("li"),Tue=a("strong"),OVo=o("nllb"),VVo=o(" \u2014 "),ZX=a("a"),XVo=o("M2M100ForConditionalGeneration"),zVo=o(" (NLLB model)"),WVo=l(),sb=a("li"),Mue=a("strong"),QVo=o("pegasus"),HVo=o(" \u2014 "),ez=a("a"),UVo=o("PegasusForConditionalGeneration"),JVo=o(" (Pegasus model)"),YVo=l(),lb=a("li"),Eue=a("strong"),KVo=o("plbart"),ZVo=o(" \u2014 "),oz=a("a"),eXo=o("PLBartForConditionalGeneration"),oXo=o(" (PLBart model)"),rXo=l(),ib=a("li"),Cue=a("strong"),tXo=o("prophetnet"),aXo=o(" \u2014 "),rz=a("a"),nXo=o("ProphetNetForConditionalGeneration"),sXo=o(" (ProphetNet model)"),lXo=l(),db=a("li"),wue=a("strong"),iXo=o("t5"),dXo=o(" \u2014 "),tz=a("a"),cXo=o("T5ForConditionalGeneration"),fXo=o(" (T5 model)"),mXo=l(),cb=a("li"),Aue=a("strong"),gXo=o("xlm-prophetnet"),hXo=o(" \u2014 "),az=a("a"),pXo=o("XLMProphetNetForConditionalGeneration"),_Xo=o(" (XLM-ProphetNet model)"),uXo=l(),fb=a("p"),bXo=o("The model is set in evaluation mode by default using "),Lue=a("code"),vXo=o("model.eval()"),FXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yue=a("code"),TXo=o("model.train()"),MXo=l(),F(mb.$$.fragment),iQe=l(),fd=a("h2"),gb=a("a"),xue=a("span"),F(Xy.$$.fragment),EXo=l(),$ue=a("span"),CXo=o("AutoModelForSequenceClassification"),dQe=l(),No=a("div"),F(zy.$$.fragment),wXo=l(),md=a("p"),AXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nz=a("a"),LXo=o("from_pretrained()"),yXo=o(" class method or the "),sz=a("a"),xXo=o("from_config()"),$Xo=o(` class
method.`),kXo=l(),Wy=a("p"),SXo=o("This class cannot be instantiated directly using "),kue=a("code"),RXo=o("__init__()"),PXo=o(" (throws an error)."),BXo=l(),pt=a("div"),F(Qy.$$.fragment),IXo=l(),Sue=a("p"),NXo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),qXo=l(),gd=a("p"),jXo=o(`Note:
Loading a model from its configuration file does `),Rue=a("strong"),DXo=o("not"),GXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lz=a("a"),OXo=o("from_pretrained()"),VXo=o(" to load the model weights."),XXo=l(),F(hb.$$.fragment),zXo=l(),ro=a("div"),F(Hy.$$.fragment),WXo=l(),Pue=a("p"),QXo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),HXo=l(),za=a("p"),UXo=o("The model class to instantiate is selected based on the "),Bue=a("code"),JXo=o("model_type"),YXo=o(` property of the config object (either
passed as an argument or loaded from `),Iue=a("code"),KXo=o("pretrained_model_name_or_path"),ZXo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nue=a("code"),ezo=o("pretrained_model_name_or_path"),ozo=o(":"),rzo=l(),B=a("ul"),pb=a("li"),que=a("strong"),tzo=o("albert"),azo=o(" \u2014 "),iz=a("a"),nzo=o("AlbertForSequenceClassification"),szo=o(" (ALBERT model)"),lzo=l(),_b=a("li"),jue=a("strong"),izo=o("bart"),dzo=o(" \u2014 "),dz=a("a"),czo=o("BartForSequenceClassification"),fzo=o(" (BART model)"),mzo=l(),ub=a("li"),Due=a("strong"),gzo=o("bert"),hzo=o(" \u2014 "),cz=a("a"),pzo=o("BertForSequenceClassification"),_zo=o(" (BERT model)"),uzo=l(),bb=a("li"),Gue=a("strong"),bzo=o("big_bird"),vzo=o(" \u2014 "),fz=a("a"),Fzo=o("BigBirdForSequenceClassification"),Tzo=o(" (BigBird model)"),Mzo=l(),vb=a("li"),Oue=a("strong"),Ezo=o("bigbird_pegasus"),Czo=o(" \u2014 "),mz=a("a"),wzo=o("BigBirdPegasusForSequenceClassification"),Azo=o(" (BigBird-Pegasus model)"),Lzo=l(),Fb=a("li"),Vue=a("strong"),yzo=o("bloom"),xzo=o(" \u2014 "),gz=a("a"),$zo=o("BloomForSequenceClassification"),kzo=o(" (BLOOM model)"),Szo=l(),Tb=a("li"),Xue=a("strong"),Rzo=o("camembert"),Pzo=o(" \u2014 "),hz=a("a"),Bzo=o("CamembertForSequenceClassification"),Izo=o(" (CamemBERT model)"),Nzo=l(),Mb=a("li"),zue=a("strong"),qzo=o("canine"),jzo=o(" \u2014 "),pz=a("a"),Dzo=o("CanineForSequenceClassification"),Gzo=o(" (CANINE model)"),Ozo=l(),Eb=a("li"),Wue=a("strong"),Vzo=o("convbert"),Xzo=o(" \u2014 "),_z=a("a"),zzo=o("ConvBertForSequenceClassification"),Wzo=o(" (ConvBERT model)"),Qzo=l(),Cb=a("li"),Que=a("strong"),Hzo=o("ctrl"),Uzo=o(" \u2014 "),uz=a("a"),Jzo=o("CTRLForSequenceClassification"),Yzo=o(" (CTRL model)"),Kzo=l(),wb=a("li"),Hue=a("strong"),Zzo=o("data2vec-text"),eWo=o(" \u2014 "),bz=a("a"),oWo=o("Data2VecTextForSequenceClassification"),rWo=o(" (Data2VecText model)"),tWo=l(),Ab=a("li"),Uue=a("strong"),aWo=o("deberta"),nWo=o(" \u2014 "),vz=a("a"),sWo=o("DebertaForSequenceClassification"),lWo=o(" (DeBERTa model)"),iWo=l(),Lb=a("li"),Jue=a("strong"),dWo=o("deberta-v2"),cWo=o(" \u2014 "),Fz=a("a"),fWo=o("DebertaV2ForSequenceClassification"),mWo=o(" (DeBERTa-v2 model)"),gWo=l(),yb=a("li"),Yue=a("strong"),hWo=o("distilbert"),pWo=o(" \u2014 "),Tz=a("a"),_Wo=o("DistilBertForSequenceClassification"),uWo=o(" (DistilBERT model)"),bWo=l(),xb=a("li"),Kue=a("strong"),vWo=o("electra"),FWo=o(" \u2014 "),Mz=a("a"),TWo=o("ElectraForSequenceClassification"),MWo=o(" (ELECTRA model)"),EWo=l(),$b=a("li"),Zue=a("strong"),CWo=o("flaubert"),wWo=o(" \u2014 "),Ez=a("a"),AWo=o("FlaubertForSequenceClassification"),LWo=o(" (FlauBERT model)"),yWo=l(),kb=a("li"),e7e=a("strong"),xWo=o("fnet"),$Wo=o(" \u2014 "),Cz=a("a"),kWo=o("FNetForSequenceClassification"),SWo=o(" (FNet model)"),RWo=l(),Sb=a("li"),o7e=a("strong"),PWo=o("funnel"),BWo=o(" \u2014 "),wz=a("a"),IWo=o("FunnelForSequenceClassification"),NWo=o(" (Funnel Transformer model)"),qWo=l(),Rb=a("li"),r7e=a("strong"),jWo=o("gpt2"),DWo=o(" \u2014 "),Az=a("a"),GWo=o("GPT2ForSequenceClassification"),OWo=o(" (OpenAI GPT-2 model)"),VWo=l(),Pb=a("li"),t7e=a("strong"),XWo=o("gpt_neo"),zWo=o(" \u2014 "),Lz=a("a"),WWo=o("GPTNeoForSequenceClassification"),QWo=o(" (GPT Neo model)"),HWo=l(),Bb=a("li"),a7e=a("strong"),UWo=o("gptj"),JWo=o(" \u2014 "),yz=a("a"),YWo=o("GPTJForSequenceClassification"),KWo=o(" (GPT-J model)"),ZWo=l(),Ib=a("li"),n7e=a("strong"),eQo=o("ibert"),oQo=o(" \u2014 "),xz=a("a"),rQo=o("IBertForSequenceClassification"),tQo=o(" (I-BERT model)"),aQo=l(),Nb=a("li"),s7e=a("strong"),nQo=o("layoutlm"),sQo=o(" \u2014 "),$z=a("a"),lQo=o("LayoutLMForSequenceClassification"),iQo=o(" (LayoutLM model)"),dQo=l(),qb=a("li"),l7e=a("strong"),cQo=o("layoutlmv2"),fQo=o(" \u2014 "),kz=a("a"),mQo=o("LayoutLMv2ForSequenceClassification"),gQo=o(" (LayoutLMv2 model)"),hQo=l(),jb=a("li"),i7e=a("strong"),pQo=o("layoutlmv3"),_Qo=o(" \u2014 "),Sz=a("a"),uQo=o("LayoutLMv3ForSequenceClassification"),bQo=o(" (LayoutLMv3 model)"),vQo=l(),Db=a("li"),d7e=a("strong"),FQo=o("led"),TQo=o(" \u2014 "),Rz=a("a"),MQo=o("LEDForSequenceClassification"),EQo=o(" (LED model)"),CQo=l(),Gb=a("li"),c7e=a("strong"),wQo=o("longformer"),AQo=o(" \u2014 "),Pz=a("a"),LQo=o("LongformerForSequenceClassification"),yQo=o(" (Longformer model)"),xQo=l(),Ob=a("li"),f7e=a("strong"),$Qo=o("luke"),kQo=o(" \u2014 "),Bz=a("a"),SQo=o("LukeForSequenceClassification"),RQo=o(" (LUKE model)"),PQo=l(),Vb=a("li"),m7e=a("strong"),BQo=o("mbart"),IQo=o(" \u2014 "),Iz=a("a"),NQo=o("MBartForSequenceClassification"),qQo=o(" (mBART model)"),jQo=l(),Xb=a("li"),g7e=a("strong"),DQo=o("megatron-bert"),GQo=o(" \u2014 "),Nz=a("a"),OQo=o("MegatronBertForSequenceClassification"),VQo=o(" (Megatron-BERT model)"),XQo=l(),zb=a("li"),h7e=a("strong"),zQo=o("mobilebert"),WQo=o(" \u2014 "),qz=a("a"),QQo=o("MobileBertForSequenceClassification"),HQo=o(" (MobileBERT model)"),UQo=l(),Wb=a("li"),p7e=a("strong"),JQo=o("mpnet"),YQo=o(" \u2014 "),jz=a("a"),KQo=o("MPNetForSequenceClassification"),ZQo=o(" (MPNet model)"),eHo=l(),Qb=a("li"),_7e=a("strong"),oHo=o("mvp"),rHo=o(" \u2014 "),Dz=a("a"),tHo=o("MvpForSequenceClassification"),aHo=o(" (MVP model)"),nHo=l(),Hb=a("li"),u7e=a("strong"),sHo=o("nezha"),lHo=o(" \u2014 "),Gz=a("a"),iHo=o("NezhaForSequenceClassification"),dHo=o(" (Nezha model)"),cHo=l(),Ub=a("li"),b7e=a("strong"),fHo=o("nystromformer"),mHo=o(" \u2014 "),Oz=a("a"),gHo=o("NystromformerForSequenceClassification"),hHo=o(" (Nystr\xF6mformer model)"),pHo=l(),Jb=a("li"),v7e=a("strong"),_Ho=o("openai-gpt"),uHo=o(" \u2014 "),Vz=a("a"),bHo=o("OpenAIGPTForSequenceClassification"),vHo=o(" (OpenAI GPT model)"),FHo=l(),Yb=a("li"),F7e=a("strong"),THo=o("opt"),MHo=o(" \u2014 "),Xz=a("a"),EHo=o("OPTForSequenceClassification"),CHo=o(" (OPT model)"),wHo=l(),Kb=a("li"),T7e=a("strong"),AHo=o("perceiver"),LHo=o(" \u2014 "),zz=a("a"),yHo=o("PerceiverForSequenceClassification"),xHo=o(" (Perceiver model)"),$Ho=l(),Zb=a("li"),M7e=a("strong"),kHo=o("plbart"),SHo=o(" \u2014 "),Wz=a("a"),RHo=o("PLBartForSequenceClassification"),PHo=o(" (PLBart model)"),BHo=l(),ev=a("li"),E7e=a("strong"),IHo=o("qdqbert"),NHo=o(" \u2014 "),Qz=a("a"),qHo=o("QDQBertForSequenceClassification"),jHo=o(" (QDQBert model)"),DHo=l(),ov=a("li"),C7e=a("strong"),GHo=o("reformer"),OHo=o(" \u2014 "),Hz=a("a"),VHo=o("ReformerForSequenceClassification"),XHo=o(" (Reformer model)"),zHo=l(),rv=a("li"),w7e=a("strong"),WHo=o("rembert"),QHo=o(" \u2014 "),Uz=a("a"),HHo=o("RemBertForSequenceClassification"),UHo=o(" (RemBERT model)"),JHo=l(),tv=a("li"),A7e=a("strong"),YHo=o("roberta"),KHo=o(" \u2014 "),Jz=a("a"),ZHo=o("RobertaForSequenceClassification"),eUo=o(" (RoBERTa model)"),oUo=l(),av=a("li"),L7e=a("strong"),rUo=o("roformer"),tUo=o(" \u2014 "),Yz=a("a"),aUo=o("RoFormerForSequenceClassification"),nUo=o(" (RoFormer model)"),sUo=l(),nv=a("li"),y7e=a("strong"),lUo=o("squeezebert"),iUo=o(" \u2014 "),Kz=a("a"),dUo=o("SqueezeBertForSequenceClassification"),cUo=o(" (SqueezeBERT model)"),fUo=l(),sv=a("li"),x7e=a("strong"),mUo=o("tapas"),gUo=o(" \u2014 "),Zz=a("a"),hUo=o("TapasForSequenceClassification"),pUo=o(" (TAPAS model)"),_Uo=l(),lv=a("li"),$7e=a("strong"),uUo=o("transfo-xl"),bUo=o(" \u2014 "),eW=a("a"),vUo=o("TransfoXLForSequenceClassification"),FUo=o(" (Transformer-XL model)"),TUo=l(),iv=a("li"),k7e=a("strong"),MUo=o("xlm"),EUo=o(" \u2014 "),oW=a("a"),CUo=o("XLMForSequenceClassification"),wUo=o(" (XLM model)"),AUo=l(),dv=a("li"),S7e=a("strong"),LUo=o("xlm-roberta"),yUo=o(" \u2014 "),rW=a("a"),xUo=o("XLMRobertaForSequenceClassification"),$Uo=o(" (XLM-RoBERTa model)"),kUo=l(),cv=a("li"),R7e=a("strong"),SUo=o("xlm-roberta-xl"),RUo=o(" \u2014 "),tW=a("a"),PUo=o("XLMRobertaXLForSequenceClassification"),BUo=o(" (XLM-RoBERTa-XL model)"),IUo=l(),fv=a("li"),P7e=a("strong"),NUo=o("xlnet"),qUo=o(" \u2014 "),aW=a("a"),jUo=o("XLNetForSequenceClassification"),DUo=o(" (XLNet model)"),GUo=l(),mv=a("li"),B7e=a("strong"),OUo=o("yoso"),VUo=o(" \u2014 "),nW=a("a"),XUo=o("YosoForSequenceClassification"),zUo=o(" (YOSO model)"),WUo=l(),gv=a("p"),QUo=o("The model is set in evaluation mode by default using "),I7e=a("code"),HUo=o("model.eval()"),UUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N7e=a("code"),JUo=o("model.train()"),YUo=l(),F(hv.$$.fragment),cQe=l(),hd=a("h2"),pv=a("a"),q7e=a("span"),F(Uy.$$.fragment),KUo=l(),j7e=a("span"),ZUo=o("AutoModelForMultipleChoice"),fQe=l(),qo=a("div"),F(Jy.$$.fragment),eJo=l(),pd=a("p"),oJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),sW=a("a"),rJo=o("from_pretrained()"),tJo=o(" class method or the "),lW=a("a"),aJo=o("from_config()"),nJo=o(` class
method.`),sJo=l(),Yy=a("p"),lJo=o("This class cannot be instantiated directly using "),D7e=a("code"),iJo=o("__init__()"),dJo=o(" (throws an error)."),cJo=l(),_t=a("div"),F(Ky.$$.fragment),fJo=l(),G7e=a("p"),mJo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),gJo=l(),_d=a("p"),hJo=o(`Note:
Loading a model from its configuration file does `),O7e=a("strong"),pJo=o("not"),_Jo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iW=a("a"),uJo=o("from_pretrained()"),bJo=o(" to load the model weights."),vJo=l(),F(_v.$$.fragment),FJo=l(),to=a("div"),F(Zy.$$.fragment),TJo=l(),V7e=a("p"),MJo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),EJo=l(),Wa=a("p"),CJo=o("The model class to instantiate is selected based on the "),X7e=a("code"),wJo=o("model_type"),AJo=o(` property of the config object (either
passed as an argument or loaded from `),z7e=a("code"),LJo=o("pretrained_model_name_or_path"),yJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W7e=a("code"),xJo=o("pretrained_model_name_or_path"),$Jo=o(":"),kJo=l(),Z=a("ul"),uv=a("li"),Q7e=a("strong"),SJo=o("albert"),RJo=o(" \u2014 "),dW=a("a"),PJo=o("AlbertForMultipleChoice"),BJo=o(" (ALBERT model)"),IJo=l(),bv=a("li"),H7e=a("strong"),NJo=o("bert"),qJo=o(" \u2014 "),cW=a("a"),jJo=o("BertForMultipleChoice"),DJo=o(" (BERT model)"),GJo=l(),vv=a("li"),U7e=a("strong"),OJo=o("big_bird"),VJo=o(" \u2014 "),fW=a("a"),XJo=o("BigBirdForMultipleChoice"),zJo=o(" (BigBird model)"),WJo=l(),Fv=a("li"),J7e=a("strong"),QJo=o("camembert"),HJo=o(" \u2014 "),mW=a("a"),UJo=o("CamembertForMultipleChoice"),JJo=o(" (CamemBERT model)"),YJo=l(),Tv=a("li"),Y7e=a("strong"),KJo=o("canine"),ZJo=o(" \u2014 "),gW=a("a"),eYo=o("CanineForMultipleChoice"),oYo=o(" (CANINE model)"),rYo=l(),Mv=a("li"),K7e=a("strong"),tYo=o("convbert"),aYo=o(" \u2014 "),hW=a("a"),nYo=o("ConvBertForMultipleChoice"),sYo=o(" (ConvBERT model)"),lYo=l(),Ev=a("li"),Z7e=a("strong"),iYo=o("data2vec-text"),dYo=o(" \u2014 "),pW=a("a"),cYo=o("Data2VecTextForMultipleChoice"),fYo=o(" (Data2VecText model)"),mYo=l(),Cv=a("li"),e1e=a("strong"),gYo=o("deberta-v2"),hYo=o(" \u2014 "),_W=a("a"),pYo=o("DebertaV2ForMultipleChoice"),_Yo=o(" (DeBERTa-v2 model)"),uYo=l(),wv=a("li"),o1e=a("strong"),bYo=o("distilbert"),vYo=o(" \u2014 "),uW=a("a"),FYo=o("DistilBertForMultipleChoice"),TYo=o(" (DistilBERT model)"),MYo=l(),Av=a("li"),r1e=a("strong"),EYo=o("electra"),CYo=o(" \u2014 "),bW=a("a"),wYo=o("ElectraForMultipleChoice"),AYo=o(" (ELECTRA model)"),LYo=l(),Lv=a("li"),t1e=a("strong"),yYo=o("flaubert"),xYo=o(" \u2014 "),vW=a("a"),$Yo=o("FlaubertForMultipleChoice"),kYo=o(" (FlauBERT model)"),SYo=l(),yv=a("li"),a1e=a("strong"),RYo=o("fnet"),PYo=o(" \u2014 "),FW=a("a"),BYo=o("FNetForMultipleChoice"),IYo=o(" (FNet model)"),NYo=l(),xv=a("li"),n1e=a("strong"),qYo=o("funnel"),jYo=o(" \u2014 "),TW=a("a"),DYo=o("FunnelForMultipleChoice"),GYo=o(" (Funnel Transformer model)"),OYo=l(),$v=a("li"),s1e=a("strong"),VYo=o("ibert"),XYo=o(" \u2014 "),MW=a("a"),zYo=o("IBertForMultipleChoice"),WYo=o(" (I-BERT model)"),QYo=l(),kv=a("li"),l1e=a("strong"),HYo=o("longformer"),UYo=o(" \u2014 "),EW=a("a"),JYo=o("LongformerForMultipleChoice"),YYo=o(" (Longformer model)"),KYo=l(),Sv=a("li"),i1e=a("strong"),ZYo=o("luke"),eKo=o(" \u2014 "),CW=a("a"),oKo=o("LukeForMultipleChoice"),rKo=o(" (LUKE model)"),tKo=l(),Rv=a("li"),d1e=a("strong"),aKo=o("megatron-bert"),nKo=o(" \u2014 "),wW=a("a"),sKo=o("MegatronBertForMultipleChoice"),lKo=o(" (Megatron-BERT model)"),iKo=l(),Pv=a("li"),c1e=a("strong"),dKo=o("mobilebert"),cKo=o(" \u2014 "),AW=a("a"),fKo=o("MobileBertForMultipleChoice"),mKo=o(" (MobileBERT model)"),gKo=l(),Bv=a("li"),f1e=a("strong"),hKo=o("mpnet"),pKo=o(" \u2014 "),LW=a("a"),_Ko=o("MPNetForMultipleChoice"),uKo=o(" (MPNet model)"),bKo=l(),Iv=a("li"),m1e=a("strong"),vKo=o("nezha"),FKo=o(" \u2014 "),yW=a("a"),TKo=o("NezhaForMultipleChoice"),MKo=o(" (Nezha model)"),EKo=l(),Nv=a("li"),g1e=a("strong"),CKo=o("nystromformer"),wKo=o(" \u2014 "),xW=a("a"),AKo=o("NystromformerForMultipleChoice"),LKo=o(" (Nystr\xF6mformer model)"),yKo=l(),qv=a("li"),h1e=a("strong"),xKo=o("qdqbert"),$Ko=o(" \u2014 "),$W=a("a"),kKo=o("QDQBertForMultipleChoice"),SKo=o(" (QDQBert model)"),RKo=l(),jv=a("li"),p1e=a("strong"),PKo=o("rembert"),BKo=o(" \u2014 "),kW=a("a"),IKo=o("RemBertForMultipleChoice"),NKo=o(" (RemBERT model)"),qKo=l(),Dv=a("li"),_1e=a("strong"),jKo=o("roberta"),DKo=o(" \u2014 "),SW=a("a"),GKo=o("RobertaForMultipleChoice"),OKo=o(" (RoBERTa model)"),VKo=l(),Gv=a("li"),u1e=a("strong"),XKo=o("roformer"),zKo=o(" \u2014 "),RW=a("a"),WKo=o("RoFormerForMultipleChoice"),QKo=o(" (RoFormer model)"),HKo=l(),Ov=a("li"),b1e=a("strong"),UKo=o("squeezebert"),JKo=o(" \u2014 "),PW=a("a"),YKo=o("SqueezeBertForMultipleChoice"),KKo=o(" (SqueezeBERT model)"),ZKo=l(),Vv=a("li"),v1e=a("strong"),eZo=o("xlm"),oZo=o(" \u2014 "),BW=a("a"),rZo=o("XLMForMultipleChoice"),tZo=o(" (XLM model)"),aZo=l(),Xv=a("li"),F1e=a("strong"),nZo=o("xlm-roberta"),sZo=o(" \u2014 "),IW=a("a"),lZo=o("XLMRobertaForMultipleChoice"),iZo=o(" (XLM-RoBERTa model)"),dZo=l(),zv=a("li"),T1e=a("strong"),cZo=o("xlm-roberta-xl"),fZo=o(" \u2014 "),NW=a("a"),mZo=o("XLMRobertaXLForMultipleChoice"),gZo=o(" (XLM-RoBERTa-XL model)"),hZo=l(),Wv=a("li"),M1e=a("strong"),pZo=o("xlnet"),_Zo=o(" \u2014 "),qW=a("a"),uZo=o("XLNetForMultipleChoice"),bZo=o(" (XLNet model)"),vZo=l(),Qv=a("li"),E1e=a("strong"),FZo=o("yoso"),TZo=o(" \u2014 "),jW=a("a"),MZo=o("YosoForMultipleChoice"),EZo=o(" (YOSO model)"),CZo=l(),Hv=a("p"),wZo=o("The model is set in evaluation mode by default using "),C1e=a("code"),AZo=o("model.eval()"),LZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w1e=a("code"),yZo=o("model.train()"),xZo=l(),F(Uv.$$.fragment),mQe=l(),ud=a("h2"),Jv=a("a"),A1e=a("span"),F(e8.$$.fragment),$Zo=l(),L1e=a("span"),kZo=o("AutoModelForNextSentencePrediction"),gQe=l(),jo=a("div"),F(o8.$$.fragment),SZo=l(),bd=a("p"),RZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DW=a("a"),PZo=o("from_pretrained()"),BZo=o(" class method or the "),GW=a("a"),IZo=o("from_config()"),NZo=o(` class
method.`),qZo=l(),r8=a("p"),jZo=o("This class cannot be instantiated directly using "),y1e=a("code"),DZo=o("__init__()"),GZo=o(" (throws an error)."),OZo=l(),ut=a("div"),F(t8.$$.fragment),VZo=l(),x1e=a("p"),XZo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),zZo=l(),vd=a("p"),WZo=o(`Note:
Loading a model from its configuration file does `),$1e=a("strong"),QZo=o("not"),HZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=a("a"),UZo=o("from_pretrained()"),JZo=o(" to load the model weights."),YZo=l(),F(Yv.$$.fragment),KZo=l(),ao=a("div"),F(a8.$$.fragment),ZZo=l(),k1e=a("p"),eer=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),oer=l(),Qa=a("p"),rer=o("The model class to instantiate is selected based on the "),S1e=a("code"),ter=o("model_type"),aer=o(` property of the config object (either
passed as an argument or loaded from `),R1e=a("code"),ner=o("pretrained_model_name_or_path"),ser=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P1e=a("code"),ler=o("pretrained_model_name_or_path"),ier=o(":"),der=l(),Do=a("ul"),Kv=a("li"),B1e=a("strong"),cer=o("bert"),fer=o(" \u2014 "),VW=a("a"),mer=o("BertForNextSentencePrediction"),ger=o(" (BERT model)"),her=l(),Zv=a("li"),I1e=a("strong"),per=o("fnet"),_er=o(" \u2014 "),XW=a("a"),uer=o("FNetForNextSentencePrediction"),ber=o(" (FNet model)"),ver=l(),eF=a("li"),N1e=a("strong"),Fer=o("megatron-bert"),Ter=o(" \u2014 "),zW=a("a"),Mer=o("MegatronBertForNextSentencePrediction"),Eer=o(" (Megatron-BERT model)"),Cer=l(),oF=a("li"),q1e=a("strong"),wer=o("mobilebert"),Aer=o(" \u2014 "),WW=a("a"),Ler=o("MobileBertForNextSentencePrediction"),yer=o(" (MobileBERT model)"),xer=l(),rF=a("li"),j1e=a("strong"),$er=o("nezha"),ker=o(" \u2014 "),QW=a("a"),Ser=o("NezhaForNextSentencePrediction"),Rer=o(" (Nezha model)"),Per=l(),tF=a("li"),D1e=a("strong"),Ber=o("qdqbert"),Ier=o(" \u2014 "),HW=a("a"),Ner=o("QDQBertForNextSentencePrediction"),qer=o(" (QDQBert model)"),jer=l(),aF=a("p"),Der=o("The model is set in evaluation mode by default using "),G1e=a("code"),Ger=o("model.eval()"),Oer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O1e=a("code"),Ver=o("model.train()"),Xer=l(),F(nF.$$.fragment),hQe=l(),Fd=a("h2"),sF=a("a"),V1e=a("span"),F(n8.$$.fragment),zer=l(),X1e=a("span"),Wer=o("AutoModelForTokenClassification"),pQe=l(),Go=a("div"),F(s8.$$.fragment),Qer=l(),Td=a("p"),Her=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),UW=a("a"),Uer=o("from_pretrained()"),Jer=o(" class method or the "),JW=a("a"),Yer=o("from_config()"),Ker=o(` class
method.`),Zer=l(),l8=a("p"),eor=o("This class cannot be instantiated directly using "),z1e=a("code"),oor=o("__init__()"),ror=o(" (throws an error)."),tor=l(),bt=a("div"),F(i8.$$.fragment),aor=l(),W1e=a("p"),nor=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),sor=l(),Md=a("p"),lor=o(`Note:
Loading a model from its configuration file does `),Q1e=a("strong"),ior=o("not"),dor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=a("a"),cor=o("from_pretrained()"),mor=o(" to load the model weights."),gor=l(),F(lF.$$.fragment),hor=l(),no=a("div"),F(d8.$$.fragment),por=l(),H1e=a("p"),_or=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),uor=l(),Ha=a("p"),bor=o("The model class to instantiate is selected based on the "),U1e=a("code"),vor=o("model_type"),For=o(` property of the config object (either
passed as an argument or loaded from `),J1e=a("code"),Tor=o("pretrained_model_name_or_path"),Mor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y1e=a("code"),Eor=o("pretrained_model_name_or_path"),Cor=o(":"),wor=l(),U=a("ul"),iF=a("li"),K1e=a("strong"),Aor=o("albert"),Lor=o(" \u2014 "),KW=a("a"),yor=o("AlbertForTokenClassification"),xor=o(" (ALBERT model)"),$or=l(),dF=a("li"),Z1e=a("strong"),kor=o("bert"),Sor=o(" \u2014 "),ZW=a("a"),Ror=o("BertForTokenClassification"),Por=o(" (BERT model)"),Bor=l(),cF=a("li"),e2e=a("strong"),Ior=o("big_bird"),Nor=o(" \u2014 "),eQ=a("a"),qor=o("BigBirdForTokenClassification"),jor=o(" (BigBird model)"),Dor=l(),fF=a("li"),o2e=a("strong"),Gor=o("bloom"),Oor=o(" \u2014 "),oQ=a("a"),Vor=o("BloomForTokenClassification"),Xor=o(" (BLOOM model)"),zor=l(),mF=a("li"),r2e=a("strong"),Wor=o("camembert"),Qor=o(" \u2014 "),rQ=a("a"),Hor=o("CamembertForTokenClassification"),Uor=o(" (CamemBERT model)"),Jor=l(),gF=a("li"),t2e=a("strong"),Yor=o("canine"),Kor=o(" \u2014 "),tQ=a("a"),Zor=o("CanineForTokenClassification"),err=o(" (CANINE model)"),orr=l(),hF=a("li"),a2e=a("strong"),rrr=o("convbert"),trr=o(" \u2014 "),aQ=a("a"),arr=o("ConvBertForTokenClassification"),nrr=o(" (ConvBERT model)"),srr=l(),pF=a("li"),n2e=a("strong"),lrr=o("data2vec-text"),irr=o(" \u2014 "),nQ=a("a"),drr=o("Data2VecTextForTokenClassification"),crr=o(" (Data2VecText model)"),frr=l(),_F=a("li"),s2e=a("strong"),mrr=o("deberta"),grr=o(" \u2014 "),sQ=a("a"),hrr=o("DebertaForTokenClassification"),prr=o(" (DeBERTa model)"),_rr=l(),uF=a("li"),l2e=a("strong"),urr=o("deberta-v2"),brr=o(" \u2014 "),lQ=a("a"),vrr=o("DebertaV2ForTokenClassification"),Frr=o(" (DeBERTa-v2 model)"),Trr=l(),bF=a("li"),i2e=a("strong"),Mrr=o("distilbert"),Err=o(" \u2014 "),iQ=a("a"),Crr=o("DistilBertForTokenClassification"),wrr=o(" (DistilBERT model)"),Arr=l(),vF=a("li"),d2e=a("strong"),Lrr=o("electra"),yrr=o(" \u2014 "),dQ=a("a"),xrr=o("ElectraForTokenClassification"),$rr=o(" (ELECTRA model)"),krr=l(),FF=a("li"),c2e=a("strong"),Srr=o("flaubert"),Rrr=o(" \u2014 "),cQ=a("a"),Prr=o("FlaubertForTokenClassification"),Brr=o(" (FlauBERT model)"),Irr=l(),TF=a("li"),f2e=a("strong"),Nrr=o("fnet"),qrr=o(" \u2014 "),fQ=a("a"),jrr=o("FNetForTokenClassification"),Drr=o(" (FNet model)"),Grr=l(),MF=a("li"),m2e=a("strong"),Orr=o("funnel"),Vrr=o(" \u2014 "),mQ=a("a"),Xrr=o("FunnelForTokenClassification"),zrr=o(" (Funnel Transformer model)"),Wrr=l(),EF=a("li"),g2e=a("strong"),Qrr=o("gpt2"),Hrr=o(" \u2014 "),gQ=a("a"),Urr=o("GPT2ForTokenClassification"),Jrr=o(" (OpenAI GPT-2 model)"),Yrr=l(),CF=a("li"),h2e=a("strong"),Krr=o("ibert"),Zrr=o(" \u2014 "),hQ=a("a"),etr=o("IBertForTokenClassification"),otr=o(" (I-BERT model)"),rtr=l(),wF=a("li"),p2e=a("strong"),ttr=o("layoutlm"),atr=o(" \u2014 "),pQ=a("a"),ntr=o("LayoutLMForTokenClassification"),str=o(" (LayoutLM model)"),ltr=l(),AF=a("li"),_2e=a("strong"),itr=o("layoutlmv2"),dtr=o(" \u2014 "),_Q=a("a"),ctr=o("LayoutLMv2ForTokenClassification"),ftr=o(" (LayoutLMv2 model)"),mtr=l(),LF=a("li"),u2e=a("strong"),gtr=o("layoutlmv3"),htr=o(" \u2014 "),uQ=a("a"),ptr=o("LayoutLMv3ForTokenClassification"),_tr=o(" (LayoutLMv3 model)"),utr=l(),yF=a("li"),b2e=a("strong"),btr=o("longformer"),vtr=o(" \u2014 "),bQ=a("a"),Ftr=o("LongformerForTokenClassification"),Ttr=o(" (Longformer model)"),Mtr=l(),xF=a("li"),v2e=a("strong"),Etr=o("luke"),Ctr=o(" \u2014 "),vQ=a("a"),wtr=o("LukeForTokenClassification"),Atr=o(" (LUKE model)"),Ltr=l(),$F=a("li"),F2e=a("strong"),ytr=o("megatron-bert"),xtr=o(" \u2014 "),FQ=a("a"),$tr=o("MegatronBertForTokenClassification"),ktr=o(" (Megatron-BERT model)"),Str=l(),kF=a("li"),T2e=a("strong"),Rtr=o("mobilebert"),Ptr=o(" \u2014 "),TQ=a("a"),Btr=o("MobileBertForTokenClassification"),Itr=o(" (MobileBERT model)"),Ntr=l(),SF=a("li"),M2e=a("strong"),qtr=o("mpnet"),jtr=o(" \u2014 "),MQ=a("a"),Dtr=o("MPNetForTokenClassification"),Gtr=o(" (MPNet model)"),Otr=l(),RF=a("li"),E2e=a("strong"),Vtr=o("nezha"),Xtr=o(" \u2014 "),EQ=a("a"),ztr=o("NezhaForTokenClassification"),Wtr=o(" (Nezha model)"),Qtr=l(),PF=a("li"),C2e=a("strong"),Htr=o("nystromformer"),Utr=o(" \u2014 "),CQ=a("a"),Jtr=o("NystromformerForTokenClassification"),Ytr=o(" (Nystr\xF6mformer model)"),Ktr=l(),BF=a("li"),w2e=a("strong"),Ztr=o("qdqbert"),ear=o(" \u2014 "),wQ=a("a"),oar=o("QDQBertForTokenClassification"),rar=o(" (QDQBert model)"),tar=l(),IF=a("li"),A2e=a("strong"),aar=o("rembert"),nar=o(" \u2014 "),AQ=a("a"),sar=o("RemBertForTokenClassification"),lar=o(" (RemBERT model)"),iar=l(),NF=a("li"),L2e=a("strong"),dar=o("roberta"),car=o(" \u2014 "),LQ=a("a"),far=o("RobertaForTokenClassification"),mar=o(" (RoBERTa model)"),gar=l(),qF=a("li"),y2e=a("strong"),har=o("roformer"),par=o(" \u2014 "),yQ=a("a"),_ar=o("RoFormerForTokenClassification"),uar=o(" (RoFormer model)"),bar=l(),jF=a("li"),x2e=a("strong"),Far=o("squeezebert"),Tar=o(" \u2014 "),xQ=a("a"),Mar=o("SqueezeBertForTokenClassification"),Ear=o(" (SqueezeBERT model)"),Car=l(),DF=a("li"),$2e=a("strong"),war=o("xlm"),Aar=o(" \u2014 "),$Q=a("a"),Lar=o("XLMForTokenClassification"),yar=o(" (XLM model)"),xar=l(),GF=a("li"),k2e=a("strong"),$ar=o("xlm-roberta"),kar=o(" \u2014 "),kQ=a("a"),Sar=o("XLMRobertaForTokenClassification"),Rar=o(" (XLM-RoBERTa model)"),Par=l(),OF=a("li"),S2e=a("strong"),Bar=o("xlm-roberta-xl"),Iar=o(" \u2014 "),SQ=a("a"),Nar=o("XLMRobertaXLForTokenClassification"),qar=o(" (XLM-RoBERTa-XL model)"),jar=l(),VF=a("li"),R2e=a("strong"),Dar=o("xlnet"),Gar=o(" \u2014 "),RQ=a("a"),Oar=o("XLNetForTokenClassification"),Var=o(" (XLNet model)"),Xar=l(),XF=a("li"),P2e=a("strong"),zar=o("yoso"),War=o(" \u2014 "),PQ=a("a"),Qar=o("YosoForTokenClassification"),Har=o(" (YOSO model)"),Uar=l(),zF=a("p"),Jar=o("The model is set in evaluation mode by default using "),B2e=a("code"),Yar=o("model.eval()"),Kar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I2e=a("code"),Zar=o("model.train()"),enr=l(),F(WF.$$.fragment),_Qe=l(),Ed=a("h2"),QF=a("a"),N2e=a("span"),F(c8.$$.fragment),onr=l(),q2e=a("span"),rnr=o("AutoModelForQuestionAnswering"),uQe=l(),Oo=a("div"),F(f8.$$.fragment),tnr=l(),Cd=a("p"),anr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),BQ=a("a"),nnr=o("from_pretrained()"),snr=o(" class method or the "),IQ=a("a"),lnr=o("from_config()"),inr=o(` class
method.`),dnr=l(),m8=a("p"),cnr=o("This class cannot be instantiated directly using "),j2e=a("code"),fnr=o("__init__()"),mnr=o(" (throws an error)."),gnr=l(),vt=a("div"),F(g8.$$.fragment),hnr=l(),D2e=a("p"),pnr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),_nr=l(),wd=a("p"),unr=o(`Note:
Loading a model from its configuration file does `),G2e=a("strong"),bnr=o("not"),vnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NQ=a("a"),Fnr=o("from_pretrained()"),Tnr=o(" to load the model weights."),Mnr=l(),F(HF.$$.fragment),Enr=l(),so=a("div"),F(h8.$$.fragment),Cnr=l(),O2e=a("p"),wnr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Anr=l(),Ua=a("p"),Lnr=o("The model class to instantiate is selected based on the "),V2e=a("code"),ynr=o("model_type"),xnr=o(` property of the config object (either
passed as an argument or loaded from `),X2e=a("code"),$nr=o("pretrained_model_name_or_path"),knr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z2e=a("code"),Snr=o("pretrained_model_name_or_path"),Rnr=o(":"),Pnr=l(),V=a("ul"),UF=a("li"),W2e=a("strong"),Bnr=o("albert"),Inr=o(" \u2014 "),qQ=a("a"),Nnr=o("AlbertForQuestionAnswering"),qnr=o(" (ALBERT model)"),jnr=l(),JF=a("li"),Q2e=a("strong"),Dnr=o("bart"),Gnr=o(" \u2014 "),jQ=a("a"),Onr=o("BartForQuestionAnswering"),Vnr=o(" (BART model)"),Xnr=l(),YF=a("li"),H2e=a("strong"),znr=o("bert"),Wnr=o(" \u2014 "),DQ=a("a"),Qnr=o("BertForQuestionAnswering"),Hnr=o(" (BERT model)"),Unr=l(),KF=a("li"),U2e=a("strong"),Jnr=o("big_bird"),Ynr=o(" \u2014 "),GQ=a("a"),Knr=o("BigBirdForQuestionAnswering"),Znr=o(" (BigBird model)"),esr=l(),ZF=a("li"),J2e=a("strong"),osr=o("bigbird_pegasus"),rsr=o(" \u2014 "),OQ=a("a"),tsr=o("BigBirdPegasusForQuestionAnswering"),asr=o(" (BigBird-Pegasus model)"),nsr=l(),eT=a("li"),Y2e=a("strong"),ssr=o("camembert"),lsr=o(" \u2014 "),VQ=a("a"),isr=o("CamembertForQuestionAnswering"),dsr=o(" (CamemBERT model)"),csr=l(),oT=a("li"),K2e=a("strong"),fsr=o("canine"),msr=o(" \u2014 "),XQ=a("a"),gsr=o("CanineForQuestionAnswering"),hsr=o(" (CANINE model)"),psr=l(),rT=a("li"),Z2e=a("strong"),_sr=o("convbert"),usr=o(" \u2014 "),zQ=a("a"),bsr=o("ConvBertForQuestionAnswering"),vsr=o(" (ConvBERT model)"),Fsr=l(),tT=a("li"),ebe=a("strong"),Tsr=o("data2vec-text"),Msr=o(" \u2014 "),WQ=a("a"),Esr=o("Data2VecTextForQuestionAnswering"),Csr=o(" (Data2VecText model)"),wsr=l(),aT=a("li"),obe=a("strong"),Asr=o("deberta"),Lsr=o(" \u2014 "),QQ=a("a"),ysr=o("DebertaForQuestionAnswering"),xsr=o(" (DeBERTa model)"),$sr=l(),nT=a("li"),rbe=a("strong"),ksr=o("deberta-v2"),Ssr=o(" \u2014 "),HQ=a("a"),Rsr=o("DebertaV2ForQuestionAnswering"),Psr=o(" (DeBERTa-v2 model)"),Bsr=l(),sT=a("li"),tbe=a("strong"),Isr=o("distilbert"),Nsr=o(" \u2014 "),UQ=a("a"),qsr=o("DistilBertForQuestionAnswering"),jsr=o(" (DistilBERT model)"),Dsr=l(),lT=a("li"),abe=a("strong"),Gsr=o("electra"),Osr=o(" \u2014 "),JQ=a("a"),Vsr=o("ElectraForQuestionAnswering"),Xsr=o(" (ELECTRA model)"),zsr=l(),iT=a("li"),nbe=a("strong"),Wsr=o("flaubert"),Qsr=o(" \u2014 "),YQ=a("a"),Hsr=o("FlaubertForQuestionAnsweringSimple"),Usr=o(" (FlauBERT model)"),Jsr=l(),dT=a("li"),sbe=a("strong"),Ysr=o("fnet"),Ksr=o(" \u2014 "),KQ=a("a"),Zsr=o("FNetForQuestionAnswering"),elr=o(" (FNet model)"),olr=l(),cT=a("li"),lbe=a("strong"),rlr=o("funnel"),tlr=o(" \u2014 "),ZQ=a("a"),alr=o("FunnelForQuestionAnswering"),nlr=o(" (Funnel Transformer model)"),slr=l(),fT=a("li"),ibe=a("strong"),llr=o("gptj"),ilr=o(" \u2014 "),eH=a("a"),dlr=o("GPTJForQuestionAnswering"),clr=o(" (GPT-J model)"),flr=l(),mT=a("li"),dbe=a("strong"),mlr=o("ibert"),glr=o(" \u2014 "),oH=a("a"),hlr=o("IBertForQuestionAnswering"),plr=o(" (I-BERT model)"),_lr=l(),gT=a("li"),cbe=a("strong"),ulr=o("layoutlmv2"),blr=o(" \u2014 "),rH=a("a"),vlr=o("LayoutLMv2ForQuestionAnswering"),Flr=o(" (LayoutLMv2 model)"),Tlr=l(),hT=a("li"),fbe=a("strong"),Mlr=o("layoutlmv3"),Elr=o(" \u2014 "),tH=a("a"),Clr=o("LayoutLMv3ForQuestionAnswering"),wlr=o(" (LayoutLMv3 model)"),Alr=l(),pT=a("li"),mbe=a("strong"),Llr=o("led"),ylr=o(" \u2014 "),aH=a("a"),xlr=o("LEDForQuestionAnswering"),$lr=o(" (LED model)"),klr=l(),_T=a("li"),gbe=a("strong"),Slr=o("longformer"),Rlr=o(" \u2014 "),nH=a("a"),Plr=o("LongformerForQuestionAnswering"),Blr=o(" (Longformer model)"),Ilr=l(),uT=a("li"),hbe=a("strong"),Nlr=o("luke"),qlr=o(" \u2014 "),sH=a("a"),jlr=o("LukeForQuestionAnswering"),Dlr=o(" (LUKE model)"),Glr=l(),bT=a("li"),pbe=a("strong"),Olr=o("lxmert"),Vlr=o(" \u2014 "),lH=a("a"),Xlr=o("LxmertForQuestionAnswering"),zlr=o(" (LXMERT model)"),Wlr=l(),vT=a("li"),_be=a("strong"),Qlr=o("mbart"),Hlr=o(" \u2014 "),iH=a("a"),Ulr=o("MBartForQuestionAnswering"),Jlr=o(" (mBART model)"),Ylr=l(),FT=a("li"),ube=a("strong"),Klr=o("megatron-bert"),Zlr=o(" \u2014 "),dH=a("a"),eir=o("MegatronBertForQuestionAnswering"),oir=o(" (Megatron-BERT model)"),rir=l(),TT=a("li"),bbe=a("strong"),tir=o("mobilebert"),air=o(" \u2014 "),cH=a("a"),nir=o("MobileBertForQuestionAnswering"),sir=o(" (MobileBERT model)"),lir=l(),MT=a("li"),vbe=a("strong"),iir=o("mpnet"),dir=o(" \u2014 "),fH=a("a"),cir=o("MPNetForQuestionAnswering"),fir=o(" (MPNet model)"),mir=l(),ET=a("li"),Fbe=a("strong"),gir=o("mvp"),hir=o(" \u2014 "),mH=a("a"),pir=o("MvpForQuestionAnswering"),_ir=o(" (MVP model)"),uir=l(),CT=a("li"),Tbe=a("strong"),bir=o("nezha"),vir=o(" \u2014 "),gH=a("a"),Fir=o("NezhaForQuestionAnswering"),Tir=o(" (Nezha model)"),Mir=l(),wT=a("li"),Mbe=a("strong"),Eir=o("nystromformer"),Cir=o(" \u2014 "),hH=a("a"),wir=o("NystromformerForQuestionAnswering"),Air=o(" (Nystr\xF6mformer model)"),Lir=l(),AT=a("li"),Ebe=a("strong"),yir=o("qdqbert"),xir=o(" \u2014 "),pH=a("a"),$ir=o("QDQBertForQuestionAnswering"),kir=o(" (QDQBert model)"),Sir=l(),LT=a("li"),Cbe=a("strong"),Rir=o("reformer"),Pir=o(" \u2014 "),_H=a("a"),Bir=o("ReformerForQuestionAnswering"),Iir=o(" (Reformer model)"),Nir=l(),yT=a("li"),wbe=a("strong"),qir=o("rembert"),jir=o(" \u2014 "),uH=a("a"),Dir=o("RemBertForQuestionAnswering"),Gir=o(" (RemBERT model)"),Oir=l(),xT=a("li"),Abe=a("strong"),Vir=o("roberta"),Xir=o(" \u2014 "),bH=a("a"),zir=o("RobertaForQuestionAnswering"),Wir=o(" (RoBERTa model)"),Qir=l(),$T=a("li"),Lbe=a("strong"),Hir=o("roformer"),Uir=o(" \u2014 "),vH=a("a"),Jir=o("RoFormerForQuestionAnswering"),Yir=o(" (RoFormer model)"),Kir=l(),kT=a("li"),ybe=a("strong"),Zir=o("splinter"),edr=o(" \u2014 "),FH=a("a"),odr=o("SplinterForQuestionAnswering"),rdr=o(" (Splinter model)"),tdr=l(),ST=a("li"),xbe=a("strong"),adr=o("squeezebert"),ndr=o(" \u2014 "),TH=a("a"),sdr=o("SqueezeBertForQuestionAnswering"),ldr=o(" (SqueezeBERT model)"),idr=l(),RT=a("li"),$be=a("strong"),ddr=o("xlm"),cdr=o(" \u2014 "),MH=a("a"),fdr=o("XLMForQuestionAnsweringSimple"),mdr=o(" (XLM model)"),gdr=l(),PT=a("li"),kbe=a("strong"),hdr=o("xlm-roberta"),pdr=o(" \u2014 "),EH=a("a"),_dr=o("XLMRobertaForQuestionAnswering"),udr=o(" (XLM-RoBERTa model)"),bdr=l(),BT=a("li"),Sbe=a("strong"),vdr=o("xlm-roberta-xl"),Fdr=o(" \u2014 "),CH=a("a"),Tdr=o("XLMRobertaXLForQuestionAnswering"),Mdr=o(" (XLM-RoBERTa-XL model)"),Edr=l(),IT=a("li"),Rbe=a("strong"),Cdr=o("xlnet"),wdr=o(" \u2014 "),wH=a("a"),Adr=o("XLNetForQuestionAnsweringSimple"),Ldr=o(" (XLNet model)"),ydr=l(),NT=a("li"),Pbe=a("strong"),xdr=o("yoso"),$dr=o(" \u2014 "),AH=a("a"),kdr=o("YosoForQuestionAnswering"),Sdr=o(" (YOSO model)"),Rdr=l(),qT=a("p"),Pdr=o("The model is set in evaluation mode by default using "),Bbe=a("code"),Bdr=o("model.eval()"),Idr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=a("code"),Ndr=o("model.train()"),qdr=l(),F(jT.$$.fragment),bQe=l(),Ad=a("h2"),DT=a("a"),Nbe=a("span"),F(p8.$$.fragment),jdr=l(),qbe=a("span"),Ddr=o("AutoModelForTableQuestionAnswering"),vQe=l(),Vo=a("div"),F(_8.$$.fragment),Gdr=l(),Ld=a("p"),Odr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),LH=a("a"),Vdr=o("from_pretrained()"),Xdr=o(" class method or the "),yH=a("a"),zdr=o("from_config()"),Wdr=o(` class
method.`),Qdr=l(),u8=a("p"),Hdr=o("This class cannot be instantiated directly using "),jbe=a("code"),Udr=o("__init__()"),Jdr=o(" (throws an error)."),Ydr=l(),Ft=a("div"),F(b8.$$.fragment),Kdr=l(),Dbe=a("p"),Zdr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),ecr=l(),yd=a("p"),ocr=o(`Note:
Loading a model from its configuration file does `),Gbe=a("strong"),rcr=o("not"),tcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),xH=a("a"),acr=o("from_pretrained()"),ncr=o(" to load the model weights."),scr=l(),F(GT.$$.fragment),lcr=l(),lo=a("div"),F(v8.$$.fragment),icr=l(),Obe=a("p"),dcr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),ccr=l(),Ja=a("p"),fcr=o("The model class to instantiate is selected based on the "),Vbe=a("code"),mcr=o("model_type"),gcr=o(` property of the config object (either
passed as an argument or loaded from `),Xbe=a("code"),hcr=o("pretrained_model_name_or_path"),pcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=a("code"),_cr=o("pretrained_model_name_or_path"),ucr=o(":"),bcr=l(),Wbe=a("ul"),OT=a("li"),Qbe=a("strong"),vcr=o("tapas"),Fcr=o(" \u2014 "),$H=a("a"),Tcr=o("TapasForQuestionAnswering"),Mcr=o(" (TAPAS model)"),Ecr=l(),VT=a("p"),Ccr=o("The model is set in evaluation mode by default using "),Hbe=a("code"),wcr=o("model.eval()"),Acr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ube=a("code"),Lcr=o("model.train()"),ycr=l(),F(XT.$$.fragment),FQe=l(),xd=a("h2"),zT=a("a"),Jbe=a("span"),F(F8.$$.fragment),xcr=l(),Ybe=a("span"),$cr=o("AutoModelForImageClassification"),TQe=l(),Xo=a("div"),F(T8.$$.fragment),kcr=l(),$d=a("p"),Scr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),kH=a("a"),Rcr=o("from_pretrained()"),Pcr=o(" class method or the "),SH=a("a"),Bcr=o("from_config()"),Icr=o(` class
method.`),Ncr=l(),M8=a("p"),qcr=o("This class cannot be instantiated directly using "),Kbe=a("code"),jcr=o("__init__()"),Dcr=o(" (throws an error)."),Gcr=l(),Tt=a("div"),F(E8.$$.fragment),Ocr=l(),Zbe=a("p"),Vcr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Xcr=l(),kd=a("p"),zcr=o(`Note:
Loading a model from its configuration file does `),eve=a("strong"),Wcr=o("not"),Qcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),RH=a("a"),Hcr=o("from_pretrained()"),Ucr=o(" to load the model weights."),Jcr=l(),F(WT.$$.fragment),Ycr=l(),io=a("div"),F(C8.$$.fragment),Kcr=l(),ove=a("p"),Zcr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),efr=l(),Ya=a("p"),ofr=o("The model class to instantiate is selected based on the "),rve=a("code"),rfr=o("model_type"),tfr=o(` property of the config object (either
passed as an argument or loaded from `),tve=a("code"),afr=o("pretrained_model_name_or_path"),nfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ave=a("code"),sfr=o("pretrained_model_name_or_path"),lfr=o(":"),ifr=l(),be=a("ul"),QT=a("li"),nve=a("strong"),dfr=o("beit"),cfr=o(" \u2014 "),PH=a("a"),ffr=o("BeitForImageClassification"),mfr=o(" (BEiT model)"),gfr=l(),HT=a("li"),sve=a("strong"),hfr=o("convnext"),pfr=o(" \u2014 "),BH=a("a"),_fr=o("ConvNextForImageClassification"),ufr=o(" (ConvNeXT model)"),bfr=l(),UT=a("li"),lve=a("strong"),vfr=o("cvt"),Ffr=o(" \u2014 "),IH=a("a"),Tfr=o("CvtForImageClassification"),Mfr=o(" (CvT model)"),Efr=l(),JT=a("li"),ive=a("strong"),Cfr=o("data2vec-vision"),wfr=o(" \u2014 "),NH=a("a"),Afr=o("Data2VecVisionForImageClassification"),Lfr=o(" (Data2VecVision model)"),yfr=l(),rl=a("li"),dve=a("strong"),xfr=o("deit"),$fr=o(" \u2014 "),qH=a("a"),kfr=o("DeiTForImageClassification"),Sfr=o(" or "),jH=a("a"),Rfr=o("DeiTForImageClassificationWithTeacher"),Pfr=o(" (DeiT model)"),Bfr=l(),YT=a("li"),cve=a("strong"),Ifr=o("imagegpt"),Nfr=o(" \u2014 "),DH=a("a"),qfr=o("ImageGPTForImageClassification"),jfr=o(" (ImageGPT model)"),Dfr=l(),tl=a("li"),fve=a("strong"),Gfr=o("levit"),Ofr=o(" \u2014 "),GH=a("a"),Vfr=o("LevitForImageClassification"),Xfr=o(" or "),OH=a("a"),zfr=o("LevitForImageClassificationWithTeacher"),Wfr=o(" (LeViT model)"),Qfr=l(),KT=a("li"),mve=a("strong"),Hfr=o("mobilevit"),Ufr=o(" \u2014 "),VH=a("a"),Jfr=o("MobileViTForImageClassification"),Yfr=o(" (MobileViT model)"),Kfr=l(),Mt=a("li"),gve=a("strong"),Zfr=o("perceiver"),emr=o(" \u2014 "),XH=a("a"),omr=o("PerceiverForImageClassificationLearned"),rmr=o(" or "),zH=a("a"),tmr=o("PerceiverForImageClassificationFourier"),amr=o(" or "),WH=a("a"),nmr=o("PerceiverForImageClassificationConvProcessing"),smr=o(" (Perceiver model)"),lmr=l(),ZT=a("li"),hve=a("strong"),imr=o("poolformer"),dmr=o(" \u2014 "),QH=a("a"),cmr=o("PoolFormerForImageClassification"),fmr=o(" (PoolFormer model)"),mmr=l(),e9=a("li"),pve=a("strong"),gmr=o("regnet"),hmr=o(" \u2014 "),HH=a("a"),pmr=o("RegNetForImageClassification"),_mr=o(" (RegNet model)"),umr=l(),o9=a("li"),_ve=a("strong"),bmr=o("resnet"),vmr=o(" \u2014 "),UH=a("a"),Fmr=o("ResNetForImageClassification"),Tmr=o(" (ResNet model)"),Mmr=l(),r9=a("li"),uve=a("strong"),Emr=o("segformer"),Cmr=o(" \u2014 "),JH=a("a"),wmr=o("SegformerForImageClassification"),Amr=o(" (SegFormer model)"),Lmr=l(),t9=a("li"),bve=a("strong"),ymr=o("swin"),xmr=o(" \u2014 "),YH=a("a"),$mr=o("SwinForImageClassification"),kmr=o(" (Swin Transformer model)"),Smr=l(),a9=a("li"),vve=a("strong"),Rmr=o("swinv2"),Pmr=o(" \u2014 "),KH=a("a"),Bmr=o("Swinv2ForImageClassification"),Imr=o(" (Swin Transformer V2 model)"),Nmr=l(),n9=a("li"),Fve=a("strong"),qmr=o("van"),jmr=o(" \u2014 "),ZH=a("a"),Dmr=o("VanForImageClassification"),Gmr=o(" (VAN model)"),Omr=l(),s9=a("li"),Tve=a("strong"),Vmr=o("vit"),Xmr=o(" \u2014 "),eU=a("a"),zmr=o("ViTForImageClassification"),Wmr=o(" (ViT model)"),Qmr=l(),l9=a("p"),Hmr=o("The model is set in evaluation mode by default using "),Mve=a("code"),Umr=o("model.eval()"),Jmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Eve=a("code"),Ymr=o("model.train()"),Kmr=l(),F(i9.$$.fragment),MQe=l(),Sd=a("h2"),d9=a("a"),Cve=a("span"),F(w8.$$.fragment),Zmr=l(),wve=a("span"),egr=o("AutoModelForVideoClassification"),EQe=l(),zo=a("div"),F(A8.$$.fragment),ogr=l(),Rd=a("p"),rgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),oU=a("a"),tgr=o("from_pretrained()"),agr=o(" class method or the "),rU=a("a"),ngr=o("from_config()"),sgr=o(` class
method.`),lgr=l(),L8=a("p"),igr=o("This class cannot be instantiated directly using "),Ave=a("code"),dgr=o("__init__()"),cgr=o(" (throws an error)."),fgr=l(),Et=a("div"),F(y8.$$.fragment),mgr=l(),Lve=a("p"),ggr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),hgr=l(),Pd=a("p"),pgr=o(`Note:
Loading a model from its configuration file does `),yve=a("strong"),_gr=o("not"),ugr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tU=a("a"),bgr=o("from_pretrained()"),vgr=o(" to load the model weights."),Fgr=l(),F(c9.$$.fragment),Tgr=l(),co=a("div"),F(x8.$$.fragment),Mgr=l(),xve=a("p"),Egr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),Cgr=l(),Ka=a("p"),wgr=o("The model class to instantiate is selected based on the "),$ve=a("code"),Agr=o("model_type"),Lgr=o(` property of the config object (either
passed as an argument or loaded from `),kve=a("code"),ygr=o("pretrained_model_name_or_path"),xgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sve=a("code"),$gr=o("pretrained_model_name_or_path"),kgr=o(":"),Sgr=l(),Rve=a("ul"),f9=a("li"),Pve=a("strong"),Rgr=o("videomae"),Pgr=o(" \u2014 "),aU=a("a"),Bgr=o("VideoMAEForVideoClassification"),Igr=o(" (VideoMAE model)"),Ngr=l(),m9=a("p"),qgr=o("The model is set in evaluation mode by default using "),Bve=a("code"),jgr=o("model.eval()"),Dgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ive=a("code"),Ggr=o("model.train()"),Ogr=l(),F(g9.$$.fragment),CQe=l(),Bd=a("h2"),h9=a("a"),Nve=a("span"),F($8.$$.fragment),Vgr=l(),qve=a("span"),Xgr=o("AutoModelForVision2Seq"),wQe=l(),Wo=a("div"),F(k8.$$.fragment),zgr=l(),Id=a("p"),Wgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),nU=a("a"),Qgr=o("from_pretrained()"),Hgr=o(" class method or the "),sU=a("a"),Ugr=o("from_config()"),Jgr=o(` class
method.`),Ygr=l(),S8=a("p"),Kgr=o("This class cannot be instantiated directly using "),jve=a("code"),Zgr=o("__init__()"),ehr=o(" (throws an error)."),ohr=l(),Ct=a("div"),F(R8.$$.fragment),rhr=l(),Dve=a("p"),thr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),ahr=l(),Nd=a("p"),nhr=o(`Note:
Loading a model from its configuration file does `),Gve=a("strong"),shr=o("not"),lhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lU=a("a"),ihr=o("from_pretrained()"),dhr=o(" to load the model weights."),chr=l(),F(p9.$$.fragment),fhr=l(),fo=a("div"),F(P8.$$.fragment),mhr=l(),Ove=a("p"),ghr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),hhr=l(),Za=a("p"),phr=o("The model class to instantiate is selected based on the "),Vve=a("code"),_hr=o("model_type"),uhr=o(` property of the config object (either
passed as an argument or loaded from `),Xve=a("code"),bhr=o("pretrained_model_name_or_path"),vhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zve=a("code"),Fhr=o("pretrained_model_name_or_path"),Thr=o(":"),Mhr=l(),Wve=a("ul"),_9=a("li"),Qve=a("strong"),Ehr=o("vision-encoder-decoder"),Chr=o(" \u2014 "),iU=a("a"),whr=o("VisionEncoderDecoderModel"),Ahr=o(" (Vision Encoder decoder model)"),Lhr=l(),u9=a("p"),yhr=o("The model is set in evaluation mode by default using "),Hve=a("code"),xhr=o("model.eval()"),$hr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uve=a("code"),khr=o("model.train()"),Shr=l(),F(b9.$$.fragment),AQe=l(),qd=a("h2"),v9=a("a"),Jve=a("span"),F(B8.$$.fragment),Rhr=l(),Yve=a("span"),Phr=o("AutoModelForVisualQuestionAnswering"),LQe=l(),Qo=a("div"),F(I8.$$.fragment),Bhr=l(),jd=a("p"),Ihr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),dU=a("a"),Nhr=o("from_pretrained()"),qhr=o(" class method or the "),cU=a("a"),jhr=o("from_config()"),Dhr=o(` class
method.`),Ghr=l(),N8=a("p"),Ohr=o("This class cannot be instantiated directly using "),Kve=a("code"),Vhr=o("__init__()"),Xhr=o(" (throws an error)."),zhr=l(),wt=a("div"),F(q8.$$.fragment),Whr=l(),Zve=a("p"),Qhr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Hhr=l(),Dd=a("p"),Uhr=o(`Note:
Loading a model from its configuration file does `),eFe=a("strong"),Jhr=o("not"),Yhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fU=a("a"),Khr=o("from_pretrained()"),Zhr=o(" to load the model weights."),epr=l(),F(F9.$$.fragment),opr=l(),mo=a("div"),F(j8.$$.fragment),rpr=l(),oFe=a("p"),tpr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),apr=l(),en=a("p"),npr=o("The model class to instantiate is selected based on the "),rFe=a("code"),spr=o("model_type"),lpr=o(` property of the config object (either
passed as an argument or loaded from `),tFe=a("code"),ipr=o("pretrained_model_name_or_path"),dpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aFe=a("code"),cpr=o("pretrained_model_name_or_path"),fpr=o(":"),mpr=l(),nFe=a("ul"),T9=a("li"),sFe=a("strong"),gpr=o("vilt"),hpr=o(" \u2014 "),mU=a("a"),ppr=o("ViltForQuestionAnswering"),_pr=o(" (ViLT model)"),upr=l(),M9=a("p"),bpr=o("The model is set in evaluation mode by default using "),lFe=a("code"),vpr=o("model.eval()"),Fpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iFe=a("code"),Tpr=o("model.train()"),Mpr=l(),F(E9.$$.fragment),yQe=l(),Gd=a("h2"),C9=a("a"),dFe=a("span"),F(D8.$$.fragment),Epr=l(),cFe=a("span"),Cpr=o("AutoModelForAudioClassification"),xQe=l(),Ho=a("div"),F(G8.$$.fragment),wpr=l(),Od=a("p"),Apr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),gU=a("a"),Lpr=o("from_pretrained()"),ypr=o(" class method or the "),hU=a("a"),xpr=o("from_config()"),$pr=o(` class
method.`),kpr=l(),O8=a("p"),Spr=o("This class cannot be instantiated directly using "),fFe=a("code"),Rpr=o("__init__()"),Ppr=o(" (throws an error)."),Bpr=l(),At=a("div"),F(V8.$$.fragment),Ipr=l(),mFe=a("p"),Npr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),qpr=l(),Vd=a("p"),jpr=o(`Note:
Loading a model from its configuration file does `),gFe=a("strong"),Dpr=o("not"),Gpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pU=a("a"),Opr=o("from_pretrained()"),Vpr=o(" to load the model weights."),Xpr=l(),F(w9.$$.fragment),zpr=l(),go=a("div"),F(X8.$$.fragment),Wpr=l(),hFe=a("p"),Qpr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Hpr=l(),on=a("p"),Upr=o("The model class to instantiate is selected based on the "),pFe=a("code"),Jpr=o("model_type"),Ypr=o(` property of the config object (either
passed as an argument or loaded from `),_Fe=a("code"),Kpr=o("pretrained_model_name_or_path"),Zpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uFe=a("code"),e_r=o("pretrained_model_name_or_path"),o_r=o(":"),r_r=l(),Pe=a("ul"),A9=a("li"),bFe=a("strong"),t_r=o("data2vec-audio"),a_r=o(" \u2014 "),_U=a("a"),n_r=o("Data2VecAudioForSequenceClassification"),s_r=o(" (Data2VecAudio model)"),l_r=l(),L9=a("li"),vFe=a("strong"),i_r=o("hubert"),d_r=o(" \u2014 "),uU=a("a"),c_r=o("HubertForSequenceClassification"),f_r=o(" (Hubert model)"),m_r=l(),y9=a("li"),FFe=a("strong"),g_r=o("sew"),h_r=o(" \u2014 "),bU=a("a"),p_r=o("SEWForSequenceClassification"),__r=o(" (SEW model)"),u_r=l(),x9=a("li"),TFe=a("strong"),b_r=o("sew-d"),v_r=o(" \u2014 "),vU=a("a"),F_r=o("SEWDForSequenceClassification"),T_r=o(" (SEW-D model)"),M_r=l(),$9=a("li"),MFe=a("strong"),E_r=o("unispeech"),C_r=o(" \u2014 "),FU=a("a"),w_r=o("UniSpeechForSequenceClassification"),A_r=o(" (UniSpeech model)"),L_r=l(),k9=a("li"),EFe=a("strong"),y_r=o("unispeech-sat"),x_r=o(" \u2014 "),TU=a("a"),$_r=o("UniSpeechSatForSequenceClassification"),k_r=o(" (UniSpeechSat model)"),S_r=l(),S9=a("li"),CFe=a("strong"),R_r=o("wav2vec2"),P_r=o(" \u2014 "),MU=a("a"),B_r=o("Wav2Vec2ForSequenceClassification"),I_r=o(" (Wav2Vec2 model)"),N_r=l(),R9=a("li"),wFe=a("strong"),q_r=o("wav2vec2-conformer"),j_r=o(" \u2014 "),EU=a("a"),D_r=o("Wav2Vec2ConformerForSequenceClassification"),G_r=o(" (Wav2Vec2-Conformer model)"),O_r=l(),P9=a("li"),AFe=a("strong"),V_r=o("wavlm"),X_r=o(" \u2014 "),CU=a("a"),z_r=o("WavLMForSequenceClassification"),W_r=o(" (WavLM model)"),Q_r=l(),B9=a("p"),H_r=o("The model is set in evaluation mode by default using "),LFe=a("code"),U_r=o("model.eval()"),J_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yFe=a("code"),Y_r=o("model.train()"),K_r=l(),F(I9.$$.fragment),$Qe=l(),Xd=a("h2"),N9=a("a"),xFe=a("span"),F(z8.$$.fragment),Z_r=l(),$Fe=a("span"),eur=o("AutoModelForAudioFrameClassification"),kQe=l(),Uo=a("div"),F(W8.$$.fragment),our=l(),zd=a("p"),rur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),wU=a("a"),tur=o("from_pretrained()"),aur=o(" class method or the "),AU=a("a"),nur=o("from_config()"),sur=o(` class
method.`),lur=l(),Q8=a("p"),iur=o("This class cannot be instantiated directly using "),kFe=a("code"),dur=o("__init__()"),cur=o(" (throws an error)."),fur=l(),Lt=a("div"),F(H8.$$.fragment),mur=l(),SFe=a("p"),gur=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),hur=l(),Wd=a("p"),pur=o(`Note:
Loading a model from its configuration file does `),RFe=a("strong"),_ur=o("not"),uur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),bur=o("from_pretrained()"),vur=o(" to load the model weights."),Fur=l(),F(q9.$$.fragment),Tur=l(),ho=a("div"),F(U8.$$.fragment),Mur=l(),PFe=a("p"),Eur=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Cur=l(),rn=a("p"),wur=o("The model class to instantiate is selected based on the "),BFe=a("code"),Aur=o("model_type"),Lur=o(` property of the config object (either
passed as an argument or loaded from `),IFe=a("code"),yur=o("pretrained_model_name_or_path"),xur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NFe=a("code"),$ur=o("pretrained_model_name_or_path"),kur=o(":"),Sur=l(),at=a("ul"),j9=a("li"),qFe=a("strong"),Rur=o("data2vec-audio"),Pur=o(" \u2014 "),yU=a("a"),Bur=o("Data2VecAudioForAudioFrameClassification"),Iur=o(" (Data2VecAudio model)"),Nur=l(),D9=a("li"),jFe=a("strong"),qur=o("unispeech-sat"),jur=o(" \u2014 "),xU=a("a"),Dur=o("UniSpeechSatForAudioFrameClassification"),Gur=o(" (UniSpeechSat model)"),Our=l(),G9=a("li"),DFe=a("strong"),Vur=o("wav2vec2"),Xur=o(" \u2014 "),$U=a("a"),zur=o("Wav2Vec2ForAudioFrameClassification"),Wur=o(" (Wav2Vec2 model)"),Qur=l(),O9=a("li"),GFe=a("strong"),Hur=o("wav2vec2-conformer"),Uur=o(" \u2014 "),kU=a("a"),Jur=o("Wav2Vec2ConformerForAudioFrameClassification"),Yur=o(" (Wav2Vec2-Conformer model)"),Kur=l(),V9=a("li"),OFe=a("strong"),Zur=o("wavlm"),e7r=o(" \u2014 "),SU=a("a"),o7r=o("WavLMForAudioFrameClassification"),r7r=o(" (WavLM model)"),t7r=l(),X9=a("p"),a7r=o("The model is set in evaluation mode by default using "),VFe=a("code"),n7r=o("model.eval()"),s7r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XFe=a("code"),l7r=o("model.train()"),i7r=l(),F(z9.$$.fragment),SQe=l(),Qd=a("h2"),W9=a("a"),zFe=a("span"),F(J8.$$.fragment),d7r=l(),WFe=a("span"),c7r=o("AutoModelForCTC"),RQe=l(),Jo=a("div"),F(Y8.$$.fragment),f7r=l(),Hd=a("p"),m7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),RU=a("a"),g7r=o("from_pretrained()"),h7r=o(" class method or the "),PU=a("a"),p7r=o("from_config()"),_7r=o(` class
method.`),u7r=l(),K8=a("p"),b7r=o("This class cannot be instantiated directly using "),QFe=a("code"),v7r=o("__init__()"),F7r=o(" (throws an error)."),T7r=l(),yt=a("div"),F(Z8.$$.fragment),M7r=l(),HFe=a("p"),E7r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),C7r=l(),Ud=a("p"),w7r=o(`Note:
Loading a model from its configuration file does `),UFe=a("strong"),A7r=o("not"),L7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BU=a("a"),y7r=o("from_pretrained()"),x7r=o(" to load the model weights."),$7r=l(),F(Q9.$$.fragment),k7r=l(),po=a("div"),F(ex.$$.fragment),S7r=l(),JFe=a("p"),R7r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),P7r=l(),tn=a("p"),B7r=o("The model class to instantiate is selected based on the "),YFe=a("code"),I7r=o("model_type"),N7r=o(` property of the config object (either
passed as an argument or loaded from `),KFe=a("code"),q7r=o("pretrained_model_name_or_path"),j7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZFe=a("code"),D7r=o("pretrained_model_name_or_path"),G7r=o(":"),O7r=l(),Le=a("ul"),H9=a("li"),eTe=a("strong"),V7r=o("data2vec-audio"),X7r=o(" \u2014 "),IU=a("a"),z7r=o("Data2VecAudioForCTC"),W7r=o(" (Data2VecAudio model)"),Q7r=l(),U9=a("li"),oTe=a("strong"),H7r=o("hubert"),U7r=o(" \u2014 "),NU=a("a"),J7r=o("HubertForCTC"),Y7r=o(" (Hubert model)"),K7r=l(),J9=a("li"),rTe=a("strong"),Z7r=o("mctct"),e1r=o(" \u2014 "),qU=a("a"),o1r=o("MCTCTForCTC"),r1r=o(" (M-CTC-T model)"),t1r=l(),Y9=a("li"),tTe=a("strong"),a1r=o("sew"),n1r=o(" \u2014 "),jU=a("a"),s1r=o("SEWForCTC"),l1r=o(" (SEW model)"),i1r=l(),K9=a("li"),aTe=a("strong"),d1r=o("sew-d"),c1r=o(" \u2014 "),DU=a("a"),f1r=o("SEWDForCTC"),m1r=o(" (SEW-D model)"),g1r=l(),Z9=a("li"),nTe=a("strong"),h1r=o("unispeech"),p1r=o(" \u2014 "),GU=a("a"),_1r=o("UniSpeechForCTC"),u1r=o(" (UniSpeech model)"),b1r=l(),eM=a("li"),sTe=a("strong"),v1r=o("unispeech-sat"),F1r=o(" \u2014 "),OU=a("a"),T1r=o("UniSpeechSatForCTC"),M1r=o(" (UniSpeechSat model)"),E1r=l(),oM=a("li"),lTe=a("strong"),C1r=o("wav2vec2"),w1r=o(" \u2014 "),VU=a("a"),A1r=o("Wav2Vec2ForCTC"),L1r=o(" (Wav2Vec2 model)"),y1r=l(),rM=a("li"),iTe=a("strong"),x1r=o("wav2vec2-conformer"),$1r=o(" \u2014 "),XU=a("a"),k1r=o("Wav2Vec2ConformerForCTC"),S1r=o(" (Wav2Vec2-Conformer model)"),R1r=l(),tM=a("li"),dTe=a("strong"),P1r=o("wavlm"),B1r=o(" \u2014 "),zU=a("a"),I1r=o("WavLMForCTC"),N1r=o(" (WavLM model)"),q1r=l(),aM=a("p"),j1r=o("The model is set in evaluation mode by default using "),cTe=a("code"),D1r=o("model.eval()"),G1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fTe=a("code"),O1r=o("model.train()"),V1r=l(),F(nM.$$.fragment),PQe=l(),Jd=a("h2"),sM=a("a"),mTe=a("span"),F(ox.$$.fragment),X1r=l(),gTe=a("span"),z1r=o("AutoModelForSpeechSeq2Seq"),BQe=l(),Yo=a("div"),F(rx.$$.fragment),W1r=l(),Yd=a("p"),Q1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),WU=a("a"),H1r=o("from_pretrained()"),U1r=o(" class method or the "),QU=a("a"),J1r=o("from_config()"),Y1r=o(` class
method.`),K1r=l(),tx=a("p"),Z1r=o("This class cannot be instantiated directly using "),hTe=a("code"),e2r=o("__init__()"),o2r=o(" (throws an error)."),r2r=l(),xt=a("div"),F(ax.$$.fragment),t2r=l(),pTe=a("p"),a2r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),n2r=l(),Kd=a("p"),s2r=o(`Note:
Loading a model from its configuration file does `),_Te=a("strong"),l2r=o("not"),i2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=a("a"),d2r=o("from_pretrained()"),c2r=o(" to load the model weights."),f2r=l(),F(lM.$$.fragment),m2r=l(),_o=a("div"),F(nx.$$.fragment),g2r=l(),uTe=a("p"),h2r=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),p2r=l(),an=a("p"),_2r=o("The model class to instantiate is selected based on the "),bTe=a("code"),u2r=o("model_type"),b2r=o(` property of the config object (either
passed as an argument or loaded from `),vTe=a("code"),v2r=o("pretrained_model_name_or_path"),F2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FTe=a("code"),T2r=o("pretrained_model_name_or_path"),M2r=o(":"),E2r=l(),sx=a("ul"),iM=a("li"),TTe=a("strong"),C2r=o("speech-encoder-decoder"),w2r=o(" \u2014 "),UU=a("a"),A2r=o("SpeechEncoderDecoderModel"),L2r=o(" (Speech Encoder decoder model)"),y2r=l(),dM=a("li"),MTe=a("strong"),x2r=o("speech_to_text"),$2r=o(" \u2014 "),JU=a("a"),k2r=o("Speech2TextForConditionalGeneration"),S2r=o(" (Speech2Text model)"),R2r=l(),cM=a("p"),P2r=o("The model is set in evaluation mode by default using "),ETe=a("code"),B2r=o("model.eval()"),I2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CTe=a("code"),N2r=o("model.train()"),q2r=l(),F(fM.$$.fragment),IQe=l(),Zd=a("h2"),mM=a("a"),wTe=a("span"),F(lx.$$.fragment),j2r=l(),ATe=a("span"),D2r=o("AutoModelForAudioXVector"),NQe=l(),Ko=a("div"),F(ix.$$.fragment),G2r=l(),ec=a("p"),O2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),YU=a("a"),V2r=o("from_pretrained()"),X2r=o(" class method or the "),KU=a("a"),z2r=o("from_config()"),W2r=o(` class
method.`),Q2r=l(),dx=a("p"),H2r=o("This class cannot be instantiated directly using "),LTe=a("code"),U2r=o("__init__()"),J2r=o(" (throws an error)."),Y2r=l(),$t=a("div"),F(cx.$$.fragment),K2r=l(),yTe=a("p"),Z2r=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),ebr=l(),oc=a("p"),obr=o(`Note:
Loading a model from its configuration file does `),xTe=a("strong"),rbr=o("not"),tbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZU=a("a"),abr=o("from_pretrained()"),nbr=o(" to load the model weights."),sbr=l(),F(gM.$$.fragment),lbr=l(),uo=a("div"),F(fx.$$.fragment),ibr=l(),$Te=a("p"),dbr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),cbr=l(),nn=a("p"),fbr=o("The model class to instantiate is selected based on the "),kTe=a("code"),mbr=o("model_type"),gbr=o(` property of the config object (either
passed as an argument or loaded from `),STe=a("code"),hbr=o("pretrained_model_name_or_path"),pbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=a("code"),_br=o("pretrained_model_name_or_path"),ubr=o(":"),bbr=l(),nt=a("ul"),hM=a("li"),PTe=a("strong"),vbr=o("data2vec-audio"),Fbr=o(" \u2014 "),eJ=a("a"),Tbr=o("Data2VecAudioForXVector"),Mbr=o(" (Data2VecAudio model)"),Ebr=l(),pM=a("li"),BTe=a("strong"),Cbr=o("unispeech-sat"),wbr=o(" \u2014 "),oJ=a("a"),Abr=o("UniSpeechSatForXVector"),Lbr=o(" (UniSpeechSat model)"),ybr=l(),_M=a("li"),ITe=a("strong"),xbr=o("wav2vec2"),$br=o(" \u2014 "),rJ=a("a"),kbr=o("Wav2Vec2ForXVector"),Sbr=o(" (Wav2Vec2 model)"),Rbr=l(),uM=a("li"),NTe=a("strong"),Pbr=o("wav2vec2-conformer"),Bbr=o(" \u2014 "),tJ=a("a"),Ibr=o("Wav2Vec2ConformerForXVector"),Nbr=o(" (Wav2Vec2-Conformer model)"),qbr=l(),bM=a("li"),qTe=a("strong"),jbr=o("wavlm"),Dbr=o(" \u2014 "),aJ=a("a"),Gbr=o("WavLMForXVector"),Obr=o(" (WavLM model)"),Vbr=l(),vM=a("p"),Xbr=o("The model is set in evaluation mode by default using "),jTe=a("code"),zbr=o("model.eval()"),Wbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DTe=a("code"),Qbr=o("model.train()"),Hbr=l(),F(FM.$$.fragment),qQe=l(),rc=a("h2"),TM=a("a"),GTe=a("span"),F(mx.$$.fragment),Ubr=l(),OTe=a("span"),Jbr=o("AutoModelForMaskedImageModeling"),jQe=l(),Zo=a("div"),F(gx.$$.fragment),Ybr=l(),tc=a("p"),Kbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),nJ=a("a"),Zbr=o("from_pretrained()"),evr=o(" class method or the "),sJ=a("a"),ovr=o("from_config()"),rvr=o(` class
method.`),tvr=l(),hx=a("p"),avr=o("This class cannot be instantiated directly using "),VTe=a("code"),nvr=o("__init__()"),svr=o(" (throws an error)."),lvr=l(),kt=a("div"),F(px.$$.fragment),ivr=l(),XTe=a("p"),dvr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),cvr=l(),ac=a("p"),fvr=o(`Note:
Loading a model from its configuration file does `),zTe=a("strong"),mvr=o("not"),gvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lJ=a("a"),hvr=o("from_pretrained()"),pvr=o(" to load the model weights."),_vr=l(),F(MM.$$.fragment),uvr=l(),bo=a("div"),F(_x.$$.fragment),bvr=l(),WTe=a("p"),vvr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),Fvr=l(),sn=a("p"),Tvr=o("The model class to instantiate is selected based on the "),QTe=a("code"),Mvr=o("model_type"),Evr=o(` property of the config object (either
passed as an argument or loaded from `),HTe=a("code"),Cvr=o("pretrained_model_name_or_path"),wvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UTe=a("code"),Avr=o("pretrained_model_name_or_path"),Lvr=o(":"),yvr=l(),ln=a("ul"),EM=a("li"),JTe=a("strong"),xvr=o("deit"),$vr=o(" \u2014 "),iJ=a("a"),kvr=o("DeiTForMaskedImageModeling"),Svr=o(" (DeiT model)"),Rvr=l(),CM=a("li"),YTe=a("strong"),Pvr=o("swin"),Bvr=o(" \u2014 "),dJ=a("a"),Ivr=o("SwinForMaskedImageModeling"),Nvr=o(" (Swin Transformer model)"),qvr=l(),wM=a("li"),KTe=a("strong"),jvr=o("swinv2"),Dvr=o(" \u2014 "),cJ=a("a"),Gvr=o("Swinv2ForMaskedImageModeling"),Ovr=o(" (Swin Transformer V2 model)"),Vvr=l(),AM=a("li"),ZTe=a("strong"),Xvr=o("vit"),zvr=o(" \u2014 "),fJ=a("a"),Wvr=o("ViTForMaskedImageModeling"),Qvr=o(" (ViT model)"),Hvr=l(),LM=a("p"),Uvr=o("The model is set in evaluation mode by default using "),e9e=a("code"),Jvr=o("model.eval()"),Yvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o9e=a("code"),Kvr=o("model.train()"),Zvr=l(),F(yM.$$.fragment),DQe=l(),nc=a("h2"),xM=a("a"),r9e=a("span"),F(ux.$$.fragment),eFr=l(),t9e=a("span"),oFr=o("AutoModelForObjectDetection"),GQe=l(),er=a("div"),F(bx.$$.fragment),rFr=l(),sc=a("p"),tFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),mJ=a("a"),aFr=o("from_pretrained()"),nFr=o(" class method or the "),gJ=a("a"),sFr=o("from_config()"),lFr=o(` class
method.`),iFr=l(),vx=a("p"),dFr=o("This class cannot be instantiated directly using "),a9e=a("code"),cFr=o("__init__()"),fFr=o(" (throws an error)."),mFr=l(),St=a("div"),F(Fx.$$.fragment),gFr=l(),n9e=a("p"),hFr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),pFr=l(),lc=a("p"),_Fr=o(`Note:
Loading a model from its configuration file does `),s9e=a("strong"),uFr=o("not"),bFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hJ=a("a"),vFr=o("from_pretrained()"),FFr=o(" to load the model weights."),TFr=l(),F($M.$$.fragment),MFr=l(),vo=a("div"),F(Tx.$$.fragment),EFr=l(),l9e=a("p"),CFr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),wFr=l(),dn=a("p"),AFr=o("The model class to instantiate is selected based on the "),i9e=a("code"),LFr=o("model_type"),yFr=o(` property of the config object (either
passed as an argument or loaded from `),d9e=a("code"),xFr=o("pretrained_model_name_or_path"),$Fr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c9e=a("code"),kFr=o("pretrained_model_name_or_path"),SFr=o(":"),RFr=l(),Mx=a("ul"),kM=a("li"),f9e=a("strong"),PFr=o("detr"),BFr=o(" \u2014 "),pJ=a("a"),IFr=o("DetrForObjectDetection"),NFr=o(" (DETR model)"),qFr=l(),SM=a("li"),m9e=a("strong"),jFr=o("yolos"),DFr=o(" \u2014 "),_J=a("a"),GFr=o("YolosForObjectDetection"),OFr=o(" (YOLOS model)"),VFr=l(),RM=a("p"),XFr=o("The model is set in evaluation mode by default using "),g9e=a("code"),zFr=o("model.eval()"),WFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h9e=a("code"),QFr=o("model.train()"),HFr=l(),F(PM.$$.fragment),OQe=l(),ic=a("h2"),BM=a("a"),p9e=a("span"),F(Ex.$$.fragment),UFr=l(),_9e=a("span"),JFr=o("AutoModelForImageSegmentation"),VQe=l(),or=a("div"),F(Cx.$$.fragment),YFr=l(),dc=a("p"),KFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),uJ=a("a"),ZFr=o("from_pretrained()"),eTr=o(" class method or the "),bJ=a("a"),oTr=o("from_config()"),rTr=o(` class
method.`),tTr=l(),wx=a("p"),aTr=o("This class cannot be instantiated directly using "),u9e=a("code"),nTr=o("__init__()"),sTr=o(" (throws an error)."),lTr=l(),Rt=a("div"),F(Ax.$$.fragment),iTr=l(),b9e=a("p"),dTr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),cTr=l(),cc=a("p"),fTr=o(`Note:
Loading a model from its configuration file does `),v9e=a("strong"),mTr=o("not"),gTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=a("a"),hTr=o("from_pretrained()"),pTr=o(" to load the model weights."),_Tr=l(),F(IM.$$.fragment),uTr=l(),Fo=a("div"),F(Lx.$$.fragment),bTr=l(),F9e=a("p"),vTr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),FTr=l(),cn=a("p"),TTr=o("The model class to instantiate is selected based on the "),T9e=a("code"),MTr=o("model_type"),ETr=o(` property of the config object (either
passed as an argument or loaded from `),M9e=a("code"),CTr=o("pretrained_model_name_or_path"),wTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E9e=a("code"),ATr=o("pretrained_model_name_or_path"),LTr=o(":"),yTr=l(),C9e=a("ul"),NM=a("li"),w9e=a("strong"),xTr=o("detr"),$Tr=o(" \u2014 "),FJ=a("a"),kTr=o("DetrForSegmentation"),STr=o(" (DETR model)"),RTr=l(),qM=a("p"),PTr=o("The model is set in evaluation mode by default using "),A9e=a("code"),BTr=o("model.eval()"),ITr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L9e=a("code"),NTr=o("model.train()"),qTr=l(),F(jM.$$.fragment),XQe=l(),fc=a("h2"),DM=a("a"),y9e=a("span"),F(yx.$$.fragment),jTr=l(),x9e=a("span"),DTr=o("AutoModelForSemanticSegmentation"),zQe=l(),rr=a("div"),F(xx.$$.fragment),GTr=l(),mc=a("p"),OTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),TJ=a("a"),VTr=o("from_pretrained()"),XTr=o(" class method or the "),MJ=a("a"),zTr=o("from_config()"),WTr=o(` class
method.`),QTr=l(),$x=a("p"),HTr=o("This class cannot be instantiated directly using "),$9e=a("code"),UTr=o("__init__()"),JTr=o(" (throws an error)."),YTr=l(),Pt=a("div"),F(kx.$$.fragment),KTr=l(),k9e=a("p"),ZTr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),e9r=l(),gc=a("p"),o9r=o(`Note:
Loading a model from its configuration file does `),S9e=a("strong"),r9r=o("not"),t9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),EJ=a("a"),a9r=o("from_pretrained()"),n9r=o(" to load the model weights."),s9r=l(),F(GM.$$.fragment),l9r=l(),To=a("div"),F(Sx.$$.fragment),i9r=l(),R9e=a("p"),d9r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),c9r=l(),fn=a("p"),f9r=o("The model class to instantiate is selected based on the "),P9e=a("code"),m9r=o("model_type"),g9r=o(` property of the config object (either
passed as an argument or loaded from `),B9e=a("code"),h9r=o("pretrained_model_name_or_path"),p9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I9e=a("code"),_9r=o("pretrained_model_name_or_path"),u9r=o(":"),b9r=l(),st=a("ul"),OM=a("li"),N9e=a("strong"),v9r=o("beit"),F9r=o(" \u2014 "),CJ=a("a"),T9r=o("BeitForSemanticSegmentation"),M9r=o(" (BEiT model)"),E9r=l(),VM=a("li"),q9e=a("strong"),C9r=o("data2vec-vision"),w9r=o(" \u2014 "),wJ=a("a"),A9r=o("Data2VecVisionForSemanticSegmentation"),L9r=o(" (Data2VecVision model)"),y9r=l(),XM=a("li"),j9e=a("strong"),x9r=o("dpt"),$9r=o(" \u2014 "),AJ=a("a"),k9r=o("DPTForSemanticSegmentation"),S9r=o(" (DPT model)"),R9r=l(),zM=a("li"),D9e=a("strong"),P9r=o("mobilevit"),B9r=o(" \u2014 "),LJ=a("a"),I9r=o("MobileViTForSemanticSegmentation"),N9r=o(" (MobileViT model)"),q9r=l(),WM=a("li"),G9e=a("strong"),j9r=o("segformer"),D9r=o(" \u2014 "),yJ=a("a"),G9r=o("SegformerForSemanticSegmentation"),O9r=o(" (SegFormer model)"),V9r=l(),QM=a("p"),X9r=o("The model is set in evaluation mode by default using "),O9e=a("code"),z9r=o("model.eval()"),W9r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V9e=a("code"),Q9r=o("model.train()"),H9r=l(),F(HM.$$.fragment),WQe=l(),hc=a("h2"),UM=a("a"),X9e=a("span"),F(Rx.$$.fragment),U9r=l(),z9e=a("span"),J9r=o("AutoModelForInstanceSegmentation"),QQe=l(),tr=a("div"),F(Px.$$.fragment),Y9r=l(),pc=a("p"),K9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),xJ=a("a"),Z9r=o("from_pretrained()"),eMr=o(" class method or the "),$J=a("a"),oMr=o("from_config()"),rMr=o(` class
method.`),tMr=l(),Bx=a("p"),aMr=o("This class cannot be instantiated directly using "),W9e=a("code"),nMr=o("__init__()"),sMr=o(" (throws an error)."),lMr=l(),Bt=a("div"),F(Ix.$$.fragment),iMr=l(),Q9e=a("p"),dMr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),cMr=l(),_c=a("p"),fMr=o(`Note:
Loading a model from its configuration file does `),H9e=a("strong"),mMr=o("not"),gMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kJ=a("a"),hMr=o("from_pretrained()"),pMr=o(" to load the model weights."),_Mr=l(),F(JM.$$.fragment),uMr=l(),Mo=a("div"),F(Nx.$$.fragment),bMr=l(),U9e=a("p"),vMr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),FMr=l(),mn=a("p"),TMr=o("The model class to instantiate is selected based on the "),J9e=a("code"),MMr=o("model_type"),EMr=o(` property of the config object (either
passed as an argument or loaded from `),Y9e=a("code"),CMr=o("pretrained_model_name_or_path"),wMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K9e=a("code"),AMr=o("pretrained_model_name_or_path"),LMr=o(":"),yMr=l(),Z9e=a("ul"),YM=a("li"),eMe=a("strong"),xMr=o("maskformer"),$Mr=o(" \u2014 "),SJ=a("a"),kMr=o("MaskFormerForInstanceSegmentation"),SMr=o(" (MaskFormer model)"),RMr=l(),KM=a("p"),PMr=o("The model is set in evaluation mode by default using "),oMe=a("code"),BMr=o("model.eval()"),IMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rMe=a("code"),NMr=o("model.train()"),qMr=l(),F(ZM.$$.fragment),HQe=l(),uc=a("h2"),eE=a("a"),tMe=a("span"),F(qx.$$.fragment),jMr=l(),aMe=a("span"),DMr=o("TFAutoModel"),UQe=l(),ar=a("div"),F(jx.$$.fragment),GMr=l(),bc=a("p"),OMr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),RJ=a("a"),VMr=o("from_pretrained()"),XMr=o(" class method or the "),PJ=a("a"),zMr=o("from_config()"),WMr=o(` class
method.`),QMr=l(),Dx=a("p"),HMr=o("This class cannot be instantiated directly using "),nMe=a("code"),UMr=o("__init__()"),JMr=o(" (throws an error)."),YMr=l(),It=a("div"),F(Gx.$$.fragment),KMr=l(),sMe=a("p"),ZMr=o("Instantiates one of the base model classes of the library from a configuration."),eEr=l(),vc=a("p"),oEr=o(`Note:
Loading a model from its configuration file does `),lMe=a("strong"),rEr=o("not"),tEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),BJ=a("a"),aEr=o("from_pretrained()"),nEr=o(" to load the model weights."),sEr=l(),F(oE.$$.fragment),lEr=l(),Sr=a("div"),F(Ox.$$.fragment),iEr=l(),iMe=a("p"),dEr=o("Instantiate one of the base model classes of the library from a pretrained model."),cEr=l(),gn=a("p"),fEr=o("The model class to instantiate is selected based on the "),dMe=a("code"),mEr=o("model_type"),gEr=o(` property of the config object (either
passed as an argument or loaded from `),cMe=a("code"),hEr=o("pretrained_model_name_or_path"),pEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fMe=a("code"),_Er=o("pretrained_model_name_or_path"),uEr=o(":"),bEr=l(),q=a("ul"),rE=a("li"),mMe=a("strong"),vEr=o("albert"),FEr=o(" \u2014 "),IJ=a("a"),TEr=o("TFAlbertModel"),MEr=o(" (ALBERT model)"),EEr=l(),tE=a("li"),gMe=a("strong"),CEr=o("bart"),wEr=o(" \u2014 "),NJ=a("a"),AEr=o("TFBartModel"),LEr=o(" (BART model)"),yEr=l(),aE=a("li"),hMe=a("strong"),xEr=o("bert"),$Er=o(" \u2014 "),qJ=a("a"),kEr=o("TFBertModel"),SEr=o(" (BERT model)"),REr=l(),nE=a("li"),pMe=a("strong"),PEr=o("blenderbot"),BEr=o(" \u2014 "),jJ=a("a"),IEr=o("TFBlenderbotModel"),NEr=o(" (Blenderbot model)"),qEr=l(),sE=a("li"),_Me=a("strong"),jEr=o("blenderbot-small"),DEr=o(" \u2014 "),DJ=a("a"),GEr=o("TFBlenderbotSmallModel"),OEr=o(" (BlenderbotSmall model)"),VEr=l(),lE=a("li"),uMe=a("strong"),XEr=o("camembert"),zEr=o(" \u2014 "),GJ=a("a"),WEr=o("TFCamembertModel"),QEr=o(" (CamemBERT model)"),HEr=l(),iE=a("li"),bMe=a("strong"),UEr=o("clip"),JEr=o(" \u2014 "),OJ=a("a"),YEr=o("TFCLIPModel"),KEr=o(" (CLIP model)"),ZEr=l(),dE=a("li"),vMe=a("strong"),e4r=o("convbert"),o4r=o(" \u2014 "),VJ=a("a"),r4r=o("TFConvBertModel"),t4r=o(" (ConvBERT model)"),a4r=l(),cE=a("li"),FMe=a("strong"),n4r=o("convnext"),s4r=o(" \u2014 "),XJ=a("a"),l4r=o("TFConvNextModel"),i4r=o(" (ConvNeXT model)"),d4r=l(),fE=a("li"),TMe=a("strong"),c4r=o("ctrl"),f4r=o(" \u2014 "),zJ=a("a"),m4r=o("TFCTRLModel"),g4r=o(" (CTRL model)"),h4r=l(),mE=a("li"),MMe=a("strong"),p4r=o("data2vec-vision"),_4r=o(" \u2014 "),WJ=a("a"),u4r=o("TFData2VecVisionModel"),b4r=o(" (Data2VecVision model)"),v4r=l(),gE=a("li"),EMe=a("strong"),F4r=o("deberta"),T4r=o(" \u2014 "),QJ=a("a"),M4r=o("TFDebertaModel"),E4r=o(" (DeBERTa model)"),C4r=l(),hE=a("li"),CMe=a("strong"),w4r=o("deberta-v2"),A4r=o(" \u2014 "),HJ=a("a"),L4r=o("TFDebertaV2Model"),y4r=o(" (DeBERTa-v2 model)"),x4r=l(),pE=a("li"),wMe=a("strong"),$4r=o("deit"),k4r=o(" \u2014 "),UJ=a("a"),S4r=o("TFDeiTModel"),R4r=o(" (DeiT model)"),P4r=l(),_E=a("li"),AMe=a("strong"),B4r=o("distilbert"),I4r=o(" \u2014 "),JJ=a("a"),N4r=o("TFDistilBertModel"),q4r=o(" (DistilBERT model)"),j4r=l(),uE=a("li"),LMe=a("strong"),D4r=o("dpr"),G4r=o(" \u2014 "),YJ=a("a"),O4r=o("TFDPRQuestionEncoder"),V4r=o(" (DPR model)"),X4r=l(),bE=a("li"),yMe=a("strong"),z4r=o("electra"),W4r=o(" \u2014 "),KJ=a("a"),Q4r=o("TFElectraModel"),H4r=o(" (ELECTRA model)"),U4r=l(),vE=a("li"),xMe=a("strong"),J4r=o("flaubert"),Y4r=o(" \u2014 "),ZJ=a("a"),K4r=o("TFFlaubertModel"),Z4r=o(" (FlauBERT model)"),eCr=l(),al=a("li"),$Me=a("strong"),oCr=o("funnel"),rCr=o(" \u2014 "),eY=a("a"),tCr=o("TFFunnelModel"),aCr=o(" or "),oY=a("a"),nCr=o("TFFunnelBaseModel"),sCr=o(" (Funnel Transformer model)"),lCr=l(),FE=a("li"),kMe=a("strong"),iCr=o("gpt2"),dCr=o(" \u2014 "),rY=a("a"),cCr=o("TFGPT2Model"),fCr=o(" (OpenAI GPT-2 model)"),mCr=l(),TE=a("li"),SMe=a("strong"),gCr=o("gptj"),hCr=o(" \u2014 "),tY=a("a"),pCr=o("TFGPTJModel"),_Cr=o(" (GPT-J model)"),uCr=l(),ME=a("li"),RMe=a("strong"),bCr=o("hubert"),vCr=o(" \u2014 "),aY=a("a"),FCr=o("TFHubertModel"),TCr=o(" (Hubert model)"),MCr=l(),EE=a("li"),PMe=a("strong"),ECr=o("layoutlm"),CCr=o(" \u2014 "),nY=a("a"),wCr=o("TFLayoutLMModel"),ACr=o(" (LayoutLM model)"),LCr=l(),CE=a("li"),BMe=a("strong"),yCr=o("led"),xCr=o(" \u2014 "),sY=a("a"),$Cr=o("TFLEDModel"),kCr=o(" (LED model)"),SCr=l(),wE=a("li"),IMe=a("strong"),RCr=o("longformer"),PCr=o(" \u2014 "),lY=a("a"),BCr=o("TFLongformerModel"),ICr=o(" (Longformer model)"),NCr=l(),AE=a("li"),NMe=a("strong"),qCr=o("lxmert"),jCr=o(" \u2014 "),iY=a("a"),DCr=o("TFLxmertModel"),GCr=o(" (LXMERT model)"),OCr=l(),LE=a("li"),qMe=a("strong"),VCr=o("marian"),XCr=o(" \u2014 "),dY=a("a"),zCr=o("TFMarianModel"),WCr=o(" (Marian model)"),QCr=l(),yE=a("li"),jMe=a("strong"),HCr=o("mbart"),UCr=o(" \u2014 "),cY=a("a"),JCr=o("TFMBartModel"),YCr=o(" (mBART model)"),KCr=l(),xE=a("li"),DMe=a("strong"),ZCr=o("mobilebert"),e3r=o(" \u2014 "),fY=a("a"),o3r=o("TFMobileBertModel"),r3r=o(" (MobileBERT model)"),t3r=l(),$E=a("li"),GMe=a("strong"),a3r=o("mpnet"),n3r=o(" \u2014 "),mY=a("a"),s3r=o("TFMPNetModel"),l3r=o(" (MPNet model)"),i3r=l(),kE=a("li"),OMe=a("strong"),d3r=o("mt5"),c3r=o(" \u2014 "),gY=a("a"),f3r=o("TFMT5Model"),m3r=o(" (MT5 model)"),g3r=l(),SE=a("li"),VMe=a("strong"),h3r=o("openai-gpt"),p3r=o(" \u2014 "),hY=a("a"),_3r=o("TFOpenAIGPTModel"),u3r=o(" (OpenAI GPT model)"),b3r=l(),RE=a("li"),XMe=a("strong"),v3r=o("opt"),F3r=o(" \u2014 "),pY=a("a"),T3r=o("TFOPTModel"),M3r=o(" (OPT model)"),E3r=l(),PE=a("li"),zMe=a("strong"),C3r=o("pegasus"),w3r=o(" \u2014 "),_Y=a("a"),A3r=o("TFPegasusModel"),L3r=o(" (Pegasus model)"),y3r=l(),BE=a("li"),WMe=a("strong"),x3r=o("regnet"),$3r=o(" \u2014 "),uY=a("a"),k3r=o("TFRegNetModel"),S3r=o(" (RegNet model)"),R3r=l(),IE=a("li"),QMe=a("strong"),P3r=o("rembert"),B3r=o(" \u2014 "),bY=a("a"),I3r=o("TFRemBertModel"),N3r=o(" (RemBERT model)"),q3r=l(),NE=a("li"),HMe=a("strong"),j3r=o("resnet"),D3r=o(" \u2014 "),vY=a("a"),G3r=o("TFResNetModel"),O3r=o(" (ResNet model)"),V3r=l(),qE=a("li"),UMe=a("strong"),X3r=o("roberta"),z3r=o(" \u2014 "),FY=a("a"),W3r=o("TFRobertaModel"),Q3r=o(" (RoBERTa model)"),H3r=l(),jE=a("li"),JMe=a("strong"),U3r=o("roformer"),J3r=o(" \u2014 "),TY=a("a"),Y3r=o("TFRoFormerModel"),K3r=o(" (RoFormer model)"),Z3r=l(),DE=a("li"),YMe=a("strong"),e5r=o("segformer"),o5r=o(" \u2014 "),MY=a("a"),r5r=o("TFSegformerModel"),t5r=o(" (SegFormer model)"),a5r=l(),GE=a("li"),KMe=a("strong"),n5r=o("speech_to_text"),s5r=o(" \u2014 "),EY=a("a"),l5r=o("TFSpeech2TextModel"),i5r=o(" (Speech2Text model)"),d5r=l(),OE=a("li"),ZMe=a("strong"),c5r=o("swin"),f5r=o(" \u2014 "),CY=a("a"),m5r=o("TFSwinModel"),g5r=o(" (Swin Transformer model)"),h5r=l(),VE=a("li"),eEe=a("strong"),p5r=o("t5"),_5r=o(" \u2014 "),wY=a("a"),u5r=o("TFT5Model"),b5r=o(" (T5 model)"),v5r=l(),XE=a("li"),oEe=a("strong"),F5r=o("tapas"),T5r=o(" \u2014 "),AY=a("a"),M5r=o("TFTapasModel"),E5r=o(" (TAPAS model)"),C5r=l(),zE=a("li"),rEe=a("strong"),w5r=o("transfo-xl"),A5r=o(" \u2014 "),LY=a("a"),L5r=o("TFTransfoXLModel"),y5r=o(" (Transformer-XL model)"),x5r=l(),WE=a("li"),tEe=a("strong"),$5r=o("vit"),k5r=o(" \u2014 "),yY=a("a"),S5r=o("TFViTModel"),R5r=o(" (ViT model)"),P5r=l(),QE=a("li"),aEe=a("strong"),B5r=o("vit_mae"),I5r=o(" \u2014 "),xY=a("a"),N5r=o("TFViTMAEModel"),q5r=o(" (ViTMAE model)"),j5r=l(),HE=a("li"),nEe=a("strong"),D5r=o("wav2vec2"),G5r=o(" \u2014 "),$Y=a("a"),O5r=o("TFWav2Vec2Model"),V5r=o(" (Wav2Vec2 model)"),X5r=l(),UE=a("li"),sEe=a("strong"),z5r=o("xlm"),W5r=o(" \u2014 "),kY=a("a"),Q5r=o("TFXLMModel"),H5r=o(" (XLM model)"),U5r=l(),JE=a("li"),lEe=a("strong"),J5r=o("xlm-roberta"),Y5r=o(" \u2014 "),SY=a("a"),K5r=o("TFXLMRobertaModel"),Z5r=o(" (XLM-RoBERTa model)"),e0r=l(),YE=a("li"),iEe=a("strong"),o0r=o("xlnet"),r0r=o(" \u2014 "),RY=a("a"),t0r=o("TFXLNetModel"),a0r=o(" (XLNet model)"),n0r=l(),F(KE.$$.fragment),JQe=l(),Fc=a("h2"),ZE=a("a"),dEe=a("span"),F(Vx.$$.fragment),s0r=l(),cEe=a("span"),l0r=o("TFAutoModelForPreTraining"),YQe=l(),nr=a("div"),F(Xx.$$.fragment),i0r=l(),Tc=a("p"),d0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),PY=a("a"),c0r=o("from_pretrained()"),f0r=o(" class method or the "),BY=a("a"),m0r=o("from_config()"),g0r=o(` class
method.`),h0r=l(),zx=a("p"),p0r=o("This class cannot be instantiated directly using "),fEe=a("code"),_0r=o("__init__()"),u0r=o(" (throws an error)."),b0r=l(),Nt=a("div"),F(Wx.$$.fragment),v0r=l(),mEe=a("p"),F0r=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),T0r=l(),Mc=a("p"),M0r=o(`Note:
Loading a model from its configuration file does `),gEe=a("strong"),E0r=o("not"),C0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),w0r=o("from_pretrained()"),A0r=o(" to load the model weights."),L0r=l(),F(e4.$$.fragment),y0r=l(),Rr=a("div"),F(Qx.$$.fragment),x0r=l(),hEe=a("p"),$0r=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),k0r=l(),hn=a("p"),S0r=o("The model class to instantiate is selected based on the "),pEe=a("code"),R0r=o("model_type"),P0r=o(` property of the config object (either
passed as an argument or loaded from `),_Ee=a("code"),B0r=o("pretrained_model_name_or_path"),I0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uEe=a("code"),N0r=o("pretrained_model_name_or_path"),q0r=o(":"),j0r=l(),se=a("ul"),o4=a("li"),bEe=a("strong"),D0r=o("albert"),G0r=o(" \u2014 "),NY=a("a"),O0r=o("TFAlbertForPreTraining"),V0r=o(" (ALBERT model)"),X0r=l(),r4=a("li"),vEe=a("strong"),z0r=o("bart"),W0r=o(" \u2014 "),qY=a("a"),Q0r=o("TFBartForConditionalGeneration"),H0r=o(" (BART model)"),U0r=l(),t4=a("li"),FEe=a("strong"),J0r=o("bert"),Y0r=o(" \u2014 "),jY=a("a"),K0r=o("TFBertForPreTraining"),Z0r=o(" (BERT model)"),ewr=l(),a4=a("li"),TEe=a("strong"),owr=o("camembert"),rwr=o(" \u2014 "),DY=a("a"),twr=o("TFCamembertForMaskedLM"),awr=o(" (CamemBERT model)"),nwr=l(),n4=a("li"),MEe=a("strong"),swr=o("ctrl"),lwr=o(" \u2014 "),GY=a("a"),iwr=o("TFCTRLLMHeadModel"),dwr=o(" (CTRL model)"),cwr=l(),s4=a("li"),EEe=a("strong"),fwr=o("distilbert"),mwr=o(" \u2014 "),OY=a("a"),gwr=o("TFDistilBertForMaskedLM"),hwr=o(" (DistilBERT model)"),pwr=l(),l4=a("li"),CEe=a("strong"),_wr=o("electra"),uwr=o(" \u2014 "),VY=a("a"),bwr=o("TFElectraForPreTraining"),vwr=o(" (ELECTRA model)"),Fwr=l(),i4=a("li"),wEe=a("strong"),Twr=o("flaubert"),Mwr=o(" \u2014 "),XY=a("a"),Ewr=o("TFFlaubertWithLMHeadModel"),Cwr=o(" (FlauBERT model)"),wwr=l(),d4=a("li"),AEe=a("strong"),Awr=o("funnel"),Lwr=o(" \u2014 "),zY=a("a"),ywr=o("TFFunnelForPreTraining"),xwr=o(" (Funnel Transformer model)"),$wr=l(),c4=a("li"),LEe=a("strong"),kwr=o("gpt2"),Swr=o(" \u2014 "),WY=a("a"),Rwr=o("TFGPT2LMHeadModel"),Pwr=o(" (OpenAI GPT-2 model)"),Bwr=l(),f4=a("li"),yEe=a("strong"),Iwr=o("layoutlm"),Nwr=o(" \u2014 "),QY=a("a"),qwr=o("TFLayoutLMForMaskedLM"),jwr=o(" (LayoutLM model)"),Dwr=l(),m4=a("li"),xEe=a("strong"),Gwr=o("lxmert"),Owr=o(" \u2014 "),HY=a("a"),Vwr=o("TFLxmertForPreTraining"),Xwr=o(" (LXMERT model)"),zwr=l(),g4=a("li"),$Ee=a("strong"),Wwr=o("mobilebert"),Qwr=o(" \u2014 "),UY=a("a"),Hwr=o("TFMobileBertForPreTraining"),Uwr=o(" (MobileBERT model)"),Jwr=l(),h4=a("li"),kEe=a("strong"),Ywr=o("mpnet"),Kwr=o(" \u2014 "),JY=a("a"),Zwr=o("TFMPNetForMaskedLM"),e6r=o(" (MPNet model)"),o6r=l(),p4=a("li"),SEe=a("strong"),r6r=o("openai-gpt"),t6r=o(" \u2014 "),YY=a("a"),a6r=o("TFOpenAIGPTLMHeadModel"),n6r=o(" (OpenAI GPT model)"),s6r=l(),_4=a("li"),REe=a("strong"),l6r=o("roberta"),i6r=o(" \u2014 "),KY=a("a"),d6r=o("TFRobertaForMaskedLM"),c6r=o(" (RoBERTa model)"),f6r=l(),u4=a("li"),PEe=a("strong"),m6r=o("t5"),g6r=o(" \u2014 "),ZY=a("a"),h6r=o("TFT5ForConditionalGeneration"),p6r=o(" (T5 model)"),_6r=l(),b4=a("li"),BEe=a("strong"),u6r=o("tapas"),b6r=o(" \u2014 "),eK=a("a"),v6r=o("TFTapasForMaskedLM"),F6r=o(" (TAPAS model)"),T6r=l(),v4=a("li"),IEe=a("strong"),M6r=o("transfo-xl"),E6r=o(" \u2014 "),oK=a("a"),C6r=o("TFTransfoXLLMHeadModel"),w6r=o(" (Transformer-XL model)"),A6r=l(),F4=a("li"),NEe=a("strong"),L6r=o("vit_mae"),y6r=o(" \u2014 "),rK=a("a"),x6r=o("TFViTMAEForPreTraining"),$6r=o(" (ViTMAE model)"),k6r=l(),T4=a("li"),qEe=a("strong"),S6r=o("xlm"),R6r=o(" \u2014 "),tK=a("a"),P6r=o("TFXLMWithLMHeadModel"),B6r=o(" (XLM model)"),I6r=l(),M4=a("li"),jEe=a("strong"),N6r=o("xlm-roberta"),q6r=o(" \u2014 "),aK=a("a"),j6r=o("TFXLMRobertaForMaskedLM"),D6r=o(" (XLM-RoBERTa model)"),G6r=l(),E4=a("li"),DEe=a("strong"),O6r=o("xlnet"),V6r=o(" \u2014 "),nK=a("a"),X6r=o("TFXLNetLMHeadModel"),z6r=o(" (XLNet model)"),W6r=l(),F(C4.$$.fragment),KQe=l(),Ec=a("h2"),w4=a("a"),GEe=a("span"),F(Hx.$$.fragment),Q6r=l(),OEe=a("span"),H6r=o("TFAutoModelForCausalLM"),ZQe=l(),sr=a("div"),F(Ux.$$.fragment),U6r=l(),Cc=a("p"),J6r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),sK=a("a"),Y6r=o("from_pretrained()"),K6r=o(" class method or the "),lK=a("a"),Z6r=o("from_config()"),eAr=o(` class
method.`),oAr=l(),Jx=a("p"),rAr=o("This class cannot be instantiated directly using "),VEe=a("code"),tAr=o("__init__()"),aAr=o(" (throws an error)."),nAr=l(),qt=a("div"),F(Yx.$$.fragment),sAr=l(),XEe=a("p"),lAr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),iAr=l(),wc=a("p"),dAr=o(`Note:
Loading a model from its configuration file does `),zEe=a("strong"),cAr=o("not"),fAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iK=a("a"),mAr=o("from_pretrained()"),gAr=o(" to load the model weights."),hAr=l(),F(A4.$$.fragment),pAr=l(),Pr=a("div"),F(Kx.$$.fragment),_Ar=l(),WEe=a("p"),uAr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),bAr=l(),pn=a("p"),vAr=o("The model class to instantiate is selected based on the "),QEe=a("code"),FAr=o("model_type"),TAr=o(` property of the config object (either
passed as an argument or loaded from `),HEe=a("code"),MAr=o("pretrained_model_name_or_path"),EAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UEe=a("code"),CAr=o("pretrained_model_name_or_path"),wAr=o(":"),AAr=l(),Me=a("ul"),L4=a("li"),JEe=a("strong"),LAr=o("bert"),yAr=o(" \u2014 "),dK=a("a"),xAr=o("TFBertLMHeadModel"),$Ar=o(" (BERT model)"),kAr=l(),y4=a("li"),YEe=a("strong"),SAr=o("camembert"),RAr=o(" \u2014 "),cK=a("a"),PAr=o("TFCamembertForCausalLM"),BAr=o(" (CamemBERT model)"),IAr=l(),x4=a("li"),KEe=a("strong"),NAr=o("ctrl"),qAr=o(" \u2014 "),fK=a("a"),jAr=o("TFCTRLLMHeadModel"),DAr=o(" (CTRL model)"),GAr=l(),$4=a("li"),ZEe=a("strong"),OAr=o("gpt2"),VAr=o(" \u2014 "),mK=a("a"),XAr=o("TFGPT2LMHeadModel"),zAr=o(" (OpenAI GPT-2 model)"),WAr=l(),k4=a("li"),e4e=a("strong"),QAr=o("gptj"),HAr=o(" \u2014 "),gK=a("a"),UAr=o("TFGPTJForCausalLM"),JAr=o(" (GPT-J model)"),YAr=l(),S4=a("li"),o4e=a("strong"),KAr=o("openai-gpt"),ZAr=o(" \u2014 "),hK=a("a"),eLr=o("TFOpenAIGPTLMHeadModel"),oLr=o(" (OpenAI GPT model)"),rLr=l(),R4=a("li"),r4e=a("strong"),tLr=o("opt"),aLr=o(" \u2014 "),pK=a("a"),nLr=o("TFOPTForCausalLM"),sLr=o(" (OPT model)"),lLr=l(),P4=a("li"),t4e=a("strong"),iLr=o("rembert"),dLr=o(" \u2014 "),_K=a("a"),cLr=o("TFRemBertForCausalLM"),fLr=o(" (RemBERT model)"),mLr=l(),B4=a("li"),a4e=a("strong"),gLr=o("roberta"),hLr=o(" \u2014 "),uK=a("a"),pLr=o("TFRobertaForCausalLM"),_Lr=o(" (RoBERTa model)"),uLr=l(),I4=a("li"),n4e=a("strong"),bLr=o("roformer"),vLr=o(" \u2014 "),bK=a("a"),FLr=o("TFRoFormerForCausalLM"),TLr=o(" (RoFormer model)"),MLr=l(),N4=a("li"),s4e=a("strong"),ELr=o("transfo-xl"),CLr=o(" \u2014 "),vK=a("a"),wLr=o("TFTransfoXLLMHeadModel"),ALr=o(" (Transformer-XL model)"),LLr=l(),q4=a("li"),l4e=a("strong"),yLr=o("xlm"),xLr=o(" \u2014 "),FK=a("a"),$Lr=o("TFXLMWithLMHeadModel"),kLr=o(" (XLM model)"),SLr=l(),j4=a("li"),i4e=a("strong"),RLr=o("xlnet"),PLr=o(" \u2014 "),TK=a("a"),BLr=o("TFXLNetLMHeadModel"),ILr=o(" (XLNet model)"),NLr=l(),F(D4.$$.fragment),eHe=l(),Ac=a("h2"),G4=a("a"),d4e=a("span"),F(Zx.$$.fragment),qLr=l(),c4e=a("span"),jLr=o("TFAutoModelForImageClassification"),oHe=l(),lr=a("div"),F(e$.$$.fragment),DLr=l(),Lc=a("p"),GLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),MK=a("a"),OLr=o("from_pretrained()"),VLr=o(" class method or the "),EK=a("a"),XLr=o("from_config()"),zLr=o(` class
method.`),WLr=l(),o$=a("p"),QLr=o("This class cannot be instantiated directly using "),f4e=a("code"),HLr=o("__init__()"),ULr=o(" (throws an error)."),JLr=l(),jt=a("div"),F(r$.$$.fragment),YLr=l(),m4e=a("p"),KLr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),ZLr=l(),yc=a("p"),eyr=o(`Note:
Loading a model from its configuration file does `),g4e=a("strong"),oyr=o("not"),ryr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CK=a("a"),tyr=o("from_pretrained()"),ayr=o(" to load the model weights."),nyr=l(),F(O4.$$.fragment),syr=l(),Br=a("div"),F(t$.$$.fragment),lyr=l(),h4e=a("p"),iyr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),dyr=l(),_n=a("p"),cyr=o("The model class to instantiate is selected based on the "),p4e=a("code"),fyr=o("model_type"),myr=o(` property of the config object (either
passed as an argument or loaded from `),_4e=a("code"),gyr=o("pretrained_model_name_or_path"),hyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u4e=a("code"),pyr=o("pretrained_model_name_or_path"),_yr=o(":"),uyr=l(),Ve=a("ul"),V4=a("li"),b4e=a("strong"),byr=o("convnext"),vyr=o(" \u2014 "),wK=a("a"),Fyr=o("TFConvNextForImageClassification"),Tyr=o(" (ConvNeXT model)"),Myr=l(),X4=a("li"),v4e=a("strong"),Eyr=o("data2vec-vision"),Cyr=o(" \u2014 "),AK=a("a"),wyr=o("TFData2VecVisionForImageClassification"),Ayr=o(" (Data2VecVision model)"),Lyr=l(),nl=a("li"),F4e=a("strong"),yyr=o("deit"),xyr=o(" \u2014 "),LK=a("a"),$yr=o("TFDeiTForImageClassification"),kyr=o(" or "),yK=a("a"),Syr=o("TFDeiTForImageClassificationWithTeacher"),Ryr=o(" (DeiT model)"),Pyr=l(),z4=a("li"),T4e=a("strong"),Byr=o("regnet"),Iyr=o(" \u2014 "),xK=a("a"),Nyr=o("TFRegNetForImageClassification"),qyr=o(" (RegNet model)"),jyr=l(),W4=a("li"),M4e=a("strong"),Dyr=o("resnet"),Gyr=o(" \u2014 "),$K=a("a"),Oyr=o("TFResNetForImageClassification"),Vyr=o(" (ResNet model)"),Xyr=l(),Q4=a("li"),E4e=a("strong"),zyr=o("segformer"),Wyr=o(" \u2014 "),kK=a("a"),Qyr=o("TFSegformerForImageClassification"),Hyr=o(" (SegFormer model)"),Uyr=l(),H4=a("li"),C4e=a("strong"),Jyr=o("swin"),Yyr=o(" \u2014 "),SK=a("a"),Kyr=o("TFSwinForImageClassification"),Zyr=o(" (Swin Transformer model)"),e8r=l(),U4=a("li"),w4e=a("strong"),o8r=o("vit"),r8r=o(" \u2014 "),RK=a("a"),t8r=o("TFViTForImageClassification"),a8r=o(" (ViT model)"),n8r=l(),F(J4.$$.fragment),rHe=l(),xc=a("h2"),Y4=a("a"),A4e=a("span"),F(a$.$$.fragment),s8r=l(),L4e=a("span"),l8r=o("TFAutoModelForMaskedLM"),tHe=l(),ir=a("div"),F(n$.$$.fragment),i8r=l(),$c=a("p"),d8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PK=a("a"),c8r=o("from_pretrained()"),f8r=o(" class method or the "),BK=a("a"),m8r=o("from_config()"),g8r=o(` class
method.`),h8r=l(),s$=a("p"),p8r=o("This class cannot be instantiated directly using "),y4e=a("code"),_8r=o("__init__()"),u8r=o(" (throws an error)."),b8r=l(),Dt=a("div"),F(l$.$$.fragment),v8r=l(),x4e=a("p"),F8r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),T8r=l(),kc=a("p"),M8r=o(`Note:
Loading a model from its configuration file does `),$4e=a("strong"),E8r=o("not"),C8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),w8r=o("from_pretrained()"),A8r=o(" to load the model weights."),L8r=l(),F(K4.$$.fragment),y8r=l(),Ir=a("div"),F(i$.$$.fragment),x8r=l(),k4e=a("p"),$8r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),k8r=l(),un=a("p"),S8r=o("The model class to instantiate is selected based on the "),S4e=a("code"),R8r=o("model_type"),P8r=o(` property of the config object (either
passed as an argument or loaded from `),R4e=a("code"),B8r=o("pretrained_model_name_or_path"),I8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P4e=a("code"),N8r=o("pretrained_model_name_or_path"),q8r=o(":"),j8r=l(),ie=a("ul"),Z4=a("li"),B4e=a("strong"),D8r=o("albert"),G8r=o(" \u2014 "),NK=a("a"),O8r=o("TFAlbertForMaskedLM"),V8r=o(" (ALBERT model)"),X8r=l(),eC=a("li"),I4e=a("strong"),z8r=o("bert"),W8r=o(" \u2014 "),qK=a("a"),Q8r=o("TFBertForMaskedLM"),H8r=o(" (BERT model)"),U8r=l(),oC=a("li"),N4e=a("strong"),J8r=o("camembert"),Y8r=o(" \u2014 "),jK=a("a"),K8r=o("TFCamembertForMaskedLM"),Z8r=o(" (CamemBERT model)"),exr=l(),rC=a("li"),q4e=a("strong"),oxr=o("convbert"),rxr=o(" \u2014 "),DK=a("a"),txr=o("TFConvBertForMaskedLM"),axr=o(" (ConvBERT model)"),nxr=l(),tC=a("li"),j4e=a("strong"),sxr=o("deberta"),lxr=o(" \u2014 "),GK=a("a"),ixr=o("TFDebertaForMaskedLM"),dxr=o(" (DeBERTa model)"),cxr=l(),aC=a("li"),D4e=a("strong"),fxr=o("deberta-v2"),mxr=o(" \u2014 "),OK=a("a"),gxr=o("TFDebertaV2ForMaskedLM"),hxr=o(" (DeBERTa-v2 model)"),pxr=l(),nC=a("li"),G4e=a("strong"),_xr=o("distilbert"),uxr=o(" \u2014 "),VK=a("a"),bxr=o("TFDistilBertForMaskedLM"),vxr=o(" (DistilBERT model)"),Fxr=l(),sC=a("li"),O4e=a("strong"),Txr=o("electra"),Mxr=o(" \u2014 "),XK=a("a"),Exr=o("TFElectraForMaskedLM"),Cxr=o(" (ELECTRA model)"),wxr=l(),lC=a("li"),V4e=a("strong"),Axr=o("flaubert"),Lxr=o(" \u2014 "),zK=a("a"),yxr=o("TFFlaubertWithLMHeadModel"),xxr=o(" (FlauBERT model)"),$xr=l(),iC=a("li"),X4e=a("strong"),kxr=o("funnel"),Sxr=o(" \u2014 "),WK=a("a"),Rxr=o("TFFunnelForMaskedLM"),Pxr=o(" (Funnel Transformer model)"),Bxr=l(),dC=a("li"),z4e=a("strong"),Ixr=o("layoutlm"),Nxr=o(" \u2014 "),QK=a("a"),qxr=o("TFLayoutLMForMaskedLM"),jxr=o(" (LayoutLM model)"),Dxr=l(),cC=a("li"),W4e=a("strong"),Gxr=o("longformer"),Oxr=o(" \u2014 "),HK=a("a"),Vxr=o("TFLongformerForMaskedLM"),Xxr=o(" (Longformer model)"),zxr=l(),fC=a("li"),Q4e=a("strong"),Wxr=o("mobilebert"),Qxr=o(" \u2014 "),UK=a("a"),Hxr=o("TFMobileBertForMaskedLM"),Uxr=o(" (MobileBERT model)"),Jxr=l(),mC=a("li"),H4e=a("strong"),Yxr=o("mpnet"),Kxr=o(" \u2014 "),JK=a("a"),Zxr=o("TFMPNetForMaskedLM"),e$r=o(" (MPNet model)"),o$r=l(),gC=a("li"),U4e=a("strong"),r$r=o("rembert"),t$r=o(" \u2014 "),YK=a("a"),a$r=o("TFRemBertForMaskedLM"),n$r=o(" (RemBERT model)"),s$r=l(),hC=a("li"),J4e=a("strong"),l$r=o("roberta"),i$r=o(" \u2014 "),KK=a("a"),d$r=o("TFRobertaForMaskedLM"),c$r=o(" (RoBERTa model)"),f$r=l(),pC=a("li"),Y4e=a("strong"),m$r=o("roformer"),g$r=o(" \u2014 "),ZK=a("a"),h$r=o("TFRoFormerForMaskedLM"),p$r=o(" (RoFormer model)"),_$r=l(),_C=a("li"),K4e=a("strong"),u$r=o("tapas"),b$r=o(" \u2014 "),eZ=a("a"),v$r=o("TFTapasForMaskedLM"),F$r=o(" (TAPAS model)"),T$r=l(),uC=a("li"),Z4e=a("strong"),M$r=o("xlm"),E$r=o(" \u2014 "),oZ=a("a"),C$r=o("TFXLMWithLMHeadModel"),w$r=o(" (XLM model)"),A$r=l(),bC=a("li"),eCe=a("strong"),L$r=o("xlm-roberta"),y$r=o(" \u2014 "),rZ=a("a"),x$r=o("TFXLMRobertaForMaskedLM"),$$r=o(" (XLM-RoBERTa model)"),k$r=l(),F(vC.$$.fragment),aHe=l(),Sc=a("h2"),FC=a("a"),oCe=a("span"),F(d$.$$.fragment),S$r=l(),rCe=a("span"),R$r=o("TFAutoModelForSeq2SeqLM"),nHe=l(),dr=a("div"),F(c$.$$.fragment),P$r=l(),Rc=a("p"),B$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tZ=a("a"),I$r=o("from_pretrained()"),N$r=o(" class method or the "),aZ=a("a"),q$r=o("from_config()"),j$r=o(` class
method.`),D$r=l(),f$=a("p"),G$r=o("This class cannot be instantiated directly using "),tCe=a("code"),O$r=o("__init__()"),V$r=o(" (throws an error)."),X$r=l(),Gt=a("div"),F(m$.$$.fragment),z$r=l(),aCe=a("p"),W$r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Q$r=l(),Pc=a("p"),H$r=o(`Note:
Loading a model from its configuration file does `),nCe=a("strong"),U$r=o("not"),J$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=a("a"),Y$r=o("from_pretrained()"),K$r=o(" to load the model weights."),Z$r=l(),F(TC.$$.fragment),ekr=l(),Nr=a("div"),F(g$.$$.fragment),okr=l(),sCe=a("p"),rkr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),tkr=l(),bn=a("p"),akr=o("The model class to instantiate is selected based on the "),lCe=a("code"),nkr=o("model_type"),skr=o(` property of the config object (either
passed as an argument or loaded from `),iCe=a("code"),lkr=o("pretrained_model_name_or_path"),ikr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dCe=a("code"),dkr=o("pretrained_model_name_or_path"),ckr=o(":"),fkr=l(),ye=a("ul"),MC=a("li"),cCe=a("strong"),mkr=o("bart"),gkr=o(" \u2014 "),sZ=a("a"),hkr=o("TFBartForConditionalGeneration"),pkr=o(" (BART model)"),_kr=l(),EC=a("li"),fCe=a("strong"),ukr=o("blenderbot"),bkr=o(" \u2014 "),lZ=a("a"),vkr=o("TFBlenderbotForConditionalGeneration"),Fkr=o(" (Blenderbot model)"),Tkr=l(),CC=a("li"),mCe=a("strong"),Mkr=o("blenderbot-small"),Ekr=o(" \u2014 "),iZ=a("a"),Ckr=o("TFBlenderbotSmallForConditionalGeneration"),wkr=o(" (BlenderbotSmall model)"),Akr=l(),wC=a("li"),gCe=a("strong"),Lkr=o("encoder-decoder"),ykr=o(" \u2014 "),dZ=a("a"),xkr=o("TFEncoderDecoderModel"),$kr=o(" (Encoder decoder model)"),kkr=l(),AC=a("li"),hCe=a("strong"),Skr=o("led"),Rkr=o(" \u2014 "),cZ=a("a"),Pkr=o("TFLEDForConditionalGeneration"),Bkr=o(" (LED model)"),Ikr=l(),LC=a("li"),pCe=a("strong"),Nkr=o("marian"),qkr=o(" \u2014 "),fZ=a("a"),jkr=o("TFMarianMTModel"),Dkr=o(" (Marian model)"),Gkr=l(),yC=a("li"),_Ce=a("strong"),Okr=o("mbart"),Vkr=o(" \u2014 "),mZ=a("a"),Xkr=o("TFMBartForConditionalGeneration"),zkr=o(" (mBART model)"),Wkr=l(),xC=a("li"),uCe=a("strong"),Qkr=o("mt5"),Hkr=o(" \u2014 "),gZ=a("a"),Ukr=o("TFMT5ForConditionalGeneration"),Jkr=o(" (MT5 model)"),Ykr=l(),$C=a("li"),bCe=a("strong"),Kkr=o("pegasus"),Zkr=o(" \u2014 "),hZ=a("a"),eSr=o("TFPegasusForConditionalGeneration"),oSr=o(" (Pegasus model)"),rSr=l(),kC=a("li"),vCe=a("strong"),tSr=o("t5"),aSr=o(" \u2014 "),pZ=a("a"),nSr=o("TFT5ForConditionalGeneration"),sSr=o(" (T5 model)"),lSr=l(),F(SC.$$.fragment),sHe=l(),Bc=a("h2"),RC=a("a"),FCe=a("span"),F(h$.$$.fragment),iSr=l(),TCe=a("span"),dSr=o("TFAutoModelForSequenceClassification"),lHe=l(),cr=a("div"),F(p$.$$.fragment),cSr=l(),Ic=a("p"),fSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_Z=a("a"),mSr=o("from_pretrained()"),gSr=o(" class method or the "),uZ=a("a"),hSr=o("from_config()"),pSr=o(` class
method.`),_Sr=l(),_$=a("p"),uSr=o("This class cannot be instantiated directly using "),MCe=a("code"),bSr=o("__init__()"),vSr=o(" (throws an error)."),FSr=l(),Ot=a("div"),F(u$.$$.fragment),TSr=l(),ECe=a("p"),MSr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),ESr=l(),Nc=a("p"),CSr=o(`Note:
Loading a model from its configuration file does `),CCe=a("strong"),wSr=o("not"),ASr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bZ=a("a"),LSr=o("from_pretrained()"),ySr=o(" to load the model weights."),xSr=l(),F(PC.$$.fragment),$Sr=l(),qr=a("div"),F(b$.$$.fragment),kSr=l(),wCe=a("p"),SSr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),RSr=l(),vn=a("p"),PSr=o("The model class to instantiate is selected based on the "),ACe=a("code"),BSr=o("model_type"),ISr=o(` property of the config object (either
passed as an argument or loaded from `),LCe=a("code"),NSr=o("pretrained_model_name_or_path"),qSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yCe=a("code"),jSr=o("pretrained_model_name_or_path"),DSr=o(":"),GSr=l(),ae=a("ul"),BC=a("li"),xCe=a("strong"),OSr=o("albert"),VSr=o(" \u2014 "),vZ=a("a"),XSr=o("TFAlbertForSequenceClassification"),zSr=o(" (ALBERT model)"),WSr=l(),IC=a("li"),$Ce=a("strong"),QSr=o("bert"),HSr=o(" \u2014 "),FZ=a("a"),USr=o("TFBertForSequenceClassification"),JSr=o(" (BERT model)"),YSr=l(),NC=a("li"),kCe=a("strong"),KSr=o("camembert"),ZSr=o(" \u2014 "),TZ=a("a"),eRr=o("TFCamembertForSequenceClassification"),oRr=o(" (CamemBERT model)"),rRr=l(),qC=a("li"),SCe=a("strong"),tRr=o("convbert"),aRr=o(" \u2014 "),MZ=a("a"),nRr=o("TFConvBertForSequenceClassification"),sRr=o(" (ConvBERT model)"),lRr=l(),jC=a("li"),RCe=a("strong"),iRr=o("ctrl"),dRr=o(" \u2014 "),EZ=a("a"),cRr=o("TFCTRLForSequenceClassification"),fRr=o(" (CTRL model)"),mRr=l(),DC=a("li"),PCe=a("strong"),gRr=o("deberta"),hRr=o(" \u2014 "),CZ=a("a"),pRr=o("TFDebertaForSequenceClassification"),_Rr=o(" (DeBERTa model)"),uRr=l(),GC=a("li"),BCe=a("strong"),bRr=o("deberta-v2"),vRr=o(" \u2014 "),wZ=a("a"),FRr=o("TFDebertaV2ForSequenceClassification"),TRr=o(" (DeBERTa-v2 model)"),MRr=l(),OC=a("li"),ICe=a("strong"),ERr=o("distilbert"),CRr=o(" \u2014 "),AZ=a("a"),wRr=o("TFDistilBertForSequenceClassification"),ARr=o(" (DistilBERT model)"),LRr=l(),VC=a("li"),NCe=a("strong"),yRr=o("electra"),xRr=o(" \u2014 "),LZ=a("a"),$Rr=o("TFElectraForSequenceClassification"),kRr=o(" (ELECTRA model)"),SRr=l(),XC=a("li"),qCe=a("strong"),RRr=o("flaubert"),PRr=o(" \u2014 "),yZ=a("a"),BRr=o("TFFlaubertForSequenceClassification"),IRr=o(" (FlauBERT model)"),NRr=l(),zC=a("li"),jCe=a("strong"),qRr=o("funnel"),jRr=o(" \u2014 "),xZ=a("a"),DRr=o("TFFunnelForSequenceClassification"),GRr=o(" (Funnel Transformer model)"),ORr=l(),WC=a("li"),DCe=a("strong"),VRr=o("gpt2"),XRr=o(" \u2014 "),$Z=a("a"),zRr=o("TFGPT2ForSequenceClassification"),WRr=o(" (OpenAI GPT-2 model)"),QRr=l(),QC=a("li"),GCe=a("strong"),HRr=o("gptj"),URr=o(" \u2014 "),kZ=a("a"),JRr=o("TFGPTJForSequenceClassification"),YRr=o(" (GPT-J model)"),KRr=l(),HC=a("li"),OCe=a("strong"),ZRr=o("layoutlm"),ePr=o(" \u2014 "),SZ=a("a"),oPr=o("TFLayoutLMForSequenceClassification"),rPr=o(" (LayoutLM model)"),tPr=l(),UC=a("li"),VCe=a("strong"),aPr=o("longformer"),nPr=o(" \u2014 "),RZ=a("a"),sPr=o("TFLongformerForSequenceClassification"),lPr=o(" (Longformer model)"),iPr=l(),JC=a("li"),XCe=a("strong"),dPr=o("mobilebert"),cPr=o(" \u2014 "),PZ=a("a"),fPr=o("TFMobileBertForSequenceClassification"),mPr=o(" (MobileBERT model)"),gPr=l(),YC=a("li"),zCe=a("strong"),hPr=o("mpnet"),pPr=o(" \u2014 "),BZ=a("a"),_Pr=o("TFMPNetForSequenceClassification"),uPr=o(" (MPNet model)"),bPr=l(),KC=a("li"),WCe=a("strong"),vPr=o("openai-gpt"),FPr=o(" \u2014 "),IZ=a("a"),TPr=o("TFOpenAIGPTForSequenceClassification"),MPr=o(" (OpenAI GPT model)"),EPr=l(),ZC=a("li"),QCe=a("strong"),CPr=o("rembert"),wPr=o(" \u2014 "),NZ=a("a"),APr=o("TFRemBertForSequenceClassification"),LPr=o(" (RemBERT model)"),yPr=l(),e3=a("li"),HCe=a("strong"),xPr=o("roberta"),$Pr=o(" \u2014 "),qZ=a("a"),kPr=o("TFRobertaForSequenceClassification"),SPr=o(" (RoBERTa model)"),RPr=l(),o3=a("li"),UCe=a("strong"),PPr=o("roformer"),BPr=o(" \u2014 "),jZ=a("a"),IPr=o("TFRoFormerForSequenceClassification"),NPr=o(" (RoFormer model)"),qPr=l(),r3=a("li"),JCe=a("strong"),jPr=o("tapas"),DPr=o(" \u2014 "),DZ=a("a"),GPr=o("TFTapasForSequenceClassification"),OPr=o(" (TAPAS model)"),VPr=l(),t3=a("li"),YCe=a("strong"),XPr=o("transfo-xl"),zPr=o(" \u2014 "),GZ=a("a"),WPr=o("TFTransfoXLForSequenceClassification"),QPr=o(" (Transformer-XL model)"),HPr=l(),a3=a("li"),KCe=a("strong"),UPr=o("xlm"),JPr=o(" \u2014 "),OZ=a("a"),YPr=o("TFXLMForSequenceClassification"),KPr=o(" (XLM model)"),ZPr=l(),n3=a("li"),ZCe=a("strong"),eBr=o("xlm-roberta"),oBr=o(" \u2014 "),VZ=a("a"),rBr=o("TFXLMRobertaForSequenceClassification"),tBr=o(" (XLM-RoBERTa model)"),aBr=l(),s3=a("li"),e3e=a("strong"),nBr=o("xlnet"),sBr=o(" \u2014 "),XZ=a("a"),lBr=o("TFXLNetForSequenceClassification"),iBr=o(" (XLNet model)"),dBr=l(),F(l3.$$.fragment),iHe=l(),qc=a("h2"),i3=a("a"),o3e=a("span"),F(v$.$$.fragment),cBr=l(),r3e=a("span"),fBr=o("TFAutoModelForMultipleChoice"),dHe=l(),fr=a("div"),F(F$.$$.fragment),mBr=l(),jc=a("p"),gBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zZ=a("a"),hBr=o("from_pretrained()"),pBr=o(" class method or the "),WZ=a("a"),_Br=o("from_config()"),uBr=o(` class
method.`),bBr=l(),T$=a("p"),vBr=o("This class cannot be instantiated directly using "),t3e=a("code"),FBr=o("__init__()"),TBr=o(" (throws an error)."),MBr=l(),Vt=a("div"),F(M$.$$.fragment),EBr=l(),a3e=a("p"),CBr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wBr=l(),Dc=a("p"),ABr=o(`Note:
Loading a model from its configuration file does `),n3e=a("strong"),LBr=o("not"),yBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),QZ=a("a"),xBr=o("from_pretrained()"),$Br=o(" to load the model weights."),kBr=l(),F(d3.$$.fragment),SBr=l(),jr=a("div"),F(E$.$$.fragment),RBr=l(),s3e=a("p"),PBr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),BBr=l(),Fn=a("p"),IBr=o("The model class to instantiate is selected based on the "),l3e=a("code"),NBr=o("model_type"),qBr=o(` property of the config object (either
passed as an argument or loaded from `),i3e=a("code"),jBr=o("pretrained_model_name_or_path"),DBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d3e=a("code"),GBr=o("pretrained_model_name_or_path"),OBr=o(":"),VBr=l(),ve=a("ul"),c3=a("li"),c3e=a("strong"),XBr=o("albert"),zBr=o(" \u2014 "),HZ=a("a"),WBr=o("TFAlbertForMultipleChoice"),QBr=o(" (ALBERT model)"),HBr=l(),f3=a("li"),f3e=a("strong"),UBr=o("bert"),JBr=o(" \u2014 "),UZ=a("a"),YBr=o("TFBertForMultipleChoice"),KBr=o(" (BERT model)"),ZBr=l(),m3=a("li"),m3e=a("strong"),eIr=o("camembert"),oIr=o(" \u2014 "),JZ=a("a"),rIr=o("TFCamembertForMultipleChoice"),tIr=o(" (CamemBERT model)"),aIr=l(),g3=a("li"),g3e=a("strong"),nIr=o("convbert"),sIr=o(" \u2014 "),YZ=a("a"),lIr=o("TFConvBertForMultipleChoice"),iIr=o(" (ConvBERT model)"),dIr=l(),h3=a("li"),h3e=a("strong"),cIr=o("distilbert"),fIr=o(" \u2014 "),KZ=a("a"),mIr=o("TFDistilBertForMultipleChoice"),gIr=o(" (DistilBERT model)"),hIr=l(),p3=a("li"),p3e=a("strong"),pIr=o("electra"),_Ir=o(" \u2014 "),ZZ=a("a"),uIr=o("TFElectraForMultipleChoice"),bIr=o(" (ELECTRA model)"),vIr=l(),_3=a("li"),_3e=a("strong"),FIr=o("flaubert"),TIr=o(" \u2014 "),eee=a("a"),MIr=o("TFFlaubertForMultipleChoice"),EIr=o(" (FlauBERT model)"),CIr=l(),u3=a("li"),u3e=a("strong"),wIr=o("funnel"),AIr=o(" \u2014 "),oee=a("a"),LIr=o("TFFunnelForMultipleChoice"),yIr=o(" (Funnel Transformer model)"),xIr=l(),b3=a("li"),b3e=a("strong"),$Ir=o("longformer"),kIr=o(" \u2014 "),ree=a("a"),SIr=o("TFLongformerForMultipleChoice"),RIr=o(" (Longformer model)"),PIr=l(),v3=a("li"),v3e=a("strong"),BIr=o("mobilebert"),IIr=o(" \u2014 "),tee=a("a"),NIr=o("TFMobileBertForMultipleChoice"),qIr=o(" (MobileBERT model)"),jIr=l(),F3=a("li"),F3e=a("strong"),DIr=o("mpnet"),GIr=o(" \u2014 "),aee=a("a"),OIr=o("TFMPNetForMultipleChoice"),VIr=o(" (MPNet model)"),XIr=l(),T3=a("li"),T3e=a("strong"),zIr=o("rembert"),WIr=o(" \u2014 "),nee=a("a"),QIr=o("TFRemBertForMultipleChoice"),HIr=o(" (RemBERT model)"),UIr=l(),M3=a("li"),M3e=a("strong"),JIr=o("roberta"),YIr=o(" \u2014 "),see=a("a"),KIr=o("TFRobertaForMultipleChoice"),ZIr=o(" (RoBERTa model)"),eNr=l(),E3=a("li"),E3e=a("strong"),oNr=o("roformer"),rNr=o(" \u2014 "),lee=a("a"),tNr=o("TFRoFormerForMultipleChoice"),aNr=o(" (RoFormer model)"),nNr=l(),C3=a("li"),C3e=a("strong"),sNr=o("xlm"),lNr=o(" \u2014 "),iee=a("a"),iNr=o("TFXLMForMultipleChoice"),dNr=o(" (XLM model)"),cNr=l(),w3=a("li"),w3e=a("strong"),fNr=o("xlm-roberta"),mNr=o(" \u2014 "),dee=a("a"),gNr=o("TFXLMRobertaForMultipleChoice"),hNr=o(" (XLM-RoBERTa model)"),pNr=l(),A3=a("li"),A3e=a("strong"),_Nr=o("xlnet"),uNr=o(" \u2014 "),cee=a("a"),bNr=o("TFXLNetForMultipleChoice"),vNr=o(" (XLNet model)"),FNr=l(),F(L3.$$.fragment),cHe=l(),Gc=a("h2"),y3=a("a"),L3e=a("span"),F(C$.$$.fragment),TNr=l(),y3e=a("span"),MNr=o("TFAutoModelForNextSentencePrediction"),fHe=l(),mr=a("div"),F(w$.$$.fragment),ENr=l(),Oc=a("p"),CNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fee=a("a"),wNr=o("from_pretrained()"),ANr=o(" class method or the "),mee=a("a"),LNr=o("from_config()"),yNr=o(` class
method.`),xNr=l(),A$=a("p"),$Nr=o("This class cannot be instantiated directly using "),x3e=a("code"),kNr=o("__init__()"),SNr=o(" (throws an error)."),RNr=l(),Xt=a("div"),F(L$.$$.fragment),PNr=l(),$3e=a("p"),BNr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),INr=l(),Vc=a("p"),NNr=o(`Note:
Loading a model from its configuration file does `),k3e=a("strong"),qNr=o("not"),jNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=a("a"),DNr=o("from_pretrained()"),GNr=o(" to load the model weights."),ONr=l(),F(x3.$$.fragment),VNr=l(),Dr=a("div"),F(y$.$$.fragment),XNr=l(),S3e=a("p"),zNr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),WNr=l(),Tn=a("p"),QNr=o("The model class to instantiate is selected based on the "),R3e=a("code"),HNr=o("model_type"),UNr=o(` property of the config object (either
passed as an argument or loaded from `),P3e=a("code"),JNr=o("pretrained_model_name_or_path"),YNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B3e=a("code"),KNr=o("pretrained_model_name_or_path"),ZNr=o(":"),eqr=l(),x$=a("ul"),$3=a("li"),I3e=a("strong"),oqr=o("bert"),rqr=o(" \u2014 "),hee=a("a"),tqr=o("TFBertForNextSentencePrediction"),aqr=o(" (BERT model)"),nqr=l(),k3=a("li"),N3e=a("strong"),sqr=o("mobilebert"),lqr=o(" \u2014 "),pee=a("a"),iqr=o("TFMobileBertForNextSentencePrediction"),dqr=o(" (MobileBERT model)"),cqr=l(),F(S3.$$.fragment),mHe=l(),Xc=a("h2"),R3=a("a"),q3e=a("span"),F($$.$$.fragment),fqr=l(),j3e=a("span"),mqr=o("TFAutoModelForTableQuestionAnswering"),gHe=l(),gr=a("div"),F(k$.$$.fragment),gqr=l(),zc=a("p"),hqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),_ee=a("a"),pqr=o("from_pretrained()"),_qr=o(" class method or the "),uee=a("a"),uqr=o("from_config()"),bqr=o(` class
method.`),vqr=l(),S$=a("p"),Fqr=o("This class cannot be instantiated directly using "),D3e=a("code"),Tqr=o("__init__()"),Mqr=o(" (throws an error)."),Eqr=l(),zt=a("div"),F(R$.$$.fragment),Cqr=l(),G3e=a("p"),wqr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Aqr=l(),Wc=a("p"),Lqr=o(`Note:
Loading a model from its configuration file does `),O3e=a("strong"),yqr=o("not"),xqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),bee=a("a"),$qr=o("from_pretrained()"),kqr=o(" to load the model weights."),Sqr=l(),F(P3.$$.fragment),Rqr=l(),Gr=a("div"),F(P$.$$.fragment),Pqr=l(),V3e=a("p"),Bqr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Iqr=l(),Mn=a("p"),Nqr=o("The model class to instantiate is selected based on the "),X3e=a("code"),qqr=o("model_type"),jqr=o(` property of the config object (either
passed as an argument or loaded from `),z3e=a("code"),Dqr=o("pretrained_model_name_or_path"),Gqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W3e=a("code"),Oqr=o("pretrained_model_name_or_path"),Vqr=o(":"),Xqr=l(),Q3e=a("ul"),B3=a("li"),H3e=a("strong"),zqr=o("tapas"),Wqr=o(" \u2014 "),vee=a("a"),Qqr=o("TFTapasForQuestionAnswering"),Hqr=o(" (TAPAS model)"),Uqr=l(),F(I3.$$.fragment),hHe=l(),Qc=a("h2"),N3=a("a"),U3e=a("span"),F(B$.$$.fragment),Jqr=l(),J3e=a("span"),Yqr=o("TFAutoModelForTokenClassification"),pHe=l(),hr=a("div"),F(I$.$$.fragment),Kqr=l(),Hc=a("p"),Zqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Fee=a("a"),ejr=o("from_pretrained()"),ojr=o(" class method or the "),Tee=a("a"),rjr=o("from_config()"),tjr=o(` class
method.`),ajr=l(),N$=a("p"),njr=o("This class cannot be instantiated directly using "),Y3e=a("code"),sjr=o("__init__()"),ljr=o(" (throws an error)."),ijr=l(),Wt=a("div"),F(q$.$$.fragment),djr=l(),K3e=a("p"),cjr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),fjr=l(),Uc=a("p"),mjr=o(`Note:
Loading a model from its configuration file does `),Z3e=a("strong"),gjr=o("not"),hjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Mee=a("a"),pjr=o("from_pretrained()"),_jr=o(" to load the model weights."),ujr=l(),F(q3.$$.fragment),bjr=l(),Or=a("div"),F(j$.$$.fragment),vjr=l(),e5e=a("p"),Fjr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Tjr=l(),En=a("p"),Mjr=o("The model class to instantiate is selected based on the "),o5e=a("code"),Ejr=o("model_type"),Cjr=o(` property of the config object (either
passed as an argument or loaded from `),r5e=a("code"),wjr=o("pretrained_model_name_or_path"),Ajr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t5e=a("code"),Ljr=o("pretrained_model_name_or_path"),yjr=o(":"),xjr=l(),de=a("ul"),j3=a("li"),a5e=a("strong"),$jr=o("albert"),kjr=o(" \u2014 "),Eee=a("a"),Sjr=o("TFAlbertForTokenClassification"),Rjr=o(" (ALBERT model)"),Pjr=l(),D3=a("li"),n5e=a("strong"),Bjr=o("bert"),Ijr=o(" \u2014 "),Cee=a("a"),Njr=o("TFBertForTokenClassification"),qjr=o(" (BERT model)"),jjr=l(),G3=a("li"),s5e=a("strong"),Djr=o("camembert"),Gjr=o(" \u2014 "),wee=a("a"),Ojr=o("TFCamembertForTokenClassification"),Vjr=o(" (CamemBERT model)"),Xjr=l(),O3=a("li"),l5e=a("strong"),zjr=o("convbert"),Wjr=o(" \u2014 "),Aee=a("a"),Qjr=o("TFConvBertForTokenClassification"),Hjr=o(" (ConvBERT model)"),Ujr=l(),V3=a("li"),i5e=a("strong"),Jjr=o("deberta"),Yjr=o(" \u2014 "),Lee=a("a"),Kjr=o("TFDebertaForTokenClassification"),Zjr=o(" (DeBERTa model)"),eDr=l(),X3=a("li"),d5e=a("strong"),oDr=o("deberta-v2"),rDr=o(" \u2014 "),yee=a("a"),tDr=o("TFDebertaV2ForTokenClassification"),aDr=o(" (DeBERTa-v2 model)"),nDr=l(),z3=a("li"),c5e=a("strong"),sDr=o("distilbert"),lDr=o(" \u2014 "),xee=a("a"),iDr=o("TFDistilBertForTokenClassification"),dDr=o(" (DistilBERT model)"),cDr=l(),W3=a("li"),f5e=a("strong"),fDr=o("electra"),mDr=o(" \u2014 "),$ee=a("a"),gDr=o("TFElectraForTokenClassification"),hDr=o(" (ELECTRA model)"),pDr=l(),Q3=a("li"),m5e=a("strong"),_Dr=o("flaubert"),uDr=o(" \u2014 "),kee=a("a"),bDr=o("TFFlaubertForTokenClassification"),vDr=o(" (FlauBERT model)"),FDr=l(),H3=a("li"),g5e=a("strong"),TDr=o("funnel"),MDr=o(" \u2014 "),See=a("a"),EDr=o("TFFunnelForTokenClassification"),CDr=o(" (Funnel Transformer model)"),wDr=l(),U3=a("li"),h5e=a("strong"),ADr=o("layoutlm"),LDr=o(" \u2014 "),Ree=a("a"),yDr=o("TFLayoutLMForTokenClassification"),xDr=o(" (LayoutLM model)"),$Dr=l(),J3=a("li"),p5e=a("strong"),kDr=o("longformer"),SDr=o(" \u2014 "),Pee=a("a"),RDr=o("TFLongformerForTokenClassification"),PDr=o(" (Longformer model)"),BDr=l(),Y3=a("li"),_5e=a("strong"),IDr=o("mobilebert"),NDr=o(" \u2014 "),Bee=a("a"),qDr=o("TFMobileBertForTokenClassification"),jDr=o(" (MobileBERT model)"),DDr=l(),K3=a("li"),u5e=a("strong"),GDr=o("mpnet"),ODr=o(" \u2014 "),Iee=a("a"),VDr=o("TFMPNetForTokenClassification"),XDr=o(" (MPNet model)"),zDr=l(),Z3=a("li"),b5e=a("strong"),WDr=o("rembert"),QDr=o(" \u2014 "),Nee=a("a"),HDr=o("TFRemBertForTokenClassification"),UDr=o(" (RemBERT model)"),JDr=l(),e5=a("li"),v5e=a("strong"),YDr=o("roberta"),KDr=o(" \u2014 "),qee=a("a"),ZDr=o("TFRobertaForTokenClassification"),eGr=o(" (RoBERTa model)"),oGr=l(),o5=a("li"),F5e=a("strong"),rGr=o("roformer"),tGr=o(" \u2014 "),jee=a("a"),aGr=o("TFRoFormerForTokenClassification"),nGr=o(" (RoFormer model)"),sGr=l(),r5=a("li"),T5e=a("strong"),lGr=o("xlm"),iGr=o(" \u2014 "),Dee=a("a"),dGr=o("TFXLMForTokenClassification"),cGr=o(" (XLM model)"),fGr=l(),t5=a("li"),M5e=a("strong"),mGr=o("xlm-roberta"),gGr=o(" \u2014 "),Gee=a("a"),hGr=o("TFXLMRobertaForTokenClassification"),pGr=o(" (XLM-RoBERTa model)"),_Gr=l(),a5=a("li"),E5e=a("strong"),uGr=o("xlnet"),bGr=o(" \u2014 "),Oee=a("a"),vGr=o("TFXLNetForTokenClassification"),FGr=o(" (XLNet model)"),TGr=l(),F(n5.$$.fragment),_He=l(),Jc=a("h2"),s5=a("a"),C5e=a("span"),F(D$.$$.fragment),MGr=l(),w5e=a("span"),EGr=o("TFAutoModelForQuestionAnswering"),uHe=l(),pr=a("div"),F(G$.$$.fragment),CGr=l(),Yc=a("p"),wGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Vee=a("a"),AGr=o("from_pretrained()"),LGr=o(" class method or the "),Xee=a("a"),yGr=o("from_config()"),xGr=o(` class
method.`),$Gr=l(),O$=a("p"),kGr=o("This class cannot be instantiated directly using "),A5e=a("code"),SGr=o("__init__()"),RGr=o(" (throws an error)."),PGr=l(),Qt=a("div"),F(V$.$$.fragment),BGr=l(),L5e=a("p"),IGr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),NGr=l(),Kc=a("p"),qGr=o(`Note:
Loading a model from its configuration file does `),y5e=a("strong"),jGr=o("not"),DGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=a("a"),GGr=o("from_pretrained()"),OGr=o(" to load the model weights."),VGr=l(),F(l5.$$.fragment),XGr=l(),Vr=a("div"),F(X$.$$.fragment),zGr=l(),x5e=a("p"),WGr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),QGr=l(),Cn=a("p"),HGr=o("The model class to instantiate is selected based on the "),$5e=a("code"),UGr=o("model_type"),JGr=o(` property of the config object (either
passed as an argument or loaded from `),k5e=a("code"),YGr=o("pretrained_model_name_or_path"),KGr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S5e=a("code"),ZGr=o("pretrained_model_name_or_path"),eOr=o(":"),oOr=l(),ce=a("ul"),i5=a("li"),R5e=a("strong"),rOr=o("albert"),tOr=o(" \u2014 "),Wee=a("a"),aOr=o("TFAlbertForQuestionAnswering"),nOr=o(" (ALBERT model)"),sOr=l(),d5=a("li"),P5e=a("strong"),lOr=o("bert"),iOr=o(" \u2014 "),Qee=a("a"),dOr=o("TFBertForQuestionAnswering"),cOr=o(" (BERT model)"),fOr=l(),c5=a("li"),B5e=a("strong"),mOr=o("camembert"),gOr=o(" \u2014 "),Hee=a("a"),hOr=o("TFCamembertForQuestionAnswering"),pOr=o(" (CamemBERT model)"),_Or=l(),f5=a("li"),I5e=a("strong"),uOr=o("convbert"),bOr=o(" \u2014 "),Uee=a("a"),vOr=o("TFConvBertForQuestionAnswering"),FOr=o(" (ConvBERT model)"),TOr=l(),m5=a("li"),N5e=a("strong"),MOr=o("deberta"),EOr=o(" \u2014 "),Jee=a("a"),COr=o("TFDebertaForQuestionAnswering"),wOr=o(" (DeBERTa model)"),AOr=l(),g5=a("li"),q5e=a("strong"),LOr=o("deberta-v2"),yOr=o(" \u2014 "),Yee=a("a"),xOr=o("TFDebertaV2ForQuestionAnswering"),$Or=o(" (DeBERTa-v2 model)"),kOr=l(),h5=a("li"),j5e=a("strong"),SOr=o("distilbert"),ROr=o(" \u2014 "),Kee=a("a"),POr=o("TFDistilBertForQuestionAnswering"),BOr=o(" (DistilBERT model)"),IOr=l(),p5=a("li"),D5e=a("strong"),NOr=o("electra"),qOr=o(" \u2014 "),Zee=a("a"),jOr=o("TFElectraForQuestionAnswering"),DOr=o(" (ELECTRA model)"),GOr=l(),_5=a("li"),G5e=a("strong"),OOr=o("flaubert"),VOr=o(" \u2014 "),eoe=a("a"),XOr=o("TFFlaubertForQuestionAnsweringSimple"),zOr=o(" (FlauBERT model)"),WOr=l(),u5=a("li"),O5e=a("strong"),QOr=o("funnel"),HOr=o(" \u2014 "),ooe=a("a"),UOr=o("TFFunnelForQuestionAnswering"),JOr=o(" (Funnel Transformer model)"),YOr=l(),b5=a("li"),V5e=a("strong"),KOr=o("gptj"),ZOr=o(" \u2014 "),roe=a("a"),eVr=o("TFGPTJForQuestionAnswering"),oVr=o(" (GPT-J model)"),rVr=l(),v5=a("li"),X5e=a("strong"),tVr=o("longformer"),aVr=o(" \u2014 "),toe=a("a"),nVr=o("TFLongformerForQuestionAnswering"),sVr=o(" (Longformer model)"),lVr=l(),F5=a("li"),z5e=a("strong"),iVr=o("mobilebert"),dVr=o(" \u2014 "),aoe=a("a"),cVr=o("TFMobileBertForQuestionAnswering"),fVr=o(" (MobileBERT model)"),mVr=l(),T5=a("li"),W5e=a("strong"),gVr=o("mpnet"),hVr=o(" \u2014 "),noe=a("a"),pVr=o("TFMPNetForQuestionAnswering"),_Vr=o(" (MPNet model)"),uVr=l(),M5=a("li"),Q5e=a("strong"),bVr=o("rembert"),vVr=o(" \u2014 "),soe=a("a"),FVr=o("TFRemBertForQuestionAnswering"),TVr=o(" (RemBERT model)"),MVr=l(),E5=a("li"),H5e=a("strong"),EVr=o("roberta"),CVr=o(" \u2014 "),loe=a("a"),wVr=o("TFRobertaForQuestionAnswering"),AVr=o(" (RoBERTa model)"),LVr=l(),C5=a("li"),U5e=a("strong"),yVr=o("roformer"),xVr=o(" \u2014 "),ioe=a("a"),$Vr=o("TFRoFormerForQuestionAnswering"),kVr=o(" (RoFormer model)"),SVr=l(),w5=a("li"),J5e=a("strong"),RVr=o("xlm"),PVr=o(" \u2014 "),doe=a("a"),BVr=o("TFXLMForQuestionAnsweringSimple"),IVr=o(" (XLM model)"),NVr=l(),A5=a("li"),Y5e=a("strong"),qVr=o("xlm-roberta"),jVr=o(" \u2014 "),coe=a("a"),DVr=o("TFXLMRobertaForQuestionAnswering"),GVr=o(" (XLM-RoBERTa model)"),OVr=l(),L5=a("li"),K5e=a("strong"),VVr=o("xlnet"),XVr=o(" \u2014 "),foe=a("a"),zVr=o("TFXLNetForQuestionAnsweringSimple"),WVr=o(" (XLNet model)"),QVr=l(),F(y5.$$.fragment),bHe=l(),Zc=a("h2"),x5=a("a"),Z5e=a("span"),F(z$.$$.fragment),HVr=l(),e0e=a("span"),UVr=o("TFAutoModelForVision2Seq"),vHe=l(),_r=a("div"),F(W$.$$.fragment),JVr=l(),ef=a("p"),YVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),moe=a("a"),KVr=o("from_pretrained()"),ZVr=o(" class method or the "),goe=a("a"),eXr=o("from_config()"),oXr=o(` class
method.`),rXr=l(),Q$=a("p"),tXr=o("This class cannot be instantiated directly using "),o0e=a("code"),aXr=o("__init__()"),nXr=o(" (throws an error)."),sXr=l(),Ht=a("div"),F(H$.$$.fragment),lXr=l(),r0e=a("p"),iXr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dXr=l(),of=a("p"),cXr=o(`Note:
Loading a model from its configuration file does `),t0e=a("strong"),fXr=o("not"),mXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hoe=a("a"),gXr=o("from_pretrained()"),hXr=o(" to load the model weights."),pXr=l(),F($5.$$.fragment),_Xr=l(),Xr=a("div"),F(U$.$$.fragment),uXr=l(),a0e=a("p"),bXr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),vXr=l(),wn=a("p"),FXr=o("The model class to instantiate is selected based on the "),n0e=a("code"),TXr=o("model_type"),MXr=o(` property of the config object (either
passed as an argument or loaded from `),s0e=a("code"),EXr=o("pretrained_model_name_or_path"),CXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l0e=a("code"),wXr=o("pretrained_model_name_or_path"),AXr=o(":"),LXr=l(),i0e=a("ul"),k5=a("li"),d0e=a("strong"),yXr=o("vision-encoder-decoder"),xXr=o(" \u2014 "),poe=a("a"),$Xr=o("TFVisionEncoderDecoderModel"),kXr=o(" (Vision Encoder decoder model)"),SXr=l(),F(S5.$$.fragment),FHe=l(),rf=a("h2"),R5=a("a"),c0e=a("span"),F(J$.$$.fragment),RXr=l(),f0e=a("span"),PXr=o("TFAutoModelForSpeechSeq2Seq"),THe=l(),ur=a("div"),F(Y$.$$.fragment),BXr=l(),tf=a("p"),IXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),_oe=a("a"),NXr=o("from_pretrained()"),qXr=o(" class method or the "),uoe=a("a"),jXr=o("from_config()"),DXr=o(` class
method.`),GXr=l(),K$=a("p"),OXr=o("This class cannot be instantiated directly using "),m0e=a("code"),VXr=o("__init__()"),XXr=o(" (throws an error)."),zXr=l(),Ut=a("div"),F(Z$.$$.fragment),WXr=l(),g0e=a("p"),QXr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),HXr=l(),af=a("p"),UXr=o(`Note:
Loading a model from its configuration file does `),h0e=a("strong"),JXr=o("not"),YXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=a("a"),KXr=o("from_pretrained()"),ZXr=o(" to load the model weights."),ezr=l(),F(P5.$$.fragment),ozr=l(),zr=a("div"),F(ek.$$.fragment),rzr=l(),p0e=a("p"),tzr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),azr=l(),An=a("p"),nzr=o("The model class to instantiate is selected based on the "),_0e=a("code"),szr=o("model_type"),lzr=o(` property of the config object (either
passed as an argument or loaded from `),u0e=a("code"),izr=o("pretrained_model_name_or_path"),dzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b0e=a("code"),czr=o("pretrained_model_name_or_path"),fzr=o(":"),mzr=l(),v0e=a("ul"),B5=a("li"),F0e=a("strong"),gzr=o("speech_to_text"),hzr=o(" \u2014 "),voe=a("a"),pzr=o("TFSpeech2TextForConditionalGeneration"),_zr=o(" (Speech2Text model)"),uzr=l(),F(I5.$$.fragment),MHe=l(),nf=a("h2"),N5=a("a"),T0e=a("span"),F(ok.$$.fragment),bzr=l(),M0e=a("span"),vzr=o("FlaxAutoModel"),EHe=l(),br=a("div"),F(rk.$$.fragment),Fzr=l(),sf=a("p"),Tzr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Foe=a("a"),Mzr=o("from_pretrained()"),Ezr=o(" class method or the "),Toe=a("a"),Czr=o("from_config()"),wzr=o(` class
method.`),Azr=l(),tk=a("p"),Lzr=o("This class cannot be instantiated directly using "),E0e=a("code"),yzr=o("__init__()"),xzr=o(" (throws an error)."),$zr=l(),Jt=a("div"),F(ak.$$.fragment),kzr=l(),C0e=a("p"),Szr=o("Instantiates one of the base model classes of the library from a configuration."),Rzr=l(),lf=a("p"),Pzr=o(`Note:
Loading a model from its configuration file does `),w0e=a("strong"),Bzr=o("not"),Izr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Moe=a("a"),Nzr=o("from_pretrained()"),qzr=o(" to load the model weights."),jzr=l(),F(q5.$$.fragment),Dzr=l(),Wr=a("div"),F(nk.$$.fragment),Gzr=l(),A0e=a("p"),Ozr=o("Instantiate one of the base model classes of the library from a pretrained model."),Vzr=l(),Ln=a("p"),Xzr=o("The model class to instantiate is selected based on the "),L0e=a("code"),zzr=o("model_type"),Wzr=o(` property of the config object (either
passed as an argument or loaded from `),y0e=a("code"),Qzr=o("pretrained_model_name_or_path"),Hzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x0e=a("code"),Uzr=o("pretrained_model_name_or_path"),Jzr=o(":"),Yzr=l(),oe=a("ul"),j5=a("li"),$0e=a("strong"),Kzr=o("albert"),Zzr=o(" \u2014 "),Eoe=a("a"),eWr=o("FlaxAlbertModel"),oWr=o(" (ALBERT model)"),rWr=l(),D5=a("li"),k0e=a("strong"),tWr=o("bart"),aWr=o(" \u2014 "),Coe=a("a"),nWr=o("FlaxBartModel"),sWr=o(" (BART model)"),lWr=l(),G5=a("li"),S0e=a("strong"),iWr=o("beit"),dWr=o(" \u2014 "),woe=a("a"),cWr=o("FlaxBeitModel"),fWr=o(" (BEiT model)"),mWr=l(),O5=a("li"),R0e=a("strong"),gWr=o("bert"),hWr=o(" \u2014 "),Aoe=a("a"),pWr=o("FlaxBertModel"),_Wr=o(" (BERT model)"),uWr=l(),V5=a("li"),P0e=a("strong"),bWr=o("big_bird"),vWr=o(" \u2014 "),Loe=a("a"),FWr=o("FlaxBigBirdModel"),TWr=o(" (BigBird model)"),MWr=l(),X5=a("li"),B0e=a("strong"),EWr=o("blenderbot"),CWr=o(" \u2014 "),yoe=a("a"),wWr=o("FlaxBlenderbotModel"),AWr=o(" (Blenderbot model)"),LWr=l(),z5=a("li"),I0e=a("strong"),yWr=o("blenderbot-small"),xWr=o(" \u2014 "),xoe=a("a"),$Wr=o("FlaxBlenderbotSmallModel"),kWr=o(" (BlenderbotSmall model)"),SWr=l(),W5=a("li"),N0e=a("strong"),RWr=o("clip"),PWr=o(" \u2014 "),$oe=a("a"),BWr=o("FlaxCLIPModel"),IWr=o(" (CLIP model)"),NWr=l(),Q5=a("li"),q0e=a("strong"),qWr=o("distilbert"),jWr=o(" \u2014 "),koe=a("a"),DWr=o("FlaxDistilBertModel"),GWr=o(" (DistilBERT model)"),OWr=l(),H5=a("li"),j0e=a("strong"),VWr=o("dpt"),XWr=o(" \u2014 "),Soe=a("a"),zWr=o("FlaxDPTModel"),WWr=o(" (DPT model)"),QWr=l(),U5=a("li"),D0e=a("strong"),HWr=o("electra"),UWr=o(" \u2014 "),Roe=a("a"),JWr=o("FlaxElectraModel"),YWr=o(" (ELECTRA model)"),KWr=l(),J5=a("li"),G0e=a("strong"),ZWr=o("gpt2"),eQr=o(" \u2014 "),Poe=a("a"),oQr=o("FlaxGPT2Model"),rQr=o(" (OpenAI GPT-2 model)"),tQr=l(),Y5=a("li"),O0e=a("strong"),aQr=o("gpt_neo"),nQr=o(" \u2014 "),Boe=a("a"),sQr=o("FlaxGPTNeoModel"),lQr=o(" (GPT Neo model)"),iQr=l(),K5=a("li"),V0e=a("strong"),dQr=o("gptj"),cQr=o(" \u2014 "),Ioe=a("a"),fQr=o("FlaxGPTJModel"),mQr=o(" (GPT-J model)"),gQr=l(),Z5=a("li"),X0e=a("strong"),hQr=o("longt5"),pQr=o(" \u2014 "),Noe=a("a"),_Qr=o("FlaxLongT5Model"),uQr=o(" (LongT5 model)"),bQr=l(),e0=a("li"),z0e=a("strong"),vQr=o("marian"),FQr=o(" \u2014 "),qoe=a("a"),TQr=o("FlaxMarianModel"),MQr=o(" (Marian model)"),EQr=l(),o0=a("li"),W0e=a("strong"),CQr=o("mbart"),wQr=o(" \u2014 "),joe=a("a"),AQr=o("FlaxMBartModel"),LQr=o(" (mBART model)"),yQr=l(),r0=a("li"),Q0e=a("strong"),xQr=o("mt5"),$Qr=o(" \u2014 "),Doe=a("a"),kQr=o("FlaxMT5Model"),SQr=o(" (MT5 model)"),RQr=l(),t0=a("li"),H0e=a("strong"),PQr=o("opt"),BQr=o(" \u2014 "),Goe=a("a"),IQr=o("FlaxOPTModel"),NQr=o(" (OPT model)"),qQr=l(),a0=a("li"),U0e=a("strong"),jQr=o("pegasus"),DQr=o(" \u2014 "),Ooe=a("a"),GQr=o("FlaxPegasusModel"),OQr=o(" (Pegasus model)"),VQr=l(),n0=a("li"),J0e=a("strong"),XQr=o("roberta"),zQr=o(" \u2014 "),Voe=a("a"),WQr=o("FlaxRobertaModel"),QQr=o(" (RoBERTa model)"),HQr=l(),s0=a("li"),Y0e=a("strong"),UQr=o("roformer"),JQr=o(" \u2014 "),Xoe=a("a"),YQr=o("FlaxRoFormerModel"),KQr=o(" (RoFormer model)"),ZQr=l(),l0=a("li"),K0e=a("strong"),eHr=o("t5"),oHr=o(" \u2014 "),zoe=a("a"),rHr=o("FlaxT5Model"),tHr=o(" (T5 model)"),aHr=l(),i0=a("li"),Z0e=a("strong"),nHr=o("vision-text-dual-encoder"),sHr=o(" \u2014 "),Woe=a("a"),lHr=o("FlaxVisionTextDualEncoderModel"),iHr=o(" (VisionTextDualEncoder model)"),dHr=l(),d0=a("li"),ewe=a("strong"),cHr=o("vit"),fHr=o(" \u2014 "),Qoe=a("a"),mHr=o("FlaxViTModel"),gHr=o(" (ViT model)"),hHr=l(),c0=a("li"),owe=a("strong"),pHr=o("wav2vec2"),_Hr=o(" \u2014 "),Hoe=a("a"),uHr=o("FlaxWav2Vec2Model"),bHr=o(" (Wav2Vec2 model)"),vHr=l(),f0=a("li"),rwe=a("strong"),FHr=o("xglm"),THr=o(" \u2014 "),Uoe=a("a"),MHr=o("FlaxXGLMModel"),EHr=o(" (XGLM model)"),CHr=l(),m0=a("li"),twe=a("strong"),wHr=o("xlm-roberta"),AHr=o(" \u2014 "),Joe=a("a"),LHr=o("FlaxXLMRobertaModel"),yHr=o(" (XLM-RoBERTa model)"),xHr=l(),F(g0.$$.fragment),CHe=l(),df=a("h2"),h0=a("a"),awe=a("span"),F(sk.$$.fragment),$Hr=l(),nwe=a("span"),kHr=o("FlaxAutoModelForCausalLM"),wHe=l(),vr=a("div"),F(lk.$$.fragment),SHr=l(),cf=a("p"),RHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yoe=a("a"),PHr=o("from_pretrained()"),BHr=o(" class method or the "),Koe=a("a"),IHr=o("from_config()"),NHr=o(` class
method.`),qHr=l(),ik=a("p"),jHr=o("This class cannot be instantiated directly using "),swe=a("code"),DHr=o("__init__()"),GHr=o(" (throws an error)."),OHr=l(),Yt=a("div"),F(dk.$$.fragment),VHr=l(),lwe=a("p"),XHr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),zHr=l(),ff=a("p"),WHr=o(`Note:
Loading a model from its configuration file does `),iwe=a("strong"),QHr=o("not"),HHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=a("a"),UHr=o("from_pretrained()"),JHr=o(" to load the model weights."),YHr=l(),F(p0.$$.fragment),KHr=l(),Qr=a("div"),F(ck.$$.fragment),ZHr=l(),dwe=a("p"),eUr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),oUr=l(),yn=a("p"),rUr=o("The model class to instantiate is selected based on the "),cwe=a("code"),tUr=o("model_type"),aUr=o(` property of the config object (either
passed as an argument or loaded from `),fwe=a("code"),nUr=o("pretrained_model_name_or_path"),sUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mwe=a("code"),lUr=o("pretrained_model_name_or_path"),iUr=o(":"),dUr=l(),xe=a("ul"),_0=a("li"),gwe=a("strong"),cUr=o("bart"),fUr=o(" \u2014 "),ere=a("a"),mUr=o("FlaxBartForCausalLM"),gUr=o(" (BART model)"),hUr=l(),u0=a("li"),hwe=a("strong"),pUr=o("bert"),_Ur=o(" \u2014 "),ore=a("a"),uUr=o("FlaxBertForCausalLM"),bUr=o(" (BERT model)"),vUr=l(),b0=a("li"),pwe=a("strong"),FUr=o("big_bird"),TUr=o(" \u2014 "),rre=a("a"),MUr=o("FlaxBigBirdForCausalLM"),EUr=o(" (BigBird model)"),CUr=l(),v0=a("li"),_we=a("strong"),wUr=o("electra"),AUr=o(" \u2014 "),tre=a("a"),LUr=o("FlaxElectraForCausalLM"),yUr=o(" (ELECTRA model)"),xUr=l(),F0=a("li"),uwe=a("strong"),$Ur=o("gpt2"),kUr=o(" \u2014 "),are=a("a"),SUr=o("FlaxGPT2LMHeadModel"),RUr=o(" (OpenAI GPT-2 model)"),PUr=l(),T0=a("li"),bwe=a("strong"),BUr=o("gpt_neo"),IUr=o(" \u2014 "),nre=a("a"),NUr=o("FlaxGPTNeoForCausalLM"),qUr=o(" (GPT Neo model)"),jUr=l(),M0=a("li"),vwe=a("strong"),DUr=o("gptj"),GUr=o(" \u2014 "),sre=a("a"),OUr=o("FlaxGPTJForCausalLM"),VUr=o(" (GPT-J model)"),XUr=l(),E0=a("li"),Fwe=a("strong"),zUr=o("opt"),WUr=o(" \u2014 "),lre=a("a"),QUr=o("FlaxOPTForCausalLM"),HUr=o(" (OPT model)"),UUr=l(),C0=a("li"),Twe=a("strong"),JUr=o("roberta"),YUr=o(" \u2014 "),ire=a("a"),KUr=o("FlaxRobertaForCausalLM"),ZUr=o(" (RoBERTa model)"),eJr=l(),w0=a("li"),Mwe=a("strong"),oJr=o("xglm"),rJr=o(" \u2014 "),dre=a("a"),tJr=o("FlaxXGLMForCausalLM"),aJr=o(" (XGLM model)"),nJr=l(),F(A0.$$.fragment),AHe=l(),mf=a("h2"),L0=a("a"),Ewe=a("span"),F(fk.$$.fragment),sJr=l(),Cwe=a("span"),lJr=o("FlaxAutoModelForPreTraining"),LHe=l(),Fr=a("div"),F(mk.$$.fragment),iJr=l(),gf=a("p"),dJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),cre=a("a"),cJr=o("from_pretrained()"),fJr=o(" class method or the "),fre=a("a"),mJr=o("from_config()"),gJr=o(` class
method.`),hJr=l(),gk=a("p"),pJr=o("This class cannot be instantiated directly using "),wwe=a("code"),_Jr=o("__init__()"),uJr=o(" (throws an error)."),bJr=l(),Kt=a("div"),F(hk.$$.fragment),vJr=l(),Awe=a("p"),FJr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),TJr=l(),hf=a("p"),MJr=o(`Note:
Loading a model from its configuration file does `),Lwe=a("strong"),EJr=o("not"),CJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mre=a("a"),wJr=o("from_pretrained()"),AJr=o(" to load the model weights."),LJr=l(),F(y0.$$.fragment),yJr=l(),Hr=a("div"),F(pk.$$.fragment),xJr=l(),ywe=a("p"),$Jr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),kJr=l(),xn=a("p"),SJr=o("The model class to instantiate is selected based on the "),xwe=a("code"),RJr=o("model_type"),PJr=o(` property of the config object (either
passed as an argument or loaded from `),$we=a("code"),BJr=o("pretrained_model_name_or_path"),IJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=a("code"),NJr=o("pretrained_model_name_or_path"),qJr=o(":"),jJr=l(),Ee=a("ul"),x0=a("li"),Swe=a("strong"),DJr=o("albert"),GJr=o(" \u2014 "),gre=a("a"),OJr=o("FlaxAlbertForPreTraining"),VJr=o(" (ALBERT model)"),XJr=l(),$0=a("li"),Rwe=a("strong"),zJr=o("bart"),WJr=o(" \u2014 "),hre=a("a"),QJr=o("FlaxBartForConditionalGeneration"),HJr=o(" (BART model)"),UJr=l(),k0=a("li"),Pwe=a("strong"),JJr=o("bert"),YJr=o(" \u2014 "),pre=a("a"),KJr=o("FlaxBertForPreTraining"),ZJr=o(" (BERT model)"),eYr=l(),S0=a("li"),Bwe=a("strong"),oYr=o("big_bird"),rYr=o(" \u2014 "),_re=a("a"),tYr=o("FlaxBigBirdForPreTraining"),aYr=o(" (BigBird model)"),nYr=l(),R0=a("li"),Iwe=a("strong"),sYr=o("electra"),lYr=o(" \u2014 "),ure=a("a"),iYr=o("FlaxElectraForPreTraining"),dYr=o(" (ELECTRA model)"),cYr=l(),P0=a("li"),Nwe=a("strong"),fYr=o("longt5"),mYr=o(" \u2014 "),bre=a("a"),gYr=o("FlaxLongT5ForConditionalGeneration"),hYr=o(" (LongT5 model)"),pYr=l(),B0=a("li"),qwe=a("strong"),_Yr=o("mbart"),uYr=o(" \u2014 "),vre=a("a"),bYr=o("FlaxMBartForConditionalGeneration"),vYr=o(" (mBART model)"),FYr=l(),I0=a("li"),jwe=a("strong"),TYr=o("mt5"),MYr=o(" \u2014 "),Fre=a("a"),EYr=o("FlaxMT5ForConditionalGeneration"),CYr=o(" (MT5 model)"),wYr=l(),N0=a("li"),Dwe=a("strong"),AYr=o("roberta"),LYr=o(" \u2014 "),Tre=a("a"),yYr=o("FlaxRobertaForMaskedLM"),xYr=o(" (RoBERTa model)"),$Yr=l(),q0=a("li"),Gwe=a("strong"),kYr=o("roformer"),SYr=o(" \u2014 "),Mre=a("a"),RYr=o("FlaxRoFormerForMaskedLM"),PYr=o(" (RoFormer model)"),BYr=l(),j0=a("li"),Owe=a("strong"),IYr=o("t5"),NYr=o(" \u2014 "),Ere=a("a"),qYr=o("FlaxT5ForConditionalGeneration"),jYr=o(" (T5 model)"),DYr=l(),D0=a("li"),Vwe=a("strong"),GYr=o("wav2vec2"),OYr=o(" \u2014 "),Cre=a("a"),VYr=o("FlaxWav2Vec2ForPreTraining"),XYr=o(" (Wav2Vec2 model)"),zYr=l(),G0=a("li"),Xwe=a("strong"),WYr=o("xlm-roberta"),QYr=o(" \u2014 "),wre=a("a"),HYr=o("FlaxXLMRobertaForMaskedLM"),UYr=o(" (XLM-RoBERTa model)"),JYr=l(),F(O0.$$.fragment),yHe=l(),pf=a("h2"),V0=a("a"),zwe=a("span"),F(_k.$$.fragment),YYr=l(),Wwe=a("span"),KYr=o("FlaxAutoModelForMaskedLM"),xHe=l(),Tr=a("div"),F(uk.$$.fragment),ZYr=l(),_f=a("p"),eKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Are=a("a"),oKr=o("from_pretrained()"),rKr=o(" class method or the "),Lre=a("a"),tKr=o("from_config()"),aKr=o(` class
method.`),nKr=l(),bk=a("p"),sKr=o("This class cannot be instantiated directly using "),Qwe=a("code"),lKr=o("__init__()"),iKr=o(" (throws an error)."),dKr=l(),Zt=a("div"),F(vk.$$.fragment),cKr=l(),Hwe=a("p"),fKr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),mKr=l(),uf=a("p"),gKr=o(`Note:
Loading a model from its configuration file does `),Uwe=a("strong"),hKr=o("not"),pKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yre=a("a"),_Kr=o("from_pretrained()"),uKr=o(" to load the model weights."),bKr=l(),F(X0.$$.fragment),vKr=l(),Ur=a("div"),F(Fk.$$.fragment),FKr=l(),Jwe=a("p"),TKr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),MKr=l(),$n=a("p"),EKr=o("The model class to instantiate is selected based on the "),Ywe=a("code"),CKr=o("model_type"),wKr=o(` property of the config object (either
passed as an argument or loaded from `),Kwe=a("code"),AKr=o("pretrained_model_name_or_path"),LKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=a("code"),yKr=o("pretrained_model_name_or_path"),xKr=o(":"),$Kr=l(),$e=a("ul"),z0=a("li"),e6e=a("strong"),kKr=o("albert"),SKr=o(" \u2014 "),xre=a("a"),RKr=o("FlaxAlbertForMaskedLM"),PKr=o(" (ALBERT model)"),BKr=l(),W0=a("li"),o6e=a("strong"),IKr=o("bart"),NKr=o(" \u2014 "),$re=a("a"),qKr=o("FlaxBartForConditionalGeneration"),jKr=o(" (BART model)"),DKr=l(),Q0=a("li"),r6e=a("strong"),GKr=o("bert"),OKr=o(" \u2014 "),kre=a("a"),VKr=o("FlaxBertForMaskedLM"),XKr=o(" (BERT model)"),zKr=l(),H0=a("li"),t6e=a("strong"),WKr=o("big_bird"),QKr=o(" \u2014 "),Sre=a("a"),HKr=o("FlaxBigBirdForMaskedLM"),UKr=o(" (BigBird model)"),JKr=l(),U0=a("li"),a6e=a("strong"),YKr=o("distilbert"),KKr=o(" \u2014 "),Rre=a("a"),ZKr=o("FlaxDistilBertForMaskedLM"),eZr=o(" (DistilBERT model)"),oZr=l(),J0=a("li"),n6e=a("strong"),rZr=o("electra"),tZr=o(" \u2014 "),Pre=a("a"),aZr=o("FlaxElectraForMaskedLM"),nZr=o(" (ELECTRA model)"),sZr=l(),Y0=a("li"),s6e=a("strong"),lZr=o("mbart"),iZr=o(" \u2014 "),Bre=a("a"),dZr=o("FlaxMBartForConditionalGeneration"),cZr=o(" (mBART model)"),fZr=l(),K0=a("li"),l6e=a("strong"),mZr=o("roberta"),gZr=o(" \u2014 "),Ire=a("a"),hZr=o("FlaxRobertaForMaskedLM"),pZr=o(" (RoBERTa model)"),_Zr=l(),Z0=a("li"),i6e=a("strong"),uZr=o("roformer"),bZr=o(" \u2014 "),Nre=a("a"),vZr=o("FlaxRoFormerForMaskedLM"),FZr=o(" (RoFormer model)"),TZr=l(),ew=a("li"),d6e=a("strong"),MZr=o("xlm-roberta"),EZr=o(" \u2014 "),qre=a("a"),CZr=o("FlaxXLMRobertaForMaskedLM"),wZr=o(" (XLM-RoBERTa model)"),AZr=l(),F(ow.$$.fragment),$He=l(),bf=a("h2"),rw=a("a"),c6e=a("span"),F(Tk.$$.fragment),LZr=l(),f6e=a("span"),yZr=o("FlaxAutoModelForSeq2SeqLM"),kHe=l(),Mr=a("div"),F(Mk.$$.fragment),xZr=l(),vf=a("p"),$Zr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),jre=a("a"),kZr=o("from_pretrained()"),SZr=o(" class method or the "),Dre=a("a"),RZr=o("from_config()"),PZr=o(` class
method.`),BZr=l(),Ek=a("p"),IZr=o("This class cannot be instantiated directly using "),m6e=a("code"),NZr=o("__init__()"),qZr=o(" (throws an error)."),jZr=l(),ea=a("div"),F(Ck.$$.fragment),DZr=l(),g6e=a("p"),GZr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),OZr=l(),Ff=a("p"),VZr=o(`Note:
Loading a model from its configuration file does `),h6e=a("strong"),XZr=o("not"),zZr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Gre=a("a"),WZr=o("from_pretrained()"),QZr=o(" to load the model weights."),HZr=l(),F(tw.$$.fragment),UZr=l(),Jr=a("div"),F(wk.$$.fragment),JZr=l(),p6e=a("p"),YZr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),KZr=l(),kn=a("p"),ZZr=o("The model class to instantiate is selected based on the "),_6e=a("code"),eet=o("model_type"),oet=o(` property of the config object (either
passed as an argument or loaded from `),u6e=a("code"),ret=o("pretrained_model_name_or_path"),tet=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b6e=a("code"),aet=o("pretrained_model_name_or_path"),net=o(":"),set=l(),ke=a("ul"),aw=a("li"),v6e=a("strong"),iet=o("bart"),det=o(" \u2014 "),Ore=a("a"),cet=o("FlaxBartForConditionalGeneration"),fet=o(" (BART model)"),met=l(),nw=a("li"),F6e=a("strong"),get=o("blenderbot"),het=o(" \u2014 "),Vre=a("a"),pet=o("FlaxBlenderbotForConditionalGeneration"),_et=o(" (Blenderbot model)"),uet=l(),sw=a("li"),T6e=a("strong"),bet=o("blenderbot-small"),vet=o(" \u2014 "),Xre=a("a"),Fet=o("FlaxBlenderbotSmallForConditionalGeneration"),Tet=o(" (BlenderbotSmall model)"),Met=l(),lw=a("li"),M6e=a("strong"),Eet=o("encoder-decoder"),Cet=o(" \u2014 "),zre=a("a"),wet=o("FlaxEncoderDecoderModel"),Aet=o(" (Encoder decoder model)"),Let=l(),iw=a("li"),E6e=a("strong"),yet=o("longt5"),xet=o(" \u2014 "),Wre=a("a"),$et=o("FlaxLongT5ForConditionalGeneration"),ket=o(" (LongT5 model)"),Set=l(),dw=a("li"),C6e=a("strong"),Ret=o("marian"),Pet=o(" \u2014 "),Qre=a("a"),Bet=o("FlaxMarianMTModel"),Iet=o(" (Marian model)"),Net=l(),cw=a("li"),w6e=a("strong"),qet=o("mbart"),jet=o(" \u2014 "),Hre=a("a"),Det=o("FlaxMBartForConditionalGeneration"),Get=o(" (mBART model)"),Oet=l(),fw=a("li"),A6e=a("strong"),Vet=o("mt5"),Xet=o(" \u2014 "),Ure=a("a"),zet=o("FlaxMT5ForConditionalGeneration"),Wet=o(" (MT5 model)"),Qet=l(),mw=a("li"),L6e=a("strong"),Het=o("pegasus"),Uet=o(" \u2014 "),Jre=a("a"),Jet=o("FlaxPegasusForConditionalGeneration"),Yet=o(" (Pegasus model)"),Ket=l(),gw=a("li"),y6e=a("strong"),Zet=o("t5"),eot=o(" \u2014 "),Yre=a("a"),oot=o("FlaxT5ForConditionalGeneration"),rot=o(" (T5 model)"),tot=l(),F(hw.$$.fragment),SHe=l(),Tf=a("h2"),pw=a("a"),x6e=a("span"),F(Ak.$$.fragment),aot=l(),$6e=a("span"),not=o("FlaxAutoModelForSequenceClassification"),RHe=l(),Er=a("div"),F(Lk.$$.fragment),sot=l(),Mf=a("p"),lot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Kre=a("a"),iot=o("from_pretrained()"),dot=o(" class method or the "),Zre=a("a"),cot=o("from_config()"),fot=o(` class
method.`),mot=l(),yk=a("p"),got=o("This class cannot be instantiated directly using "),k6e=a("code"),hot=o("__init__()"),pot=o(" (throws an error)."),_ot=l(),oa=a("div"),F(xk.$$.fragment),uot=l(),S6e=a("p"),bot=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),vot=l(),Ef=a("p"),Fot=o(`Note:
Loading a model from its configuration file does `),R6e=a("strong"),Tot=o("not"),Mot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=a("a"),Eot=o("from_pretrained()"),Cot=o(" to load the model weights."),wot=l(),F(_w.$$.fragment),Aot=l(),Yr=a("div"),F($k.$$.fragment),Lot=l(),P6e=a("p"),yot=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),xot=l(),Sn=a("p"),$ot=o("The model class to instantiate is selected based on the "),B6e=a("code"),kot=o("model_type"),Sot=o(` property of the config object (either
passed as an argument or loaded from `),I6e=a("code"),Rot=o("pretrained_model_name_or_path"),Pot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N6e=a("code"),Bot=o("pretrained_model_name_or_path"),Iot=o(":"),Not=l(),Se=a("ul"),uw=a("li"),q6e=a("strong"),qot=o("albert"),jot=o(" \u2014 "),ote=a("a"),Dot=o("FlaxAlbertForSequenceClassification"),Got=o(" (ALBERT model)"),Oot=l(),bw=a("li"),j6e=a("strong"),Vot=o("bart"),Xot=o(" \u2014 "),rte=a("a"),zot=o("FlaxBartForSequenceClassification"),Wot=o(" (BART model)"),Qot=l(),vw=a("li"),D6e=a("strong"),Hot=o("bert"),Uot=o(" \u2014 "),tte=a("a"),Jot=o("FlaxBertForSequenceClassification"),Yot=o(" (BERT model)"),Kot=l(),Fw=a("li"),G6e=a("strong"),Zot=o("big_bird"),ert=o(" \u2014 "),ate=a("a"),ort=o("FlaxBigBirdForSequenceClassification"),rrt=o(" (BigBird model)"),trt=l(),Tw=a("li"),O6e=a("strong"),art=o("distilbert"),nrt=o(" \u2014 "),nte=a("a"),srt=o("FlaxDistilBertForSequenceClassification"),lrt=o(" (DistilBERT model)"),irt=l(),Mw=a("li"),V6e=a("strong"),drt=o("electra"),crt=o(" \u2014 "),ste=a("a"),frt=o("FlaxElectraForSequenceClassification"),mrt=o(" (ELECTRA model)"),grt=l(),Ew=a("li"),X6e=a("strong"),hrt=o("mbart"),prt=o(" \u2014 "),lte=a("a"),_rt=o("FlaxMBartForSequenceClassification"),urt=o(" (mBART model)"),brt=l(),Cw=a("li"),z6e=a("strong"),vrt=o("roberta"),Frt=o(" \u2014 "),ite=a("a"),Trt=o("FlaxRobertaForSequenceClassification"),Mrt=o(" (RoBERTa model)"),Ert=l(),ww=a("li"),W6e=a("strong"),Crt=o("roformer"),wrt=o(" \u2014 "),dte=a("a"),Art=o("FlaxRoFormerForSequenceClassification"),Lrt=o(" (RoFormer model)"),yrt=l(),Aw=a("li"),Q6e=a("strong"),xrt=o("xlm-roberta"),$rt=o(" \u2014 "),cte=a("a"),krt=o("FlaxXLMRobertaForSequenceClassification"),Srt=o(" (XLM-RoBERTa model)"),Rrt=l(),F(Lw.$$.fragment),PHe=l(),Cf=a("h2"),yw=a("a"),H6e=a("span"),F(kk.$$.fragment),Prt=l(),U6e=a("span"),Brt=o("FlaxAutoModelForQuestionAnswering"),BHe=l(),Cr=a("div"),F(Sk.$$.fragment),Irt=l(),wf=a("p"),Nrt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),fte=a("a"),qrt=o("from_pretrained()"),jrt=o(" class method or the "),mte=a("a"),Drt=o("from_config()"),Grt=o(` class
method.`),Ort=l(),Rk=a("p"),Vrt=o("This class cannot be instantiated directly using "),J6e=a("code"),Xrt=o("__init__()"),zrt=o(" (throws an error)."),Wrt=l(),ra=a("div"),F(Pk.$$.fragment),Qrt=l(),Y6e=a("p"),Hrt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Urt=l(),Af=a("p"),Jrt=o(`Note:
Loading a model from its configuration file does `),K6e=a("strong"),Yrt=o("not"),Krt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gte=a("a"),Zrt=o("from_pretrained()"),ett=o(" to load the model weights."),ott=l(),F(xw.$$.fragment),rtt=l(),Kr=a("div"),F(Bk.$$.fragment),ttt=l(),Z6e=a("p"),att=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),ntt=l(),Rn=a("p"),stt=o("The model class to instantiate is selected based on the "),eAe=a("code"),ltt=o("model_type"),itt=o(` property of the config object (either
passed as an argument or loaded from `),oAe=a("code"),dtt=o("pretrained_model_name_or_path"),ctt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rAe=a("code"),ftt=o("pretrained_model_name_or_path"),mtt=o(":"),gtt=l(),Re=a("ul"),$w=a("li"),tAe=a("strong"),htt=o("albert"),ptt=o(" \u2014 "),hte=a("a"),_tt=o("FlaxAlbertForQuestionAnswering"),utt=o(" (ALBERT model)"),btt=l(),kw=a("li"),aAe=a("strong"),vtt=o("bart"),Ftt=o(" \u2014 "),pte=a("a"),Ttt=o("FlaxBartForQuestionAnswering"),Mtt=o(" (BART model)"),Ett=l(),Sw=a("li"),nAe=a("strong"),Ctt=o("bert"),wtt=o(" \u2014 "),_te=a("a"),Att=o("FlaxBertForQuestionAnswering"),Ltt=o(" (BERT model)"),ytt=l(),Rw=a("li"),sAe=a("strong"),xtt=o("big_bird"),$tt=o(" \u2014 "),ute=a("a"),ktt=o("FlaxBigBirdForQuestionAnswering"),Stt=o(" (BigBird model)"),Rtt=l(),Pw=a("li"),lAe=a("strong"),Ptt=o("distilbert"),Btt=o(" \u2014 "),bte=a("a"),Itt=o("FlaxDistilBertForQuestionAnswering"),Ntt=o(" (DistilBERT model)"),qtt=l(),Bw=a("li"),iAe=a("strong"),jtt=o("electra"),Dtt=o(" \u2014 "),vte=a("a"),Gtt=o("FlaxElectraForQuestionAnswering"),Ott=o(" (ELECTRA model)"),Vtt=l(),Iw=a("li"),dAe=a("strong"),Xtt=o("mbart"),ztt=o(" \u2014 "),Fte=a("a"),Wtt=o("FlaxMBartForQuestionAnswering"),Qtt=o(" (mBART model)"),Htt=l(),Nw=a("li"),cAe=a("strong"),Utt=o("roberta"),Jtt=o(" \u2014 "),Tte=a("a"),Ytt=o("FlaxRobertaForQuestionAnswering"),Ktt=o(" (RoBERTa model)"),Ztt=l(),qw=a("li"),fAe=a("strong"),eat=o("roformer"),oat=o(" \u2014 "),Mte=a("a"),rat=o("FlaxRoFormerForQuestionAnswering"),tat=o(" (RoFormer model)"),aat=l(),jw=a("li"),mAe=a("strong"),nat=o("xlm-roberta"),sat=o(" \u2014 "),Ete=a("a"),lat=o("FlaxXLMRobertaForQuestionAnswering"),iat=o(" (XLM-RoBERTa model)"),dat=l(),F(Dw.$$.fragment),IHe=l(),Lf=a("h2"),Gw=a("a"),gAe=a("span"),F(Ik.$$.fragment),cat=l(),hAe=a("span"),fat=o("FlaxAutoModelForTokenClassification"),NHe=l(),wr=a("div"),F(Nk.$$.fragment),mat=l(),yf=a("p"),gat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Cte=a("a"),hat=o("from_pretrained()"),pat=o(" class method or the "),wte=a("a"),_at=o("from_config()"),uat=o(` class
method.`),bat=l(),qk=a("p"),vat=o("This class cannot be instantiated directly using "),pAe=a("code"),Fat=o("__init__()"),Tat=o(" (throws an error)."),Mat=l(),ta=a("div"),F(jk.$$.fragment),Eat=l(),_Ae=a("p"),Cat=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),wat=l(),xf=a("p"),Aat=o(`Note:
Loading a model from its configuration file does `),uAe=a("strong"),Lat=o("not"),yat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Ate=a("a"),xat=o("from_pretrained()"),$at=o(" to load the model weights."),kat=l(),F(Ow.$$.fragment),Sat=l(),Zr=a("div"),F(Dk.$$.fragment),Rat=l(),bAe=a("p"),Pat=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Bat=l(),Pn=a("p"),Iat=o("The model class to instantiate is selected based on the "),vAe=a("code"),Nat=o("model_type"),qat=o(` property of the config object (either
passed as an argument or loaded from `),FAe=a("code"),jat=o("pretrained_model_name_or_path"),Dat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TAe=a("code"),Gat=o("pretrained_model_name_or_path"),Oat=o(":"),Vat=l(),Xe=a("ul"),Vw=a("li"),MAe=a("strong"),Xat=o("albert"),zat=o(" \u2014 "),Lte=a("a"),Wat=o("FlaxAlbertForTokenClassification"),Qat=o(" (ALBERT model)"),Hat=l(),Xw=a("li"),EAe=a("strong"),Uat=o("bert"),Jat=o(" \u2014 "),yte=a("a"),Yat=o("FlaxBertForTokenClassification"),Kat=o(" (BERT model)"),Zat=l(),zw=a("li"),CAe=a("strong"),ent=o("big_bird"),ont=o(" \u2014 "),xte=a("a"),rnt=o("FlaxBigBirdForTokenClassification"),tnt=o(" (BigBird model)"),ant=l(),Ww=a("li"),wAe=a("strong"),nnt=o("distilbert"),snt=o(" \u2014 "),$te=a("a"),lnt=o("FlaxDistilBertForTokenClassification"),int=o(" (DistilBERT model)"),dnt=l(),Qw=a("li"),AAe=a("strong"),cnt=o("electra"),fnt=o(" \u2014 "),kte=a("a"),mnt=o("FlaxElectraForTokenClassification"),gnt=o(" (ELECTRA model)"),hnt=l(),Hw=a("li"),LAe=a("strong"),pnt=o("roberta"),_nt=o(" \u2014 "),Ste=a("a"),unt=o("FlaxRobertaForTokenClassification"),bnt=o(" (RoBERTa model)"),vnt=l(),Uw=a("li"),yAe=a("strong"),Fnt=o("roformer"),Tnt=o(" \u2014 "),Rte=a("a"),Mnt=o("FlaxRoFormerForTokenClassification"),Ent=o(" (RoFormer model)"),Cnt=l(),Jw=a("li"),xAe=a("strong"),wnt=o("xlm-roberta"),Ant=o(" \u2014 "),Pte=a("a"),Lnt=o("FlaxXLMRobertaForTokenClassification"),ynt=o(" (XLM-RoBERTa model)"),xnt=l(),F(Yw.$$.fragment),qHe=l(),$f=a("h2"),Kw=a("a"),$Ae=a("span"),F(Gk.$$.fragment),$nt=l(),kAe=a("span"),knt=o("FlaxAutoModelForMultipleChoice"),jHe=l(),Ar=a("div"),F(Ok.$$.fragment),Snt=l(),kf=a("p"),Rnt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Bte=a("a"),Pnt=o("from_pretrained()"),Bnt=o(" class method or the "),Ite=a("a"),Int=o("from_config()"),Nnt=o(` class
method.`),qnt=l(),Vk=a("p"),jnt=o("This class cannot be instantiated directly using "),SAe=a("code"),Dnt=o("__init__()"),Gnt=o(" (throws an error)."),Ont=l(),aa=a("div"),F(Xk.$$.fragment),Vnt=l(),RAe=a("p"),Xnt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),znt=l(),Sf=a("p"),Wnt=o(`Note:
Loading a model from its configuration file does `),PAe=a("strong"),Qnt=o("not"),Hnt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Nte=a("a"),Unt=o("from_pretrained()"),Jnt=o(" to load the model weights."),Ynt=l(),F(Zw.$$.fragment),Knt=l(),et=a("div"),F(zk.$$.fragment),Znt=l(),BAe=a("p"),est=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ost=l(),Bn=a("p"),rst=o("The model class to instantiate is selected based on the "),IAe=a("code"),tst=o("model_type"),ast=o(` property of the config object (either
passed as an argument or loaded from `),NAe=a("code"),nst=o("pretrained_model_name_or_path"),sst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qAe=a("code"),lst=o("pretrained_model_name_or_path"),ist=o(":"),dst=l(),ze=a("ul"),e6=a("li"),jAe=a("strong"),cst=o("albert"),fst=o(" \u2014 "),qte=a("a"),mst=o("FlaxAlbertForMultipleChoice"),gst=o(" (ALBERT model)"),hst=l(),o6=a("li"),DAe=a("strong"),pst=o("bert"),_st=o(" \u2014 "),jte=a("a"),ust=o("FlaxBertForMultipleChoice"),bst=o(" (BERT model)"),vst=l(),r6=a("li"),GAe=a("strong"),Fst=o("big_bird"),Tst=o(" \u2014 "),Dte=a("a"),Mst=o("FlaxBigBirdForMultipleChoice"),Est=o(" (BigBird model)"),Cst=l(),t6=a("li"),OAe=a("strong"),wst=o("distilbert"),Ast=o(" \u2014 "),Gte=a("a"),Lst=o("FlaxDistilBertForMultipleChoice"),yst=o(" (DistilBERT model)"),xst=l(),a6=a("li"),VAe=a("strong"),$st=o("electra"),kst=o(" \u2014 "),Ote=a("a"),Sst=o("FlaxElectraForMultipleChoice"),Rst=o(" (ELECTRA model)"),Pst=l(),n6=a("li"),XAe=a("strong"),Bst=o("roberta"),Ist=o(" \u2014 "),Vte=a("a"),Nst=o("FlaxRobertaForMultipleChoice"),qst=o(" (RoBERTa model)"),jst=l(),s6=a("li"),zAe=a("strong"),Dst=o("roformer"),Gst=o(" \u2014 "),Xte=a("a"),Ost=o("FlaxRoFormerForMultipleChoice"),Vst=o(" (RoFormer model)"),Xst=l(),l6=a("li"),WAe=a("strong"),zst=o("xlm-roberta"),Wst=o(" \u2014 "),zte=a("a"),Qst=o("FlaxXLMRobertaForMultipleChoice"),Hst=o(" (XLM-RoBERTa model)"),Ust=l(),F(i6.$$.fragment),DHe=l(),Rf=a("h2"),d6=a("a"),QAe=a("span"),F(Wk.$$.fragment),Jst=l(),HAe=a("span"),Yst=o("FlaxAutoModelForNextSentencePrediction"),GHe=l(),Lr=a("div"),F(Qk.$$.fragment),Kst=l(),Pf=a("p"),Zst=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Wte=a("a"),elt=o("from_pretrained()"),olt=o(" class method or the "),Qte=a("a"),rlt=o("from_config()"),tlt=o(` class
method.`),alt=l(),Hk=a("p"),nlt=o("This class cannot be instantiated directly using "),UAe=a("code"),slt=o("__init__()"),llt=o(" (throws an error)."),ilt=l(),na=a("div"),F(Uk.$$.fragment),dlt=l(),JAe=a("p"),clt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),flt=l(),Bf=a("p"),mlt=o(`Note:
Loading a model from its configuration file does `),YAe=a("strong"),glt=o("not"),hlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Hte=a("a"),plt=o("from_pretrained()"),_lt=o(" to load the model weights."),ult=l(),F(c6.$$.fragment),blt=l(),ot=a("div"),F(Jk.$$.fragment),vlt=l(),KAe=a("p"),Flt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Tlt=l(),In=a("p"),Mlt=o("The model class to instantiate is selected based on the "),ZAe=a("code"),Elt=o("model_type"),Clt=o(` property of the config object (either
passed as an argument or loaded from `),eLe=a("code"),wlt=o("pretrained_model_name_or_path"),Alt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=a("code"),Llt=o("pretrained_model_name_or_path"),ylt=o(":"),xlt=l(),rLe=a("ul"),f6=a("li"),tLe=a("strong"),$lt=o("bert"),klt=o(" \u2014 "),Ute=a("a"),Slt=o("FlaxBertForNextSentencePrediction"),Rlt=o(" (BERT model)"),Plt=l(),F(m6.$$.fragment),OHe=l(),If=a("h2"),g6=a("a"),aLe=a("span"),F(Yk.$$.fragment),Blt=l(),nLe=a("span"),Ilt=o("FlaxAutoModelForImageClassification"),VHe=l(),yr=a("div"),F(Kk.$$.fragment),Nlt=l(),Nf=a("p"),qlt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jte=a("a"),jlt=o("from_pretrained()"),Dlt=o(" class method or the "),Yte=a("a"),Glt=o("from_config()"),Olt=o(` class
method.`),Vlt=l(),Zk=a("p"),Xlt=o("This class cannot be instantiated directly using "),sLe=a("code"),zlt=o("__init__()"),Wlt=o(" (throws an error)."),Qlt=l(),sa=a("div"),F(eS.$$.fragment),Hlt=l(),lLe=a("p"),Ult=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Jlt=l(),qf=a("p"),Ylt=o(`Note:
Loading a model from its configuration file does `),iLe=a("strong"),Klt=o("not"),Zlt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Kte=a("a"),eit=o("from_pretrained()"),oit=o(" to load the model weights."),rit=l(),F(h6.$$.fragment),tit=l(),rt=a("div"),F(oS.$$.fragment),ait=l(),dLe=a("p"),nit=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),sit=l(),Nn=a("p"),lit=o("The model class to instantiate is selected based on the "),cLe=a("code"),iit=o("model_type"),dit=o(` property of the config object (either
passed as an argument or loaded from `),fLe=a("code"),cit=o("pretrained_model_name_or_path"),fit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mLe=a("code"),mit=o("pretrained_model_name_or_path"),git=o(":"),hit=l(),rS=a("ul"),p6=a("li"),gLe=a("strong"),pit=o("beit"),_it=o(" \u2014 "),Zte=a("a"),uit=o("FlaxBeitForImageClassification"),bit=o(" (BEiT model)"),vit=l(),_6=a("li"),hLe=a("strong"),Fit=o("vit"),Tit=o(" \u2014 "),eae=a("a"),Mit=o("FlaxViTForImageClassification"),Eit=o(" (ViT model)"),Cit=l(),F(u6.$$.fragment),XHe=l(),jf=a("h2"),b6=a("a"),pLe=a("span"),F(tS.$$.fragment),wit=l(),_Le=a("span"),Ait=o("FlaxAutoModelForVision2Seq"),zHe=l(),xr=a("div"),F(aS.$$.fragment),Lit=l(),Df=a("p"),yit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),oae=a("a"),xit=o("from_pretrained()"),$it=o(" class method or the "),rae=a("a"),kit=o("from_config()"),Sit=o(` class
method.`),Rit=l(),nS=a("p"),Pit=o("This class cannot be instantiated directly using "),uLe=a("code"),Bit=o("__init__()"),Iit=o(" (throws an error)."),Nit=l(),la=a("div"),F(sS.$$.fragment),qit=l(),bLe=a("p"),jit=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Dit=l(),Gf=a("p"),Git=o(`Note:
Loading a model from its configuration file does `),vLe=a("strong"),Oit=o("not"),Vit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tae=a("a"),Xit=o("from_pretrained()"),zit=o(" to load the model weights."),Wit=l(),F(v6.$$.fragment),Qit=l(),tt=a("div"),F(lS.$$.fragment),Hit=l(),FLe=a("p"),Uit=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),Jit=l(),qn=a("p"),Yit=o("The model class to instantiate is selected based on the "),TLe=a("code"),Kit=o("model_type"),Zit=o(` property of the config object (either
passed as an argument or loaded from `),MLe=a("code"),edt=o("pretrained_model_name_or_path"),odt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ELe=a("code"),rdt=o("pretrained_model_name_or_path"),tdt=o(":"),adt=l(),CLe=a("ul"),F6=a("li"),wLe=a("strong"),ndt=o("vision-encoder-decoder"),sdt=o(" \u2014 "),aae=a("a"),ldt=o("FlaxVisionEncoderDecoderModel"),idt=o(" (Vision Encoder decoder model)"),ddt=l(),F(T6.$$.fragment),this.h()},l(f){const u=tea('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var iS=s(p);m=n(iS,"A",{id:!0,class:!0,href:!0});var ALe=s(m);_=n(ALe,"SPAN",{});var LLe=s(_);T(d.$$.fragment,LLe),LLe.forEach(t),ALe.forEach(t),h=i(iS),Ao=n(iS,"SPAN",{});var yLe=s(Ao);Ii=r(yLe,"Auto Classes"),yLe.forEach(t),iS.forEach(t),zf=i(f),dt=n(f,"P",{});var dS=s(dt);Ni=r(dS,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),qi=n(dS,"CODE",{});var xLe=s(qi);VL=r(xLe,"from_pretrained()"),xLe.forEach(t),Wf=r(dS,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),dS.forEach(t),Oe=i(f),Qe=n(f,"P",{});var jn=s(Qe);ji=r(jn,"Instantiating one of "),Dn=n(jn,"A",{href:!0});var $Le=s(Dn);XL=r($Le,"AutoConfig"),$Le.forEach(t),Gn=r(jn,", "),On=n(jn,"A",{href:!0});var kLe=s(On);zL=r(kLe,"AutoModel"),kLe.forEach(t),Di=r(jn,`, and
`),Vn=n(jn,"A",{href:!0});var SLe=s(Vn);WL=r(SLe,"AutoTokenizer"),SLe.forEach(t),Gi=r(jn," will directly create a class of the relevant architecture. For instance"),jn.forEach(t),Qf=i(f),T(Ia.$$.fragment,f),He=i(f),Ae=n(f,"P",{});var cS=s(Ae);kR=r(cS,"will create a model that is an instance of "),Oi=n(cS,"A",{href:!0});var RLe=s(Oi);SR=r(RLe,"BertModel"),RLe.forEach(t),RR=r(cS,"."),cS.forEach(t),Lo=i(f),Na=n(f,"P",{});var fS=s(Na);PR=r(fS,"There is one class of "),Hf=n(fS,"CODE",{});var PLe=s(Hf);BR=r(PLe,"AutoModel"),PLe.forEach(t),aYe=r(fS," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),fS.forEach(t),jWe=i(f),Vi=n(f,"H2",{class:!0});var mS=s(Vi);Uf=n(mS,"A",{id:!0,class:!0,href:!0});var BLe=s(Uf);ese=n(BLe,"SPAN",{});var ILe=s(ese);T(QL.$$.fragment,ILe),ILe.forEach(t),BLe.forEach(t),nYe=i(mS),ose=n(mS,"SPAN",{});var NLe=s(ose);sYe=r(NLe,"Extending the Auto Classes"),NLe.forEach(t),mS.forEach(t),DWe=i(f),Xn=n(f,"P",{});var Of=s(Xn);lYe=r(Of,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),rse=n(Of,"CODE",{});var qLe=s(rse);iYe=r(qLe,"NewModel"),qLe.forEach(t),dYe=r(Of,", make sure you have a "),tse=n(Of,"CODE",{});var jLe=s(tse);cYe=r(jLe,"NewModelConfig"),jLe.forEach(t),fYe=r(Of,` then you can add those to the auto
classes like this:`),Of.forEach(t),GWe=i(f),T(HL.$$.fragment,f),OWe=i(f),IR=n(f,"P",{});var DLe=s(IR);mYe=r(DLe,"You will then be able to use the auto classes like you would usually do!"),DLe.forEach(t),VWe=i(f),T(Jf.$$.fragment,f),XWe=i(f),Xi=n(f,"H2",{class:!0});var gS=s(Xi);Yf=n(gS,"A",{id:!0,class:!0,href:!0});var GLe=s(Yf);ase=n(GLe,"SPAN",{});var OLe=s(ase);T(UL.$$.fragment,OLe),OLe.forEach(t),GLe.forEach(t),gYe=i(gS),nse=n(gS,"SPAN",{});var VLe=s(nse);hYe=r(VLe,"AutoConfig"),VLe.forEach(t),gS.forEach(t),zWe=i(f),yo=n(f,"DIV",{class:!0});var lt=s(yo);T(JL.$$.fragment,lt),pYe=i(lt),YL=n(lt,"P",{});var hS=s(YL);_Ye=r(hS,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),NR=n(hS,"A",{href:!0});var XLe=s(NR);uYe=r(XLe,"from_pretrained()"),XLe.forEach(t),bYe=r(hS," class method."),hS.forEach(t),vYe=i(lt),KL=n(lt,"P",{});var pS=s(KL);FYe=r(pS,"This class cannot be instantiated directly using "),sse=n(pS,"CODE",{});var zLe=s(sse);TYe=r(zLe,"__init__()"),zLe.forEach(t),MYe=r(pS," (throws an error)."),pS.forEach(t),EYe=i(lt),$r=n(lt,"DIV",{class:!0});var it=s($r);T(ZL.$$.fragment,it),CYe=i(it),lse=n(it,"P",{});var WLe=s(lse);wYe=r(WLe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),WLe.forEach(t),AYe=i(it),zi=n(it,"P",{});var Vf=s(zi);LYe=r(Vf,"The configuration class to instantiate is selected based on the "),ise=n(Vf,"CODE",{});var QLe=s(ise);yYe=r(QLe,"model_type"),QLe.forEach(t),xYe=r(Vf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),dse=n(Vf,"CODE",{});var HLe=s(dse);$Ye=r(HLe,"pretrained_model_name_or_path"),HLe.forEach(t),kYe=r(Vf,":"),Vf.forEach(t),SYe=i(it),A=n(it,"UL",{});var L=s(A);Kf=n(L,"LI",{});var M6=s(Kf);cse=n(M6,"STRONG",{});var ULe=s(cse);RYe=r(ULe,"albert"),ULe.forEach(t),PYe=r(M6," \u2014 "),qR=n(M6,"A",{href:!0});var JLe=s(qR);BYe=r(JLe,"AlbertConfig"),JLe.forEach(t),IYe=r(M6," (ALBERT model)"),M6.forEach(t),NYe=i(L),Zf=n(L,"LI",{});var E6=s(Zf);fse=n(E6,"STRONG",{});var YLe=s(fse);qYe=r(YLe,"bart"),YLe.forEach(t),jYe=r(E6," \u2014 "),jR=n(E6,"A",{href:!0});var KLe=s(jR);DYe=r(KLe,"BartConfig"),KLe.forEach(t),GYe=r(E6," (BART model)"),E6.forEach(t),OYe=i(L),em=n(L,"LI",{});var C6=s(em);mse=n(C6,"STRONG",{});var ZLe=s(mse);VYe=r(ZLe,"beit"),ZLe.forEach(t),XYe=r(C6," \u2014 "),DR=n(C6,"A",{href:!0});var eye=s(DR);zYe=r(eye,"BeitConfig"),eye.forEach(t),WYe=r(C6," (BEiT model)"),C6.forEach(t),QYe=i(L),om=n(L,"LI",{});var w6=s(om);gse=n(w6,"STRONG",{});var oye=s(gse);HYe=r(oye,"bert"),oye.forEach(t),UYe=r(w6," \u2014 "),GR=n(w6,"A",{href:!0});var rye=s(GR);JYe=r(rye,"BertConfig"),rye.forEach(t),YYe=r(w6," (BERT model)"),w6.forEach(t),KYe=i(L),rm=n(L,"LI",{});var A6=s(rm);hse=n(A6,"STRONG",{});var tye=s(hse);ZYe=r(tye,"bert-generation"),tye.forEach(t),eKe=r(A6," \u2014 "),OR=n(A6,"A",{href:!0});var aye=s(OR);oKe=r(aye,"BertGenerationConfig"),aye.forEach(t),rKe=r(A6," (Bert Generation model)"),A6.forEach(t),tKe=i(L),tm=n(L,"LI",{});var L6=s(tm);pse=n(L6,"STRONG",{});var nye=s(pse);aKe=r(nye,"big_bird"),nye.forEach(t),nKe=r(L6," \u2014 "),VR=n(L6,"A",{href:!0});var sye=s(VR);sKe=r(sye,"BigBirdConfig"),sye.forEach(t),lKe=r(L6," (BigBird model)"),L6.forEach(t),iKe=i(L),am=n(L,"LI",{});var y6=s(am);_se=n(y6,"STRONG",{});var lye=s(_se);dKe=r(lye,"bigbird_pegasus"),lye.forEach(t),cKe=r(y6," \u2014 "),XR=n(y6,"A",{href:!0});var iye=s(XR);fKe=r(iye,"BigBirdPegasusConfig"),iye.forEach(t),mKe=r(y6," (BigBird-Pegasus model)"),y6.forEach(t),gKe=i(L),nm=n(L,"LI",{});var x6=s(nm);use=n(x6,"STRONG",{});var dye=s(use);hKe=r(dye,"blenderbot"),dye.forEach(t),pKe=r(x6," \u2014 "),zR=n(x6,"A",{href:!0});var cye=s(zR);_Ke=r(cye,"BlenderbotConfig"),cye.forEach(t),uKe=r(x6," (Blenderbot model)"),x6.forEach(t),bKe=i(L),sm=n(L,"LI",{});var $6=s(sm);bse=n($6,"STRONG",{});var fye=s(bse);vKe=r(fye,"blenderbot-small"),fye.forEach(t),FKe=r($6," \u2014 "),WR=n($6,"A",{href:!0});var mye=s(WR);TKe=r(mye,"BlenderbotSmallConfig"),mye.forEach(t),MKe=r($6," (BlenderbotSmall model)"),$6.forEach(t),EKe=i(L),lm=n(L,"LI",{});var k6=s(lm);vse=n(k6,"STRONG",{});var gye=s(vse);CKe=r(gye,"bloom"),gye.forEach(t),wKe=r(k6," \u2014 "),QR=n(k6,"A",{href:!0});var hye=s(QR);AKe=r(hye,"BloomConfig"),hye.forEach(t),LKe=r(k6," (BLOOM model)"),k6.forEach(t),yKe=i(L),im=n(L,"LI",{});var S6=s(im);Fse=n(S6,"STRONG",{});var pye=s(Fse);xKe=r(pye,"camembert"),pye.forEach(t),$Ke=r(S6," \u2014 "),HR=n(S6,"A",{href:!0});var _ye=s(HR);kKe=r(_ye,"CamembertConfig"),_ye.forEach(t),SKe=r(S6," (CamemBERT model)"),S6.forEach(t),RKe=i(L),dm=n(L,"LI",{});var R6=s(dm);Tse=n(R6,"STRONG",{});var uye=s(Tse);PKe=r(uye,"canine"),uye.forEach(t),BKe=r(R6," \u2014 "),UR=n(R6,"A",{href:!0});var bye=s(UR);IKe=r(bye,"CanineConfig"),bye.forEach(t),NKe=r(R6," (CANINE model)"),R6.forEach(t),qKe=i(L),cm=n(L,"LI",{});var P6=s(cm);Mse=n(P6,"STRONG",{});var vye=s(Mse);jKe=r(vye,"clip"),vye.forEach(t),DKe=r(P6," \u2014 "),JR=n(P6,"A",{href:!0});var Fye=s(JR);GKe=r(Fye,"CLIPConfig"),Fye.forEach(t),OKe=r(P6," (CLIP model)"),P6.forEach(t),VKe=i(L),fm=n(L,"LI",{});var B6=s(fm);Ese=n(B6,"STRONG",{});var Tye=s(Ese);XKe=r(Tye,"codegen"),Tye.forEach(t),zKe=r(B6," \u2014 "),YR=n(B6,"A",{href:!0});var Mye=s(YR);WKe=r(Mye,"CodeGenConfig"),Mye.forEach(t),QKe=r(B6," (CodeGen model)"),B6.forEach(t),HKe=i(L),mm=n(L,"LI",{});var I6=s(mm);Cse=n(I6,"STRONG",{});var Eye=s(Cse);UKe=r(Eye,"convbert"),Eye.forEach(t),JKe=r(I6," \u2014 "),KR=n(I6,"A",{href:!0});var Cye=s(KR);YKe=r(Cye,"ConvBertConfig"),Cye.forEach(t),KKe=r(I6," (ConvBERT model)"),I6.forEach(t),ZKe=i(L),gm=n(L,"LI",{});var N6=s(gm);wse=n(N6,"STRONG",{});var wye=s(wse);eZe=r(wye,"convnext"),wye.forEach(t),oZe=r(N6," \u2014 "),ZR=n(N6,"A",{href:!0});var Aye=s(ZR);rZe=r(Aye,"ConvNextConfig"),Aye.forEach(t),tZe=r(N6," (ConvNeXT model)"),N6.forEach(t),aZe=i(L),hm=n(L,"LI",{});var q6=s(hm);Ase=n(q6,"STRONG",{});var Lye=s(Ase);nZe=r(Lye,"ctrl"),Lye.forEach(t),sZe=r(q6," \u2014 "),eP=n(q6,"A",{href:!0});var yye=s(eP);lZe=r(yye,"CTRLConfig"),yye.forEach(t),iZe=r(q6," (CTRL model)"),q6.forEach(t),dZe=i(L),pm=n(L,"LI",{});var j6=s(pm);Lse=n(j6,"STRONG",{});var xye=s(Lse);cZe=r(xye,"cvt"),xye.forEach(t),fZe=r(j6," \u2014 "),oP=n(j6,"A",{href:!0});var $ye=s(oP);mZe=r($ye,"CvtConfig"),$ye.forEach(t),gZe=r(j6," (CvT model)"),j6.forEach(t),hZe=i(L),_m=n(L,"LI",{});var D6=s(_m);yse=n(D6,"STRONG",{});var kye=s(yse);pZe=r(kye,"data2vec-audio"),kye.forEach(t),_Ze=r(D6," \u2014 "),rP=n(D6,"A",{href:!0});var Sye=s(rP);uZe=r(Sye,"Data2VecAudioConfig"),Sye.forEach(t),bZe=r(D6," (Data2VecAudio model)"),D6.forEach(t),vZe=i(L),um=n(L,"LI",{});var G6=s(um);xse=n(G6,"STRONG",{});var Rye=s(xse);FZe=r(Rye,"data2vec-text"),Rye.forEach(t),TZe=r(G6," \u2014 "),tP=n(G6,"A",{href:!0});var Pye=s(tP);MZe=r(Pye,"Data2VecTextConfig"),Pye.forEach(t),EZe=r(G6," (Data2VecText model)"),G6.forEach(t),CZe=i(L),bm=n(L,"LI",{});var O6=s(bm);$se=n(O6,"STRONG",{});var Bye=s($se);wZe=r(Bye,"data2vec-vision"),Bye.forEach(t),AZe=r(O6," \u2014 "),aP=n(O6,"A",{href:!0});var Iye=s(aP);LZe=r(Iye,"Data2VecVisionConfig"),Iye.forEach(t),yZe=r(O6," (Data2VecVision model)"),O6.forEach(t),xZe=i(L),vm=n(L,"LI",{});var V6=s(vm);kse=n(V6,"STRONG",{});var Nye=s(kse);$Ze=r(Nye,"deberta"),Nye.forEach(t),kZe=r(V6," \u2014 "),nP=n(V6,"A",{href:!0});var qye=s(nP);SZe=r(qye,"DebertaConfig"),qye.forEach(t),RZe=r(V6," (DeBERTa model)"),V6.forEach(t),PZe=i(L),Fm=n(L,"LI",{});var X6=s(Fm);Sse=n(X6,"STRONG",{});var jye=s(Sse);BZe=r(jye,"deberta-v2"),jye.forEach(t),IZe=r(X6," \u2014 "),sP=n(X6,"A",{href:!0});var Dye=s(sP);NZe=r(Dye,"DebertaV2Config"),Dye.forEach(t),qZe=r(X6," (DeBERTa-v2 model)"),X6.forEach(t),jZe=i(L),Tm=n(L,"LI",{});var z6=s(Tm);Rse=n(z6,"STRONG",{});var Gye=s(Rse);DZe=r(Gye,"decision_transformer"),Gye.forEach(t),GZe=r(z6," \u2014 "),lP=n(z6,"A",{href:!0});var Oye=s(lP);OZe=r(Oye,"DecisionTransformerConfig"),Oye.forEach(t),VZe=r(z6," (Decision Transformer model)"),z6.forEach(t),XZe=i(L),Mm=n(L,"LI",{});var Vye=s(Mm);Pse=n(Vye,"STRONG",{});var fdt=s(Pse);zZe=r(fdt,"deit"),fdt.forEach(t),WZe=r(Vye," \u2014 "),iP=n(Vye,"A",{href:!0});var mdt=s(iP);QZe=r(mdt,"DeiTConfig"),mdt.forEach(t),HZe=r(Vye," (DeiT model)"),Vye.forEach(t),UZe=i(L),Em=n(L,"LI",{});var Xye=s(Em);Bse=n(Xye,"STRONG",{});var gdt=s(Bse);JZe=r(gdt,"detr"),gdt.forEach(t),YZe=r(Xye," \u2014 "),dP=n(Xye,"A",{href:!0});var hdt=s(dP);KZe=r(hdt,"DetrConfig"),hdt.forEach(t),ZZe=r(Xye," (DETR model)"),Xye.forEach(t),eeo=i(L),Cm=n(L,"LI",{});var zye=s(Cm);Ise=n(zye,"STRONG",{});var pdt=s(Ise);oeo=r(pdt,"distilbert"),pdt.forEach(t),reo=r(zye," \u2014 "),cP=n(zye,"A",{href:!0});var _dt=s(cP);teo=r(_dt,"DistilBertConfig"),_dt.forEach(t),aeo=r(zye," (DistilBERT model)"),zye.forEach(t),neo=i(L),wm=n(L,"LI",{});var Wye=s(wm);Nse=n(Wye,"STRONG",{});var udt=s(Nse);seo=r(udt,"dpr"),udt.forEach(t),leo=r(Wye," \u2014 "),fP=n(Wye,"A",{href:!0});var bdt=s(fP);ieo=r(bdt,"DPRConfig"),bdt.forEach(t),deo=r(Wye," (DPR model)"),Wye.forEach(t),ceo=i(L),Am=n(L,"LI",{});var Qye=s(Am);qse=n(Qye,"STRONG",{});var vdt=s(qse);feo=r(vdt,"dpt"),vdt.forEach(t),meo=r(Qye," \u2014 "),mP=n(Qye,"A",{href:!0});var Fdt=s(mP);geo=r(Fdt,"DPTConfig"),Fdt.forEach(t),heo=r(Qye," (DPT model)"),Qye.forEach(t),peo=i(L),Lm=n(L,"LI",{});var Hye=s(Lm);jse=n(Hye,"STRONG",{});var Tdt=s(jse);_eo=r(Tdt,"electra"),Tdt.forEach(t),ueo=r(Hye," \u2014 "),gP=n(Hye,"A",{href:!0});var Mdt=s(gP);beo=r(Mdt,"ElectraConfig"),Mdt.forEach(t),veo=r(Hye," (ELECTRA model)"),Hye.forEach(t),Feo=i(L),ym=n(L,"LI",{});var Uye=s(ym);Dse=n(Uye,"STRONG",{});var Edt=s(Dse);Teo=r(Edt,"encoder-decoder"),Edt.forEach(t),Meo=r(Uye," \u2014 "),hP=n(Uye,"A",{href:!0});var Cdt=s(hP);Eeo=r(Cdt,"EncoderDecoderConfig"),Cdt.forEach(t),Ceo=r(Uye," (Encoder decoder model)"),Uye.forEach(t),weo=i(L),xm=n(L,"LI",{});var Jye=s(xm);Gse=n(Jye,"STRONG",{});var wdt=s(Gse);Aeo=r(wdt,"flaubert"),wdt.forEach(t),Leo=r(Jye," \u2014 "),pP=n(Jye,"A",{href:!0});var Adt=s(pP);yeo=r(Adt,"FlaubertConfig"),Adt.forEach(t),xeo=r(Jye," (FlauBERT model)"),Jye.forEach(t),$eo=i(L),$m=n(L,"LI",{});var Yye=s($m);Ose=n(Yye,"STRONG",{});var Ldt=s(Ose);keo=r(Ldt,"flava"),Ldt.forEach(t),Seo=r(Yye," \u2014 "),_P=n(Yye,"A",{href:!0});var ydt=s(_P);Reo=r(ydt,"FlavaConfig"),ydt.forEach(t),Peo=r(Yye," (FLAVA model)"),Yye.forEach(t),Beo=i(L),km=n(L,"LI",{});var Kye=s(km);Vse=n(Kye,"STRONG",{});var xdt=s(Vse);Ieo=r(xdt,"fnet"),xdt.forEach(t),Neo=r(Kye," \u2014 "),uP=n(Kye,"A",{href:!0});var $dt=s(uP);qeo=r($dt,"FNetConfig"),$dt.forEach(t),jeo=r(Kye," (FNet model)"),Kye.forEach(t),Deo=i(L),Sm=n(L,"LI",{});var Zye=s(Sm);Xse=n(Zye,"STRONG",{});var kdt=s(Xse);Geo=r(kdt,"fsmt"),kdt.forEach(t),Oeo=r(Zye," \u2014 "),bP=n(Zye,"A",{href:!0});var Sdt=s(bP);Veo=r(Sdt,"FSMTConfig"),Sdt.forEach(t),Xeo=r(Zye," (FairSeq Machine-Translation model)"),Zye.forEach(t),zeo=i(L),Rm=n(L,"LI",{});var e8e=s(Rm);zse=n(e8e,"STRONG",{});var Rdt=s(zse);Weo=r(Rdt,"funnel"),Rdt.forEach(t),Qeo=r(e8e," \u2014 "),vP=n(e8e,"A",{href:!0});var Pdt=s(vP);Heo=r(Pdt,"FunnelConfig"),Pdt.forEach(t),Ueo=r(e8e," (Funnel Transformer model)"),e8e.forEach(t),Jeo=i(L),Pm=n(L,"LI",{});var o8e=s(Pm);Wse=n(o8e,"STRONG",{});var Bdt=s(Wse);Yeo=r(Bdt,"glpn"),Bdt.forEach(t),Keo=r(o8e," \u2014 "),FP=n(o8e,"A",{href:!0});var Idt=s(FP);Zeo=r(Idt,"GLPNConfig"),Idt.forEach(t),eoo=r(o8e," (GLPN model)"),o8e.forEach(t),ooo=i(L),Bm=n(L,"LI",{});var r8e=s(Bm);Qse=n(r8e,"STRONG",{});var Ndt=s(Qse);roo=r(Ndt,"gpt2"),Ndt.forEach(t),too=r(r8e," \u2014 "),TP=n(r8e,"A",{href:!0});var qdt=s(TP);aoo=r(qdt,"GPT2Config"),qdt.forEach(t),noo=r(r8e," (OpenAI GPT-2 model)"),r8e.forEach(t),soo=i(L),Im=n(L,"LI",{});var t8e=s(Im);Hse=n(t8e,"STRONG",{});var jdt=s(Hse);loo=r(jdt,"gpt_neo"),jdt.forEach(t),ioo=r(t8e," \u2014 "),MP=n(t8e,"A",{href:!0});var Ddt=s(MP);doo=r(Ddt,"GPTNeoConfig"),Ddt.forEach(t),coo=r(t8e," (GPT Neo model)"),t8e.forEach(t),foo=i(L),Nm=n(L,"LI",{});var a8e=s(Nm);Use=n(a8e,"STRONG",{});var Gdt=s(Use);moo=r(Gdt,"gpt_neox"),Gdt.forEach(t),goo=r(a8e," \u2014 "),EP=n(a8e,"A",{href:!0});var Odt=s(EP);hoo=r(Odt,"GPTNeoXConfig"),Odt.forEach(t),poo=r(a8e," (GPT NeoX model)"),a8e.forEach(t),_oo=i(L),qm=n(L,"LI",{});var n8e=s(qm);Jse=n(n8e,"STRONG",{});var Vdt=s(Jse);uoo=r(Vdt,"gptj"),Vdt.forEach(t),boo=r(n8e," \u2014 "),CP=n(n8e,"A",{href:!0});var Xdt=s(CP);voo=r(Xdt,"GPTJConfig"),Xdt.forEach(t),Foo=r(n8e," (GPT-J model)"),n8e.forEach(t),Too=i(L),jm=n(L,"LI",{});var s8e=s(jm);Yse=n(s8e,"STRONG",{});var zdt=s(Yse);Moo=r(zdt,"groupvit"),zdt.forEach(t),Eoo=r(s8e," \u2014 "),wP=n(s8e,"A",{href:!0});var Wdt=s(wP);Coo=r(Wdt,"GroupViTConfig"),Wdt.forEach(t),woo=r(s8e," (GroupViT model)"),s8e.forEach(t),Aoo=i(L),Dm=n(L,"LI",{});var l8e=s(Dm);Kse=n(l8e,"STRONG",{});var Qdt=s(Kse);Loo=r(Qdt,"hubert"),Qdt.forEach(t),yoo=r(l8e," \u2014 "),AP=n(l8e,"A",{href:!0});var Hdt=s(AP);xoo=r(Hdt,"HubertConfig"),Hdt.forEach(t),$oo=r(l8e," (Hubert model)"),l8e.forEach(t),koo=i(L),Gm=n(L,"LI",{});var i8e=s(Gm);Zse=n(i8e,"STRONG",{});var Udt=s(Zse);Soo=r(Udt,"ibert"),Udt.forEach(t),Roo=r(i8e," \u2014 "),LP=n(i8e,"A",{href:!0});var Jdt=s(LP);Poo=r(Jdt,"IBertConfig"),Jdt.forEach(t),Boo=r(i8e," (I-BERT model)"),i8e.forEach(t),Ioo=i(L),Om=n(L,"LI",{});var d8e=s(Om);ele=n(d8e,"STRONG",{});var Ydt=s(ele);Noo=r(Ydt,"imagegpt"),Ydt.forEach(t),qoo=r(d8e," \u2014 "),yP=n(d8e,"A",{href:!0});var Kdt=s(yP);joo=r(Kdt,"ImageGPTConfig"),Kdt.forEach(t),Doo=r(d8e," (ImageGPT model)"),d8e.forEach(t),Goo=i(L),Vm=n(L,"LI",{});var c8e=s(Vm);ole=n(c8e,"STRONG",{});var Zdt=s(ole);Ooo=r(Zdt,"layoutlm"),Zdt.forEach(t),Voo=r(c8e," \u2014 "),xP=n(c8e,"A",{href:!0});var ect=s(xP);Xoo=r(ect,"LayoutLMConfig"),ect.forEach(t),zoo=r(c8e," (LayoutLM model)"),c8e.forEach(t),Woo=i(L),Xm=n(L,"LI",{});var f8e=s(Xm);rle=n(f8e,"STRONG",{});var oct=s(rle);Qoo=r(oct,"layoutlmv2"),oct.forEach(t),Hoo=r(f8e," \u2014 "),$P=n(f8e,"A",{href:!0});var rct=s($P);Uoo=r(rct,"LayoutLMv2Config"),rct.forEach(t),Joo=r(f8e," (LayoutLMv2 model)"),f8e.forEach(t),Yoo=i(L),zm=n(L,"LI",{});var m8e=s(zm);tle=n(m8e,"STRONG",{});var tct=s(tle);Koo=r(tct,"layoutlmv3"),tct.forEach(t),Zoo=r(m8e," \u2014 "),kP=n(m8e,"A",{href:!0});var act=s(kP);ero=r(act,"LayoutLMv3Config"),act.forEach(t),oro=r(m8e," (LayoutLMv3 model)"),m8e.forEach(t),rro=i(L),Wm=n(L,"LI",{});var g8e=s(Wm);ale=n(g8e,"STRONG",{});var nct=s(ale);tro=r(nct,"led"),nct.forEach(t),aro=r(g8e," \u2014 "),SP=n(g8e,"A",{href:!0});var sct=s(SP);nro=r(sct,"LEDConfig"),sct.forEach(t),sro=r(g8e," (LED model)"),g8e.forEach(t),lro=i(L),Qm=n(L,"LI",{});var h8e=s(Qm);nle=n(h8e,"STRONG",{});var lct=s(nle);iro=r(lct,"levit"),lct.forEach(t),dro=r(h8e," \u2014 "),RP=n(h8e,"A",{href:!0});var ict=s(RP);cro=r(ict,"LevitConfig"),ict.forEach(t),fro=r(h8e," (LeViT model)"),h8e.forEach(t),mro=i(L),Hm=n(L,"LI",{});var p8e=s(Hm);sle=n(p8e,"STRONG",{});var dct=s(sle);gro=r(dct,"longformer"),dct.forEach(t),hro=r(p8e," \u2014 "),PP=n(p8e,"A",{href:!0});var cct=s(PP);pro=r(cct,"LongformerConfig"),cct.forEach(t),_ro=r(p8e," (Longformer model)"),p8e.forEach(t),uro=i(L),Um=n(L,"LI",{});var _8e=s(Um);lle=n(_8e,"STRONG",{});var fct=s(lle);bro=r(fct,"longt5"),fct.forEach(t),vro=r(_8e," \u2014 "),BP=n(_8e,"A",{href:!0});var mct=s(BP);Fro=r(mct,"LongT5Config"),mct.forEach(t),Tro=r(_8e," (LongT5 model)"),_8e.forEach(t),Mro=i(L),Jm=n(L,"LI",{});var u8e=s(Jm);ile=n(u8e,"STRONG",{});var gct=s(ile);Ero=r(gct,"luke"),gct.forEach(t),Cro=r(u8e," \u2014 "),IP=n(u8e,"A",{href:!0});var hct=s(IP);wro=r(hct,"LukeConfig"),hct.forEach(t),Aro=r(u8e," (LUKE model)"),u8e.forEach(t),Lro=i(L),Ym=n(L,"LI",{});var b8e=s(Ym);dle=n(b8e,"STRONG",{});var pct=s(dle);yro=r(pct,"lxmert"),pct.forEach(t),xro=r(b8e," \u2014 "),NP=n(b8e,"A",{href:!0});var _ct=s(NP);$ro=r(_ct,"LxmertConfig"),_ct.forEach(t),kro=r(b8e," (LXMERT model)"),b8e.forEach(t),Sro=i(L),Km=n(L,"LI",{});var v8e=s(Km);cle=n(v8e,"STRONG",{});var uct=s(cle);Rro=r(uct,"m2m_100"),uct.forEach(t),Pro=r(v8e," \u2014 "),qP=n(v8e,"A",{href:!0});var bct=s(qP);Bro=r(bct,"M2M100Config"),bct.forEach(t),Iro=r(v8e," (M2M100 model)"),v8e.forEach(t),Nro=i(L),Zm=n(L,"LI",{});var F8e=s(Zm);fle=n(F8e,"STRONG",{});var vct=s(fle);qro=r(vct,"marian"),vct.forEach(t),jro=r(F8e," \u2014 "),jP=n(F8e,"A",{href:!0});var Fct=s(jP);Dro=r(Fct,"MarianConfig"),Fct.forEach(t),Gro=r(F8e," (Marian model)"),F8e.forEach(t),Oro=i(L),eg=n(L,"LI",{});var T8e=s(eg);mle=n(T8e,"STRONG",{});var Tct=s(mle);Vro=r(Tct,"maskformer"),Tct.forEach(t),Xro=r(T8e," \u2014 "),DP=n(T8e,"A",{href:!0});var Mct=s(DP);zro=r(Mct,"MaskFormerConfig"),Mct.forEach(t),Wro=r(T8e," (MaskFormer model)"),T8e.forEach(t),Qro=i(L),og=n(L,"LI",{});var M8e=s(og);gle=n(M8e,"STRONG",{});var Ect=s(gle);Hro=r(Ect,"mbart"),Ect.forEach(t),Uro=r(M8e," \u2014 "),GP=n(M8e,"A",{href:!0});var Cct=s(GP);Jro=r(Cct,"MBartConfig"),Cct.forEach(t),Yro=r(M8e," (mBART model)"),M8e.forEach(t),Kro=i(L),rg=n(L,"LI",{});var E8e=s(rg);hle=n(E8e,"STRONG",{});var wct=s(hle);Zro=r(wct,"mctct"),wct.forEach(t),eto=r(E8e," \u2014 "),OP=n(E8e,"A",{href:!0});var Act=s(OP);oto=r(Act,"MCTCTConfig"),Act.forEach(t),rto=r(E8e," (M-CTC-T model)"),E8e.forEach(t),tto=i(L),tg=n(L,"LI",{});var C8e=s(tg);ple=n(C8e,"STRONG",{});var Lct=s(ple);ato=r(Lct,"megatron-bert"),Lct.forEach(t),nto=r(C8e," \u2014 "),VP=n(C8e,"A",{href:!0});var yct=s(VP);sto=r(yct,"MegatronBertConfig"),yct.forEach(t),lto=r(C8e," (Megatron-BERT model)"),C8e.forEach(t),ito=i(L),ag=n(L,"LI",{});var w8e=s(ag);_le=n(w8e,"STRONG",{});var xct=s(_le);dto=r(xct,"mobilebert"),xct.forEach(t),cto=r(w8e," \u2014 "),XP=n(w8e,"A",{href:!0});var $ct=s(XP);fto=r($ct,"MobileBertConfig"),$ct.forEach(t),mto=r(w8e," (MobileBERT model)"),w8e.forEach(t),gto=i(L),ng=n(L,"LI",{});var A8e=s(ng);ule=n(A8e,"STRONG",{});var kct=s(ule);hto=r(kct,"mobilevit"),kct.forEach(t),pto=r(A8e," \u2014 "),zP=n(A8e,"A",{href:!0});var Sct=s(zP);_to=r(Sct,"MobileViTConfig"),Sct.forEach(t),uto=r(A8e," (MobileViT model)"),A8e.forEach(t),bto=i(L),sg=n(L,"LI",{});var L8e=s(sg);ble=n(L8e,"STRONG",{});var Rct=s(ble);vto=r(Rct,"mpnet"),Rct.forEach(t),Fto=r(L8e," \u2014 "),WP=n(L8e,"A",{href:!0});var Pct=s(WP);Tto=r(Pct,"MPNetConfig"),Pct.forEach(t),Mto=r(L8e," (MPNet model)"),L8e.forEach(t),Eto=i(L),lg=n(L,"LI",{});var y8e=s(lg);vle=n(y8e,"STRONG",{});var Bct=s(vle);Cto=r(Bct,"mt5"),Bct.forEach(t),wto=r(y8e," \u2014 "),QP=n(y8e,"A",{href:!0});var Ict=s(QP);Ato=r(Ict,"MT5Config"),Ict.forEach(t),Lto=r(y8e," (MT5 model)"),y8e.forEach(t),yto=i(L),ig=n(L,"LI",{});var x8e=s(ig);Fle=n(x8e,"STRONG",{});var Nct=s(Fle);xto=r(Nct,"mvp"),Nct.forEach(t),$to=r(x8e," \u2014 "),HP=n(x8e,"A",{href:!0});var qct=s(HP);kto=r(qct,"MvpConfig"),qct.forEach(t),Sto=r(x8e," (MVP model)"),x8e.forEach(t),Rto=i(L),dg=n(L,"LI",{});var $8e=s(dg);Tle=n($8e,"STRONG",{});var jct=s(Tle);Pto=r(jct,"nezha"),jct.forEach(t),Bto=r($8e," \u2014 "),UP=n($8e,"A",{href:!0});var Dct=s(UP);Ito=r(Dct,"NezhaConfig"),Dct.forEach(t),Nto=r($8e," (Nezha model)"),$8e.forEach(t),qto=i(L),cg=n(L,"LI",{});var k8e=s(cg);Mle=n(k8e,"STRONG",{});var Gct=s(Mle);jto=r(Gct,"nystromformer"),Gct.forEach(t),Dto=r(k8e," \u2014 "),JP=n(k8e,"A",{href:!0});var Oct=s(JP);Gto=r(Oct,"NystromformerConfig"),Oct.forEach(t),Oto=r(k8e," (Nystr\xF6mformer model)"),k8e.forEach(t),Vto=i(L),fg=n(L,"LI",{});var S8e=s(fg);Ele=n(S8e,"STRONG",{});var Vct=s(Ele);Xto=r(Vct,"openai-gpt"),Vct.forEach(t),zto=r(S8e," \u2014 "),YP=n(S8e,"A",{href:!0});var Xct=s(YP);Wto=r(Xct,"OpenAIGPTConfig"),Xct.forEach(t),Qto=r(S8e," (OpenAI GPT model)"),S8e.forEach(t),Hto=i(L),mg=n(L,"LI",{});var R8e=s(mg);Cle=n(R8e,"STRONG",{});var zct=s(Cle);Uto=r(zct,"opt"),zct.forEach(t),Jto=r(R8e," \u2014 "),KP=n(R8e,"A",{href:!0});var Wct=s(KP);Yto=r(Wct,"OPTConfig"),Wct.forEach(t),Kto=r(R8e," (OPT model)"),R8e.forEach(t),Zto=i(L),gg=n(L,"LI",{});var P8e=s(gg);wle=n(P8e,"STRONG",{});var Qct=s(wle);eao=r(Qct,"owlvit"),Qct.forEach(t),oao=r(P8e," \u2014 "),ZP=n(P8e,"A",{href:!0});var Hct=s(ZP);rao=r(Hct,"OwlViTConfig"),Hct.forEach(t),tao=r(P8e," (OWL-ViT model)"),P8e.forEach(t),aao=i(L),hg=n(L,"LI",{});var B8e=s(hg);Ale=n(B8e,"STRONG",{});var Uct=s(Ale);nao=r(Uct,"pegasus"),Uct.forEach(t),sao=r(B8e," \u2014 "),eB=n(B8e,"A",{href:!0});var Jct=s(eB);lao=r(Jct,"PegasusConfig"),Jct.forEach(t),iao=r(B8e," (Pegasus model)"),B8e.forEach(t),dao=i(L),pg=n(L,"LI",{});var I8e=s(pg);Lle=n(I8e,"STRONG",{});var Yct=s(Lle);cao=r(Yct,"perceiver"),Yct.forEach(t),fao=r(I8e," \u2014 "),oB=n(I8e,"A",{href:!0});var Kct=s(oB);mao=r(Kct,"PerceiverConfig"),Kct.forEach(t),gao=r(I8e," (Perceiver model)"),I8e.forEach(t),hao=i(L),_g=n(L,"LI",{});var N8e=s(_g);yle=n(N8e,"STRONG",{});var Zct=s(yle);pao=r(Zct,"plbart"),Zct.forEach(t),_ao=r(N8e," \u2014 "),rB=n(N8e,"A",{href:!0});var eft=s(rB);uao=r(eft,"PLBartConfig"),eft.forEach(t),bao=r(N8e," (PLBart model)"),N8e.forEach(t),vao=i(L),ug=n(L,"LI",{});var q8e=s(ug);xle=n(q8e,"STRONG",{});var oft=s(xle);Fao=r(oft,"poolformer"),oft.forEach(t),Tao=r(q8e," \u2014 "),tB=n(q8e,"A",{href:!0});var rft=s(tB);Mao=r(rft,"PoolFormerConfig"),rft.forEach(t),Eao=r(q8e," (PoolFormer model)"),q8e.forEach(t),Cao=i(L),bg=n(L,"LI",{});var j8e=s(bg);$le=n(j8e,"STRONG",{});var tft=s($le);wao=r(tft,"prophetnet"),tft.forEach(t),Aao=r(j8e," \u2014 "),aB=n(j8e,"A",{href:!0});var aft=s(aB);Lao=r(aft,"ProphetNetConfig"),aft.forEach(t),yao=r(j8e," (ProphetNet model)"),j8e.forEach(t),xao=i(L),vg=n(L,"LI",{});var D8e=s(vg);kle=n(D8e,"STRONG",{});var nft=s(kle);$ao=r(nft,"qdqbert"),nft.forEach(t),kao=r(D8e," \u2014 "),nB=n(D8e,"A",{href:!0});var sft=s(nB);Sao=r(sft,"QDQBertConfig"),sft.forEach(t),Rao=r(D8e," (QDQBert model)"),D8e.forEach(t),Pao=i(L),Fg=n(L,"LI",{});var G8e=s(Fg);Sle=n(G8e,"STRONG",{});var lft=s(Sle);Bao=r(lft,"rag"),lft.forEach(t),Iao=r(G8e," \u2014 "),sB=n(G8e,"A",{href:!0});var ift=s(sB);Nao=r(ift,"RagConfig"),ift.forEach(t),qao=r(G8e," (RAG model)"),G8e.forEach(t),jao=i(L),Tg=n(L,"LI",{});var O8e=s(Tg);Rle=n(O8e,"STRONG",{});var dft=s(Rle);Dao=r(dft,"realm"),dft.forEach(t),Gao=r(O8e," \u2014 "),lB=n(O8e,"A",{href:!0});var cft=s(lB);Oao=r(cft,"RealmConfig"),cft.forEach(t),Vao=r(O8e," (REALM model)"),O8e.forEach(t),Xao=i(L),Mg=n(L,"LI",{});var V8e=s(Mg);Ple=n(V8e,"STRONG",{});var fft=s(Ple);zao=r(fft,"reformer"),fft.forEach(t),Wao=r(V8e," \u2014 "),iB=n(V8e,"A",{href:!0});var mft=s(iB);Qao=r(mft,"ReformerConfig"),mft.forEach(t),Hao=r(V8e," (Reformer model)"),V8e.forEach(t),Uao=i(L),Eg=n(L,"LI",{});var X8e=s(Eg);Ble=n(X8e,"STRONG",{});var gft=s(Ble);Jao=r(gft,"regnet"),gft.forEach(t),Yao=r(X8e," \u2014 "),dB=n(X8e,"A",{href:!0});var hft=s(dB);Kao=r(hft,"RegNetConfig"),hft.forEach(t),Zao=r(X8e," (RegNet model)"),X8e.forEach(t),eno=i(L),Cg=n(L,"LI",{});var z8e=s(Cg);Ile=n(z8e,"STRONG",{});var pft=s(Ile);ono=r(pft,"rembert"),pft.forEach(t),rno=r(z8e," \u2014 "),cB=n(z8e,"A",{href:!0});var _ft=s(cB);tno=r(_ft,"RemBertConfig"),_ft.forEach(t),ano=r(z8e," (RemBERT model)"),z8e.forEach(t),nno=i(L),wg=n(L,"LI",{});var W8e=s(wg);Nle=n(W8e,"STRONG",{});var uft=s(Nle);sno=r(uft,"resnet"),uft.forEach(t),lno=r(W8e," \u2014 "),fB=n(W8e,"A",{href:!0});var bft=s(fB);ino=r(bft,"ResNetConfig"),bft.forEach(t),dno=r(W8e," (ResNet model)"),W8e.forEach(t),cno=i(L),Ag=n(L,"LI",{});var Q8e=s(Ag);qle=n(Q8e,"STRONG",{});var vft=s(qle);fno=r(vft,"retribert"),vft.forEach(t),mno=r(Q8e," \u2014 "),mB=n(Q8e,"A",{href:!0});var Fft=s(mB);gno=r(Fft,"RetriBertConfig"),Fft.forEach(t),hno=r(Q8e," (RetriBERT model)"),Q8e.forEach(t),pno=i(L),Lg=n(L,"LI",{});var H8e=s(Lg);jle=n(H8e,"STRONG",{});var Tft=s(jle);_no=r(Tft,"roberta"),Tft.forEach(t),uno=r(H8e," \u2014 "),gB=n(H8e,"A",{href:!0});var Mft=s(gB);bno=r(Mft,"RobertaConfig"),Mft.forEach(t),vno=r(H8e," (RoBERTa model)"),H8e.forEach(t),Fno=i(L),yg=n(L,"LI",{});var U8e=s(yg);Dle=n(U8e,"STRONG",{});var Eft=s(Dle);Tno=r(Eft,"roformer"),Eft.forEach(t),Mno=r(U8e," \u2014 "),hB=n(U8e,"A",{href:!0});var Cft=s(hB);Eno=r(Cft,"RoFormerConfig"),Cft.forEach(t),Cno=r(U8e," (RoFormer model)"),U8e.forEach(t),wno=i(L),xg=n(L,"LI",{});var J8e=s(xg);Gle=n(J8e,"STRONG",{});var wft=s(Gle);Ano=r(wft,"segformer"),wft.forEach(t),Lno=r(J8e," \u2014 "),pB=n(J8e,"A",{href:!0});var Aft=s(pB);yno=r(Aft,"SegformerConfig"),Aft.forEach(t),xno=r(J8e," (SegFormer model)"),J8e.forEach(t),$no=i(L),$g=n(L,"LI",{});var Y8e=s($g);Ole=n(Y8e,"STRONG",{});var Lft=s(Ole);kno=r(Lft,"sew"),Lft.forEach(t),Sno=r(Y8e," \u2014 "),_B=n(Y8e,"A",{href:!0});var yft=s(_B);Rno=r(yft,"SEWConfig"),yft.forEach(t),Pno=r(Y8e," (SEW model)"),Y8e.forEach(t),Bno=i(L),kg=n(L,"LI",{});var K8e=s(kg);Vle=n(K8e,"STRONG",{});var xft=s(Vle);Ino=r(xft,"sew-d"),xft.forEach(t),Nno=r(K8e," \u2014 "),uB=n(K8e,"A",{href:!0});var $ft=s(uB);qno=r($ft,"SEWDConfig"),$ft.forEach(t),jno=r(K8e," (SEW-D model)"),K8e.forEach(t),Dno=i(L),Sg=n(L,"LI",{});var Z8e=s(Sg);Xle=n(Z8e,"STRONG",{});var kft=s(Xle);Gno=r(kft,"speech-encoder-decoder"),kft.forEach(t),Ono=r(Z8e," \u2014 "),bB=n(Z8e,"A",{href:!0});var Sft=s(bB);Vno=r(Sft,"SpeechEncoderDecoderConfig"),Sft.forEach(t),Xno=r(Z8e," (Speech Encoder decoder model)"),Z8e.forEach(t),zno=i(L),Rg=n(L,"LI",{});var exe=s(Rg);zle=n(exe,"STRONG",{});var Rft=s(zle);Wno=r(Rft,"speech_to_text"),Rft.forEach(t),Qno=r(exe," \u2014 "),vB=n(exe,"A",{href:!0});var Pft=s(vB);Hno=r(Pft,"Speech2TextConfig"),Pft.forEach(t),Uno=r(exe," (Speech2Text model)"),exe.forEach(t),Jno=i(L),Pg=n(L,"LI",{});var oxe=s(Pg);Wle=n(oxe,"STRONG",{});var Bft=s(Wle);Yno=r(Bft,"speech_to_text_2"),Bft.forEach(t),Kno=r(oxe," \u2014 "),FB=n(oxe,"A",{href:!0});var Ift=s(FB);Zno=r(Ift,"Speech2Text2Config"),Ift.forEach(t),eso=r(oxe," (Speech2Text2 model)"),oxe.forEach(t),oso=i(L),Bg=n(L,"LI",{});var rxe=s(Bg);Qle=n(rxe,"STRONG",{});var Nft=s(Qle);rso=r(Nft,"splinter"),Nft.forEach(t),tso=r(rxe," \u2014 "),TB=n(rxe,"A",{href:!0});var qft=s(TB);aso=r(qft,"SplinterConfig"),qft.forEach(t),nso=r(rxe," (Splinter model)"),rxe.forEach(t),sso=i(L),Ig=n(L,"LI",{});var txe=s(Ig);Hle=n(txe,"STRONG",{});var jft=s(Hle);lso=r(jft,"squeezebert"),jft.forEach(t),iso=r(txe," \u2014 "),MB=n(txe,"A",{href:!0});var Dft=s(MB);dso=r(Dft,"SqueezeBertConfig"),Dft.forEach(t),cso=r(txe," (SqueezeBERT model)"),txe.forEach(t),fso=i(L),Ng=n(L,"LI",{});var axe=s(Ng);Ule=n(axe,"STRONG",{});var Gft=s(Ule);mso=r(Gft,"swin"),Gft.forEach(t),gso=r(axe," \u2014 "),EB=n(axe,"A",{href:!0});var Oft=s(EB);hso=r(Oft,"SwinConfig"),Oft.forEach(t),pso=r(axe," (Swin Transformer model)"),axe.forEach(t),_so=i(L),qg=n(L,"LI",{});var nxe=s(qg);Jle=n(nxe,"STRONG",{});var Vft=s(Jle);uso=r(Vft,"swinv2"),Vft.forEach(t),bso=r(nxe," \u2014 "),CB=n(nxe,"A",{href:!0});var Xft=s(CB);vso=r(Xft,"Swinv2Config"),Xft.forEach(t),Fso=r(nxe," (Swin Transformer V2 model)"),nxe.forEach(t),Tso=i(L),jg=n(L,"LI",{});var sxe=s(jg);Yle=n(sxe,"STRONG",{});var zft=s(Yle);Mso=r(zft,"t5"),zft.forEach(t),Eso=r(sxe," \u2014 "),wB=n(sxe,"A",{href:!0});var Wft=s(wB);Cso=r(Wft,"T5Config"),Wft.forEach(t),wso=r(sxe," (T5 model)"),sxe.forEach(t),Aso=i(L),Dg=n(L,"LI",{});var lxe=s(Dg);Kle=n(lxe,"STRONG",{});var Qft=s(Kle);Lso=r(Qft,"tapas"),Qft.forEach(t),yso=r(lxe," \u2014 "),AB=n(lxe,"A",{href:!0});var Hft=s(AB);xso=r(Hft,"TapasConfig"),Hft.forEach(t),$so=r(lxe," (TAPAS model)"),lxe.forEach(t),kso=i(L),Gg=n(L,"LI",{});var ixe=s(Gg);Zle=n(ixe,"STRONG",{});var Uft=s(Zle);Sso=r(Uft,"trajectory_transformer"),Uft.forEach(t),Rso=r(ixe," \u2014 "),LB=n(ixe,"A",{href:!0});var Jft=s(LB);Pso=r(Jft,"TrajectoryTransformerConfig"),Jft.forEach(t),Bso=r(ixe," (Trajectory Transformer model)"),ixe.forEach(t),Iso=i(L),Og=n(L,"LI",{});var dxe=s(Og);eie=n(dxe,"STRONG",{});var Yft=s(eie);Nso=r(Yft,"transfo-xl"),Yft.forEach(t),qso=r(dxe," \u2014 "),yB=n(dxe,"A",{href:!0});var Kft=s(yB);jso=r(Kft,"TransfoXLConfig"),Kft.forEach(t),Dso=r(dxe," (Transformer-XL model)"),dxe.forEach(t),Gso=i(L),Vg=n(L,"LI",{});var cxe=s(Vg);oie=n(cxe,"STRONG",{});var Zft=s(oie);Oso=r(Zft,"trocr"),Zft.forEach(t),Vso=r(cxe," \u2014 "),xB=n(cxe,"A",{href:!0});var emt=s(xB);Xso=r(emt,"TrOCRConfig"),emt.forEach(t),zso=r(cxe," (TrOCR model)"),cxe.forEach(t),Wso=i(L),Xg=n(L,"LI",{});var fxe=s(Xg);rie=n(fxe,"STRONG",{});var omt=s(rie);Qso=r(omt,"unispeech"),omt.forEach(t),Hso=r(fxe," \u2014 "),$B=n(fxe,"A",{href:!0});var rmt=s($B);Uso=r(rmt,"UniSpeechConfig"),rmt.forEach(t),Jso=r(fxe," (UniSpeech model)"),fxe.forEach(t),Yso=i(L),zg=n(L,"LI",{});var mxe=s(zg);tie=n(mxe,"STRONG",{});var tmt=s(tie);Kso=r(tmt,"unispeech-sat"),tmt.forEach(t),Zso=r(mxe," \u2014 "),kB=n(mxe,"A",{href:!0});var amt=s(kB);elo=r(amt,"UniSpeechSatConfig"),amt.forEach(t),olo=r(mxe," (UniSpeechSat model)"),mxe.forEach(t),rlo=i(L),Wg=n(L,"LI",{});var gxe=s(Wg);aie=n(gxe,"STRONG",{});var nmt=s(aie);tlo=r(nmt,"van"),nmt.forEach(t),alo=r(gxe," \u2014 "),SB=n(gxe,"A",{href:!0});var smt=s(SB);nlo=r(smt,"VanConfig"),smt.forEach(t),slo=r(gxe," (VAN model)"),gxe.forEach(t),llo=i(L),Qg=n(L,"LI",{});var hxe=s(Qg);nie=n(hxe,"STRONG",{});var lmt=s(nie);ilo=r(lmt,"videomae"),lmt.forEach(t),dlo=r(hxe," \u2014 "),RB=n(hxe,"A",{href:!0});var imt=s(RB);clo=r(imt,"VideoMAEConfig"),imt.forEach(t),flo=r(hxe," (VideoMAE model)"),hxe.forEach(t),mlo=i(L),Hg=n(L,"LI",{});var pxe=s(Hg);sie=n(pxe,"STRONG",{});var dmt=s(sie);glo=r(dmt,"vilt"),dmt.forEach(t),hlo=r(pxe," \u2014 "),PB=n(pxe,"A",{href:!0});var cmt=s(PB);plo=r(cmt,"ViltConfig"),cmt.forEach(t),_lo=r(pxe," (ViLT model)"),pxe.forEach(t),ulo=i(L),Ug=n(L,"LI",{});var _xe=s(Ug);lie=n(_xe,"STRONG",{});var fmt=s(lie);blo=r(fmt,"vision-encoder-decoder"),fmt.forEach(t),vlo=r(_xe," \u2014 "),BB=n(_xe,"A",{href:!0});var mmt=s(BB);Flo=r(mmt,"VisionEncoderDecoderConfig"),mmt.forEach(t),Tlo=r(_xe," (Vision Encoder decoder model)"),_xe.forEach(t),Mlo=i(L),Jg=n(L,"LI",{});var uxe=s(Jg);iie=n(uxe,"STRONG",{});var gmt=s(iie);Elo=r(gmt,"vision-text-dual-encoder"),gmt.forEach(t),Clo=r(uxe," \u2014 "),IB=n(uxe,"A",{href:!0});var hmt=s(IB);wlo=r(hmt,"VisionTextDualEncoderConfig"),hmt.forEach(t),Alo=r(uxe," (VisionTextDualEncoder model)"),uxe.forEach(t),Llo=i(L),Yg=n(L,"LI",{});var bxe=s(Yg);die=n(bxe,"STRONG",{});var pmt=s(die);ylo=r(pmt,"visual_bert"),pmt.forEach(t),xlo=r(bxe," \u2014 "),NB=n(bxe,"A",{href:!0});var _mt=s(NB);$lo=r(_mt,"VisualBertConfig"),_mt.forEach(t),klo=r(bxe," (VisualBERT model)"),bxe.forEach(t),Slo=i(L),Kg=n(L,"LI",{});var vxe=s(Kg);cie=n(vxe,"STRONG",{});var umt=s(cie);Rlo=r(umt,"vit"),umt.forEach(t),Plo=r(vxe," \u2014 "),qB=n(vxe,"A",{href:!0});var bmt=s(qB);Blo=r(bmt,"ViTConfig"),bmt.forEach(t),Ilo=r(vxe," (ViT model)"),vxe.forEach(t),Nlo=i(L),Zg=n(L,"LI",{});var Fxe=s(Zg);fie=n(Fxe,"STRONG",{});var vmt=s(fie);qlo=r(vmt,"vit_mae"),vmt.forEach(t),jlo=r(Fxe," \u2014 "),jB=n(Fxe,"A",{href:!0});var Fmt=s(jB);Dlo=r(Fmt,"ViTMAEConfig"),Fmt.forEach(t),Glo=r(Fxe," (ViTMAE model)"),Fxe.forEach(t),Olo=i(L),eh=n(L,"LI",{});var Txe=s(eh);mie=n(Txe,"STRONG",{});var Tmt=s(mie);Vlo=r(Tmt,"wav2vec2"),Tmt.forEach(t),Xlo=r(Txe," \u2014 "),DB=n(Txe,"A",{href:!0});var Mmt=s(DB);zlo=r(Mmt,"Wav2Vec2Config"),Mmt.forEach(t),Wlo=r(Txe," (Wav2Vec2 model)"),Txe.forEach(t),Qlo=i(L),oh=n(L,"LI",{});var Mxe=s(oh);gie=n(Mxe,"STRONG",{});var Emt=s(gie);Hlo=r(Emt,"wav2vec2-conformer"),Emt.forEach(t),Ulo=r(Mxe," \u2014 "),GB=n(Mxe,"A",{href:!0});var Cmt=s(GB);Jlo=r(Cmt,"Wav2Vec2ConformerConfig"),Cmt.forEach(t),Ylo=r(Mxe," (Wav2Vec2-Conformer model)"),Mxe.forEach(t),Klo=i(L),rh=n(L,"LI",{});var Exe=s(rh);hie=n(Exe,"STRONG",{});var wmt=s(hie);Zlo=r(wmt,"wavlm"),wmt.forEach(t),eio=r(Exe," \u2014 "),OB=n(Exe,"A",{href:!0});var Amt=s(OB);oio=r(Amt,"WavLMConfig"),Amt.forEach(t),rio=r(Exe," (WavLM model)"),Exe.forEach(t),tio=i(L),th=n(L,"LI",{});var Cxe=s(th);pie=n(Cxe,"STRONG",{});var Lmt=s(pie);aio=r(Lmt,"xglm"),Lmt.forEach(t),nio=r(Cxe," \u2014 "),VB=n(Cxe,"A",{href:!0});var ymt=s(VB);sio=r(ymt,"XGLMConfig"),ymt.forEach(t),lio=r(Cxe," (XGLM model)"),Cxe.forEach(t),iio=i(L),ah=n(L,"LI",{});var wxe=s(ah);_ie=n(wxe,"STRONG",{});var xmt=s(_ie);dio=r(xmt,"xlm"),xmt.forEach(t),cio=r(wxe," \u2014 "),XB=n(wxe,"A",{href:!0});var $mt=s(XB);fio=r($mt,"XLMConfig"),$mt.forEach(t),mio=r(wxe," (XLM model)"),wxe.forEach(t),gio=i(L),nh=n(L,"LI",{});var Axe=s(nh);uie=n(Axe,"STRONG",{});var kmt=s(uie);hio=r(kmt,"xlm-prophetnet"),kmt.forEach(t),pio=r(Axe," \u2014 "),zB=n(Axe,"A",{href:!0});var Smt=s(zB);_io=r(Smt,"XLMProphetNetConfig"),Smt.forEach(t),uio=r(Axe," (XLM-ProphetNet model)"),Axe.forEach(t),bio=i(L),sh=n(L,"LI",{});var Lxe=s(sh);bie=n(Lxe,"STRONG",{});var Rmt=s(bie);vio=r(Rmt,"xlm-roberta"),Rmt.forEach(t),Fio=r(Lxe," \u2014 "),WB=n(Lxe,"A",{href:!0});var Pmt=s(WB);Tio=r(Pmt,"XLMRobertaConfig"),Pmt.forEach(t),Mio=r(Lxe," (XLM-RoBERTa model)"),Lxe.forEach(t),Eio=i(L),lh=n(L,"LI",{});var yxe=s(lh);vie=n(yxe,"STRONG",{});var Bmt=s(vie);Cio=r(Bmt,"xlm-roberta-xl"),Bmt.forEach(t),wio=r(yxe," \u2014 "),QB=n(yxe,"A",{href:!0});var Imt=s(QB);Aio=r(Imt,"XLMRobertaXLConfig"),Imt.forEach(t),Lio=r(yxe," (XLM-RoBERTa-XL model)"),yxe.forEach(t),yio=i(L),ih=n(L,"LI",{});var xxe=s(ih);Fie=n(xxe,"STRONG",{});var Nmt=s(Fie);xio=r(Nmt,"xlnet"),Nmt.forEach(t),$io=r(xxe," \u2014 "),HB=n(xxe,"A",{href:!0});var qmt=s(HB);kio=r(qmt,"XLNetConfig"),qmt.forEach(t),Sio=r(xxe," (XLNet model)"),xxe.forEach(t),Rio=i(L),dh=n(L,"LI",{});var $xe=s(dh);Tie=n($xe,"STRONG",{});var jmt=s(Tie);Pio=r(jmt,"yolos"),jmt.forEach(t),Bio=r($xe," \u2014 "),UB=n($xe,"A",{href:!0});var Dmt=s(UB);Iio=r(Dmt,"YolosConfig"),Dmt.forEach(t),Nio=r($xe," (YOLOS model)"),$xe.forEach(t),qio=i(L),ch=n(L,"LI",{});var kxe=s(ch);Mie=n(kxe,"STRONG",{});var Gmt=s(Mie);jio=r(Gmt,"yoso"),Gmt.forEach(t),Dio=r(kxe," \u2014 "),JB=n(kxe,"A",{href:!0});var Omt=s(JB);Gio=r(Omt,"YosoConfig"),Omt.forEach(t),Oio=r(kxe," (YOSO model)"),kxe.forEach(t),L.forEach(t),Vio=i(it),T(fh.$$.fragment,it),it.forEach(t),Xio=i(lt),mh=n(lt,"DIV",{class:!0});var QHe=s(mh);T(ey.$$.fragment,QHe),zio=i(QHe),Eie=n(QHe,"P",{});var Vmt=s(Eie);Wio=r(Vmt,"Register a new configuration for this class."),Vmt.forEach(t),QHe.forEach(t),lt.forEach(t),WWe=i(f),Wi=n(f,"H2",{class:!0});var HHe=s(Wi);gh=n(HHe,"A",{id:!0,class:!0,href:!0});var Xmt=s(gh);Cie=n(Xmt,"SPAN",{});var zmt=s(Cie);T(oy.$$.fragment,zmt),zmt.forEach(t),Xmt.forEach(t),Qio=i(HHe),wie=n(HHe,"SPAN",{});var Wmt=s(wie);Hio=r(Wmt,"AutoTokenizer"),Wmt.forEach(t),HHe.forEach(t),QWe=i(f),xo=n(f,"DIV",{class:!0});var sl=s(xo);T(ry.$$.fragment,sl),Uio=i(sl),ty=n(sl,"P",{});var UHe=s(ty);Jio=r(UHe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),YB=n(UHe,"A",{href:!0});var Qmt=s(YB);Yio=r(Qmt,"AutoTokenizer.from_pretrained()"),Qmt.forEach(t),Kio=r(UHe," class method."),UHe.forEach(t),Zio=i(sl),ay=n(sl,"P",{});var JHe=s(ay);edo=r(JHe,"This class cannot be instantiated directly using "),Aie=n(JHe,"CODE",{});var Hmt=s(Aie);odo=r(Hmt,"__init__()"),Hmt.forEach(t),rdo=r(JHe," (throws an error)."),JHe.forEach(t),tdo=i(sl),kr=n(sl,"DIV",{class:!0});var ll=s(kr);T(ny.$$.fragment,ll),ado=i(ll),Lie=n(ll,"P",{});var Umt=s(Lie);ndo=r(Umt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Umt.forEach(t),sdo=i(ll),qa=n(ll,"P",{});var W6=s(qa);ldo=r(W6,"The tokenizer class to instantiate is selected based on the "),yie=n(W6,"CODE",{});var Jmt=s(yie);ido=r(Jmt,"model_type"),Jmt.forEach(t),ddo=r(W6,` property of the config object (either
passed as an argument or loaded from `),xie=n(W6,"CODE",{});var Ymt=s(xie);cdo=r(Ymt,"pretrained_model_name_or_path"),Ymt.forEach(t),fdo=r(W6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$ie=n(W6,"CODE",{});var Kmt=s($ie);mdo=r(Kmt,"pretrained_model_name_or_path"),Kmt.forEach(t),gdo=r(W6,":"),W6.forEach(t),hdo=i(ll),k=n(ll,"UL",{});var S=s(k);zn=n(S,"LI",{});var _S=s(zn);kie=n(_S,"STRONG",{});var Zmt=s(kie);pdo=r(Zmt,"albert"),Zmt.forEach(t),_do=r(_S," \u2014 "),KB=n(_S,"A",{href:!0});var egt=s(KB);udo=r(egt,"AlbertTokenizer"),egt.forEach(t),bdo=r(_S," or "),ZB=n(_S,"A",{href:!0});var ogt=s(ZB);vdo=r(ogt,"AlbertTokenizerFast"),ogt.forEach(t),Fdo=r(_S," (ALBERT model)"),_S.forEach(t),Tdo=i(S),Wn=n(S,"LI",{});var uS=s(Wn);Sie=n(uS,"STRONG",{});var rgt=s(Sie);Mdo=r(rgt,"bart"),rgt.forEach(t),Edo=r(uS," \u2014 "),eI=n(uS,"A",{href:!0});var tgt=s(eI);Cdo=r(tgt,"BartTokenizer"),tgt.forEach(t),wdo=r(uS," or "),oI=n(uS,"A",{href:!0});var agt=s(oI);Ado=r(agt,"BartTokenizerFast"),agt.forEach(t),Ldo=r(uS," (BART model)"),uS.forEach(t),ydo=i(S),Qn=n(S,"LI",{});var bS=s(Qn);Rie=n(bS,"STRONG",{});var ngt=s(Rie);xdo=r(ngt,"barthez"),ngt.forEach(t),$do=r(bS," \u2014 "),rI=n(bS,"A",{href:!0});var sgt=s(rI);kdo=r(sgt,"BarthezTokenizer"),sgt.forEach(t),Sdo=r(bS," or "),tI=n(bS,"A",{href:!0});var lgt=s(tI);Rdo=r(lgt,"BarthezTokenizerFast"),lgt.forEach(t),Pdo=r(bS," (BARThez model)"),bS.forEach(t),Bdo=i(S),hh=n(S,"LI",{});var Sxe=s(hh);Pie=n(Sxe,"STRONG",{});var igt=s(Pie);Ido=r(igt,"bartpho"),igt.forEach(t),Ndo=r(Sxe," \u2014 "),aI=n(Sxe,"A",{href:!0});var dgt=s(aI);qdo=r(dgt,"BartphoTokenizer"),dgt.forEach(t),jdo=r(Sxe," (BARTpho model)"),Sxe.forEach(t),Ddo=i(S),Hn=n(S,"LI",{});var vS=s(Hn);Bie=n(vS,"STRONG",{});var cgt=s(Bie);Gdo=r(cgt,"bert"),cgt.forEach(t),Odo=r(vS," \u2014 "),nI=n(vS,"A",{href:!0});var fgt=s(nI);Vdo=r(fgt,"BertTokenizer"),fgt.forEach(t),Xdo=r(vS," or "),sI=n(vS,"A",{href:!0});var mgt=s(sI);zdo=r(mgt,"BertTokenizerFast"),mgt.forEach(t),Wdo=r(vS," (BERT model)"),vS.forEach(t),Qdo=i(S),ph=n(S,"LI",{});var Rxe=s(ph);Iie=n(Rxe,"STRONG",{});var ggt=s(Iie);Hdo=r(ggt,"bert-generation"),ggt.forEach(t),Udo=r(Rxe," \u2014 "),lI=n(Rxe,"A",{href:!0});var hgt=s(lI);Jdo=r(hgt,"BertGenerationTokenizer"),hgt.forEach(t),Ydo=r(Rxe," (Bert Generation model)"),Rxe.forEach(t),Kdo=i(S),_h=n(S,"LI",{});var Pxe=s(_h);Nie=n(Pxe,"STRONG",{});var pgt=s(Nie);Zdo=r(pgt,"bert-japanese"),pgt.forEach(t),eco=r(Pxe," \u2014 "),iI=n(Pxe,"A",{href:!0});var _gt=s(iI);oco=r(_gt,"BertJapaneseTokenizer"),_gt.forEach(t),rco=r(Pxe," (BertJapanese model)"),Pxe.forEach(t),tco=i(S),uh=n(S,"LI",{});var Bxe=s(uh);qie=n(Bxe,"STRONG",{});var ugt=s(qie);aco=r(ugt,"bertweet"),ugt.forEach(t),nco=r(Bxe," \u2014 "),dI=n(Bxe,"A",{href:!0});var bgt=s(dI);sco=r(bgt,"BertweetTokenizer"),bgt.forEach(t),lco=r(Bxe," (BERTweet model)"),Bxe.forEach(t),ico=i(S),Un=n(S,"LI",{});var FS=s(Un);jie=n(FS,"STRONG",{});var vgt=s(jie);dco=r(vgt,"big_bird"),vgt.forEach(t),cco=r(FS," \u2014 "),cI=n(FS,"A",{href:!0});var Fgt=s(cI);fco=r(Fgt,"BigBirdTokenizer"),Fgt.forEach(t),mco=r(FS," or "),fI=n(FS,"A",{href:!0});var Tgt=s(fI);gco=r(Tgt,"BigBirdTokenizerFast"),Tgt.forEach(t),hco=r(FS," (BigBird model)"),FS.forEach(t),pco=i(S),Jn=n(S,"LI",{});var TS=s(Jn);Die=n(TS,"STRONG",{});var Mgt=s(Die);_co=r(Mgt,"bigbird_pegasus"),Mgt.forEach(t),uco=r(TS," \u2014 "),mI=n(TS,"A",{href:!0});var Egt=s(mI);bco=r(Egt,"PegasusTokenizer"),Egt.forEach(t),vco=r(TS," or "),gI=n(TS,"A",{href:!0});var Cgt=s(gI);Fco=r(Cgt,"PegasusTokenizerFast"),Cgt.forEach(t),Tco=r(TS," (BigBird-Pegasus model)"),TS.forEach(t),Mco=i(S),Yn=n(S,"LI",{});var MS=s(Yn);Gie=n(MS,"STRONG",{});var wgt=s(Gie);Eco=r(wgt,"blenderbot"),wgt.forEach(t),Cco=r(MS," \u2014 "),hI=n(MS,"A",{href:!0});var Agt=s(hI);wco=r(Agt,"BlenderbotTokenizer"),Agt.forEach(t),Aco=r(MS," or "),pI=n(MS,"A",{href:!0});var Lgt=s(pI);Lco=r(Lgt,"BlenderbotTokenizerFast"),Lgt.forEach(t),yco=r(MS," (Blenderbot model)"),MS.forEach(t),xco=i(S),bh=n(S,"LI",{});var Ixe=s(bh);Oie=n(Ixe,"STRONG",{});var ygt=s(Oie);$co=r(ygt,"blenderbot-small"),ygt.forEach(t),kco=r(Ixe," \u2014 "),_I=n(Ixe,"A",{href:!0});var xgt=s(_I);Sco=r(xgt,"BlenderbotSmallTokenizer"),xgt.forEach(t),Rco=r(Ixe," (BlenderbotSmall model)"),Ixe.forEach(t),Pco=i(S),vh=n(S,"LI",{});var Nxe=s(vh);Vie=n(Nxe,"STRONG",{});var $gt=s(Vie);Bco=r($gt,"bloom"),$gt.forEach(t),Ico=r(Nxe," \u2014 "),uI=n(Nxe,"A",{href:!0});var kgt=s(uI);Nco=r(kgt,"BloomTokenizerFast"),kgt.forEach(t),qco=r(Nxe," (BLOOM model)"),Nxe.forEach(t),jco=i(S),Fh=n(S,"LI",{});var qxe=s(Fh);Xie=n(qxe,"STRONG",{});var Sgt=s(Xie);Dco=r(Sgt,"byt5"),Sgt.forEach(t),Gco=r(qxe," \u2014 "),bI=n(qxe,"A",{href:!0});var Rgt=s(bI);Oco=r(Rgt,"ByT5Tokenizer"),Rgt.forEach(t),Vco=r(qxe," (ByT5 model)"),qxe.forEach(t),Xco=i(S),Kn=n(S,"LI",{});var ES=s(Kn);zie=n(ES,"STRONG",{});var Pgt=s(zie);zco=r(Pgt,"camembert"),Pgt.forEach(t),Wco=r(ES," \u2014 "),vI=n(ES,"A",{href:!0});var Bgt=s(vI);Qco=r(Bgt,"CamembertTokenizer"),Bgt.forEach(t),Hco=r(ES," or "),FI=n(ES,"A",{href:!0});var Igt=s(FI);Uco=r(Igt,"CamembertTokenizerFast"),Igt.forEach(t),Jco=r(ES," (CamemBERT model)"),ES.forEach(t),Yco=i(S),Th=n(S,"LI",{});var jxe=s(Th);Wie=n(jxe,"STRONG",{});var Ngt=s(Wie);Kco=r(Ngt,"canine"),Ngt.forEach(t),Zco=r(jxe," \u2014 "),TI=n(jxe,"A",{href:!0});var qgt=s(TI);efo=r(qgt,"CanineTokenizer"),qgt.forEach(t),ofo=r(jxe," (CANINE model)"),jxe.forEach(t),rfo=i(S),Zn=n(S,"LI",{});var CS=s(Zn);Qie=n(CS,"STRONG",{});var jgt=s(Qie);tfo=r(jgt,"clip"),jgt.forEach(t),afo=r(CS," \u2014 "),MI=n(CS,"A",{href:!0});var Dgt=s(MI);nfo=r(Dgt,"CLIPTokenizer"),Dgt.forEach(t),sfo=r(CS," or "),EI=n(CS,"A",{href:!0});var Ggt=s(EI);lfo=r(Ggt,"CLIPTokenizerFast"),Ggt.forEach(t),ifo=r(CS," (CLIP model)"),CS.forEach(t),dfo=i(S),es=n(S,"LI",{});var wS=s(es);Hie=n(wS,"STRONG",{});var Ogt=s(Hie);cfo=r(Ogt,"codegen"),Ogt.forEach(t),ffo=r(wS," \u2014 "),CI=n(wS,"A",{href:!0});var Vgt=s(CI);mfo=r(Vgt,"CodeGenTokenizer"),Vgt.forEach(t),gfo=r(wS," or "),wI=n(wS,"A",{href:!0});var Xgt=s(wI);hfo=r(Xgt,"CodeGenTokenizerFast"),Xgt.forEach(t),pfo=r(wS," (CodeGen model)"),wS.forEach(t),_fo=i(S),os=n(S,"LI",{});var AS=s(os);Uie=n(AS,"STRONG",{});var zgt=s(Uie);ufo=r(zgt,"convbert"),zgt.forEach(t),bfo=r(AS," \u2014 "),AI=n(AS,"A",{href:!0});var Wgt=s(AI);vfo=r(Wgt,"ConvBertTokenizer"),Wgt.forEach(t),Ffo=r(AS," or "),LI=n(AS,"A",{href:!0});var Qgt=s(LI);Tfo=r(Qgt,"ConvBertTokenizerFast"),Qgt.forEach(t),Mfo=r(AS," (ConvBERT model)"),AS.forEach(t),Efo=i(S),rs=n(S,"LI",{});var LS=s(rs);Jie=n(LS,"STRONG",{});var Hgt=s(Jie);Cfo=r(Hgt,"cpm"),Hgt.forEach(t),wfo=r(LS," \u2014 "),yI=n(LS,"A",{href:!0});var Ugt=s(yI);Afo=r(Ugt,"CpmTokenizer"),Ugt.forEach(t),Lfo=r(LS," or "),xI=n(LS,"A",{href:!0});var Jgt=s(xI);yfo=r(Jgt,"CpmTokenizerFast"),Jgt.forEach(t),xfo=r(LS," (CPM model)"),LS.forEach(t),$fo=i(S),Mh=n(S,"LI",{});var Dxe=s(Mh);Yie=n(Dxe,"STRONG",{});var Ygt=s(Yie);kfo=r(Ygt,"ctrl"),Ygt.forEach(t),Sfo=r(Dxe," \u2014 "),$I=n(Dxe,"A",{href:!0});var Kgt=s($I);Rfo=r(Kgt,"CTRLTokenizer"),Kgt.forEach(t),Pfo=r(Dxe," (CTRL model)"),Dxe.forEach(t),Bfo=i(S),ts=n(S,"LI",{});var yS=s(ts);Kie=n(yS,"STRONG",{});var Zgt=s(Kie);Ifo=r(Zgt,"data2vec-text"),Zgt.forEach(t),Nfo=r(yS," \u2014 "),kI=n(yS,"A",{href:!0});var eht=s(kI);qfo=r(eht,"RobertaTokenizer"),eht.forEach(t),jfo=r(yS," or "),SI=n(yS,"A",{href:!0});var oht=s(SI);Dfo=r(oht,"RobertaTokenizerFast"),oht.forEach(t),Gfo=r(yS," (Data2VecText model)"),yS.forEach(t),Ofo=i(S),as=n(S,"LI",{});var xS=s(as);Zie=n(xS,"STRONG",{});var rht=s(Zie);Vfo=r(rht,"deberta"),rht.forEach(t),Xfo=r(xS," \u2014 "),RI=n(xS,"A",{href:!0});var tht=s(RI);zfo=r(tht,"DebertaTokenizer"),tht.forEach(t),Wfo=r(xS," or "),PI=n(xS,"A",{href:!0});var aht=s(PI);Qfo=r(aht,"DebertaTokenizerFast"),aht.forEach(t),Hfo=r(xS," (DeBERTa model)"),xS.forEach(t),Ufo=i(S),ns=n(S,"LI",{});var $S=s(ns);ede=n($S,"STRONG",{});var nht=s(ede);Jfo=r(nht,"deberta-v2"),nht.forEach(t),Yfo=r($S," \u2014 "),BI=n($S,"A",{href:!0});var sht=s(BI);Kfo=r(sht,"DebertaV2Tokenizer"),sht.forEach(t),Zfo=r($S," or "),II=n($S,"A",{href:!0});var lht=s(II);emo=r(lht,"DebertaV2TokenizerFast"),lht.forEach(t),omo=r($S," (DeBERTa-v2 model)"),$S.forEach(t),rmo=i(S),ss=n(S,"LI",{});var kS=s(ss);ode=n(kS,"STRONG",{});var iht=s(ode);tmo=r(iht,"distilbert"),iht.forEach(t),amo=r(kS," \u2014 "),NI=n(kS,"A",{href:!0});var dht=s(NI);nmo=r(dht,"DistilBertTokenizer"),dht.forEach(t),smo=r(kS," or "),qI=n(kS,"A",{href:!0});var cht=s(qI);lmo=r(cht,"DistilBertTokenizerFast"),cht.forEach(t),imo=r(kS," (DistilBERT model)"),kS.forEach(t),dmo=i(S),ls=n(S,"LI",{});var SS=s(ls);rde=n(SS,"STRONG",{});var fht=s(rde);cmo=r(fht,"dpr"),fht.forEach(t),fmo=r(SS," \u2014 "),jI=n(SS,"A",{href:!0});var mht=s(jI);mmo=r(mht,"DPRQuestionEncoderTokenizer"),mht.forEach(t),gmo=r(SS," or "),DI=n(SS,"A",{href:!0});var ght=s(DI);hmo=r(ght,"DPRQuestionEncoderTokenizerFast"),ght.forEach(t),pmo=r(SS," (DPR model)"),SS.forEach(t),_mo=i(S),is=n(S,"LI",{});var RS=s(is);tde=n(RS,"STRONG",{});var hht=s(tde);umo=r(hht,"electra"),hht.forEach(t),bmo=r(RS," \u2014 "),GI=n(RS,"A",{href:!0});var pht=s(GI);vmo=r(pht,"ElectraTokenizer"),pht.forEach(t),Fmo=r(RS," or "),OI=n(RS,"A",{href:!0});var _ht=s(OI);Tmo=r(_ht,"ElectraTokenizerFast"),_ht.forEach(t),Mmo=r(RS," (ELECTRA model)"),RS.forEach(t),Emo=i(S),Eh=n(S,"LI",{});var Gxe=s(Eh);ade=n(Gxe,"STRONG",{});var uht=s(ade);Cmo=r(uht,"flaubert"),uht.forEach(t),wmo=r(Gxe," \u2014 "),VI=n(Gxe,"A",{href:!0});var bht=s(VI);Amo=r(bht,"FlaubertTokenizer"),bht.forEach(t),Lmo=r(Gxe," (FlauBERT model)"),Gxe.forEach(t),ymo=i(S),ds=n(S,"LI",{});var PS=s(ds);nde=n(PS,"STRONG",{});var vht=s(nde);xmo=r(vht,"fnet"),vht.forEach(t),$mo=r(PS," \u2014 "),XI=n(PS,"A",{href:!0});var Fht=s(XI);kmo=r(Fht,"FNetTokenizer"),Fht.forEach(t),Smo=r(PS," or "),zI=n(PS,"A",{href:!0});var Tht=s(zI);Rmo=r(Tht,"FNetTokenizerFast"),Tht.forEach(t),Pmo=r(PS," (FNet model)"),PS.forEach(t),Bmo=i(S),Ch=n(S,"LI",{});var Oxe=s(Ch);sde=n(Oxe,"STRONG",{});var Mht=s(sde);Imo=r(Mht,"fsmt"),Mht.forEach(t),Nmo=r(Oxe," \u2014 "),WI=n(Oxe,"A",{href:!0});var Eht=s(WI);qmo=r(Eht,"FSMTTokenizer"),Eht.forEach(t),jmo=r(Oxe," (FairSeq Machine-Translation model)"),Oxe.forEach(t),Dmo=i(S),cs=n(S,"LI",{});var BS=s(cs);lde=n(BS,"STRONG",{});var Cht=s(lde);Gmo=r(Cht,"funnel"),Cht.forEach(t),Omo=r(BS," \u2014 "),QI=n(BS,"A",{href:!0});var wht=s(QI);Vmo=r(wht,"FunnelTokenizer"),wht.forEach(t),Xmo=r(BS," or "),HI=n(BS,"A",{href:!0});var Aht=s(HI);zmo=r(Aht,"FunnelTokenizerFast"),Aht.forEach(t),Wmo=r(BS," (Funnel Transformer model)"),BS.forEach(t),Qmo=i(S),fs=n(S,"LI",{});var IS=s(fs);ide=n(IS,"STRONG",{});var Lht=s(ide);Hmo=r(Lht,"gpt2"),Lht.forEach(t),Umo=r(IS," \u2014 "),UI=n(IS,"A",{href:!0});var yht=s(UI);Jmo=r(yht,"GPT2Tokenizer"),yht.forEach(t),Ymo=r(IS," or "),JI=n(IS,"A",{href:!0});var xht=s(JI);Kmo=r(xht,"GPT2TokenizerFast"),xht.forEach(t),Zmo=r(IS," (OpenAI GPT-2 model)"),IS.forEach(t),ego=i(S),ms=n(S,"LI",{});var NS=s(ms);dde=n(NS,"STRONG",{});var $ht=s(dde);ogo=r($ht,"gpt_neo"),$ht.forEach(t),rgo=r(NS," \u2014 "),YI=n(NS,"A",{href:!0});var kht=s(YI);tgo=r(kht,"GPT2Tokenizer"),kht.forEach(t),ago=r(NS," or "),KI=n(NS,"A",{href:!0});var Sht=s(KI);ngo=r(Sht,"GPT2TokenizerFast"),Sht.forEach(t),sgo=r(NS," (GPT Neo model)"),NS.forEach(t),lgo=i(S),wh=n(S,"LI",{});var Vxe=s(wh);cde=n(Vxe,"STRONG",{});var Rht=s(cde);igo=r(Rht,"gpt_neox"),Rht.forEach(t),dgo=r(Vxe," \u2014 "),ZI=n(Vxe,"A",{href:!0});var Pht=s(ZI);cgo=r(Pht,"GPTNeoXTokenizerFast"),Pht.forEach(t),fgo=r(Vxe," (GPT NeoX model)"),Vxe.forEach(t),mgo=i(S),gs=n(S,"LI",{});var qS=s(gs);fde=n(qS,"STRONG",{});var Bht=s(fde);ggo=r(Bht,"gptj"),Bht.forEach(t),hgo=r(qS," \u2014 "),eN=n(qS,"A",{href:!0});var Iht=s(eN);pgo=r(Iht,"GPT2Tokenizer"),Iht.forEach(t),_go=r(qS," or "),oN=n(qS,"A",{href:!0});var Nht=s(oN);ugo=r(Nht,"GPT2TokenizerFast"),Nht.forEach(t),bgo=r(qS," (GPT-J model)"),qS.forEach(t),vgo=i(S),hs=n(S,"LI",{});var jS=s(hs);mde=n(jS,"STRONG",{});var qht=s(mde);Fgo=r(qht,"groupvit"),qht.forEach(t),Tgo=r(jS," \u2014 "),rN=n(jS,"A",{href:!0});var jht=s(rN);Mgo=r(jht,"CLIPTokenizer"),jht.forEach(t),Ego=r(jS," or "),tN=n(jS,"A",{href:!0});var Dht=s(tN);Cgo=r(Dht,"CLIPTokenizerFast"),Dht.forEach(t),wgo=r(jS," (GroupViT model)"),jS.forEach(t),Ago=i(S),ps=n(S,"LI",{});var DS=s(ps);gde=n(DS,"STRONG",{});var Ght=s(gde);Lgo=r(Ght,"herbert"),Ght.forEach(t),ygo=r(DS," \u2014 "),aN=n(DS,"A",{href:!0});var Oht=s(aN);xgo=r(Oht,"HerbertTokenizer"),Oht.forEach(t),$go=r(DS," or "),nN=n(DS,"A",{href:!0});var Vht=s(nN);kgo=r(Vht,"HerbertTokenizerFast"),Vht.forEach(t),Sgo=r(DS," (HerBERT model)"),DS.forEach(t),Rgo=i(S),Ah=n(S,"LI",{});var Xxe=s(Ah);hde=n(Xxe,"STRONG",{});var Xht=s(hde);Pgo=r(Xht,"hubert"),Xht.forEach(t),Bgo=r(Xxe," \u2014 "),sN=n(Xxe,"A",{href:!0});var zht=s(sN);Igo=r(zht,"Wav2Vec2CTCTokenizer"),zht.forEach(t),Ngo=r(Xxe," (Hubert model)"),Xxe.forEach(t),qgo=i(S),_s=n(S,"LI",{});var GS=s(_s);pde=n(GS,"STRONG",{});var Wht=s(pde);jgo=r(Wht,"ibert"),Wht.forEach(t),Dgo=r(GS," \u2014 "),lN=n(GS,"A",{href:!0});var Qht=s(lN);Ggo=r(Qht,"RobertaTokenizer"),Qht.forEach(t),Ogo=r(GS," or "),iN=n(GS,"A",{href:!0});var Hht=s(iN);Vgo=r(Hht,"RobertaTokenizerFast"),Hht.forEach(t),Xgo=r(GS," (I-BERT model)"),GS.forEach(t),zgo=i(S),us=n(S,"LI",{});var OS=s(us);_de=n(OS,"STRONG",{});var Uht=s(_de);Wgo=r(Uht,"layoutlm"),Uht.forEach(t),Qgo=r(OS," \u2014 "),dN=n(OS,"A",{href:!0});var Jht=s(dN);Hgo=r(Jht,"LayoutLMTokenizer"),Jht.forEach(t),Ugo=r(OS," or "),cN=n(OS,"A",{href:!0});var Yht=s(cN);Jgo=r(Yht,"LayoutLMTokenizerFast"),Yht.forEach(t),Ygo=r(OS," (LayoutLM model)"),OS.forEach(t),Kgo=i(S),bs=n(S,"LI",{});var VS=s(bs);ude=n(VS,"STRONG",{});var Kht=s(ude);Zgo=r(Kht,"layoutlmv2"),Kht.forEach(t),eho=r(VS," \u2014 "),fN=n(VS,"A",{href:!0});var Zht=s(fN);oho=r(Zht,"LayoutLMv2Tokenizer"),Zht.forEach(t),rho=r(VS," or "),mN=n(VS,"A",{href:!0});var ept=s(mN);tho=r(ept,"LayoutLMv2TokenizerFast"),ept.forEach(t),aho=r(VS," (LayoutLMv2 model)"),VS.forEach(t),nho=i(S),vs=n(S,"LI",{});var XS=s(vs);bde=n(XS,"STRONG",{});var opt=s(bde);sho=r(opt,"layoutlmv3"),opt.forEach(t),lho=r(XS," \u2014 "),gN=n(XS,"A",{href:!0});var rpt=s(gN);iho=r(rpt,"LayoutLMv3Tokenizer"),rpt.forEach(t),dho=r(XS," or "),hN=n(XS,"A",{href:!0});var tpt=s(hN);cho=r(tpt,"LayoutLMv3TokenizerFast"),tpt.forEach(t),fho=r(XS," (LayoutLMv3 model)"),XS.forEach(t),mho=i(S),Fs=n(S,"LI",{});var zS=s(Fs);vde=n(zS,"STRONG",{});var apt=s(vde);gho=r(apt,"layoutxlm"),apt.forEach(t),hho=r(zS," \u2014 "),pN=n(zS,"A",{href:!0});var npt=s(pN);pho=r(npt,"LayoutXLMTokenizer"),npt.forEach(t),_ho=r(zS," or "),_N=n(zS,"A",{href:!0});var spt=s(_N);uho=r(spt,"LayoutXLMTokenizerFast"),spt.forEach(t),bho=r(zS," (LayoutXLM model)"),zS.forEach(t),vho=i(S),Ts=n(S,"LI",{});var WS=s(Ts);Fde=n(WS,"STRONG",{});var lpt=s(Fde);Fho=r(lpt,"led"),lpt.forEach(t),Tho=r(WS," \u2014 "),uN=n(WS,"A",{href:!0});var ipt=s(uN);Mho=r(ipt,"LEDTokenizer"),ipt.forEach(t),Eho=r(WS," or "),bN=n(WS,"A",{href:!0});var dpt=s(bN);Cho=r(dpt,"LEDTokenizerFast"),dpt.forEach(t),who=r(WS," (LED model)"),WS.forEach(t),Aho=i(S),Ms=n(S,"LI",{});var QS=s(Ms);Tde=n(QS,"STRONG",{});var cpt=s(Tde);Lho=r(cpt,"longformer"),cpt.forEach(t),yho=r(QS," \u2014 "),vN=n(QS,"A",{href:!0});var fpt=s(vN);xho=r(fpt,"LongformerTokenizer"),fpt.forEach(t),$ho=r(QS," or "),FN=n(QS,"A",{href:!0});var mpt=s(FN);kho=r(mpt,"LongformerTokenizerFast"),mpt.forEach(t),Sho=r(QS," (Longformer model)"),QS.forEach(t),Rho=i(S),Es=n(S,"LI",{});var HS=s(Es);Mde=n(HS,"STRONG",{});var gpt=s(Mde);Pho=r(gpt,"longt5"),gpt.forEach(t),Bho=r(HS," \u2014 "),TN=n(HS,"A",{href:!0});var hpt=s(TN);Iho=r(hpt,"T5Tokenizer"),hpt.forEach(t),Nho=r(HS," or "),MN=n(HS,"A",{href:!0});var ppt=s(MN);qho=r(ppt,"T5TokenizerFast"),ppt.forEach(t),jho=r(HS," (LongT5 model)"),HS.forEach(t),Dho=i(S),Lh=n(S,"LI",{});var zxe=s(Lh);Ede=n(zxe,"STRONG",{});var _pt=s(Ede);Gho=r(_pt,"luke"),_pt.forEach(t),Oho=r(zxe," \u2014 "),EN=n(zxe,"A",{href:!0});var upt=s(EN);Vho=r(upt,"LukeTokenizer"),upt.forEach(t),Xho=r(zxe," (LUKE model)"),zxe.forEach(t),zho=i(S),Cs=n(S,"LI",{});var US=s(Cs);Cde=n(US,"STRONG",{});var bpt=s(Cde);Who=r(bpt,"lxmert"),bpt.forEach(t),Qho=r(US," \u2014 "),CN=n(US,"A",{href:!0});var vpt=s(CN);Hho=r(vpt,"LxmertTokenizer"),vpt.forEach(t),Uho=r(US," or "),wN=n(US,"A",{href:!0});var Fpt=s(wN);Jho=r(Fpt,"LxmertTokenizerFast"),Fpt.forEach(t),Yho=r(US," (LXMERT model)"),US.forEach(t),Kho=i(S),yh=n(S,"LI",{});var Wxe=s(yh);wde=n(Wxe,"STRONG",{});var Tpt=s(wde);Zho=r(Tpt,"m2m_100"),Tpt.forEach(t),epo=r(Wxe," \u2014 "),AN=n(Wxe,"A",{href:!0});var Mpt=s(AN);opo=r(Mpt,"M2M100Tokenizer"),Mpt.forEach(t),rpo=r(Wxe," (M2M100 model)"),Wxe.forEach(t),tpo=i(S),xh=n(S,"LI",{});var Qxe=s(xh);Ade=n(Qxe,"STRONG",{});var Ept=s(Ade);apo=r(Ept,"marian"),Ept.forEach(t),npo=r(Qxe," \u2014 "),LN=n(Qxe,"A",{href:!0});var Cpt=s(LN);spo=r(Cpt,"MarianTokenizer"),Cpt.forEach(t),lpo=r(Qxe," (Marian model)"),Qxe.forEach(t),ipo=i(S),ws=n(S,"LI",{});var JS=s(ws);Lde=n(JS,"STRONG",{});var wpt=s(Lde);dpo=r(wpt,"mbart"),wpt.forEach(t),cpo=r(JS," \u2014 "),yN=n(JS,"A",{href:!0});var Apt=s(yN);fpo=r(Apt,"MBartTokenizer"),Apt.forEach(t),mpo=r(JS," or "),xN=n(JS,"A",{href:!0});var Lpt=s(xN);gpo=r(Lpt,"MBartTokenizerFast"),Lpt.forEach(t),hpo=r(JS," (mBART model)"),JS.forEach(t),ppo=i(S),As=n(S,"LI",{});var YS=s(As);yde=n(YS,"STRONG",{});var ypt=s(yde);_po=r(ypt,"mbart50"),ypt.forEach(t),upo=r(YS," \u2014 "),$N=n(YS,"A",{href:!0});var xpt=s($N);bpo=r(xpt,"MBart50Tokenizer"),xpt.forEach(t),vpo=r(YS," or "),kN=n(YS,"A",{href:!0});var $pt=s(kN);Fpo=r($pt,"MBart50TokenizerFast"),$pt.forEach(t),Tpo=r(YS," (mBART-50 model)"),YS.forEach(t),Mpo=i(S),Ls=n(S,"LI",{});var KS=s(Ls);xde=n(KS,"STRONG",{});var kpt=s(xde);Epo=r(kpt,"megatron-bert"),kpt.forEach(t),Cpo=r(KS," \u2014 "),SN=n(KS,"A",{href:!0});var Spt=s(SN);wpo=r(Spt,"BertTokenizer"),Spt.forEach(t),Apo=r(KS," or "),RN=n(KS,"A",{href:!0});var Rpt=s(RN);Lpo=r(Rpt,"BertTokenizerFast"),Rpt.forEach(t),ypo=r(KS," (Megatron-BERT model)"),KS.forEach(t),xpo=i(S),$h=n(S,"LI",{});var Hxe=s($h);$de=n(Hxe,"STRONG",{});var Ppt=s($de);$po=r(Ppt,"mluke"),Ppt.forEach(t),kpo=r(Hxe," \u2014 "),PN=n(Hxe,"A",{href:!0});var Bpt=s(PN);Spo=r(Bpt,"MLukeTokenizer"),Bpt.forEach(t),Rpo=r(Hxe," (mLUKE model)"),Hxe.forEach(t),Ppo=i(S),ys=n(S,"LI",{});var ZS=s(ys);kde=n(ZS,"STRONG",{});var Ipt=s(kde);Bpo=r(Ipt,"mobilebert"),Ipt.forEach(t),Ipo=r(ZS," \u2014 "),BN=n(ZS,"A",{href:!0});var Npt=s(BN);Npo=r(Npt,"MobileBertTokenizer"),Npt.forEach(t),qpo=r(ZS," or "),IN=n(ZS,"A",{href:!0});var qpt=s(IN);jpo=r(qpt,"MobileBertTokenizerFast"),qpt.forEach(t),Dpo=r(ZS," (MobileBERT model)"),ZS.forEach(t),Gpo=i(S),xs=n(S,"LI",{});var eR=s(xs);Sde=n(eR,"STRONG",{});var jpt=s(Sde);Opo=r(jpt,"mpnet"),jpt.forEach(t),Vpo=r(eR," \u2014 "),NN=n(eR,"A",{href:!0});var Dpt=s(NN);Xpo=r(Dpt,"MPNetTokenizer"),Dpt.forEach(t),zpo=r(eR," or "),qN=n(eR,"A",{href:!0});var Gpt=s(qN);Wpo=r(Gpt,"MPNetTokenizerFast"),Gpt.forEach(t),Qpo=r(eR," (MPNet model)"),eR.forEach(t),Hpo=i(S),$s=n(S,"LI",{});var oR=s($s);Rde=n(oR,"STRONG",{});var Opt=s(Rde);Upo=r(Opt,"mt5"),Opt.forEach(t),Jpo=r(oR," \u2014 "),jN=n(oR,"A",{href:!0});var Vpt=s(jN);Ypo=r(Vpt,"MT5Tokenizer"),Vpt.forEach(t),Kpo=r(oR," or "),DN=n(oR,"A",{href:!0});var Xpt=s(DN);Zpo=r(Xpt,"MT5TokenizerFast"),Xpt.forEach(t),e_o=r(oR," (MT5 model)"),oR.forEach(t),o_o=i(S),ks=n(S,"LI",{});var rR=s(ks);Pde=n(rR,"STRONG",{});var zpt=s(Pde);r_o=r(zpt,"mvp"),zpt.forEach(t),t_o=r(rR," \u2014 "),GN=n(rR,"A",{href:!0});var Wpt=s(GN);a_o=r(Wpt,"MvpTokenizer"),Wpt.forEach(t),n_o=r(rR," or "),ON=n(rR,"A",{href:!0});var Qpt=s(ON);s_o=r(Qpt,"MvpTokenizerFast"),Qpt.forEach(t),l_o=r(rR," (MVP model)"),rR.forEach(t),i_o=i(S),Ss=n(S,"LI",{});var tR=s(Ss);Bde=n(tR,"STRONG",{});var Hpt=s(Bde);d_o=r(Hpt,"nezha"),Hpt.forEach(t),c_o=r(tR," \u2014 "),VN=n(tR,"A",{href:!0});var Upt=s(VN);f_o=r(Upt,"BertTokenizer"),Upt.forEach(t),m_o=r(tR," or "),XN=n(tR,"A",{href:!0});var Jpt=s(XN);g_o=r(Jpt,"BertTokenizerFast"),Jpt.forEach(t),h_o=r(tR," (Nezha model)"),tR.forEach(t),p_o=i(S),Rs=n(S,"LI",{});var aR=s(Rs);Ide=n(aR,"STRONG",{});var Ypt=s(Ide);__o=r(Ypt,"nllb"),Ypt.forEach(t),u_o=r(aR," \u2014 "),zN=n(aR,"A",{href:!0});var Kpt=s(zN);b_o=r(Kpt,"NllbTokenizer"),Kpt.forEach(t),v_o=r(aR," or "),WN=n(aR,"A",{href:!0});var Zpt=s(WN);F_o=r(Zpt,"NllbTokenizerFast"),Zpt.forEach(t),T_o=r(aR," (NLLB model)"),aR.forEach(t),M_o=i(S),Ps=n(S,"LI",{});var nR=s(Ps);Nde=n(nR,"STRONG",{});var e_t=s(Nde);E_o=r(e_t,"nystromformer"),e_t.forEach(t),C_o=r(nR," \u2014 "),QN=n(nR,"A",{href:!0});var o_t=s(QN);w_o=r(o_t,"AlbertTokenizer"),o_t.forEach(t),A_o=r(nR," or "),HN=n(nR,"A",{href:!0});var r_t=s(HN);L_o=r(r_t,"AlbertTokenizerFast"),r_t.forEach(t),y_o=r(nR," (Nystr\xF6mformer model)"),nR.forEach(t),x_o=i(S),Bs=n(S,"LI",{});var sR=s(Bs);qde=n(sR,"STRONG",{});var t_t=s(qde);$_o=r(t_t,"openai-gpt"),t_t.forEach(t),k_o=r(sR," \u2014 "),UN=n(sR,"A",{href:!0});var a_t=s(UN);S_o=r(a_t,"OpenAIGPTTokenizer"),a_t.forEach(t),R_o=r(sR," or "),JN=n(sR,"A",{href:!0});var n_t=s(JN);P_o=r(n_t,"OpenAIGPTTokenizerFast"),n_t.forEach(t),B_o=r(sR," (OpenAI GPT model)"),sR.forEach(t),I_o=i(S),kh=n(S,"LI",{});var Uxe=s(kh);jde=n(Uxe,"STRONG",{});var s_t=s(jde);N_o=r(s_t,"opt"),s_t.forEach(t),q_o=r(Uxe," \u2014 "),YN=n(Uxe,"A",{href:!0});var l_t=s(YN);j_o=r(l_t,"GPT2Tokenizer"),l_t.forEach(t),D_o=r(Uxe," (OPT model)"),Uxe.forEach(t),G_o=i(S),Is=n(S,"LI",{});var lR=s(Is);Dde=n(lR,"STRONG",{});var i_t=s(Dde);O_o=r(i_t,"owlvit"),i_t.forEach(t),V_o=r(lR," \u2014 "),KN=n(lR,"A",{href:!0});var d_t=s(KN);X_o=r(d_t,"CLIPTokenizer"),d_t.forEach(t),z_o=r(lR," or "),ZN=n(lR,"A",{href:!0});var c_t=s(ZN);W_o=r(c_t,"CLIPTokenizerFast"),c_t.forEach(t),Q_o=r(lR," (OWL-ViT model)"),lR.forEach(t),H_o=i(S),Ns=n(S,"LI",{});var iR=s(Ns);Gde=n(iR,"STRONG",{});var f_t=s(Gde);U_o=r(f_t,"pegasus"),f_t.forEach(t),J_o=r(iR," \u2014 "),eq=n(iR,"A",{href:!0});var m_t=s(eq);Y_o=r(m_t,"PegasusTokenizer"),m_t.forEach(t),K_o=r(iR," or "),oq=n(iR,"A",{href:!0});var g_t=s(oq);Z_o=r(g_t,"PegasusTokenizerFast"),g_t.forEach(t),euo=r(iR," (Pegasus model)"),iR.forEach(t),ouo=i(S),Sh=n(S,"LI",{});var Jxe=s(Sh);Ode=n(Jxe,"STRONG",{});var h_t=s(Ode);ruo=r(h_t,"perceiver"),h_t.forEach(t),tuo=r(Jxe," \u2014 "),rq=n(Jxe,"A",{href:!0});var p_t=s(rq);auo=r(p_t,"PerceiverTokenizer"),p_t.forEach(t),nuo=r(Jxe," (Perceiver model)"),Jxe.forEach(t),suo=i(S),Rh=n(S,"LI",{});var Yxe=s(Rh);Vde=n(Yxe,"STRONG",{});var __t=s(Vde);luo=r(__t,"phobert"),__t.forEach(t),iuo=r(Yxe," \u2014 "),tq=n(Yxe,"A",{href:!0});var u_t=s(tq);duo=r(u_t,"PhobertTokenizer"),u_t.forEach(t),cuo=r(Yxe," (PhoBERT model)"),Yxe.forEach(t),fuo=i(S),Ph=n(S,"LI",{});var Kxe=s(Ph);Xde=n(Kxe,"STRONG",{});var b_t=s(Xde);muo=r(b_t,"plbart"),b_t.forEach(t),guo=r(Kxe," \u2014 "),aq=n(Kxe,"A",{href:!0});var v_t=s(aq);huo=r(v_t,"PLBartTokenizer"),v_t.forEach(t),puo=r(Kxe," (PLBart model)"),Kxe.forEach(t),_uo=i(S),Bh=n(S,"LI",{});var Zxe=s(Bh);zde=n(Zxe,"STRONG",{});var F_t=s(zde);uuo=r(F_t,"prophetnet"),F_t.forEach(t),buo=r(Zxe," \u2014 "),nq=n(Zxe,"A",{href:!0});var T_t=s(nq);vuo=r(T_t,"ProphetNetTokenizer"),T_t.forEach(t),Fuo=r(Zxe," (ProphetNet model)"),Zxe.forEach(t),Tuo=i(S),qs=n(S,"LI",{});var dR=s(qs);Wde=n(dR,"STRONG",{});var M_t=s(Wde);Muo=r(M_t,"qdqbert"),M_t.forEach(t),Euo=r(dR," \u2014 "),sq=n(dR,"A",{href:!0});var E_t=s(sq);Cuo=r(E_t,"BertTokenizer"),E_t.forEach(t),wuo=r(dR," or "),lq=n(dR,"A",{href:!0});var C_t=s(lq);Auo=r(C_t,"BertTokenizerFast"),C_t.forEach(t),Luo=r(dR," (QDQBert model)"),dR.forEach(t),yuo=i(S),Ih=n(S,"LI",{});var e$e=s(Ih);Qde=n(e$e,"STRONG",{});var w_t=s(Qde);xuo=r(w_t,"rag"),w_t.forEach(t),$uo=r(e$e," \u2014 "),iq=n(e$e,"A",{href:!0});var A_t=s(iq);kuo=r(A_t,"RagTokenizer"),A_t.forEach(t),Suo=r(e$e," (RAG model)"),e$e.forEach(t),Ruo=i(S),js=n(S,"LI",{});var cR=s(js);Hde=n(cR,"STRONG",{});var L_t=s(Hde);Puo=r(L_t,"realm"),L_t.forEach(t),Buo=r(cR," \u2014 "),dq=n(cR,"A",{href:!0});var y_t=s(dq);Iuo=r(y_t,"RealmTokenizer"),y_t.forEach(t),Nuo=r(cR," or "),cq=n(cR,"A",{href:!0});var x_t=s(cq);quo=r(x_t,"RealmTokenizerFast"),x_t.forEach(t),juo=r(cR," (REALM model)"),cR.forEach(t),Duo=i(S),Ds=n(S,"LI",{});var fR=s(Ds);Ude=n(fR,"STRONG",{});var $_t=s(Ude);Guo=r($_t,"reformer"),$_t.forEach(t),Ouo=r(fR," \u2014 "),fq=n(fR,"A",{href:!0});var k_t=s(fq);Vuo=r(k_t,"ReformerTokenizer"),k_t.forEach(t),Xuo=r(fR," or "),mq=n(fR,"A",{href:!0});var S_t=s(mq);zuo=r(S_t,"ReformerTokenizerFast"),S_t.forEach(t),Wuo=r(fR," (Reformer model)"),fR.forEach(t),Quo=i(S),Gs=n(S,"LI",{});var mR=s(Gs);Jde=n(mR,"STRONG",{});var R_t=s(Jde);Huo=r(R_t,"rembert"),R_t.forEach(t),Uuo=r(mR," \u2014 "),gq=n(mR,"A",{href:!0});var P_t=s(gq);Juo=r(P_t,"RemBertTokenizer"),P_t.forEach(t),Yuo=r(mR," or "),hq=n(mR,"A",{href:!0});var B_t=s(hq);Kuo=r(B_t,"RemBertTokenizerFast"),B_t.forEach(t),Zuo=r(mR," (RemBERT model)"),mR.forEach(t),e7o=i(S),Os=n(S,"LI",{});var gR=s(Os);Yde=n(gR,"STRONG",{});var I_t=s(Yde);o7o=r(I_t,"retribert"),I_t.forEach(t),r7o=r(gR," \u2014 "),pq=n(gR,"A",{href:!0});var N_t=s(pq);t7o=r(N_t,"RetriBertTokenizer"),N_t.forEach(t),a7o=r(gR," or "),_q=n(gR,"A",{href:!0});var q_t=s(_q);n7o=r(q_t,"RetriBertTokenizerFast"),q_t.forEach(t),s7o=r(gR," (RetriBERT model)"),gR.forEach(t),l7o=i(S),Vs=n(S,"LI",{});var hR=s(Vs);Kde=n(hR,"STRONG",{});var j_t=s(Kde);i7o=r(j_t,"roberta"),j_t.forEach(t),d7o=r(hR," \u2014 "),uq=n(hR,"A",{href:!0});var D_t=s(uq);c7o=r(D_t,"RobertaTokenizer"),D_t.forEach(t),f7o=r(hR," or "),bq=n(hR,"A",{href:!0});var G_t=s(bq);m7o=r(G_t,"RobertaTokenizerFast"),G_t.forEach(t),g7o=r(hR," (RoBERTa model)"),hR.forEach(t),h7o=i(S),Xs=n(S,"LI",{});var pR=s(Xs);Zde=n(pR,"STRONG",{});var O_t=s(Zde);p7o=r(O_t,"roformer"),O_t.forEach(t),_7o=r(pR," \u2014 "),vq=n(pR,"A",{href:!0});var V_t=s(vq);u7o=r(V_t,"RoFormerTokenizer"),V_t.forEach(t),b7o=r(pR," or "),Fq=n(pR,"A",{href:!0});var X_t=s(Fq);v7o=r(X_t,"RoFormerTokenizerFast"),X_t.forEach(t),F7o=r(pR," (RoFormer model)"),pR.forEach(t),T7o=i(S),Nh=n(S,"LI",{});var o$e=s(Nh);ece=n(o$e,"STRONG",{});var z_t=s(ece);M7o=r(z_t,"speech_to_text"),z_t.forEach(t),E7o=r(o$e," \u2014 "),Tq=n(o$e,"A",{href:!0});var W_t=s(Tq);C7o=r(W_t,"Speech2TextTokenizer"),W_t.forEach(t),w7o=r(o$e," (Speech2Text model)"),o$e.forEach(t),A7o=i(S),qh=n(S,"LI",{});var r$e=s(qh);oce=n(r$e,"STRONG",{});var Q_t=s(oce);L7o=r(Q_t,"speech_to_text_2"),Q_t.forEach(t),y7o=r(r$e," \u2014 "),Mq=n(r$e,"A",{href:!0});var H_t=s(Mq);x7o=r(H_t,"Speech2Text2Tokenizer"),H_t.forEach(t),$7o=r(r$e," (Speech2Text2 model)"),r$e.forEach(t),k7o=i(S),zs=n(S,"LI",{});var _R=s(zs);rce=n(_R,"STRONG",{});var U_t=s(rce);S7o=r(U_t,"splinter"),U_t.forEach(t),R7o=r(_R," \u2014 "),Eq=n(_R,"A",{href:!0});var J_t=s(Eq);P7o=r(J_t,"SplinterTokenizer"),J_t.forEach(t),B7o=r(_R," or "),Cq=n(_R,"A",{href:!0});var Y_t=s(Cq);I7o=r(Y_t,"SplinterTokenizerFast"),Y_t.forEach(t),N7o=r(_R," (Splinter model)"),_R.forEach(t),q7o=i(S),Ws=n(S,"LI",{});var uR=s(Ws);tce=n(uR,"STRONG",{});var K_t=s(tce);j7o=r(K_t,"squeezebert"),K_t.forEach(t),D7o=r(uR," \u2014 "),wq=n(uR,"A",{href:!0});var Z_t=s(wq);G7o=r(Z_t,"SqueezeBertTokenizer"),Z_t.forEach(t),O7o=r(uR," or "),Aq=n(uR,"A",{href:!0});var eut=s(Aq);V7o=r(eut,"SqueezeBertTokenizerFast"),eut.forEach(t),X7o=r(uR," (SqueezeBERT model)"),uR.forEach(t),z7o=i(S),Qs=n(S,"LI",{});var bR=s(Qs);ace=n(bR,"STRONG",{});var out=s(ace);W7o=r(out,"t5"),out.forEach(t),Q7o=r(bR," \u2014 "),Lq=n(bR,"A",{href:!0});var rut=s(Lq);H7o=r(rut,"T5Tokenizer"),rut.forEach(t),U7o=r(bR," or "),yq=n(bR,"A",{href:!0});var tut=s(yq);J7o=r(tut,"T5TokenizerFast"),tut.forEach(t),Y7o=r(bR," (T5 model)"),bR.forEach(t),K7o=i(S),jh=n(S,"LI",{});var t$e=s(jh);nce=n(t$e,"STRONG",{});var aut=s(nce);Z7o=r(aut,"tapas"),aut.forEach(t),e1o=r(t$e," \u2014 "),xq=n(t$e,"A",{href:!0});var nut=s(xq);o1o=r(nut,"TapasTokenizer"),nut.forEach(t),r1o=r(t$e," (TAPAS model)"),t$e.forEach(t),t1o=i(S),Dh=n(S,"LI",{});var a$e=s(Dh);sce=n(a$e,"STRONG",{});var sut=s(sce);a1o=r(sut,"tapex"),sut.forEach(t),n1o=r(a$e," \u2014 "),$q=n(a$e,"A",{href:!0});var lut=s($q);s1o=r(lut,"TapexTokenizer"),lut.forEach(t),l1o=r(a$e," (TAPEX model)"),a$e.forEach(t),i1o=i(S),Gh=n(S,"LI",{});var n$e=s(Gh);lce=n(n$e,"STRONG",{});var iut=s(lce);d1o=r(iut,"transfo-xl"),iut.forEach(t),c1o=r(n$e," \u2014 "),kq=n(n$e,"A",{href:!0});var dut=s(kq);f1o=r(dut,"TransfoXLTokenizer"),dut.forEach(t),m1o=r(n$e," (Transformer-XL model)"),n$e.forEach(t),g1o=i(S),Hs=n(S,"LI",{});var vR=s(Hs);ice=n(vR,"STRONG",{});var cut=s(ice);h1o=r(cut,"vilt"),cut.forEach(t),p1o=r(vR," \u2014 "),Sq=n(vR,"A",{href:!0});var fut=s(Sq);_1o=r(fut,"BertTokenizer"),fut.forEach(t),u1o=r(vR," or "),Rq=n(vR,"A",{href:!0});var mut=s(Rq);b1o=r(mut,"BertTokenizerFast"),mut.forEach(t),v1o=r(vR," (ViLT model)"),vR.forEach(t),F1o=i(S),Us=n(S,"LI",{});var FR=s(Us);dce=n(FR,"STRONG",{});var gut=s(dce);T1o=r(gut,"visual_bert"),gut.forEach(t),M1o=r(FR," \u2014 "),Pq=n(FR,"A",{href:!0});var hut=s(Pq);E1o=r(hut,"BertTokenizer"),hut.forEach(t),C1o=r(FR," or "),Bq=n(FR,"A",{href:!0});var put=s(Bq);w1o=r(put,"BertTokenizerFast"),put.forEach(t),A1o=r(FR," (VisualBERT model)"),FR.forEach(t),L1o=i(S),Oh=n(S,"LI",{});var s$e=s(Oh);cce=n(s$e,"STRONG",{});var _ut=s(cce);y1o=r(_ut,"wav2vec2"),_ut.forEach(t),x1o=r(s$e," \u2014 "),Iq=n(s$e,"A",{href:!0});var uut=s(Iq);$1o=r(uut,"Wav2Vec2CTCTokenizer"),uut.forEach(t),k1o=r(s$e," (Wav2Vec2 model)"),s$e.forEach(t),S1o=i(S),Vh=n(S,"LI",{});var l$e=s(Vh);fce=n(l$e,"STRONG",{});var but=s(fce);R1o=r(but,"wav2vec2-conformer"),but.forEach(t),P1o=r(l$e," \u2014 "),Nq=n(l$e,"A",{href:!0});var vut=s(Nq);B1o=r(vut,"Wav2Vec2CTCTokenizer"),vut.forEach(t),I1o=r(l$e," (Wav2Vec2-Conformer model)"),l$e.forEach(t),N1o=i(S),Xh=n(S,"LI",{});var i$e=s(Xh);mce=n(i$e,"STRONG",{});var Fut=s(mce);q1o=r(Fut,"wav2vec2_phoneme"),Fut.forEach(t),j1o=r(i$e," \u2014 "),qq=n(i$e,"A",{href:!0});var Tut=s(qq);D1o=r(Tut,"Wav2Vec2PhonemeCTCTokenizer"),Tut.forEach(t),G1o=r(i$e," (Wav2Vec2Phoneme model)"),i$e.forEach(t),O1o=i(S),Js=n(S,"LI",{});var TR=s(Js);gce=n(TR,"STRONG",{});var Mut=s(gce);V1o=r(Mut,"xglm"),Mut.forEach(t),X1o=r(TR," \u2014 "),jq=n(TR,"A",{href:!0});var Eut=s(jq);z1o=r(Eut,"XGLMTokenizer"),Eut.forEach(t),W1o=r(TR," or "),Dq=n(TR,"A",{href:!0});var Cut=s(Dq);Q1o=r(Cut,"XGLMTokenizerFast"),Cut.forEach(t),H1o=r(TR," (XGLM model)"),TR.forEach(t),U1o=i(S),zh=n(S,"LI",{});var d$e=s(zh);hce=n(d$e,"STRONG",{});var wut=s(hce);J1o=r(wut,"xlm"),wut.forEach(t),Y1o=r(d$e," \u2014 "),Gq=n(d$e,"A",{href:!0});var Aut=s(Gq);K1o=r(Aut,"XLMTokenizer"),Aut.forEach(t),Z1o=r(d$e," (XLM model)"),d$e.forEach(t),e2o=i(S),Wh=n(S,"LI",{});var c$e=s(Wh);pce=n(c$e,"STRONG",{});var Lut=s(pce);o2o=r(Lut,"xlm-prophetnet"),Lut.forEach(t),r2o=r(c$e," \u2014 "),Oq=n(c$e,"A",{href:!0});var yut=s(Oq);t2o=r(yut,"XLMProphetNetTokenizer"),yut.forEach(t),a2o=r(c$e," (XLM-ProphetNet model)"),c$e.forEach(t),n2o=i(S),Ys=n(S,"LI",{});var MR=s(Ys);_ce=n(MR,"STRONG",{});var xut=s(_ce);s2o=r(xut,"xlm-roberta"),xut.forEach(t),l2o=r(MR," \u2014 "),Vq=n(MR,"A",{href:!0});var $ut=s(Vq);i2o=r($ut,"XLMRobertaTokenizer"),$ut.forEach(t),d2o=r(MR," or "),Xq=n(MR,"A",{href:!0});var kut=s(Xq);c2o=r(kut,"XLMRobertaTokenizerFast"),kut.forEach(t),f2o=r(MR," (XLM-RoBERTa model)"),MR.forEach(t),m2o=i(S),Ks=n(S,"LI",{});var ER=s(Ks);uce=n(ER,"STRONG",{});var Sut=s(uce);g2o=r(Sut,"xlm-roberta-xl"),Sut.forEach(t),h2o=r(ER," \u2014 "),zq=n(ER,"A",{href:!0});var Rut=s(zq);p2o=r(Rut,"RobertaTokenizer"),Rut.forEach(t),_2o=r(ER," or "),Wq=n(ER,"A",{href:!0});var Put=s(Wq);u2o=r(Put,"RobertaTokenizerFast"),Put.forEach(t),b2o=r(ER," (XLM-RoBERTa-XL model)"),ER.forEach(t),v2o=i(S),Zs=n(S,"LI",{});var CR=s(Zs);bce=n(CR,"STRONG",{});var But=s(bce);F2o=r(But,"xlnet"),But.forEach(t),T2o=r(CR," \u2014 "),Qq=n(CR,"A",{href:!0});var Iut=s(Qq);M2o=r(Iut,"XLNetTokenizer"),Iut.forEach(t),E2o=r(CR," or "),Hq=n(CR,"A",{href:!0});var Nut=s(Hq);C2o=r(Nut,"XLNetTokenizerFast"),Nut.forEach(t),w2o=r(CR," (XLNet model)"),CR.forEach(t),A2o=i(S),el=n(S,"LI",{});var wR=s(el);vce=n(wR,"STRONG",{});var qut=s(vce);L2o=r(qut,"yoso"),qut.forEach(t),y2o=r(wR," \u2014 "),Uq=n(wR,"A",{href:!0});var jut=s(Uq);x2o=r(jut,"AlbertTokenizer"),jut.forEach(t),$2o=r(wR," or "),Jq=n(wR,"A",{href:!0});var Dut=s(Jq);k2o=r(Dut,"AlbertTokenizerFast"),Dut.forEach(t),S2o=r(wR," (YOSO model)"),wR.forEach(t),S.forEach(t),R2o=i(ll),T(Qh.$$.fragment,ll),ll.forEach(t),P2o=i(sl),Hh=n(sl,"DIV",{class:!0});var YHe=s(Hh);T(sy.$$.fragment,YHe),B2o=i(YHe),Fce=n(YHe,"P",{});var Gut=s(Fce);I2o=r(Gut,"Register a new tokenizer in this mapping."),Gut.forEach(t),YHe.forEach(t),sl.forEach(t),HWe=i(f),Qi=n(f,"H2",{class:!0});var KHe=s(Qi);Uh=n(KHe,"A",{id:!0,class:!0,href:!0});var Out=s(Uh);Tce=n(Out,"SPAN",{});var Vut=s(Tce);T(ly.$$.fragment,Vut),Vut.forEach(t),Out.forEach(t),N2o=i(KHe),Mce=n(KHe,"SPAN",{});var Xut=s(Mce);q2o=r(Xut,"AutoFeatureExtractor"),Xut.forEach(t),KHe.forEach(t),UWe=i(f),$o=n(f,"DIV",{class:!0});var il=s($o);T(iy.$$.fragment,il),j2o=i(il),dy=n(il,"P",{});var ZHe=s(dy);D2o=r(ZHe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),Yq=n(ZHe,"A",{href:!0});var zut=s(Yq);G2o=r(zut,"AutoFeatureExtractor.from_pretrained()"),zut.forEach(t),O2o=r(ZHe," class method."),ZHe.forEach(t),V2o=i(il),cy=n(il,"P",{});var eUe=s(cy);X2o=r(eUe,"This class cannot be instantiated directly using "),Ece=n(eUe,"CODE",{});var Wut=s(Ece);z2o=r(Wut,"__init__()"),Wut.forEach(t),W2o=r(eUe," (throws an error)."),eUe.forEach(t),Q2o=i(il),Ue=n(il,"DIV",{class:!0});var ia=s(Ue);T(fy.$$.fragment,ia),H2o=i(ia),Cce=n(ia,"P",{});var Qut=s(Cce);U2o=r(Qut,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),Qut.forEach(t),J2o=i(ia),ja=n(ia,"P",{});var Q6=s(ja);Y2o=r(Q6,"The feature extractor class to instantiate is selected based on the "),wce=n(Q6,"CODE",{});var Hut=s(wce);K2o=r(Hut,"model_type"),Hut.forEach(t),Z2o=r(Q6,` property of the config object
(either passed as an argument or loaded from `),Ace=n(Q6,"CODE",{});var Uut=s(Ace);ebo=r(Uut,"pretrained_model_name_or_path"),Uut.forEach(t),obo=r(Q6,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lce=n(Q6,"CODE",{});var Jut=s(Lce);rbo=r(Jut,"pretrained_model_name_or_path"),Jut.forEach(t),tbo=r(Q6,":"),Q6.forEach(t),abo=i(ia),H=n(ia,"UL",{});var Y=s(H);Jh=n(Y,"LI",{});var f$e=s(Jh);yce=n(f$e,"STRONG",{});var Yut=s(yce);nbo=r(Yut,"beit"),Yut.forEach(t),sbo=r(f$e," \u2014 "),Kq=n(f$e,"A",{href:!0});var Kut=s(Kq);lbo=r(Kut,"BeitFeatureExtractor"),Kut.forEach(t),ibo=r(f$e," (BEiT model)"),f$e.forEach(t),dbo=i(Y),Yh=n(Y,"LI",{});var m$e=s(Yh);xce=n(m$e,"STRONG",{});var Zut=s(xce);cbo=r(Zut,"clip"),Zut.forEach(t),fbo=r(m$e," \u2014 "),Zq=n(m$e,"A",{href:!0});var e7t=s(Zq);mbo=r(e7t,"CLIPFeatureExtractor"),e7t.forEach(t),gbo=r(m$e," (CLIP model)"),m$e.forEach(t),hbo=i(Y),Kh=n(Y,"LI",{});var g$e=s(Kh);$ce=n(g$e,"STRONG",{});var o7t=s($ce);pbo=r(o7t,"convnext"),o7t.forEach(t),_bo=r(g$e," \u2014 "),ej=n(g$e,"A",{href:!0});var r7t=s(ej);ubo=r(r7t,"ConvNextFeatureExtractor"),r7t.forEach(t),bbo=r(g$e," (ConvNeXT model)"),g$e.forEach(t),vbo=i(Y),Zh=n(Y,"LI",{});var h$e=s(Zh);kce=n(h$e,"STRONG",{});var t7t=s(kce);Fbo=r(t7t,"cvt"),t7t.forEach(t),Tbo=r(h$e," \u2014 "),oj=n(h$e,"A",{href:!0});var a7t=s(oj);Mbo=r(a7t,"ConvNextFeatureExtractor"),a7t.forEach(t),Ebo=r(h$e," (CvT model)"),h$e.forEach(t),Cbo=i(Y),ep=n(Y,"LI",{});var p$e=s(ep);Sce=n(p$e,"STRONG",{});var n7t=s(Sce);wbo=r(n7t,"data2vec-audio"),n7t.forEach(t),Abo=r(p$e," \u2014 "),rj=n(p$e,"A",{href:!0});var s7t=s(rj);Lbo=r(s7t,"Wav2Vec2FeatureExtractor"),s7t.forEach(t),ybo=r(p$e," (Data2VecAudio model)"),p$e.forEach(t),xbo=i(Y),op=n(Y,"LI",{});var _$e=s(op);Rce=n(_$e,"STRONG",{});var l7t=s(Rce);$bo=r(l7t,"data2vec-vision"),l7t.forEach(t),kbo=r(_$e," \u2014 "),tj=n(_$e,"A",{href:!0});var i7t=s(tj);Sbo=r(i7t,"BeitFeatureExtractor"),i7t.forEach(t),Rbo=r(_$e," (Data2VecVision model)"),_$e.forEach(t),Pbo=i(Y),rp=n(Y,"LI",{});var u$e=s(rp);Pce=n(u$e,"STRONG",{});var d7t=s(Pce);Bbo=r(d7t,"deit"),d7t.forEach(t),Ibo=r(u$e," \u2014 "),aj=n(u$e,"A",{href:!0});var c7t=s(aj);Nbo=r(c7t,"DeiTFeatureExtractor"),c7t.forEach(t),qbo=r(u$e," (DeiT model)"),u$e.forEach(t),jbo=i(Y),tp=n(Y,"LI",{});var b$e=s(tp);Bce=n(b$e,"STRONG",{});var f7t=s(Bce);Dbo=r(f7t,"detr"),f7t.forEach(t),Gbo=r(b$e," \u2014 "),nj=n(b$e,"A",{href:!0});var m7t=s(nj);Obo=r(m7t,"DetrFeatureExtractor"),m7t.forEach(t),Vbo=r(b$e," (DETR model)"),b$e.forEach(t),Xbo=i(Y),ap=n(Y,"LI",{});var v$e=s(ap);Ice=n(v$e,"STRONG",{});var g7t=s(Ice);zbo=r(g7t,"dpt"),g7t.forEach(t),Wbo=r(v$e," \u2014 "),sj=n(v$e,"A",{href:!0});var h7t=s(sj);Qbo=r(h7t,"DPTFeatureExtractor"),h7t.forEach(t),Hbo=r(v$e," (DPT model)"),v$e.forEach(t),Ubo=i(Y),np=n(Y,"LI",{});var F$e=s(np);Nce=n(F$e,"STRONG",{});var p7t=s(Nce);Jbo=r(p7t,"flava"),p7t.forEach(t),Ybo=r(F$e," \u2014 "),lj=n(F$e,"A",{href:!0});var _7t=s(lj);Kbo=r(_7t,"FlavaFeatureExtractor"),_7t.forEach(t),Zbo=r(F$e," (FLAVA model)"),F$e.forEach(t),evo=i(Y),sp=n(Y,"LI",{});var T$e=s(sp);qce=n(T$e,"STRONG",{});var u7t=s(qce);ovo=r(u7t,"glpn"),u7t.forEach(t),rvo=r(T$e," \u2014 "),ij=n(T$e,"A",{href:!0});var b7t=s(ij);tvo=r(b7t,"GLPNFeatureExtractor"),b7t.forEach(t),avo=r(T$e," (GLPN model)"),T$e.forEach(t),nvo=i(Y),lp=n(Y,"LI",{});var M$e=s(lp);jce=n(M$e,"STRONG",{});var v7t=s(jce);svo=r(v7t,"groupvit"),v7t.forEach(t),lvo=r(M$e," \u2014 "),dj=n(M$e,"A",{href:!0});var F7t=s(dj);ivo=r(F7t,"CLIPFeatureExtractor"),F7t.forEach(t),dvo=r(M$e," (GroupViT model)"),M$e.forEach(t),cvo=i(Y),ip=n(Y,"LI",{});var E$e=s(ip);Dce=n(E$e,"STRONG",{});var T7t=s(Dce);fvo=r(T7t,"hubert"),T7t.forEach(t),mvo=r(E$e," \u2014 "),cj=n(E$e,"A",{href:!0});var M7t=s(cj);gvo=r(M7t,"Wav2Vec2FeatureExtractor"),M7t.forEach(t),hvo=r(E$e," (Hubert model)"),E$e.forEach(t),pvo=i(Y),dp=n(Y,"LI",{});var C$e=s(dp);Gce=n(C$e,"STRONG",{});var E7t=s(Gce);_vo=r(E7t,"imagegpt"),E7t.forEach(t),uvo=r(C$e," \u2014 "),fj=n(C$e,"A",{href:!0});var C7t=s(fj);bvo=r(C7t,"ImageGPTFeatureExtractor"),C7t.forEach(t),vvo=r(C$e," (ImageGPT model)"),C$e.forEach(t),Fvo=i(Y),cp=n(Y,"LI",{});var w$e=s(cp);Oce=n(w$e,"STRONG",{});var w7t=s(Oce);Tvo=r(w7t,"layoutlmv2"),w7t.forEach(t),Mvo=r(w$e," \u2014 "),mj=n(w$e,"A",{href:!0});var A7t=s(mj);Evo=r(A7t,"LayoutLMv2FeatureExtractor"),A7t.forEach(t),Cvo=r(w$e," (LayoutLMv2 model)"),w$e.forEach(t),wvo=i(Y),fp=n(Y,"LI",{});var A$e=s(fp);Vce=n(A$e,"STRONG",{});var L7t=s(Vce);Avo=r(L7t,"layoutlmv3"),L7t.forEach(t),Lvo=r(A$e," \u2014 "),gj=n(A$e,"A",{href:!0});var y7t=s(gj);yvo=r(y7t,"LayoutLMv3FeatureExtractor"),y7t.forEach(t),xvo=r(A$e," (LayoutLMv3 model)"),A$e.forEach(t),$vo=i(Y),mp=n(Y,"LI",{});var L$e=s(mp);Xce=n(L$e,"STRONG",{});var x7t=s(Xce);kvo=r(x7t,"levit"),x7t.forEach(t),Svo=r(L$e," \u2014 "),hj=n(L$e,"A",{href:!0});var $7t=s(hj);Rvo=r($7t,"LevitFeatureExtractor"),$7t.forEach(t),Pvo=r(L$e," (LeViT model)"),L$e.forEach(t),Bvo=i(Y),gp=n(Y,"LI",{});var y$e=s(gp);zce=n(y$e,"STRONG",{});var k7t=s(zce);Ivo=r(k7t,"maskformer"),k7t.forEach(t),Nvo=r(y$e," \u2014 "),pj=n(y$e,"A",{href:!0});var S7t=s(pj);qvo=r(S7t,"MaskFormerFeatureExtractor"),S7t.forEach(t),jvo=r(y$e," (MaskFormer model)"),y$e.forEach(t),Dvo=i(Y),hp=n(Y,"LI",{});var x$e=s(hp);Wce=n(x$e,"STRONG",{});var R7t=s(Wce);Gvo=r(R7t,"mctct"),R7t.forEach(t),Ovo=r(x$e," \u2014 "),_j=n(x$e,"A",{href:!0});var P7t=s(_j);Vvo=r(P7t,"MCTCTFeatureExtractor"),P7t.forEach(t),Xvo=r(x$e," (M-CTC-T model)"),x$e.forEach(t),zvo=i(Y),pp=n(Y,"LI",{});var $$e=s(pp);Qce=n($$e,"STRONG",{});var B7t=s(Qce);Wvo=r(B7t,"mobilevit"),B7t.forEach(t),Qvo=r($$e," \u2014 "),uj=n($$e,"A",{href:!0});var I7t=s(uj);Hvo=r(I7t,"MobileViTFeatureExtractor"),I7t.forEach(t),Uvo=r($$e," (MobileViT model)"),$$e.forEach(t),Jvo=i(Y),_p=n(Y,"LI",{});var k$e=s(_p);Hce=n(k$e,"STRONG",{});var N7t=s(Hce);Yvo=r(N7t,"owlvit"),N7t.forEach(t),Kvo=r(k$e," \u2014 "),bj=n(k$e,"A",{href:!0});var q7t=s(bj);Zvo=r(q7t,"OwlViTFeatureExtractor"),q7t.forEach(t),eFo=r(k$e," (OWL-ViT model)"),k$e.forEach(t),oFo=i(Y),up=n(Y,"LI",{});var S$e=s(up);Uce=n(S$e,"STRONG",{});var j7t=s(Uce);rFo=r(j7t,"perceiver"),j7t.forEach(t),tFo=r(S$e," \u2014 "),vj=n(S$e,"A",{href:!0});var D7t=s(vj);aFo=r(D7t,"PerceiverFeatureExtractor"),D7t.forEach(t),nFo=r(S$e," (Perceiver model)"),S$e.forEach(t),sFo=i(Y),bp=n(Y,"LI",{});var R$e=s(bp);Jce=n(R$e,"STRONG",{});var G7t=s(Jce);lFo=r(G7t,"poolformer"),G7t.forEach(t),iFo=r(R$e," \u2014 "),Fj=n(R$e,"A",{href:!0});var O7t=s(Fj);dFo=r(O7t,"PoolFormerFeatureExtractor"),O7t.forEach(t),cFo=r(R$e," (PoolFormer model)"),R$e.forEach(t),fFo=i(Y),vp=n(Y,"LI",{});var P$e=s(vp);Yce=n(P$e,"STRONG",{});var V7t=s(Yce);mFo=r(V7t,"regnet"),V7t.forEach(t),gFo=r(P$e," \u2014 "),Tj=n(P$e,"A",{href:!0});var X7t=s(Tj);hFo=r(X7t,"ConvNextFeatureExtractor"),X7t.forEach(t),pFo=r(P$e," (RegNet model)"),P$e.forEach(t),_Fo=i(Y),Fp=n(Y,"LI",{});var B$e=s(Fp);Kce=n(B$e,"STRONG",{});var z7t=s(Kce);uFo=r(z7t,"resnet"),z7t.forEach(t),bFo=r(B$e," \u2014 "),Mj=n(B$e,"A",{href:!0});var W7t=s(Mj);vFo=r(W7t,"ConvNextFeatureExtractor"),W7t.forEach(t),FFo=r(B$e," (ResNet model)"),B$e.forEach(t),TFo=i(Y),Tp=n(Y,"LI",{});var I$e=s(Tp);Zce=n(I$e,"STRONG",{});var Q7t=s(Zce);MFo=r(Q7t,"segformer"),Q7t.forEach(t),EFo=r(I$e," \u2014 "),Ej=n(I$e,"A",{href:!0});var H7t=s(Ej);CFo=r(H7t,"SegformerFeatureExtractor"),H7t.forEach(t),wFo=r(I$e," (SegFormer model)"),I$e.forEach(t),AFo=i(Y),Mp=n(Y,"LI",{});var N$e=s(Mp);efe=n(N$e,"STRONG",{});var U7t=s(efe);LFo=r(U7t,"speech_to_text"),U7t.forEach(t),yFo=r(N$e," \u2014 "),Cj=n(N$e,"A",{href:!0});var J7t=s(Cj);xFo=r(J7t,"Speech2TextFeatureExtractor"),J7t.forEach(t),$Fo=r(N$e," (Speech2Text model)"),N$e.forEach(t),kFo=i(Y),Ep=n(Y,"LI",{});var q$e=s(Ep);ofe=n(q$e,"STRONG",{});var Y7t=s(ofe);SFo=r(Y7t,"swin"),Y7t.forEach(t),RFo=r(q$e," \u2014 "),wj=n(q$e,"A",{href:!0});var K7t=s(wj);PFo=r(K7t,"ViTFeatureExtractor"),K7t.forEach(t),BFo=r(q$e," (Swin Transformer model)"),q$e.forEach(t),IFo=i(Y),Cp=n(Y,"LI",{});var j$e=s(Cp);rfe=n(j$e,"STRONG",{});var Z7t=s(rfe);NFo=r(Z7t,"swinv2"),Z7t.forEach(t),qFo=r(j$e," \u2014 "),Aj=n(j$e,"A",{href:!0});var e1t=s(Aj);jFo=r(e1t,"ViTFeatureExtractor"),e1t.forEach(t),DFo=r(j$e," (Swin Transformer V2 model)"),j$e.forEach(t),GFo=i(Y),wp=n(Y,"LI",{});var D$e=s(wp);tfe=n(D$e,"STRONG",{});var o1t=s(tfe);OFo=r(o1t,"van"),o1t.forEach(t),VFo=r(D$e," \u2014 "),Lj=n(D$e,"A",{href:!0});var r1t=s(Lj);XFo=r(r1t,"ConvNextFeatureExtractor"),r1t.forEach(t),zFo=r(D$e," (VAN model)"),D$e.forEach(t),WFo=i(Y),Ap=n(Y,"LI",{});var G$e=s(Ap);afe=n(G$e,"STRONG",{});var t1t=s(afe);QFo=r(t1t,"videomae"),t1t.forEach(t),HFo=r(G$e," \u2014 "),yj=n(G$e,"A",{href:!0});var a1t=s(yj);UFo=r(a1t,"ViTFeatureExtractor"),a1t.forEach(t),JFo=r(G$e," (VideoMAE model)"),G$e.forEach(t),YFo=i(Y),Lp=n(Y,"LI",{});var O$e=s(Lp);nfe=n(O$e,"STRONG",{});var n1t=s(nfe);KFo=r(n1t,"vilt"),n1t.forEach(t),ZFo=r(O$e," \u2014 "),xj=n(O$e,"A",{href:!0});var s1t=s(xj);eTo=r(s1t,"ViltFeatureExtractor"),s1t.forEach(t),oTo=r(O$e," (ViLT model)"),O$e.forEach(t),rTo=i(Y),yp=n(Y,"LI",{});var V$e=s(yp);sfe=n(V$e,"STRONG",{});var l1t=s(sfe);tTo=r(l1t,"vit"),l1t.forEach(t),aTo=r(V$e," \u2014 "),$j=n(V$e,"A",{href:!0});var i1t=s($j);nTo=r(i1t,"ViTFeatureExtractor"),i1t.forEach(t),sTo=r(V$e," (ViT model)"),V$e.forEach(t),lTo=i(Y),xp=n(Y,"LI",{});var X$e=s(xp);lfe=n(X$e,"STRONG",{});var d1t=s(lfe);iTo=r(d1t,"vit_mae"),d1t.forEach(t),dTo=r(X$e," \u2014 "),kj=n(X$e,"A",{href:!0});var c1t=s(kj);cTo=r(c1t,"ViTFeatureExtractor"),c1t.forEach(t),fTo=r(X$e," (ViTMAE model)"),X$e.forEach(t),mTo=i(Y),$p=n(Y,"LI",{});var z$e=s($p);ife=n(z$e,"STRONG",{});var f1t=s(ife);gTo=r(f1t,"wav2vec2"),f1t.forEach(t),hTo=r(z$e," \u2014 "),Sj=n(z$e,"A",{href:!0});var m1t=s(Sj);pTo=r(m1t,"Wav2Vec2FeatureExtractor"),m1t.forEach(t),_To=r(z$e," (Wav2Vec2 model)"),z$e.forEach(t),uTo=i(Y),kp=n(Y,"LI",{});var W$e=s(kp);dfe=n(W$e,"STRONG",{});var g1t=s(dfe);bTo=r(g1t,"wav2vec2-conformer"),g1t.forEach(t),vTo=r(W$e," \u2014 "),Rj=n(W$e,"A",{href:!0});var h1t=s(Rj);FTo=r(h1t,"Wav2Vec2FeatureExtractor"),h1t.forEach(t),TTo=r(W$e," (Wav2Vec2-Conformer model)"),W$e.forEach(t),MTo=i(Y),Sp=n(Y,"LI",{});var Q$e=s(Sp);cfe=n(Q$e,"STRONG",{});var p1t=s(cfe);ETo=r(p1t,"yolos"),p1t.forEach(t),CTo=r(Q$e," \u2014 "),Pj=n(Q$e,"A",{href:!0});var _1t=s(Pj);wTo=r(_1t,"YolosFeatureExtractor"),_1t.forEach(t),ATo=r(Q$e," (YOLOS model)"),Q$e.forEach(t),Y.forEach(t),LTo=i(ia),T(Rp.$$.fragment,ia),yTo=i(ia),T(Pp.$$.fragment,ia),ia.forEach(t),xTo=i(il),Bp=n(il,"DIV",{class:!0});var oUe=s(Bp);T(my.$$.fragment,oUe),$To=i(oUe),ffe=n(oUe,"P",{});var u1t=s(ffe);kTo=r(u1t,"Register a new feature extractor for this class."),u1t.forEach(t),oUe.forEach(t),il.forEach(t),JWe=i(f),Hi=n(f,"H2",{class:!0});var rUe=s(Hi);Ip=n(rUe,"A",{id:!0,class:!0,href:!0});var b1t=s(Ip);mfe=n(b1t,"SPAN",{});var v1t=s(mfe);T(gy.$$.fragment,v1t),v1t.forEach(t),b1t.forEach(t),STo=i(rUe),gfe=n(rUe,"SPAN",{});var F1t=s(gfe);RTo=r(F1t,"AutoProcessor"),F1t.forEach(t),rUe.forEach(t),YWe=i(f),ko=n(f,"DIV",{class:!0});var dl=s(ko);T(hy.$$.fragment,dl),PTo=i(dl),py=n(dl,"P",{});var tUe=s(py);BTo=r(tUe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Bj=n(tUe,"A",{href:!0});var T1t=s(Bj);ITo=r(T1t,"AutoProcessor.from_pretrained()"),T1t.forEach(t),NTo=r(tUe," class method."),tUe.forEach(t),qTo=i(dl),_y=n(dl,"P",{});var aUe=s(_y);jTo=r(aUe,"This class cannot be instantiated directly using "),hfe=n(aUe,"CODE",{});var M1t=s(hfe);DTo=r(M1t,"__init__()"),M1t.forEach(t),GTo=r(aUe," (throws an error)."),aUe.forEach(t),OTo=i(dl),Je=n(dl,"DIV",{class:!0});var da=s(Je);T(uy.$$.fragment,da),VTo=i(da),pfe=n(da,"P",{});var E1t=s(pfe);XTo=r(E1t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),E1t.forEach(t),zTo=i(da),Ui=n(da,"P",{});var nae=s(Ui);WTo=r(nae,"The processor class to instantiate is selected based on the "),_fe=n(nae,"CODE",{});var C1t=s(_fe);QTo=r(C1t,"model_type"),C1t.forEach(t),HTo=r(nae,` property of the config object (either
passed as an argument or loaded from `),ufe=n(nae,"CODE",{});var w1t=s(ufe);UTo=r(w1t,"pretrained_model_name_or_path"),w1t.forEach(t),JTo=r(nae," if possible):"),nae.forEach(t),YTo=i(da),fe=n(da,"UL",{});var _e=s(fe);Np=n(_e,"LI",{});var H$e=s(Np);bfe=n(H$e,"STRONG",{});var A1t=s(bfe);KTo=r(A1t,"clip"),A1t.forEach(t),ZTo=r(H$e," \u2014 "),Ij=n(H$e,"A",{href:!0});var L1t=s(Ij);e9o=r(L1t,"CLIPProcessor"),L1t.forEach(t),o9o=r(H$e," (CLIP model)"),H$e.forEach(t),r9o=i(_e),qp=n(_e,"LI",{});var U$e=s(qp);vfe=n(U$e,"STRONG",{});var y1t=s(vfe);t9o=r(y1t,"flava"),y1t.forEach(t),a9o=r(U$e," \u2014 "),Nj=n(U$e,"A",{href:!0});var x1t=s(Nj);n9o=r(x1t,"FlavaProcessor"),x1t.forEach(t),s9o=r(U$e," (FLAVA model)"),U$e.forEach(t),l9o=i(_e),jp=n(_e,"LI",{});var J$e=s(jp);Ffe=n(J$e,"STRONG",{});var $1t=s(Ffe);i9o=r($1t,"groupvit"),$1t.forEach(t),d9o=r(J$e," \u2014 "),qj=n(J$e,"A",{href:!0});var k1t=s(qj);c9o=r(k1t,"CLIPProcessor"),k1t.forEach(t),f9o=r(J$e," (GroupViT model)"),J$e.forEach(t),m9o=i(_e),Dp=n(_e,"LI",{});var Y$e=s(Dp);Tfe=n(Y$e,"STRONG",{});var S1t=s(Tfe);g9o=r(S1t,"layoutlmv2"),S1t.forEach(t),h9o=r(Y$e," \u2014 "),jj=n(Y$e,"A",{href:!0});var R1t=s(jj);p9o=r(R1t,"LayoutLMv2Processor"),R1t.forEach(t),_9o=r(Y$e," (LayoutLMv2 model)"),Y$e.forEach(t),u9o=i(_e),Gp=n(_e,"LI",{});var K$e=s(Gp);Mfe=n(K$e,"STRONG",{});var P1t=s(Mfe);b9o=r(P1t,"layoutlmv3"),P1t.forEach(t),v9o=r(K$e," \u2014 "),Dj=n(K$e,"A",{href:!0});var B1t=s(Dj);F9o=r(B1t,"LayoutLMv3Processor"),B1t.forEach(t),T9o=r(K$e," (LayoutLMv3 model)"),K$e.forEach(t),M9o=i(_e),Op=n(_e,"LI",{});var Z$e=s(Op);Efe=n(Z$e,"STRONG",{});var I1t=s(Efe);E9o=r(I1t,"layoutxlm"),I1t.forEach(t),C9o=r(Z$e," \u2014 "),Gj=n(Z$e,"A",{href:!0});var N1t=s(Gj);w9o=r(N1t,"LayoutXLMProcessor"),N1t.forEach(t),A9o=r(Z$e," (LayoutXLM model)"),Z$e.forEach(t),L9o=i(_e),Vp=n(_e,"LI",{});var eke=s(Vp);Cfe=n(eke,"STRONG",{});var q1t=s(Cfe);y9o=r(q1t,"owlvit"),q1t.forEach(t),x9o=r(eke," \u2014 "),Oj=n(eke,"A",{href:!0});var j1t=s(Oj);$9o=r(j1t,"OwlViTProcessor"),j1t.forEach(t),k9o=r(eke," (OWL-ViT model)"),eke.forEach(t),S9o=i(_e),Xp=n(_e,"LI",{});var oke=s(Xp);wfe=n(oke,"STRONG",{});var D1t=s(wfe);R9o=r(D1t,"sew"),D1t.forEach(t),P9o=r(oke," \u2014 "),Vj=n(oke,"A",{href:!0});var G1t=s(Vj);B9o=r(G1t,"Wav2Vec2Processor"),G1t.forEach(t),I9o=r(oke," (SEW model)"),oke.forEach(t),N9o=i(_e),zp=n(_e,"LI",{});var rke=s(zp);Afe=n(rke,"STRONG",{});var O1t=s(Afe);q9o=r(O1t,"sew-d"),O1t.forEach(t),j9o=r(rke," \u2014 "),Xj=n(rke,"A",{href:!0});var V1t=s(Xj);D9o=r(V1t,"Wav2Vec2Processor"),V1t.forEach(t),G9o=r(rke," (SEW-D model)"),rke.forEach(t),O9o=i(_e),Wp=n(_e,"LI",{});var tke=s(Wp);Lfe=n(tke,"STRONG",{});var X1t=s(Lfe);V9o=r(X1t,"speech_to_text"),X1t.forEach(t),X9o=r(tke," \u2014 "),zj=n(tke,"A",{href:!0});var z1t=s(zj);z9o=r(z1t,"Speech2TextProcessor"),z1t.forEach(t),W9o=r(tke," (Speech2Text model)"),tke.forEach(t),Q9o=i(_e),Qp=n(_e,"LI",{});var ake=s(Qp);yfe=n(ake,"STRONG",{});var W1t=s(yfe);H9o=r(W1t,"speech_to_text_2"),W1t.forEach(t),U9o=r(ake," \u2014 "),Wj=n(ake,"A",{href:!0});var Q1t=s(Wj);J9o=r(Q1t,"Speech2Text2Processor"),Q1t.forEach(t),Y9o=r(ake," (Speech2Text2 model)"),ake.forEach(t),K9o=i(_e),Hp=n(_e,"LI",{});var nke=s(Hp);xfe=n(nke,"STRONG",{});var H1t=s(xfe);Z9o=r(H1t,"trocr"),H1t.forEach(t),eMo=r(nke," \u2014 "),Qj=n(nke,"A",{href:!0});var U1t=s(Qj);oMo=r(U1t,"TrOCRProcessor"),U1t.forEach(t),rMo=r(nke," (TrOCR model)"),nke.forEach(t),tMo=i(_e),Up=n(_e,"LI",{});var ske=s(Up);$fe=n(ske,"STRONG",{});var J1t=s($fe);aMo=r(J1t,"unispeech"),J1t.forEach(t),nMo=r(ske," \u2014 "),Hj=n(ske,"A",{href:!0});var Y1t=s(Hj);sMo=r(Y1t,"Wav2Vec2Processor"),Y1t.forEach(t),lMo=r(ske," (UniSpeech model)"),ske.forEach(t),iMo=i(_e),Jp=n(_e,"LI",{});var lke=s(Jp);kfe=n(lke,"STRONG",{});var K1t=s(kfe);dMo=r(K1t,"unispeech-sat"),K1t.forEach(t),cMo=r(lke," \u2014 "),Uj=n(lke,"A",{href:!0});var Z1t=s(Uj);fMo=r(Z1t,"Wav2Vec2Processor"),Z1t.forEach(t),mMo=r(lke," (UniSpeechSat model)"),lke.forEach(t),gMo=i(_e),Yp=n(_e,"LI",{});var ike=s(Yp);Sfe=n(ike,"STRONG",{});var e2t=s(Sfe);hMo=r(e2t,"vilt"),e2t.forEach(t),pMo=r(ike," \u2014 "),Jj=n(ike,"A",{href:!0});var o2t=s(Jj);_Mo=r(o2t,"ViltProcessor"),o2t.forEach(t),uMo=r(ike," (ViLT model)"),ike.forEach(t),bMo=i(_e),Kp=n(_e,"LI",{});var dke=s(Kp);Rfe=n(dke,"STRONG",{});var r2t=s(Rfe);vMo=r(r2t,"vision-text-dual-encoder"),r2t.forEach(t),FMo=r(dke," \u2014 "),Yj=n(dke,"A",{href:!0});var t2t=s(Yj);TMo=r(t2t,"VisionTextDualEncoderProcessor"),t2t.forEach(t),MMo=r(dke," (VisionTextDualEncoder model)"),dke.forEach(t),EMo=i(_e),Zp=n(_e,"LI",{});var cke=s(Zp);Pfe=n(cke,"STRONG",{});var a2t=s(Pfe);CMo=r(a2t,"wav2vec2"),a2t.forEach(t),wMo=r(cke," \u2014 "),Kj=n(cke,"A",{href:!0});var n2t=s(Kj);AMo=r(n2t,"Wav2Vec2Processor"),n2t.forEach(t),LMo=r(cke," (Wav2Vec2 model)"),cke.forEach(t),yMo=i(_e),e_=n(_e,"LI",{});var fke=s(e_);Bfe=n(fke,"STRONG",{});var s2t=s(Bfe);xMo=r(s2t,"wav2vec2-conformer"),s2t.forEach(t),$Mo=r(fke," \u2014 "),Zj=n(fke,"A",{href:!0});var l2t=s(Zj);kMo=r(l2t,"Wav2Vec2Processor"),l2t.forEach(t),SMo=r(fke," (Wav2Vec2-Conformer model)"),fke.forEach(t),RMo=i(_e),o_=n(_e,"LI",{});var mke=s(o_);Ife=n(mke,"STRONG",{});var i2t=s(Ife);PMo=r(i2t,"wavlm"),i2t.forEach(t),BMo=r(mke," \u2014 "),eD=n(mke,"A",{href:!0});var d2t=s(eD);IMo=r(d2t,"Wav2Vec2Processor"),d2t.forEach(t),NMo=r(mke," (WavLM model)"),mke.forEach(t),_e.forEach(t),qMo=i(da),T(r_.$$.fragment,da),jMo=i(da),T(t_.$$.fragment,da),da.forEach(t),DMo=i(dl),a_=n(dl,"DIV",{class:!0});var nUe=s(a_);T(by.$$.fragment,nUe),GMo=i(nUe),Nfe=n(nUe,"P",{});var c2t=s(Nfe);OMo=r(c2t,"Register a new processor for this class."),c2t.forEach(t),nUe.forEach(t),dl.forEach(t),KWe=i(f),Ji=n(f,"H2",{class:!0});var sUe=s(Ji);n_=n(sUe,"A",{id:!0,class:!0,href:!0});var f2t=s(n_);qfe=n(f2t,"SPAN",{});var m2t=s(qfe);T(vy.$$.fragment,m2t),m2t.forEach(t),f2t.forEach(t),VMo=i(sUe),jfe=n(sUe,"SPAN",{});var g2t=s(jfe);XMo=r(g2t,"AutoModel"),g2t.forEach(t),sUe.forEach(t),ZWe=i(f),So=n(f,"DIV",{class:!0});var cl=s(So);T(Fy.$$.fragment,cl),zMo=i(cl),Yi=n(cl,"P",{});var sae=s(Yi);WMo=r(sae,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oD=n(sae,"A",{href:!0});var h2t=s(oD);QMo=r(h2t,"from_pretrained()"),h2t.forEach(t),HMo=r(sae," class method or the "),rD=n(sae,"A",{href:!0});var p2t=s(rD);UMo=r(p2t,"from_config()"),p2t.forEach(t),JMo=r(sae,` class
method.`),sae.forEach(t),YMo=i(cl),Ty=n(cl,"P",{});var lUe=s(Ty);KMo=r(lUe,"This class cannot be instantiated directly using "),Dfe=n(lUe,"CODE",{});var _2t=s(Dfe);ZMo=r(_2t,"__init__()"),_2t.forEach(t),eEo=r(lUe," (throws an error)."),lUe.forEach(t),oEo=i(cl),ct=n(cl,"DIV",{class:!0});var H6=s(ct);T(My.$$.fragment,H6),rEo=i(H6),Gfe=n(H6,"P",{});var u2t=s(Gfe);tEo=r(u2t,"Instantiates one of the base model classes of the library from a configuration."),u2t.forEach(t),aEo=i(H6),Ki=n(H6,"P",{});var lae=s(Ki);nEo=r(lae,`Note:
Loading a model from its configuration file does `),Ofe=n(lae,"STRONG",{});var b2t=s(Ofe);sEo=r(b2t,"not"),b2t.forEach(t),lEo=r(lae,` load the model weights. It only affects the
model\u2019s configuration. Use `),tD=n(lae,"A",{href:!0});var v2t=s(tD);iEo=r(v2t,"from_pretrained()"),v2t.forEach(t),dEo=r(lae," to load the model weights."),lae.forEach(t),cEo=i(H6),T(s_.$$.fragment,H6),H6.forEach(t),fEo=i(cl),Ye=n(cl,"DIV",{class:!0});var ca=s(Ye);T(Ey.$$.fragment,ca),mEo=i(ca),Vfe=n(ca,"P",{});var F2t=s(Vfe);gEo=r(F2t,"Instantiate one of the base model classes of the library from a pretrained model."),F2t.forEach(t),hEo=i(ca),Da=n(ca,"P",{});var U6=s(Da);pEo=r(U6,"The model class to instantiate is selected based on the "),Xfe=n(U6,"CODE",{});var T2t=s(Xfe);_Eo=r(T2t,"model_type"),T2t.forEach(t),uEo=r(U6,` property of the config object (either
passed as an argument or loaded from `),zfe=n(U6,"CODE",{});var M2t=s(zfe);bEo=r(M2t,"pretrained_model_name_or_path"),M2t.forEach(t),vEo=r(U6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Wfe=n(U6,"CODE",{});var E2t=s(Wfe);FEo=r(E2t,"pretrained_model_name_or_path"),E2t.forEach(t),TEo=r(U6,":"),U6.forEach(t),MEo=i(ca),y=n(ca,"UL",{});var x=s(y);l_=n(x,"LI",{});var gke=s(l_);Qfe=n(gke,"STRONG",{});var C2t=s(Qfe);EEo=r(C2t,"albert"),C2t.forEach(t),CEo=r(gke," \u2014 "),aD=n(gke,"A",{href:!0});var w2t=s(aD);wEo=r(w2t,"AlbertModel"),w2t.forEach(t),AEo=r(gke," (ALBERT model)"),gke.forEach(t),LEo=i(x),i_=n(x,"LI",{});var hke=s(i_);Hfe=n(hke,"STRONG",{});var A2t=s(Hfe);yEo=r(A2t,"bart"),A2t.forEach(t),xEo=r(hke," \u2014 "),nD=n(hke,"A",{href:!0});var L2t=s(nD);$Eo=r(L2t,"BartModel"),L2t.forEach(t),kEo=r(hke," (BART model)"),hke.forEach(t),SEo=i(x),d_=n(x,"LI",{});var pke=s(d_);Ufe=n(pke,"STRONG",{});var y2t=s(Ufe);REo=r(y2t,"beit"),y2t.forEach(t),PEo=r(pke," \u2014 "),sD=n(pke,"A",{href:!0});var x2t=s(sD);BEo=r(x2t,"BeitModel"),x2t.forEach(t),IEo=r(pke," (BEiT model)"),pke.forEach(t),NEo=i(x),c_=n(x,"LI",{});var _ke=s(c_);Jfe=n(_ke,"STRONG",{});var $2t=s(Jfe);qEo=r($2t,"bert"),$2t.forEach(t),jEo=r(_ke," \u2014 "),lD=n(_ke,"A",{href:!0});var k2t=s(lD);DEo=r(k2t,"BertModel"),k2t.forEach(t),GEo=r(_ke," (BERT model)"),_ke.forEach(t),OEo=i(x),f_=n(x,"LI",{});var uke=s(f_);Yfe=n(uke,"STRONG",{});var S2t=s(Yfe);VEo=r(S2t,"bert-generation"),S2t.forEach(t),XEo=r(uke," \u2014 "),iD=n(uke,"A",{href:!0});var R2t=s(iD);zEo=r(R2t,"BertGenerationEncoder"),R2t.forEach(t),WEo=r(uke," (Bert Generation model)"),uke.forEach(t),QEo=i(x),m_=n(x,"LI",{});var bke=s(m_);Kfe=n(bke,"STRONG",{});var P2t=s(Kfe);HEo=r(P2t,"big_bird"),P2t.forEach(t),UEo=r(bke," \u2014 "),dD=n(bke,"A",{href:!0});var B2t=s(dD);JEo=r(B2t,"BigBirdModel"),B2t.forEach(t),YEo=r(bke," (BigBird model)"),bke.forEach(t),KEo=i(x),g_=n(x,"LI",{});var vke=s(g_);Zfe=n(vke,"STRONG",{});var I2t=s(Zfe);ZEo=r(I2t,"bigbird_pegasus"),I2t.forEach(t),e4o=r(vke," \u2014 "),cD=n(vke,"A",{href:!0});var N2t=s(cD);o4o=r(N2t,"BigBirdPegasusModel"),N2t.forEach(t),r4o=r(vke," (BigBird-Pegasus model)"),vke.forEach(t),t4o=i(x),h_=n(x,"LI",{});var Fke=s(h_);eme=n(Fke,"STRONG",{});var q2t=s(eme);a4o=r(q2t,"blenderbot"),q2t.forEach(t),n4o=r(Fke," \u2014 "),fD=n(Fke,"A",{href:!0});var j2t=s(fD);s4o=r(j2t,"BlenderbotModel"),j2t.forEach(t),l4o=r(Fke," (Blenderbot model)"),Fke.forEach(t),i4o=i(x),p_=n(x,"LI",{});var Tke=s(p_);ome=n(Tke,"STRONG",{});var D2t=s(ome);d4o=r(D2t,"blenderbot-small"),D2t.forEach(t),c4o=r(Tke," \u2014 "),mD=n(Tke,"A",{href:!0});var G2t=s(mD);f4o=r(G2t,"BlenderbotSmallModel"),G2t.forEach(t),m4o=r(Tke," (BlenderbotSmall model)"),Tke.forEach(t),g4o=i(x),__=n(x,"LI",{});var Mke=s(__);rme=n(Mke,"STRONG",{});var O2t=s(rme);h4o=r(O2t,"bloom"),O2t.forEach(t),p4o=r(Mke," \u2014 "),gD=n(Mke,"A",{href:!0});var V2t=s(gD);_4o=r(V2t,"BloomModel"),V2t.forEach(t),u4o=r(Mke," (BLOOM model)"),Mke.forEach(t),b4o=i(x),u_=n(x,"LI",{});var Eke=s(u_);tme=n(Eke,"STRONG",{});var X2t=s(tme);v4o=r(X2t,"camembert"),X2t.forEach(t),F4o=r(Eke," \u2014 "),hD=n(Eke,"A",{href:!0});var z2t=s(hD);T4o=r(z2t,"CamembertModel"),z2t.forEach(t),M4o=r(Eke," (CamemBERT model)"),Eke.forEach(t),E4o=i(x),b_=n(x,"LI",{});var Cke=s(b_);ame=n(Cke,"STRONG",{});var W2t=s(ame);C4o=r(W2t,"canine"),W2t.forEach(t),w4o=r(Cke," \u2014 "),pD=n(Cke,"A",{href:!0});var Q2t=s(pD);A4o=r(Q2t,"CanineModel"),Q2t.forEach(t),L4o=r(Cke," (CANINE model)"),Cke.forEach(t),y4o=i(x),v_=n(x,"LI",{});var wke=s(v_);nme=n(wke,"STRONG",{});var H2t=s(nme);x4o=r(H2t,"clip"),H2t.forEach(t),$4o=r(wke," \u2014 "),_D=n(wke,"A",{href:!0});var U2t=s(_D);k4o=r(U2t,"CLIPModel"),U2t.forEach(t),S4o=r(wke," (CLIP model)"),wke.forEach(t),R4o=i(x),F_=n(x,"LI",{});var Ake=s(F_);sme=n(Ake,"STRONG",{});var J2t=s(sme);P4o=r(J2t,"codegen"),J2t.forEach(t),B4o=r(Ake," \u2014 "),uD=n(Ake,"A",{href:!0});var Y2t=s(uD);I4o=r(Y2t,"CodeGenModel"),Y2t.forEach(t),N4o=r(Ake," (CodeGen model)"),Ake.forEach(t),q4o=i(x),T_=n(x,"LI",{});var Lke=s(T_);lme=n(Lke,"STRONG",{});var K2t=s(lme);j4o=r(K2t,"convbert"),K2t.forEach(t),D4o=r(Lke," \u2014 "),bD=n(Lke,"A",{href:!0});var Z2t=s(bD);G4o=r(Z2t,"ConvBertModel"),Z2t.forEach(t),O4o=r(Lke," (ConvBERT model)"),Lke.forEach(t),V4o=i(x),M_=n(x,"LI",{});var yke=s(M_);ime=n(yke,"STRONG",{});var ebt=s(ime);X4o=r(ebt,"convnext"),ebt.forEach(t),z4o=r(yke," \u2014 "),vD=n(yke,"A",{href:!0});var obt=s(vD);W4o=r(obt,"ConvNextModel"),obt.forEach(t),Q4o=r(yke," (ConvNeXT model)"),yke.forEach(t),H4o=i(x),E_=n(x,"LI",{});var xke=s(E_);dme=n(xke,"STRONG",{});var rbt=s(dme);U4o=r(rbt,"ctrl"),rbt.forEach(t),J4o=r(xke," \u2014 "),FD=n(xke,"A",{href:!0});var tbt=s(FD);Y4o=r(tbt,"CTRLModel"),tbt.forEach(t),K4o=r(xke," (CTRL model)"),xke.forEach(t),Z4o=i(x),C_=n(x,"LI",{});var $ke=s(C_);cme=n($ke,"STRONG",{});var abt=s(cme);eCo=r(abt,"cvt"),abt.forEach(t),oCo=r($ke," \u2014 "),TD=n($ke,"A",{href:!0});var nbt=s(TD);rCo=r(nbt,"CvtModel"),nbt.forEach(t),tCo=r($ke," (CvT model)"),$ke.forEach(t),aCo=i(x),w_=n(x,"LI",{});var kke=s(w_);fme=n(kke,"STRONG",{});var sbt=s(fme);nCo=r(sbt,"data2vec-audio"),sbt.forEach(t),sCo=r(kke," \u2014 "),MD=n(kke,"A",{href:!0});var lbt=s(MD);lCo=r(lbt,"Data2VecAudioModel"),lbt.forEach(t),iCo=r(kke," (Data2VecAudio model)"),kke.forEach(t),dCo=i(x),A_=n(x,"LI",{});var Ske=s(A_);mme=n(Ske,"STRONG",{});var ibt=s(mme);cCo=r(ibt,"data2vec-text"),ibt.forEach(t),fCo=r(Ske," \u2014 "),ED=n(Ske,"A",{href:!0});var dbt=s(ED);mCo=r(dbt,"Data2VecTextModel"),dbt.forEach(t),gCo=r(Ske," (Data2VecText model)"),Ske.forEach(t),hCo=i(x),L_=n(x,"LI",{});var Rke=s(L_);gme=n(Rke,"STRONG",{});var cbt=s(gme);pCo=r(cbt,"data2vec-vision"),cbt.forEach(t),_Co=r(Rke," \u2014 "),CD=n(Rke,"A",{href:!0});var fbt=s(CD);uCo=r(fbt,"Data2VecVisionModel"),fbt.forEach(t),bCo=r(Rke," (Data2VecVision model)"),Rke.forEach(t),vCo=i(x),y_=n(x,"LI",{});var Pke=s(y_);hme=n(Pke,"STRONG",{});var mbt=s(hme);FCo=r(mbt,"deberta"),mbt.forEach(t),TCo=r(Pke," \u2014 "),wD=n(Pke,"A",{href:!0});var gbt=s(wD);MCo=r(gbt,"DebertaModel"),gbt.forEach(t),ECo=r(Pke," (DeBERTa model)"),Pke.forEach(t),CCo=i(x),x_=n(x,"LI",{});var Bke=s(x_);pme=n(Bke,"STRONG",{});var hbt=s(pme);wCo=r(hbt,"deberta-v2"),hbt.forEach(t),ACo=r(Bke," \u2014 "),AD=n(Bke,"A",{href:!0});var pbt=s(AD);LCo=r(pbt,"DebertaV2Model"),pbt.forEach(t),yCo=r(Bke," (DeBERTa-v2 model)"),Bke.forEach(t),xCo=i(x),$_=n(x,"LI",{});var Ike=s($_);_me=n(Ike,"STRONG",{});var _bt=s(_me);$Co=r(_bt,"decision_transformer"),_bt.forEach(t),kCo=r(Ike," \u2014 "),LD=n(Ike,"A",{href:!0});var ubt=s(LD);SCo=r(ubt,"DecisionTransformerModel"),ubt.forEach(t),RCo=r(Ike," (Decision Transformer model)"),Ike.forEach(t),PCo=i(x),k_=n(x,"LI",{});var Nke=s(k_);ume=n(Nke,"STRONG",{});var bbt=s(ume);BCo=r(bbt,"deit"),bbt.forEach(t),ICo=r(Nke," \u2014 "),yD=n(Nke,"A",{href:!0});var vbt=s(yD);NCo=r(vbt,"DeiTModel"),vbt.forEach(t),qCo=r(Nke," (DeiT model)"),Nke.forEach(t),jCo=i(x),S_=n(x,"LI",{});var qke=s(S_);bme=n(qke,"STRONG",{});var Fbt=s(bme);DCo=r(Fbt,"detr"),Fbt.forEach(t),GCo=r(qke," \u2014 "),xD=n(qke,"A",{href:!0});var Tbt=s(xD);OCo=r(Tbt,"DetrModel"),Tbt.forEach(t),VCo=r(qke," (DETR model)"),qke.forEach(t),XCo=i(x),R_=n(x,"LI",{});var jke=s(R_);vme=n(jke,"STRONG",{});var Mbt=s(vme);zCo=r(Mbt,"distilbert"),Mbt.forEach(t),WCo=r(jke," \u2014 "),$D=n(jke,"A",{href:!0});var Ebt=s($D);QCo=r(Ebt,"DistilBertModel"),Ebt.forEach(t),HCo=r(jke," (DistilBERT model)"),jke.forEach(t),UCo=i(x),P_=n(x,"LI",{});var Dke=s(P_);Fme=n(Dke,"STRONG",{});var Cbt=s(Fme);JCo=r(Cbt,"dpr"),Cbt.forEach(t),YCo=r(Dke," \u2014 "),kD=n(Dke,"A",{href:!0});var wbt=s(kD);KCo=r(wbt,"DPRQuestionEncoder"),wbt.forEach(t),ZCo=r(Dke," (DPR model)"),Dke.forEach(t),e3o=i(x),B_=n(x,"LI",{});var Gke=s(B_);Tme=n(Gke,"STRONG",{});var Abt=s(Tme);o3o=r(Abt,"dpt"),Abt.forEach(t),r3o=r(Gke," \u2014 "),SD=n(Gke,"A",{href:!0});var Lbt=s(SD);t3o=r(Lbt,"DPTModel"),Lbt.forEach(t),a3o=r(Gke," (DPT model)"),Gke.forEach(t),n3o=i(x),I_=n(x,"LI",{});var Oke=s(I_);Mme=n(Oke,"STRONG",{});var ybt=s(Mme);s3o=r(ybt,"electra"),ybt.forEach(t),l3o=r(Oke," \u2014 "),RD=n(Oke,"A",{href:!0});var xbt=s(RD);i3o=r(xbt,"ElectraModel"),xbt.forEach(t),d3o=r(Oke," (ELECTRA model)"),Oke.forEach(t),c3o=i(x),N_=n(x,"LI",{});var Vke=s(N_);Eme=n(Vke,"STRONG",{});var $bt=s(Eme);f3o=r($bt,"flaubert"),$bt.forEach(t),m3o=r(Vke," \u2014 "),PD=n(Vke,"A",{href:!0});var kbt=s(PD);g3o=r(kbt,"FlaubertModel"),kbt.forEach(t),h3o=r(Vke," (FlauBERT model)"),Vke.forEach(t),p3o=i(x),q_=n(x,"LI",{});var Xke=s(q_);Cme=n(Xke,"STRONG",{});var Sbt=s(Cme);_3o=r(Sbt,"flava"),Sbt.forEach(t),u3o=r(Xke," \u2014 "),BD=n(Xke,"A",{href:!0});var Rbt=s(BD);b3o=r(Rbt,"FlavaModel"),Rbt.forEach(t),v3o=r(Xke," (FLAVA model)"),Xke.forEach(t),F3o=i(x),j_=n(x,"LI",{});var zke=s(j_);wme=n(zke,"STRONG",{});var Pbt=s(wme);T3o=r(Pbt,"fnet"),Pbt.forEach(t),M3o=r(zke," \u2014 "),ID=n(zke,"A",{href:!0});var Bbt=s(ID);E3o=r(Bbt,"FNetModel"),Bbt.forEach(t),C3o=r(zke," (FNet model)"),zke.forEach(t),w3o=i(x),D_=n(x,"LI",{});var Wke=s(D_);Ame=n(Wke,"STRONG",{});var Ibt=s(Ame);A3o=r(Ibt,"fsmt"),Ibt.forEach(t),L3o=r(Wke," \u2014 "),ND=n(Wke,"A",{href:!0});var Nbt=s(ND);y3o=r(Nbt,"FSMTModel"),Nbt.forEach(t),x3o=r(Wke," (FairSeq Machine-Translation model)"),Wke.forEach(t),$3o=i(x),ol=n(x,"LI",{});var AR=s(ol);Lme=n(AR,"STRONG",{});var qbt=s(Lme);k3o=r(qbt,"funnel"),qbt.forEach(t),S3o=r(AR," \u2014 "),qD=n(AR,"A",{href:!0});var jbt=s(qD);R3o=r(jbt,"FunnelModel"),jbt.forEach(t),P3o=r(AR," or "),jD=n(AR,"A",{href:!0});var Dbt=s(jD);B3o=r(Dbt,"FunnelBaseModel"),Dbt.forEach(t),I3o=r(AR," (Funnel Transformer model)"),AR.forEach(t),N3o=i(x),G_=n(x,"LI",{});var Qke=s(G_);yme=n(Qke,"STRONG",{});var Gbt=s(yme);q3o=r(Gbt,"glpn"),Gbt.forEach(t),j3o=r(Qke," \u2014 "),DD=n(Qke,"A",{href:!0});var Obt=s(DD);D3o=r(Obt,"GLPNModel"),Obt.forEach(t),G3o=r(Qke," (GLPN model)"),Qke.forEach(t),O3o=i(x),O_=n(x,"LI",{});var Hke=s(O_);xme=n(Hke,"STRONG",{});var Vbt=s(xme);V3o=r(Vbt,"gpt2"),Vbt.forEach(t),X3o=r(Hke," \u2014 "),GD=n(Hke,"A",{href:!0});var Xbt=s(GD);z3o=r(Xbt,"GPT2Model"),Xbt.forEach(t),W3o=r(Hke," (OpenAI GPT-2 model)"),Hke.forEach(t),Q3o=i(x),V_=n(x,"LI",{});var Uke=s(V_);$me=n(Uke,"STRONG",{});var zbt=s($me);H3o=r(zbt,"gpt_neo"),zbt.forEach(t),U3o=r(Uke," \u2014 "),OD=n(Uke,"A",{href:!0});var Wbt=s(OD);J3o=r(Wbt,"GPTNeoModel"),Wbt.forEach(t),Y3o=r(Uke," (GPT Neo model)"),Uke.forEach(t),K3o=i(x),X_=n(x,"LI",{});var Jke=s(X_);kme=n(Jke,"STRONG",{});var Qbt=s(kme);Z3o=r(Qbt,"gpt_neox"),Qbt.forEach(t),e5o=r(Jke," \u2014 "),VD=n(Jke,"A",{href:!0});var Hbt=s(VD);o5o=r(Hbt,"GPTNeoXModel"),Hbt.forEach(t),r5o=r(Jke," (GPT NeoX model)"),Jke.forEach(t),t5o=i(x),z_=n(x,"LI",{});var Yke=s(z_);Sme=n(Yke,"STRONG",{});var Ubt=s(Sme);a5o=r(Ubt,"gptj"),Ubt.forEach(t),n5o=r(Yke," \u2014 "),XD=n(Yke,"A",{href:!0});var Jbt=s(XD);s5o=r(Jbt,"GPTJModel"),Jbt.forEach(t),l5o=r(Yke," (GPT-J model)"),Yke.forEach(t),i5o=i(x),W_=n(x,"LI",{});var Kke=s(W_);Rme=n(Kke,"STRONG",{});var Ybt=s(Rme);d5o=r(Ybt,"groupvit"),Ybt.forEach(t),c5o=r(Kke," \u2014 "),zD=n(Kke,"A",{href:!0});var Kbt=s(zD);f5o=r(Kbt,"GroupViTModel"),Kbt.forEach(t),m5o=r(Kke," (GroupViT model)"),Kke.forEach(t),g5o=i(x),Q_=n(x,"LI",{});var Zke=s(Q_);Pme=n(Zke,"STRONG",{});var Zbt=s(Pme);h5o=r(Zbt,"hubert"),Zbt.forEach(t),p5o=r(Zke," \u2014 "),WD=n(Zke,"A",{href:!0});var evt=s(WD);_5o=r(evt,"HubertModel"),evt.forEach(t),u5o=r(Zke," (Hubert model)"),Zke.forEach(t),b5o=i(x),H_=n(x,"LI",{});var eSe=s(H_);Bme=n(eSe,"STRONG",{});var ovt=s(Bme);v5o=r(ovt,"ibert"),ovt.forEach(t),F5o=r(eSe," \u2014 "),QD=n(eSe,"A",{href:!0});var rvt=s(QD);T5o=r(rvt,"IBertModel"),rvt.forEach(t),M5o=r(eSe," (I-BERT model)"),eSe.forEach(t),E5o=i(x),U_=n(x,"LI",{});var oSe=s(U_);Ime=n(oSe,"STRONG",{});var tvt=s(Ime);C5o=r(tvt,"imagegpt"),tvt.forEach(t),w5o=r(oSe," \u2014 "),HD=n(oSe,"A",{href:!0});var avt=s(HD);A5o=r(avt,"ImageGPTModel"),avt.forEach(t),L5o=r(oSe," (ImageGPT model)"),oSe.forEach(t),y5o=i(x),J_=n(x,"LI",{});var rSe=s(J_);Nme=n(rSe,"STRONG",{});var nvt=s(Nme);x5o=r(nvt,"layoutlm"),nvt.forEach(t),$5o=r(rSe," \u2014 "),UD=n(rSe,"A",{href:!0});var svt=s(UD);k5o=r(svt,"LayoutLMModel"),svt.forEach(t),S5o=r(rSe," (LayoutLM model)"),rSe.forEach(t),R5o=i(x),Y_=n(x,"LI",{});var tSe=s(Y_);qme=n(tSe,"STRONG",{});var lvt=s(qme);P5o=r(lvt,"layoutlmv2"),lvt.forEach(t),B5o=r(tSe," \u2014 "),JD=n(tSe,"A",{href:!0});var ivt=s(JD);I5o=r(ivt,"LayoutLMv2Model"),ivt.forEach(t),N5o=r(tSe," (LayoutLMv2 model)"),tSe.forEach(t),q5o=i(x),K_=n(x,"LI",{});var aSe=s(K_);jme=n(aSe,"STRONG",{});var dvt=s(jme);j5o=r(dvt,"layoutlmv3"),dvt.forEach(t),D5o=r(aSe," \u2014 "),YD=n(aSe,"A",{href:!0});var cvt=s(YD);G5o=r(cvt,"LayoutLMv3Model"),cvt.forEach(t),O5o=r(aSe," (LayoutLMv3 model)"),aSe.forEach(t),V5o=i(x),Z_=n(x,"LI",{});var nSe=s(Z_);Dme=n(nSe,"STRONG",{});var fvt=s(Dme);X5o=r(fvt,"led"),fvt.forEach(t),z5o=r(nSe," \u2014 "),KD=n(nSe,"A",{href:!0});var mvt=s(KD);W5o=r(mvt,"LEDModel"),mvt.forEach(t),Q5o=r(nSe," (LED model)"),nSe.forEach(t),H5o=i(x),eu=n(x,"LI",{});var sSe=s(eu);Gme=n(sSe,"STRONG",{});var gvt=s(Gme);U5o=r(gvt,"levit"),gvt.forEach(t),J5o=r(sSe," \u2014 "),ZD=n(sSe,"A",{href:!0});var hvt=s(ZD);Y5o=r(hvt,"LevitModel"),hvt.forEach(t),K5o=r(sSe," (LeViT model)"),sSe.forEach(t),Z5o=i(x),ou=n(x,"LI",{});var lSe=s(ou);Ome=n(lSe,"STRONG",{});var pvt=s(Ome);e0o=r(pvt,"longformer"),pvt.forEach(t),o0o=r(lSe," \u2014 "),eG=n(lSe,"A",{href:!0});var _vt=s(eG);r0o=r(_vt,"LongformerModel"),_vt.forEach(t),t0o=r(lSe," (Longformer model)"),lSe.forEach(t),a0o=i(x),ru=n(x,"LI",{});var iSe=s(ru);Vme=n(iSe,"STRONG",{});var uvt=s(Vme);n0o=r(uvt,"longt5"),uvt.forEach(t),s0o=r(iSe," \u2014 "),oG=n(iSe,"A",{href:!0});var bvt=s(oG);l0o=r(bvt,"LongT5Model"),bvt.forEach(t),i0o=r(iSe," (LongT5 model)"),iSe.forEach(t),d0o=i(x),tu=n(x,"LI",{});var dSe=s(tu);Xme=n(dSe,"STRONG",{});var vvt=s(Xme);c0o=r(vvt,"luke"),vvt.forEach(t),f0o=r(dSe," \u2014 "),rG=n(dSe,"A",{href:!0});var Fvt=s(rG);m0o=r(Fvt,"LukeModel"),Fvt.forEach(t),g0o=r(dSe," (LUKE model)"),dSe.forEach(t),h0o=i(x),au=n(x,"LI",{});var cSe=s(au);zme=n(cSe,"STRONG",{});var Tvt=s(zme);p0o=r(Tvt,"lxmert"),Tvt.forEach(t),_0o=r(cSe," \u2014 "),tG=n(cSe,"A",{href:!0});var Mvt=s(tG);u0o=r(Mvt,"LxmertModel"),Mvt.forEach(t),b0o=r(cSe," (LXMERT model)"),cSe.forEach(t),v0o=i(x),nu=n(x,"LI",{});var fSe=s(nu);Wme=n(fSe,"STRONG",{});var Evt=s(Wme);F0o=r(Evt,"m2m_100"),Evt.forEach(t),T0o=r(fSe," \u2014 "),aG=n(fSe,"A",{href:!0});var Cvt=s(aG);M0o=r(Cvt,"M2M100Model"),Cvt.forEach(t),E0o=r(fSe," (M2M100 model)"),fSe.forEach(t),C0o=i(x),su=n(x,"LI",{});var mSe=s(su);Qme=n(mSe,"STRONG",{});var wvt=s(Qme);w0o=r(wvt,"marian"),wvt.forEach(t),A0o=r(mSe," \u2014 "),nG=n(mSe,"A",{href:!0});var Avt=s(nG);L0o=r(Avt,"MarianModel"),Avt.forEach(t),y0o=r(mSe," (Marian model)"),mSe.forEach(t),x0o=i(x),lu=n(x,"LI",{});var gSe=s(lu);Hme=n(gSe,"STRONG",{});var Lvt=s(Hme);$0o=r(Lvt,"maskformer"),Lvt.forEach(t),k0o=r(gSe," \u2014 "),sG=n(gSe,"A",{href:!0});var yvt=s(sG);S0o=r(yvt,"MaskFormerModel"),yvt.forEach(t),R0o=r(gSe," (MaskFormer model)"),gSe.forEach(t),P0o=i(x),iu=n(x,"LI",{});var hSe=s(iu);Ume=n(hSe,"STRONG",{});var xvt=s(Ume);B0o=r(xvt,"mbart"),xvt.forEach(t),I0o=r(hSe," \u2014 "),lG=n(hSe,"A",{href:!0});var $vt=s(lG);N0o=r($vt,"MBartModel"),$vt.forEach(t),q0o=r(hSe," (mBART model)"),hSe.forEach(t),j0o=i(x),du=n(x,"LI",{});var pSe=s(du);Jme=n(pSe,"STRONG",{});var kvt=s(Jme);D0o=r(kvt,"mctct"),kvt.forEach(t),G0o=r(pSe," \u2014 "),iG=n(pSe,"A",{href:!0});var Svt=s(iG);O0o=r(Svt,"MCTCTModel"),Svt.forEach(t),V0o=r(pSe," (M-CTC-T model)"),pSe.forEach(t),X0o=i(x),cu=n(x,"LI",{});var _Se=s(cu);Yme=n(_Se,"STRONG",{});var Rvt=s(Yme);z0o=r(Rvt,"megatron-bert"),Rvt.forEach(t),W0o=r(_Se," \u2014 "),dG=n(_Se,"A",{href:!0});var Pvt=s(dG);Q0o=r(Pvt,"MegatronBertModel"),Pvt.forEach(t),H0o=r(_Se," (Megatron-BERT model)"),_Se.forEach(t),U0o=i(x),fu=n(x,"LI",{});var uSe=s(fu);Kme=n(uSe,"STRONG",{});var Bvt=s(Kme);J0o=r(Bvt,"mobilebert"),Bvt.forEach(t),Y0o=r(uSe," \u2014 "),cG=n(uSe,"A",{href:!0});var Ivt=s(cG);K0o=r(Ivt,"MobileBertModel"),Ivt.forEach(t),Z0o=r(uSe," (MobileBERT model)"),uSe.forEach(t),ewo=i(x),mu=n(x,"LI",{});var bSe=s(mu);Zme=n(bSe,"STRONG",{});var Nvt=s(Zme);owo=r(Nvt,"mobilevit"),Nvt.forEach(t),rwo=r(bSe," \u2014 "),fG=n(bSe,"A",{href:!0});var qvt=s(fG);two=r(qvt,"MobileViTModel"),qvt.forEach(t),awo=r(bSe," (MobileViT model)"),bSe.forEach(t),nwo=i(x),gu=n(x,"LI",{});var vSe=s(gu);ege=n(vSe,"STRONG",{});var jvt=s(ege);swo=r(jvt,"mpnet"),jvt.forEach(t),lwo=r(vSe," \u2014 "),mG=n(vSe,"A",{href:!0});var Dvt=s(mG);iwo=r(Dvt,"MPNetModel"),Dvt.forEach(t),dwo=r(vSe," (MPNet model)"),vSe.forEach(t),cwo=i(x),hu=n(x,"LI",{});var FSe=s(hu);oge=n(FSe,"STRONG",{});var Gvt=s(oge);fwo=r(Gvt,"mt5"),Gvt.forEach(t),mwo=r(FSe," \u2014 "),gG=n(FSe,"A",{href:!0});var Ovt=s(gG);gwo=r(Ovt,"MT5Model"),Ovt.forEach(t),hwo=r(FSe," (MT5 model)"),FSe.forEach(t),pwo=i(x),pu=n(x,"LI",{});var TSe=s(pu);rge=n(TSe,"STRONG",{});var Vvt=s(rge);_wo=r(Vvt,"mvp"),Vvt.forEach(t),uwo=r(TSe," \u2014 "),hG=n(TSe,"A",{href:!0});var Xvt=s(hG);bwo=r(Xvt,"MvpModel"),Xvt.forEach(t),vwo=r(TSe," (MVP model)"),TSe.forEach(t),Fwo=i(x),_u=n(x,"LI",{});var MSe=s(_u);tge=n(MSe,"STRONG",{});var zvt=s(tge);Two=r(zvt,"nezha"),zvt.forEach(t),Mwo=r(MSe," \u2014 "),pG=n(MSe,"A",{href:!0});var Wvt=s(pG);Ewo=r(Wvt,"NezhaModel"),Wvt.forEach(t),Cwo=r(MSe," (Nezha model)"),MSe.forEach(t),wwo=i(x),uu=n(x,"LI",{});var ESe=s(uu);age=n(ESe,"STRONG",{});var Qvt=s(age);Awo=r(Qvt,"nllb"),Qvt.forEach(t),Lwo=r(ESe," \u2014 "),_G=n(ESe,"A",{href:!0});var Hvt=s(_G);ywo=r(Hvt,"M2M100Model"),Hvt.forEach(t),xwo=r(ESe," (NLLB model)"),ESe.forEach(t),$wo=i(x),bu=n(x,"LI",{});var CSe=s(bu);nge=n(CSe,"STRONG",{});var Uvt=s(nge);kwo=r(Uvt,"nystromformer"),Uvt.forEach(t),Swo=r(CSe," \u2014 "),uG=n(CSe,"A",{href:!0});var Jvt=s(uG);Rwo=r(Jvt,"NystromformerModel"),Jvt.forEach(t),Pwo=r(CSe," (Nystr\xF6mformer model)"),CSe.forEach(t),Bwo=i(x),vu=n(x,"LI",{});var wSe=s(vu);sge=n(wSe,"STRONG",{});var Yvt=s(sge);Iwo=r(Yvt,"openai-gpt"),Yvt.forEach(t),Nwo=r(wSe," \u2014 "),bG=n(wSe,"A",{href:!0});var Kvt=s(bG);qwo=r(Kvt,"OpenAIGPTModel"),Kvt.forEach(t),jwo=r(wSe," (OpenAI GPT model)"),wSe.forEach(t),Dwo=i(x),Fu=n(x,"LI",{});var ASe=s(Fu);lge=n(ASe,"STRONG",{});var Zvt=s(lge);Gwo=r(Zvt,"opt"),Zvt.forEach(t),Owo=r(ASe," \u2014 "),vG=n(ASe,"A",{href:!0});var eFt=s(vG);Vwo=r(eFt,"OPTModel"),eFt.forEach(t),Xwo=r(ASe," (OPT model)"),ASe.forEach(t),zwo=i(x),Tu=n(x,"LI",{});var LSe=s(Tu);ige=n(LSe,"STRONG",{});var oFt=s(ige);Wwo=r(oFt,"owlvit"),oFt.forEach(t),Qwo=r(LSe," \u2014 "),FG=n(LSe,"A",{href:!0});var rFt=s(FG);Hwo=r(rFt,"OwlViTModel"),rFt.forEach(t),Uwo=r(LSe," (OWL-ViT model)"),LSe.forEach(t),Jwo=i(x),Mu=n(x,"LI",{});var ySe=s(Mu);dge=n(ySe,"STRONG",{});var tFt=s(dge);Ywo=r(tFt,"pegasus"),tFt.forEach(t),Kwo=r(ySe," \u2014 "),TG=n(ySe,"A",{href:!0});var aFt=s(TG);Zwo=r(aFt,"PegasusModel"),aFt.forEach(t),e6o=r(ySe," (Pegasus model)"),ySe.forEach(t),o6o=i(x),Eu=n(x,"LI",{});var xSe=s(Eu);cge=n(xSe,"STRONG",{});var nFt=s(cge);r6o=r(nFt,"perceiver"),nFt.forEach(t),t6o=r(xSe," \u2014 "),MG=n(xSe,"A",{href:!0});var sFt=s(MG);a6o=r(sFt,"PerceiverModel"),sFt.forEach(t),n6o=r(xSe," (Perceiver model)"),xSe.forEach(t),s6o=i(x),Cu=n(x,"LI",{});var $Se=s(Cu);fge=n($Se,"STRONG",{});var lFt=s(fge);l6o=r(lFt,"plbart"),lFt.forEach(t),i6o=r($Se," \u2014 "),EG=n($Se,"A",{href:!0});var iFt=s(EG);d6o=r(iFt,"PLBartModel"),iFt.forEach(t),c6o=r($Se," (PLBart model)"),$Se.forEach(t),f6o=i(x),wu=n(x,"LI",{});var kSe=s(wu);mge=n(kSe,"STRONG",{});var dFt=s(mge);m6o=r(dFt,"poolformer"),dFt.forEach(t),g6o=r(kSe," \u2014 "),CG=n(kSe,"A",{href:!0});var cFt=s(CG);h6o=r(cFt,"PoolFormerModel"),cFt.forEach(t),p6o=r(kSe," (PoolFormer model)"),kSe.forEach(t),_6o=i(x),Au=n(x,"LI",{});var SSe=s(Au);gge=n(SSe,"STRONG",{});var fFt=s(gge);u6o=r(fFt,"prophetnet"),fFt.forEach(t),b6o=r(SSe," \u2014 "),wG=n(SSe,"A",{href:!0});var mFt=s(wG);v6o=r(mFt,"ProphetNetModel"),mFt.forEach(t),F6o=r(SSe," (ProphetNet model)"),SSe.forEach(t),T6o=i(x),Lu=n(x,"LI",{});var RSe=s(Lu);hge=n(RSe,"STRONG",{});var gFt=s(hge);M6o=r(gFt,"qdqbert"),gFt.forEach(t),E6o=r(RSe," \u2014 "),AG=n(RSe,"A",{href:!0});var hFt=s(AG);C6o=r(hFt,"QDQBertModel"),hFt.forEach(t),w6o=r(RSe," (QDQBert model)"),RSe.forEach(t),A6o=i(x),yu=n(x,"LI",{});var PSe=s(yu);pge=n(PSe,"STRONG",{});var pFt=s(pge);L6o=r(pFt,"reformer"),pFt.forEach(t),y6o=r(PSe," \u2014 "),LG=n(PSe,"A",{href:!0});var _Ft=s(LG);x6o=r(_Ft,"ReformerModel"),_Ft.forEach(t),$6o=r(PSe," (Reformer model)"),PSe.forEach(t),k6o=i(x),xu=n(x,"LI",{});var BSe=s(xu);_ge=n(BSe,"STRONG",{});var uFt=s(_ge);S6o=r(uFt,"regnet"),uFt.forEach(t),R6o=r(BSe," \u2014 "),yG=n(BSe,"A",{href:!0});var bFt=s(yG);P6o=r(bFt,"RegNetModel"),bFt.forEach(t),B6o=r(BSe," (RegNet model)"),BSe.forEach(t),I6o=i(x),$u=n(x,"LI",{});var ISe=s($u);uge=n(ISe,"STRONG",{});var vFt=s(uge);N6o=r(vFt,"rembert"),vFt.forEach(t),q6o=r(ISe," \u2014 "),xG=n(ISe,"A",{href:!0});var FFt=s(xG);j6o=r(FFt,"RemBertModel"),FFt.forEach(t),D6o=r(ISe," (RemBERT model)"),ISe.forEach(t),G6o=i(x),ku=n(x,"LI",{});var NSe=s(ku);bge=n(NSe,"STRONG",{});var TFt=s(bge);O6o=r(TFt,"resnet"),TFt.forEach(t),V6o=r(NSe," \u2014 "),$G=n(NSe,"A",{href:!0});var MFt=s($G);X6o=r(MFt,"ResNetModel"),MFt.forEach(t),z6o=r(NSe," (ResNet model)"),NSe.forEach(t),W6o=i(x),Su=n(x,"LI",{});var qSe=s(Su);vge=n(qSe,"STRONG",{});var EFt=s(vge);Q6o=r(EFt,"retribert"),EFt.forEach(t),H6o=r(qSe," \u2014 "),kG=n(qSe,"A",{href:!0});var CFt=s(kG);U6o=r(CFt,"RetriBertModel"),CFt.forEach(t),J6o=r(qSe," (RetriBERT model)"),qSe.forEach(t),Y6o=i(x),Ru=n(x,"LI",{});var jSe=s(Ru);Fge=n(jSe,"STRONG",{});var wFt=s(Fge);K6o=r(wFt,"roberta"),wFt.forEach(t),Z6o=r(jSe," \u2014 "),SG=n(jSe,"A",{href:!0});var AFt=s(SG);eAo=r(AFt,"RobertaModel"),AFt.forEach(t),oAo=r(jSe," (RoBERTa model)"),jSe.forEach(t),rAo=i(x),Pu=n(x,"LI",{});var DSe=s(Pu);Tge=n(DSe,"STRONG",{});var LFt=s(Tge);tAo=r(LFt,"roformer"),LFt.forEach(t),aAo=r(DSe," \u2014 "),RG=n(DSe,"A",{href:!0});var yFt=s(RG);nAo=r(yFt,"RoFormerModel"),yFt.forEach(t),sAo=r(DSe," (RoFormer model)"),DSe.forEach(t),lAo=i(x),Bu=n(x,"LI",{});var GSe=s(Bu);Mge=n(GSe,"STRONG",{});var xFt=s(Mge);iAo=r(xFt,"segformer"),xFt.forEach(t),dAo=r(GSe," \u2014 "),PG=n(GSe,"A",{href:!0});var $Ft=s(PG);cAo=r($Ft,"SegformerModel"),$Ft.forEach(t),fAo=r(GSe," (SegFormer model)"),GSe.forEach(t),mAo=i(x),Iu=n(x,"LI",{});var OSe=s(Iu);Ege=n(OSe,"STRONG",{});var kFt=s(Ege);gAo=r(kFt,"sew"),kFt.forEach(t),hAo=r(OSe," \u2014 "),BG=n(OSe,"A",{href:!0});var SFt=s(BG);pAo=r(SFt,"SEWModel"),SFt.forEach(t),_Ao=r(OSe," (SEW model)"),OSe.forEach(t),uAo=i(x),Nu=n(x,"LI",{});var VSe=s(Nu);Cge=n(VSe,"STRONG",{});var RFt=s(Cge);bAo=r(RFt,"sew-d"),RFt.forEach(t),vAo=r(VSe," \u2014 "),IG=n(VSe,"A",{href:!0});var PFt=s(IG);FAo=r(PFt,"SEWDModel"),PFt.forEach(t),TAo=r(VSe," (SEW-D model)"),VSe.forEach(t),MAo=i(x),qu=n(x,"LI",{});var XSe=s(qu);wge=n(XSe,"STRONG",{});var BFt=s(wge);EAo=r(BFt,"speech_to_text"),BFt.forEach(t),CAo=r(XSe," \u2014 "),NG=n(XSe,"A",{href:!0});var IFt=s(NG);wAo=r(IFt,"Speech2TextModel"),IFt.forEach(t),AAo=r(XSe," (Speech2Text model)"),XSe.forEach(t),LAo=i(x),ju=n(x,"LI",{});var zSe=s(ju);Age=n(zSe,"STRONG",{});var NFt=s(Age);yAo=r(NFt,"splinter"),NFt.forEach(t),xAo=r(zSe," \u2014 "),qG=n(zSe,"A",{href:!0});var qFt=s(qG);$Ao=r(qFt,"SplinterModel"),qFt.forEach(t),kAo=r(zSe," (Splinter model)"),zSe.forEach(t),SAo=i(x),Du=n(x,"LI",{});var WSe=s(Du);Lge=n(WSe,"STRONG",{});var jFt=s(Lge);RAo=r(jFt,"squeezebert"),jFt.forEach(t),PAo=r(WSe," \u2014 "),jG=n(WSe,"A",{href:!0});var DFt=s(jG);BAo=r(DFt,"SqueezeBertModel"),DFt.forEach(t),IAo=r(WSe," (SqueezeBERT model)"),WSe.forEach(t),NAo=i(x),Gu=n(x,"LI",{});var QSe=s(Gu);yge=n(QSe,"STRONG",{});var GFt=s(yge);qAo=r(GFt,"swin"),GFt.forEach(t),jAo=r(QSe," \u2014 "),DG=n(QSe,"A",{href:!0});var OFt=s(DG);DAo=r(OFt,"SwinModel"),OFt.forEach(t),GAo=r(QSe," (Swin Transformer model)"),QSe.forEach(t),OAo=i(x),Ou=n(x,"LI",{});var HSe=s(Ou);xge=n(HSe,"STRONG",{});var VFt=s(xge);VAo=r(VFt,"swinv2"),VFt.forEach(t),XAo=r(HSe," \u2014 "),GG=n(HSe,"A",{href:!0});var XFt=s(GG);zAo=r(XFt,"Swinv2Model"),XFt.forEach(t),WAo=r(HSe," (Swin Transformer V2 model)"),HSe.forEach(t),QAo=i(x),Vu=n(x,"LI",{});var USe=s(Vu);$ge=n(USe,"STRONG",{});var zFt=s($ge);HAo=r(zFt,"t5"),zFt.forEach(t),UAo=r(USe," \u2014 "),OG=n(USe,"A",{href:!0});var WFt=s(OG);JAo=r(WFt,"T5Model"),WFt.forEach(t),YAo=r(USe," (T5 model)"),USe.forEach(t),KAo=i(x),Xu=n(x,"LI",{});var JSe=s(Xu);kge=n(JSe,"STRONG",{});var QFt=s(kge);ZAo=r(QFt,"tapas"),QFt.forEach(t),eLo=r(JSe," \u2014 "),VG=n(JSe,"A",{href:!0});var HFt=s(VG);oLo=r(HFt,"TapasModel"),HFt.forEach(t),rLo=r(JSe," (TAPAS model)"),JSe.forEach(t),tLo=i(x),zu=n(x,"LI",{});var YSe=s(zu);Sge=n(YSe,"STRONG",{});var UFt=s(Sge);aLo=r(UFt,"trajectory_transformer"),UFt.forEach(t),nLo=r(YSe," \u2014 "),XG=n(YSe,"A",{href:!0});var JFt=s(XG);sLo=r(JFt,"TrajectoryTransformerModel"),JFt.forEach(t),lLo=r(YSe," (Trajectory Transformer model)"),YSe.forEach(t),iLo=i(x),Wu=n(x,"LI",{});var KSe=s(Wu);Rge=n(KSe,"STRONG",{});var YFt=s(Rge);dLo=r(YFt,"transfo-xl"),YFt.forEach(t),cLo=r(KSe," \u2014 "),zG=n(KSe,"A",{href:!0});var KFt=s(zG);fLo=r(KFt,"TransfoXLModel"),KFt.forEach(t),mLo=r(KSe," (Transformer-XL model)"),KSe.forEach(t),gLo=i(x),Qu=n(x,"LI",{});var ZSe=s(Qu);Pge=n(ZSe,"STRONG",{});var ZFt=s(Pge);hLo=r(ZFt,"unispeech"),ZFt.forEach(t),pLo=r(ZSe," \u2014 "),WG=n(ZSe,"A",{href:!0});var eTt=s(WG);_Lo=r(eTt,"UniSpeechModel"),eTt.forEach(t),uLo=r(ZSe," (UniSpeech model)"),ZSe.forEach(t),bLo=i(x),Hu=n(x,"LI",{});var eRe=s(Hu);Bge=n(eRe,"STRONG",{});var oTt=s(Bge);vLo=r(oTt,"unispeech-sat"),oTt.forEach(t),FLo=r(eRe," \u2014 "),QG=n(eRe,"A",{href:!0});var rTt=s(QG);TLo=r(rTt,"UniSpeechSatModel"),rTt.forEach(t),MLo=r(eRe," (UniSpeechSat model)"),eRe.forEach(t),ELo=i(x),Uu=n(x,"LI",{});var oRe=s(Uu);Ige=n(oRe,"STRONG",{});var tTt=s(Ige);CLo=r(tTt,"van"),tTt.forEach(t),wLo=r(oRe," \u2014 "),HG=n(oRe,"A",{href:!0});var aTt=s(HG);ALo=r(aTt,"VanModel"),aTt.forEach(t),LLo=r(oRe," (VAN model)"),oRe.forEach(t),yLo=i(x),Ju=n(x,"LI",{});var rRe=s(Ju);Nge=n(rRe,"STRONG",{});var nTt=s(Nge);xLo=r(nTt,"videomae"),nTt.forEach(t),$Lo=r(rRe," \u2014 "),UG=n(rRe,"A",{href:!0});var sTt=s(UG);kLo=r(sTt,"VideoMAEModel"),sTt.forEach(t),SLo=r(rRe," (VideoMAE model)"),rRe.forEach(t),RLo=i(x),Yu=n(x,"LI",{});var tRe=s(Yu);qge=n(tRe,"STRONG",{});var lTt=s(qge);PLo=r(lTt,"vilt"),lTt.forEach(t),BLo=r(tRe," \u2014 "),JG=n(tRe,"A",{href:!0});var iTt=s(JG);ILo=r(iTt,"ViltModel"),iTt.forEach(t),NLo=r(tRe," (ViLT model)"),tRe.forEach(t),qLo=i(x),Ku=n(x,"LI",{});var aRe=s(Ku);jge=n(aRe,"STRONG",{});var dTt=s(jge);jLo=r(dTt,"vision-text-dual-encoder"),dTt.forEach(t),DLo=r(aRe," \u2014 "),YG=n(aRe,"A",{href:!0});var cTt=s(YG);GLo=r(cTt,"VisionTextDualEncoderModel"),cTt.forEach(t),OLo=r(aRe," (VisionTextDualEncoder model)"),aRe.forEach(t),VLo=i(x),Zu=n(x,"LI",{});var nRe=s(Zu);Dge=n(nRe,"STRONG",{});var fTt=s(Dge);XLo=r(fTt,"visual_bert"),fTt.forEach(t),zLo=r(nRe," \u2014 "),KG=n(nRe,"A",{href:!0});var mTt=s(KG);WLo=r(mTt,"VisualBertModel"),mTt.forEach(t),QLo=r(nRe," (VisualBERT model)"),nRe.forEach(t),HLo=i(x),e7=n(x,"LI",{});var sRe=s(e7);Gge=n(sRe,"STRONG",{});var gTt=s(Gge);ULo=r(gTt,"vit"),gTt.forEach(t),JLo=r(sRe," \u2014 "),ZG=n(sRe,"A",{href:!0});var hTt=s(ZG);YLo=r(hTt,"ViTModel"),hTt.forEach(t),KLo=r(sRe," (ViT model)"),sRe.forEach(t),ZLo=i(x),o7=n(x,"LI",{});var lRe=s(o7);Oge=n(lRe,"STRONG",{});var pTt=s(Oge);eyo=r(pTt,"vit_mae"),pTt.forEach(t),oyo=r(lRe," \u2014 "),eO=n(lRe,"A",{href:!0});var _Tt=s(eO);ryo=r(_Tt,"ViTMAEModel"),_Tt.forEach(t),tyo=r(lRe," (ViTMAE model)"),lRe.forEach(t),ayo=i(x),r7=n(x,"LI",{});var iRe=s(r7);Vge=n(iRe,"STRONG",{});var uTt=s(Vge);nyo=r(uTt,"wav2vec2"),uTt.forEach(t),syo=r(iRe," \u2014 "),oO=n(iRe,"A",{href:!0});var bTt=s(oO);lyo=r(bTt,"Wav2Vec2Model"),bTt.forEach(t),iyo=r(iRe," (Wav2Vec2 model)"),iRe.forEach(t),dyo=i(x),t7=n(x,"LI",{});var dRe=s(t7);Xge=n(dRe,"STRONG",{});var vTt=s(Xge);cyo=r(vTt,"wav2vec2-conformer"),vTt.forEach(t),fyo=r(dRe," \u2014 "),rO=n(dRe,"A",{href:!0});var FTt=s(rO);myo=r(FTt,"Wav2Vec2ConformerModel"),FTt.forEach(t),gyo=r(dRe," (Wav2Vec2-Conformer model)"),dRe.forEach(t),hyo=i(x),a7=n(x,"LI",{});var cRe=s(a7);zge=n(cRe,"STRONG",{});var TTt=s(zge);pyo=r(TTt,"wavlm"),TTt.forEach(t),_yo=r(cRe," \u2014 "),tO=n(cRe,"A",{href:!0});var MTt=s(tO);uyo=r(MTt,"WavLMModel"),MTt.forEach(t),byo=r(cRe," (WavLM model)"),cRe.forEach(t),vyo=i(x),n7=n(x,"LI",{});var fRe=s(n7);Wge=n(fRe,"STRONG",{});var ETt=s(Wge);Fyo=r(ETt,"xglm"),ETt.forEach(t),Tyo=r(fRe," \u2014 "),aO=n(fRe,"A",{href:!0});var CTt=s(aO);Myo=r(CTt,"XGLMModel"),CTt.forEach(t),Eyo=r(fRe," (XGLM model)"),fRe.forEach(t),Cyo=i(x),s7=n(x,"LI",{});var mRe=s(s7);Qge=n(mRe,"STRONG",{});var wTt=s(Qge);wyo=r(wTt,"xlm"),wTt.forEach(t),Ayo=r(mRe," \u2014 "),nO=n(mRe,"A",{href:!0});var ATt=s(nO);Lyo=r(ATt,"XLMModel"),ATt.forEach(t),yyo=r(mRe," (XLM model)"),mRe.forEach(t),xyo=i(x),l7=n(x,"LI",{});var gRe=s(l7);Hge=n(gRe,"STRONG",{});var LTt=s(Hge);$yo=r(LTt,"xlm-prophetnet"),LTt.forEach(t),kyo=r(gRe," \u2014 "),sO=n(gRe,"A",{href:!0});var yTt=s(sO);Syo=r(yTt,"XLMProphetNetModel"),yTt.forEach(t),Ryo=r(gRe," (XLM-ProphetNet model)"),gRe.forEach(t),Pyo=i(x),i7=n(x,"LI",{});var hRe=s(i7);Uge=n(hRe,"STRONG",{});var xTt=s(Uge);Byo=r(xTt,"xlm-roberta"),xTt.forEach(t),Iyo=r(hRe," \u2014 "),lO=n(hRe,"A",{href:!0});var $Tt=s(lO);Nyo=r($Tt,"XLMRobertaModel"),$Tt.forEach(t),qyo=r(hRe," (XLM-RoBERTa model)"),hRe.forEach(t),jyo=i(x),d7=n(x,"LI",{});var pRe=s(d7);Jge=n(pRe,"STRONG",{});var kTt=s(Jge);Dyo=r(kTt,"xlm-roberta-xl"),kTt.forEach(t),Gyo=r(pRe," \u2014 "),iO=n(pRe,"A",{href:!0});var STt=s(iO);Oyo=r(STt,"XLMRobertaXLModel"),STt.forEach(t),Vyo=r(pRe," (XLM-RoBERTa-XL model)"),pRe.forEach(t),Xyo=i(x),c7=n(x,"LI",{});var _Re=s(c7);Yge=n(_Re,"STRONG",{});var RTt=s(Yge);zyo=r(RTt,"xlnet"),RTt.forEach(t),Wyo=r(_Re," \u2014 "),dO=n(_Re,"A",{href:!0});var PTt=s(dO);Qyo=r(PTt,"XLNetModel"),PTt.forEach(t),Hyo=r(_Re," (XLNet model)"),_Re.forEach(t),Uyo=i(x),f7=n(x,"LI",{});var uRe=s(f7);Kge=n(uRe,"STRONG",{});var BTt=s(Kge);Jyo=r(BTt,"yolos"),BTt.forEach(t),Yyo=r(uRe," \u2014 "),cO=n(uRe,"A",{href:!0});var ITt=s(cO);Kyo=r(ITt,"YolosModel"),ITt.forEach(t),Zyo=r(uRe," (YOLOS model)"),uRe.forEach(t),e8o=i(x),m7=n(x,"LI",{});var bRe=s(m7);Zge=n(bRe,"STRONG",{});var NTt=s(Zge);o8o=r(NTt,"yoso"),NTt.forEach(t),r8o=r(bRe," \u2014 "),fO=n(bRe,"A",{href:!0});var qTt=s(fO);t8o=r(qTt,"YosoModel"),qTt.forEach(t),a8o=r(bRe," (YOSO model)"),bRe.forEach(t),x.forEach(t),n8o=i(ca),g7=n(ca,"P",{});var vRe=s(g7);s8o=r(vRe,"The model is set in evaluation mode by default using "),ehe=n(vRe,"CODE",{});var jTt=s(ehe);l8o=r(jTt,"model.eval()"),jTt.forEach(t),i8o=r(vRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ohe=n(vRe,"CODE",{});var DTt=s(ohe);d8o=r(DTt,"model.train()"),DTt.forEach(t),vRe.forEach(t),c8o=i(ca),T(h7.$$.fragment,ca),ca.forEach(t),cl.forEach(t),eQe=i(f),Zi=n(f,"H2",{class:!0});var iUe=s(Zi);p7=n(iUe,"A",{id:!0,class:!0,href:!0});var GTt=s(p7);rhe=n(GTt,"SPAN",{});var OTt=s(rhe);T(Cy.$$.fragment,OTt),OTt.forEach(t),GTt.forEach(t),f8o=i(iUe),the=n(iUe,"SPAN",{});var VTt=s(the);m8o=r(VTt,"AutoModelForPreTraining"),VTt.forEach(t),iUe.forEach(t),oQe=i(f),Ro=n(f,"DIV",{class:!0});var fl=s(Ro);T(wy.$$.fragment,fl),g8o=i(fl),ed=n(fl,"P",{});var iae=s(ed);h8o=r(iae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mO=n(iae,"A",{href:!0});var XTt=s(mO);p8o=r(XTt,"from_pretrained()"),XTt.forEach(t),_8o=r(iae," class method or the "),gO=n(iae,"A",{href:!0});var zTt=s(gO);u8o=r(zTt,"from_config()"),zTt.forEach(t),b8o=r(iae,` class
method.`),iae.forEach(t),v8o=i(fl),Ay=n(fl,"P",{});var dUe=s(Ay);F8o=r(dUe,"This class cannot be instantiated directly using "),ahe=n(dUe,"CODE",{});var WTt=s(ahe);T8o=r(WTt,"__init__()"),WTt.forEach(t),M8o=r(dUe," (throws an error)."),dUe.forEach(t),E8o=i(fl),ft=n(fl,"DIV",{class:!0});var J6=s(ft);T(Ly.$$.fragment,J6),C8o=i(J6),nhe=n(J6,"P",{});var QTt=s(nhe);w8o=r(QTt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),QTt.forEach(t),A8o=i(J6),od=n(J6,"P",{});var dae=s(od);L8o=r(dae,`Note:
Loading a model from its configuration file does `),she=n(dae,"STRONG",{});var HTt=s(she);y8o=r(HTt,"not"),HTt.forEach(t),x8o=r(dae,` load the model weights. It only affects the
model\u2019s configuration. Use `),hO=n(dae,"A",{href:!0});var UTt=s(hO);$8o=r(UTt,"from_pretrained()"),UTt.forEach(t),k8o=r(dae," to load the model weights."),dae.forEach(t),S8o=i(J6),T(_7.$$.fragment,J6),J6.forEach(t),R8o=i(fl),Ke=n(fl,"DIV",{class:!0});var fa=s(Ke);T(yy.$$.fragment,fa),P8o=i(fa),lhe=n(fa,"P",{});var JTt=s(lhe);B8o=r(JTt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),JTt.forEach(t),I8o=i(fa),Ga=n(fa,"P",{});var Y6=s(Ga);N8o=r(Y6,"The model class to instantiate is selected based on the "),ihe=n(Y6,"CODE",{});var YTt=s(ihe);q8o=r(YTt,"model_type"),YTt.forEach(t),j8o=r(Y6,` property of the config object (either
passed as an argument or loaded from `),dhe=n(Y6,"CODE",{});var KTt=s(dhe);D8o=r(KTt,"pretrained_model_name_or_path"),KTt.forEach(t),G8o=r(Y6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),che=n(Y6,"CODE",{});var ZTt=s(che);O8o=r(ZTt,"pretrained_model_name_or_path"),ZTt.forEach(t),V8o=r(Y6,":"),Y6.forEach(t),X8o=i(fa),G=n(fa,"UL",{});var O=s(G);u7=n(O,"LI",{});var FRe=s(u7);fhe=n(FRe,"STRONG",{});var e9t=s(fhe);z8o=r(e9t,"albert"),e9t.forEach(t),W8o=r(FRe," \u2014 "),pO=n(FRe,"A",{href:!0});var o9t=s(pO);Q8o=r(o9t,"AlbertForPreTraining"),o9t.forEach(t),H8o=r(FRe," (ALBERT model)"),FRe.forEach(t),U8o=i(O),b7=n(O,"LI",{});var TRe=s(b7);mhe=n(TRe,"STRONG",{});var r9t=s(mhe);J8o=r(r9t,"bart"),r9t.forEach(t),Y8o=r(TRe," \u2014 "),_O=n(TRe,"A",{href:!0});var t9t=s(_O);K8o=r(t9t,"BartForConditionalGeneration"),t9t.forEach(t),Z8o=r(TRe," (BART model)"),TRe.forEach(t),exo=i(O),v7=n(O,"LI",{});var MRe=s(v7);ghe=n(MRe,"STRONG",{});var a9t=s(ghe);oxo=r(a9t,"bert"),a9t.forEach(t),rxo=r(MRe," \u2014 "),uO=n(MRe,"A",{href:!0});var n9t=s(uO);txo=r(n9t,"BertForPreTraining"),n9t.forEach(t),axo=r(MRe," (BERT model)"),MRe.forEach(t),nxo=i(O),F7=n(O,"LI",{});var ERe=s(F7);hhe=n(ERe,"STRONG",{});var s9t=s(hhe);sxo=r(s9t,"big_bird"),s9t.forEach(t),lxo=r(ERe," \u2014 "),bO=n(ERe,"A",{href:!0});var l9t=s(bO);ixo=r(l9t,"BigBirdForPreTraining"),l9t.forEach(t),dxo=r(ERe," (BigBird model)"),ERe.forEach(t),cxo=i(O),T7=n(O,"LI",{});var CRe=s(T7);phe=n(CRe,"STRONG",{});var i9t=s(phe);fxo=r(i9t,"bloom"),i9t.forEach(t),mxo=r(CRe," \u2014 "),vO=n(CRe,"A",{href:!0});var d9t=s(vO);gxo=r(d9t,"BloomForCausalLM"),d9t.forEach(t),hxo=r(CRe," (BLOOM model)"),CRe.forEach(t),pxo=i(O),M7=n(O,"LI",{});var wRe=s(M7);_he=n(wRe,"STRONG",{});var c9t=s(_he);_xo=r(c9t,"camembert"),c9t.forEach(t),uxo=r(wRe," \u2014 "),FO=n(wRe,"A",{href:!0});var f9t=s(FO);bxo=r(f9t,"CamembertForMaskedLM"),f9t.forEach(t),vxo=r(wRe," (CamemBERT model)"),wRe.forEach(t),Fxo=i(O),E7=n(O,"LI",{});var ARe=s(E7);uhe=n(ARe,"STRONG",{});var m9t=s(uhe);Txo=r(m9t,"ctrl"),m9t.forEach(t),Mxo=r(ARe," \u2014 "),TO=n(ARe,"A",{href:!0});var g9t=s(TO);Exo=r(g9t,"CTRLLMHeadModel"),g9t.forEach(t),Cxo=r(ARe," (CTRL model)"),ARe.forEach(t),wxo=i(O),C7=n(O,"LI",{});var LRe=s(C7);bhe=n(LRe,"STRONG",{});var h9t=s(bhe);Axo=r(h9t,"data2vec-text"),h9t.forEach(t),Lxo=r(LRe," \u2014 "),MO=n(LRe,"A",{href:!0});var p9t=s(MO);yxo=r(p9t,"Data2VecTextForMaskedLM"),p9t.forEach(t),xxo=r(LRe," (Data2VecText model)"),LRe.forEach(t),$xo=i(O),w7=n(O,"LI",{});var yRe=s(w7);vhe=n(yRe,"STRONG",{});var _9t=s(vhe);kxo=r(_9t,"deberta"),_9t.forEach(t),Sxo=r(yRe," \u2014 "),EO=n(yRe,"A",{href:!0});var u9t=s(EO);Rxo=r(u9t,"DebertaForMaskedLM"),u9t.forEach(t),Pxo=r(yRe," (DeBERTa model)"),yRe.forEach(t),Bxo=i(O),A7=n(O,"LI",{});var xRe=s(A7);Fhe=n(xRe,"STRONG",{});var b9t=s(Fhe);Ixo=r(b9t,"deberta-v2"),b9t.forEach(t),Nxo=r(xRe," \u2014 "),CO=n(xRe,"A",{href:!0});var v9t=s(CO);qxo=r(v9t,"DebertaV2ForMaskedLM"),v9t.forEach(t),jxo=r(xRe," (DeBERTa-v2 model)"),xRe.forEach(t),Dxo=i(O),L7=n(O,"LI",{});var $Re=s(L7);The=n($Re,"STRONG",{});var F9t=s(The);Gxo=r(F9t,"distilbert"),F9t.forEach(t),Oxo=r($Re," \u2014 "),wO=n($Re,"A",{href:!0});var T9t=s(wO);Vxo=r(T9t,"DistilBertForMaskedLM"),T9t.forEach(t),Xxo=r($Re," (DistilBERT model)"),$Re.forEach(t),zxo=i(O),y7=n(O,"LI",{});var kRe=s(y7);Mhe=n(kRe,"STRONG",{});var M9t=s(Mhe);Wxo=r(M9t,"electra"),M9t.forEach(t),Qxo=r(kRe," \u2014 "),AO=n(kRe,"A",{href:!0});var E9t=s(AO);Hxo=r(E9t,"ElectraForPreTraining"),E9t.forEach(t),Uxo=r(kRe," (ELECTRA model)"),kRe.forEach(t),Jxo=i(O),x7=n(O,"LI",{});var SRe=s(x7);Ehe=n(SRe,"STRONG",{});var C9t=s(Ehe);Yxo=r(C9t,"flaubert"),C9t.forEach(t),Kxo=r(SRe," \u2014 "),LO=n(SRe,"A",{href:!0});var w9t=s(LO);Zxo=r(w9t,"FlaubertWithLMHeadModel"),w9t.forEach(t),e$o=r(SRe," (FlauBERT model)"),SRe.forEach(t),o$o=i(O),$7=n(O,"LI",{});var RRe=s($7);Che=n(RRe,"STRONG",{});var A9t=s(Che);r$o=r(A9t,"flava"),A9t.forEach(t),t$o=r(RRe," \u2014 "),yO=n(RRe,"A",{href:!0});var L9t=s(yO);a$o=r(L9t,"FlavaForPreTraining"),L9t.forEach(t),n$o=r(RRe," (FLAVA model)"),RRe.forEach(t),s$o=i(O),k7=n(O,"LI",{});var PRe=s(k7);whe=n(PRe,"STRONG",{});var y9t=s(whe);l$o=r(y9t,"fnet"),y9t.forEach(t),i$o=r(PRe," \u2014 "),xO=n(PRe,"A",{href:!0});var x9t=s(xO);d$o=r(x9t,"FNetForPreTraining"),x9t.forEach(t),c$o=r(PRe," (FNet model)"),PRe.forEach(t),f$o=i(O),S7=n(O,"LI",{});var BRe=s(S7);Ahe=n(BRe,"STRONG",{});var $9t=s(Ahe);m$o=r($9t,"fsmt"),$9t.forEach(t),g$o=r(BRe," \u2014 "),$O=n(BRe,"A",{href:!0});var k9t=s($O);h$o=r(k9t,"FSMTForConditionalGeneration"),k9t.forEach(t),p$o=r(BRe," (FairSeq Machine-Translation model)"),BRe.forEach(t),_$o=i(O),R7=n(O,"LI",{});var IRe=s(R7);Lhe=n(IRe,"STRONG",{});var S9t=s(Lhe);u$o=r(S9t,"funnel"),S9t.forEach(t),b$o=r(IRe," \u2014 "),kO=n(IRe,"A",{href:!0});var R9t=s(kO);v$o=r(R9t,"FunnelForPreTraining"),R9t.forEach(t),F$o=r(IRe," (Funnel Transformer model)"),IRe.forEach(t),T$o=i(O),P7=n(O,"LI",{});var NRe=s(P7);yhe=n(NRe,"STRONG",{});var P9t=s(yhe);M$o=r(P9t,"gpt2"),P9t.forEach(t),E$o=r(NRe," \u2014 "),SO=n(NRe,"A",{href:!0});var B9t=s(SO);C$o=r(B9t,"GPT2LMHeadModel"),B9t.forEach(t),w$o=r(NRe," (OpenAI GPT-2 model)"),NRe.forEach(t),A$o=i(O),B7=n(O,"LI",{});var qRe=s(B7);xhe=n(qRe,"STRONG",{});var I9t=s(xhe);L$o=r(I9t,"ibert"),I9t.forEach(t),y$o=r(qRe," \u2014 "),RO=n(qRe,"A",{href:!0});var N9t=s(RO);x$o=r(N9t,"IBertForMaskedLM"),N9t.forEach(t),$$o=r(qRe," (I-BERT model)"),qRe.forEach(t),k$o=i(O),I7=n(O,"LI",{});var jRe=s(I7);$he=n(jRe,"STRONG",{});var q9t=s($he);S$o=r(q9t,"layoutlm"),q9t.forEach(t),R$o=r(jRe," \u2014 "),PO=n(jRe,"A",{href:!0});var j9t=s(PO);P$o=r(j9t,"LayoutLMForMaskedLM"),j9t.forEach(t),B$o=r(jRe," (LayoutLM model)"),jRe.forEach(t),I$o=i(O),N7=n(O,"LI",{});var DRe=s(N7);khe=n(DRe,"STRONG",{});var D9t=s(khe);N$o=r(D9t,"longformer"),D9t.forEach(t),q$o=r(DRe," \u2014 "),BO=n(DRe,"A",{href:!0});var G9t=s(BO);j$o=r(G9t,"LongformerForMaskedLM"),G9t.forEach(t),D$o=r(DRe," (Longformer model)"),DRe.forEach(t),G$o=i(O),q7=n(O,"LI",{});var GRe=s(q7);She=n(GRe,"STRONG",{});var O9t=s(She);O$o=r(O9t,"luke"),O9t.forEach(t),V$o=r(GRe," \u2014 "),IO=n(GRe,"A",{href:!0});var V9t=s(IO);X$o=r(V9t,"LukeForMaskedLM"),V9t.forEach(t),z$o=r(GRe," (LUKE model)"),GRe.forEach(t),W$o=i(O),j7=n(O,"LI",{});var ORe=s(j7);Rhe=n(ORe,"STRONG",{});var X9t=s(Rhe);Q$o=r(X9t,"lxmert"),X9t.forEach(t),H$o=r(ORe," \u2014 "),NO=n(ORe,"A",{href:!0});var z9t=s(NO);U$o=r(z9t,"LxmertForPreTraining"),z9t.forEach(t),J$o=r(ORe," (LXMERT model)"),ORe.forEach(t),Y$o=i(O),D7=n(O,"LI",{});var VRe=s(D7);Phe=n(VRe,"STRONG",{});var W9t=s(Phe);K$o=r(W9t,"megatron-bert"),W9t.forEach(t),Z$o=r(VRe," \u2014 "),qO=n(VRe,"A",{href:!0});var Q9t=s(qO);eko=r(Q9t,"MegatronBertForPreTraining"),Q9t.forEach(t),oko=r(VRe," (Megatron-BERT model)"),VRe.forEach(t),rko=i(O),G7=n(O,"LI",{});var XRe=s(G7);Bhe=n(XRe,"STRONG",{});var H9t=s(Bhe);tko=r(H9t,"mobilebert"),H9t.forEach(t),ako=r(XRe," \u2014 "),jO=n(XRe,"A",{href:!0});var U9t=s(jO);nko=r(U9t,"MobileBertForPreTraining"),U9t.forEach(t),sko=r(XRe," (MobileBERT model)"),XRe.forEach(t),lko=i(O),O7=n(O,"LI",{});var zRe=s(O7);Ihe=n(zRe,"STRONG",{});var J9t=s(Ihe);iko=r(J9t,"mpnet"),J9t.forEach(t),dko=r(zRe," \u2014 "),DO=n(zRe,"A",{href:!0});var Y9t=s(DO);cko=r(Y9t,"MPNetForMaskedLM"),Y9t.forEach(t),fko=r(zRe," (MPNet model)"),zRe.forEach(t),mko=i(O),V7=n(O,"LI",{});var WRe=s(V7);Nhe=n(WRe,"STRONG",{});var K9t=s(Nhe);gko=r(K9t,"mvp"),K9t.forEach(t),hko=r(WRe," \u2014 "),GO=n(WRe,"A",{href:!0});var Z9t=s(GO);pko=r(Z9t,"MvpForConditionalGeneration"),Z9t.forEach(t),_ko=r(WRe," (MVP model)"),WRe.forEach(t),uko=i(O),X7=n(O,"LI",{});var QRe=s(X7);qhe=n(QRe,"STRONG",{});var eMt=s(qhe);bko=r(eMt,"nezha"),eMt.forEach(t),vko=r(QRe," \u2014 "),OO=n(QRe,"A",{href:!0});var oMt=s(OO);Fko=r(oMt,"NezhaForPreTraining"),oMt.forEach(t),Tko=r(QRe," (Nezha model)"),QRe.forEach(t),Mko=i(O),z7=n(O,"LI",{});var HRe=s(z7);jhe=n(HRe,"STRONG",{});var rMt=s(jhe);Eko=r(rMt,"openai-gpt"),rMt.forEach(t),Cko=r(HRe," \u2014 "),VO=n(HRe,"A",{href:!0});var tMt=s(VO);wko=r(tMt,"OpenAIGPTLMHeadModel"),tMt.forEach(t),Ako=r(HRe," (OpenAI GPT model)"),HRe.forEach(t),Lko=i(O),W7=n(O,"LI",{});var URe=s(W7);Dhe=n(URe,"STRONG",{});var aMt=s(Dhe);yko=r(aMt,"retribert"),aMt.forEach(t),xko=r(URe," \u2014 "),XO=n(URe,"A",{href:!0});var nMt=s(XO);$ko=r(nMt,"RetriBertModel"),nMt.forEach(t),kko=r(URe," (RetriBERT model)"),URe.forEach(t),Sko=i(O),Q7=n(O,"LI",{});var JRe=s(Q7);Ghe=n(JRe,"STRONG",{});var sMt=s(Ghe);Rko=r(sMt,"roberta"),sMt.forEach(t),Pko=r(JRe," \u2014 "),zO=n(JRe,"A",{href:!0});var lMt=s(zO);Bko=r(lMt,"RobertaForMaskedLM"),lMt.forEach(t),Iko=r(JRe," (RoBERTa model)"),JRe.forEach(t),Nko=i(O),H7=n(O,"LI",{});var YRe=s(H7);Ohe=n(YRe,"STRONG",{});var iMt=s(Ohe);qko=r(iMt,"splinter"),iMt.forEach(t),jko=r(YRe," \u2014 "),WO=n(YRe,"A",{href:!0});var dMt=s(WO);Dko=r(dMt,"SplinterForPreTraining"),dMt.forEach(t),Gko=r(YRe," (Splinter model)"),YRe.forEach(t),Oko=i(O),U7=n(O,"LI",{});var KRe=s(U7);Vhe=n(KRe,"STRONG",{});var cMt=s(Vhe);Vko=r(cMt,"squeezebert"),cMt.forEach(t),Xko=r(KRe," \u2014 "),QO=n(KRe,"A",{href:!0});var fMt=s(QO);zko=r(fMt,"SqueezeBertForMaskedLM"),fMt.forEach(t),Wko=r(KRe," (SqueezeBERT model)"),KRe.forEach(t),Qko=i(O),J7=n(O,"LI",{});var ZRe=s(J7);Xhe=n(ZRe,"STRONG",{});var mMt=s(Xhe);Hko=r(mMt,"t5"),mMt.forEach(t),Uko=r(ZRe," \u2014 "),HO=n(ZRe,"A",{href:!0});var gMt=s(HO);Jko=r(gMt,"T5ForConditionalGeneration"),gMt.forEach(t),Yko=r(ZRe," (T5 model)"),ZRe.forEach(t),Kko=i(O),Y7=n(O,"LI",{});var ePe=s(Y7);zhe=n(ePe,"STRONG",{});var hMt=s(zhe);Zko=r(hMt,"tapas"),hMt.forEach(t),eSo=r(ePe," \u2014 "),UO=n(ePe,"A",{href:!0});var pMt=s(UO);oSo=r(pMt,"TapasForMaskedLM"),pMt.forEach(t),rSo=r(ePe," (TAPAS model)"),ePe.forEach(t),tSo=i(O),K7=n(O,"LI",{});var oPe=s(K7);Whe=n(oPe,"STRONG",{});var _Mt=s(Whe);aSo=r(_Mt,"transfo-xl"),_Mt.forEach(t),nSo=r(oPe," \u2014 "),JO=n(oPe,"A",{href:!0});var uMt=s(JO);sSo=r(uMt,"TransfoXLLMHeadModel"),uMt.forEach(t),lSo=r(oPe," (Transformer-XL model)"),oPe.forEach(t),iSo=i(O),Z7=n(O,"LI",{});var rPe=s(Z7);Qhe=n(rPe,"STRONG",{});var bMt=s(Qhe);dSo=r(bMt,"unispeech"),bMt.forEach(t),cSo=r(rPe," \u2014 "),YO=n(rPe,"A",{href:!0});var vMt=s(YO);fSo=r(vMt,"UniSpeechForPreTraining"),vMt.forEach(t),mSo=r(rPe," (UniSpeech model)"),rPe.forEach(t),gSo=i(O),e1=n(O,"LI",{});var tPe=s(e1);Hhe=n(tPe,"STRONG",{});var FMt=s(Hhe);hSo=r(FMt,"unispeech-sat"),FMt.forEach(t),pSo=r(tPe," \u2014 "),KO=n(tPe,"A",{href:!0});var TMt=s(KO);_So=r(TMt,"UniSpeechSatForPreTraining"),TMt.forEach(t),uSo=r(tPe," (UniSpeechSat model)"),tPe.forEach(t),bSo=i(O),o1=n(O,"LI",{});var aPe=s(o1);Uhe=n(aPe,"STRONG",{});var MMt=s(Uhe);vSo=r(MMt,"videomae"),MMt.forEach(t),FSo=r(aPe," \u2014 "),ZO=n(aPe,"A",{href:!0});var EMt=s(ZO);TSo=r(EMt,"VideoMAEForPreTraining"),EMt.forEach(t),MSo=r(aPe," (VideoMAE model)"),aPe.forEach(t),ESo=i(O),r1=n(O,"LI",{});var nPe=s(r1);Jhe=n(nPe,"STRONG",{});var CMt=s(Jhe);CSo=r(CMt,"visual_bert"),CMt.forEach(t),wSo=r(nPe," \u2014 "),eV=n(nPe,"A",{href:!0});var wMt=s(eV);ASo=r(wMt,"VisualBertForPreTraining"),wMt.forEach(t),LSo=r(nPe," (VisualBERT model)"),nPe.forEach(t),ySo=i(O),t1=n(O,"LI",{});var sPe=s(t1);Yhe=n(sPe,"STRONG",{});var AMt=s(Yhe);xSo=r(AMt,"vit_mae"),AMt.forEach(t),$So=r(sPe," \u2014 "),oV=n(sPe,"A",{href:!0});var LMt=s(oV);kSo=r(LMt,"ViTMAEForPreTraining"),LMt.forEach(t),SSo=r(sPe," (ViTMAE model)"),sPe.forEach(t),RSo=i(O),a1=n(O,"LI",{});var lPe=s(a1);Khe=n(lPe,"STRONG",{});var yMt=s(Khe);PSo=r(yMt,"wav2vec2"),yMt.forEach(t),BSo=r(lPe," \u2014 "),rV=n(lPe,"A",{href:!0});var xMt=s(rV);ISo=r(xMt,"Wav2Vec2ForPreTraining"),xMt.forEach(t),NSo=r(lPe," (Wav2Vec2 model)"),lPe.forEach(t),qSo=i(O),n1=n(O,"LI",{});var iPe=s(n1);Zhe=n(iPe,"STRONG",{});var $Mt=s(Zhe);jSo=r($Mt,"wav2vec2-conformer"),$Mt.forEach(t),DSo=r(iPe," \u2014 "),tV=n(iPe,"A",{href:!0});var kMt=s(tV);GSo=r(kMt,"Wav2Vec2ConformerForPreTraining"),kMt.forEach(t),OSo=r(iPe," (Wav2Vec2-Conformer model)"),iPe.forEach(t),VSo=i(O),s1=n(O,"LI",{});var dPe=s(s1);epe=n(dPe,"STRONG",{});var SMt=s(epe);XSo=r(SMt,"xlm"),SMt.forEach(t),zSo=r(dPe," \u2014 "),aV=n(dPe,"A",{href:!0});var RMt=s(aV);WSo=r(RMt,"XLMWithLMHeadModel"),RMt.forEach(t),QSo=r(dPe," (XLM model)"),dPe.forEach(t),HSo=i(O),l1=n(O,"LI",{});var cPe=s(l1);ope=n(cPe,"STRONG",{});var PMt=s(ope);USo=r(PMt,"xlm-roberta"),PMt.forEach(t),JSo=r(cPe," \u2014 "),nV=n(cPe,"A",{href:!0});var BMt=s(nV);YSo=r(BMt,"XLMRobertaForMaskedLM"),BMt.forEach(t),KSo=r(cPe," (XLM-RoBERTa model)"),cPe.forEach(t),ZSo=i(O),i1=n(O,"LI",{});var fPe=s(i1);rpe=n(fPe,"STRONG",{});var IMt=s(rpe);eRo=r(IMt,"xlm-roberta-xl"),IMt.forEach(t),oRo=r(fPe," \u2014 "),sV=n(fPe,"A",{href:!0});var NMt=s(sV);rRo=r(NMt,"XLMRobertaXLForMaskedLM"),NMt.forEach(t),tRo=r(fPe," (XLM-RoBERTa-XL model)"),fPe.forEach(t),aRo=i(O),d1=n(O,"LI",{});var mPe=s(d1);tpe=n(mPe,"STRONG",{});var qMt=s(tpe);nRo=r(qMt,"xlnet"),qMt.forEach(t),sRo=r(mPe," \u2014 "),lV=n(mPe,"A",{href:!0});var jMt=s(lV);lRo=r(jMt,"XLNetLMHeadModel"),jMt.forEach(t),iRo=r(mPe," (XLNet model)"),mPe.forEach(t),O.forEach(t),dRo=i(fa),c1=n(fa,"P",{});var gPe=s(c1);cRo=r(gPe,"The model is set in evaluation mode by default using "),ape=n(gPe,"CODE",{});var DMt=s(ape);fRo=r(DMt,"model.eval()"),DMt.forEach(t),mRo=r(gPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),npe=n(gPe,"CODE",{});var GMt=s(npe);gRo=r(GMt,"model.train()"),GMt.forEach(t),gPe.forEach(t),hRo=i(fa),T(f1.$$.fragment,fa),fa.forEach(t),fl.forEach(t),rQe=i(f),rd=n(f,"H2",{class:!0});var cUe=s(rd);m1=n(cUe,"A",{id:!0,class:!0,href:!0});var OMt=s(m1);spe=n(OMt,"SPAN",{});var VMt=s(spe);T(xy.$$.fragment,VMt),VMt.forEach(t),OMt.forEach(t),pRo=i(cUe),lpe=n(cUe,"SPAN",{});var XMt=s(lpe);_Ro=r(XMt,"AutoModelForCausalLM"),XMt.forEach(t),cUe.forEach(t),tQe=i(f),Po=n(f,"DIV",{class:!0});var ml=s(Po);T($y.$$.fragment,ml),uRo=i(ml),td=n(ml,"P",{});var cae=s(td);bRo=r(cae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),iV=n(cae,"A",{href:!0});var zMt=s(iV);vRo=r(zMt,"from_pretrained()"),zMt.forEach(t),FRo=r(cae," class method or the "),dV=n(cae,"A",{href:!0});var WMt=s(dV);TRo=r(WMt,"from_config()"),WMt.forEach(t),MRo=r(cae,` class
method.`),cae.forEach(t),ERo=i(ml),ky=n(ml,"P",{});var fUe=s(ky);CRo=r(fUe,"This class cannot be instantiated directly using "),ipe=n(fUe,"CODE",{});var QMt=s(ipe);wRo=r(QMt,"__init__()"),QMt.forEach(t),ARo=r(fUe," (throws an error)."),fUe.forEach(t),LRo=i(ml),mt=n(ml,"DIV",{class:!0});var K6=s(mt);T(Sy.$$.fragment,K6),yRo=i(K6),dpe=n(K6,"P",{});var HMt=s(dpe);xRo=r(HMt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),HMt.forEach(t),$Ro=i(K6),ad=n(K6,"P",{});var fae=s(ad);kRo=r(fae,`Note:
Loading a model from its configuration file does `),cpe=n(fae,"STRONG",{});var UMt=s(cpe);SRo=r(UMt,"not"),UMt.forEach(t),RRo=r(fae,` load the model weights. It only affects the
model\u2019s configuration. Use `),cV=n(fae,"A",{href:!0});var JMt=s(cV);PRo=r(JMt,"from_pretrained()"),JMt.forEach(t),BRo=r(fae," to load the model weights."),fae.forEach(t),IRo=i(K6),T(g1.$$.fragment,K6),K6.forEach(t),NRo=i(ml),Ze=n(ml,"DIV",{class:!0});var ma=s(Ze);T(Ry.$$.fragment,ma),qRo=i(ma),fpe=n(ma,"P",{});var YMt=s(fpe);jRo=r(YMt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),YMt.forEach(t),DRo=i(ma),Oa=n(ma,"P",{});var Z6=s(Oa);GRo=r(Z6,"The model class to instantiate is selected based on the "),mpe=n(Z6,"CODE",{});var KMt=s(mpe);ORo=r(KMt,"model_type"),KMt.forEach(t),VRo=r(Z6,` property of the config object (either
passed as an argument or loaded from `),gpe=n(Z6,"CODE",{});var ZMt=s(gpe);XRo=r(ZMt,"pretrained_model_name_or_path"),ZMt.forEach(t),zRo=r(Z6,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),hpe=n(Z6,"CODE",{});var eEt=s(hpe);WRo=r(eEt,"pretrained_model_name_or_path"),eEt.forEach(t),QRo=r(Z6,":"),Z6.forEach(t),HRo=i(ma),z=n(ma,"UL",{});var W=s(z);h1=n(W,"LI",{});var hPe=s(h1);ppe=n(hPe,"STRONG",{});var oEt=s(ppe);URo=r(oEt,"bart"),oEt.forEach(t),JRo=r(hPe," \u2014 "),fV=n(hPe,"A",{href:!0});var rEt=s(fV);YRo=r(rEt,"BartForCausalLM"),rEt.forEach(t),KRo=r(hPe," (BART model)"),hPe.forEach(t),ZRo=i(W),p1=n(W,"LI",{});var pPe=s(p1);_pe=n(pPe,"STRONG",{});var tEt=s(_pe);ePo=r(tEt,"bert"),tEt.forEach(t),oPo=r(pPe," \u2014 "),mV=n(pPe,"A",{href:!0});var aEt=s(mV);rPo=r(aEt,"BertLMHeadModel"),aEt.forEach(t),tPo=r(pPe," (BERT model)"),pPe.forEach(t),aPo=i(W),_1=n(W,"LI",{});var _Pe=s(_1);upe=n(_Pe,"STRONG",{});var nEt=s(upe);nPo=r(nEt,"bert-generation"),nEt.forEach(t),sPo=r(_Pe," \u2014 "),gV=n(_Pe,"A",{href:!0});var sEt=s(gV);lPo=r(sEt,"BertGenerationDecoder"),sEt.forEach(t),iPo=r(_Pe," (Bert Generation model)"),_Pe.forEach(t),dPo=i(W),u1=n(W,"LI",{});var uPe=s(u1);bpe=n(uPe,"STRONG",{});var lEt=s(bpe);cPo=r(lEt,"big_bird"),lEt.forEach(t),fPo=r(uPe," \u2014 "),hV=n(uPe,"A",{href:!0});var iEt=s(hV);mPo=r(iEt,"BigBirdForCausalLM"),iEt.forEach(t),gPo=r(uPe," (BigBird model)"),uPe.forEach(t),hPo=i(W),b1=n(W,"LI",{});var bPe=s(b1);vpe=n(bPe,"STRONG",{});var dEt=s(vpe);pPo=r(dEt,"bigbird_pegasus"),dEt.forEach(t),_Po=r(bPe," \u2014 "),pV=n(bPe,"A",{href:!0});var cEt=s(pV);uPo=r(cEt,"BigBirdPegasusForCausalLM"),cEt.forEach(t),bPo=r(bPe," (BigBird-Pegasus model)"),bPe.forEach(t),vPo=i(W),v1=n(W,"LI",{});var vPe=s(v1);Fpe=n(vPe,"STRONG",{});var fEt=s(Fpe);FPo=r(fEt,"blenderbot"),fEt.forEach(t),TPo=r(vPe," \u2014 "),_V=n(vPe,"A",{href:!0});var mEt=s(_V);MPo=r(mEt,"BlenderbotForCausalLM"),mEt.forEach(t),EPo=r(vPe," (Blenderbot model)"),vPe.forEach(t),CPo=i(W),F1=n(W,"LI",{});var FPe=s(F1);Tpe=n(FPe,"STRONG",{});var gEt=s(Tpe);wPo=r(gEt,"blenderbot-small"),gEt.forEach(t),APo=r(FPe," \u2014 "),uV=n(FPe,"A",{href:!0});var hEt=s(uV);LPo=r(hEt,"BlenderbotSmallForCausalLM"),hEt.forEach(t),yPo=r(FPe," (BlenderbotSmall model)"),FPe.forEach(t),xPo=i(W),T1=n(W,"LI",{});var TPe=s(T1);Mpe=n(TPe,"STRONG",{});var pEt=s(Mpe);$Po=r(pEt,"bloom"),pEt.forEach(t),kPo=r(TPe," \u2014 "),bV=n(TPe,"A",{href:!0});var _Et=s(bV);SPo=r(_Et,"BloomForCausalLM"),_Et.forEach(t),RPo=r(TPe," (BLOOM model)"),TPe.forEach(t),PPo=i(W),M1=n(W,"LI",{});var MPe=s(M1);Epe=n(MPe,"STRONG",{});var uEt=s(Epe);BPo=r(uEt,"camembert"),uEt.forEach(t),IPo=r(MPe," \u2014 "),vV=n(MPe,"A",{href:!0});var bEt=s(vV);NPo=r(bEt,"CamembertForCausalLM"),bEt.forEach(t),qPo=r(MPe," (CamemBERT model)"),MPe.forEach(t),jPo=i(W),E1=n(W,"LI",{});var EPe=s(E1);Cpe=n(EPe,"STRONG",{});var vEt=s(Cpe);DPo=r(vEt,"codegen"),vEt.forEach(t),GPo=r(EPe," \u2014 "),FV=n(EPe,"A",{href:!0});var FEt=s(FV);OPo=r(FEt,"CodeGenForCausalLM"),FEt.forEach(t),VPo=r(EPe," (CodeGen model)"),EPe.forEach(t),XPo=i(W),C1=n(W,"LI",{});var CPe=s(C1);wpe=n(CPe,"STRONG",{});var TEt=s(wpe);zPo=r(TEt,"ctrl"),TEt.forEach(t),WPo=r(CPe," \u2014 "),TV=n(CPe,"A",{href:!0});var MEt=s(TV);QPo=r(MEt,"CTRLLMHeadModel"),MEt.forEach(t),HPo=r(CPe," (CTRL model)"),CPe.forEach(t),UPo=i(W),w1=n(W,"LI",{});var wPe=s(w1);Ape=n(wPe,"STRONG",{});var EEt=s(Ape);JPo=r(EEt,"data2vec-text"),EEt.forEach(t),YPo=r(wPe," \u2014 "),MV=n(wPe,"A",{href:!0});var CEt=s(MV);KPo=r(CEt,"Data2VecTextForCausalLM"),CEt.forEach(t),ZPo=r(wPe," (Data2VecText model)"),wPe.forEach(t),eBo=i(W),A1=n(W,"LI",{});var APe=s(A1);Lpe=n(APe,"STRONG",{});var wEt=s(Lpe);oBo=r(wEt,"electra"),wEt.forEach(t),rBo=r(APe," \u2014 "),EV=n(APe,"A",{href:!0});var AEt=s(EV);tBo=r(AEt,"ElectraForCausalLM"),AEt.forEach(t),aBo=r(APe," (ELECTRA model)"),APe.forEach(t),nBo=i(W),L1=n(W,"LI",{});var LPe=s(L1);ype=n(LPe,"STRONG",{});var LEt=s(ype);sBo=r(LEt,"gpt2"),LEt.forEach(t),lBo=r(LPe," \u2014 "),CV=n(LPe,"A",{href:!0});var yEt=s(CV);iBo=r(yEt,"GPT2LMHeadModel"),yEt.forEach(t),dBo=r(LPe," (OpenAI GPT-2 model)"),LPe.forEach(t),cBo=i(W),y1=n(W,"LI",{});var yPe=s(y1);xpe=n(yPe,"STRONG",{});var xEt=s(xpe);fBo=r(xEt,"gpt_neo"),xEt.forEach(t),mBo=r(yPe," \u2014 "),wV=n(yPe,"A",{href:!0});var $Et=s(wV);gBo=r($Et,"GPTNeoForCausalLM"),$Et.forEach(t),hBo=r(yPe," (GPT Neo model)"),yPe.forEach(t),pBo=i(W),x1=n(W,"LI",{});var xPe=s(x1);$pe=n(xPe,"STRONG",{});var kEt=s($pe);_Bo=r(kEt,"gpt_neox"),kEt.forEach(t),uBo=r(xPe," \u2014 "),AV=n(xPe,"A",{href:!0});var SEt=s(AV);bBo=r(SEt,"GPTNeoXForCausalLM"),SEt.forEach(t),vBo=r(xPe," (GPT NeoX model)"),xPe.forEach(t),FBo=i(W),$1=n(W,"LI",{});var $Pe=s($1);kpe=n($Pe,"STRONG",{});var REt=s(kpe);TBo=r(REt,"gptj"),REt.forEach(t),MBo=r($Pe," \u2014 "),LV=n($Pe,"A",{href:!0});var PEt=s(LV);EBo=r(PEt,"GPTJForCausalLM"),PEt.forEach(t),CBo=r($Pe," (GPT-J model)"),$Pe.forEach(t),wBo=i(W),k1=n(W,"LI",{});var kPe=s(k1);Spe=n(kPe,"STRONG",{});var BEt=s(Spe);ABo=r(BEt,"marian"),BEt.forEach(t),LBo=r(kPe," \u2014 "),yV=n(kPe,"A",{href:!0});var IEt=s(yV);yBo=r(IEt,"MarianForCausalLM"),IEt.forEach(t),xBo=r(kPe," (Marian model)"),kPe.forEach(t),$Bo=i(W),S1=n(W,"LI",{});var SPe=s(S1);Rpe=n(SPe,"STRONG",{});var NEt=s(Rpe);kBo=r(NEt,"mbart"),NEt.forEach(t),SBo=r(SPe," \u2014 "),xV=n(SPe,"A",{href:!0});var qEt=s(xV);RBo=r(qEt,"MBartForCausalLM"),qEt.forEach(t),PBo=r(SPe," (mBART model)"),SPe.forEach(t),BBo=i(W),R1=n(W,"LI",{});var RPe=s(R1);Ppe=n(RPe,"STRONG",{});var jEt=s(Ppe);IBo=r(jEt,"megatron-bert"),jEt.forEach(t),NBo=r(RPe," \u2014 "),$V=n(RPe,"A",{href:!0});var DEt=s($V);qBo=r(DEt,"MegatronBertForCausalLM"),DEt.forEach(t),jBo=r(RPe," (Megatron-BERT model)"),RPe.forEach(t),DBo=i(W),P1=n(W,"LI",{});var PPe=s(P1);Bpe=n(PPe,"STRONG",{});var GEt=s(Bpe);GBo=r(GEt,"mvp"),GEt.forEach(t),OBo=r(PPe," \u2014 "),kV=n(PPe,"A",{href:!0});var OEt=s(kV);VBo=r(OEt,"MvpForCausalLM"),OEt.forEach(t),XBo=r(PPe," (MVP model)"),PPe.forEach(t),zBo=i(W),B1=n(W,"LI",{});var BPe=s(B1);Ipe=n(BPe,"STRONG",{});var VEt=s(Ipe);WBo=r(VEt,"openai-gpt"),VEt.forEach(t),QBo=r(BPe," \u2014 "),SV=n(BPe,"A",{href:!0});var XEt=s(SV);HBo=r(XEt,"OpenAIGPTLMHeadModel"),XEt.forEach(t),UBo=r(BPe," (OpenAI GPT model)"),BPe.forEach(t),JBo=i(W),I1=n(W,"LI",{});var IPe=s(I1);Npe=n(IPe,"STRONG",{});var zEt=s(Npe);YBo=r(zEt,"opt"),zEt.forEach(t),KBo=r(IPe," \u2014 "),RV=n(IPe,"A",{href:!0});var WEt=s(RV);ZBo=r(WEt,"OPTForCausalLM"),WEt.forEach(t),eIo=r(IPe," (OPT model)"),IPe.forEach(t),oIo=i(W),N1=n(W,"LI",{});var NPe=s(N1);qpe=n(NPe,"STRONG",{});var QEt=s(qpe);rIo=r(QEt,"pegasus"),QEt.forEach(t),tIo=r(NPe," \u2014 "),PV=n(NPe,"A",{href:!0});var HEt=s(PV);aIo=r(HEt,"PegasusForCausalLM"),HEt.forEach(t),nIo=r(NPe," (Pegasus model)"),NPe.forEach(t),sIo=i(W),q1=n(W,"LI",{});var qPe=s(q1);jpe=n(qPe,"STRONG",{});var UEt=s(jpe);lIo=r(UEt,"plbart"),UEt.forEach(t),iIo=r(qPe," \u2014 "),BV=n(qPe,"A",{href:!0});var JEt=s(BV);dIo=r(JEt,"PLBartForCausalLM"),JEt.forEach(t),cIo=r(qPe," (PLBart model)"),qPe.forEach(t),fIo=i(W),j1=n(W,"LI",{});var jPe=s(j1);Dpe=n(jPe,"STRONG",{});var YEt=s(Dpe);mIo=r(YEt,"prophetnet"),YEt.forEach(t),gIo=r(jPe," \u2014 "),IV=n(jPe,"A",{href:!0});var KEt=s(IV);hIo=r(KEt,"ProphetNetForCausalLM"),KEt.forEach(t),pIo=r(jPe," (ProphetNet model)"),jPe.forEach(t),_Io=i(W),D1=n(W,"LI",{});var DPe=s(D1);Gpe=n(DPe,"STRONG",{});var ZEt=s(Gpe);uIo=r(ZEt,"qdqbert"),ZEt.forEach(t),bIo=r(DPe," \u2014 "),NV=n(DPe,"A",{href:!0});var e4t=s(NV);vIo=r(e4t,"QDQBertLMHeadModel"),e4t.forEach(t),FIo=r(DPe," (QDQBert model)"),DPe.forEach(t),TIo=i(W),G1=n(W,"LI",{});var GPe=s(G1);Ope=n(GPe,"STRONG",{});var o4t=s(Ope);MIo=r(o4t,"reformer"),o4t.forEach(t),EIo=r(GPe," \u2014 "),qV=n(GPe,"A",{href:!0});var r4t=s(qV);CIo=r(r4t,"ReformerModelWithLMHead"),r4t.forEach(t),wIo=r(GPe," (Reformer model)"),GPe.forEach(t),AIo=i(W),O1=n(W,"LI",{});var OPe=s(O1);Vpe=n(OPe,"STRONG",{});var t4t=s(Vpe);LIo=r(t4t,"rembert"),t4t.forEach(t),yIo=r(OPe," \u2014 "),jV=n(OPe,"A",{href:!0});var a4t=s(jV);xIo=r(a4t,"RemBertForCausalLM"),a4t.forEach(t),$Io=r(OPe," (RemBERT model)"),OPe.forEach(t),kIo=i(W),V1=n(W,"LI",{});var VPe=s(V1);Xpe=n(VPe,"STRONG",{});var n4t=s(Xpe);SIo=r(n4t,"roberta"),n4t.forEach(t),RIo=r(VPe," \u2014 "),DV=n(VPe,"A",{href:!0});var s4t=s(DV);PIo=r(s4t,"RobertaForCausalLM"),s4t.forEach(t),BIo=r(VPe," (RoBERTa model)"),VPe.forEach(t),IIo=i(W),X1=n(W,"LI",{});var XPe=s(X1);zpe=n(XPe,"STRONG",{});var l4t=s(zpe);NIo=r(l4t,"roformer"),l4t.forEach(t),qIo=r(XPe," \u2014 "),GV=n(XPe,"A",{href:!0});var i4t=s(GV);jIo=r(i4t,"RoFormerForCausalLM"),i4t.forEach(t),DIo=r(XPe," (RoFormer model)"),XPe.forEach(t),GIo=i(W),z1=n(W,"LI",{});var zPe=s(z1);Wpe=n(zPe,"STRONG",{});var d4t=s(Wpe);OIo=r(d4t,"speech_to_text_2"),d4t.forEach(t),VIo=r(zPe," \u2014 "),OV=n(zPe,"A",{href:!0});var c4t=s(OV);XIo=r(c4t,"Speech2Text2ForCausalLM"),c4t.forEach(t),zIo=r(zPe," (Speech2Text2 model)"),zPe.forEach(t),WIo=i(W),W1=n(W,"LI",{});var WPe=s(W1);Qpe=n(WPe,"STRONG",{});var f4t=s(Qpe);QIo=r(f4t,"transfo-xl"),f4t.forEach(t),HIo=r(WPe," \u2014 "),VV=n(WPe,"A",{href:!0});var m4t=s(VV);UIo=r(m4t,"TransfoXLLMHeadModel"),m4t.forEach(t),JIo=r(WPe," (Transformer-XL model)"),WPe.forEach(t),YIo=i(W),Q1=n(W,"LI",{});var QPe=s(Q1);Hpe=n(QPe,"STRONG",{});var g4t=s(Hpe);KIo=r(g4t,"trocr"),g4t.forEach(t),ZIo=r(QPe," \u2014 "),XV=n(QPe,"A",{href:!0});var h4t=s(XV);eNo=r(h4t,"TrOCRForCausalLM"),h4t.forEach(t),oNo=r(QPe," (TrOCR model)"),QPe.forEach(t),rNo=i(W),H1=n(W,"LI",{});var HPe=s(H1);Upe=n(HPe,"STRONG",{});var p4t=s(Upe);tNo=r(p4t,"xglm"),p4t.forEach(t),aNo=r(HPe," \u2014 "),zV=n(HPe,"A",{href:!0});var _4t=s(zV);nNo=r(_4t,"XGLMForCausalLM"),_4t.forEach(t),sNo=r(HPe," (XGLM model)"),HPe.forEach(t),lNo=i(W),U1=n(W,"LI",{});var UPe=s(U1);Jpe=n(UPe,"STRONG",{});var u4t=s(Jpe);iNo=r(u4t,"xlm"),u4t.forEach(t),dNo=r(UPe," \u2014 "),WV=n(UPe,"A",{href:!0});var b4t=s(WV);cNo=r(b4t,"XLMWithLMHeadModel"),b4t.forEach(t),fNo=r(UPe," (XLM model)"),UPe.forEach(t),mNo=i(W),J1=n(W,"LI",{});var JPe=s(J1);Ype=n(JPe,"STRONG",{});var v4t=s(Ype);gNo=r(v4t,"xlm-prophetnet"),v4t.forEach(t),hNo=r(JPe," \u2014 "),QV=n(JPe,"A",{href:!0});var F4t=s(QV);pNo=r(F4t,"XLMProphetNetForCausalLM"),F4t.forEach(t),_No=r(JPe," (XLM-ProphetNet model)"),JPe.forEach(t),uNo=i(W),Y1=n(W,"LI",{});var YPe=s(Y1);Kpe=n(YPe,"STRONG",{});var T4t=s(Kpe);bNo=r(T4t,"xlm-roberta"),T4t.forEach(t),vNo=r(YPe," \u2014 "),HV=n(YPe,"A",{href:!0});var M4t=s(HV);FNo=r(M4t,"XLMRobertaForCausalLM"),M4t.forEach(t),TNo=r(YPe," (XLM-RoBERTa model)"),YPe.forEach(t),MNo=i(W),K1=n(W,"LI",{});var KPe=s(K1);Zpe=n(KPe,"STRONG",{});var E4t=s(Zpe);ENo=r(E4t,"xlm-roberta-xl"),E4t.forEach(t),CNo=r(KPe," \u2014 "),UV=n(KPe,"A",{href:!0});var C4t=s(UV);wNo=r(C4t,"XLMRobertaXLForCausalLM"),C4t.forEach(t),ANo=r(KPe," (XLM-RoBERTa-XL model)"),KPe.forEach(t),LNo=i(W),Z1=n(W,"LI",{});var ZPe=s(Z1);e_e=n(ZPe,"STRONG",{});var w4t=s(e_e);yNo=r(w4t,"xlnet"),w4t.forEach(t),xNo=r(ZPe," \u2014 "),JV=n(ZPe,"A",{href:!0});var A4t=s(JV);$No=r(A4t,"XLNetLMHeadModel"),A4t.forEach(t),kNo=r(ZPe," (XLNet model)"),ZPe.forEach(t),W.forEach(t),SNo=i(ma),e2=n(ma,"P",{});var eBe=s(e2);RNo=r(eBe,"The model is set in evaluation mode by default using "),o_e=n(eBe,"CODE",{});var L4t=s(o_e);PNo=r(L4t,"model.eval()"),L4t.forEach(t),BNo=r(eBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),r_e=n(eBe,"CODE",{});var y4t=s(r_e);INo=r(y4t,"model.train()"),y4t.forEach(t),eBe.forEach(t),NNo=i(ma),T(o2.$$.fragment,ma),ma.forEach(t),ml.forEach(t),aQe=i(f),nd=n(f,"H2",{class:!0});var mUe=s(nd);r2=n(mUe,"A",{id:!0,class:!0,href:!0});var x4t=s(r2);t_e=n(x4t,"SPAN",{});var $4t=s(t_e);T(Py.$$.fragment,$4t),$4t.forEach(t),x4t.forEach(t),qNo=i(mUe),a_e=n(mUe,"SPAN",{});var k4t=s(a_e);jNo=r(k4t,"AutoModelForMaskedLM"),k4t.forEach(t),mUe.forEach(t),nQe=i(f),Bo=n(f,"DIV",{class:!0});var gl=s(Bo);T(By.$$.fragment,gl),DNo=i(gl),sd=n(gl,"P",{});var mae=s(sd);GNo=r(mae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),YV=n(mae,"A",{href:!0});var S4t=s(YV);ONo=r(S4t,"from_pretrained()"),S4t.forEach(t),VNo=r(mae," class method or the "),KV=n(mae,"A",{href:!0});var R4t=s(KV);XNo=r(R4t,"from_config()"),R4t.forEach(t),zNo=r(mae,` class
method.`),mae.forEach(t),WNo=i(gl),Iy=n(gl,"P",{});var gUe=s(Iy);QNo=r(gUe,"This class cannot be instantiated directly using "),n_e=n(gUe,"CODE",{});var P4t=s(n_e);HNo=r(P4t,"__init__()"),P4t.forEach(t),UNo=r(gUe," (throws an error)."),gUe.forEach(t),JNo=i(gl),gt=n(gl,"DIV",{class:!0});var eA=s(gt);T(Ny.$$.fragment,eA),YNo=i(eA),s_e=n(eA,"P",{});var B4t=s(s_e);KNo=r(B4t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),B4t.forEach(t),ZNo=i(eA),ld=n(eA,"P",{});var gae=s(ld);eqo=r(gae,`Note:
Loading a model from its configuration file does `),l_e=n(gae,"STRONG",{});var I4t=s(l_e);oqo=r(I4t,"not"),I4t.forEach(t),rqo=r(gae,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZV=n(gae,"A",{href:!0});var N4t=s(ZV);tqo=r(N4t,"from_pretrained()"),N4t.forEach(t),aqo=r(gae," to load the model weights."),gae.forEach(t),nqo=i(eA),T(t2.$$.fragment,eA),eA.forEach(t),sqo=i(gl),eo=n(gl,"DIV",{class:!0});var ga=s(eo);T(qy.$$.fragment,ga),lqo=i(ga),i_e=n(ga,"P",{});var q4t=s(i_e);iqo=r(q4t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),q4t.forEach(t),dqo=i(ga),Va=n(ga,"P",{});var oA=s(Va);cqo=r(oA,"The model class to instantiate is selected based on the "),d_e=n(oA,"CODE",{});var j4t=s(d_e);fqo=r(j4t,"model_type"),j4t.forEach(t),mqo=r(oA,` property of the config object (either
passed as an argument or loaded from `),c_e=n(oA,"CODE",{});var D4t=s(c_e);gqo=r(D4t,"pretrained_model_name_or_path"),D4t.forEach(t),hqo=r(oA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f_e=n(oA,"CODE",{});var G4t=s(f_e);pqo=r(G4t,"pretrained_model_name_or_path"),G4t.forEach(t),_qo=r(oA,":"),oA.forEach(t),uqo=i(ga),Q=n(ga,"UL",{});var J=s(Q);a2=n(J,"LI",{});var oBe=s(a2);m_e=n(oBe,"STRONG",{});var O4t=s(m_e);bqo=r(O4t,"albert"),O4t.forEach(t),vqo=r(oBe," \u2014 "),eX=n(oBe,"A",{href:!0});var V4t=s(eX);Fqo=r(V4t,"AlbertForMaskedLM"),V4t.forEach(t),Tqo=r(oBe," (ALBERT model)"),oBe.forEach(t),Mqo=i(J),n2=n(J,"LI",{});var rBe=s(n2);g_e=n(rBe,"STRONG",{});var X4t=s(g_e);Eqo=r(X4t,"bart"),X4t.forEach(t),Cqo=r(rBe," \u2014 "),oX=n(rBe,"A",{href:!0});var z4t=s(oX);wqo=r(z4t,"BartForConditionalGeneration"),z4t.forEach(t),Aqo=r(rBe," (BART model)"),rBe.forEach(t),Lqo=i(J),s2=n(J,"LI",{});var tBe=s(s2);h_e=n(tBe,"STRONG",{});var W4t=s(h_e);yqo=r(W4t,"bert"),W4t.forEach(t),xqo=r(tBe," \u2014 "),rX=n(tBe,"A",{href:!0});var Q4t=s(rX);$qo=r(Q4t,"BertForMaskedLM"),Q4t.forEach(t),kqo=r(tBe," (BERT model)"),tBe.forEach(t),Sqo=i(J),l2=n(J,"LI",{});var aBe=s(l2);p_e=n(aBe,"STRONG",{});var H4t=s(p_e);Rqo=r(H4t,"big_bird"),H4t.forEach(t),Pqo=r(aBe," \u2014 "),tX=n(aBe,"A",{href:!0});var U4t=s(tX);Bqo=r(U4t,"BigBirdForMaskedLM"),U4t.forEach(t),Iqo=r(aBe," (BigBird model)"),aBe.forEach(t),Nqo=i(J),i2=n(J,"LI",{});var nBe=s(i2);__e=n(nBe,"STRONG",{});var J4t=s(__e);qqo=r(J4t,"camembert"),J4t.forEach(t),jqo=r(nBe," \u2014 "),aX=n(nBe,"A",{href:!0});var Y4t=s(aX);Dqo=r(Y4t,"CamembertForMaskedLM"),Y4t.forEach(t),Gqo=r(nBe," (CamemBERT model)"),nBe.forEach(t),Oqo=i(J),d2=n(J,"LI",{});var sBe=s(d2);u_e=n(sBe,"STRONG",{});var K4t=s(u_e);Vqo=r(K4t,"convbert"),K4t.forEach(t),Xqo=r(sBe," \u2014 "),nX=n(sBe,"A",{href:!0});var Z4t=s(nX);zqo=r(Z4t,"ConvBertForMaskedLM"),Z4t.forEach(t),Wqo=r(sBe," (ConvBERT model)"),sBe.forEach(t),Qqo=i(J),c2=n(J,"LI",{});var lBe=s(c2);b_e=n(lBe,"STRONG",{});var eCt=s(b_e);Hqo=r(eCt,"data2vec-text"),eCt.forEach(t),Uqo=r(lBe," \u2014 "),sX=n(lBe,"A",{href:!0});var oCt=s(sX);Jqo=r(oCt,"Data2VecTextForMaskedLM"),oCt.forEach(t),Yqo=r(lBe," (Data2VecText model)"),lBe.forEach(t),Kqo=i(J),f2=n(J,"LI",{});var iBe=s(f2);v_e=n(iBe,"STRONG",{});var rCt=s(v_e);Zqo=r(rCt,"deberta"),rCt.forEach(t),ejo=r(iBe," \u2014 "),lX=n(iBe,"A",{href:!0});var tCt=s(lX);ojo=r(tCt,"DebertaForMaskedLM"),tCt.forEach(t),rjo=r(iBe," (DeBERTa model)"),iBe.forEach(t),tjo=i(J),m2=n(J,"LI",{});var dBe=s(m2);F_e=n(dBe,"STRONG",{});var aCt=s(F_e);ajo=r(aCt,"deberta-v2"),aCt.forEach(t),njo=r(dBe," \u2014 "),iX=n(dBe,"A",{href:!0});var nCt=s(iX);sjo=r(nCt,"DebertaV2ForMaskedLM"),nCt.forEach(t),ljo=r(dBe," (DeBERTa-v2 model)"),dBe.forEach(t),ijo=i(J),g2=n(J,"LI",{});var cBe=s(g2);T_e=n(cBe,"STRONG",{});var sCt=s(T_e);djo=r(sCt,"distilbert"),sCt.forEach(t),cjo=r(cBe," \u2014 "),dX=n(cBe,"A",{href:!0});var lCt=s(dX);fjo=r(lCt,"DistilBertForMaskedLM"),lCt.forEach(t),mjo=r(cBe," (DistilBERT model)"),cBe.forEach(t),gjo=i(J),h2=n(J,"LI",{});var fBe=s(h2);M_e=n(fBe,"STRONG",{});var iCt=s(M_e);hjo=r(iCt,"electra"),iCt.forEach(t),pjo=r(fBe," \u2014 "),cX=n(fBe,"A",{href:!0});var dCt=s(cX);_jo=r(dCt,"ElectraForMaskedLM"),dCt.forEach(t),ujo=r(fBe," (ELECTRA model)"),fBe.forEach(t),bjo=i(J),p2=n(J,"LI",{});var mBe=s(p2);E_e=n(mBe,"STRONG",{});var cCt=s(E_e);vjo=r(cCt,"flaubert"),cCt.forEach(t),Fjo=r(mBe," \u2014 "),fX=n(mBe,"A",{href:!0});var fCt=s(fX);Tjo=r(fCt,"FlaubertWithLMHeadModel"),fCt.forEach(t),Mjo=r(mBe," (FlauBERT model)"),mBe.forEach(t),Ejo=i(J),_2=n(J,"LI",{});var gBe=s(_2);C_e=n(gBe,"STRONG",{});var mCt=s(C_e);Cjo=r(mCt,"fnet"),mCt.forEach(t),wjo=r(gBe," \u2014 "),mX=n(gBe,"A",{href:!0});var gCt=s(mX);Ajo=r(gCt,"FNetForMaskedLM"),gCt.forEach(t),Ljo=r(gBe," (FNet model)"),gBe.forEach(t),yjo=i(J),u2=n(J,"LI",{});var hBe=s(u2);w_e=n(hBe,"STRONG",{});var hCt=s(w_e);xjo=r(hCt,"funnel"),hCt.forEach(t),$jo=r(hBe," \u2014 "),gX=n(hBe,"A",{href:!0});var pCt=s(gX);kjo=r(pCt,"FunnelForMaskedLM"),pCt.forEach(t),Sjo=r(hBe," (Funnel Transformer model)"),hBe.forEach(t),Rjo=i(J),b2=n(J,"LI",{});var pBe=s(b2);A_e=n(pBe,"STRONG",{});var _Ct=s(A_e);Pjo=r(_Ct,"ibert"),_Ct.forEach(t),Bjo=r(pBe," \u2014 "),hX=n(pBe,"A",{href:!0});var uCt=s(hX);Ijo=r(uCt,"IBertForMaskedLM"),uCt.forEach(t),Njo=r(pBe," (I-BERT model)"),pBe.forEach(t),qjo=i(J),v2=n(J,"LI",{});var _Be=s(v2);L_e=n(_Be,"STRONG",{});var bCt=s(L_e);jjo=r(bCt,"layoutlm"),bCt.forEach(t),Djo=r(_Be," \u2014 "),pX=n(_Be,"A",{href:!0});var vCt=s(pX);Gjo=r(vCt,"LayoutLMForMaskedLM"),vCt.forEach(t),Ojo=r(_Be," (LayoutLM model)"),_Be.forEach(t),Vjo=i(J),F2=n(J,"LI",{});var uBe=s(F2);y_e=n(uBe,"STRONG",{});var FCt=s(y_e);Xjo=r(FCt,"longformer"),FCt.forEach(t),zjo=r(uBe," \u2014 "),_X=n(uBe,"A",{href:!0});var TCt=s(_X);Wjo=r(TCt,"LongformerForMaskedLM"),TCt.forEach(t),Qjo=r(uBe," (Longformer model)"),uBe.forEach(t),Hjo=i(J),T2=n(J,"LI",{});var bBe=s(T2);x_e=n(bBe,"STRONG",{});var MCt=s(x_e);Ujo=r(MCt,"luke"),MCt.forEach(t),Jjo=r(bBe," \u2014 "),uX=n(bBe,"A",{href:!0});var ECt=s(uX);Yjo=r(ECt,"LukeForMaskedLM"),ECt.forEach(t),Kjo=r(bBe," (LUKE model)"),bBe.forEach(t),Zjo=i(J),M2=n(J,"LI",{});var vBe=s(M2);$_e=n(vBe,"STRONG",{});var CCt=s($_e);eDo=r(CCt,"mbart"),CCt.forEach(t),oDo=r(vBe," \u2014 "),bX=n(vBe,"A",{href:!0});var wCt=s(bX);rDo=r(wCt,"MBartForConditionalGeneration"),wCt.forEach(t),tDo=r(vBe," (mBART model)"),vBe.forEach(t),aDo=i(J),E2=n(J,"LI",{});var FBe=s(E2);k_e=n(FBe,"STRONG",{});var ACt=s(k_e);nDo=r(ACt,"megatron-bert"),ACt.forEach(t),sDo=r(FBe," \u2014 "),vX=n(FBe,"A",{href:!0});var LCt=s(vX);lDo=r(LCt,"MegatronBertForMaskedLM"),LCt.forEach(t),iDo=r(FBe," (Megatron-BERT model)"),FBe.forEach(t),dDo=i(J),C2=n(J,"LI",{});var TBe=s(C2);S_e=n(TBe,"STRONG",{});var yCt=s(S_e);cDo=r(yCt,"mobilebert"),yCt.forEach(t),fDo=r(TBe," \u2014 "),FX=n(TBe,"A",{href:!0});var xCt=s(FX);mDo=r(xCt,"MobileBertForMaskedLM"),xCt.forEach(t),gDo=r(TBe," (MobileBERT model)"),TBe.forEach(t),hDo=i(J),w2=n(J,"LI",{});var MBe=s(w2);R_e=n(MBe,"STRONG",{});var $Ct=s(R_e);pDo=r($Ct,"mpnet"),$Ct.forEach(t),_Do=r(MBe," \u2014 "),TX=n(MBe,"A",{href:!0});var kCt=s(TX);uDo=r(kCt,"MPNetForMaskedLM"),kCt.forEach(t),bDo=r(MBe," (MPNet model)"),MBe.forEach(t),vDo=i(J),A2=n(J,"LI",{});var EBe=s(A2);P_e=n(EBe,"STRONG",{});var SCt=s(P_e);FDo=r(SCt,"mvp"),SCt.forEach(t),TDo=r(EBe," \u2014 "),MX=n(EBe,"A",{href:!0});var RCt=s(MX);MDo=r(RCt,"MvpForConditionalGeneration"),RCt.forEach(t),EDo=r(EBe," (MVP model)"),EBe.forEach(t),CDo=i(J),L2=n(J,"LI",{});var CBe=s(L2);B_e=n(CBe,"STRONG",{});var PCt=s(B_e);wDo=r(PCt,"nezha"),PCt.forEach(t),ADo=r(CBe," \u2014 "),EX=n(CBe,"A",{href:!0});var BCt=s(EX);LDo=r(BCt,"NezhaForMaskedLM"),BCt.forEach(t),yDo=r(CBe," (Nezha model)"),CBe.forEach(t),xDo=i(J),y2=n(J,"LI",{});var wBe=s(y2);I_e=n(wBe,"STRONG",{});var ICt=s(I_e);$Do=r(ICt,"nystromformer"),ICt.forEach(t),kDo=r(wBe," \u2014 "),CX=n(wBe,"A",{href:!0});var NCt=s(CX);SDo=r(NCt,"NystromformerForMaskedLM"),NCt.forEach(t),RDo=r(wBe," (Nystr\xF6mformer model)"),wBe.forEach(t),PDo=i(J),x2=n(J,"LI",{});var ABe=s(x2);N_e=n(ABe,"STRONG",{});var qCt=s(N_e);BDo=r(qCt,"perceiver"),qCt.forEach(t),IDo=r(ABe," \u2014 "),wX=n(ABe,"A",{href:!0});var jCt=s(wX);NDo=r(jCt,"PerceiverForMaskedLM"),jCt.forEach(t),qDo=r(ABe," (Perceiver model)"),ABe.forEach(t),jDo=i(J),$2=n(J,"LI",{});var LBe=s($2);q_e=n(LBe,"STRONG",{});var DCt=s(q_e);DDo=r(DCt,"qdqbert"),DCt.forEach(t),GDo=r(LBe," \u2014 "),AX=n(LBe,"A",{href:!0});var GCt=s(AX);ODo=r(GCt,"QDQBertForMaskedLM"),GCt.forEach(t),VDo=r(LBe," (QDQBert model)"),LBe.forEach(t),XDo=i(J),k2=n(J,"LI",{});var yBe=s(k2);j_e=n(yBe,"STRONG",{});var OCt=s(j_e);zDo=r(OCt,"reformer"),OCt.forEach(t),WDo=r(yBe," \u2014 "),LX=n(yBe,"A",{href:!0});var VCt=s(LX);QDo=r(VCt,"ReformerForMaskedLM"),VCt.forEach(t),HDo=r(yBe," (Reformer model)"),yBe.forEach(t),UDo=i(J),S2=n(J,"LI",{});var xBe=s(S2);D_e=n(xBe,"STRONG",{});var XCt=s(D_e);JDo=r(XCt,"rembert"),XCt.forEach(t),YDo=r(xBe," \u2014 "),yX=n(xBe,"A",{href:!0});var zCt=s(yX);KDo=r(zCt,"RemBertForMaskedLM"),zCt.forEach(t),ZDo=r(xBe," (RemBERT model)"),xBe.forEach(t),eGo=i(J),R2=n(J,"LI",{});var $Be=s(R2);G_e=n($Be,"STRONG",{});var WCt=s(G_e);oGo=r(WCt,"roberta"),WCt.forEach(t),rGo=r($Be," \u2014 "),xX=n($Be,"A",{href:!0});var QCt=s(xX);tGo=r(QCt,"RobertaForMaskedLM"),QCt.forEach(t),aGo=r($Be," (RoBERTa model)"),$Be.forEach(t),nGo=i(J),P2=n(J,"LI",{});var kBe=s(P2);O_e=n(kBe,"STRONG",{});var HCt=s(O_e);sGo=r(HCt,"roformer"),HCt.forEach(t),lGo=r(kBe," \u2014 "),$X=n(kBe,"A",{href:!0});var UCt=s($X);iGo=r(UCt,"RoFormerForMaskedLM"),UCt.forEach(t),dGo=r(kBe," (RoFormer model)"),kBe.forEach(t),cGo=i(J),B2=n(J,"LI",{});var SBe=s(B2);V_e=n(SBe,"STRONG",{});var JCt=s(V_e);fGo=r(JCt,"squeezebert"),JCt.forEach(t),mGo=r(SBe," \u2014 "),kX=n(SBe,"A",{href:!0});var YCt=s(kX);gGo=r(YCt,"SqueezeBertForMaskedLM"),YCt.forEach(t),hGo=r(SBe," (SqueezeBERT model)"),SBe.forEach(t),pGo=i(J),I2=n(J,"LI",{});var RBe=s(I2);X_e=n(RBe,"STRONG",{});var KCt=s(X_e);_Go=r(KCt,"tapas"),KCt.forEach(t),uGo=r(RBe," \u2014 "),SX=n(RBe,"A",{href:!0});var ZCt=s(SX);bGo=r(ZCt,"TapasForMaskedLM"),ZCt.forEach(t),vGo=r(RBe," (TAPAS model)"),RBe.forEach(t),FGo=i(J),N2=n(J,"LI",{});var PBe=s(N2);z_e=n(PBe,"STRONG",{});var e3t=s(z_e);TGo=r(e3t,"wav2vec2"),e3t.forEach(t),MGo=r(PBe," \u2014 "),W_e=n(PBe,"CODE",{});var o3t=s(W_e);EGo=r(o3t,"Wav2Vec2ForMaskedLM"),o3t.forEach(t),CGo=r(PBe," (Wav2Vec2 model)"),PBe.forEach(t),wGo=i(J),q2=n(J,"LI",{});var BBe=s(q2);Q_e=n(BBe,"STRONG",{});var r3t=s(Q_e);AGo=r(r3t,"xlm"),r3t.forEach(t),LGo=r(BBe," \u2014 "),RX=n(BBe,"A",{href:!0});var t3t=s(RX);yGo=r(t3t,"XLMWithLMHeadModel"),t3t.forEach(t),xGo=r(BBe," (XLM model)"),BBe.forEach(t),$Go=i(J),j2=n(J,"LI",{});var IBe=s(j2);H_e=n(IBe,"STRONG",{});var a3t=s(H_e);kGo=r(a3t,"xlm-roberta"),a3t.forEach(t),SGo=r(IBe," \u2014 "),PX=n(IBe,"A",{href:!0});var n3t=s(PX);RGo=r(n3t,"XLMRobertaForMaskedLM"),n3t.forEach(t),PGo=r(IBe," (XLM-RoBERTa model)"),IBe.forEach(t),BGo=i(J),D2=n(J,"LI",{});var NBe=s(D2);U_e=n(NBe,"STRONG",{});var s3t=s(U_e);IGo=r(s3t,"xlm-roberta-xl"),s3t.forEach(t),NGo=r(NBe," \u2014 "),BX=n(NBe,"A",{href:!0});var l3t=s(BX);qGo=r(l3t,"XLMRobertaXLForMaskedLM"),l3t.forEach(t),jGo=r(NBe," (XLM-RoBERTa-XL model)"),NBe.forEach(t),DGo=i(J),G2=n(J,"LI",{});var qBe=s(G2);J_e=n(qBe,"STRONG",{});var i3t=s(J_e);GGo=r(i3t,"yoso"),i3t.forEach(t),OGo=r(qBe," \u2014 "),IX=n(qBe,"A",{href:!0});var d3t=s(IX);VGo=r(d3t,"YosoForMaskedLM"),d3t.forEach(t),XGo=r(qBe," (YOSO model)"),qBe.forEach(t),J.forEach(t),zGo=i(ga),O2=n(ga,"P",{});var jBe=s(O2);WGo=r(jBe,"The model is set in evaluation mode by default using "),Y_e=n(jBe,"CODE",{});var c3t=s(Y_e);QGo=r(c3t,"model.eval()"),c3t.forEach(t),HGo=r(jBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),K_e=n(jBe,"CODE",{});var f3t=s(K_e);UGo=r(f3t,"model.train()"),f3t.forEach(t),jBe.forEach(t),JGo=i(ga),T(V2.$$.fragment,ga),ga.forEach(t),gl.forEach(t),sQe=i(f),id=n(f,"H2",{class:!0});var hUe=s(id);X2=n(hUe,"A",{id:!0,class:!0,href:!0});var m3t=s(X2);Z_e=n(m3t,"SPAN",{});var g3t=s(Z_e);T(jy.$$.fragment,g3t),g3t.forEach(t),m3t.forEach(t),YGo=i(hUe),eue=n(hUe,"SPAN",{});var h3t=s(eue);KGo=r(h3t,"AutoModelForSeq2SeqLM"),h3t.forEach(t),hUe.forEach(t),lQe=i(f),Io=n(f,"DIV",{class:!0});var hl=s(Io);T(Dy.$$.fragment,hl),ZGo=i(hl),dd=n(hl,"P",{});var hae=s(dd);eOo=r(hae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),NX=n(hae,"A",{href:!0});var p3t=s(NX);oOo=r(p3t,"from_pretrained()"),p3t.forEach(t),rOo=r(hae," class method or the "),qX=n(hae,"A",{href:!0});var _3t=s(qX);tOo=r(_3t,"from_config()"),_3t.forEach(t),aOo=r(hae,` class
method.`),hae.forEach(t),nOo=i(hl),Gy=n(hl,"P",{});var pUe=s(Gy);sOo=r(pUe,"This class cannot be instantiated directly using "),oue=n(pUe,"CODE",{});var u3t=s(oue);lOo=r(u3t,"__init__()"),u3t.forEach(t),iOo=r(pUe," (throws an error)."),pUe.forEach(t),dOo=i(hl),ht=n(hl,"DIV",{class:!0});var rA=s(ht);T(Oy.$$.fragment,rA),cOo=i(rA),rue=n(rA,"P",{});var b3t=s(rue);fOo=r(b3t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),b3t.forEach(t),mOo=i(rA),cd=n(rA,"P",{});var pae=s(cd);gOo=r(pae,`Note:
Loading a model from its configuration file does `),tue=n(pae,"STRONG",{});var v3t=s(tue);hOo=r(v3t,"not"),v3t.forEach(t),pOo=r(pae,` load the model weights. It only affects the
model\u2019s configuration. Use `),jX=n(pae,"A",{href:!0});var F3t=s(jX);_Oo=r(F3t,"from_pretrained()"),F3t.forEach(t),uOo=r(pae," to load the model weights."),pae.forEach(t),bOo=i(rA),T(z2.$$.fragment,rA),rA.forEach(t),vOo=i(hl),oo=n(hl,"DIV",{class:!0});var ha=s(oo);T(Vy.$$.fragment,ha),FOo=i(ha),aue=n(ha,"P",{});var T3t=s(aue);TOo=r(T3t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),T3t.forEach(t),MOo=i(ha),Xa=n(ha,"P",{});var tA=s(Xa);EOo=r(tA,"The model class to instantiate is selected based on the "),nue=n(tA,"CODE",{});var M3t=s(nue);COo=r(M3t,"model_type"),M3t.forEach(t),wOo=r(tA,` property of the config object (either
passed as an argument or loaded from `),sue=n(tA,"CODE",{});var E3t=s(sue);AOo=r(E3t,"pretrained_model_name_or_path"),E3t.forEach(t),LOo=r(tA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lue=n(tA,"CODE",{});var C3t=s(lue);yOo=r(C3t,"pretrained_model_name_or_path"),C3t.forEach(t),xOo=r(tA,":"),tA.forEach(t),$Oo=i(ha),me=n(ha,"UL",{});var ue=s(me);W2=n(ue,"LI",{});var DBe=s(W2);iue=n(DBe,"STRONG",{});var w3t=s(iue);kOo=r(w3t,"bart"),w3t.forEach(t),SOo=r(DBe," \u2014 "),DX=n(DBe,"A",{href:!0});var A3t=s(DX);ROo=r(A3t,"BartForConditionalGeneration"),A3t.forEach(t),POo=r(DBe," (BART model)"),DBe.forEach(t),BOo=i(ue),Q2=n(ue,"LI",{});var GBe=s(Q2);due=n(GBe,"STRONG",{});var L3t=s(due);IOo=r(L3t,"bigbird_pegasus"),L3t.forEach(t),NOo=r(GBe," \u2014 "),GX=n(GBe,"A",{href:!0});var y3t=s(GX);qOo=r(y3t,"BigBirdPegasusForConditionalGeneration"),y3t.forEach(t),jOo=r(GBe," (BigBird-Pegasus model)"),GBe.forEach(t),DOo=i(ue),H2=n(ue,"LI",{});var OBe=s(H2);cue=n(OBe,"STRONG",{});var x3t=s(cue);GOo=r(x3t,"blenderbot"),x3t.forEach(t),OOo=r(OBe," \u2014 "),OX=n(OBe,"A",{href:!0});var $3t=s(OX);VOo=r($3t,"BlenderbotForConditionalGeneration"),$3t.forEach(t),XOo=r(OBe," (Blenderbot model)"),OBe.forEach(t),zOo=i(ue),U2=n(ue,"LI",{});var VBe=s(U2);fue=n(VBe,"STRONG",{});var k3t=s(fue);WOo=r(k3t,"blenderbot-small"),k3t.forEach(t),QOo=r(VBe," \u2014 "),VX=n(VBe,"A",{href:!0});var S3t=s(VX);HOo=r(S3t,"BlenderbotSmallForConditionalGeneration"),S3t.forEach(t),UOo=r(VBe," (BlenderbotSmall model)"),VBe.forEach(t),JOo=i(ue),J2=n(ue,"LI",{});var XBe=s(J2);mue=n(XBe,"STRONG",{});var R3t=s(mue);YOo=r(R3t,"encoder-decoder"),R3t.forEach(t),KOo=r(XBe," \u2014 "),XX=n(XBe,"A",{href:!0});var P3t=s(XX);ZOo=r(P3t,"EncoderDecoderModel"),P3t.forEach(t),eVo=r(XBe," (Encoder decoder model)"),XBe.forEach(t),oVo=i(ue),Y2=n(ue,"LI",{});var zBe=s(Y2);gue=n(zBe,"STRONG",{});var B3t=s(gue);rVo=r(B3t,"fsmt"),B3t.forEach(t),tVo=r(zBe," \u2014 "),zX=n(zBe,"A",{href:!0});var I3t=s(zX);aVo=r(I3t,"FSMTForConditionalGeneration"),I3t.forEach(t),nVo=r(zBe," (FairSeq Machine-Translation model)"),zBe.forEach(t),sVo=i(ue),K2=n(ue,"LI",{});var WBe=s(K2);hue=n(WBe,"STRONG",{});var N3t=s(hue);lVo=r(N3t,"led"),N3t.forEach(t),iVo=r(WBe," \u2014 "),WX=n(WBe,"A",{href:!0});var q3t=s(WX);dVo=r(q3t,"LEDForConditionalGeneration"),q3t.forEach(t),cVo=r(WBe," (LED model)"),WBe.forEach(t),fVo=i(ue),Z2=n(ue,"LI",{});var QBe=s(Z2);pue=n(QBe,"STRONG",{});var j3t=s(pue);mVo=r(j3t,"longt5"),j3t.forEach(t),gVo=r(QBe," \u2014 "),QX=n(QBe,"A",{href:!0});var D3t=s(QX);hVo=r(D3t,"LongT5ForConditionalGeneration"),D3t.forEach(t),pVo=r(QBe," (LongT5 model)"),QBe.forEach(t),_Vo=i(ue),eb=n(ue,"LI",{});var HBe=s(eb);_ue=n(HBe,"STRONG",{});var G3t=s(_ue);uVo=r(G3t,"m2m_100"),G3t.forEach(t),bVo=r(HBe," \u2014 "),HX=n(HBe,"A",{href:!0});var O3t=s(HX);vVo=r(O3t,"M2M100ForConditionalGeneration"),O3t.forEach(t),FVo=r(HBe," (M2M100 model)"),HBe.forEach(t),TVo=i(ue),ob=n(ue,"LI",{});var UBe=s(ob);uue=n(UBe,"STRONG",{});var V3t=s(uue);MVo=r(V3t,"marian"),V3t.forEach(t),EVo=r(UBe," \u2014 "),UX=n(UBe,"A",{href:!0});var X3t=s(UX);CVo=r(X3t,"MarianMTModel"),X3t.forEach(t),wVo=r(UBe," (Marian model)"),UBe.forEach(t),AVo=i(ue),rb=n(ue,"LI",{});var JBe=s(rb);bue=n(JBe,"STRONG",{});var z3t=s(bue);LVo=r(z3t,"mbart"),z3t.forEach(t),yVo=r(JBe," \u2014 "),JX=n(JBe,"A",{href:!0});var W3t=s(JX);xVo=r(W3t,"MBartForConditionalGeneration"),W3t.forEach(t),$Vo=r(JBe," (mBART model)"),JBe.forEach(t),kVo=i(ue),tb=n(ue,"LI",{});var YBe=s(tb);vue=n(YBe,"STRONG",{});var Q3t=s(vue);SVo=r(Q3t,"mt5"),Q3t.forEach(t),RVo=r(YBe," \u2014 "),YX=n(YBe,"A",{href:!0});var H3t=s(YX);PVo=r(H3t,"MT5ForConditionalGeneration"),H3t.forEach(t),BVo=r(YBe," (MT5 model)"),YBe.forEach(t),IVo=i(ue),ab=n(ue,"LI",{});var KBe=s(ab);Fue=n(KBe,"STRONG",{});var U3t=s(Fue);NVo=r(U3t,"mvp"),U3t.forEach(t),qVo=r(KBe," \u2014 "),KX=n(KBe,"A",{href:!0});var J3t=s(KX);jVo=r(J3t,"MvpForConditionalGeneration"),J3t.forEach(t),DVo=r(KBe," (MVP model)"),KBe.forEach(t),GVo=i(ue),nb=n(ue,"LI",{});var ZBe=s(nb);Tue=n(ZBe,"STRONG",{});var Y3t=s(Tue);OVo=r(Y3t,"nllb"),Y3t.forEach(t),VVo=r(ZBe," \u2014 "),ZX=n(ZBe,"A",{href:!0});var K3t=s(ZX);XVo=r(K3t,"M2M100ForConditionalGeneration"),K3t.forEach(t),zVo=r(ZBe," (NLLB model)"),ZBe.forEach(t),WVo=i(ue),sb=n(ue,"LI",{});var eIe=s(sb);Mue=n(eIe,"STRONG",{});var Z3t=s(Mue);QVo=r(Z3t,"pegasus"),Z3t.forEach(t),HVo=r(eIe," \u2014 "),ez=n(eIe,"A",{href:!0});var e5t=s(ez);UVo=r(e5t,"PegasusForConditionalGeneration"),e5t.forEach(t),JVo=r(eIe," (Pegasus model)"),eIe.forEach(t),YVo=i(ue),lb=n(ue,"LI",{});var oIe=s(lb);Eue=n(oIe,"STRONG",{});var o5t=s(Eue);KVo=r(o5t,"plbart"),o5t.forEach(t),ZVo=r(oIe," \u2014 "),oz=n(oIe,"A",{href:!0});var r5t=s(oz);eXo=r(r5t,"PLBartForConditionalGeneration"),r5t.forEach(t),oXo=r(oIe," (PLBart model)"),oIe.forEach(t),rXo=i(ue),ib=n(ue,"LI",{});var rIe=s(ib);Cue=n(rIe,"STRONG",{});var t5t=s(Cue);tXo=r(t5t,"prophetnet"),t5t.forEach(t),aXo=r(rIe," \u2014 "),rz=n(rIe,"A",{href:!0});var a5t=s(rz);nXo=r(a5t,"ProphetNetForConditionalGeneration"),a5t.forEach(t),sXo=r(rIe," (ProphetNet model)"),rIe.forEach(t),lXo=i(ue),db=n(ue,"LI",{});var tIe=s(db);wue=n(tIe,"STRONG",{});var n5t=s(wue);iXo=r(n5t,"t5"),n5t.forEach(t),dXo=r(tIe," \u2014 "),tz=n(tIe,"A",{href:!0});var s5t=s(tz);cXo=r(s5t,"T5ForConditionalGeneration"),s5t.forEach(t),fXo=r(tIe," (T5 model)"),tIe.forEach(t),mXo=i(ue),cb=n(ue,"LI",{});var aIe=s(cb);Aue=n(aIe,"STRONG",{});var l5t=s(Aue);gXo=r(l5t,"xlm-prophetnet"),l5t.forEach(t),hXo=r(aIe," \u2014 "),az=n(aIe,"A",{href:!0});var i5t=s(az);pXo=r(i5t,"XLMProphetNetForConditionalGeneration"),i5t.forEach(t),_Xo=r(aIe," (XLM-ProphetNet model)"),aIe.forEach(t),ue.forEach(t),uXo=i(ha),fb=n(ha,"P",{});var nIe=s(fb);bXo=r(nIe,"The model is set in evaluation mode by default using "),Lue=n(nIe,"CODE",{});var d5t=s(Lue);vXo=r(d5t,"model.eval()"),d5t.forEach(t),FXo=r(nIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yue=n(nIe,"CODE",{});var c5t=s(yue);TXo=r(c5t,"model.train()"),c5t.forEach(t),nIe.forEach(t),MXo=i(ha),T(mb.$$.fragment,ha),ha.forEach(t),hl.forEach(t),iQe=i(f),fd=n(f,"H2",{class:!0});var _Ue=s(fd);gb=n(_Ue,"A",{id:!0,class:!0,href:!0});var f5t=s(gb);xue=n(f5t,"SPAN",{});var m5t=s(xue);T(Xy.$$.fragment,m5t),m5t.forEach(t),f5t.forEach(t),EXo=i(_Ue),$ue=n(_Ue,"SPAN",{});var g5t=s($ue);CXo=r(g5t,"AutoModelForSequenceClassification"),g5t.forEach(t),_Ue.forEach(t),dQe=i(f),No=n(f,"DIV",{class:!0});var pl=s(No);T(zy.$$.fragment,pl),wXo=i(pl),md=n(pl,"P",{});var _ae=s(md);AXo=r(_ae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),nz=n(_ae,"A",{href:!0});var h5t=s(nz);LXo=r(h5t,"from_pretrained()"),h5t.forEach(t),yXo=r(_ae," class method or the "),sz=n(_ae,"A",{href:!0});var p5t=s(sz);xXo=r(p5t,"from_config()"),p5t.forEach(t),$Xo=r(_ae,` class
method.`),_ae.forEach(t),kXo=i(pl),Wy=n(pl,"P",{});var uUe=s(Wy);SXo=r(uUe,"This class cannot be instantiated directly using "),kue=n(uUe,"CODE",{});var _5t=s(kue);RXo=r(_5t,"__init__()"),_5t.forEach(t),PXo=r(uUe," (throws an error)."),uUe.forEach(t),BXo=i(pl),pt=n(pl,"DIV",{class:!0});var aA=s(pt);T(Qy.$$.fragment,aA),IXo=i(aA),Sue=n(aA,"P",{});var u5t=s(Sue);NXo=r(u5t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),u5t.forEach(t),qXo=i(aA),gd=n(aA,"P",{});var uae=s(gd);jXo=r(uae,`Note:
Loading a model from its configuration file does `),Rue=n(uae,"STRONG",{});var b5t=s(Rue);DXo=r(b5t,"not"),b5t.forEach(t),GXo=r(uae,` load the model weights. It only affects the
model\u2019s configuration. Use `),lz=n(uae,"A",{href:!0});var v5t=s(lz);OXo=r(v5t,"from_pretrained()"),v5t.forEach(t),VXo=r(uae," to load the model weights."),uae.forEach(t),XXo=i(aA),T(hb.$$.fragment,aA),aA.forEach(t),zXo=i(pl),ro=n(pl,"DIV",{class:!0});var pa=s(ro);T(Hy.$$.fragment,pa),WXo=i(pa),Pue=n(pa,"P",{});var F5t=s(Pue);QXo=r(F5t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),F5t.forEach(t),HXo=i(pa),za=n(pa,"P",{});var nA=s(za);UXo=r(nA,"The model class to instantiate is selected based on the "),Bue=n(nA,"CODE",{});var T5t=s(Bue);JXo=r(T5t,"model_type"),T5t.forEach(t),YXo=r(nA,` property of the config object (either
passed as an argument or loaded from `),Iue=n(nA,"CODE",{});var M5t=s(Iue);KXo=r(M5t,"pretrained_model_name_or_path"),M5t.forEach(t),ZXo=r(nA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Nue=n(nA,"CODE",{});var E5t=s(Nue);ezo=r(E5t,"pretrained_model_name_or_path"),E5t.forEach(t),ozo=r(nA,":"),nA.forEach(t),rzo=i(pa),B=n(pa,"UL",{});var j=s(B);pb=n(j,"LI",{});var sIe=s(pb);que=n(sIe,"STRONG",{});var C5t=s(que);tzo=r(C5t,"albert"),C5t.forEach(t),azo=r(sIe," \u2014 "),iz=n(sIe,"A",{href:!0});var w5t=s(iz);nzo=r(w5t,"AlbertForSequenceClassification"),w5t.forEach(t),szo=r(sIe," (ALBERT model)"),sIe.forEach(t),lzo=i(j),_b=n(j,"LI",{});var lIe=s(_b);jue=n(lIe,"STRONG",{});var A5t=s(jue);izo=r(A5t,"bart"),A5t.forEach(t),dzo=r(lIe," \u2014 "),dz=n(lIe,"A",{href:!0});var L5t=s(dz);czo=r(L5t,"BartForSequenceClassification"),L5t.forEach(t),fzo=r(lIe," (BART model)"),lIe.forEach(t),mzo=i(j),ub=n(j,"LI",{});var iIe=s(ub);Due=n(iIe,"STRONG",{});var y5t=s(Due);gzo=r(y5t,"bert"),y5t.forEach(t),hzo=r(iIe," \u2014 "),cz=n(iIe,"A",{href:!0});var x5t=s(cz);pzo=r(x5t,"BertForSequenceClassification"),x5t.forEach(t),_zo=r(iIe," (BERT model)"),iIe.forEach(t),uzo=i(j),bb=n(j,"LI",{});var dIe=s(bb);Gue=n(dIe,"STRONG",{});var $5t=s(Gue);bzo=r($5t,"big_bird"),$5t.forEach(t),vzo=r(dIe," \u2014 "),fz=n(dIe,"A",{href:!0});var k5t=s(fz);Fzo=r(k5t,"BigBirdForSequenceClassification"),k5t.forEach(t),Tzo=r(dIe," (BigBird model)"),dIe.forEach(t),Mzo=i(j),vb=n(j,"LI",{});var cIe=s(vb);Oue=n(cIe,"STRONG",{});var S5t=s(Oue);Ezo=r(S5t,"bigbird_pegasus"),S5t.forEach(t),Czo=r(cIe," \u2014 "),mz=n(cIe,"A",{href:!0});var R5t=s(mz);wzo=r(R5t,"BigBirdPegasusForSequenceClassification"),R5t.forEach(t),Azo=r(cIe," (BigBird-Pegasus model)"),cIe.forEach(t),Lzo=i(j),Fb=n(j,"LI",{});var fIe=s(Fb);Vue=n(fIe,"STRONG",{});var P5t=s(Vue);yzo=r(P5t,"bloom"),P5t.forEach(t),xzo=r(fIe," \u2014 "),gz=n(fIe,"A",{href:!0});var B5t=s(gz);$zo=r(B5t,"BloomForSequenceClassification"),B5t.forEach(t),kzo=r(fIe," (BLOOM model)"),fIe.forEach(t),Szo=i(j),Tb=n(j,"LI",{});var mIe=s(Tb);Xue=n(mIe,"STRONG",{});var I5t=s(Xue);Rzo=r(I5t,"camembert"),I5t.forEach(t),Pzo=r(mIe," \u2014 "),hz=n(mIe,"A",{href:!0});var N5t=s(hz);Bzo=r(N5t,"CamembertForSequenceClassification"),N5t.forEach(t),Izo=r(mIe," (CamemBERT model)"),mIe.forEach(t),Nzo=i(j),Mb=n(j,"LI",{});var gIe=s(Mb);zue=n(gIe,"STRONG",{});var q5t=s(zue);qzo=r(q5t,"canine"),q5t.forEach(t),jzo=r(gIe," \u2014 "),pz=n(gIe,"A",{href:!0});var j5t=s(pz);Dzo=r(j5t,"CanineForSequenceClassification"),j5t.forEach(t),Gzo=r(gIe," (CANINE model)"),gIe.forEach(t),Ozo=i(j),Eb=n(j,"LI",{});var hIe=s(Eb);Wue=n(hIe,"STRONG",{});var D5t=s(Wue);Vzo=r(D5t,"convbert"),D5t.forEach(t),Xzo=r(hIe," \u2014 "),_z=n(hIe,"A",{href:!0});var G5t=s(_z);zzo=r(G5t,"ConvBertForSequenceClassification"),G5t.forEach(t),Wzo=r(hIe," (ConvBERT model)"),hIe.forEach(t),Qzo=i(j),Cb=n(j,"LI",{});var pIe=s(Cb);Que=n(pIe,"STRONG",{});var O5t=s(Que);Hzo=r(O5t,"ctrl"),O5t.forEach(t),Uzo=r(pIe," \u2014 "),uz=n(pIe,"A",{href:!0});var V5t=s(uz);Jzo=r(V5t,"CTRLForSequenceClassification"),V5t.forEach(t),Yzo=r(pIe," (CTRL model)"),pIe.forEach(t),Kzo=i(j),wb=n(j,"LI",{});var _Ie=s(wb);Hue=n(_Ie,"STRONG",{});var X5t=s(Hue);Zzo=r(X5t,"data2vec-text"),X5t.forEach(t),eWo=r(_Ie," \u2014 "),bz=n(_Ie,"A",{href:!0});var z5t=s(bz);oWo=r(z5t,"Data2VecTextForSequenceClassification"),z5t.forEach(t),rWo=r(_Ie," (Data2VecText model)"),_Ie.forEach(t),tWo=i(j),Ab=n(j,"LI",{});var uIe=s(Ab);Uue=n(uIe,"STRONG",{});var W5t=s(Uue);aWo=r(W5t,"deberta"),W5t.forEach(t),nWo=r(uIe," \u2014 "),vz=n(uIe,"A",{href:!0});var Q5t=s(vz);sWo=r(Q5t,"DebertaForSequenceClassification"),Q5t.forEach(t),lWo=r(uIe," (DeBERTa model)"),uIe.forEach(t),iWo=i(j),Lb=n(j,"LI",{});var bIe=s(Lb);Jue=n(bIe,"STRONG",{});var H5t=s(Jue);dWo=r(H5t,"deberta-v2"),H5t.forEach(t),cWo=r(bIe," \u2014 "),Fz=n(bIe,"A",{href:!0});var U5t=s(Fz);fWo=r(U5t,"DebertaV2ForSequenceClassification"),U5t.forEach(t),mWo=r(bIe," (DeBERTa-v2 model)"),bIe.forEach(t),gWo=i(j),yb=n(j,"LI",{});var vIe=s(yb);Yue=n(vIe,"STRONG",{});var J5t=s(Yue);hWo=r(J5t,"distilbert"),J5t.forEach(t),pWo=r(vIe," \u2014 "),Tz=n(vIe,"A",{href:!0});var Y5t=s(Tz);_Wo=r(Y5t,"DistilBertForSequenceClassification"),Y5t.forEach(t),uWo=r(vIe," (DistilBERT model)"),vIe.forEach(t),bWo=i(j),xb=n(j,"LI",{});var FIe=s(xb);Kue=n(FIe,"STRONG",{});var K5t=s(Kue);vWo=r(K5t,"electra"),K5t.forEach(t),FWo=r(FIe," \u2014 "),Mz=n(FIe,"A",{href:!0});var Z5t=s(Mz);TWo=r(Z5t,"ElectraForSequenceClassification"),Z5t.forEach(t),MWo=r(FIe," (ELECTRA model)"),FIe.forEach(t),EWo=i(j),$b=n(j,"LI",{});var TIe=s($b);Zue=n(TIe,"STRONG",{});var e0t=s(Zue);CWo=r(e0t,"flaubert"),e0t.forEach(t),wWo=r(TIe," \u2014 "),Ez=n(TIe,"A",{href:!0});var o0t=s(Ez);AWo=r(o0t,"FlaubertForSequenceClassification"),o0t.forEach(t),LWo=r(TIe," (FlauBERT model)"),TIe.forEach(t),yWo=i(j),kb=n(j,"LI",{});var MIe=s(kb);e7e=n(MIe,"STRONG",{});var r0t=s(e7e);xWo=r(r0t,"fnet"),r0t.forEach(t),$Wo=r(MIe," \u2014 "),Cz=n(MIe,"A",{href:!0});var t0t=s(Cz);kWo=r(t0t,"FNetForSequenceClassification"),t0t.forEach(t),SWo=r(MIe," (FNet model)"),MIe.forEach(t),RWo=i(j),Sb=n(j,"LI",{});var EIe=s(Sb);o7e=n(EIe,"STRONG",{});var a0t=s(o7e);PWo=r(a0t,"funnel"),a0t.forEach(t),BWo=r(EIe," \u2014 "),wz=n(EIe,"A",{href:!0});var n0t=s(wz);IWo=r(n0t,"FunnelForSequenceClassification"),n0t.forEach(t),NWo=r(EIe," (Funnel Transformer model)"),EIe.forEach(t),qWo=i(j),Rb=n(j,"LI",{});var CIe=s(Rb);r7e=n(CIe,"STRONG",{});var s0t=s(r7e);jWo=r(s0t,"gpt2"),s0t.forEach(t),DWo=r(CIe," \u2014 "),Az=n(CIe,"A",{href:!0});var l0t=s(Az);GWo=r(l0t,"GPT2ForSequenceClassification"),l0t.forEach(t),OWo=r(CIe," (OpenAI GPT-2 model)"),CIe.forEach(t),VWo=i(j),Pb=n(j,"LI",{});var wIe=s(Pb);t7e=n(wIe,"STRONG",{});var i0t=s(t7e);XWo=r(i0t,"gpt_neo"),i0t.forEach(t),zWo=r(wIe," \u2014 "),Lz=n(wIe,"A",{href:!0});var d0t=s(Lz);WWo=r(d0t,"GPTNeoForSequenceClassification"),d0t.forEach(t),QWo=r(wIe," (GPT Neo model)"),wIe.forEach(t),HWo=i(j),Bb=n(j,"LI",{});var AIe=s(Bb);a7e=n(AIe,"STRONG",{});var c0t=s(a7e);UWo=r(c0t,"gptj"),c0t.forEach(t),JWo=r(AIe," \u2014 "),yz=n(AIe,"A",{href:!0});var f0t=s(yz);YWo=r(f0t,"GPTJForSequenceClassification"),f0t.forEach(t),KWo=r(AIe," (GPT-J model)"),AIe.forEach(t),ZWo=i(j),Ib=n(j,"LI",{});var LIe=s(Ib);n7e=n(LIe,"STRONG",{});var m0t=s(n7e);eQo=r(m0t,"ibert"),m0t.forEach(t),oQo=r(LIe," \u2014 "),xz=n(LIe,"A",{href:!0});var g0t=s(xz);rQo=r(g0t,"IBertForSequenceClassification"),g0t.forEach(t),tQo=r(LIe," (I-BERT model)"),LIe.forEach(t),aQo=i(j),Nb=n(j,"LI",{});var yIe=s(Nb);s7e=n(yIe,"STRONG",{});var h0t=s(s7e);nQo=r(h0t,"layoutlm"),h0t.forEach(t),sQo=r(yIe," \u2014 "),$z=n(yIe,"A",{href:!0});var p0t=s($z);lQo=r(p0t,"LayoutLMForSequenceClassification"),p0t.forEach(t),iQo=r(yIe," (LayoutLM model)"),yIe.forEach(t),dQo=i(j),qb=n(j,"LI",{});var xIe=s(qb);l7e=n(xIe,"STRONG",{});var _0t=s(l7e);cQo=r(_0t,"layoutlmv2"),_0t.forEach(t),fQo=r(xIe," \u2014 "),kz=n(xIe,"A",{href:!0});var u0t=s(kz);mQo=r(u0t,"LayoutLMv2ForSequenceClassification"),u0t.forEach(t),gQo=r(xIe," (LayoutLMv2 model)"),xIe.forEach(t),hQo=i(j),jb=n(j,"LI",{});var $Ie=s(jb);i7e=n($Ie,"STRONG",{});var b0t=s(i7e);pQo=r(b0t,"layoutlmv3"),b0t.forEach(t),_Qo=r($Ie," \u2014 "),Sz=n($Ie,"A",{href:!0});var v0t=s(Sz);uQo=r(v0t,"LayoutLMv3ForSequenceClassification"),v0t.forEach(t),bQo=r($Ie," (LayoutLMv3 model)"),$Ie.forEach(t),vQo=i(j),Db=n(j,"LI",{});var kIe=s(Db);d7e=n(kIe,"STRONG",{});var F0t=s(d7e);FQo=r(F0t,"led"),F0t.forEach(t),TQo=r(kIe," \u2014 "),Rz=n(kIe,"A",{href:!0});var T0t=s(Rz);MQo=r(T0t,"LEDForSequenceClassification"),T0t.forEach(t),EQo=r(kIe," (LED model)"),kIe.forEach(t),CQo=i(j),Gb=n(j,"LI",{});var SIe=s(Gb);c7e=n(SIe,"STRONG",{});var M0t=s(c7e);wQo=r(M0t,"longformer"),M0t.forEach(t),AQo=r(SIe," \u2014 "),Pz=n(SIe,"A",{href:!0});var E0t=s(Pz);LQo=r(E0t,"LongformerForSequenceClassification"),E0t.forEach(t),yQo=r(SIe," (Longformer model)"),SIe.forEach(t),xQo=i(j),Ob=n(j,"LI",{});var RIe=s(Ob);f7e=n(RIe,"STRONG",{});var C0t=s(f7e);$Qo=r(C0t,"luke"),C0t.forEach(t),kQo=r(RIe," \u2014 "),Bz=n(RIe,"A",{href:!0});var w0t=s(Bz);SQo=r(w0t,"LukeForSequenceClassification"),w0t.forEach(t),RQo=r(RIe," (LUKE model)"),RIe.forEach(t),PQo=i(j),Vb=n(j,"LI",{});var PIe=s(Vb);m7e=n(PIe,"STRONG",{});var A0t=s(m7e);BQo=r(A0t,"mbart"),A0t.forEach(t),IQo=r(PIe," \u2014 "),Iz=n(PIe,"A",{href:!0});var L0t=s(Iz);NQo=r(L0t,"MBartForSequenceClassification"),L0t.forEach(t),qQo=r(PIe," (mBART model)"),PIe.forEach(t),jQo=i(j),Xb=n(j,"LI",{});var BIe=s(Xb);g7e=n(BIe,"STRONG",{});var y0t=s(g7e);DQo=r(y0t,"megatron-bert"),y0t.forEach(t),GQo=r(BIe," \u2014 "),Nz=n(BIe,"A",{href:!0});var x0t=s(Nz);OQo=r(x0t,"MegatronBertForSequenceClassification"),x0t.forEach(t),VQo=r(BIe," (Megatron-BERT model)"),BIe.forEach(t),XQo=i(j),zb=n(j,"LI",{});var IIe=s(zb);h7e=n(IIe,"STRONG",{});var $0t=s(h7e);zQo=r($0t,"mobilebert"),$0t.forEach(t),WQo=r(IIe," \u2014 "),qz=n(IIe,"A",{href:!0});var k0t=s(qz);QQo=r(k0t,"MobileBertForSequenceClassification"),k0t.forEach(t),HQo=r(IIe," (MobileBERT model)"),IIe.forEach(t),UQo=i(j),Wb=n(j,"LI",{});var NIe=s(Wb);p7e=n(NIe,"STRONG",{});var S0t=s(p7e);JQo=r(S0t,"mpnet"),S0t.forEach(t),YQo=r(NIe," \u2014 "),jz=n(NIe,"A",{href:!0});var R0t=s(jz);KQo=r(R0t,"MPNetForSequenceClassification"),R0t.forEach(t),ZQo=r(NIe," (MPNet model)"),NIe.forEach(t),eHo=i(j),Qb=n(j,"LI",{});var qIe=s(Qb);_7e=n(qIe,"STRONG",{});var P0t=s(_7e);oHo=r(P0t,"mvp"),P0t.forEach(t),rHo=r(qIe," \u2014 "),Dz=n(qIe,"A",{href:!0});var B0t=s(Dz);tHo=r(B0t,"MvpForSequenceClassification"),B0t.forEach(t),aHo=r(qIe," (MVP model)"),qIe.forEach(t),nHo=i(j),Hb=n(j,"LI",{});var jIe=s(Hb);u7e=n(jIe,"STRONG",{});var I0t=s(u7e);sHo=r(I0t,"nezha"),I0t.forEach(t),lHo=r(jIe," \u2014 "),Gz=n(jIe,"A",{href:!0});var N0t=s(Gz);iHo=r(N0t,"NezhaForSequenceClassification"),N0t.forEach(t),dHo=r(jIe," (Nezha model)"),jIe.forEach(t),cHo=i(j),Ub=n(j,"LI",{});var DIe=s(Ub);b7e=n(DIe,"STRONG",{});var q0t=s(b7e);fHo=r(q0t,"nystromformer"),q0t.forEach(t),mHo=r(DIe," \u2014 "),Oz=n(DIe,"A",{href:!0});var j0t=s(Oz);gHo=r(j0t,"NystromformerForSequenceClassification"),j0t.forEach(t),hHo=r(DIe," (Nystr\xF6mformer model)"),DIe.forEach(t),pHo=i(j),Jb=n(j,"LI",{});var GIe=s(Jb);v7e=n(GIe,"STRONG",{});var D0t=s(v7e);_Ho=r(D0t,"openai-gpt"),D0t.forEach(t),uHo=r(GIe," \u2014 "),Vz=n(GIe,"A",{href:!0});var G0t=s(Vz);bHo=r(G0t,"OpenAIGPTForSequenceClassification"),G0t.forEach(t),vHo=r(GIe," (OpenAI GPT model)"),GIe.forEach(t),FHo=i(j),Yb=n(j,"LI",{});var OIe=s(Yb);F7e=n(OIe,"STRONG",{});var O0t=s(F7e);THo=r(O0t,"opt"),O0t.forEach(t),MHo=r(OIe," \u2014 "),Xz=n(OIe,"A",{href:!0});var V0t=s(Xz);EHo=r(V0t,"OPTForSequenceClassification"),V0t.forEach(t),CHo=r(OIe," (OPT model)"),OIe.forEach(t),wHo=i(j),Kb=n(j,"LI",{});var VIe=s(Kb);T7e=n(VIe,"STRONG",{});var X0t=s(T7e);AHo=r(X0t,"perceiver"),X0t.forEach(t),LHo=r(VIe," \u2014 "),zz=n(VIe,"A",{href:!0});var z0t=s(zz);yHo=r(z0t,"PerceiverForSequenceClassification"),z0t.forEach(t),xHo=r(VIe," (Perceiver model)"),VIe.forEach(t),$Ho=i(j),Zb=n(j,"LI",{});var XIe=s(Zb);M7e=n(XIe,"STRONG",{});var W0t=s(M7e);kHo=r(W0t,"plbart"),W0t.forEach(t),SHo=r(XIe," \u2014 "),Wz=n(XIe,"A",{href:!0});var Q0t=s(Wz);RHo=r(Q0t,"PLBartForSequenceClassification"),Q0t.forEach(t),PHo=r(XIe," (PLBart model)"),XIe.forEach(t),BHo=i(j),ev=n(j,"LI",{});var zIe=s(ev);E7e=n(zIe,"STRONG",{});var H0t=s(E7e);IHo=r(H0t,"qdqbert"),H0t.forEach(t),NHo=r(zIe," \u2014 "),Qz=n(zIe,"A",{href:!0});var U0t=s(Qz);qHo=r(U0t,"QDQBertForSequenceClassification"),U0t.forEach(t),jHo=r(zIe," (QDQBert model)"),zIe.forEach(t),DHo=i(j),ov=n(j,"LI",{});var WIe=s(ov);C7e=n(WIe,"STRONG",{});var J0t=s(C7e);GHo=r(J0t,"reformer"),J0t.forEach(t),OHo=r(WIe," \u2014 "),Hz=n(WIe,"A",{href:!0});var Y0t=s(Hz);VHo=r(Y0t,"ReformerForSequenceClassification"),Y0t.forEach(t),XHo=r(WIe," (Reformer model)"),WIe.forEach(t),zHo=i(j),rv=n(j,"LI",{});var QIe=s(rv);w7e=n(QIe,"STRONG",{});var K0t=s(w7e);WHo=r(K0t,"rembert"),K0t.forEach(t),QHo=r(QIe," \u2014 "),Uz=n(QIe,"A",{href:!0});var Z0t=s(Uz);HHo=r(Z0t,"RemBertForSequenceClassification"),Z0t.forEach(t),UHo=r(QIe," (RemBERT model)"),QIe.forEach(t),JHo=i(j),tv=n(j,"LI",{});var HIe=s(tv);A7e=n(HIe,"STRONG",{});var ewt=s(A7e);YHo=r(ewt,"roberta"),ewt.forEach(t),KHo=r(HIe," \u2014 "),Jz=n(HIe,"A",{href:!0});var owt=s(Jz);ZHo=r(owt,"RobertaForSequenceClassification"),owt.forEach(t),eUo=r(HIe," (RoBERTa model)"),HIe.forEach(t),oUo=i(j),av=n(j,"LI",{});var UIe=s(av);L7e=n(UIe,"STRONG",{});var rwt=s(L7e);rUo=r(rwt,"roformer"),rwt.forEach(t),tUo=r(UIe," \u2014 "),Yz=n(UIe,"A",{href:!0});var twt=s(Yz);aUo=r(twt,"RoFormerForSequenceClassification"),twt.forEach(t),nUo=r(UIe," (RoFormer model)"),UIe.forEach(t),sUo=i(j),nv=n(j,"LI",{});var JIe=s(nv);y7e=n(JIe,"STRONG",{});var awt=s(y7e);lUo=r(awt,"squeezebert"),awt.forEach(t),iUo=r(JIe," \u2014 "),Kz=n(JIe,"A",{href:!0});var nwt=s(Kz);dUo=r(nwt,"SqueezeBertForSequenceClassification"),nwt.forEach(t),cUo=r(JIe," (SqueezeBERT model)"),JIe.forEach(t),fUo=i(j),sv=n(j,"LI",{});var YIe=s(sv);x7e=n(YIe,"STRONG",{});var swt=s(x7e);mUo=r(swt,"tapas"),swt.forEach(t),gUo=r(YIe," \u2014 "),Zz=n(YIe,"A",{href:!0});var lwt=s(Zz);hUo=r(lwt,"TapasForSequenceClassification"),lwt.forEach(t),pUo=r(YIe," (TAPAS model)"),YIe.forEach(t),_Uo=i(j),lv=n(j,"LI",{});var KIe=s(lv);$7e=n(KIe,"STRONG",{});var iwt=s($7e);uUo=r(iwt,"transfo-xl"),iwt.forEach(t),bUo=r(KIe," \u2014 "),eW=n(KIe,"A",{href:!0});var dwt=s(eW);vUo=r(dwt,"TransfoXLForSequenceClassification"),dwt.forEach(t),FUo=r(KIe," (Transformer-XL model)"),KIe.forEach(t),TUo=i(j),iv=n(j,"LI",{});var ZIe=s(iv);k7e=n(ZIe,"STRONG",{});var cwt=s(k7e);MUo=r(cwt,"xlm"),cwt.forEach(t),EUo=r(ZIe," \u2014 "),oW=n(ZIe,"A",{href:!0});var fwt=s(oW);CUo=r(fwt,"XLMForSequenceClassification"),fwt.forEach(t),wUo=r(ZIe," (XLM model)"),ZIe.forEach(t),AUo=i(j),dv=n(j,"LI",{});var eNe=s(dv);S7e=n(eNe,"STRONG",{});var mwt=s(S7e);LUo=r(mwt,"xlm-roberta"),mwt.forEach(t),yUo=r(eNe," \u2014 "),rW=n(eNe,"A",{href:!0});var gwt=s(rW);xUo=r(gwt,"XLMRobertaForSequenceClassification"),gwt.forEach(t),$Uo=r(eNe," (XLM-RoBERTa model)"),eNe.forEach(t),kUo=i(j),cv=n(j,"LI",{});var oNe=s(cv);R7e=n(oNe,"STRONG",{});var hwt=s(R7e);SUo=r(hwt,"xlm-roberta-xl"),hwt.forEach(t),RUo=r(oNe," \u2014 "),tW=n(oNe,"A",{href:!0});var pwt=s(tW);PUo=r(pwt,"XLMRobertaXLForSequenceClassification"),pwt.forEach(t),BUo=r(oNe," (XLM-RoBERTa-XL model)"),oNe.forEach(t),IUo=i(j),fv=n(j,"LI",{});var rNe=s(fv);P7e=n(rNe,"STRONG",{});var _wt=s(P7e);NUo=r(_wt,"xlnet"),_wt.forEach(t),qUo=r(rNe," \u2014 "),aW=n(rNe,"A",{href:!0});var uwt=s(aW);jUo=r(uwt,"XLNetForSequenceClassification"),uwt.forEach(t),DUo=r(rNe," (XLNet model)"),rNe.forEach(t),GUo=i(j),mv=n(j,"LI",{});var tNe=s(mv);B7e=n(tNe,"STRONG",{});var bwt=s(B7e);OUo=r(bwt,"yoso"),bwt.forEach(t),VUo=r(tNe," \u2014 "),nW=n(tNe,"A",{href:!0});var vwt=s(nW);XUo=r(vwt,"YosoForSequenceClassification"),vwt.forEach(t),zUo=r(tNe," (YOSO model)"),tNe.forEach(t),j.forEach(t),WUo=i(pa),gv=n(pa,"P",{});var aNe=s(gv);QUo=r(aNe,"The model is set in evaluation mode by default using "),I7e=n(aNe,"CODE",{});var Fwt=s(I7e);HUo=r(Fwt,"model.eval()"),Fwt.forEach(t),UUo=r(aNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),N7e=n(aNe,"CODE",{});var Twt=s(N7e);JUo=r(Twt,"model.train()"),Twt.forEach(t),aNe.forEach(t),YUo=i(pa),T(hv.$$.fragment,pa),pa.forEach(t),pl.forEach(t),cQe=i(f),hd=n(f,"H2",{class:!0});var bUe=s(hd);pv=n(bUe,"A",{id:!0,class:!0,href:!0});var Mwt=s(pv);q7e=n(Mwt,"SPAN",{});var Ewt=s(q7e);T(Uy.$$.fragment,Ewt),Ewt.forEach(t),Mwt.forEach(t),KUo=i(bUe),j7e=n(bUe,"SPAN",{});var Cwt=s(j7e);ZUo=r(Cwt,"AutoModelForMultipleChoice"),Cwt.forEach(t),bUe.forEach(t),fQe=i(f),qo=n(f,"DIV",{class:!0});var _l=s(qo);T(Jy.$$.fragment,_l),eJo=i(_l),pd=n(_l,"P",{});var bae=s(pd);oJo=r(bae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),sW=n(bae,"A",{href:!0});var wwt=s(sW);rJo=r(wwt,"from_pretrained()"),wwt.forEach(t),tJo=r(bae," class method or the "),lW=n(bae,"A",{href:!0});var Awt=s(lW);aJo=r(Awt,"from_config()"),Awt.forEach(t),nJo=r(bae,` class
method.`),bae.forEach(t),sJo=i(_l),Yy=n(_l,"P",{});var vUe=s(Yy);lJo=r(vUe,"This class cannot be instantiated directly using "),D7e=n(vUe,"CODE",{});var Lwt=s(D7e);iJo=r(Lwt,"__init__()"),Lwt.forEach(t),dJo=r(vUe," (throws an error)."),vUe.forEach(t),cJo=i(_l),_t=n(_l,"DIV",{class:!0});var sA=s(_t);T(Ky.$$.fragment,sA),fJo=i(sA),G7e=n(sA,"P",{});var ywt=s(G7e);mJo=r(ywt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ywt.forEach(t),gJo=i(sA),_d=n(sA,"P",{});var vae=s(_d);hJo=r(vae,`Note:
Loading a model from its configuration file does `),O7e=n(vae,"STRONG",{});var xwt=s(O7e);pJo=r(xwt,"not"),xwt.forEach(t),_Jo=r(vae,` load the model weights. It only affects the
model\u2019s configuration. Use `),iW=n(vae,"A",{href:!0});var $wt=s(iW);uJo=r($wt,"from_pretrained()"),$wt.forEach(t),bJo=r(vae," to load the model weights."),vae.forEach(t),vJo=i(sA),T(_v.$$.fragment,sA),sA.forEach(t),FJo=i(_l),to=n(_l,"DIV",{class:!0});var _a=s(to);T(Zy.$$.fragment,_a),TJo=i(_a),V7e=n(_a,"P",{});var kwt=s(V7e);MJo=r(kwt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),kwt.forEach(t),EJo=i(_a),Wa=n(_a,"P",{});var lA=s(Wa);CJo=r(lA,"The model class to instantiate is selected based on the "),X7e=n(lA,"CODE",{});var Swt=s(X7e);wJo=r(Swt,"model_type"),Swt.forEach(t),AJo=r(lA,` property of the config object (either
passed as an argument or loaded from `),z7e=n(lA,"CODE",{});var Rwt=s(z7e);LJo=r(Rwt,"pretrained_model_name_or_path"),Rwt.forEach(t),yJo=r(lA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W7e=n(lA,"CODE",{});var Pwt=s(W7e);xJo=r(Pwt,"pretrained_model_name_or_path"),Pwt.forEach(t),$Jo=r(lA,":"),lA.forEach(t),kJo=i(_a),Z=n(_a,"UL",{});var ee=s(Z);uv=n(ee,"LI",{});var nNe=s(uv);Q7e=n(nNe,"STRONG",{});var Bwt=s(Q7e);SJo=r(Bwt,"albert"),Bwt.forEach(t),RJo=r(nNe," \u2014 "),dW=n(nNe,"A",{href:!0});var Iwt=s(dW);PJo=r(Iwt,"AlbertForMultipleChoice"),Iwt.forEach(t),BJo=r(nNe," (ALBERT model)"),nNe.forEach(t),IJo=i(ee),bv=n(ee,"LI",{});var sNe=s(bv);H7e=n(sNe,"STRONG",{});var Nwt=s(H7e);NJo=r(Nwt,"bert"),Nwt.forEach(t),qJo=r(sNe," \u2014 "),cW=n(sNe,"A",{href:!0});var qwt=s(cW);jJo=r(qwt,"BertForMultipleChoice"),qwt.forEach(t),DJo=r(sNe," (BERT model)"),sNe.forEach(t),GJo=i(ee),vv=n(ee,"LI",{});var lNe=s(vv);U7e=n(lNe,"STRONG",{});var jwt=s(U7e);OJo=r(jwt,"big_bird"),jwt.forEach(t),VJo=r(lNe," \u2014 "),fW=n(lNe,"A",{href:!0});var Dwt=s(fW);XJo=r(Dwt,"BigBirdForMultipleChoice"),Dwt.forEach(t),zJo=r(lNe," (BigBird model)"),lNe.forEach(t),WJo=i(ee),Fv=n(ee,"LI",{});var iNe=s(Fv);J7e=n(iNe,"STRONG",{});var Gwt=s(J7e);QJo=r(Gwt,"camembert"),Gwt.forEach(t),HJo=r(iNe," \u2014 "),mW=n(iNe,"A",{href:!0});var Owt=s(mW);UJo=r(Owt,"CamembertForMultipleChoice"),Owt.forEach(t),JJo=r(iNe," (CamemBERT model)"),iNe.forEach(t),YJo=i(ee),Tv=n(ee,"LI",{});var dNe=s(Tv);Y7e=n(dNe,"STRONG",{});var Vwt=s(Y7e);KJo=r(Vwt,"canine"),Vwt.forEach(t),ZJo=r(dNe," \u2014 "),gW=n(dNe,"A",{href:!0});var Xwt=s(gW);eYo=r(Xwt,"CanineForMultipleChoice"),Xwt.forEach(t),oYo=r(dNe," (CANINE model)"),dNe.forEach(t),rYo=i(ee),Mv=n(ee,"LI",{});var cNe=s(Mv);K7e=n(cNe,"STRONG",{});var zwt=s(K7e);tYo=r(zwt,"convbert"),zwt.forEach(t),aYo=r(cNe," \u2014 "),hW=n(cNe,"A",{href:!0});var Wwt=s(hW);nYo=r(Wwt,"ConvBertForMultipleChoice"),Wwt.forEach(t),sYo=r(cNe," (ConvBERT model)"),cNe.forEach(t),lYo=i(ee),Ev=n(ee,"LI",{});var fNe=s(Ev);Z7e=n(fNe,"STRONG",{});var Qwt=s(Z7e);iYo=r(Qwt,"data2vec-text"),Qwt.forEach(t),dYo=r(fNe," \u2014 "),pW=n(fNe,"A",{href:!0});var Hwt=s(pW);cYo=r(Hwt,"Data2VecTextForMultipleChoice"),Hwt.forEach(t),fYo=r(fNe," (Data2VecText model)"),fNe.forEach(t),mYo=i(ee),Cv=n(ee,"LI",{});var mNe=s(Cv);e1e=n(mNe,"STRONG",{});var Uwt=s(e1e);gYo=r(Uwt,"deberta-v2"),Uwt.forEach(t),hYo=r(mNe," \u2014 "),_W=n(mNe,"A",{href:!0});var Jwt=s(_W);pYo=r(Jwt,"DebertaV2ForMultipleChoice"),Jwt.forEach(t),_Yo=r(mNe," (DeBERTa-v2 model)"),mNe.forEach(t),uYo=i(ee),wv=n(ee,"LI",{});var gNe=s(wv);o1e=n(gNe,"STRONG",{});var Ywt=s(o1e);bYo=r(Ywt,"distilbert"),Ywt.forEach(t),vYo=r(gNe," \u2014 "),uW=n(gNe,"A",{href:!0});var Kwt=s(uW);FYo=r(Kwt,"DistilBertForMultipleChoice"),Kwt.forEach(t),TYo=r(gNe," (DistilBERT model)"),gNe.forEach(t),MYo=i(ee),Av=n(ee,"LI",{});var hNe=s(Av);r1e=n(hNe,"STRONG",{});var Zwt=s(r1e);EYo=r(Zwt,"electra"),Zwt.forEach(t),CYo=r(hNe," \u2014 "),bW=n(hNe,"A",{href:!0});var e6t=s(bW);wYo=r(e6t,"ElectraForMultipleChoice"),e6t.forEach(t),AYo=r(hNe," (ELECTRA model)"),hNe.forEach(t),LYo=i(ee),Lv=n(ee,"LI",{});var pNe=s(Lv);t1e=n(pNe,"STRONG",{});var o6t=s(t1e);yYo=r(o6t,"flaubert"),o6t.forEach(t),xYo=r(pNe," \u2014 "),vW=n(pNe,"A",{href:!0});var r6t=s(vW);$Yo=r(r6t,"FlaubertForMultipleChoice"),r6t.forEach(t),kYo=r(pNe," (FlauBERT model)"),pNe.forEach(t),SYo=i(ee),yv=n(ee,"LI",{});var _Ne=s(yv);a1e=n(_Ne,"STRONG",{});var t6t=s(a1e);RYo=r(t6t,"fnet"),t6t.forEach(t),PYo=r(_Ne," \u2014 "),FW=n(_Ne,"A",{href:!0});var a6t=s(FW);BYo=r(a6t,"FNetForMultipleChoice"),a6t.forEach(t),IYo=r(_Ne," (FNet model)"),_Ne.forEach(t),NYo=i(ee),xv=n(ee,"LI",{});var uNe=s(xv);n1e=n(uNe,"STRONG",{});var n6t=s(n1e);qYo=r(n6t,"funnel"),n6t.forEach(t),jYo=r(uNe," \u2014 "),TW=n(uNe,"A",{href:!0});var s6t=s(TW);DYo=r(s6t,"FunnelForMultipleChoice"),s6t.forEach(t),GYo=r(uNe," (Funnel Transformer model)"),uNe.forEach(t),OYo=i(ee),$v=n(ee,"LI",{});var bNe=s($v);s1e=n(bNe,"STRONG",{});var l6t=s(s1e);VYo=r(l6t,"ibert"),l6t.forEach(t),XYo=r(bNe," \u2014 "),MW=n(bNe,"A",{href:!0});var i6t=s(MW);zYo=r(i6t,"IBertForMultipleChoice"),i6t.forEach(t),WYo=r(bNe," (I-BERT model)"),bNe.forEach(t),QYo=i(ee),kv=n(ee,"LI",{});var vNe=s(kv);l1e=n(vNe,"STRONG",{});var d6t=s(l1e);HYo=r(d6t,"longformer"),d6t.forEach(t),UYo=r(vNe," \u2014 "),EW=n(vNe,"A",{href:!0});var c6t=s(EW);JYo=r(c6t,"LongformerForMultipleChoice"),c6t.forEach(t),YYo=r(vNe," (Longformer model)"),vNe.forEach(t),KYo=i(ee),Sv=n(ee,"LI",{});var FNe=s(Sv);i1e=n(FNe,"STRONG",{});var f6t=s(i1e);ZYo=r(f6t,"luke"),f6t.forEach(t),eKo=r(FNe," \u2014 "),CW=n(FNe,"A",{href:!0});var m6t=s(CW);oKo=r(m6t,"LukeForMultipleChoice"),m6t.forEach(t),rKo=r(FNe," (LUKE model)"),FNe.forEach(t),tKo=i(ee),Rv=n(ee,"LI",{});var TNe=s(Rv);d1e=n(TNe,"STRONG",{});var g6t=s(d1e);aKo=r(g6t,"megatron-bert"),g6t.forEach(t),nKo=r(TNe," \u2014 "),wW=n(TNe,"A",{href:!0});var h6t=s(wW);sKo=r(h6t,"MegatronBertForMultipleChoice"),h6t.forEach(t),lKo=r(TNe," (Megatron-BERT model)"),TNe.forEach(t),iKo=i(ee),Pv=n(ee,"LI",{});var MNe=s(Pv);c1e=n(MNe,"STRONG",{});var p6t=s(c1e);dKo=r(p6t,"mobilebert"),p6t.forEach(t),cKo=r(MNe," \u2014 "),AW=n(MNe,"A",{href:!0});var _6t=s(AW);fKo=r(_6t,"MobileBertForMultipleChoice"),_6t.forEach(t),mKo=r(MNe," (MobileBERT model)"),MNe.forEach(t),gKo=i(ee),Bv=n(ee,"LI",{});var ENe=s(Bv);f1e=n(ENe,"STRONG",{});var u6t=s(f1e);hKo=r(u6t,"mpnet"),u6t.forEach(t),pKo=r(ENe," \u2014 "),LW=n(ENe,"A",{href:!0});var b6t=s(LW);_Ko=r(b6t,"MPNetForMultipleChoice"),b6t.forEach(t),uKo=r(ENe," (MPNet model)"),ENe.forEach(t),bKo=i(ee),Iv=n(ee,"LI",{});var CNe=s(Iv);m1e=n(CNe,"STRONG",{});var v6t=s(m1e);vKo=r(v6t,"nezha"),v6t.forEach(t),FKo=r(CNe," \u2014 "),yW=n(CNe,"A",{href:!0});var F6t=s(yW);TKo=r(F6t,"NezhaForMultipleChoice"),F6t.forEach(t),MKo=r(CNe," (Nezha model)"),CNe.forEach(t),EKo=i(ee),Nv=n(ee,"LI",{});var wNe=s(Nv);g1e=n(wNe,"STRONG",{});var T6t=s(g1e);CKo=r(T6t,"nystromformer"),T6t.forEach(t),wKo=r(wNe," \u2014 "),xW=n(wNe,"A",{href:!0});var M6t=s(xW);AKo=r(M6t,"NystromformerForMultipleChoice"),M6t.forEach(t),LKo=r(wNe," (Nystr\xF6mformer model)"),wNe.forEach(t),yKo=i(ee),qv=n(ee,"LI",{});var ANe=s(qv);h1e=n(ANe,"STRONG",{});var E6t=s(h1e);xKo=r(E6t,"qdqbert"),E6t.forEach(t),$Ko=r(ANe," \u2014 "),$W=n(ANe,"A",{href:!0});var C6t=s($W);kKo=r(C6t,"QDQBertForMultipleChoice"),C6t.forEach(t),SKo=r(ANe," (QDQBert model)"),ANe.forEach(t),RKo=i(ee),jv=n(ee,"LI",{});var LNe=s(jv);p1e=n(LNe,"STRONG",{});var w6t=s(p1e);PKo=r(w6t,"rembert"),w6t.forEach(t),BKo=r(LNe," \u2014 "),kW=n(LNe,"A",{href:!0});var A6t=s(kW);IKo=r(A6t,"RemBertForMultipleChoice"),A6t.forEach(t),NKo=r(LNe," (RemBERT model)"),LNe.forEach(t),qKo=i(ee),Dv=n(ee,"LI",{});var yNe=s(Dv);_1e=n(yNe,"STRONG",{});var L6t=s(_1e);jKo=r(L6t,"roberta"),L6t.forEach(t),DKo=r(yNe," \u2014 "),SW=n(yNe,"A",{href:!0});var y6t=s(SW);GKo=r(y6t,"RobertaForMultipleChoice"),y6t.forEach(t),OKo=r(yNe," (RoBERTa model)"),yNe.forEach(t),VKo=i(ee),Gv=n(ee,"LI",{});var xNe=s(Gv);u1e=n(xNe,"STRONG",{});var x6t=s(u1e);XKo=r(x6t,"roformer"),x6t.forEach(t),zKo=r(xNe," \u2014 "),RW=n(xNe,"A",{href:!0});var $6t=s(RW);WKo=r($6t,"RoFormerForMultipleChoice"),$6t.forEach(t),QKo=r(xNe," (RoFormer model)"),xNe.forEach(t),HKo=i(ee),Ov=n(ee,"LI",{});var $Ne=s(Ov);b1e=n($Ne,"STRONG",{});var k6t=s(b1e);UKo=r(k6t,"squeezebert"),k6t.forEach(t),JKo=r($Ne," \u2014 "),PW=n($Ne,"A",{href:!0});var S6t=s(PW);YKo=r(S6t,"SqueezeBertForMultipleChoice"),S6t.forEach(t),KKo=r($Ne," (SqueezeBERT model)"),$Ne.forEach(t),ZKo=i(ee),Vv=n(ee,"LI",{});var kNe=s(Vv);v1e=n(kNe,"STRONG",{});var R6t=s(v1e);eZo=r(R6t,"xlm"),R6t.forEach(t),oZo=r(kNe," \u2014 "),BW=n(kNe,"A",{href:!0});var P6t=s(BW);rZo=r(P6t,"XLMForMultipleChoice"),P6t.forEach(t),tZo=r(kNe," (XLM model)"),kNe.forEach(t),aZo=i(ee),Xv=n(ee,"LI",{});var SNe=s(Xv);F1e=n(SNe,"STRONG",{});var B6t=s(F1e);nZo=r(B6t,"xlm-roberta"),B6t.forEach(t),sZo=r(SNe," \u2014 "),IW=n(SNe,"A",{href:!0});var I6t=s(IW);lZo=r(I6t,"XLMRobertaForMultipleChoice"),I6t.forEach(t),iZo=r(SNe," (XLM-RoBERTa model)"),SNe.forEach(t),dZo=i(ee),zv=n(ee,"LI",{});var RNe=s(zv);T1e=n(RNe,"STRONG",{});var N6t=s(T1e);cZo=r(N6t,"xlm-roberta-xl"),N6t.forEach(t),fZo=r(RNe," \u2014 "),NW=n(RNe,"A",{href:!0});var q6t=s(NW);mZo=r(q6t,"XLMRobertaXLForMultipleChoice"),q6t.forEach(t),gZo=r(RNe," (XLM-RoBERTa-XL model)"),RNe.forEach(t),hZo=i(ee),Wv=n(ee,"LI",{});var PNe=s(Wv);M1e=n(PNe,"STRONG",{});var j6t=s(M1e);pZo=r(j6t,"xlnet"),j6t.forEach(t),_Zo=r(PNe," \u2014 "),qW=n(PNe,"A",{href:!0});var D6t=s(qW);uZo=r(D6t,"XLNetForMultipleChoice"),D6t.forEach(t),bZo=r(PNe," (XLNet model)"),PNe.forEach(t),vZo=i(ee),Qv=n(ee,"LI",{});var BNe=s(Qv);E1e=n(BNe,"STRONG",{});var G6t=s(E1e);FZo=r(G6t,"yoso"),G6t.forEach(t),TZo=r(BNe," \u2014 "),jW=n(BNe,"A",{href:!0});var O6t=s(jW);MZo=r(O6t,"YosoForMultipleChoice"),O6t.forEach(t),EZo=r(BNe," (YOSO model)"),BNe.forEach(t),ee.forEach(t),CZo=i(_a),Hv=n(_a,"P",{});var INe=s(Hv);wZo=r(INe,"The model is set in evaluation mode by default using "),C1e=n(INe,"CODE",{});var V6t=s(C1e);AZo=r(V6t,"model.eval()"),V6t.forEach(t),LZo=r(INe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w1e=n(INe,"CODE",{});var X6t=s(w1e);yZo=r(X6t,"model.train()"),X6t.forEach(t),INe.forEach(t),xZo=i(_a),T(Uv.$$.fragment,_a),_a.forEach(t),_l.forEach(t),mQe=i(f),ud=n(f,"H2",{class:!0});var FUe=s(ud);Jv=n(FUe,"A",{id:!0,class:!0,href:!0});var z6t=s(Jv);A1e=n(z6t,"SPAN",{});var W6t=s(A1e);T(e8.$$.fragment,W6t),W6t.forEach(t),z6t.forEach(t),$Zo=i(FUe),L1e=n(FUe,"SPAN",{});var Q6t=s(L1e);kZo=r(Q6t,"AutoModelForNextSentencePrediction"),Q6t.forEach(t),FUe.forEach(t),gQe=i(f),jo=n(f,"DIV",{class:!0});var ul=s(jo);T(o8.$$.fragment,ul),SZo=i(ul),bd=n(ul,"P",{});var Fae=s(bd);RZo=r(Fae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),DW=n(Fae,"A",{href:!0});var H6t=s(DW);PZo=r(H6t,"from_pretrained()"),H6t.forEach(t),BZo=r(Fae," class method or the "),GW=n(Fae,"A",{href:!0});var U6t=s(GW);IZo=r(U6t,"from_config()"),U6t.forEach(t),NZo=r(Fae,` class
method.`),Fae.forEach(t),qZo=i(ul),r8=n(ul,"P",{});var TUe=s(r8);jZo=r(TUe,"This class cannot be instantiated directly using "),y1e=n(TUe,"CODE",{});var J6t=s(y1e);DZo=r(J6t,"__init__()"),J6t.forEach(t),GZo=r(TUe," (throws an error)."),TUe.forEach(t),OZo=i(ul),ut=n(ul,"DIV",{class:!0});var iA=s(ut);T(t8.$$.fragment,iA),VZo=i(iA),x1e=n(iA,"P",{});var Y6t=s(x1e);XZo=r(Y6t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Y6t.forEach(t),zZo=i(iA),vd=n(iA,"P",{});var Tae=s(vd);WZo=r(Tae,`Note:
Loading a model from its configuration file does `),$1e=n(Tae,"STRONG",{});var K6t=s($1e);QZo=r(K6t,"not"),K6t.forEach(t),HZo=r(Tae,` load the model weights. It only affects the
model\u2019s configuration. Use `),OW=n(Tae,"A",{href:!0});var Z6t=s(OW);UZo=r(Z6t,"from_pretrained()"),Z6t.forEach(t),JZo=r(Tae," to load the model weights."),Tae.forEach(t),YZo=i(iA),T(Yv.$$.fragment,iA),iA.forEach(t),KZo=i(ul),ao=n(ul,"DIV",{class:!0});var ua=s(ao);T(a8.$$.fragment,ua),ZZo=i(ua),k1e=n(ua,"P",{});var eAt=s(k1e);eer=r(eAt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),eAt.forEach(t),oer=i(ua),Qa=n(ua,"P",{});var dA=s(Qa);rer=r(dA,"The model class to instantiate is selected based on the "),S1e=n(dA,"CODE",{});var oAt=s(S1e);ter=r(oAt,"model_type"),oAt.forEach(t),aer=r(dA,` property of the config object (either
passed as an argument or loaded from `),R1e=n(dA,"CODE",{});var rAt=s(R1e);ner=r(rAt,"pretrained_model_name_or_path"),rAt.forEach(t),ser=r(dA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P1e=n(dA,"CODE",{});var tAt=s(P1e);ler=r(tAt,"pretrained_model_name_or_path"),tAt.forEach(t),ier=r(dA,":"),dA.forEach(t),der=i(ua),Do=n(ua,"UL",{});var ba=s(Do);Kv=n(ba,"LI",{});var NNe=s(Kv);B1e=n(NNe,"STRONG",{});var aAt=s(B1e);cer=r(aAt,"bert"),aAt.forEach(t),fer=r(NNe," \u2014 "),VW=n(NNe,"A",{href:!0});var nAt=s(VW);mer=r(nAt,"BertForNextSentencePrediction"),nAt.forEach(t),ger=r(NNe," (BERT model)"),NNe.forEach(t),her=i(ba),Zv=n(ba,"LI",{});var qNe=s(Zv);I1e=n(qNe,"STRONG",{});var sAt=s(I1e);per=r(sAt,"fnet"),sAt.forEach(t),_er=r(qNe," \u2014 "),XW=n(qNe,"A",{href:!0});var lAt=s(XW);uer=r(lAt,"FNetForNextSentencePrediction"),lAt.forEach(t),ber=r(qNe," (FNet model)"),qNe.forEach(t),ver=i(ba),eF=n(ba,"LI",{});var jNe=s(eF);N1e=n(jNe,"STRONG",{});var iAt=s(N1e);Fer=r(iAt,"megatron-bert"),iAt.forEach(t),Ter=r(jNe," \u2014 "),zW=n(jNe,"A",{href:!0});var dAt=s(zW);Mer=r(dAt,"MegatronBertForNextSentencePrediction"),dAt.forEach(t),Eer=r(jNe," (Megatron-BERT model)"),jNe.forEach(t),Cer=i(ba),oF=n(ba,"LI",{});var DNe=s(oF);q1e=n(DNe,"STRONG",{});var cAt=s(q1e);wer=r(cAt,"mobilebert"),cAt.forEach(t),Aer=r(DNe," \u2014 "),WW=n(DNe,"A",{href:!0});var fAt=s(WW);Ler=r(fAt,"MobileBertForNextSentencePrediction"),fAt.forEach(t),yer=r(DNe," (MobileBERT model)"),DNe.forEach(t),xer=i(ba),rF=n(ba,"LI",{});var GNe=s(rF);j1e=n(GNe,"STRONG",{});var mAt=s(j1e);$er=r(mAt,"nezha"),mAt.forEach(t),ker=r(GNe," \u2014 "),QW=n(GNe,"A",{href:!0});var gAt=s(QW);Ser=r(gAt,"NezhaForNextSentencePrediction"),gAt.forEach(t),Rer=r(GNe," (Nezha model)"),GNe.forEach(t),Per=i(ba),tF=n(ba,"LI",{});var ONe=s(tF);D1e=n(ONe,"STRONG",{});var hAt=s(D1e);Ber=r(hAt,"qdqbert"),hAt.forEach(t),Ier=r(ONe," \u2014 "),HW=n(ONe,"A",{href:!0});var pAt=s(HW);Ner=r(pAt,"QDQBertForNextSentencePrediction"),pAt.forEach(t),qer=r(ONe," (QDQBert model)"),ONe.forEach(t),ba.forEach(t),jer=i(ua),aF=n(ua,"P",{});var VNe=s(aF);Der=r(VNe,"The model is set in evaluation mode by default using "),G1e=n(VNe,"CODE",{});var _At=s(G1e);Ger=r(_At,"model.eval()"),_At.forEach(t),Oer=r(VNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),O1e=n(VNe,"CODE",{});var uAt=s(O1e);Ver=r(uAt,"model.train()"),uAt.forEach(t),VNe.forEach(t),Xer=i(ua),T(nF.$$.fragment,ua),ua.forEach(t),ul.forEach(t),hQe=i(f),Fd=n(f,"H2",{class:!0});var MUe=s(Fd);sF=n(MUe,"A",{id:!0,class:!0,href:!0});var bAt=s(sF);V1e=n(bAt,"SPAN",{});var vAt=s(V1e);T(n8.$$.fragment,vAt),vAt.forEach(t),bAt.forEach(t),zer=i(MUe),X1e=n(MUe,"SPAN",{});var FAt=s(X1e);Wer=r(FAt,"AutoModelForTokenClassification"),FAt.forEach(t),MUe.forEach(t),pQe=i(f),Go=n(f,"DIV",{class:!0});var bl=s(Go);T(s8.$$.fragment,bl),Qer=i(bl),Td=n(bl,"P",{});var Mae=s(Td);Her=r(Mae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),UW=n(Mae,"A",{href:!0});var TAt=s(UW);Uer=r(TAt,"from_pretrained()"),TAt.forEach(t),Jer=r(Mae," class method or the "),JW=n(Mae,"A",{href:!0});var MAt=s(JW);Yer=r(MAt,"from_config()"),MAt.forEach(t),Ker=r(Mae,` class
method.`),Mae.forEach(t),Zer=i(bl),l8=n(bl,"P",{});var EUe=s(l8);eor=r(EUe,"This class cannot be instantiated directly using "),z1e=n(EUe,"CODE",{});var EAt=s(z1e);oor=r(EAt,"__init__()"),EAt.forEach(t),ror=r(EUe," (throws an error)."),EUe.forEach(t),tor=i(bl),bt=n(bl,"DIV",{class:!0});var cA=s(bt);T(i8.$$.fragment,cA),aor=i(cA),W1e=n(cA,"P",{});var CAt=s(W1e);nor=r(CAt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),CAt.forEach(t),sor=i(cA),Md=n(cA,"P",{});var Eae=s(Md);lor=r(Eae,`Note:
Loading a model from its configuration file does `),Q1e=n(Eae,"STRONG",{});var wAt=s(Q1e);ior=r(wAt,"not"),wAt.forEach(t),dor=r(Eae,` load the model weights. It only affects the
model\u2019s configuration. Use `),YW=n(Eae,"A",{href:!0});var AAt=s(YW);cor=r(AAt,"from_pretrained()"),AAt.forEach(t),mor=r(Eae," to load the model weights."),Eae.forEach(t),gor=i(cA),T(lF.$$.fragment,cA),cA.forEach(t),hor=i(bl),no=n(bl,"DIV",{class:!0});var va=s(no);T(d8.$$.fragment,va),por=i(va),H1e=n(va,"P",{});var LAt=s(H1e);_or=r(LAt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),LAt.forEach(t),uor=i(va),Ha=n(va,"P",{});var fA=s(Ha);bor=r(fA,"The model class to instantiate is selected based on the "),U1e=n(fA,"CODE",{});var yAt=s(U1e);vor=r(yAt,"model_type"),yAt.forEach(t),For=r(fA,` property of the config object (either
passed as an argument or loaded from `),J1e=n(fA,"CODE",{});var xAt=s(J1e);Tor=r(xAt,"pretrained_model_name_or_path"),xAt.forEach(t),Mor=r(fA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Y1e=n(fA,"CODE",{});var $At=s(Y1e);Eor=r($At,"pretrained_model_name_or_path"),$At.forEach(t),Cor=r(fA,":"),fA.forEach(t),wor=i(va),U=n(va,"UL",{});var K=s(U);iF=n(K,"LI",{});var XNe=s(iF);K1e=n(XNe,"STRONG",{});var kAt=s(K1e);Aor=r(kAt,"albert"),kAt.forEach(t),Lor=r(XNe," \u2014 "),KW=n(XNe,"A",{href:!0});var SAt=s(KW);yor=r(SAt,"AlbertForTokenClassification"),SAt.forEach(t),xor=r(XNe," (ALBERT model)"),XNe.forEach(t),$or=i(K),dF=n(K,"LI",{});var zNe=s(dF);Z1e=n(zNe,"STRONG",{});var RAt=s(Z1e);kor=r(RAt,"bert"),RAt.forEach(t),Sor=r(zNe," \u2014 "),ZW=n(zNe,"A",{href:!0});var PAt=s(ZW);Ror=r(PAt,"BertForTokenClassification"),PAt.forEach(t),Por=r(zNe," (BERT model)"),zNe.forEach(t),Bor=i(K),cF=n(K,"LI",{});var WNe=s(cF);e2e=n(WNe,"STRONG",{});var BAt=s(e2e);Ior=r(BAt,"big_bird"),BAt.forEach(t),Nor=r(WNe," \u2014 "),eQ=n(WNe,"A",{href:!0});var IAt=s(eQ);qor=r(IAt,"BigBirdForTokenClassification"),IAt.forEach(t),jor=r(WNe," (BigBird model)"),WNe.forEach(t),Dor=i(K),fF=n(K,"LI",{});var QNe=s(fF);o2e=n(QNe,"STRONG",{});var NAt=s(o2e);Gor=r(NAt,"bloom"),NAt.forEach(t),Oor=r(QNe," \u2014 "),oQ=n(QNe,"A",{href:!0});var qAt=s(oQ);Vor=r(qAt,"BloomForTokenClassification"),qAt.forEach(t),Xor=r(QNe," (BLOOM model)"),QNe.forEach(t),zor=i(K),mF=n(K,"LI",{});var HNe=s(mF);r2e=n(HNe,"STRONG",{});var jAt=s(r2e);Wor=r(jAt,"camembert"),jAt.forEach(t),Qor=r(HNe," \u2014 "),rQ=n(HNe,"A",{href:!0});var DAt=s(rQ);Hor=r(DAt,"CamembertForTokenClassification"),DAt.forEach(t),Uor=r(HNe," (CamemBERT model)"),HNe.forEach(t),Jor=i(K),gF=n(K,"LI",{});var UNe=s(gF);t2e=n(UNe,"STRONG",{});var GAt=s(t2e);Yor=r(GAt,"canine"),GAt.forEach(t),Kor=r(UNe," \u2014 "),tQ=n(UNe,"A",{href:!0});var OAt=s(tQ);Zor=r(OAt,"CanineForTokenClassification"),OAt.forEach(t),err=r(UNe," (CANINE model)"),UNe.forEach(t),orr=i(K),hF=n(K,"LI",{});var JNe=s(hF);a2e=n(JNe,"STRONG",{});var VAt=s(a2e);rrr=r(VAt,"convbert"),VAt.forEach(t),trr=r(JNe," \u2014 "),aQ=n(JNe,"A",{href:!0});var XAt=s(aQ);arr=r(XAt,"ConvBertForTokenClassification"),XAt.forEach(t),nrr=r(JNe," (ConvBERT model)"),JNe.forEach(t),srr=i(K),pF=n(K,"LI",{});var YNe=s(pF);n2e=n(YNe,"STRONG",{});var zAt=s(n2e);lrr=r(zAt,"data2vec-text"),zAt.forEach(t),irr=r(YNe," \u2014 "),nQ=n(YNe,"A",{href:!0});var WAt=s(nQ);drr=r(WAt,"Data2VecTextForTokenClassification"),WAt.forEach(t),crr=r(YNe," (Data2VecText model)"),YNe.forEach(t),frr=i(K),_F=n(K,"LI",{});var KNe=s(_F);s2e=n(KNe,"STRONG",{});var QAt=s(s2e);mrr=r(QAt,"deberta"),QAt.forEach(t),grr=r(KNe," \u2014 "),sQ=n(KNe,"A",{href:!0});var HAt=s(sQ);hrr=r(HAt,"DebertaForTokenClassification"),HAt.forEach(t),prr=r(KNe," (DeBERTa model)"),KNe.forEach(t),_rr=i(K),uF=n(K,"LI",{});var ZNe=s(uF);l2e=n(ZNe,"STRONG",{});var UAt=s(l2e);urr=r(UAt,"deberta-v2"),UAt.forEach(t),brr=r(ZNe," \u2014 "),lQ=n(ZNe,"A",{href:!0});var JAt=s(lQ);vrr=r(JAt,"DebertaV2ForTokenClassification"),JAt.forEach(t),Frr=r(ZNe," (DeBERTa-v2 model)"),ZNe.forEach(t),Trr=i(K),bF=n(K,"LI",{});var eqe=s(bF);i2e=n(eqe,"STRONG",{});var YAt=s(i2e);Mrr=r(YAt,"distilbert"),YAt.forEach(t),Err=r(eqe," \u2014 "),iQ=n(eqe,"A",{href:!0});var KAt=s(iQ);Crr=r(KAt,"DistilBertForTokenClassification"),KAt.forEach(t),wrr=r(eqe," (DistilBERT model)"),eqe.forEach(t),Arr=i(K),vF=n(K,"LI",{});var oqe=s(vF);d2e=n(oqe,"STRONG",{});var ZAt=s(d2e);Lrr=r(ZAt,"electra"),ZAt.forEach(t),yrr=r(oqe," \u2014 "),dQ=n(oqe,"A",{href:!0});var eLt=s(dQ);xrr=r(eLt,"ElectraForTokenClassification"),eLt.forEach(t),$rr=r(oqe," (ELECTRA model)"),oqe.forEach(t),krr=i(K),FF=n(K,"LI",{});var rqe=s(FF);c2e=n(rqe,"STRONG",{});var oLt=s(c2e);Srr=r(oLt,"flaubert"),oLt.forEach(t),Rrr=r(rqe," \u2014 "),cQ=n(rqe,"A",{href:!0});var rLt=s(cQ);Prr=r(rLt,"FlaubertForTokenClassification"),rLt.forEach(t),Brr=r(rqe," (FlauBERT model)"),rqe.forEach(t),Irr=i(K),TF=n(K,"LI",{});var tqe=s(TF);f2e=n(tqe,"STRONG",{});var tLt=s(f2e);Nrr=r(tLt,"fnet"),tLt.forEach(t),qrr=r(tqe," \u2014 "),fQ=n(tqe,"A",{href:!0});var aLt=s(fQ);jrr=r(aLt,"FNetForTokenClassification"),aLt.forEach(t),Drr=r(tqe," (FNet model)"),tqe.forEach(t),Grr=i(K),MF=n(K,"LI",{});var aqe=s(MF);m2e=n(aqe,"STRONG",{});var nLt=s(m2e);Orr=r(nLt,"funnel"),nLt.forEach(t),Vrr=r(aqe," \u2014 "),mQ=n(aqe,"A",{href:!0});var sLt=s(mQ);Xrr=r(sLt,"FunnelForTokenClassification"),sLt.forEach(t),zrr=r(aqe," (Funnel Transformer model)"),aqe.forEach(t),Wrr=i(K),EF=n(K,"LI",{});var nqe=s(EF);g2e=n(nqe,"STRONG",{});var lLt=s(g2e);Qrr=r(lLt,"gpt2"),lLt.forEach(t),Hrr=r(nqe," \u2014 "),gQ=n(nqe,"A",{href:!0});var iLt=s(gQ);Urr=r(iLt,"GPT2ForTokenClassification"),iLt.forEach(t),Jrr=r(nqe," (OpenAI GPT-2 model)"),nqe.forEach(t),Yrr=i(K),CF=n(K,"LI",{});var sqe=s(CF);h2e=n(sqe,"STRONG",{});var dLt=s(h2e);Krr=r(dLt,"ibert"),dLt.forEach(t),Zrr=r(sqe," \u2014 "),hQ=n(sqe,"A",{href:!0});var cLt=s(hQ);etr=r(cLt,"IBertForTokenClassification"),cLt.forEach(t),otr=r(sqe," (I-BERT model)"),sqe.forEach(t),rtr=i(K),wF=n(K,"LI",{});var lqe=s(wF);p2e=n(lqe,"STRONG",{});var fLt=s(p2e);ttr=r(fLt,"layoutlm"),fLt.forEach(t),atr=r(lqe," \u2014 "),pQ=n(lqe,"A",{href:!0});var mLt=s(pQ);ntr=r(mLt,"LayoutLMForTokenClassification"),mLt.forEach(t),str=r(lqe," (LayoutLM model)"),lqe.forEach(t),ltr=i(K),AF=n(K,"LI",{});var iqe=s(AF);_2e=n(iqe,"STRONG",{});var gLt=s(_2e);itr=r(gLt,"layoutlmv2"),gLt.forEach(t),dtr=r(iqe," \u2014 "),_Q=n(iqe,"A",{href:!0});var hLt=s(_Q);ctr=r(hLt,"LayoutLMv2ForTokenClassification"),hLt.forEach(t),ftr=r(iqe," (LayoutLMv2 model)"),iqe.forEach(t),mtr=i(K),LF=n(K,"LI",{});var dqe=s(LF);u2e=n(dqe,"STRONG",{});var pLt=s(u2e);gtr=r(pLt,"layoutlmv3"),pLt.forEach(t),htr=r(dqe," \u2014 "),uQ=n(dqe,"A",{href:!0});var _Lt=s(uQ);ptr=r(_Lt,"LayoutLMv3ForTokenClassification"),_Lt.forEach(t),_tr=r(dqe," (LayoutLMv3 model)"),dqe.forEach(t),utr=i(K),yF=n(K,"LI",{});var cqe=s(yF);b2e=n(cqe,"STRONG",{});var uLt=s(b2e);btr=r(uLt,"longformer"),uLt.forEach(t),vtr=r(cqe," \u2014 "),bQ=n(cqe,"A",{href:!0});var bLt=s(bQ);Ftr=r(bLt,"LongformerForTokenClassification"),bLt.forEach(t),Ttr=r(cqe," (Longformer model)"),cqe.forEach(t),Mtr=i(K),xF=n(K,"LI",{});var fqe=s(xF);v2e=n(fqe,"STRONG",{});var vLt=s(v2e);Etr=r(vLt,"luke"),vLt.forEach(t),Ctr=r(fqe," \u2014 "),vQ=n(fqe,"A",{href:!0});var FLt=s(vQ);wtr=r(FLt,"LukeForTokenClassification"),FLt.forEach(t),Atr=r(fqe," (LUKE model)"),fqe.forEach(t),Ltr=i(K),$F=n(K,"LI",{});var mqe=s($F);F2e=n(mqe,"STRONG",{});var TLt=s(F2e);ytr=r(TLt,"megatron-bert"),TLt.forEach(t),xtr=r(mqe," \u2014 "),FQ=n(mqe,"A",{href:!0});var MLt=s(FQ);$tr=r(MLt,"MegatronBertForTokenClassification"),MLt.forEach(t),ktr=r(mqe," (Megatron-BERT model)"),mqe.forEach(t),Str=i(K),kF=n(K,"LI",{});var gqe=s(kF);T2e=n(gqe,"STRONG",{});var ELt=s(T2e);Rtr=r(ELt,"mobilebert"),ELt.forEach(t),Ptr=r(gqe," \u2014 "),TQ=n(gqe,"A",{href:!0});var CLt=s(TQ);Btr=r(CLt,"MobileBertForTokenClassification"),CLt.forEach(t),Itr=r(gqe," (MobileBERT model)"),gqe.forEach(t),Ntr=i(K),SF=n(K,"LI",{});var hqe=s(SF);M2e=n(hqe,"STRONG",{});var wLt=s(M2e);qtr=r(wLt,"mpnet"),wLt.forEach(t),jtr=r(hqe," \u2014 "),MQ=n(hqe,"A",{href:!0});var ALt=s(MQ);Dtr=r(ALt,"MPNetForTokenClassification"),ALt.forEach(t),Gtr=r(hqe," (MPNet model)"),hqe.forEach(t),Otr=i(K),RF=n(K,"LI",{});var pqe=s(RF);E2e=n(pqe,"STRONG",{});var LLt=s(E2e);Vtr=r(LLt,"nezha"),LLt.forEach(t),Xtr=r(pqe," \u2014 "),EQ=n(pqe,"A",{href:!0});var yLt=s(EQ);ztr=r(yLt,"NezhaForTokenClassification"),yLt.forEach(t),Wtr=r(pqe," (Nezha model)"),pqe.forEach(t),Qtr=i(K),PF=n(K,"LI",{});var _qe=s(PF);C2e=n(_qe,"STRONG",{});var xLt=s(C2e);Htr=r(xLt,"nystromformer"),xLt.forEach(t),Utr=r(_qe," \u2014 "),CQ=n(_qe,"A",{href:!0});var $Lt=s(CQ);Jtr=r($Lt,"NystromformerForTokenClassification"),$Lt.forEach(t),Ytr=r(_qe," (Nystr\xF6mformer model)"),_qe.forEach(t),Ktr=i(K),BF=n(K,"LI",{});var uqe=s(BF);w2e=n(uqe,"STRONG",{});var kLt=s(w2e);Ztr=r(kLt,"qdqbert"),kLt.forEach(t),ear=r(uqe," \u2014 "),wQ=n(uqe,"A",{href:!0});var SLt=s(wQ);oar=r(SLt,"QDQBertForTokenClassification"),SLt.forEach(t),rar=r(uqe," (QDQBert model)"),uqe.forEach(t),tar=i(K),IF=n(K,"LI",{});var bqe=s(IF);A2e=n(bqe,"STRONG",{});var RLt=s(A2e);aar=r(RLt,"rembert"),RLt.forEach(t),nar=r(bqe," \u2014 "),AQ=n(bqe,"A",{href:!0});var PLt=s(AQ);sar=r(PLt,"RemBertForTokenClassification"),PLt.forEach(t),lar=r(bqe," (RemBERT model)"),bqe.forEach(t),iar=i(K),NF=n(K,"LI",{});var vqe=s(NF);L2e=n(vqe,"STRONG",{});var BLt=s(L2e);dar=r(BLt,"roberta"),BLt.forEach(t),car=r(vqe," \u2014 "),LQ=n(vqe,"A",{href:!0});var ILt=s(LQ);far=r(ILt,"RobertaForTokenClassification"),ILt.forEach(t),mar=r(vqe," (RoBERTa model)"),vqe.forEach(t),gar=i(K),qF=n(K,"LI",{});var Fqe=s(qF);y2e=n(Fqe,"STRONG",{});var NLt=s(y2e);har=r(NLt,"roformer"),NLt.forEach(t),par=r(Fqe," \u2014 "),yQ=n(Fqe,"A",{href:!0});var qLt=s(yQ);_ar=r(qLt,"RoFormerForTokenClassification"),qLt.forEach(t),uar=r(Fqe," (RoFormer model)"),Fqe.forEach(t),bar=i(K),jF=n(K,"LI",{});var Tqe=s(jF);x2e=n(Tqe,"STRONG",{});var jLt=s(x2e);Far=r(jLt,"squeezebert"),jLt.forEach(t),Tar=r(Tqe," \u2014 "),xQ=n(Tqe,"A",{href:!0});var DLt=s(xQ);Mar=r(DLt,"SqueezeBertForTokenClassification"),DLt.forEach(t),Ear=r(Tqe," (SqueezeBERT model)"),Tqe.forEach(t),Car=i(K),DF=n(K,"LI",{});var Mqe=s(DF);$2e=n(Mqe,"STRONG",{});var GLt=s($2e);war=r(GLt,"xlm"),GLt.forEach(t),Aar=r(Mqe," \u2014 "),$Q=n(Mqe,"A",{href:!0});var OLt=s($Q);Lar=r(OLt,"XLMForTokenClassification"),OLt.forEach(t),yar=r(Mqe," (XLM model)"),Mqe.forEach(t),xar=i(K),GF=n(K,"LI",{});var Eqe=s(GF);k2e=n(Eqe,"STRONG",{});var VLt=s(k2e);$ar=r(VLt,"xlm-roberta"),VLt.forEach(t),kar=r(Eqe," \u2014 "),kQ=n(Eqe,"A",{href:!0});var XLt=s(kQ);Sar=r(XLt,"XLMRobertaForTokenClassification"),XLt.forEach(t),Rar=r(Eqe," (XLM-RoBERTa model)"),Eqe.forEach(t),Par=i(K),OF=n(K,"LI",{});var Cqe=s(OF);S2e=n(Cqe,"STRONG",{});var zLt=s(S2e);Bar=r(zLt,"xlm-roberta-xl"),zLt.forEach(t),Iar=r(Cqe," \u2014 "),SQ=n(Cqe,"A",{href:!0});var WLt=s(SQ);Nar=r(WLt,"XLMRobertaXLForTokenClassification"),WLt.forEach(t),qar=r(Cqe," (XLM-RoBERTa-XL model)"),Cqe.forEach(t),jar=i(K),VF=n(K,"LI",{});var wqe=s(VF);R2e=n(wqe,"STRONG",{});var QLt=s(R2e);Dar=r(QLt,"xlnet"),QLt.forEach(t),Gar=r(wqe," \u2014 "),RQ=n(wqe,"A",{href:!0});var HLt=s(RQ);Oar=r(HLt,"XLNetForTokenClassification"),HLt.forEach(t),Var=r(wqe," (XLNet model)"),wqe.forEach(t),Xar=i(K),XF=n(K,"LI",{});var Aqe=s(XF);P2e=n(Aqe,"STRONG",{});var ULt=s(P2e);zar=r(ULt,"yoso"),ULt.forEach(t),War=r(Aqe," \u2014 "),PQ=n(Aqe,"A",{href:!0});var JLt=s(PQ);Qar=r(JLt,"YosoForTokenClassification"),JLt.forEach(t),Har=r(Aqe," (YOSO model)"),Aqe.forEach(t),K.forEach(t),Uar=i(va),zF=n(va,"P",{});var Lqe=s(zF);Jar=r(Lqe,"The model is set in evaluation mode by default using "),B2e=n(Lqe,"CODE",{});var YLt=s(B2e);Yar=r(YLt,"model.eval()"),YLt.forEach(t),Kar=r(Lqe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),I2e=n(Lqe,"CODE",{});var KLt=s(I2e);Zar=r(KLt,"model.train()"),KLt.forEach(t),Lqe.forEach(t),enr=i(va),T(WF.$$.fragment,va),va.forEach(t),bl.forEach(t),_Qe=i(f),Ed=n(f,"H2",{class:!0});var CUe=s(Ed);QF=n(CUe,"A",{id:!0,class:!0,href:!0});var ZLt=s(QF);N2e=n(ZLt,"SPAN",{});var eyt=s(N2e);T(c8.$$.fragment,eyt),eyt.forEach(t),ZLt.forEach(t),onr=i(CUe),q2e=n(CUe,"SPAN",{});var oyt=s(q2e);rnr=r(oyt,"AutoModelForQuestionAnswering"),oyt.forEach(t),CUe.forEach(t),uQe=i(f),Oo=n(f,"DIV",{class:!0});var vl=s(Oo);T(f8.$$.fragment,vl),tnr=i(vl),Cd=n(vl,"P",{});var Cae=s(Cd);anr=r(Cae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),BQ=n(Cae,"A",{href:!0});var ryt=s(BQ);nnr=r(ryt,"from_pretrained()"),ryt.forEach(t),snr=r(Cae," class method or the "),IQ=n(Cae,"A",{href:!0});var tyt=s(IQ);lnr=r(tyt,"from_config()"),tyt.forEach(t),inr=r(Cae,` class
method.`),Cae.forEach(t),dnr=i(vl),m8=n(vl,"P",{});var wUe=s(m8);cnr=r(wUe,"This class cannot be instantiated directly using "),j2e=n(wUe,"CODE",{});var ayt=s(j2e);fnr=r(ayt,"__init__()"),ayt.forEach(t),mnr=r(wUe," (throws an error)."),wUe.forEach(t),gnr=i(vl),vt=n(vl,"DIV",{class:!0});var mA=s(vt);T(g8.$$.fragment,mA),hnr=i(mA),D2e=n(mA,"P",{});var nyt=s(D2e);pnr=r(nyt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),nyt.forEach(t),_nr=i(mA),wd=n(mA,"P",{});var wae=s(wd);unr=r(wae,`Note:
Loading a model from its configuration file does `),G2e=n(wae,"STRONG",{});var syt=s(G2e);bnr=r(syt,"not"),syt.forEach(t),vnr=r(wae,` load the model weights. It only affects the
model\u2019s configuration. Use `),NQ=n(wae,"A",{href:!0});var lyt=s(NQ);Fnr=r(lyt,"from_pretrained()"),lyt.forEach(t),Tnr=r(wae," to load the model weights."),wae.forEach(t),Mnr=i(mA),T(HF.$$.fragment,mA),mA.forEach(t),Enr=i(vl),so=n(vl,"DIV",{class:!0});var Fa=s(so);T(h8.$$.fragment,Fa),Cnr=i(Fa),O2e=n(Fa,"P",{});var iyt=s(O2e);wnr=r(iyt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),iyt.forEach(t),Anr=i(Fa),Ua=n(Fa,"P",{});var gA=s(Ua);Lnr=r(gA,"The model class to instantiate is selected based on the "),V2e=n(gA,"CODE",{});var dyt=s(V2e);ynr=r(dyt,"model_type"),dyt.forEach(t),xnr=r(gA,` property of the config object (either
passed as an argument or loaded from `),X2e=n(gA,"CODE",{});var cyt=s(X2e);$nr=r(cyt,"pretrained_model_name_or_path"),cyt.forEach(t),knr=r(gA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),z2e=n(gA,"CODE",{});var fyt=s(z2e);Snr=r(fyt,"pretrained_model_name_or_path"),fyt.forEach(t),Rnr=r(gA,":"),gA.forEach(t),Pnr=i(Fa),V=n(Fa,"UL",{});var X=s(V);UF=n(X,"LI",{});var yqe=s(UF);W2e=n(yqe,"STRONG",{});var myt=s(W2e);Bnr=r(myt,"albert"),myt.forEach(t),Inr=r(yqe," \u2014 "),qQ=n(yqe,"A",{href:!0});var gyt=s(qQ);Nnr=r(gyt,"AlbertForQuestionAnswering"),gyt.forEach(t),qnr=r(yqe," (ALBERT model)"),yqe.forEach(t),jnr=i(X),JF=n(X,"LI",{});var xqe=s(JF);Q2e=n(xqe,"STRONG",{});var hyt=s(Q2e);Dnr=r(hyt,"bart"),hyt.forEach(t),Gnr=r(xqe," \u2014 "),jQ=n(xqe,"A",{href:!0});var pyt=s(jQ);Onr=r(pyt,"BartForQuestionAnswering"),pyt.forEach(t),Vnr=r(xqe," (BART model)"),xqe.forEach(t),Xnr=i(X),YF=n(X,"LI",{});var $qe=s(YF);H2e=n($qe,"STRONG",{});var _yt=s(H2e);znr=r(_yt,"bert"),_yt.forEach(t),Wnr=r($qe," \u2014 "),DQ=n($qe,"A",{href:!0});var uyt=s(DQ);Qnr=r(uyt,"BertForQuestionAnswering"),uyt.forEach(t),Hnr=r($qe," (BERT model)"),$qe.forEach(t),Unr=i(X),KF=n(X,"LI",{});var kqe=s(KF);U2e=n(kqe,"STRONG",{});var byt=s(U2e);Jnr=r(byt,"big_bird"),byt.forEach(t),Ynr=r(kqe," \u2014 "),GQ=n(kqe,"A",{href:!0});var vyt=s(GQ);Knr=r(vyt,"BigBirdForQuestionAnswering"),vyt.forEach(t),Znr=r(kqe," (BigBird model)"),kqe.forEach(t),esr=i(X),ZF=n(X,"LI",{});var Sqe=s(ZF);J2e=n(Sqe,"STRONG",{});var Fyt=s(J2e);osr=r(Fyt,"bigbird_pegasus"),Fyt.forEach(t),rsr=r(Sqe," \u2014 "),OQ=n(Sqe,"A",{href:!0});var Tyt=s(OQ);tsr=r(Tyt,"BigBirdPegasusForQuestionAnswering"),Tyt.forEach(t),asr=r(Sqe," (BigBird-Pegasus model)"),Sqe.forEach(t),nsr=i(X),eT=n(X,"LI",{});var Rqe=s(eT);Y2e=n(Rqe,"STRONG",{});var Myt=s(Y2e);ssr=r(Myt,"camembert"),Myt.forEach(t),lsr=r(Rqe," \u2014 "),VQ=n(Rqe,"A",{href:!0});var Eyt=s(VQ);isr=r(Eyt,"CamembertForQuestionAnswering"),Eyt.forEach(t),dsr=r(Rqe," (CamemBERT model)"),Rqe.forEach(t),csr=i(X),oT=n(X,"LI",{});var Pqe=s(oT);K2e=n(Pqe,"STRONG",{});var Cyt=s(K2e);fsr=r(Cyt,"canine"),Cyt.forEach(t),msr=r(Pqe," \u2014 "),XQ=n(Pqe,"A",{href:!0});var wyt=s(XQ);gsr=r(wyt,"CanineForQuestionAnswering"),wyt.forEach(t),hsr=r(Pqe," (CANINE model)"),Pqe.forEach(t),psr=i(X),rT=n(X,"LI",{});var Bqe=s(rT);Z2e=n(Bqe,"STRONG",{});var Ayt=s(Z2e);_sr=r(Ayt,"convbert"),Ayt.forEach(t),usr=r(Bqe," \u2014 "),zQ=n(Bqe,"A",{href:!0});var Lyt=s(zQ);bsr=r(Lyt,"ConvBertForQuestionAnswering"),Lyt.forEach(t),vsr=r(Bqe," (ConvBERT model)"),Bqe.forEach(t),Fsr=i(X),tT=n(X,"LI",{});var Iqe=s(tT);ebe=n(Iqe,"STRONG",{});var yyt=s(ebe);Tsr=r(yyt,"data2vec-text"),yyt.forEach(t),Msr=r(Iqe," \u2014 "),WQ=n(Iqe,"A",{href:!0});var xyt=s(WQ);Esr=r(xyt,"Data2VecTextForQuestionAnswering"),xyt.forEach(t),Csr=r(Iqe," (Data2VecText model)"),Iqe.forEach(t),wsr=i(X),aT=n(X,"LI",{});var Nqe=s(aT);obe=n(Nqe,"STRONG",{});var $yt=s(obe);Asr=r($yt,"deberta"),$yt.forEach(t),Lsr=r(Nqe," \u2014 "),QQ=n(Nqe,"A",{href:!0});var kyt=s(QQ);ysr=r(kyt,"DebertaForQuestionAnswering"),kyt.forEach(t),xsr=r(Nqe," (DeBERTa model)"),Nqe.forEach(t),$sr=i(X),nT=n(X,"LI",{});var qqe=s(nT);rbe=n(qqe,"STRONG",{});var Syt=s(rbe);ksr=r(Syt,"deberta-v2"),Syt.forEach(t),Ssr=r(qqe," \u2014 "),HQ=n(qqe,"A",{href:!0});var Ryt=s(HQ);Rsr=r(Ryt,"DebertaV2ForQuestionAnswering"),Ryt.forEach(t),Psr=r(qqe," (DeBERTa-v2 model)"),qqe.forEach(t),Bsr=i(X),sT=n(X,"LI",{});var jqe=s(sT);tbe=n(jqe,"STRONG",{});var Pyt=s(tbe);Isr=r(Pyt,"distilbert"),Pyt.forEach(t),Nsr=r(jqe," \u2014 "),UQ=n(jqe,"A",{href:!0});var Byt=s(UQ);qsr=r(Byt,"DistilBertForQuestionAnswering"),Byt.forEach(t),jsr=r(jqe," (DistilBERT model)"),jqe.forEach(t),Dsr=i(X),lT=n(X,"LI",{});var Dqe=s(lT);abe=n(Dqe,"STRONG",{});var Iyt=s(abe);Gsr=r(Iyt,"electra"),Iyt.forEach(t),Osr=r(Dqe," \u2014 "),JQ=n(Dqe,"A",{href:!0});var Nyt=s(JQ);Vsr=r(Nyt,"ElectraForQuestionAnswering"),Nyt.forEach(t),Xsr=r(Dqe," (ELECTRA model)"),Dqe.forEach(t),zsr=i(X),iT=n(X,"LI",{});var Gqe=s(iT);nbe=n(Gqe,"STRONG",{});var qyt=s(nbe);Wsr=r(qyt,"flaubert"),qyt.forEach(t),Qsr=r(Gqe," \u2014 "),YQ=n(Gqe,"A",{href:!0});var jyt=s(YQ);Hsr=r(jyt,"FlaubertForQuestionAnsweringSimple"),jyt.forEach(t),Usr=r(Gqe," (FlauBERT model)"),Gqe.forEach(t),Jsr=i(X),dT=n(X,"LI",{});var Oqe=s(dT);sbe=n(Oqe,"STRONG",{});var Dyt=s(sbe);Ysr=r(Dyt,"fnet"),Dyt.forEach(t),Ksr=r(Oqe," \u2014 "),KQ=n(Oqe,"A",{href:!0});var Gyt=s(KQ);Zsr=r(Gyt,"FNetForQuestionAnswering"),Gyt.forEach(t),elr=r(Oqe," (FNet model)"),Oqe.forEach(t),olr=i(X),cT=n(X,"LI",{});var Vqe=s(cT);lbe=n(Vqe,"STRONG",{});var Oyt=s(lbe);rlr=r(Oyt,"funnel"),Oyt.forEach(t),tlr=r(Vqe," \u2014 "),ZQ=n(Vqe,"A",{href:!0});var Vyt=s(ZQ);alr=r(Vyt,"FunnelForQuestionAnswering"),Vyt.forEach(t),nlr=r(Vqe," (Funnel Transformer model)"),Vqe.forEach(t),slr=i(X),fT=n(X,"LI",{});var Xqe=s(fT);ibe=n(Xqe,"STRONG",{});var Xyt=s(ibe);llr=r(Xyt,"gptj"),Xyt.forEach(t),ilr=r(Xqe," \u2014 "),eH=n(Xqe,"A",{href:!0});var zyt=s(eH);dlr=r(zyt,"GPTJForQuestionAnswering"),zyt.forEach(t),clr=r(Xqe," (GPT-J model)"),Xqe.forEach(t),flr=i(X),mT=n(X,"LI",{});var zqe=s(mT);dbe=n(zqe,"STRONG",{});var Wyt=s(dbe);mlr=r(Wyt,"ibert"),Wyt.forEach(t),glr=r(zqe," \u2014 "),oH=n(zqe,"A",{href:!0});var Qyt=s(oH);hlr=r(Qyt,"IBertForQuestionAnswering"),Qyt.forEach(t),plr=r(zqe," (I-BERT model)"),zqe.forEach(t),_lr=i(X),gT=n(X,"LI",{});var Wqe=s(gT);cbe=n(Wqe,"STRONG",{});var Hyt=s(cbe);ulr=r(Hyt,"layoutlmv2"),Hyt.forEach(t),blr=r(Wqe," \u2014 "),rH=n(Wqe,"A",{href:!0});var Uyt=s(rH);vlr=r(Uyt,"LayoutLMv2ForQuestionAnswering"),Uyt.forEach(t),Flr=r(Wqe," (LayoutLMv2 model)"),Wqe.forEach(t),Tlr=i(X),hT=n(X,"LI",{});var Qqe=s(hT);fbe=n(Qqe,"STRONG",{});var Jyt=s(fbe);Mlr=r(Jyt,"layoutlmv3"),Jyt.forEach(t),Elr=r(Qqe," \u2014 "),tH=n(Qqe,"A",{href:!0});var Yyt=s(tH);Clr=r(Yyt,"LayoutLMv3ForQuestionAnswering"),Yyt.forEach(t),wlr=r(Qqe," (LayoutLMv3 model)"),Qqe.forEach(t),Alr=i(X),pT=n(X,"LI",{});var Hqe=s(pT);mbe=n(Hqe,"STRONG",{});var Kyt=s(mbe);Llr=r(Kyt,"led"),Kyt.forEach(t),ylr=r(Hqe," \u2014 "),aH=n(Hqe,"A",{href:!0});var Zyt=s(aH);xlr=r(Zyt,"LEDForQuestionAnswering"),Zyt.forEach(t),$lr=r(Hqe," (LED model)"),Hqe.forEach(t),klr=i(X),_T=n(X,"LI",{});var Uqe=s(_T);gbe=n(Uqe,"STRONG",{});var e8t=s(gbe);Slr=r(e8t,"longformer"),e8t.forEach(t),Rlr=r(Uqe," \u2014 "),nH=n(Uqe,"A",{href:!0});var o8t=s(nH);Plr=r(o8t,"LongformerForQuestionAnswering"),o8t.forEach(t),Blr=r(Uqe," (Longformer model)"),Uqe.forEach(t),Ilr=i(X),uT=n(X,"LI",{});var Jqe=s(uT);hbe=n(Jqe,"STRONG",{});var r8t=s(hbe);Nlr=r(r8t,"luke"),r8t.forEach(t),qlr=r(Jqe," \u2014 "),sH=n(Jqe,"A",{href:!0});var t8t=s(sH);jlr=r(t8t,"LukeForQuestionAnswering"),t8t.forEach(t),Dlr=r(Jqe," (LUKE model)"),Jqe.forEach(t),Glr=i(X),bT=n(X,"LI",{});var Yqe=s(bT);pbe=n(Yqe,"STRONG",{});var a8t=s(pbe);Olr=r(a8t,"lxmert"),a8t.forEach(t),Vlr=r(Yqe," \u2014 "),lH=n(Yqe,"A",{href:!0});var n8t=s(lH);Xlr=r(n8t,"LxmertForQuestionAnswering"),n8t.forEach(t),zlr=r(Yqe," (LXMERT model)"),Yqe.forEach(t),Wlr=i(X),vT=n(X,"LI",{});var Kqe=s(vT);_be=n(Kqe,"STRONG",{});var s8t=s(_be);Qlr=r(s8t,"mbart"),s8t.forEach(t),Hlr=r(Kqe," \u2014 "),iH=n(Kqe,"A",{href:!0});var l8t=s(iH);Ulr=r(l8t,"MBartForQuestionAnswering"),l8t.forEach(t),Jlr=r(Kqe," (mBART model)"),Kqe.forEach(t),Ylr=i(X),FT=n(X,"LI",{});var Zqe=s(FT);ube=n(Zqe,"STRONG",{});var i8t=s(ube);Klr=r(i8t,"megatron-bert"),i8t.forEach(t),Zlr=r(Zqe," \u2014 "),dH=n(Zqe,"A",{href:!0});var d8t=s(dH);eir=r(d8t,"MegatronBertForQuestionAnswering"),d8t.forEach(t),oir=r(Zqe," (Megatron-BERT model)"),Zqe.forEach(t),rir=i(X),TT=n(X,"LI",{});var eje=s(TT);bbe=n(eje,"STRONG",{});var c8t=s(bbe);tir=r(c8t,"mobilebert"),c8t.forEach(t),air=r(eje," \u2014 "),cH=n(eje,"A",{href:!0});var f8t=s(cH);nir=r(f8t,"MobileBertForQuestionAnswering"),f8t.forEach(t),sir=r(eje," (MobileBERT model)"),eje.forEach(t),lir=i(X),MT=n(X,"LI",{});var oje=s(MT);vbe=n(oje,"STRONG",{});var m8t=s(vbe);iir=r(m8t,"mpnet"),m8t.forEach(t),dir=r(oje," \u2014 "),fH=n(oje,"A",{href:!0});var g8t=s(fH);cir=r(g8t,"MPNetForQuestionAnswering"),g8t.forEach(t),fir=r(oje," (MPNet model)"),oje.forEach(t),mir=i(X),ET=n(X,"LI",{});var rje=s(ET);Fbe=n(rje,"STRONG",{});var h8t=s(Fbe);gir=r(h8t,"mvp"),h8t.forEach(t),hir=r(rje," \u2014 "),mH=n(rje,"A",{href:!0});var p8t=s(mH);pir=r(p8t,"MvpForQuestionAnswering"),p8t.forEach(t),_ir=r(rje," (MVP model)"),rje.forEach(t),uir=i(X),CT=n(X,"LI",{});var tje=s(CT);Tbe=n(tje,"STRONG",{});var _8t=s(Tbe);bir=r(_8t,"nezha"),_8t.forEach(t),vir=r(tje," \u2014 "),gH=n(tje,"A",{href:!0});var u8t=s(gH);Fir=r(u8t,"NezhaForQuestionAnswering"),u8t.forEach(t),Tir=r(tje," (Nezha model)"),tje.forEach(t),Mir=i(X),wT=n(X,"LI",{});var aje=s(wT);Mbe=n(aje,"STRONG",{});var b8t=s(Mbe);Eir=r(b8t,"nystromformer"),b8t.forEach(t),Cir=r(aje," \u2014 "),hH=n(aje,"A",{href:!0});var v8t=s(hH);wir=r(v8t,"NystromformerForQuestionAnswering"),v8t.forEach(t),Air=r(aje," (Nystr\xF6mformer model)"),aje.forEach(t),Lir=i(X),AT=n(X,"LI",{});var nje=s(AT);Ebe=n(nje,"STRONG",{});var F8t=s(Ebe);yir=r(F8t,"qdqbert"),F8t.forEach(t),xir=r(nje," \u2014 "),pH=n(nje,"A",{href:!0});var T8t=s(pH);$ir=r(T8t,"QDQBertForQuestionAnswering"),T8t.forEach(t),kir=r(nje," (QDQBert model)"),nje.forEach(t),Sir=i(X),LT=n(X,"LI",{});var sje=s(LT);Cbe=n(sje,"STRONG",{});var M8t=s(Cbe);Rir=r(M8t,"reformer"),M8t.forEach(t),Pir=r(sje," \u2014 "),_H=n(sje,"A",{href:!0});var E8t=s(_H);Bir=r(E8t,"ReformerForQuestionAnswering"),E8t.forEach(t),Iir=r(sje," (Reformer model)"),sje.forEach(t),Nir=i(X),yT=n(X,"LI",{});var lje=s(yT);wbe=n(lje,"STRONG",{});var C8t=s(wbe);qir=r(C8t,"rembert"),C8t.forEach(t),jir=r(lje," \u2014 "),uH=n(lje,"A",{href:!0});var w8t=s(uH);Dir=r(w8t,"RemBertForQuestionAnswering"),w8t.forEach(t),Gir=r(lje," (RemBERT model)"),lje.forEach(t),Oir=i(X),xT=n(X,"LI",{});var ije=s(xT);Abe=n(ije,"STRONG",{});var A8t=s(Abe);Vir=r(A8t,"roberta"),A8t.forEach(t),Xir=r(ije," \u2014 "),bH=n(ije,"A",{href:!0});var L8t=s(bH);zir=r(L8t,"RobertaForQuestionAnswering"),L8t.forEach(t),Wir=r(ije," (RoBERTa model)"),ije.forEach(t),Qir=i(X),$T=n(X,"LI",{});var dje=s($T);Lbe=n(dje,"STRONG",{});var y8t=s(Lbe);Hir=r(y8t,"roformer"),y8t.forEach(t),Uir=r(dje," \u2014 "),vH=n(dje,"A",{href:!0});var x8t=s(vH);Jir=r(x8t,"RoFormerForQuestionAnswering"),x8t.forEach(t),Yir=r(dje," (RoFormer model)"),dje.forEach(t),Kir=i(X),kT=n(X,"LI",{});var cje=s(kT);ybe=n(cje,"STRONG",{});var $8t=s(ybe);Zir=r($8t,"splinter"),$8t.forEach(t),edr=r(cje," \u2014 "),FH=n(cje,"A",{href:!0});var k8t=s(FH);odr=r(k8t,"SplinterForQuestionAnswering"),k8t.forEach(t),rdr=r(cje," (Splinter model)"),cje.forEach(t),tdr=i(X),ST=n(X,"LI",{});var fje=s(ST);xbe=n(fje,"STRONG",{});var S8t=s(xbe);adr=r(S8t,"squeezebert"),S8t.forEach(t),ndr=r(fje," \u2014 "),TH=n(fje,"A",{href:!0});var R8t=s(TH);sdr=r(R8t,"SqueezeBertForQuestionAnswering"),R8t.forEach(t),ldr=r(fje," (SqueezeBERT model)"),fje.forEach(t),idr=i(X),RT=n(X,"LI",{});var mje=s(RT);$be=n(mje,"STRONG",{});var P8t=s($be);ddr=r(P8t,"xlm"),P8t.forEach(t),cdr=r(mje," \u2014 "),MH=n(mje,"A",{href:!0});var B8t=s(MH);fdr=r(B8t,"XLMForQuestionAnsweringSimple"),B8t.forEach(t),mdr=r(mje," (XLM model)"),mje.forEach(t),gdr=i(X),PT=n(X,"LI",{});var gje=s(PT);kbe=n(gje,"STRONG",{});var I8t=s(kbe);hdr=r(I8t,"xlm-roberta"),I8t.forEach(t),pdr=r(gje," \u2014 "),EH=n(gje,"A",{href:!0});var N8t=s(EH);_dr=r(N8t,"XLMRobertaForQuestionAnswering"),N8t.forEach(t),udr=r(gje," (XLM-RoBERTa model)"),gje.forEach(t),bdr=i(X),BT=n(X,"LI",{});var hje=s(BT);Sbe=n(hje,"STRONG",{});var q8t=s(Sbe);vdr=r(q8t,"xlm-roberta-xl"),q8t.forEach(t),Fdr=r(hje," \u2014 "),CH=n(hje,"A",{href:!0});var j8t=s(CH);Tdr=r(j8t,"XLMRobertaXLForQuestionAnswering"),j8t.forEach(t),Mdr=r(hje," (XLM-RoBERTa-XL model)"),hje.forEach(t),Edr=i(X),IT=n(X,"LI",{});var pje=s(IT);Rbe=n(pje,"STRONG",{});var D8t=s(Rbe);Cdr=r(D8t,"xlnet"),D8t.forEach(t),wdr=r(pje," \u2014 "),wH=n(pje,"A",{href:!0});var G8t=s(wH);Adr=r(G8t,"XLNetForQuestionAnsweringSimple"),G8t.forEach(t),Ldr=r(pje," (XLNet model)"),pje.forEach(t),ydr=i(X),NT=n(X,"LI",{});var _je=s(NT);Pbe=n(_je,"STRONG",{});var O8t=s(Pbe);xdr=r(O8t,"yoso"),O8t.forEach(t),$dr=r(_je," \u2014 "),AH=n(_je,"A",{href:!0});var V8t=s(AH);kdr=r(V8t,"YosoForQuestionAnswering"),V8t.forEach(t),Sdr=r(_je," (YOSO model)"),_je.forEach(t),X.forEach(t),Rdr=i(Fa),qT=n(Fa,"P",{});var uje=s(qT);Pdr=r(uje,"The model is set in evaluation mode by default using "),Bbe=n(uje,"CODE",{});var X8t=s(Bbe);Bdr=r(X8t,"model.eval()"),X8t.forEach(t),Idr=r(uje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ibe=n(uje,"CODE",{});var z8t=s(Ibe);Ndr=r(z8t,"model.train()"),z8t.forEach(t),uje.forEach(t),qdr=i(Fa),T(jT.$$.fragment,Fa),Fa.forEach(t),vl.forEach(t),bQe=i(f),Ad=n(f,"H2",{class:!0});var AUe=s(Ad);DT=n(AUe,"A",{id:!0,class:!0,href:!0});var W8t=s(DT);Nbe=n(W8t,"SPAN",{});var Q8t=s(Nbe);T(p8.$$.fragment,Q8t),Q8t.forEach(t),W8t.forEach(t),jdr=i(AUe),qbe=n(AUe,"SPAN",{});var H8t=s(qbe);Ddr=r(H8t,"AutoModelForTableQuestionAnswering"),H8t.forEach(t),AUe.forEach(t),vQe=i(f),Vo=n(f,"DIV",{class:!0});var Fl=s(Vo);T(_8.$$.fragment,Fl),Gdr=i(Fl),Ld=n(Fl,"P",{});var Aae=s(Ld);Odr=r(Aae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),LH=n(Aae,"A",{href:!0});var U8t=s(LH);Vdr=r(U8t,"from_pretrained()"),U8t.forEach(t),Xdr=r(Aae," class method or the "),yH=n(Aae,"A",{href:!0});var J8t=s(yH);zdr=r(J8t,"from_config()"),J8t.forEach(t),Wdr=r(Aae,` class
method.`),Aae.forEach(t),Qdr=i(Fl),u8=n(Fl,"P",{});var LUe=s(u8);Hdr=r(LUe,"This class cannot be instantiated directly using "),jbe=n(LUe,"CODE",{});var Y8t=s(jbe);Udr=r(Y8t,"__init__()"),Y8t.forEach(t),Jdr=r(LUe," (throws an error)."),LUe.forEach(t),Ydr=i(Fl),Ft=n(Fl,"DIV",{class:!0});var hA=s(Ft);T(b8.$$.fragment,hA),Kdr=i(hA),Dbe=n(hA,"P",{});var K8t=s(Dbe);Zdr=r(K8t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),K8t.forEach(t),ecr=i(hA),yd=n(hA,"P",{});var Lae=s(yd);ocr=r(Lae,`Note:
Loading a model from its configuration file does `),Gbe=n(Lae,"STRONG",{});var Z8t=s(Gbe);rcr=r(Z8t,"not"),Z8t.forEach(t),tcr=r(Lae,` load the model weights. It only affects the
model\u2019s configuration. Use `),xH=n(Lae,"A",{href:!0});var ext=s(xH);acr=r(ext,"from_pretrained()"),ext.forEach(t),ncr=r(Lae," to load the model weights."),Lae.forEach(t),scr=i(hA),T(GT.$$.fragment,hA),hA.forEach(t),lcr=i(Fl),lo=n(Fl,"DIV",{class:!0});var Ta=s(lo);T(v8.$$.fragment,Ta),icr=i(Ta),Obe=n(Ta,"P",{});var oxt=s(Obe);dcr=r(oxt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),oxt.forEach(t),ccr=i(Ta),Ja=n(Ta,"P",{});var pA=s(Ja);fcr=r(pA,"The model class to instantiate is selected based on the "),Vbe=n(pA,"CODE",{});var rxt=s(Vbe);mcr=r(rxt,"model_type"),rxt.forEach(t),gcr=r(pA,` property of the config object (either
passed as an argument or loaded from `),Xbe=n(pA,"CODE",{});var txt=s(Xbe);hcr=r(txt,"pretrained_model_name_or_path"),txt.forEach(t),pcr=r(pA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zbe=n(pA,"CODE",{});var axt=s(zbe);_cr=r(axt,"pretrained_model_name_or_path"),axt.forEach(t),ucr=r(pA,":"),pA.forEach(t),bcr=i(Ta),Wbe=n(Ta,"UL",{});var nxt=s(Wbe);OT=n(nxt,"LI",{});var bje=s(OT);Qbe=n(bje,"STRONG",{});var sxt=s(Qbe);vcr=r(sxt,"tapas"),sxt.forEach(t),Fcr=r(bje," \u2014 "),$H=n(bje,"A",{href:!0});var lxt=s($H);Tcr=r(lxt,"TapasForQuestionAnswering"),lxt.forEach(t),Mcr=r(bje," (TAPAS model)"),bje.forEach(t),nxt.forEach(t),Ecr=i(Ta),VT=n(Ta,"P",{});var vje=s(VT);Ccr=r(vje,"The model is set in evaluation mode by default using "),Hbe=n(vje,"CODE",{});var ixt=s(Hbe);wcr=r(ixt,"model.eval()"),ixt.forEach(t),Acr=r(vje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ube=n(vje,"CODE",{});var dxt=s(Ube);Lcr=r(dxt,"model.train()"),dxt.forEach(t),vje.forEach(t),ycr=i(Ta),T(XT.$$.fragment,Ta),Ta.forEach(t),Fl.forEach(t),FQe=i(f),xd=n(f,"H2",{class:!0});var yUe=s(xd);zT=n(yUe,"A",{id:!0,class:!0,href:!0});var cxt=s(zT);Jbe=n(cxt,"SPAN",{});var fxt=s(Jbe);T(F8.$$.fragment,fxt),fxt.forEach(t),cxt.forEach(t),xcr=i(yUe),Ybe=n(yUe,"SPAN",{});var mxt=s(Ybe);$cr=r(mxt,"AutoModelForImageClassification"),mxt.forEach(t),yUe.forEach(t),TQe=i(f),Xo=n(f,"DIV",{class:!0});var Tl=s(Xo);T(T8.$$.fragment,Tl),kcr=i(Tl),$d=n(Tl,"P",{});var yae=s($d);Scr=r(yae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),kH=n(yae,"A",{href:!0});var gxt=s(kH);Rcr=r(gxt,"from_pretrained()"),gxt.forEach(t),Pcr=r(yae," class method or the "),SH=n(yae,"A",{href:!0});var hxt=s(SH);Bcr=r(hxt,"from_config()"),hxt.forEach(t),Icr=r(yae,` class
method.`),yae.forEach(t),Ncr=i(Tl),M8=n(Tl,"P",{});var xUe=s(M8);qcr=r(xUe,"This class cannot be instantiated directly using "),Kbe=n(xUe,"CODE",{});var pxt=s(Kbe);jcr=r(pxt,"__init__()"),pxt.forEach(t),Dcr=r(xUe," (throws an error)."),xUe.forEach(t),Gcr=i(Tl),Tt=n(Tl,"DIV",{class:!0});var _A=s(Tt);T(E8.$$.fragment,_A),Ocr=i(_A),Zbe=n(_A,"P",{});var _xt=s(Zbe);Vcr=r(_xt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),_xt.forEach(t),Xcr=i(_A),kd=n(_A,"P",{});var xae=s(kd);zcr=r(xae,`Note:
Loading a model from its configuration file does `),eve=n(xae,"STRONG",{});var uxt=s(eve);Wcr=r(uxt,"not"),uxt.forEach(t),Qcr=r(xae,` load the model weights. It only affects the
model\u2019s configuration. Use `),RH=n(xae,"A",{href:!0});var bxt=s(RH);Hcr=r(bxt,"from_pretrained()"),bxt.forEach(t),Ucr=r(xae," to load the model weights."),xae.forEach(t),Jcr=i(_A),T(WT.$$.fragment,_A),_A.forEach(t),Ycr=i(Tl),io=n(Tl,"DIV",{class:!0});var Ma=s(io);T(C8.$$.fragment,Ma),Kcr=i(Ma),ove=n(Ma,"P",{});var vxt=s(ove);Zcr=r(vxt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),vxt.forEach(t),efr=i(Ma),Ya=n(Ma,"P",{});var uA=s(Ya);ofr=r(uA,"The model class to instantiate is selected based on the "),rve=n(uA,"CODE",{});var Fxt=s(rve);rfr=r(Fxt,"model_type"),Fxt.forEach(t),tfr=r(uA,` property of the config object (either
passed as an argument or loaded from `),tve=n(uA,"CODE",{});var Txt=s(tve);afr=r(Txt,"pretrained_model_name_or_path"),Txt.forEach(t),nfr=r(uA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ave=n(uA,"CODE",{});var Mxt=s(ave);sfr=r(Mxt,"pretrained_model_name_or_path"),Mxt.forEach(t),lfr=r(uA,":"),uA.forEach(t),ifr=i(Ma),be=n(Ma,"UL",{});var Fe=s(be);QT=n(Fe,"LI",{});var Fje=s(QT);nve=n(Fje,"STRONG",{});var Ext=s(nve);dfr=r(Ext,"beit"),Ext.forEach(t),cfr=r(Fje," \u2014 "),PH=n(Fje,"A",{href:!0});var Cxt=s(PH);ffr=r(Cxt,"BeitForImageClassification"),Cxt.forEach(t),mfr=r(Fje," (BEiT model)"),Fje.forEach(t),gfr=i(Fe),HT=n(Fe,"LI",{});var Tje=s(HT);sve=n(Tje,"STRONG",{});var wxt=s(sve);hfr=r(wxt,"convnext"),wxt.forEach(t),pfr=r(Tje," \u2014 "),BH=n(Tje,"A",{href:!0});var Axt=s(BH);_fr=r(Axt,"ConvNextForImageClassification"),Axt.forEach(t),ufr=r(Tje," (ConvNeXT model)"),Tje.forEach(t),bfr=i(Fe),UT=n(Fe,"LI",{});var Mje=s(UT);lve=n(Mje,"STRONG",{});var Lxt=s(lve);vfr=r(Lxt,"cvt"),Lxt.forEach(t),Ffr=r(Mje," \u2014 "),IH=n(Mje,"A",{href:!0});var yxt=s(IH);Tfr=r(yxt,"CvtForImageClassification"),yxt.forEach(t),Mfr=r(Mje," (CvT model)"),Mje.forEach(t),Efr=i(Fe),JT=n(Fe,"LI",{});var Eje=s(JT);ive=n(Eje,"STRONG",{});var xxt=s(ive);Cfr=r(xxt,"data2vec-vision"),xxt.forEach(t),wfr=r(Eje," \u2014 "),NH=n(Eje,"A",{href:!0});var $xt=s(NH);Afr=r($xt,"Data2VecVisionForImageClassification"),$xt.forEach(t),Lfr=r(Eje," (Data2VecVision model)"),Eje.forEach(t),yfr=i(Fe),rl=n(Fe,"LI",{});var LR=s(rl);dve=n(LR,"STRONG",{});var kxt=s(dve);xfr=r(kxt,"deit"),kxt.forEach(t),$fr=r(LR," \u2014 "),qH=n(LR,"A",{href:!0});var Sxt=s(qH);kfr=r(Sxt,"DeiTForImageClassification"),Sxt.forEach(t),Sfr=r(LR," or "),jH=n(LR,"A",{href:!0});var Rxt=s(jH);Rfr=r(Rxt,"DeiTForImageClassificationWithTeacher"),Rxt.forEach(t),Pfr=r(LR," (DeiT model)"),LR.forEach(t),Bfr=i(Fe),YT=n(Fe,"LI",{});var Cje=s(YT);cve=n(Cje,"STRONG",{});var Pxt=s(cve);Ifr=r(Pxt,"imagegpt"),Pxt.forEach(t),Nfr=r(Cje," \u2014 "),DH=n(Cje,"A",{href:!0});var Bxt=s(DH);qfr=r(Bxt,"ImageGPTForImageClassification"),Bxt.forEach(t),jfr=r(Cje," (ImageGPT model)"),Cje.forEach(t),Dfr=i(Fe),tl=n(Fe,"LI",{});var yR=s(tl);fve=n(yR,"STRONG",{});var Ixt=s(fve);Gfr=r(Ixt,"levit"),Ixt.forEach(t),Ofr=r(yR," \u2014 "),GH=n(yR,"A",{href:!0});var Nxt=s(GH);Vfr=r(Nxt,"LevitForImageClassification"),Nxt.forEach(t),Xfr=r(yR," or "),OH=n(yR,"A",{href:!0});var qxt=s(OH);zfr=r(qxt,"LevitForImageClassificationWithTeacher"),qxt.forEach(t),Wfr=r(yR," (LeViT model)"),yR.forEach(t),Qfr=i(Fe),KT=n(Fe,"LI",{});var wje=s(KT);mve=n(wje,"STRONG",{});var jxt=s(mve);Hfr=r(jxt,"mobilevit"),jxt.forEach(t),Ufr=r(wje," \u2014 "),VH=n(wje,"A",{href:!0});var Dxt=s(VH);Jfr=r(Dxt,"MobileViTForImageClassification"),Dxt.forEach(t),Yfr=r(wje," (MobileViT model)"),wje.forEach(t),Kfr=i(Fe),Mt=n(Fe,"LI",{});var Xf=s(Mt);gve=n(Xf,"STRONG",{});var Gxt=s(gve);Zfr=r(Gxt,"perceiver"),Gxt.forEach(t),emr=r(Xf," \u2014 "),XH=n(Xf,"A",{href:!0});var Oxt=s(XH);omr=r(Oxt,"PerceiverForImageClassificationLearned"),Oxt.forEach(t),rmr=r(Xf," or "),zH=n(Xf,"A",{href:!0});var Vxt=s(zH);tmr=r(Vxt,"PerceiverForImageClassificationFourier"),Vxt.forEach(t),amr=r(Xf," or "),WH=n(Xf,"A",{href:!0});var Xxt=s(WH);nmr=r(Xxt,"PerceiverForImageClassificationConvProcessing"),Xxt.forEach(t),smr=r(Xf," (Perceiver model)"),Xf.forEach(t),lmr=i(Fe),ZT=n(Fe,"LI",{});var Aje=s(ZT);hve=n(Aje,"STRONG",{});var zxt=s(hve);imr=r(zxt,"poolformer"),zxt.forEach(t),dmr=r(Aje," \u2014 "),QH=n(Aje,"A",{href:!0});var Wxt=s(QH);cmr=r(Wxt,"PoolFormerForImageClassification"),Wxt.forEach(t),fmr=r(Aje," (PoolFormer model)"),Aje.forEach(t),mmr=i(Fe),e9=n(Fe,"LI",{});var Lje=s(e9);pve=n(Lje,"STRONG",{});var Qxt=s(pve);gmr=r(Qxt,"regnet"),Qxt.forEach(t),hmr=r(Lje," \u2014 "),HH=n(Lje,"A",{href:!0});var Hxt=s(HH);pmr=r(Hxt,"RegNetForImageClassification"),Hxt.forEach(t),_mr=r(Lje," (RegNet model)"),Lje.forEach(t),umr=i(Fe),o9=n(Fe,"LI",{});var yje=s(o9);_ve=n(yje,"STRONG",{});var Uxt=s(_ve);bmr=r(Uxt,"resnet"),Uxt.forEach(t),vmr=r(yje," \u2014 "),UH=n(yje,"A",{href:!0});var Jxt=s(UH);Fmr=r(Jxt,"ResNetForImageClassification"),Jxt.forEach(t),Tmr=r(yje," (ResNet model)"),yje.forEach(t),Mmr=i(Fe),r9=n(Fe,"LI",{});var xje=s(r9);uve=n(xje,"STRONG",{});var Yxt=s(uve);Emr=r(Yxt,"segformer"),Yxt.forEach(t),Cmr=r(xje," \u2014 "),JH=n(xje,"A",{href:!0});var Kxt=s(JH);wmr=r(Kxt,"SegformerForImageClassification"),Kxt.forEach(t),Amr=r(xje," (SegFormer model)"),xje.forEach(t),Lmr=i(Fe),t9=n(Fe,"LI",{});var $je=s(t9);bve=n($je,"STRONG",{});var Zxt=s(bve);ymr=r(Zxt,"swin"),Zxt.forEach(t),xmr=r($je," \u2014 "),YH=n($je,"A",{href:!0});var e$t=s(YH);$mr=r(e$t,"SwinForImageClassification"),e$t.forEach(t),kmr=r($je," (Swin Transformer model)"),$je.forEach(t),Smr=i(Fe),a9=n(Fe,"LI",{});var kje=s(a9);vve=n(kje,"STRONG",{});var o$t=s(vve);Rmr=r(o$t,"swinv2"),o$t.forEach(t),Pmr=r(kje," \u2014 "),KH=n(kje,"A",{href:!0});var r$t=s(KH);Bmr=r(r$t,"Swinv2ForImageClassification"),r$t.forEach(t),Imr=r(kje," (Swin Transformer V2 model)"),kje.forEach(t),Nmr=i(Fe),n9=n(Fe,"LI",{});var Sje=s(n9);Fve=n(Sje,"STRONG",{});var t$t=s(Fve);qmr=r(t$t,"van"),t$t.forEach(t),jmr=r(Sje," \u2014 "),ZH=n(Sje,"A",{href:!0});var a$t=s(ZH);Dmr=r(a$t,"VanForImageClassification"),a$t.forEach(t),Gmr=r(Sje," (VAN model)"),Sje.forEach(t),Omr=i(Fe),s9=n(Fe,"LI",{});var Rje=s(s9);Tve=n(Rje,"STRONG",{});var n$t=s(Tve);Vmr=r(n$t,"vit"),n$t.forEach(t),Xmr=r(Rje," \u2014 "),eU=n(Rje,"A",{href:!0});var s$t=s(eU);zmr=r(s$t,"ViTForImageClassification"),s$t.forEach(t),Wmr=r(Rje," (ViT model)"),Rje.forEach(t),Fe.forEach(t),Qmr=i(Ma),l9=n(Ma,"P",{});var Pje=s(l9);Hmr=r(Pje,"The model is set in evaluation mode by default using "),Mve=n(Pje,"CODE",{});var l$t=s(Mve);Umr=r(l$t,"model.eval()"),l$t.forEach(t),Jmr=r(Pje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Eve=n(Pje,"CODE",{});var i$t=s(Eve);Ymr=r(i$t,"model.train()"),i$t.forEach(t),Pje.forEach(t),Kmr=i(Ma),T(i9.$$.fragment,Ma),Ma.forEach(t),Tl.forEach(t),MQe=i(f),Sd=n(f,"H2",{class:!0});var $Ue=s(Sd);d9=n($Ue,"A",{id:!0,class:!0,href:!0});var d$t=s(d9);Cve=n(d$t,"SPAN",{});var c$t=s(Cve);T(w8.$$.fragment,c$t),c$t.forEach(t),d$t.forEach(t),Zmr=i($Ue),wve=n($Ue,"SPAN",{});var f$t=s(wve);egr=r(f$t,"AutoModelForVideoClassification"),f$t.forEach(t),$Ue.forEach(t),EQe=i(f),zo=n(f,"DIV",{class:!0});var Ml=s(zo);T(A8.$$.fragment,Ml),ogr=i(Ml),Rd=n(Ml,"P",{});var $ae=s(Rd);rgr=r($ae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),oU=n($ae,"A",{href:!0});var m$t=s(oU);tgr=r(m$t,"from_pretrained()"),m$t.forEach(t),agr=r($ae," class method or the "),rU=n($ae,"A",{href:!0});var g$t=s(rU);ngr=r(g$t,"from_config()"),g$t.forEach(t),sgr=r($ae,` class
method.`),$ae.forEach(t),lgr=i(Ml),L8=n(Ml,"P",{});var kUe=s(L8);igr=r(kUe,"This class cannot be instantiated directly using "),Ave=n(kUe,"CODE",{});var h$t=s(Ave);dgr=r(h$t,"__init__()"),h$t.forEach(t),cgr=r(kUe," (throws an error)."),kUe.forEach(t),fgr=i(Ml),Et=n(Ml,"DIV",{class:!0});var bA=s(Et);T(y8.$$.fragment,bA),mgr=i(bA),Lve=n(bA,"P",{});var p$t=s(Lve);ggr=r(p$t,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),p$t.forEach(t),hgr=i(bA),Pd=n(bA,"P",{});var kae=s(Pd);pgr=r(kae,`Note:
Loading a model from its configuration file does `),yve=n(kae,"STRONG",{});var _$t=s(yve);_gr=r(_$t,"not"),_$t.forEach(t),ugr=r(kae,` load the model weights. It only affects the
model\u2019s configuration. Use `),tU=n(kae,"A",{href:!0});var u$t=s(tU);bgr=r(u$t,"from_pretrained()"),u$t.forEach(t),vgr=r(kae," to load the model weights."),kae.forEach(t),Fgr=i(bA),T(c9.$$.fragment,bA),bA.forEach(t),Tgr=i(Ml),co=n(Ml,"DIV",{class:!0});var Ea=s(co);T(x8.$$.fragment,Ea),Mgr=i(Ea),xve=n(Ea,"P",{});var b$t=s(xve);Egr=r(b$t,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),b$t.forEach(t),Cgr=i(Ea),Ka=n(Ea,"P",{});var vA=s(Ka);wgr=r(vA,"The model class to instantiate is selected based on the "),$ve=n(vA,"CODE",{});var v$t=s($ve);Agr=r(v$t,"model_type"),v$t.forEach(t),Lgr=r(vA,` property of the config object (either
passed as an argument or loaded from `),kve=n(vA,"CODE",{});var F$t=s(kve);ygr=r(F$t,"pretrained_model_name_or_path"),F$t.forEach(t),xgr=r(vA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sve=n(vA,"CODE",{});var T$t=s(Sve);$gr=r(T$t,"pretrained_model_name_or_path"),T$t.forEach(t),kgr=r(vA,":"),vA.forEach(t),Sgr=i(Ea),Rve=n(Ea,"UL",{});var M$t=s(Rve);f9=n(M$t,"LI",{});var Bje=s(f9);Pve=n(Bje,"STRONG",{});var E$t=s(Pve);Rgr=r(E$t,"videomae"),E$t.forEach(t),Pgr=r(Bje," \u2014 "),aU=n(Bje,"A",{href:!0});var C$t=s(aU);Bgr=r(C$t,"VideoMAEForVideoClassification"),C$t.forEach(t),Igr=r(Bje," (VideoMAE model)"),Bje.forEach(t),M$t.forEach(t),Ngr=i(Ea),m9=n(Ea,"P",{});var Ije=s(m9);qgr=r(Ije,"The model is set in evaluation mode by default using "),Bve=n(Ije,"CODE",{});var w$t=s(Bve);jgr=r(w$t,"model.eval()"),w$t.forEach(t),Dgr=r(Ije,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ive=n(Ije,"CODE",{});var A$t=s(Ive);Ggr=r(A$t,"model.train()"),A$t.forEach(t),Ije.forEach(t),Ogr=i(Ea),T(g9.$$.fragment,Ea),Ea.forEach(t),Ml.forEach(t),CQe=i(f),Bd=n(f,"H2",{class:!0});var SUe=s(Bd);h9=n(SUe,"A",{id:!0,class:!0,href:!0});var L$t=s(h9);Nve=n(L$t,"SPAN",{});var y$t=s(Nve);T($8.$$.fragment,y$t),y$t.forEach(t),L$t.forEach(t),Vgr=i(SUe),qve=n(SUe,"SPAN",{});var x$t=s(qve);Xgr=r(x$t,"AutoModelForVision2Seq"),x$t.forEach(t),SUe.forEach(t),wQe=i(f),Wo=n(f,"DIV",{class:!0});var El=s(Wo);T(k8.$$.fragment,El),zgr=i(El),Id=n(El,"P",{});var Sae=s(Id);Wgr=r(Sae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),nU=n(Sae,"A",{href:!0});var $$t=s(nU);Qgr=r($$t,"from_pretrained()"),$$t.forEach(t),Hgr=r(Sae," class method or the "),sU=n(Sae,"A",{href:!0});var k$t=s(sU);Ugr=r(k$t,"from_config()"),k$t.forEach(t),Jgr=r(Sae,` class
method.`),Sae.forEach(t),Ygr=i(El),S8=n(El,"P",{});var RUe=s(S8);Kgr=r(RUe,"This class cannot be instantiated directly using "),jve=n(RUe,"CODE",{});var S$t=s(jve);Zgr=r(S$t,"__init__()"),S$t.forEach(t),ehr=r(RUe," (throws an error)."),RUe.forEach(t),ohr=i(El),Ct=n(El,"DIV",{class:!0});var FA=s(Ct);T(R8.$$.fragment,FA),rhr=i(FA),Dve=n(FA,"P",{});var R$t=s(Dve);thr=r(R$t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),R$t.forEach(t),ahr=i(FA),Nd=n(FA,"P",{});var Rae=s(Nd);nhr=r(Rae,`Note:
Loading a model from its configuration file does `),Gve=n(Rae,"STRONG",{});var P$t=s(Gve);shr=r(P$t,"not"),P$t.forEach(t),lhr=r(Rae,` load the model weights. It only affects the
model\u2019s configuration. Use `),lU=n(Rae,"A",{href:!0});var B$t=s(lU);ihr=r(B$t,"from_pretrained()"),B$t.forEach(t),dhr=r(Rae," to load the model weights."),Rae.forEach(t),chr=i(FA),T(p9.$$.fragment,FA),FA.forEach(t),fhr=i(El),fo=n(El,"DIV",{class:!0});var Ca=s(fo);T(P8.$$.fragment,Ca),mhr=i(Ca),Ove=n(Ca,"P",{});var I$t=s(Ove);ghr=r(I$t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),I$t.forEach(t),hhr=i(Ca),Za=n(Ca,"P",{});var TA=s(Za);phr=r(TA,"The model class to instantiate is selected based on the "),Vve=n(TA,"CODE",{});var N$t=s(Vve);_hr=r(N$t,"model_type"),N$t.forEach(t),uhr=r(TA,` property of the config object (either
passed as an argument or loaded from `),Xve=n(TA,"CODE",{});var q$t=s(Xve);bhr=r(q$t,"pretrained_model_name_or_path"),q$t.forEach(t),vhr=r(TA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zve=n(TA,"CODE",{});var j$t=s(zve);Fhr=r(j$t,"pretrained_model_name_or_path"),j$t.forEach(t),Thr=r(TA,":"),TA.forEach(t),Mhr=i(Ca),Wve=n(Ca,"UL",{});var D$t=s(Wve);_9=n(D$t,"LI",{});var Nje=s(_9);Qve=n(Nje,"STRONG",{});var G$t=s(Qve);Ehr=r(G$t,"vision-encoder-decoder"),G$t.forEach(t),Chr=r(Nje," \u2014 "),iU=n(Nje,"A",{href:!0});var O$t=s(iU);whr=r(O$t,"VisionEncoderDecoderModel"),O$t.forEach(t),Ahr=r(Nje," (Vision Encoder decoder model)"),Nje.forEach(t),D$t.forEach(t),Lhr=i(Ca),u9=n(Ca,"P",{});var qje=s(u9);yhr=r(qje,"The model is set in evaluation mode by default using "),Hve=n(qje,"CODE",{});var V$t=s(Hve);xhr=r(V$t,"model.eval()"),V$t.forEach(t),$hr=r(qje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Uve=n(qje,"CODE",{});var X$t=s(Uve);khr=r(X$t,"model.train()"),X$t.forEach(t),qje.forEach(t),Shr=i(Ca),T(b9.$$.fragment,Ca),Ca.forEach(t),El.forEach(t),AQe=i(f),qd=n(f,"H2",{class:!0});var PUe=s(qd);v9=n(PUe,"A",{id:!0,class:!0,href:!0});var z$t=s(v9);Jve=n(z$t,"SPAN",{});var W$t=s(Jve);T(B8.$$.fragment,W$t),W$t.forEach(t),z$t.forEach(t),Rhr=i(PUe),Yve=n(PUe,"SPAN",{});var Q$t=s(Yve);Phr=r(Q$t,"AutoModelForVisualQuestionAnswering"),Q$t.forEach(t),PUe.forEach(t),LQe=i(f),Qo=n(f,"DIV",{class:!0});var Cl=s(Qo);T(I8.$$.fragment,Cl),Bhr=i(Cl),jd=n(Cl,"P",{});var Pae=s(jd);Ihr=r(Pae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),dU=n(Pae,"A",{href:!0});var H$t=s(dU);Nhr=r(H$t,"from_pretrained()"),H$t.forEach(t),qhr=r(Pae," class method or the "),cU=n(Pae,"A",{href:!0});var U$t=s(cU);jhr=r(U$t,"from_config()"),U$t.forEach(t),Dhr=r(Pae,` class
method.`),Pae.forEach(t),Ghr=i(Cl),N8=n(Cl,"P",{});var BUe=s(N8);Ohr=r(BUe,"This class cannot be instantiated directly using "),Kve=n(BUe,"CODE",{});var J$t=s(Kve);Vhr=r(J$t,"__init__()"),J$t.forEach(t),Xhr=r(BUe," (throws an error)."),BUe.forEach(t),zhr=i(Cl),wt=n(Cl,"DIV",{class:!0});var MA=s(wt);T(q8.$$.fragment,MA),Whr=i(MA),Zve=n(MA,"P",{});var Y$t=s(Zve);Qhr=r(Y$t,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Y$t.forEach(t),Hhr=i(MA),Dd=n(MA,"P",{});var Bae=s(Dd);Uhr=r(Bae,`Note:
Loading a model from its configuration file does `),eFe=n(Bae,"STRONG",{});var K$t=s(eFe);Jhr=r(K$t,"not"),K$t.forEach(t),Yhr=r(Bae,` load the model weights. It only affects the
model\u2019s configuration. Use `),fU=n(Bae,"A",{href:!0});var Z$t=s(fU);Khr=r(Z$t,"from_pretrained()"),Z$t.forEach(t),Zhr=r(Bae," to load the model weights."),Bae.forEach(t),epr=i(MA),T(F9.$$.fragment,MA),MA.forEach(t),opr=i(Cl),mo=n(Cl,"DIV",{class:!0});var wa=s(mo);T(j8.$$.fragment,wa),rpr=i(wa),oFe=n(wa,"P",{});var ekt=s(oFe);tpr=r(ekt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),ekt.forEach(t),apr=i(wa),en=n(wa,"P",{});var EA=s(en);npr=r(EA,"The model class to instantiate is selected based on the "),rFe=n(EA,"CODE",{});var okt=s(rFe);spr=r(okt,"model_type"),okt.forEach(t),lpr=r(EA,` property of the config object (either
passed as an argument or loaded from `),tFe=n(EA,"CODE",{});var rkt=s(tFe);ipr=r(rkt,"pretrained_model_name_or_path"),rkt.forEach(t),dpr=r(EA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aFe=n(EA,"CODE",{});var tkt=s(aFe);cpr=r(tkt,"pretrained_model_name_or_path"),tkt.forEach(t),fpr=r(EA,":"),EA.forEach(t),mpr=i(wa),nFe=n(wa,"UL",{});var akt=s(nFe);T9=n(akt,"LI",{});var jje=s(T9);sFe=n(jje,"STRONG",{});var nkt=s(sFe);gpr=r(nkt,"vilt"),nkt.forEach(t),hpr=r(jje," \u2014 "),mU=n(jje,"A",{href:!0});var skt=s(mU);ppr=r(skt,"ViltForQuestionAnswering"),skt.forEach(t),_pr=r(jje," (ViLT model)"),jje.forEach(t),akt.forEach(t),upr=i(wa),M9=n(wa,"P",{});var Dje=s(M9);bpr=r(Dje,"The model is set in evaluation mode by default using "),lFe=n(Dje,"CODE",{});var lkt=s(lFe);vpr=r(lkt,"model.eval()"),lkt.forEach(t),Fpr=r(Dje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),iFe=n(Dje,"CODE",{});var ikt=s(iFe);Tpr=r(ikt,"model.train()"),ikt.forEach(t),Dje.forEach(t),Mpr=i(wa),T(E9.$$.fragment,wa),wa.forEach(t),Cl.forEach(t),yQe=i(f),Gd=n(f,"H2",{class:!0});var IUe=s(Gd);C9=n(IUe,"A",{id:!0,class:!0,href:!0});var dkt=s(C9);dFe=n(dkt,"SPAN",{});var ckt=s(dFe);T(D8.$$.fragment,ckt),ckt.forEach(t),dkt.forEach(t),Epr=i(IUe),cFe=n(IUe,"SPAN",{});var fkt=s(cFe);Cpr=r(fkt,"AutoModelForAudioClassification"),fkt.forEach(t),IUe.forEach(t),xQe=i(f),Ho=n(f,"DIV",{class:!0});var wl=s(Ho);T(G8.$$.fragment,wl),wpr=i(wl),Od=n(wl,"P",{});var Iae=s(Od);Apr=r(Iae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),gU=n(Iae,"A",{href:!0});var mkt=s(gU);Lpr=r(mkt,"from_pretrained()"),mkt.forEach(t),ypr=r(Iae," class method or the "),hU=n(Iae,"A",{href:!0});var gkt=s(hU);xpr=r(gkt,"from_config()"),gkt.forEach(t),$pr=r(Iae,` class
method.`),Iae.forEach(t),kpr=i(wl),O8=n(wl,"P",{});var NUe=s(O8);Spr=r(NUe,"This class cannot be instantiated directly using "),fFe=n(NUe,"CODE",{});var hkt=s(fFe);Rpr=r(hkt,"__init__()"),hkt.forEach(t),Ppr=r(NUe," (throws an error)."),NUe.forEach(t),Bpr=i(wl),At=n(wl,"DIV",{class:!0});var CA=s(At);T(V8.$$.fragment,CA),Ipr=i(CA),mFe=n(CA,"P",{});var pkt=s(mFe);Npr=r(pkt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),pkt.forEach(t),qpr=i(CA),Vd=n(CA,"P",{});var Nae=s(Vd);jpr=r(Nae,`Note:
Loading a model from its configuration file does `),gFe=n(Nae,"STRONG",{});var _kt=s(gFe);Dpr=r(_kt,"not"),_kt.forEach(t),Gpr=r(Nae,` load the model weights. It only affects the
model\u2019s configuration. Use `),pU=n(Nae,"A",{href:!0});var ukt=s(pU);Opr=r(ukt,"from_pretrained()"),ukt.forEach(t),Vpr=r(Nae," to load the model weights."),Nae.forEach(t),Xpr=i(CA),T(w9.$$.fragment,CA),CA.forEach(t),zpr=i(wl),go=n(wl,"DIV",{class:!0});var Aa=s(go);T(X8.$$.fragment,Aa),Wpr=i(Aa),hFe=n(Aa,"P",{});var bkt=s(hFe);Qpr=r(bkt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),bkt.forEach(t),Hpr=i(Aa),on=n(Aa,"P",{});var wA=s(on);Upr=r(wA,"The model class to instantiate is selected based on the "),pFe=n(wA,"CODE",{});var vkt=s(pFe);Jpr=r(vkt,"model_type"),vkt.forEach(t),Ypr=r(wA,` property of the config object (either
passed as an argument or loaded from `),_Fe=n(wA,"CODE",{});var Fkt=s(_Fe);Kpr=r(Fkt,"pretrained_model_name_or_path"),Fkt.forEach(t),Zpr=r(wA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uFe=n(wA,"CODE",{});var Tkt=s(uFe);e_r=r(Tkt,"pretrained_model_name_or_path"),Tkt.forEach(t),o_r=r(wA,":"),wA.forEach(t),r_r=i(Aa),Pe=n(Aa,"UL",{});var We=s(Pe);A9=n(We,"LI",{});var Gje=s(A9);bFe=n(Gje,"STRONG",{});var Mkt=s(bFe);t_r=r(Mkt,"data2vec-audio"),Mkt.forEach(t),a_r=r(Gje," \u2014 "),_U=n(Gje,"A",{href:!0});var Ekt=s(_U);n_r=r(Ekt,"Data2VecAudioForSequenceClassification"),Ekt.forEach(t),s_r=r(Gje," (Data2VecAudio model)"),Gje.forEach(t),l_r=i(We),L9=n(We,"LI",{});var Oje=s(L9);vFe=n(Oje,"STRONG",{});var Ckt=s(vFe);i_r=r(Ckt,"hubert"),Ckt.forEach(t),d_r=r(Oje," \u2014 "),uU=n(Oje,"A",{href:!0});var wkt=s(uU);c_r=r(wkt,"HubertForSequenceClassification"),wkt.forEach(t),f_r=r(Oje," (Hubert model)"),Oje.forEach(t),m_r=i(We),y9=n(We,"LI",{});var Vje=s(y9);FFe=n(Vje,"STRONG",{});var Akt=s(FFe);g_r=r(Akt,"sew"),Akt.forEach(t),h_r=r(Vje," \u2014 "),bU=n(Vje,"A",{href:!0});var Lkt=s(bU);p_r=r(Lkt,"SEWForSequenceClassification"),Lkt.forEach(t),__r=r(Vje," (SEW model)"),Vje.forEach(t),u_r=i(We),x9=n(We,"LI",{});var Xje=s(x9);TFe=n(Xje,"STRONG",{});var ykt=s(TFe);b_r=r(ykt,"sew-d"),ykt.forEach(t),v_r=r(Xje," \u2014 "),vU=n(Xje,"A",{href:!0});var xkt=s(vU);F_r=r(xkt,"SEWDForSequenceClassification"),xkt.forEach(t),T_r=r(Xje," (SEW-D model)"),Xje.forEach(t),M_r=i(We),$9=n(We,"LI",{});var zje=s($9);MFe=n(zje,"STRONG",{});var $kt=s(MFe);E_r=r($kt,"unispeech"),$kt.forEach(t),C_r=r(zje," \u2014 "),FU=n(zje,"A",{href:!0});var kkt=s(FU);w_r=r(kkt,"UniSpeechForSequenceClassification"),kkt.forEach(t),A_r=r(zje," (UniSpeech model)"),zje.forEach(t),L_r=i(We),k9=n(We,"LI",{});var Wje=s(k9);EFe=n(Wje,"STRONG",{});var Skt=s(EFe);y_r=r(Skt,"unispeech-sat"),Skt.forEach(t),x_r=r(Wje," \u2014 "),TU=n(Wje,"A",{href:!0});var Rkt=s(TU);$_r=r(Rkt,"UniSpeechSatForSequenceClassification"),Rkt.forEach(t),k_r=r(Wje," (UniSpeechSat model)"),Wje.forEach(t),S_r=i(We),S9=n(We,"LI",{});var Qje=s(S9);CFe=n(Qje,"STRONG",{});var Pkt=s(CFe);R_r=r(Pkt,"wav2vec2"),Pkt.forEach(t),P_r=r(Qje," \u2014 "),MU=n(Qje,"A",{href:!0});var Bkt=s(MU);B_r=r(Bkt,"Wav2Vec2ForSequenceClassification"),Bkt.forEach(t),I_r=r(Qje," (Wav2Vec2 model)"),Qje.forEach(t),N_r=i(We),R9=n(We,"LI",{});var Hje=s(R9);wFe=n(Hje,"STRONG",{});var Ikt=s(wFe);q_r=r(Ikt,"wav2vec2-conformer"),Ikt.forEach(t),j_r=r(Hje," \u2014 "),EU=n(Hje,"A",{href:!0});var Nkt=s(EU);D_r=r(Nkt,"Wav2Vec2ConformerForSequenceClassification"),Nkt.forEach(t),G_r=r(Hje," (Wav2Vec2-Conformer model)"),Hje.forEach(t),O_r=i(We),P9=n(We,"LI",{});var Uje=s(P9);AFe=n(Uje,"STRONG",{});var qkt=s(AFe);V_r=r(qkt,"wavlm"),qkt.forEach(t),X_r=r(Uje," \u2014 "),CU=n(Uje,"A",{href:!0});var jkt=s(CU);z_r=r(jkt,"WavLMForSequenceClassification"),jkt.forEach(t),W_r=r(Uje," (WavLM model)"),Uje.forEach(t),We.forEach(t),Q_r=i(Aa),B9=n(Aa,"P",{});var Jje=s(B9);H_r=r(Jje,"The model is set in evaluation mode by default using "),LFe=n(Jje,"CODE",{});var Dkt=s(LFe);U_r=r(Dkt,"model.eval()"),Dkt.forEach(t),J_r=r(Jje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),yFe=n(Jje,"CODE",{});var Gkt=s(yFe);Y_r=r(Gkt,"model.train()"),Gkt.forEach(t),Jje.forEach(t),K_r=i(Aa),T(I9.$$.fragment,Aa),Aa.forEach(t),wl.forEach(t),$Qe=i(f),Xd=n(f,"H2",{class:!0});var qUe=s(Xd);N9=n(qUe,"A",{id:!0,class:!0,href:!0});var Okt=s(N9);xFe=n(Okt,"SPAN",{});var Vkt=s(xFe);T(z8.$$.fragment,Vkt),Vkt.forEach(t),Okt.forEach(t),Z_r=i(qUe),$Fe=n(qUe,"SPAN",{});var Xkt=s($Fe);eur=r(Xkt,"AutoModelForAudioFrameClassification"),Xkt.forEach(t),qUe.forEach(t),kQe=i(f),Uo=n(f,"DIV",{class:!0});var Al=s(Uo);T(W8.$$.fragment,Al),our=i(Al),zd=n(Al,"P",{});var qae=s(zd);rur=r(qae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),wU=n(qae,"A",{href:!0});var zkt=s(wU);tur=r(zkt,"from_pretrained()"),zkt.forEach(t),aur=r(qae," class method or the "),AU=n(qae,"A",{href:!0});var Wkt=s(AU);nur=r(Wkt,"from_config()"),Wkt.forEach(t),sur=r(qae,` class
method.`),qae.forEach(t),lur=i(Al),Q8=n(Al,"P",{});var jUe=s(Q8);iur=r(jUe,"This class cannot be instantiated directly using "),kFe=n(jUe,"CODE",{});var Qkt=s(kFe);dur=r(Qkt,"__init__()"),Qkt.forEach(t),cur=r(jUe," (throws an error)."),jUe.forEach(t),fur=i(Al),Lt=n(Al,"DIV",{class:!0});var AA=s(Lt);T(H8.$$.fragment,AA),mur=i(AA),SFe=n(AA,"P",{});var Hkt=s(SFe);gur=r(Hkt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),Hkt.forEach(t),hur=i(AA),Wd=n(AA,"P",{});var jae=s(Wd);pur=r(jae,`Note:
Loading a model from its configuration file does `),RFe=n(jae,"STRONG",{});var Ukt=s(RFe);_ur=r(Ukt,"not"),Ukt.forEach(t),uur=r(jae,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(jae,"A",{href:!0});var Jkt=s(LU);bur=r(Jkt,"from_pretrained()"),Jkt.forEach(t),vur=r(jae," to load the model weights."),jae.forEach(t),Fur=i(AA),T(q9.$$.fragment,AA),AA.forEach(t),Tur=i(Al),ho=n(Al,"DIV",{class:!0});var La=s(ho);T(U8.$$.fragment,La),Mur=i(La),PFe=n(La,"P",{});var Ykt=s(PFe);Eur=r(Ykt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),Ykt.forEach(t),Cur=i(La),rn=n(La,"P",{});var LA=s(rn);wur=r(LA,"The model class to instantiate is selected based on the "),BFe=n(LA,"CODE",{});var Kkt=s(BFe);Aur=r(Kkt,"model_type"),Kkt.forEach(t),Lur=r(LA,` property of the config object (either
passed as an argument or loaded from `),IFe=n(LA,"CODE",{});var Zkt=s(IFe);yur=r(Zkt,"pretrained_model_name_or_path"),Zkt.forEach(t),xur=r(LA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NFe=n(LA,"CODE",{});var eSt=s(NFe);$ur=r(eSt,"pretrained_model_name_or_path"),eSt.forEach(t),kur=r(LA,":"),LA.forEach(t),Sur=i(La),at=n(La,"UL",{});var Ll=s(at);j9=n(Ll,"LI",{});var Yje=s(j9);qFe=n(Yje,"STRONG",{});var oSt=s(qFe);Rur=r(oSt,"data2vec-audio"),oSt.forEach(t),Pur=r(Yje," \u2014 "),yU=n(Yje,"A",{href:!0});var rSt=s(yU);Bur=r(rSt,"Data2VecAudioForAudioFrameClassification"),rSt.forEach(t),Iur=r(Yje," (Data2VecAudio model)"),Yje.forEach(t),Nur=i(Ll),D9=n(Ll,"LI",{});var Kje=s(D9);jFe=n(Kje,"STRONG",{});var tSt=s(jFe);qur=r(tSt,"unispeech-sat"),tSt.forEach(t),jur=r(Kje," \u2014 "),xU=n(Kje,"A",{href:!0});var aSt=s(xU);Dur=r(aSt,"UniSpeechSatForAudioFrameClassification"),aSt.forEach(t),Gur=r(Kje," (UniSpeechSat model)"),Kje.forEach(t),Our=i(Ll),G9=n(Ll,"LI",{});var Zje=s(G9);DFe=n(Zje,"STRONG",{});var nSt=s(DFe);Vur=r(nSt,"wav2vec2"),nSt.forEach(t),Xur=r(Zje," \u2014 "),$U=n(Zje,"A",{href:!0});var sSt=s($U);zur=r(sSt,"Wav2Vec2ForAudioFrameClassification"),sSt.forEach(t),Wur=r(Zje," (Wav2Vec2 model)"),Zje.forEach(t),Qur=i(Ll),O9=n(Ll,"LI",{});var eDe=s(O9);GFe=n(eDe,"STRONG",{});var lSt=s(GFe);Hur=r(lSt,"wav2vec2-conformer"),lSt.forEach(t),Uur=r(eDe," \u2014 "),kU=n(eDe,"A",{href:!0});var iSt=s(kU);Jur=r(iSt,"Wav2Vec2ConformerForAudioFrameClassification"),iSt.forEach(t),Yur=r(eDe," (Wav2Vec2-Conformer model)"),eDe.forEach(t),Kur=i(Ll),V9=n(Ll,"LI",{});var oDe=s(V9);OFe=n(oDe,"STRONG",{});var dSt=s(OFe);Zur=r(dSt,"wavlm"),dSt.forEach(t),e7r=r(oDe," \u2014 "),SU=n(oDe,"A",{href:!0});var cSt=s(SU);o7r=r(cSt,"WavLMForAudioFrameClassification"),cSt.forEach(t),r7r=r(oDe," (WavLM model)"),oDe.forEach(t),Ll.forEach(t),t7r=i(La),X9=n(La,"P",{});var rDe=s(X9);a7r=r(rDe,"The model is set in evaluation mode by default using "),VFe=n(rDe,"CODE",{});var fSt=s(VFe);n7r=r(fSt,"model.eval()"),fSt.forEach(t),s7r=r(rDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),XFe=n(rDe,"CODE",{});var mSt=s(XFe);l7r=r(mSt,"model.train()"),mSt.forEach(t),rDe.forEach(t),i7r=i(La),T(z9.$$.fragment,La),La.forEach(t),Al.forEach(t),SQe=i(f),Qd=n(f,"H2",{class:!0});var DUe=s(Qd);W9=n(DUe,"A",{id:!0,class:!0,href:!0});var gSt=s(W9);zFe=n(gSt,"SPAN",{});var hSt=s(zFe);T(J8.$$.fragment,hSt),hSt.forEach(t),gSt.forEach(t),d7r=i(DUe),WFe=n(DUe,"SPAN",{});var pSt=s(WFe);c7r=r(pSt,"AutoModelForCTC"),pSt.forEach(t),DUe.forEach(t),RQe=i(f),Jo=n(f,"DIV",{class:!0});var yl=s(Jo);T(Y8.$$.fragment,yl),f7r=i(yl),Hd=n(yl,"P",{});var Dae=s(Hd);m7r=r(Dae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),RU=n(Dae,"A",{href:!0});var _St=s(RU);g7r=r(_St,"from_pretrained()"),_St.forEach(t),h7r=r(Dae," class method or the "),PU=n(Dae,"A",{href:!0});var uSt=s(PU);p7r=r(uSt,"from_config()"),uSt.forEach(t),_7r=r(Dae,` class
method.`),Dae.forEach(t),u7r=i(yl),K8=n(yl,"P",{});var GUe=s(K8);b7r=r(GUe,"This class cannot be instantiated directly using "),QFe=n(GUe,"CODE",{});var bSt=s(QFe);v7r=r(bSt,"__init__()"),bSt.forEach(t),F7r=r(GUe," (throws an error)."),GUe.forEach(t),T7r=i(yl),yt=n(yl,"DIV",{class:!0});var yA=s(yt);T(Z8.$$.fragment,yA),M7r=i(yA),HFe=n(yA,"P",{});var vSt=s(HFe);E7r=r(vSt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),vSt.forEach(t),C7r=i(yA),Ud=n(yA,"P",{});var Gae=s(Ud);w7r=r(Gae,`Note:
Loading a model from its configuration file does `),UFe=n(Gae,"STRONG",{});var FSt=s(UFe);A7r=r(FSt,"not"),FSt.forEach(t),L7r=r(Gae,` load the model weights. It only affects the
model\u2019s configuration. Use `),BU=n(Gae,"A",{href:!0});var TSt=s(BU);y7r=r(TSt,"from_pretrained()"),TSt.forEach(t),x7r=r(Gae," to load the model weights."),Gae.forEach(t),$7r=i(yA),T(Q9.$$.fragment,yA),yA.forEach(t),k7r=i(yl),po=n(yl,"DIV",{class:!0});var ya=s(po);T(ex.$$.fragment,ya),S7r=i(ya),JFe=n(ya,"P",{});var MSt=s(JFe);R7r=r(MSt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),MSt.forEach(t),P7r=i(ya),tn=n(ya,"P",{});var xA=s(tn);B7r=r(xA,"The model class to instantiate is selected based on the "),YFe=n(xA,"CODE",{});var ESt=s(YFe);I7r=r(ESt,"model_type"),ESt.forEach(t),N7r=r(xA,` property of the config object (either
passed as an argument or loaded from `),KFe=n(xA,"CODE",{});var CSt=s(KFe);q7r=r(CSt,"pretrained_model_name_or_path"),CSt.forEach(t),j7r=r(xA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ZFe=n(xA,"CODE",{});var wSt=s(ZFe);D7r=r(wSt,"pretrained_model_name_or_path"),wSt.forEach(t),G7r=r(xA,":"),xA.forEach(t),O7r=i(ya),Le=n(ya,"UL",{});var Be=s(Le);H9=n(Be,"LI",{});var tDe=s(H9);eTe=n(tDe,"STRONG",{});var ASt=s(eTe);V7r=r(ASt,"data2vec-audio"),ASt.forEach(t),X7r=r(tDe," \u2014 "),IU=n(tDe,"A",{href:!0});var LSt=s(IU);z7r=r(LSt,"Data2VecAudioForCTC"),LSt.forEach(t),W7r=r(tDe," (Data2VecAudio model)"),tDe.forEach(t),Q7r=i(Be),U9=n(Be,"LI",{});var aDe=s(U9);oTe=n(aDe,"STRONG",{});var ySt=s(oTe);H7r=r(ySt,"hubert"),ySt.forEach(t),U7r=r(aDe," \u2014 "),NU=n(aDe,"A",{href:!0});var xSt=s(NU);J7r=r(xSt,"HubertForCTC"),xSt.forEach(t),Y7r=r(aDe," (Hubert model)"),aDe.forEach(t),K7r=i(Be),J9=n(Be,"LI",{});var nDe=s(J9);rTe=n(nDe,"STRONG",{});var $St=s(rTe);Z7r=r($St,"mctct"),$St.forEach(t),e1r=r(nDe," \u2014 "),qU=n(nDe,"A",{href:!0});var kSt=s(qU);o1r=r(kSt,"MCTCTForCTC"),kSt.forEach(t),r1r=r(nDe," (M-CTC-T model)"),nDe.forEach(t),t1r=i(Be),Y9=n(Be,"LI",{});var sDe=s(Y9);tTe=n(sDe,"STRONG",{});var SSt=s(tTe);a1r=r(SSt,"sew"),SSt.forEach(t),n1r=r(sDe," \u2014 "),jU=n(sDe,"A",{href:!0});var RSt=s(jU);s1r=r(RSt,"SEWForCTC"),RSt.forEach(t),l1r=r(sDe," (SEW model)"),sDe.forEach(t),i1r=i(Be),K9=n(Be,"LI",{});var lDe=s(K9);aTe=n(lDe,"STRONG",{});var PSt=s(aTe);d1r=r(PSt,"sew-d"),PSt.forEach(t),c1r=r(lDe," \u2014 "),DU=n(lDe,"A",{href:!0});var BSt=s(DU);f1r=r(BSt,"SEWDForCTC"),BSt.forEach(t),m1r=r(lDe," (SEW-D model)"),lDe.forEach(t),g1r=i(Be),Z9=n(Be,"LI",{});var iDe=s(Z9);nTe=n(iDe,"STRONG",{});var ISt=s(nTe);h1r=r(ISt,"unispeech"),ISt.forEach(t),p1r=r(iDe," \u2014 "),GU=n(iDe,"A",{href:!0});var NSt=s(GU);_1r=r(NSt,"UniSpeechForCTC"),NSt.forEach(t),u1r=r(iDe," (UniSpeech model)"),iDe.forEach(t),b1r=i(Be),eM=n(Be,"LI",{});var dDe=s(eM);sTe=n(dDe,"STRONG",{});var qSt=s(sTe);v1r=r(qSt,"unispeech-sat"),qSt.forEach(t),F1r=r(dDe," \u2014 "),OU=n(dDe,"A",{href:!0});var jSt=s(OU);T1r=r(jSt,"UniSpeechSatForCTC"),jSt.forEach(t),M1r=r(dDe," (UniSpeechSat model)"),dDe.forEach(t),E1r=i(Be),oM=n(Be,"LI",{});var cDe=s(oM);lTe=n(cDe,"STRONG",{});var DSt=s(lTe);C1r=r(DSt,"wav2vec2"),DSt.forEach(t),w1r=r(cDe," \u2014 "),VU=n(cDe,"A",{href:!0});var GSt=s(VU);A1r=r(GSt,"Wav2Vec2ForCTC"),GSt.forEach(t),L1r=r(cDe," (Wav2Vec2 model)"),cDe.forEach(t),y1r=i(Be),rM=n(Be,"LI",{});var fDe=s(rM);iTe=n(fDe,"STRONG",{});var OSt=s(iTe);x1r=r(OSt,"wav2vec2-conformer"),OSt.forEach(t),$1r=r(fDe," \u2014 "),XU=n(fDe,"A",{href:!0});var VSt=s(XU);k1r=r(VSt,"Wav2Vec2ConformerForCTC"),VSt.forEach(t),S1r=r(fDe," (Wav2Vec2-Conformer model)"),fDe.forEach(t),R1r=i(Be),tM=n(Be,"LI",{});var mDe=s(tM);dTe=n(mDe,"STRONG",{});var XSt=s(dTe);P1r=r(XSt,"wavlm"),XSt.forEach(t),B1r=r(mDe," \u2014 "),zU=n(mDe,"A",{href:!0});var zSt=s(zU);I1r=r(zSt,"WavLMForCTC"),zSt.forEach(t),N1r=r(mDe," (WavLM model)"),mDe.forEach(t),Be.forEach(t),q1r=i(ya),aM=n(ya,"P",{});var gDe=s(aM);j1r=r(gDe,"The model is set in evaluation mode by default using "),cTe=n(gDe,"CODE",{});var WSt=s(cTe);D1r=r(WSt,"model.eval()"),WSt.forEach(t),G1r=r(gDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),fTe=n(gDe,"CODE",{});var QSt=s(fTe);O1r=r(QSt,"model.train()"),QSt.forEach(t),gDe.forEach(t),V1r=i(ya),T(nM.$$.fragment,ya),ya.forEach(t),yl.forEach(t),PQe=i(f),Jd=n(f,"H2",{class:!0});var OUe=s(Jd);sM=n(OUe,"A",{id:!0,class:!0,href:!0});var HSt=s(sM);mTe=n(HSt,"SPAN",{});var USt=s(mTe);T(ox.$$.fragment,USt),USt.forEach(t),HSt.forEach(t),X1r=i(OUe),gTe=n(OUe,"SPAN",{});var JSt=s(gTe);z1r=r(JSt,"AutoModelForSpeechSeq2Seq"),JSt.forEach(t),OUe.forEach(t),BQe=i(f),Yo=n(f,"DIV",{class:!0});var xl=s(Yo);T(rx.$$.fragment,xl),W1r=i(xl),Yd=n(xl,"P",{});var Oae=s(Yd);Q1r=r(Oae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),WU=n(Oae,"A",{href:!0});var YSt=s(WU);H1r=r(YSt,"from_pretrained()"),YSt.forEach(t),U1r=r(Oae," class method or the "),QU=n(Oae,"A",{href:!0});var KSt=s(QU);J1r=r(KSt,"from_config()"),KSt.forEach(t),Y1r=r(Oae,` class
method.`),Oae.forEach(t),K1r=i(xl),tx=n(xl,"P",{});var VUe=s(tx);Z1r=r(VUe,"This class cannot be instantiated directly using "),hTe=n(VUe,"CODE",{});var ZSt=s(hTe);e2r=r(ZSt,"__init__()"),ZSt.forEach(t),o2r=r(VUe," (throws an error)."),VUe.forEach(t),r2r=i(xl),xt=n(xl,"DIV",{class:!0});var $A=s(xt);T(ax.$$.fragment,$A),t2r=i($A),pTe=n($A,"P",{});var eRt=s(pTe);a2r=r(eRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),eRt.forEach(t),n2r=i($A),Kd=n($A,"P",{});var Vae=s(Kd);s2r=r(Vae,`Note:
Loading a model from its configuration file does `),_Te=n(Vae,"STRONG",{});var oRt=s(_Te);l2r=r(oRt,"not"),oRt.forEach(t),i2r=r(Vae,` load the model weights. It only affects the
model\u2019s configuration. Use `),HU=n(Vae,"A",{href:!0});var rRt=s(HU);d2r=r(rRt,"from_pretrained()"),rRt.forEach(t),c2r=r(Vae," to load the model weights."),Vae.forEach(t),f2r=i($A),T(lM.$$.fragment,$A),$A.forEach(t),m2r=i(xl),_o=n(xl,"DIV",{class:!0});var xa=s(_o);T(nx.$$.fragment,xa),g2r=i(xa),uTe=n(xa,"P",{});var tRt=s(uTe);h2r=r(tRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),tRt.forEach(t),p2r=i(xa),an=n(xa,"P",{});var kA=s(an);_2r=r(kA,"The model class to instantiate is selected based on the "),bTe=n(kA,"CODE",{});var aRt=s(bTe);u2r=r(aRt,"model_type"),aRt.forEach(t),b2r=r(kA,` property of the config object (either
passed as an argument or loaded from `),vTe=n(kA,"CODE",{});var nRt=s(vTe);v2r=r(nRt,"pretrained_model_name_or_path"),nRt.forEach(t),F2r=r(kA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FTe=n(kA,"CODE",{});var sRt=s(FTe);T2r=r(sRt,"pretrained_model_name_or_path"),sRt.forEach(t),M2r=r(kA,":"),kA.forEach(t),E2r=i(xa),sx=n(xa,"UL",{});var XUe=s(sx);iM=n(XUe,"LI",{});var hDe=s(iM);TTe=n(hDe,"STRONG",{});var lRt=s(TTe);C2r=r(lRt,"speech-encoder-decoder"),lRt.forEach(t),w2r=r(hDe," \u2014 "),UU=n(hDe,"A",{href:!0});var iRt=s(UU);A2r=r(iRt,"SpeechEncoderDecoderModel"),iRt.forEach(t),L2r=r(hDe," (Speech Encoder decoder model)"),hDe.forEach(t),y2r=i(XUe),dM=n(XUe,"LI",{});var pDe=s(dM);MTe=n(pDe,"STRONG",{});var dRt=s(MTe);x2r=r(dRt,"speech_to_text"),dRt.forEach(t),$2r=r(pDe," \u2014 "),JU=n(pDe,"A",{href:!0});var cRt=s(JU);k2r=r(cRt,"Speech2TextForConditionalGeneration"),cRt.forEach(t),S2r=r(pDe," (Speech2Text model)"),pDe.forEach(t),XUe.forEach(t),R2r=i(xa),cM=n(xa,"P",{});var _De=s(cM);P2r=r(_De,"The model is set in evaluation mode by default using "),ETe=n(_De,"CODE",{});var fRt=s(ETe);B2r=r(fRt,"model.eval()"),fRt.forEach(t),I2r=r(_De,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),CTe=n(_De,"CODE",{});var mRt=s(CTe);N2r=r(mRt,"model.train()"),mRt.forEach(t),_De.forEach(t),q2r=i(xa),T(fM.$$.fragment,xa),xa.forEach(t),xl.forEach(t),IQe=i(f),Zd=n(f,"H2",{class:!0});var zUe=s(Zd);mM=n(zUe,"A",{id:!0,class:!0,href:!0});var gRt=s(mM);wTe=n(gRt,"SPAN",{});var hRt=s(wTe);T(lx.$$.fragment,hRt),hRt.forEach(t),gRt.forEach(t),j2r=i(zUe),ATe=n(zUe,"SPAN",{});var pRt=s(ATe);D2r=r(pRt,"AutoModelForAudioXVector"),pRt.forEach(t),zUe.forEach(t),NQe=i(f),Ko=n(f,"DIV",{class:!0});var $l=s(Ko);T(ix.$$.fragment,$l),G2r=i($l),ec=n($l,"P",{});var Xae=s(ec);O2r=r(Xae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),YU=n(Xae,"A",{href:!0});var _Rt=s(YU);V2r=r(_Rt,"from_pretrained()"),_Rt.forEach(t),X2r=r(Xae," class method or the "),KU=n(Xae,"A",{href:!0});var uRt=s(KU);z2r=r(uRt,"from_config()"),uRt.forEach(t),W2r=r(Xae,` class
method.`),Xae.forEach(t),Q2r=i($l),dx=n($l,"P",{});var WUe=s(dx);H2r=r(WUe,"This class cannot be instantiated directly using "),LTe=n(WUe,"CODE",{});var bRt=s(LTe);U2r=r(bRt,"__init__()"),bRt.forEach(t),J2r=r(WUe," (throws an error)."),WUe.forEach(t),Y2r=i($l),$t=n($l,"DIV",{class:!0});var SA=s($t);T(cx.$$.fragment,SA),K2r=i(SA),yTe=n(SA,"P",{});var vRt=s(yTe);Z2r=r(vRt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),vRt.forEach(t),ebr=i(SA),oc=n(SA,"P",{});var zae=s(oc);obr=r(zae,`Note:
Loading a model from its configuration file does `),xTe=n(zae,"STRONG",{});var FRt=s(xTe);rbr=r(FRt,"not"),FRt.forEach(t),tbr=r(zae,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZU=n(zae,"A",{href:!0});var TRt=s(ZU);abr=r(TRt,"from_pretrained()"),TRt.forEach(t),nbr=r(zae," to load the model weights."),zae.forEach(t),sbr=i(SA),T(gM.$$.fragment,SA),SA.forEach(t),lbr=i($l),uo=n($l,"DIV",{class:!0});var $a=s(uo);T(fx.$$.fragment,$a),ibr=i($a),$Te=n($a,"P",{});var MRt=s($Te);dbr=r(MRt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),MRt.forEach(t),cbr=i($a),nn=n($a,"P",{});var RA=s(nn);fbr=r(RA,"The model class to instantiate is selected based on the "),kTe=n(RA,"CODE",{});var ERt=s(kTe);mbr=r(ERt,"model_type"),ERt.forEach(t),gbr=r(RA,` property of the config object (either
passed as an argument or loaded from `),STe=n(RA,"CODE",{});var CRt=s(STe);hbr=r(CRt,"pretrained_model_name_or_path"),CRt.forEach(t),pbr=r(RA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),RTe=n(RA,"CODE",{});var wRt=s(RTe);_br=r(wRt,"pretrained_model_name_or_path"),wRt.forEach(t),ubr=r(RA,":"),RA.forEach(t),bbr=i($a),nt=n($a,"UL",{});var kl=s(nt);hM=n(kl,"LI",{});var uDe=s(hM);PTe=n(uDe,"STRONG",{});var ARt=s(PTe);vbr=r(ARt,"data2vec-audio"),ARt.forEach(t),Fbr=r(uDe," \u2014 "),eJ=n(uDe,"A",{href:!0});var LRt=s(eJ);Tbr=r(LRt,"Data2VecAudioForXVector"),LRt.forEach(t),Mbr=r(uDe," (Data2VecAudio model)"),uDe.forEach(t),Ebr=i(kl),pM=n(kl,"LI",{});var bDe=s(pM);BTe=n(bDe,"STRONG",{});var yRt=s(BTe);Cbr=r(yRt,"unispeech-sat"),yRt.forEach(t),wbr=r(bDe," \u2014 "),oJ=n(bDe,"A",{href:!0});var xRt=s(oJ);Abr=r(xRt,"UniSpeechSatForXVector"),xRt.forEach(t),Lbr=r(bDe," (UniSpeechSat model)"),bDe.forEach(t),ybr=i(kl),_M=n(kl,"LI",{});var vDe=s(_M);ITe=n(vDe,"STRONG",{});var $Rt=s(ITe);xbr=r($Rt,"wav2vec2"),$Rt.forEach(t),$br=r(vDe," \u2014 "),rJ=n(vDe,"A",{href:!0});var kRt=s(rJ);kbr=r(kRt,"Wav2Vec2ForXVector"),kRt.forEach(t),Sbr=r(vDe," (Wav2Vec2 model)"),vDe.forEach(t),Rbr=i(kl),uM=n(kl,"LI",{});var FDe=s(uM);NTe=n(FDe,"STRONG",{});var SRt=s(NTe);Pbr=r(SRt,"wav2vec2-conformer"),SRt.forEach(t),Bbr=r(FDe," \u2014 "),tJ=n(FDe,"A",{href:!0});var RRt=s(tJ);Ibr=r(RRt,"Wav2Vec2ConformerForXVector"),RRt.forEach(t),Nbr=r(FDe," (Wav2Vec2-Conformer model)"),FDe.forEach(t),qbr=i(kl),bM=n(kl,"LI",{});var TDe=s(bM);qTe=n(TDe,"STRONG",{});var PRt=s(qTe);jbr=r(PRt,"wavlm"),PRt.forEach(t),Dbr=r(TDe," \u2014 "),aJ=n(TDe,"A",{href:!0});var BRt=s(aJ);Gbr=r(BRt,"WavLMForXVector"),BRt.forEach(t),Obr=r(TDe," (WavLM model)"),TDe.forEach(t),kl.forEach(t),Vbr=i($a),vM=n($a,"P",{});var MDe=s(vM);Xbr=r(MDe,"The model is set in evaluation mode by default using "),jTe=n(MDe,"CODE",{});var IRt=s(jTe);zbr=r(IRt,"model.eval()"),IRt.forEach(t),Wbr=r(MDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),DTe=n(MDe,"CODE",{});var NRt=s(DTe);Qbr=r(NRt,"model.train()"),NRt.forEach(t),MDe.forEach(t),Hbr=i($a),T(FM.$$.fragment,$a),$a.forEach(t),$l.forEach(t),qQe=i(f),rc=n(f,"H2",{class:!0});var QUe=s(rc);TM=n(QUe,"A",{id:!0,class:!0,href:!0});var qRt=s(TM);GTe=n(qRt,"SPAN",{});var jRt=s(GTe);T(mx.$$.fragment,jRt),jRt.forEach(t),qRt.forEach(t),Ubr=i(QUe),OTe=n(QUe,"SPAN",{});var DRt=s(OTe);Jbr=r(DRt,"AutoModelForMaskedImageModeling"),DRt.forEach(t),QUe.forEach(t),jQe=i(f),Zo=n(f,"DIV",{class:!0});var Sl=s(Zo);T(gx.$$.fragment,Sl),Ybr=i(Sl),tc=n(Sl,"P",{});var Wae=s(tc);Kbr=r(Wae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),nJ=n(Wae,"A",{href:!0});var GRt=s(nJ);Zbr=r(GRt,"from_pretrained()"),GRt.forEach(t),evr=r(Wae," class method or the "),sJ=n(Wae,"A",{href:!0});var ORt=s(sJ);ovr=r(ORt,"from_config()"),ORt.forEach(t),rvr=r(Wae,` class
method.`),Wae.forEach(t),tvr=i(Sl),hx=n(Sl,"P",{});var HUe=s(hx);avr=r(HUe,"This class cannot be instantiated directly using "),VTe=n(HUe,"CODE",{});var VRt=s(VTe);nvr=r(VRt,"__init__()"),VRt.forEach(t),svr=r(HUe," (throws an error)."),HUe.forEach(t),lvr=i(Sl),kt=n(Sl,"DIV",{class:!0});var PA=s(kt);T(px.$$.fragment,PA),ivr=i(PA),XTe=n(PA,"P",{});var XRt=s(XTe);dvr=r(XRt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),XRt.forEach(t),cvr=i(PA),ac=n(PA,"P",{});var Qae=s(ac);fvr=r(Qae,`Note:
Loading a model from its configuration file does `),zTe=n(Qae,"STRONG",{});var zRt=s(zTe);mvr=r(zRt,"not"),zRt.forEach(t),gvr=r(Qae,` load the model weights. It only affects the
model\u2019s configuration. Use `),lJ=n(Qae,"A",{href:!0});var WRt=s(lJ);hvr=r(WRt,"from_pretrained()"),WRt.forEach(t),pvr=r(Qae," to load the model weights."),Qae.forEach(t),_vr=i(PA),T(MM.$$.fragment,PA),PA.forEach(t),uvr=i(Sl),bo=n(Sl,"DIV",{class:!0});var ka=s(bo);T(_x.$$.fragment,ka),bvr=i(ka),WTe=n(ka,"P",{});var QRt=s(WTe);vvr=r(QRt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),QRt.forEach(t),Fvr=i(ka),sn=n(ka,"P",{});var BA=s(sn);Tvr=r(BA,"The model class to instantiate is selected based on the "),QTe=n(BA,"CODE",{});var HRt=s(QTe);Mvr=r(HRt,"model_type"),HRt.forEach(t),Evr=r(BA,` property of the config object (either
passed as an argument or loaded from `),HTe=n(BA,"CODE",{});var URt=s(HTe);Cvr=r(URt,"pretrained_model_name_or_path"),URt.forEach(t),wvr=r(BA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UTe=n(BA,"CODE",{});var JRt=s(UTe);Avr=r(JRt,"pretrained_model_name_or_path"),JRt.forEach(t),Lvr=r(BA,":"),BA.forEach(t),yvr=i(ka),ln=n(ka,"UL",{});var IA=s(ln);EM=n(IA,"LI",{});var EDe=s(EM);JTe=n(EDe,"STRONG",{});var YRt=s(JTe);xvr=r(YRt,"deit"),YRt.forEach(t),$vr=r(EDe," \u2014 "),iJ=n(EDe,"A",{href:!0});var KRt=s(iJ);kvr=r(KRt,"DeiTForMaskedImageModeling"),KRt.forEach(t),Svr=r(EDe," (DeiT model)"),EDe.forEach(t),Rvr=i(IA),CM=n(IA,"LI",{});var CDe=s(CM);YTe=n(CDe,"STRONG",{});var ZRt=s(YTe);Pvr=r(ZRt,"swin"),ZRt.forEach(t),Bvr=r(CDe," \u2014 "),dJ=n(CDe,"A",{href:!0});var ePt=s(dJ);Ivr=r(ePt,"SwinForMaskedImageModeling"),ePt.forEach(t),Nvr=r(CDe," (Swin Transformer model)"),CDe.forEach(t),qvr=i(IA),wM=n(IA,"LI",{});var wDe=s(wM);KTe=n(wDe,"STRONG",{});var oPt=s(KTe);jvr=r(oPt,"swinv2"),oPt.forEach(t),Dvr=r(wDe," \u2014 "),cJ=n(wDe,"A",{href:!0});var rPt=s(cJ);Gvr=r(rPt,"Swinv2ForMaskedImageModeling"),rPt.forEach(t),Ovr=r(wDe," (Swin Transformer V2 model)"),wDe.forEach(t),Vvr=i(IA),AM=n(IA,"LI",{});var ADe=s(AM);ZTe=n(ADe,"STRONG",{});var tPt=s(ZTe);Xvr=r(tPt,"vit"),tPt.forEach(t),zvr=r(ADe," \u2014 "),fJ=n(ADe,"A",{href:!0});var aPt=s(fJ);Wvr=r(aPt,"ViTForMaskedImageModeling"),aPt.forEach(t),Qvr=r(ADe," (ViT model)"),ADe.forEach(t),IA.forEach(t),Hvr=i(ka),LM=n(ka,"P",{});var LDe=s(LM);Uvr=r(LDe,"The model is set in evaluation mode by default using "),e9e=n(LDe,"CODE",{});var nPt=s(e9e);Jvr=r(nPt,"model.eval()"),nPt.forEach(t),Yvr=r(LDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),o9e=n(LDe,"CODE",{});var sPt=s(o9e);Kvr=r(sPt,"model.train()"),sPt.forEach(t),LDe.forEach(t),Zvr=i(ka),T(yM.$$.fragment,ka),ka.forEach(t),Sl.forEach(t),DQe=i(f),nc=n(f,"H2",{class:!0});var UUe=s(nc);xM=n(UUe,"A",{id:!0,class:!0,href:!0});var lPt=s(xM);r9e=n(lPt,"SPAN",{});var iPt=s(r9e);T(ux.$$.fragment,iPt),iPt.forEach(t),lPt.forEach(t),eFr=i(UUe),t9e=n(UUe,"SPAN",{});var dPt=s(t9e);oFr=r(dPt,"AutoModelForObjectDetection"),dPt.forEach(t),UUe.forEach(t),GQe=i(f),er=n(f,"DIV",{class:!0});var Rl=s(er);T(bx.$$.fragment,Rl),rFr=i(Rl),sc=n(Rl,"P",{});var Hae=s(sc);tFr=r(Hae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),mJ=n(Hae,"A",{href:!0});var cPt=s(mJ);aFr=r(cPt,"from_pretrained()"),cPt.forEach(t),nFr=r(Hae," class method or the "),gJ=n(Hae,"A",{href:!0});var fPt=s(gJ);sFr=r(fPt,"from_config()"),fPt.forEach(t),lFr=r(Hae,` class
method.`),Hae.forEach(t),iFr=i(Rl),vx=n(Rl,"P",{});var JUe=s(vx);dFr=r(JUe,"This class cannot be instantiated directly using "),a9e=n(JUe,"CODE",{});var mPt=s(a9e);cFr=r(mPt,"__init__()"),mPt.forEach(t),fFr=r(JUe," (throws an error)."),JUe.forEach(t),mFr=i(Rl),St=n(Rl,"DIV",{class:!0});var NA=s(St);T(Fx.$$.fragment,NA),gFr=i(NA),n9e=n(NA,"P",{});var gPt=s(n9e);hFr=r(gPt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),gPt.forEach(t),pFr=i(NA),lc=n(NA,"P",{});var Uae=s(lc);_Fr=r(Uae,`Note:
Loading a model from its configuration file does `),s9e=n(Uae,"STRONG",{});var hPt=s(s9e);uFr=r(hPt,"not"),hPt.forEach(t),bFr=r(Uae,` load the model weights. It only affects the
model\u2019s configuration. Use `),hJ=n(Uae,"A",{href:!0});var pPt=s(hJ);vFr=r(pPt,"from_pretrained()"),pPt.forEach(t),FFr=r(Uae," to load the model weights."),Uae.forEach(t),TFr=i(NA),T($M.$$.fragment,NA),NA.forEach(t),MFr=i(Rl),vo=n(Rl,"DIV",{class:!0});var Sa=s(vo);T(Tx.$$.fragment,Sa),EFr=i(Sa),l9e=n(Sa,"P",{});var _Pt=s(l9e);CFr=r(_Pt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),_Pt.forEach(t),wFr=i(Sa),dn=n(Sa,"P",{});var qA=s(dn);AFr=r(qA,"The model class to instantiate is selected based on the "),i9e=n(qA,"CODE",{});var uPt=s(i9e);LFr=r(uPt,"model_type"),uPt.forEach(t),yFr=r(qA,` property of the config object (either
passed as an argument or loaded from `),d9e=n(qA,"CODE",{});var bPt=s(d9e);xFr=r(bPt,"pretrained_model_name_or_path"),bPt.forEach(t),$Fr=r(qA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),c9e=n(qA,"CODE",{});var vPt=s(c9e);kFr=r(vPt,"pretrained_model_name_or_path"),vPt.forEach(t),SFr=r(qA,":"),qA.forEach(t),RFr=i(Sa),Mx=n(Sa,"UL",{});var YUe=s(Mx);kM=n(YUe,"LI",{});var yDe=s(kM);f9e=n(yDe,"STRONG",{});var FPt=s(f9e);PFr=r(FPt,"detr"),FPt.forEach(t),BFr=r(yDe," \u2014 "),pJ=n(yDe,"A",{href:!0});var TPt=s(pJ);IFr=r(TPt,"DetrForObjectDetection"),TPt.forEach(t),NFr=r(yDe," (DETR model)"),yDe.forEach(t),qFr=i(YUe),SM=n(YUe,"LI",{});var xDe=s(SM);m9e=n(xDe,"STRONG",{});var MPt=s(m9e);jFr=r(MPt,"yolos"),MPt.forEach(t),DFr=r(xDe," \u2014 "),_J=n(xDe,"A",{href:!0});var EPt=s(_J);GFr=r(EPt,"YolosForObjectDetection"),EPt.forEach(t),OFr=r(xDe," (YOLOS model)"),xDe.forEach(t),YUe.forEach(t),VFr=i(Sa),RM=n(Sa,"P",{});var $De=s(RM);XFr=r($De,"The model is set in evaluation mode by default using "),g9e=n($De,"CODE",{});var CPt=s(g9e);zFr=r(CPt,"model.eval()"),CPt.forEach(t),WFr=r($De,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),h9e=n($De,"CODE",{});var wPt=s(h9e);QFr=r(wPt,"model.train()"),wPt.forEach(t),$De.forEach(t),HFr=i(Sa),T(PM.$$.fragment,Sa),Sa.forEach(t),Rl.forEach(t),OQe=i(f),ic=n(f,"H2",{class:!0});var KUe=s(ic);BM=n(KUe,"A",{id:!0,class:!0,href:!0});var APt=s(BM);p9e=n(APt,"SPAN",{});var LPt=s(p9e);T(Ex.$$.fragment,LPt),LPt.forEach(t),APt.forEach(t),UFr=i(KUe),_9e=n(KUe,"SPAN",{});var yPt=s(_9e);JFr=r(yPt,"AutoModelForImageSegmentation"),yPt.forEach(t),KUe.forEach(t),VQe=i(f),or=n(f,"DIV",{class:!0});var Pl=s(or);T(Cx.$$.fragment,Pl),YFr=i(Pl),dc=n(Pl,"P",{});var Jae=s(dc);KFr=r(Jae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),uJ=n(Jae,"A",{href:!0});var xPt=s(uJ);ZFr=r(xPt,"from_pretrained()"),xPt.forEach(t),eTr=r(Jae," class method or the "),bJ=n(Jae,"A",{href:!0});var $Pt=s(bJ);oTr=r($Pt,"from_config()"),$Pt.forEach(t),rTr=r(Jae,` class
method.`),Jae.forEach(t),tTr=i(Pl),wx=n(Pl,"P",{});var ZUe=s(wx);aTr=r(ZUe,"This class cannot be instantiated directly using "),u9e=n(ZUe,"CODE",{});var kPt=s(u9e);nTr=r(kPt,"__init__()"),kPt.forEach(t),sTr=r(ZUe," (throws an error)."),ZUe.forEach(t),lTr=i(Pl),Rt=n(Pl,"DIV",{class:!0});var jA=s(Rt);T(Ax.$$.fragment,jA),iTr=i(jA),b9e=n(jA,"P",{});var SPt=s(b9e);dTr=r(SPt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),SPt.forEach(t),cTr=i(jA),cc=n(jA,"P",{});var Yae=s(cc);fTr=r(Yae,`Note:
Loading a model from its configuration file does `),v9e=n(Yae,"STRONG",{});var RPt=s(v9e);mTr=r(RPt,"not"),RPt.forEach(t),gTr=r(Yae,` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=n(Yae,"A",{href:!0});var PPt=s(vJ);hTr=r(PPt,"from_pretrained()"),PPt.forEach(t),pTr=r(Yae," to load the model weights."),Yae.forEach(t),_Tr=i(jA),T(IM.$$.fragment,jA),jA.forEach(t),uTr=i(Pl),Fo=n(Pl,"DIV",{class:!0});var Ra=s(Fo);T(Lx.$$.fragment,Ra),bTr=i(Ra),F9e=n(Ra,"P",{});var BPt=s(F9e);vTr=r(BPt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),BPt.forEach(t),FTr=i(Ra),cn=n(Ra,"P",{});var DA=s(cn);TTr=r(DA,"The model class to instantiate is selected based on the "),T9e=n(DA,"CODE",{});var IPt=s(T9e);MTr=r(IPt,"model_type"),IPt.forEach(t),ETr=r(DA,` property of the config object (either
passed as an argument or loaded from `),M9e=n(DA,"CODE",{});var NPt=s(M9e);CTr=r(NPt,"pretrained_model_name_or_path"),NPt.forEach(t),wTr=r(DA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),E9e=n(DA,"CODE",{});var qPt=s(E9e);ATr=r(qPt,"pretrained_model_name_or_path"),qPt.forEach(t),LTr=r(DA,":"),DA.forEach(t),yTr=i(Ra),C9e=n(Ra,"UL",{});var jPt=s(C9e);NM=n(jPt,"LI",{});var kDe=s(NM);w9e=n(kDe,"STRONG",{});var DPt=s(w9e);xTr=r(DPt,"detr"),DPt.forEach(t),$Tr=r(kDe," \u2014 "),FJ=n(kDe,"A",{href:!0});var GPt=s(FJ);kTr=r(GPt,"DetrForSegmentation"),GPt.forEach(t),STr=r(kDe," (DETR model)"),kDe.forEach(t),jPt.forEach(t),RTr=i(Ra),qM=n(Ra,"P",{});var SDe=s(qM);PTr=r(SDe,"The model is set in evaluation mode by default using "),A9e=n(SDe,"CODE",{});var OPt=s(A9e);BTr=r(OPt,"model.eval()"),OPt.forEach(t),ITr=r(SDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L9e=n(SDe,"CODE",{});var VPt=s(L9e);NTr=r(VPt,"model.train()"),VPt.forEach(t),SDe.forEach(t),qTr=i(Ra),T(jM.$$.fragment,Ra),Ra.forEach(t),Pl.forEach(t),XQe=i(f),fc=n(f,"H2",{class:!0});var eJe=s(fc);DM=n(eJe,"A",{id:!0,class:!0,href:!0});var XPt=s(DM);y9e=n(XPt,"SPAN",{});var zPt=s(y9e);T(yx.$$.fragment,zPt),zPt.forEach(t),XPt.forEach(t),jTr=i(eJe),x9e=n(eJe,"SPAN",{});var WPt=s(x9e);DTr=r(WPt,"AutoModelForSemanticSegmentation"),WPt.forEach(t),eJe.forEach(t),zQe=i(f),rr=n(f,"DIV",{class:!0});var Bl=s(rr);T(xx.$$.fragment,Bl),GTr=i(Bl),mc=n(Bl,"P",{});var Kae=s(mc);OTr=r(Kae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),TJ=n(Kae,"A",{href:!0});var QPt=s(TJ);VTr=r(QPt,"from_pretrained()"),QPt.forEach(t),XTr=r(Kae," class method or the "),MJ=n(Kae,"A",{href:!0});var HPt=s(MJ);zTr=r(HPt,"from_config()"),HPt.forEach(t),WTr=r(Kae,` class
method.`),Kae.forEach(t),QTr=i(Bl),$x=n(Bl,"P",{});var oJe=s($x);HTr=r(oJe,"This class cannot be instantiated directly using "),$9e=n(oJe,"CODE",{});var UPt=s($9e);UTr=r(UPt,"__init__()"),UPt.forEach(t),JTr=r(oJe," (throws an error)."),oJe.forEach(t),YTr=i(Bl),Pt=n(Bl,"DIV",{class:!0});var GA=s(Pt);T(kx.$$.fragment,GA),KTr=i(GA),k9e=n(GA,"P",{});var JPt=s(k9e);ZTr=r(JPt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),JPt.forEach(t),e9r=i(GA),gc=n(GA,"P",{});var Zae=s(gc);o9r=r(Zae,`Note:
Loading a model from its configuration file does `),S9e=n(Zae,"STRONG",{});var YPt=s(S9e);r9r=r(YPt,"not"),YPt.forEach(t),t9r=r(Zae,` load the model weights. It only affects the
model\u2019s configuration. Use `),EJ=n(Zae,"A",{href:!0});var KPt=s(EJ);a9r=r(KPt,"from_pretrained()"),KPt.forEach(t),n9r=r(Zae," to load the model weights."),Zae.forEach(t),s9r=i(GA),T(GM.$$.fragment,GA),GA.forEach(t),l9r=i(Bl),To=n(Bl,"DIV",{class:!0});var Pa=s(To);T(Sx.$$.fragment,Pa),i9r=i(Pa),R9e=n(Pa,"P",{});var ZPt=s(R9e);d9r=r(ZPt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),ZPt.forEach(t),c9r=i(Pa),fn=n(Pa,"P",{});var OA=s(fn);f9r=r(OA,"The model class to instantiate is selected based on the "),P9e=n(OA,"CODE",{});var eBt=s(P9e);m9r=r(eBt,"model_type"),eBt.forEach(t),g9r=r(OA,` property of the config object (either
passed as an argument or loaded from `),B9e=n(OA,"CODE",{});var oBt=s(B9e);h9r=r(oBt,"pretrained_model_name_or_path"),oBt.forEach(t),p9r=r(OA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I9e=n(OA,"CODE",{});var rBt=s(I9e);_9r=r(rBt,"pretrained_model_name_or_path"),rBt.forEach(t),u9r=r(OA,":"),OA.forEach(t),b9r=i(Pa),st=n(Pa,"UL",{});var Il=s(st);OM=n(Il,"LI",{});var RDe=s(OM);N9e=n(RDe,"STRONG",{});var tBt=s(N9e);v9r=r(tBt,"beit"),tBt.forEach(t),F9r=r(RDe," \u2014 "),CJ=n(RDe,"A",{href:!0});var aBt=s(CJ);T9r=r(aBt,"BeitForSemanticSegmentation"),aBt.forEach(t),M9r=r(RDe," (BEiT model)"),RDe.forEach(t),E9r=i(Il),VM=n(Il,"LI",{});var PDe=s(VM);q9e=n(PDe,"STRONG",{});var nBt=s(q9e);C9r=r(nBt,"data2vec-vision"),nBt.forEach(t),w9r=r(PDe," \u2014 "),wJ=n(PDe,"A",{href:!0});var sBt=s(wJ);A9r=r(sBt,"Data2VecVisionForSemanticSegmentation"),sBt.forEach(t),L9r=r(PDe," (Data2VecVision model)"),PDe.forEach(t),y9r=i(Il),XM=n(Il,"LI",{});var BDe=s(XM);j9e=n(BDe,"STRONG",{});var lBt=s(j9e);x9r=r(lBt,"dpt"),lBt.forEach(t),$9r=r(BDe," \u2014 "),AJ=n(BDe,"A",{href:!0});var iBt=s(AJ);k9r=r(iBt,"DPTForSemanticSegmentation"),iBt.forEach(t),S9r=r(BDe," (DPT model)"),BDe.forEach(t),R9r=i(Il),zM=n(Il,"LI",{});var IDe=s(zM);D9e=n(IDe,"STRONG",{});var dBt=s(D9e);P9r=r(dBt,"mobilevit"),dBt.forEach(t),B9r=r(IDe," \u2014 "),LJ=n(IDe,"A",{href:!0});var cBt=s(LJ);I9r=r(cBt,"MobileViTForSemanticSegmentation"),cBt.forEach(t),N9r=r(IDe," (MobileViT model)"),IDe.forEach(t),q9r=i(Il),WM=n(Il,"LI",{});var NDe=s(WM);G9e=n(NDe,"STRONG",{});var fBt=s(G9e);j9r=r(fBt,"segformer"),fBt.forEach(t),D9r=r(NDe," \u2014 "),yJ=n(NDe,"A",{href:!0});var mBt=s(yJ);G9r=r(mBt,"SegformerForSemanticSegmentation"),mBt.forEach(t),O9r=r(NDe," (SegFormer model)"),NDe.forEach(t),Il.forEach(t),V9r=i(Pa),QM=n(Pa,"P",{});var qDe=s(QM);X9r=r(qDe,"The model is set in evaluation mode by default using "),O9e=n(qDe,"CODE",{});var gBt=s(O9e);z9r=r(gBt,"model.eval()"),gBt.forEach(t),W9r=r(qDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),V9e=n(qDe,"CODE",{});var hBt=s(V9e);Q9r=r(hBt,"model.train()"),hBt.forEach(t),qDe.forEach(t),H9r=i(Pa),T(HM.$$.fragment,Pa),Pa.forEach(t),Bl.forEach(t),WQe=i(f),hc=n(f,"H2",{class:!0});var rJe=s(hc);UM=n(rJe,"A",{id:!0,class:!0,href:!0});var pBt=s(UM);X9e=n(pBt,"SPAN",{});var _Bt=s(X9e);T(Rx.$$.fragment,_Bt),_Bt.forEach(t),pBt.forEach(t),U9r=i(rJe),z9e=n(rJe,"SPAN",{});var uBt=s(z9e);J9r=r(uBt,"AutoModelForInstanceSegmentation"),uBt.forEach(t),rJe.forEach(t),QQe=i(f),tr=n(f,"DIV",{class:!0});var Nl=s(tr);T(Px.$$.fragment,Nl),Y9r=i(Nl),pc=n(Nl,"P",{});var ene=s(pc);K9r=r(ene,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),xJ=n(ene,"A",{href:!0});var bBt=s(xJ);Z9r=r(bBt,"from_pretrained()"),bBt.forEach(t),eMr=r(ene," class method or the "),$J=n(ene,"A",{href:!0});var vBt=s($J);oMr=r(vBt,"from_config()"),vBt.forEach(t),rMr=r(ene,` class
method.`),ene.forEach(t),tMr=i(Nl),Bx=n(Nl,"P",{});var tJe=s(Bx);aMr=r(tJe,"This class cannot be instantiated directly using "),W9e=n(tJe,"CODE",{});var FBt=s(W9e);nMr=r(FBt,"__init__()"),FBt.forEach(t),sMr=r(tJe," (throws an error)."),tJe.forEach(t),lMr=i(Nl),Bt=n(Nl,"DIV",{class:!0});var VA=s(Bt);T(Ix.$$.fragment,VA),iMr=i(VA),Q9e=n(VA,"P",{});var TBt=s(Q9e);dMr=r(TBt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),TBt.forEach(t),cMr=i(VA),_c=n(VA,"P",{});var one=s(_c);fMr=r(one,`Note:
Loading a model from its configuration file does `),H9e=n(one,"STRONG",{});var MBt=s(H9e);mMr=r(MBt,"not"),MBt.forEach(t),gMr=r(one,` load the model weights. It only affects the
model\u2019s configuration. Use `),kJ=n(one,"A",{href:!0});var EBt=s(kJ);hMr=r(EBt,"from_pretrained()"),EBt.forEach(t),pMr=r(one," to load the model weights."),one.forEach(t),_Mr=i(VA),T(JM.$$.fragment,VA),VA.forEach(t),uMr=i(Nl),Mo=n(Nl,"DIV",{class:!0});var Ba=s(Mo);T(Nx.$$.fragment,Ba),bMr=i(Ba),U9e=n(Ba,"P",{});var CBt=s(U9e);vMr=r(CBt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),CBt.forEach(t),FMr=i(Ba),mn=n(Ba,"P",{});var XA=s(mn);TMr=r(XA,"The model class to instantiate is selected based on the "),J9e=n(XA,"CODE",{});var wBt=s(J9e);MMr=r(wBt,"model_type"),wBt.forEach(t),EMr=r(XA,` property of the config object (either
passed as an argument or loaded from `),Y9e=n(XA,"CODE",{});var ABt=s(Y9e);CMr=r(ABt,"pretrained_model_name_or_path"),ABt.forEach(t),wMr=r(XA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),K9e=n(XA,"CODE",{});var LBt=s(K9e);AMr=r(LBt,"pretrained_model_name_or_path"),LBt.forEach(t),LMr=r(XA,":"),XA.forEach(t),yMr=i(Ba),Z9e=n(Ba,"UL",{});var yBt=s(Z9e);YM=n(yBt,"LI",{});var jDe=s(YM);eMe=n(jDe,"STRONG",{});var xBt=s(eMe);xMr=r(xBt,"maskformer"),xBt.forEach(t),$Mr=r(jDe," \u2014 "),SJ=n(jDe,"A",{href:!0});var $Bt=s(SJ);kMr=r($Bt,"MaskFormerForInstanceSegmentation"),$Bt.forEach(t),SMr=r(jDe," (MaskFormer model)"),jDe.forEach(t),yBt.forEach(t),RMr=i(Ba),KM=n(Ba,"P",{});var DDe=s(KM);PMr=r(DDe,"The model is set in evaluation mode by default using "),oMe=n(DDe,"CODE",{});var kBt=s(oMe);BMr=r(kBt,"model.eval()"),kBt.forEach(t),IMr=r(DDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),rMe=n(DDe,"CODE",{});var SBt=s(rMe);NMr=r(SBt,"model.train()"),SBt.forEach(t),DDe.forEach(t),qMr=i(Ba),T(ZM.$$.fragment,Ba),Ba.forEach(t),Nl.forEach(t),HQe=i(f),uc=n(f,"H2",{class:!0});var aJe=s(uc);eE=n(aJe,"A",{id:!0,class:!0,href:!0});var RBt=s(eE);tMe=n(RBt,"SPAN",{});var PBt=s(tMe);T(qx.$$.fragment,PBt),PBt.forEach(t),RBt.forEach(t),jMr=i(aJe),aMe=n(aJe,"SPAN",{});var BBt=s(aMe);DMr=r(BBt,"TFAutoModel"),BBt.forEach(t),aJe.forEach(t),UQe=i(f),ar=n(f,"DIV",{class:!0});var ql=s(ar);T(jx.$$.fragment,ql),GMr=i(ql),bc=n(ql,"P",{});var rne=s(bc);OMr=r(rne,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),RJ=n(rne,"A",{href:!0});var IBt=s(RJ);VMr=r(IBt,"from_pretrained()"),IBt.forEach(t),XMr=r(rne," class method or the "),PJ=n(rne,"A",{href:!0});var NBt=s(PJ);zMr=r(NBt,"from_config()"),NBt.forEach(t),WMr=r(rne,` class
method.`),rne.forEach(t),QMr=i(ql),Dx=n(ql,"P",{});var nJe=s(Dx);HMr=r(nJe,"This class cannot be instantiated directly using "),nMe=n(nJe,"CODE",{});var qBt=s(nMe);UMr=r(qBt,"__init__()"),qBt.forEach(t),JMr=r(nJe," (throws an error)."),nJe.forEach(t),YMr=i(ql),It=n(ql,"DIV",{class:!0});var zA=s(It);T(Gx.$$.fragment,zA),KMr=i(zA),sMe=n(zA,"P",{});var jBt=s(sMe);ZMr=r(jBt,"Instantiates one of the base model classes of the library from a configuration."),jBt.forEach(t),eEr=i(zA),vc=n(zA,"P",{});var tne=s(vc);oEr=r(tne,`Note:
Loading a model from its configuration file does `),lMe=n(tne,"STRONG",{});var DBt=s(lMe);rEr=r(DBt,"not"),DBt.forEach(t),tEr=r(tne,` load the model weights. It only affects the
model\u2019s configuration. Use `),BJ=n(tne,"A",{href:!0});var GBt=s(BJ);aEr=r(GBt,"from_pretrained()"),GBt.forEach(t),nEr=r(tne," to load the model weights."),tne.forEach(t),sEr=i(zA),T(oE.$$.fragment,zA),zA.forEach(t),lEr=i(ql),Sr=n(ql,"DIV",{class:!0});var jl=s(Sr);T(Ox.$$.fragment,jl),iEr=i(jl),iMe=n(jl,"P",{});var OBt=s(iMe);dEr=r(OBt,"Instantiate one of the base model classes of the library from a pretrained model."),OBt.forEach(t),cEr=i(jl),gn=n(jl,"P",{});var WA=s(gn);fEr=r(WA,"The model class to instantiate is selected based on the "),dMe=n(WA,"CODE",{});var VBt=s(dMe);mEr=r(VBt,"model_type"),VBt.forEach(t),gEr=r(WA,` property of the config object (either
passed as an argument or loaded from `),cMe=n(WA,"CODE",{});var XBt=s(cMe);hEr=r(XBt,"pretrained_model_name_or_path"),XBt.forEach(t),pEr=r(WA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fMe=n(WA,"CODE",{});var zBt=s(fMe);_Er=r(zBt,"pretrained_model_name_or_path"),zBt.forEach(t),uEr=r(WA,":"),WA.forEach(t),bEr=i(jl),q=n(jl,"UL",{});var D=s(q);rE=n(D,"LI",{});var GDe=s(rE);mMe=n(GDe,"STRONG",{});var WBt=s(mMe);vEr=r(WBt,"albert"),WBt.forEach(t),FEr=r(GDe," \u2014 "),IJ=n(GDe,"A",{href:!0});var QBt=s(IJ);TEr=r(QBt,"TFAlbertModel"),QBt.forEach(t),MEr=r(GDe," (ALBERT model)"),GDe.forEach(t),EEr=i(D),tE=n(D,"LI",{});var ODe=s(tE);gMe=n(ODe,"STRONG",{});var HBt=s(gMe);CEr=r(HBt,"bart"),HBt.forEach(t),wEr=r(ODe," \u2014 "),NJ=n(ODe,"A",{href:!0});var UBt=s(NJ);AEr=r(UBt,"TFBartModel"),UBt.forEach(t),LEr=r(ODe," (BART model)"),ODe.forEach(t),yEr=i(D),aE=n(D,"LI",{});var VDe=s(aE);hMe=n(VDe,"STRONG",{});var JBt=s(hMe);xEr=r(JBt,"bert"),JBt.forEach(t),$Er=r(VDe," \u2014 "),qJ=n(VDe,"A",{href:!0});var YBt=s(qJ);kEr=r(YBt,"TFBertModel"),YBt.forEach(t),SEr=r(VDe," (BERT model)"),VDe.forEach(t),REr=i(D),nE=n(D,"LI",{});var XDe=s(nE);pMe=n(XDe,"STRONG",{});var KBt=s(pMe);PEr=r(KBt,"blenderbot"),KBt.forEach(t),BEr=r(XDe," \u2014 "),jJ=n(XDe,"A",{href:!0});var ZBt=s(jJ);IEr=r(ZBt,"TFBlenderbotModel"),ZBt.forEach(t),NEr=r(XDe," (Blenderbot model)"),XDe.forEach(t),qEr=i(D),sE=n(D,"LI",{});var zDe=s(sE);_Me=n(zDe,"STRONG",{});var eIt=s(_Me);jEr=r(eIt,"blenderbot-small"),eIt.forEach(t),DEr=r(zDe," \u2014 "),DJ=n(zDe,"A",{href:!0});var oIt=s(DJ);GEr=r(oIt,"TFBlenderbotSmallModel"),oIt.forEach(t),OEr=r(zDe," (BlenderbotSmall model)"),zDe.forEach(t),VEr=i(D),lE=n(D,"LI",{});var WDe=s(lE);uMe=n(WDe,"STRONG",{});var rIt=s(uMe);XEr=r(rIt,"camembert"),rIt.forEach(t),zEr=r(WDe," \u2014 "),GJ=n(WDe,"A",{href:!0});var tIt=s(GJ);WEr=r(tIt,"TFCamembertModel"),tIt.forEach(t),QEr=r(WDe," (CamemBERT model)"),WDe.forEach(t),HEr=i(D),iE=n(D,"LI",{});var QDe=s(iE);bMe=n(QDe,"STRONG",{});var aIt=s(bMe);UEr=r(aIt,"clip"),aIt.forEach(t),JEr=r(QDe," \u2014 "),OJ=n(QDe,"A",{href:!0});var nIt=s(OJ);YEr=r(nIt,"TFCLIPModel"),nIt.forEach(t),KEr=r(QDe," (CLIP model)"),QDe.forEach(t),ZEr=i(D),dE=n(D,"LI",{});var HDe=s(dE);vMe=n(HDe,"STRONG",{});var sIt=s(vMe);e4r=r(sIt,"convbert"),sIt.forEach(t),o4r=r(HDe," \u2014 "),VJ=n(HDe,"A",{href:!0});var lIt=s(VJ);r4r=r(lIt,"TFConvBertModel"),lIt.forEach(t),t4r=r(HDe," (ConvBERT model)"),HDe.forEach(t),a4r=i(D),cE=n(D,"LI",{});var UDe=s(cE);FMe=n(UDe,"STRONG",{});var iIt=s(FMe);n4r=r(iIt,"convnext"),iIt.forEach(t),s4r=r(UDe," \u2014 "),XJ=n(UDe,"A",{href:!0});var dIt=s(XJ);l4r=r(dIt,"TFConvNextModel"),dIt.forEach(t),i4r=r(UDe," (ConvNeXT model)"),UDe.forEach(t),d4r=i(D),fE=n(D,"LI",{});var JDe=s(fE);TMe=n(JDe,"STRONG",{});var cIt=s(TMe);c4r=r(cIt,"ctrl"),cIt.forEach(t),f4r=r(JDe," \u2014 "),zJ=n(JDe,"A",{href:!0});var fIt=s(zJ);m4r=r(fIt,"TFCTRLModel"),fIt.forEach(t),g4r=r(JDe," (CTRL model)"),JDe.forEach(t),h4r=i(D),mE=n(D,"LI",{});var YDe=s(mE);MMe=n(YDe,"STRONG",{});var mIt=s(MMe);p4r=r(mIt,"data2vec-vision"),mIt.forEach(t),_4r=r(YDe," \u2014 "),WJ=n(YDe,"A",{href:!0});var gIt=s(WJ);u4r=r(gIt,"TFData2VecVisionModel"),gIt.forEach(t),b4r=r(YDe," (Data2VecVision model)"),YDe.forEach(t),v4r=i(D),gE=n(D,"LI",{});var KDe=s(gE);EMe=n(KDe,"STRONG",{});var hIt=s(EMe);F4r=r(hIt,"deberta"),hIt.forEach(t),T4r=r(KDe," \u2014 "),QJ=n(KDe,"A",{href:!0});var pIt=s(QJ);M4r=r(pIt,"TFDebertaModel"),pIt.forEach(t),E4r=r(KDe," (DeBERTa model)"),KDe.forEach(t),C4r=i(D),hE=n(D,"LI",{});var ZDe=s(hE);CMe=n(ZDe,"STRONG",{});var _It=s(CMe);w4r=r(_It,"deberta-v2"),_It.forEach(t),A4r=r(ZDe," \u2014 "),HJ=n(ZDe,"A",{href:!0});var uIt=s(HJ);L4r=r(uIt,"TFDebertaV2Model"),uIt.forEach(t),y4r=r(ZDe," (DeBERTa-v2 model)"),ZDe.forEach(t),x4r=i(D),pE=n(D,"LI",{});var eGe=s(pE);wMe=n(eGe,"STRONG",{});var bIt=s(wMe);$4r=r(bIt,"deit"),bIt.forEach(t),k4r=r(eGe," \u2014 "),UJ=n(eGe,"A",{href:!0});var vIt=s(UJ);S4r=r(vIt,"TFDeiTModel"),vIt.forEach(t),R4r=r(eGe," (DeiT model)"),eGe.forEach(t),P4r=i(D),_E=n(D,"LI",{});var oGe=s(_E);AMe=n(oGe,"STRONG",{});var FIt=s(AMe);B4r=r(FIt,"distilbert"),FIt.forEach(t),I4r=r(oGe," \u2014 "),JJ=n(oGe,"A",{href:!0});var TIt=s(JJ);N4r=r(TIt,"TFDistilBertModel"),TIt.forEach(t),q4r=r(oGe," (DistilBERT model)"),oGe.forEach(t),j4r=i(D),uE=n(D,"LI",{});var rGe=s(uE);LMe=n(rGe,"STRONG",{});var MIt=s(LMe);D4r=r(MIt,"dpr"),MIt.forEach(t),G4r=r(rGe," \u2014 "),YJ=n(rGe,"A",{href:!0});var EIt=s(YJ);O4r=r(EIt,"TFDPRQuestionEncoder"),EIt.forEach(t),V4r=r(rGe," (DPR model)"),rGe.forEach(t),X4r=i(D),bE=n(D,"LI",{});var tGe=s(bE);yMe=n(tGe,"STRONG",{});var CIt=s(yMe);z4r=r(CIt,"electra"),CIt.forEach(t),W4r=r(tGe," \u2014 "),KJ=n(tGe,"A",{href:!0});var wIt=s(KJ);Q4r=r(wIt,"TFElectraModel"),wIt.forEach(t),H4r=r(tGe," (ELECTRA model)"),tGe.forEach(t),U4r=i(D),vE=n(D,"LI",{});var aGe=s(vE);xMe=n(aGe,"STRONG",{});var AIt=s(xMe);J4r=r(AIt,"flaubert"),AIt.forEach(t),Y4r=r(aGe," \u2014 "),ZJ=n(aGe,"A",{href:!0});var LIt=s(ZJ);K4r=r(LIt,"TFFlaubertModel"),LIt.forEach(t),Z4r=r(aGe," (FlauBERT model)"),aGe.forEach(t),eCr=i(D),al=n(D,"LI",{});var xR=s(al);$Me=n(xR,"STRONG",{});var yIt=s($Me);oCr=r(yIt,"funnel"),yIt.forEach(t),rCr=r(xR," \u2014 "),eY=n(xR,"A",{href:!0});var xIt=s(eY);tCr=r(xIt,"TFFunnelModel"),xIt.forEach(t),aCr=r(xR," or "),oY=n(xR,"A",{href:!0});var $It=s(oY);nCr=r($It,"TFFunnelBaseModel"),$It.forEach(t),sCr=r(xR," (Funnel Transformer model)"),xR.forEach(t),lCr=i(D),FE=n(D,"LI",{});var nGe=s(FE);kMe=n(nGe,"STRONG",{});var kIt=s(kMe);iCr=r(kIt,"gpt2"),kIt.forEach(t),dCr=r(nGe," \u2014 "),rY=n(nGe,"A",{href:!0});var SIt=s(rY);cCr=r(SIt,"TFGPT2Model"),SIt.forEach(t),fCr=r(nGe," (OpenAI GPT-2 model)"),nGe.forEach(t),mCr=i(D),TE=n(D,"LI",{});var sGe=s(TE);SMe=n(sGe,"STRONG",{});var RIt=s(SMe);gCr=r(RIt,"gptj"),RIt.forEach(t),hCr=r(sGe," \u2014 "),tY=n(sGe,"A",{href:!0});var PIt=s(tY);pCr=r(PIt,"TFGPTJModel"),PIt.forEach(t),_Cr=r(sGe," (GPT-J model)"),sGe.forEach(t),uCr=i(D),ME=n(D,"LI",{});var lGe=s(ME);RMe=n(lGe,"STRONG",{});var BIt=s(RMe);bCr=r(BIt,"hubert"),BIt.forEach(t),vCr=r(lGe," \u2014 "),aY=n(lGe,"A",{href:!0});var IIt=s(aY);FCr=r(IIt,"TFHubertModel"),IIt.forEach(t),TCr=r(lGe," (Hubert model)"),lGe.forEach(t),MCr=i(D),EE=n(D,"LI",{});var iGe=s(EE);PMe=n(iGe,"STRONG",{});var NIt=s(PMe);ECr=r(NIt,"layoutlm"),NIt.forEach(t),CCr=r(iGe," \u2014 "),nY=n(iGe,"A",{href:!0});var qIt=s(nY);wCr=r(qIt,"TFLayoutLMModel"),qIt.forEach(t),ACr=r(iGe," (LayoutLM model)"),iGe.forEach(t),LCr=i(D),CE=n(D,"LI",{});var dGe=s(CE);BMe=n(dGe,"STRONG",{});var jIt=s(BMe);yCr=r(jIt,"led"),jIt.forEach(t),xCr=r(dGe," \u2014 "),sY=n(dGe,"A",{href:!0});var DIt=s(sY);$Cr=r(DIt,"TFLEDModel"),DIt.forEach(t),kCr=r(dGe," (LED model)"),dGe.forEach(t),SCr=i(D),wE=n(D,"LI",{});var cGe=s(wE);IMe=n(cGe,"STRONG",{});var GIt=s(IMe);RCr=r(GIt,"longformer"),GIt.forEach(t),PCr=r(cGe," \u2014 "),lY=n(cGe,"A",{href:!0});var OIt=s(lY);BCr=r(OIt,"TFLongformerModel"),OIt.forEach(t),ICr=r(cGe," (Longformer model)"),cGe.forEach(t),NCr=i(D),AE=n(D,"LI",{});var fGe=s(AE);NMe=n(fGe,"STRONG",{});var VIt=s(NMe);qCr=r(VIt,"lxmert"),VIt.forEach(t),jCr=r(fGe," \u2014 "),iY=n(fGe,"A",{href:!0});var XIt=s(iY);DCr=r(XIt,"TFLxmertModel"),XIt.forEach(t),GCr=r(fGe," (LXMERT model)"),fGe.forEach(t),OCr=i(D),LE=n(D,"LI",{});var mGe=s(LE);qMe=n(mGe,"STRONG",{});var zIt=s(qMe);VCr=r(zIt,"marian"),zIt.forEach(t),XCr=r(mGe," \u2014 "),dY=n(mGe,"A",{href:!0});var WIt=s(dY);zCr=r(WIt,"TFMarianModel"),WIt.forEach(t),WCr=r(mGe," (Marian model)"),mGe.forEach(t),QCr=i(D),yE=n(D,"LI",{});var gGe=s(yE);jMe=n(gGe,"STRONG",{});var QIt=s(jMe);HCr=r(QIt,"mbart"),QIt.forEach(t),UCr=r(gGe," \u2014 "),cY=n(gGe,"A",{href:!0});var HIt=s(cY);JCr=r(HIt,"TFMBartModel"),HIt.forEach(t),YCr=r(gGe," (mBART model)"),gGe.forEach(t),KCr=i(D),xE=n(D,"LI",{});var hGe=s(xE);DMe=n(hGe,"STRONG",{});var UIt=s(DMe);ZCr=r(UIt,"mobilebert"),UIt.forEach(t),e3r=r(hGe," \u2014 "),fY=n(hGe,"A",{href:!0});var JIt=s(fY);o3r=r(JIt,"TFMobileBertModel"),JIt.forEach(t),r3r=r(hGe," (MobileBERT model)"),hGe.forEach(t),t3r=i(D),$E=n(D,"LI",{});var pGe=s($E);GMe=n(pGe,"STRONG",{});var YIt=s(GMe);a3r=r(YIt,"mpnet"),YIt.forEach(t),n3r=r(pGe," \u2014 "),mY=n(pGe,"A",{href:!0});var KIt=s(mY);s3r=r(KIt,"TFMPNetModel"),KIt.forEach(t),l3r=r(pGe," (MPNet model)"),pGe.forEach(t),i3r=i(D),kE=n(D,"LI",{});var _Ge=s(kE);OMe=n(_Ge,"STRONG",{});var ZIt=s(OMe);d3r=r(ZIt,"mt5"),ZIt.forEach(t),c3r=r(_Ge," \u2014 "),gY=n(_Ge,"A",{href:!0});var eNt=s(gY);f3r=r(eNt,"TFMT5Model"),eNt.forEach(t),m3r=r(_Ge," (MT5 model)"),_Ge.forEach(t),g3r=i(D),SE=n(D,"LI",{});var uGe=s(SE);VMe=n(uGe,"STRONG",{});var oNt=s(VMe);h3r=r(oNt,"openai-gpt"),oNt.forEach(t),p3r=r(uGe," \u2014 "),hY=n(uGe,"A",{href:!0});var rNt=s(hY);_3r=r(rNt,"TFOpenAIGPTModel"),rNt.forEach(t),u3r=r(uGe," (OpenAI GPT model)"),uGe.forEach(t),b3r=i(D),RE=n(D,"LI",{});var bGe=s(RE);XMe=n(bGe,"STRONG",{});var tNt=s(XMe);v3r=r(tNt,"opt"),tNt.forEach(t),F3r=r(bGe," \u2014 "),pY=n(bGe,"A",{href:!0});var aNt=s(pY);T3r=r(aNt,"TFOPTModel"),aNt.forEach(t),M3r=r(bGe," (OPT model)"),bGe.forEach(t),E3r=i(D),PE=n(D,"LI",{});var vGe=s(PE);zMe=n(vGe,"STRONG",{});var nNt=s(zMe);C3r=r(nNt,"pegasus"),nNt.forEach(t),w3r=r(vGe," \u2014 "),_Y=n(vGe,"A",{href:!0});var sNt=s(_Y);A3r=r(sNt,"TFPegasusModel"),sNt.forEach(t),L3r=r(vGe," (Pegasus model)"),vGe.forEach(t),y3r=i(D),BE=n(D,"LI",{});var FGe=s(BE);WMe=n(FGe,"STRONG",{});var lNt=s(WMe);x3r=r(lNt,"regnet"),lNt.forEach(t),$3r=r(FGe," \u2014 "),uY=n(FGe,"A",{href:!0});var iNt=s(uY);k3r=r(iNt,"TFRegNetModel"),iNt.forEach(t),S3r=r(FGe," (RegNet model)"),FGe.forEach(t),R3r=i(D),IE=n(D,"LI",{});var TGe=s(IE);QMe=n(TGe,"STRONG",{});var dNt=s(QMe);P3r=r(dNt,"rembert"),dNt.forEach(t),B3r=r(TGe," \u2014 "),bY=n(TGe,"A",{href:!0});var cNt=s(bY);I3r=r(cNt,"TFRemBertModel"),cNt.forEach(t),N3r=r(TGe," (RemBERT model)"),TGe.forEach(t),q3r=i(D),NE=n(D,"LI",{});var MGe=s(NE);HMe=n(MGe,"STRONG",{});var fNt=s(HMe);j3r=r(fNt,"resnet"),fNt.forEach(t),D3r=r(MGe," \u2014 "),vY=n(MGe,"A",{href:!0});var mNt=s(vY);G3r=r(mNt,"TFResNetModel"),mNt.forEach(t),O3r=r(MGe," (ResNet model)"),MGe.forEach(t),V3r=i(D),qE=n(D,"LI",{});var EGe=s(qE);UMe=n(EGe,"STRONG",{});var gNt=s(UMe);X3r=r(gNt,"roberta"),gNt.forEach(t),z3r=r(EGe," \u2014 "),FY=n(EGe,"A",{href:!0});var hNt=s(FY);W3r=r(hNt,"TFRobertaModel"),hNt.forEach(t),Q3r=r(EGe," (RoBERTa model)"),EGe.forEach(t),H3r=i(D),jE=n(D,"LI",{});var CGe=s(jE);JMe=n(CGe,"STRONG",{});var pNt=s(JMe);U3r=r(pNt,"roformer"),pNt.forEach(t),J3r=r(CGe," \u2014 "),TY=n(CGe,"A",{href:!0});var _Nt=s(TY);Y3r=r(_Nt,"TFRoFormerModel"),_Nt.forEach(t),K3r=r(CGe," (RoFormer model)"),CGe.forEach(t),Z3r=i(D),DE=n(D,"LI",{});var wGe=s(DE);YMe=n(wGe,"STRONG",{});var uNt=s(YMe);e5r=r(uNt,"segformer"),uNt.forEach(t),o5r=r(wGe," \u2014 "),MY=n(wGe,"A",{href:!0});var bNt=s(MY);r5r=r(bNt,"TFSegformerModel"),bNt.forEach(t),t5r=r(wGe," (SegFormer model)"),wGe.forEach(t),a5r=i(D),GE=n(D,"LI",{});var AGe=s(GE);KMe=n(AGe,"STRONG",{});var vNt=s(KMe);n5r=r(vNt,"speech_to_text"),vNt.forEach(t),s5r=r(AGe," \u2014 "),EY=n(AGe,"A",{href:!0});var FNt=s(EY);l5r=r(FNt,"TFSpeech2TextModel"),FNt.forEach(t),i5r=r(AGe," (Speech2Text model)"),AGe.forEach(t),d5r=i(D),OE=n(D,"LI",{});var LGe=s(OE);ZMe=n(LGe,"STRONG",{});var TNt=s(ZMe);c5r=r(TNt,"swin"),TNt.forEach(t),f5r=r(LGe," \u2014 "),CY=n(LGe,"A",{href:!0});var MNt=s(CY);m5r=r(MNt,"TFSwinModel"),MNt.forEach(t),g5r=r(LGe," (Swin Transformer model)"),LGe.forEach(t),h5r=i(D),VE=n(D,"LI",{});var yGe=s(VE);eEe=n(yGe,"STRONG",{});var ENt=s(eEe);p5r=r(ENt,"t5"),ENt.forEach(t),_5r=r(yGe," \u2014 "),wY=n(yGe,"A",{href:!0});var CNt=s(wY);u5r=r(CNt,"TFT5Model"),CNt.forEach(t),b5r=r(yGe," (T5 model)"),yGe.forEach(t),v5r=i(D),XE=n(D,"LI",{});var xGe=s(XE);oEe=n(xGe,"STRONG",{});var wNt=s(oEe);F5r=r(wNt,"tapas"),wNt.forEach(t),T5r=r(xGe," \u2014 "),AY=n(xGe,"A",{href:!0});var ANt=s(AY);M5r=r(ANt,"TFTapasModel"),ANt.forEach(t),E5r=r(xGe," (TAPAS model)"),xGe.forEach(t),C5r=i(D),zE=n(D,"LI",{});var $Ge=s(zE);rEe=n($Ge,"STRONG",{});var LNt=s(rEe);w5r=r(LNt,"transfo-xl"),LNt.forEach(t),A5r=r($Ge," \u2014 "),LY=n($Ge,"A",{href:!0});var yNt=s(LY);L5r=r(yNt,"TFTransfoXLModel"),yNt.forEach(t),y5r=r($Ge," (Transformer-XL model)"),$Ge.forEach(t),x5r=i(D),WE=n(D,"LI",{});var kGe=s(WE);tEe=n(kGe,"STRONG",{});var xNt=s(tEe);$5r=r(xNt,"vit"),xNt.forEach(t),k5r=r(kGe," \u2014 "),yY=n(kGe,"A",{href:!0});var $Nt=s(yY);S5r=r($Nt,"TFViTModel"),$Nt.forEach(t),R5r=r(kGe," (ViT model)"),kGe.forEach(t),P5r=i(D),QE=n(D,"LI",{});var SGe=s(QE);aEe=n(SGe,"STRONG",{});var kNt=s(aEe);B5r=r(kNt,"vit_mae"),kNt.forEach(t),I5r=r(SGe," \u2014 "),xY=n(SGe,"A",{href:!0});var SNt=s(xY);N5r=r(SNt,"TFViTMAEModel"),SNt.forEach(t),q5r=r(SGe," (ViTMAE model)"),SGe.forEach(t),j5r=i(D),HE=n(D,"LI",{});var RGe=s(HE);nEe=n(RGe,"STRONG",{});var RNt=s(nEe);D5r=r(RNt,"wav2vec2"),RNt.forEach(t),G5r=r(RGe," \u2014 "),$Y=n(RGe,"A",{href:!0});var PNt=s($Y);O5r=r(PNt,"TFWav2Vec2Model"),PNt.forEach(t),V5r=r(RGe," (Wav2Vec2 model)"),RGe.forEach(t),X5r=i(D),UE=n(D,"LI",{});var PGe=s(UE);sEe=n(PGe,"STRONG",{});var BNt=s(sEe);z5r=r(BNt,"xlm"),BNt.forEach(t),W5r=r(PGe," \u2014 "),kY=n(PGe,"A",{href:!0});var INt=s(kY);Q5r=r(INt,"TFXLMModel"),INt.forEach(t),H5r=r(PGe," (XLM model)"),PGe.forEach(t),U5r=i(D),JE=n(D,"LI",{});var BGe=s(JE);lEe=n(BGe,"STRONG",{});var NNt=s(lEe);J5r=r(NNt,"xlm-roberta"),NNt.forEach(t),Y5r=r(BGe," \u2014 "),SY=n(BGe,"A",{href:!0});var qNt=s(SY);K5r=r(qNt,"TFXLMRobertaModel"),qNt.forEach(t),Z5r=r(BGe," (XLM-RoBERTa model)"),BGe.forEach(t),e0r=i(D),YE=n(D,"LI",{});var IGe=s(YE);iEe=n(IGe,"STRONG",{});var jNt=s(iEe);o0r=r(jNt,"xlnet"),jNt.forEach(t),r0r=r(IGe," \u2014 "),RY=n(IGe,"A",{href:!0});var DNt=s(RY);t0r=r(DNt,"TFXLNetModel"),DNt.forEach(t),a0r=r(IGe," (XLNet model)"),IGe.forEach(t),D.forEach(t),n0r=i(jl),T(KE.$$.fragment,jl),jl.forEach(t),ql.forEach(t),JQe=i(f),Fc=n(f,"H2",{class:!0});var sJe=s(Fc);ZE=n(sJe,"A",{id:!0,class:!0,href:!0});var GNt=s(ZE);dEe=n(GNt,"SPAN",{});var ONt=s(dEe);T(Vx.$$.fragment,ONt),ONt.forEach(t),GNt.forEach(t),s0r=i(sJe),cEe=n(sJe,"SPAN",{});var VNt=s(cEe);l0r=r(VNt,"TFAutoModelForPreTraining"),VNt.forEach(t),sJe.forEach(t),YQe=i(f),nr=n(f,"DIV",{class:!0});var Dl=s(nr);T(Xx.$$.fragment,Dl),i0r=i(Dl),Tc=n(Dl,"P",{});var ane=s(Tc);d0r=r(ane,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),PY=n(ane,"A",{href:!0});var XNt=s(PY);c0r=r(XNt,"from_pretrained()"),XNt.forEach(t),f0r=r(ane," class method or the "),BY=n(ane,"A",{href:!0});var zNt=s(BY);m0r=r(zNt,"from_config()"),zNt.forEach(t),g0r=r(ane,` class
method.`),ane.forEach(t),h0r=i(Dl),zx=n(Dl,"P",{});var lJe=s(zx);p0r=r(lJe,"This class cannot be instantiated directly using "),fEe=n(lJe,"CODE",{});var WNt=s(fEe);_0r=r(WNt,"__init__()"),WNt.forEach(t),u0r=r(lJe," (throws an error)."),lJe.forEach(t),b0r=i(Dl),Nt=n(Dl,"DIV",{class:!0});var QA=s(Nt);T(Wx.$$.fragment,QA),v0r=i(QA),mEe=n(QA,"P",{});var QNt=s(mEe);F0r=r(QNt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),QNt.forEach(t),T0r=i(QA),Mc=n(QA,"P",{});var nne=s(Mc);M0r=r(nne,`Note:
Loading a model from its configuration file does `),gEe=n(nne,"STRONG",{});var HNt=s(gEe);E0r=r(HNt,"not"),HNt.forEach(t),C0r=r(nne,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(nne,"A",{href:!0});var UNt=s(IY);w0r=r(UNt,"from_pretrained()"),UNt.forEach(t),A0r=r(nne," to load the model weights."),nne.forEach(t),L0r=i(QA),T(e4.$$.fragment,QA),QA.forEach(t),y0r=i(Dl),Rr=n(Dl,"DIV",{class:!0});var Gl=s(Rr);T(Qx.$$.fragment,Gl),x0r=i(Gl),hEe=n(Gl,"P",{});var JNt=s(hEe);$0r=r(JNt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),JNt.forEach(t),k0r=i(Gl),hn=n(Gl,"P",{});var HA=s(hn);S0r=r(HA,"The model class to instantiate is selected based on the "),pEe=n(HA,"CODE",{});var YNt=s(pEe);R0r=r(YNt,"model_type"),YNt.forEach(t),P0r=r(HA,` property of the config object (either
passed as an argument or loaded from `),_Ee=n(HA,"CODE",{});var KNt=s(_Ee);B0r=r(KNt,"pretrained_model_name_or_path"),KNt.forEach(t),I0r=r(HA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),uEe=n(HA,"CODE",{});var ZNt=s(uEe);N0r=r(ZNt,"pretrained_model_name_or_path"),ZNt.forEach(t),q0r=r(HA,":"),HA.forEach(t),j0r=i(Gl),se=n(Gl,"UL",{});var le=s(se);o4=n(le,"LI",{});var NGe=s(o4);bEe=n(NGe,"STRONG",{});var eqt=s(bEe);D0r=r(eqt,"albert"),eqt.forEach(t),G0r=r(NGe," \u2014 "),NY=n(NGe,"A",{href:!0});var oqt=s(NY);O0r=r(oqt,"TFAlbertForPreTraining"),oqt.forEach(t),V0r=r(NGe," (ALBERT model)"),NGe.forEach(t),X0r=i(le),r4=n(le,"LI",{});var qGe=s(r4);vEe=n(qGe,"STRONG",{});var rqt=s(vEe);z0r=r(rqt,"bart"),rqt.forEach(t),W0r=r(qGe," \u2014 "),qY=n(qGe,"A",{href:!0});var tqt=s(qY);Q0r=r(tqt,"TFBartForConditionalGeneration"),tqt.forEach(t),H0r=r(qGe," (BART model)"),qGe.forEach(t),U0r=i(le),t4=n(le,"LI",{});var jGe=s(t4);FEe=n(jGe,"STRONG",{});var aqt=s(FEe);J0r=r(aqt,"bert"),aqt.forEach(t),Y0r=r(jGe," \u2014 "),jY=n(jGe,"A",{href:!0});var nqt=s(jY);K0r=r(nqt,"TFBertForPreTraining"),nqt.forEach(t),Z0r=r(jGe," (BERT model)"),jGe.forEach(t),ewr=i(le),a4=n(le,"LI",{});var DGe=s(a4);TEe=n(DGe,"STRONG",{});var sqt=s(TEe);owr=r(sqt,"camembert"),sqt.forEach(t),rwr=r(DGe," \u2014 "),DY=n(DGe,"A",{href:!0});var lqt=s(DY);twr=r(lqt,"TFCamembertForMaskedLM"),lqt.forEach(t),awr=r(DGe," (CamemBERT model)"),DGe.forEach(t),nwr=i(le),n4=n(le,"LI",{});var GGe=s(n4);MEe=n(GGe,"STRONG",{});var iqt=s(MEe);swr=r(iqt,"ctrl"),iqt.forEach(t),lwr=r(GGe," \u2014 "),GY=n(GGe,"A",{href:!0});var dqt=s(GY);iwr=r(dqt,"TFCTRLLMHeadModel"),dqt.forEach(t),dwr=r(GGe," (CTRL model)"),GGe.forEach(t),cwr=i(le),s4=n(le,"LI",{});var OGe=s(s4);EEe=n(OGe,"STRONG",{});var cqt=s(EEe);fwr=r(cqt,"distilbert"),cqt.forEach(t),mwr=r(OGe," \u2014 "),OY=n(OGe,"A",{href:!0});var fqt=s(OY);gwr=r(fqt,"TFDistilBertForMaskedLM"),fqt.forEach(t),hwr=r(OGe," (DistilBERT model)"),OGe.forEach(t),pwr=i(le),l4=n(le,"LI",{});var VGe=s(l4);CEe=n(VGe,"STRONG",{});var mqt=s(CEe);_wr=r(mqt,"electra"),mqt.forEach(t),uwr=r(VGe," \u2014 "),VY=n(VGe,"A",{href:!0});var gqt=s(VY);bwr=r(gqt,"TFElectraForPreTraining"),gqt.forEach(t),vwr=r(VGe," (ELECTRA model)"),VGe.forEach(t),Fwr=i(le),i4=n(le,"LI",{});var XGe=s(i4);wEe=n(XGe,"STRONG",{});var hqt=s(wEe);Twr=r(hqt,"flaubert"),hqt.forEach(t),Mwr=r(XGe," \u2014 "),XY=n(XGe,"A",{href:!0});var pqt=s(XY);Ewr=r(pqt,"TFFlaubertWithLMHeadModel"),pqt.forEach(t),Cwr=r(XGe," (FlauBERT model)"),XGe.forEach(t),wwr=i(le),d4=n(le,"LI",{});var zGe=s(d4);AEe=n(zGe,"STRONG",{});var _qt=s(AEe);Awr=r(_qt,"funnel"),_qt.forEach(t),Lwr=r(zGe," \u2014 "),zY=n(zGe,"A",{href:!0});var uqt=s(zY);ywr=r(uqt,"TFFunnelForPreTraining"),uqt.forEach(t),xwr=r(zGe," (Funnel Transformer model)"),zGe.forEach(t),$wr=i(le),c4=n(le,"LI",{});var WGe=s(c4);LEe=n(WGe,"STRONG",{});var bqt=s(LEe);kwr=r(bqt,"gpt2"),bqt.forEach(t),Swr=r(WGe," \u2014 "),WY=n(WGe,"A",{href:!0});var vqt=s(WY);Rwr=r(vqt,"TFGPT2LMHeadModel"),vqt.forEach(t),Pwr=r(WGe," (OpenAI GPT-2 model)"),WGe.forEach(t),Bwr=i(le),f4=n(le,"LI",{});var QGe=s(f4);yEe=n(QGe,"STRONG",{});var Fqt=s(yEe);Iwr=r(Fqt,"layoutlm"),Fqt.forEach(t),Nwr=r(QGe," \u2014 "),QY=n(QGe,"A",{href:!0});var Tqt=s(QY);qwr=r(Tqt,"TFLayoutLMForMaskedLM"),Tqt.forEach(t),jwr=r(QGe," (LayoutLM model)"),QGe.forEach(t),Dwr=i(le),m4=n(le,"LI",{});var HGe=s(m4);xEe=n(HGe,"STRONG",{});var Mqt=s(xEe);Gwr=r(Mqt,"lxmert"),Mqt.forEach(t),Owr=r(HGe," \u2014 "),HY=n(HGe,"A",{href:!0});var Eqt=s(HY);Vwr=r(Eqt,"TFLxmertForPreTraining"),Eqt.forEach(t),Xwr=r(HGe," (LXMERT model)"),HGe.forEach(t),zwr=i(le),g4=n(le,"LI",{});var UGe=s(g4);$Ee=n(UGe,"STRONG",{});var Cqt=s($Ee);Wwr=r(Cqt,"mobilebert"),Cqt.forEach(t),Qwr=r(UGe," \u2014 "),UY=n(UGe,"A",{href:!0});var wqt=s(UY);Hwr=r(wqt,"TFMobileBertForPreTraining"),wqt.forEach(t),Uwr=r(UGe," (MobileBERT model)"),UGe.forEach(t),Jwr=i(le),h4=n(le,"LI",{});var JGe=s(h4);kEe=n(JGe,"STRONG",{});var Aqt=s(kEe);Ywr=r(Aqt,"mpnet"),Aqt.forEach(t),Kwr=r(JGe," \u2014 "),JY=n(JGe,"A",{href:!0});var Lqt=s(JY);Zwr=r(Lqt,"TFMPNetForMaskedLM"),Lqt.forEach(t),e6r=r(JGe," (MPNet model)"),JGe.forEach(t),o6r=i(le),p4=n(le,"LI",{});var YGe=s(p4);SEe=n(YGe,"STRONG",{});var yqt=s(SEe);r6r=r(yqt,"openai-gpt"),yqt.forEach(t),t6r=r(YGe," \u2014 "),YY=n(YGe,"A",{href:!0});var xqt=s(YY);a6r=r(xqt,"TFOpenAIGPTLMHeadModel"),xqt.forEach(t),n6r=r(YGe," (OpenAI GPT model)"),YGe.forEach(t),s6r=i(le),_4=n(le,"LI",{});var KGe=s(_4);REe=n(KGe,"STRONG",{});var $qt=s(REe);l6r=r($qt,"roberta"),$qt.forEach(t),i6r=r(KGe," \u2014 "),KY=n(KGe,"A",{href:!0});var kqt=s(KY);d6r=r(kqt,"TFRobertaForMaskedLM"),kqt.forEach(t),c6r=r(KGe," (RoBERTa model)"),KGe.forEach(t),f6r=i(le),u4=n(le,"LI",{});var ZGe=s(u4);PEe=n(ZGe,"STRONG",{});var Sqt=s(PEe);m6r=r(Sqt,"t5"),Sqt.forEach(t),g6r=r(ZGe," \u2014 "),ZY=n(ZGe,"A",{href:!0});var Rqt=s(ZY);h6r=r(Rqt,"TFT5ForConditionalGeneration"),Rqt.forEach(t),p6r=r(ZGe," (T5 model)"),ZGe.forEach(t),_6r=i(le),b4=n(le,"LI",{});var eOe=s(b4);BEe=n(eOe,"STRONG",{});var Pqt=s(BEe);u6r=r(Pqt,"tapas"),Pqt.forEach(t),b6r=r(eOe," \u2014 "),eK=n(eOe,"A",{href:!0});var Bqt=s(eK);v6r=r(Bqt,"TFTapasForMaskedLM"),Bqt.forEach(t),F6r=r(eOe," (TAPAS model)"),eOe.forEach(t),T6r=i(le),v4=n(le,"LI",{});var oOe=s(v4);IEe=n(oOe,"STRONG",{});var Iqt=s(IEe);M6r=r(Iqt,"transfo-xl"),Iqt.forEach(t),E6r=r(oOe," \u2014 "),oK=n(oOe,"A",{href:!0});var Nqt=s(oK);C6r=r(Nqt,"TFTransfoXLLMHeadModel"),Nqt.forEach(t),w6r=r(oOe," (Transformer-XL model)"),oOe.forEach(t),A6r=i(le),F4=n(le,"LI",{});var rOe=s(F4);NEe=n(rOe,"STRONG",{});var qqt=s(NEe);L6r=r(qqt,"vit_mae"),qqt.forEach(t),y6r=r(rOe," \u2014 "),rK=n(rOe,"A",{href:!0});var jqt=s(rK);x6r=r(jqt,"TFViTMAEForPreTraining"),jqt.forEach(t),$6r=r(rOe," (ViTMAE model)"),rOe.forEach(t),k6r=i(le),T4=n(le,"LI",{});var tOe=s(T4);qEe=n(tOe,"STRONG",{});var Dqt=s(qEe);S6r=r(Dqt,"xlm"),Dqt.forEach(t),R6r=r(tOe," \u2014 "),tK=n(tOe,"A",{href:!0});var Gqt=s(tK);P6r=r(Gqt,"TFXLMWithLMHeadModel"),Gqt.forEach(t),B6r=r(tOe," (XLM model)"),tOe.forEach(t),I6r=i(le),M4=n(le,"LI",{});var aOe=s(M4);jEe=n(aOe,"STRONG",{});var Oqt=s(jEe);N6r=r(Oqt,"xlm-roberta"),Oqt.forEach(t),q6r=r(aOe," \u2014 "),aK=n(aOe,"A",{href:!0});var Vqt=s(aK);j6r=r(Vqt,"TFXLMRobertaForMaskedLM"),Vqt.forEach(t),D6r=r(aOe," (XLM-RoBERTa model)"),aOe.forEach(t),G6r=i(le),E4=n(le,"LI",{});var nOe=s(E4);DEe=n(nOe,"STRONG",{});var Xqt=s(DEe);O6r=r(Xqt,"xlnet"),Xqt.forEach(t),V6r=r(nOe," \u2014 "),nK=n(nOe,"A",{href:!0});var zqt=s(nK);X6r=r(zqt,"TFXLNetLMHeadModel"),zqt.forEach(t),z6r=r(nOe," (XLNet model)"),nOe.forEach(t),le.forEach(t),W6r=i(Gl),T(C4.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),KQe=i(f),Ec=n(f,"H2",{class:!0});var iJe=s(Ec);w4=n(iJe,"A",{id:!0,class:!0,href:!0});var Wqt=s(w4);GEe=n(Wqt,"SPAN",{});var Qqt=s(GEe);T(Hx.$$.fragment,Qqt),Qqt.forEach(t),Wqt.forEach(t),Q6r=i(iJe),OEe=n(iJe,"SPAN",{});var Hqt=s(OEe);H6r=r(Hqt,"TFAutoModelForCausalLM"),Hqt.forEach(t),iJe.forEach(t),ZQe=i(f),sr=n(f,"DIV",{class:!0});var Ol=s(sr);T(Ux.$$.fragment,Ol),U6r=i(Ol),Cc=n(Ol,"P",{});var sne=s(Cc);J6r=r(sne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),sK=n(sne,"A",{href:!0});var Uqt=s(sK);Y6r=r(Uqt,"from_pretrained()"),Uqt.forEach(t),K6r=r(sne," class method or the "),lK=n(sne,"A",{href:!0});var Jqt=s(lK);Z6r=r(Jqt,"from_config()"),Jqt.forEach(t),eAr=r(sne,` class
method.`),sne.forEach(t),oAr=i(Ol),Jx=n(Ol,"P",{});var dJe=s(Jx);rAr=r(dJe,"This class cannot be instantiated directly using "),VEe=n(dJe,"CODE",{});var Yqt=s(VEe);tAr=r(Yqt,"__init__()"),Yqt.forEach(t),aAr=r(dJe," (throws an error)."),dJe.forEach(t),nAr=i(Ol),qt=n(Ol,"DIV",{class:!0});var UA=s(qt);T(Yx.$$.fragment,UA),sAr=i(UA),XEe=n(UA,"P",{});var Kqt=s(XEe);lAr=r(Kqt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),Kqt.forEach(t),iAr=i(UA),wc=n(UA,"P",{});var lne=s(wc);dAr=r(lne,`Note:
Loading a model from its configuration file does `),zEe=n(lne,"STRONG",{});var Zqt=s(zEe);cAr=r(Zqt,"not"),Zqt.forEach(t),fAr=r(lne,` load the model weights. It only affects the
model\u2019s configuration. Use `),iK=n(lne,"A",{href:!0});var ejt=s(iK);mAr=r(ejt,"from_pretrained()"),ejt.forEach(t),gAr=r(lne," to load the model weights."),lne.forEach(t),hAr=i(UA),T(A4.$$.fragment,UA),UA.forEach(t),pAr=i(Ol),Pr=n(Ol,"DIV",{class:!0});var Vl=s(Pr);T(Kx.$$.fragment,Vl),_Ar=i(Vl),WEe=n(Vl,"P",{});var ojt=s(WEe);uAr=r(ojt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),ojt.forEach(t),bAr=i(Vl),pn=n(Vl,"P",{});var JA=s(pn);vAr=r(JA,"The model class to instantiate is selected based on the "),QEe=n(JA,"CODE",{});var rjt=s(QEe);FAr=r(rjt,"model_type"),rjt.forEach(t),TAr=r(JA,` property of the config object (either
passed as an argument or loaded from `),HEe=n(JA,"CODE",{});var tjt=s(HEe);MAr=r(tjt,"pretrained_model_name_or_path"),tjt.forEach(t),EAr=r(JA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),UEe=n(JA,"CODE",{});var ajt=s(UEe);CAr=r(ajt,"pretrained_model_name_or_path"),ajt.forEach(t),wAr=r(JA,":"),JA.forEach(t),AAr=i(Vl),Me=n(Vl,"UL",{});var Ce=s(Me);L4=n(Ce,"LI",{});var sOe=s(L4);JEe=n(sOe,"STRONG",{});var njt=s(JEe);LAr=r(njt,"bert"),njt.forEach(t),yAr=r(sOe," \u2014 "),dK=n(sOe,"A",{href:!0});var sjt=s(dK);xAr=r(sjt,"TFBertLMHeadModel"),sjt.forEach(t),$Ar=r(sOe," (BERT model)"),sOe.forEach(t),kAr=i(Ce),y4=n(Ce,"LI",{});var lOe=s(y4);YEe=n(lOe,"STRONG",{});var ljt=s(YEe);SAr=r(ljt,"camembert"),ljt.forEach(t),RAr=r(lOe," \u2014 "),cK=n(lOe,"A",{href:!0});var ijt=s(cK);PAr=r(ijt,"TFCamembertForCausalLM"),ijt.forEach(t),BAr=r(lOe," (CamemBERT model)"),lOe.forEach(t),IAr=i(Ce),x4=n(Ce,"LI",{});var iOe=s(x4);KEe=n(iOe,"STRONG",{});var djt=s(KEe);NAr=r(djt,"ctrl"),djt.forEach(t),qAr=r(iOe," \u2014 "),fK=n(iOe,"A",{href:!0});var cjt=s(fK);jAr=r(cjt,"TFCTRLLMHeadModel"),cjt.forEach(t),DAr=r(iOe," (CTRL model)"),iOe.forEach(t),GAr=i(Ce),$4=n(Ce,"LI",{});var dOe=s($4);ZEe=n(dOe,"STRONG",{});var fjt=s(ZEe);OAr=r(fjt,"gpt2"),fjt.forEach(t),VAr=r(dOe," \u2014 "),mK=n(dOe,"A",{href:!0});var mjt=s(mK);XAr=r(mjt,"TFGPT2LMHeadModel"),mjt.forEach(t),zAr=r(dOe," (OpenAI GPT-2 model)"),dOe.forEach(t),WAr=i(Ce),k4=n(Ce,"LI",{});var cOe=s(k4);e4e=n(cOe,"STRONG",{});var gjt=s(e4e);QAr=r(gjt,"gptj"),gjt.forEach(t),HAr=r(cOe," \u2014 "),gK=n(cOe,"A",{href:!0});var hjt=s(gK);UAr=r(hjt,"TFGPTJForCausalLM"),hjt.forEach(t),JAr=r(cOe," (GPT-J model)"),cOe.forEach(t),YAr=i(Ce),S4=n(Ce,"LI",{});var fOe=s(S4);o4e=n(fOe,"STRONG",{});var pjt=s(o4e);KAr=r(pjt,"openai-gpt"),pjt.forEach(t),ZAr=r(fOe," \u2014 "),hK=n(fOe,"A",{href:!0});var _jt=s(hK);eLr=r(_jt,"TFOpenAIGPTLMHeadModel"),_jt.forEach(t),oLr=r(fOe," (OpenAI GPT model)"),fOe.forEach(t),rLr=i(Ce),R4=n(Ce,"LI",{});var mOe=s(R4);r4e=n(mOe,"STRONG",{});var ujt=s(r4e);tLr=r(ujt,"opt"),ujt.forEach(t),aLr=r(mOe," \u2014 "),pK=n(mOe,"A",{href:!0});var bjt=s(pK);nLr=r(bjt,"TFOPTForCausalLM"),bjt.forEach(t),sLr=r(mOe," (OPT model)"),mOe.forEach(t),lLr=i(Ce),P4=n(Ce,"LI",{});var gOe=s(P4);t4e=n(gOe,"STRONG",{});var vjt=s(t4e);iLr=r(vjt,"rembert"),vjt.forEach(t),dLr=r(gOe," \u2014 "),_K=n(gOe,"A",{href:!0});var Fjt=s(_K);cLr=r(Fjt,"TFRemBertForCausalLM"),Fjt.forEach(t),fLr=r(gOe," (RemBERT model)"),gOe.forEach(t),mLr=i(Ce),B4=n(Ce,"LI",{});var hOe=s(B4);a4e=n(hOe,"STRONG",{});var Tjt=s(a4e);gLr=r(Tjt,"roberta"),Tjt.forEach(t),hLr=r(hOe," \u2014 "),uK=n(hOe,"A",{href:!0});var Mjt=s(uK);pLr=r(Mjt,"TFRobertaForCausalLM"),Mjt.forEach(t),_Lr=r(hOe," (RoBERTa model)"),hOe.forEach(t),uLr=i(Ce),I4=n(Ce,"LI",{});var pOe=s(I4);n4e=n(pOe,"STRONG",{});var Ejt=s(n4e);bLr=r(Ejt,"roformer"),Ejt.forEach(t),vLr=r(pOe," \u2014 "),bK=n(pOe,"A",{href:!0});var Cjt=s(bK);FLr=r(Cjt,"TFRoFormerForCausalLM"),Cjt.forEach(t),TLr=r(pOe," (RoFormer model)"),pOe.forEach(t),MLr=i(Ce),N4=n(Ce,"LI",{});var _Oe=s(N4);s4e=n(_Oe,"STRONG",{});var wjt=s(s4e);ELr=r(wjt,"transfo-xl"),wjt.forEach(t),CLr=r(_Oe," \u2014 "),vK=n(_Oe,"A",{href:!0});var Ajt=s(vK);wLr=r(Ajt,"TFTransfoXLLMHeadModel"),Ajt.forEach(t),ALr=r(_Oe," (Transformer-XL model)"),_Oe.forEach(t),LLr=i(Ce),q4=n(Ce,"LI",{});var uOe=s(q4);l4e=n(uOe,"STRONG",{});var Ljt=s(l4e);yLr=r(Ljt,"xlm"),Ljt.forEach(t),xLr=r(uOe," \u2014 "),FK=n(uOe,"A",{href:!0});var yjt=s(FK);$Lr=r(yjt,"TFXLMWithLMHeadModel"),yjt.forEach(t),kLr=r(uOe," (XLM model)"),uOe.forEach(t),SLr=i(Ce),j4=n(Ce,"LI",{});var bOe=s(j4);i4e=n(bOe,"STRONG",{});var xjt=s(i4e);RLr=r(xjt,"xlnet"),xjt.forEach(t),PLr=r(bOe," \u2014 "),TK=n(bOe,"A",{href:!0});var $jt=s(TK);BLr=r($jt,"TFXLNetLMHeadModel"),$jt.forEach(t),ILr=r(bOe," (XLNet model)"),bOe.forEach(t),Ce.forEach(t),NLr=i(Vl),T(D4.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),eHe=i(f),Ac=n(f,"H2",{class:!0});var cJe=s(Ac);G4=n(cJe,"A",{id:!0,class:!0,href:!0});var kjt=s(G4);d4e=n(kjt,"SPAN",{});var Sjt=s(d4e);T(Zx.$$.fragment,Sjt),Sjt.forEach(t),kjt.forEach(t),qLr=i(cJe),c4e=n(cJe,"SPAN",{});var Rjt=s(c4e);jLr=r(Rjt,"TFAutoModelForImageClassification"),Rjt.forEach(t),cJe.forEach(t),oHe=i(f),lr=n(f,"DIV",{class:!0});var Xl=s(lr);T(e$.$$.fragment,Xl),DLr=i(Xl),Lc=n(Xl,"P",{});var ine=s(Lc);GLr=r(ine,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),MK=n(ine,"A",{href:!0});var Pjt=s(MK);OLr=r(Pjt,"from_pretrained()"),Pjt.forEach(t),VLr=r(ine," class method or the "),EK=n(ine,"A",{href:!0});var Bjt=s(EK);XLr=r(Bjt,"from_config()"),Bjt.forEach(t),zLr=r(ine,` class
method.`),ine.forEach(t),WLr=i(Xl),o$=n(Xl,"P",{});var fJe=s(o$);QLr=r(fJe,"This class cannot be instantiated directly using "),f4e=n(fJe,"CODE",{});var Ijt=s(f4e);HLr=r(Ijt,"__init__()"),Ijt.forEach(t),ULr=r(fJe," (throws an error)."),fJe.forEach(t),JLr=i(Xl),jt=n(Xl,"DIV",{class:!0});var YA=s(jt);T(r$.$$.fragment,YA),YLr=i(YA),m4e=n(YA,"P",{});var Njt=s(m4e);KLr=r(Njt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Njt.forEach(t),ZLr=i(YA),yc=n(YA,"P",{});var dne=s(yc);eyr=r(dne,`Note:
Loading a model from its configuration file does `),g4e=n(dne,"STRONG",{});var qjt=s(g4e);oyr=r(qjt,"not"),qjt.forEach(t),ryr=r(dne,` load the model weights. It only affects the
model\u2019s configuration. Use `),CK=n(dne,"A",{href:!0});var jjt=s(CK);tyr=r(jjt,"from_pretrained()"),jjt.forEach(t),ayr=r(dne," to load the model weights."),dne.forEach(t),nyr=i(YA),T(O4.$$.fragment,YA),YA.forEach(t),syr=i(Xl),Br=n(Xl,"DIV",{class:!0});var zl=s(Br);T(t$.$$.fragment,zl),lyr=i(zl),h4e=n(zl,"P",{});var Djt=s(h4e);iyr=r(Djt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Djt.forEach(t),dyr=i(zl),_n=n(zl,"P",{});var KA=s(_n);cyr=r(KA,"The model class to instantiate is selected based on the "),p4e=n(KA,"CODE",{});var Gjt=s(p4e);fyr=r(Gjt,"model_type"),Gjt.forEach(t),myr=r(KA,` property of the config object (either
passed as an argument or loaded from `),_4e=n(KA,"CODE",{});var Ojt=s(_4e);gyr=r(Ojt,"pretrained_model_name_or_path"),Ojt.forEach(t),hyr=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u4e=n(KA,"CODE",{});var Vjt=s(u4e);pyr=r(Vjt,"pretrained_model_name_or_path"),Vjt.forEach(t),_yr=r(KA,":"),KA.forEach(t),uyr=i(zl),Ve=n(zl,"UL",{});var Eo=s(Ve);V4=n(Eo,"LI",{});var vOe=s(V4);b4e=n(vOe,"STRONG",{});var Xjt=s(b4e);byr=r(Xjt,"convnext"),Xjt.forEach(t),vyr=r(vOe," \u2014 "),wK=n(vOe,"A",{href:!0});var zjt=s(wK);Fyr=r(zjt,"TFConvNextForImageClassification"),zjt.forEach(t),Tyr=r(vOe," (ConvNeXT model)"),vOe.forEach(t),Myr=i(Eo),X4=n(Eo,"LI",{});var FOe=s(X4);v4e=n(FOe,"STRONG",{});var Wjt=s(v4e);Eyr=r(Wjt,"data2vec-vision"),Wjt.forEach(t),Cyr=r(FOe," \u2014 "),AK=n(FOe,"A",{href:!0});var Qjt=s(AK);wyr=r(Qjt,"TFData2VecVisionForImageClassification"),Qjt.forEach(t),Ayr=r(FOe," (Data2VecVision model)"),FOe.forEach(t),Lyr=i(Eo),nl=n(Eo,"LI",{});var $R=s(nl);F4e=n($R,"STRONG",{});var Hjt=s(F4e);yyr=r(Hjt,"deit"),Hjt.forEach(t),xyr=r($R," \u2014 "),LK=n($R,"A",{href:!0});var Ujt=s(LK);$yr=r(Ujt,"TFDeiTForImageClassification"),Ujt.forEach(t),kyr=r($R," or "),yK=n($R,"A",{href:!0});var Jjt=s(yK);Syr=r(Jjt,"TFDeiTForImageClassificationWithTeacher"),Jjt.forEach(t),Ryr=r($R," (DeiT model)"),$R.forEach(t),Pyr=i(Eo),z4=n(Eo,"LI",{});var TOe=s(z4);T4e=n(TOe,"STRONG",{});var Yjt=s(T4e);Byr=r(Yjt,"regnet"),Yjt.forEach(t),Iyr=r(TOe," \u2014 "),xK=n(TOe,"A",{href:!0});var Kjt=s(xK);Nyr=r(Kjt,"TFRegNetForImageClassification"),Kjt.forEach(t),qyr=r(TOe," (RegNet model)"),TOe.forEach(t),jyr=i(Eo),W4=n(Eo,"LI",{});var MOe=s(W4);M4e=n(MOe,"STRONG",{});var Zjt=s(M4e);Dyr=r(Zjt,"resnet"),Zjt.forEach(t),Gyr=r(MOe," \u2014 "),$K=n(MOe,"A",{href:!0});var eDt=s($K);Oyr=r(eDt,"TFResNetForImageClassification"),eDt.forEach(t),Vyr=r(MOe," (ResNet model)"),MOe.forEach(t),Xyr=i(Eo),Q4=n(Eo,"LI",{});var EOe=s(Q4);E4e=n(EOe,"STRONG",{});var oDt=s(E4e);zyr=r(oDt,"segformer"),oDt.forEach(t),Wyr=r(EOe," \u2014 "),kK=n(EOe,"A",{href:!0});var rDt=s(kK);Qyr=r(rDt,"TFSegformerForImageClassification"),rDt.forEach(t),Hyr=r(EOe," (SegFormer model)"),EOe.forEach(t),Uyr=i(Eo),H4=n(Eo,"LI",{});var COe=s(H4);C4e=n(COe,"STRONG",{});var tDt=s(C4e);Jyr=r(tDt,"swin"),tDt.forEach(t),Yyr=r(COe," \u2014 "),SK=n(COe,"A",{href:!0});var aDt=s(SK);Kyr=r(aDt,"TFSwinForImageClassification"),aDt.forEach(t),Zyr=r(COe," (Swin Transformer model)"),COe.forEach(t),e8r=i(Eo),U4=n(Eo,"LI",{});var wOe=s(U4);w4e=n(wOe,"STRONG",{});var nDt=s(w4e);o8r=r(nDt,"vit"),nDt.forEach(t),r8r=r(wOe," \u2014 "),RK=n(wOe,"A",{href:!0});var sDt=s(RK);t8r=r(sDt,"TFViTForImageClassification"),sDt.forEach(t),a8r=r(wOe," (ViT model)"),wOe.forEach(t),Eo.forEach(t),n8r=i(zl),T(J4.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),rHe=i(f),xc=n(f,"H2",{class:!0});var mJe=s(xc);Y4=n(mJe,"A",{id:!0,class:!0,href:!0});var lDt=s(Y4);A4e=n(lDt,"SPAN",{});var iDt=s(A4e);T(a$.$$.fragment,iDt),iDt.forEach(t),lDt.forEach(t),s8r=i(mJe),L4e=n(mJe,"SPAN",{});var dDt=s(L4e);l8r=r(dDt,"TFAutoModelForMaskedLM"),dDt.forEach(t),mJe.forEach(t),tHe=i(f),ir=n(f,"DIV",{class:!0});var Wl=s(ir);T(n$.$$.fragment,Wl),i8r=i(Wl),$c=n(Wl,"P",{});var cne=s($c);d8r=r(cne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),PK=n(cne,"A",{href:!0});var cDt=s(PK);c8r=r(cDt,"from_pretrained()"),cDt.forEach(t),f8r=r(cne," class method or the "),BK=n(cne,"A",{href:!0});var fDt=s(BK);m8r=r(fDt,"from_config()"),fDt.forEach(t),g8r=r(cne,` class
method.`),cne.forEach(t),h8r=i(Wl),s$=n(Wl,"P",{});var gJe=s(s$);p8r=r(gJe,"This class cannot be instantiated directly using "),y4e=n(gJe,"CODE",{});var mDt=s(y4e);_8r=r(mDt,"__init__()"),mDt.forEach(t),u8r=r(gJe," (throws an error)."),gJe.forEach(t),b8r=i(Wl),Dt=n(Wl,"DIV",{class:!0});var ZA=s(Dt);T(l$.$$.fragment,ZA),v8r=i(ZA),x4e=n(ZA,"P",{});var gDt=s(x4e);F8r=r(gDt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),gDt.forEach(t),T8r=i(ZA),kc=n(ZA,"P",{});var fne=s(kc);M8r=r(fne,`Note:
Loading a model from its configuration file does `),$4e=n(fne,"STRONG",{});var hDt=s($4e);E8r=r(hDt,"not"),hDt.forEach(t),C8r=r(fne,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(fne,"A",{href:!0});var pDt=s(IK);w8r=r(pDt,"from_pretrained()"),pDt.forEach(t),A8r=r(fne," to load the model weights."),fne.forEach(t),L8r=i(ZA),T(K4.$$.fragment,ZA),ZA.forEach(t),y8r=i(Wl),Ir=n(Wl,"DIV",{class:!0});var Ql=s(Ir);T(i$.$$.fragment,Ql),x8r=i(Ql),k4e=n(Ql,"P",{});var _Dt=s(k4e);$8r=r(_Dt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),_Dt.forEach(t),k8r=i(Ql),un=n(Ql,"P",{});var eL=s(un);S8r=r(eL,"The model class to instantiate is selected based on the "),S4e=n(eL,"CODE",{});var uDt=s(S4e);R8r=r(uDt,"model_type"),uDt.forEach(t),P8r=r(eL,` property of the config object (either
passed as an argument or loaded from `),R4e=n(eL,"CODE",{});var bDt=s(R4e);B8r=r(bDt,"pretrained_model_name_or_path"),bDt.forEach(t),I8r=r(eL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P4e=n(eL,"CODE",{});var vDt=s(P4e);N8r=r(vDt,"pretrained_model_name_or_path"),vDt.forEach(t),q8r=r(eL,":"),eL.forEach(t),j8r=i(Ql),ie=n(Ql,"UL",{});var ge=s(ie);Z4=n(ge,"LI",{});var AOe=s(Z4);B4e=n(AOe,"STRONG",{});var FDt=s(B4e);D8r=r(FDt,"albert"),FDt.forEach(t),G8r=r(AOe," \u2014 "),NK=n(AOe,"A",{href:!0});var TDt=s(NK);O8r=r(TDt,"TFAlbertForMaskedLM"),TDt.forEach(t),V8r=r(AOe," (ALBERT model)"),AOe.forEach(t),X8r=i(ge),eC=n(ge,"LI",{});var LOe=s(eC);I4e=n(LOe,"STRONG",{});var MDt=s(I4e);z8r=r(MDt,"bert"),MDt.forEach(t),W8r=r(LOe," \u2014 "),qK=n(LOe,"A",{href:!0});var EDt=s(qK);Q8r=r(EDt,"TFBertForMaskedLM"),EDt.forEach(t),H8r=r(LOe," (BERT model)"),LOe.forEach(t),U8r=i(ge),oC=n(ge,"LI",{});var yOe=s(oC);N4e=n(yOe,"STRONG",{});var CDt=s(N4e);J8r=r(CDt,"camembert"),CDt.forEach(t),Y8r=r(yOe," \u2014 "),jK=n(yOe,"A",{href:!0});var wDt=s(jK);K8r=r(wDt,"TFCamembertForMaskedLM"),wDt.forEach(t),Z8r=r(yOe," (CamemBERT model)"),yOe.forEach(t),exr=i(ge),rC=n(ge,"LI",{});var xOe=s(rC);q4e=n(xOe,"STRONG",{});var ADt=s(q4e);oxr=r(ADt,"convbert"),ADt.forEach(t),rxr=r(xOe," \u2014 "),DK=n(xOe,"A",{href:!0});var LDt=s(DK);txr=r(LDt,"TFConvBertForMaskedLM"),LDt.forEach(t),axr=r(xOe," (ConvBERT model)"),xOe.forEach(t),nxr=i(ge),tC=n(ge,"LI",{});var $Oe=s(tC);j4e=n($Oe,"STRONG",{});var yDt=s(j4e);sxr=r(yDt,"deberta"),yDt.forEach(t),lxr=r($Oe," \u2014 "),GK=n($Oe,"A",{href:!0});var xDt=s(GK);ixr=r(xDt,"TFDebertaForMaskedLM"),xDt.forEach(t),dxr=r($Oe," (DeBERTa model)"),$Oe.forEach(t),cxr=i(ge),aC=n(ge,"LI",{});var kOe=s(aC);D4e=n(kOe,"STRONG",{});var $Dt=s(D4e);fxr=r($Dt,"deberta-v2"),$Dt.forEach(t),mxr=r(kOe," \u2014 "),OK=n(kOe,"A",{href:!0});var kDt=s(OK);gxr=r(kDt,"TFDebertaV2ForMaskedLM"),kDt.forEach(t),hxr=r(kOe," (DeBERTa-v2 model)"),kOe.forEach(t),pxr=i(ge),nC=n(ge,"LI",{});var SOe=s(nC);G4e=n(SOe,"STRONG",{});var SDt=s(G4e);_xr=r(SDt,"distilbert"),SDt.forEach(t),uxr=r(SOe," \u2014 "),VK=n(SOe,"A",{href:!0});var RDt=s(VK);bxr=r(RDt,"TFDistilBertForMaskedLM"),RDt.forEach(t),vxr=r(SOe," (DistilBERT model)"),SOe.forEach(t),Fxr=i(ge),sC=n(ge,"LI",{});var ROe=s(sC);O4e=n(ROe,"STRONG",{});var PDt=s(O4e);Txr=r(PDt,"electra"),PDt.forEach(t),Mxr=r(ROe," \u2014 "),XK=n(ROe,"A",{href:!0});var BDt=s(XK);Exr=r(BDt,"TFElectraForMaskedLM"),BDt.forEach(t),Cxr=r(ROe," (ELECTRA model)"),ROe.forEach(t),wxr=i(ge),lC=n(ge,"LI",{});var POe=s(lC);V4e=n(POe,"STRONG",{});var IDt=s(V4e);Axr=r(IDt,"flaubert"),IDt.forEach(t),Lxr=r(POe," \u2014 "),zK=n(POe,"A",{href:!0});var NDt=s(zK);yxr=r(NDt,"TFFlaubertWithLMHeadModel"),NDt.forEach(t),xxr=r(POe," (FlauBERT model)"),POe.forEach(t),$xr=i(ge),iC=n(ge,"LI",{});var BOe=s(iC);X4e=n(BOe,"STRONG",{});var qDt=s(X4e);kxr=r(qDt,"funnel"),qDt.forEach(t),Sxr=r(BOe," \u2014 "),WK=n(BOe,"A",{href:!0});var jDt=s(WK);Rxr=r(jDt,"TFFunnelForMaskedLM"),jDt.forEach(t),Pxr=r(BOe," (Funnel Transformer model)"),BOe.forEach(t),Bxr=i(ge),dC=n(ge,"LI",{});var IOe=s(dC);z4e=n(IOe,"STRONG",{});var DDt=s(z4e);Ixr=r(DDt,"layoutlm"),DDt.forEach(t),Nxr=r(IOe," \u2014 "),QK=n(IOe,"A",{href:!0});var GDt=s(QK);qxr=r(GDt,"TFLayoutLMForMaskedLM"),GDt.forEach(t),jxr=r(IOe," (LayoutLM model)"),IOe.forEach(t),Dxr=i(ge),cC=n(ge,"LI",{});var NOe=s(cC);W4e=n(NOe,"STRONG",{});var ODt=s(W4e);Gxr=r(ODt,"longformer"),ODt.forEach(t),Oxr=r(NOe," \u2014 "),HK=n(NOe,"A",{href:!0});var VDt=s(HK);Vxr=r(VDt,"TFLongformerForMaskedLM"),VDt.forEach(t),Xxr=r(NOe," (Longformer model)"),NOe.forEach(t),zxr=i(ge),fC=n(ge,"LI",{});var qOe=s(fC);Q4e=n(qOe,"STRONG",{});var XDt=s(Q4e);Wxr=r(XDt,"mobilebert"),XDt.forEach(t),Qxr=r(qOe," \u2014 "),UK=n(qOe,"A",{href:!0});var zDt=s(UK);Hxr=r(zDt,"TFMobileBertForMaskedLM"),zDt.forEach(t),Uxr=r(qOe," (MobileBERT model)"),qOe.forEach(t),Jxr=i(ge),mC=n(ge,"LI",{});var jOe=s(mC);H4e=n(jOe,"STRONG",{});var WDt=s(H4e);Yxr=r(WDt,"mpnet"),WDt.forEach(t),Kxr=r(jOe," \u2014 "),JK=n(jOe,"A",{href:!0});var QDt=s(JK);Zxr=r(QDt,"TFMPNetForMaskedLM"),QDt.forEach(t),e$r=r(jOe," (MPNet model)"),jOe.forEach(t),o$r=i(ge),gC=n(ge,"LI",{});var DOe=s(gC);U4e=n(DOe,"STRONG",{});var HDt=s(U4e);r$r=r(HDt,"rembert"),HDt.forEach(t),t$r=r(DOe," \u2014 "),YK=n(DOe,"A",{href:!0});var UDt=s(YK);a$r=r(UDt,"TFRemBertForMaskedLM"),UDt.forEach(t),n$r=r(DOe," (RemBERT model)"),DOe.forEach(t),s$r=i(ge),hC=n(ge,"LI",{});var GOe=s(hC);J4e=n(GOe,"STRONG",{});var JDt=s(J4e);l$r=r(JDt,"roberta"),JDt.forEach(t),i$r=r(GOe," \u2014 "),KK=n(GOe,"A",{href:!0});var YDt=s(KK);d$r=r(YDt,"TFRobertaForMaskedLM"),YDt.forEach(t),c$r=r(GOe," (RoBERTa model)"),GOe.forEach(t),f$r=i(ge),pC=n(ge,"LI",{});var OOe=s(pC);Y4e=n(OOe,"STRONG",{});var KDt=s(Y4e);m$r=r(KDt,"roformer"),KDt.forEach(t),g$r=r(OOe," \u2014 "),ZK=n(OOe,"A",{href:!0});var ZDt=s(ZK);h$r=r(ZDt,"TFRoFormerForMaskedLM"),ZDt.forEach(t),p$r=r(OOe," (RoFormer model)"),OOe.forEach(t),_$r=i(ge),_C=n(ge,"LI",{});var VOe=s(_C);K4e=n(VOe,"STRONG",{});var eGt=s(K4e);u$r=r(eGt,"tapas"),eGt.forEach(t),b$r=r(VOe," \u2014 "),eZ=n(VOe,"A",{href:!0});var oGt=s(eZ);v$r=r(oGt,"TFTapasForMaskedLM"),oGt.forEach(t),F$r=r(VOe," (TAPAS model)"),VOe.forEach(t),T$r=i(ge),uC=n(ge,"LI",{});var XOe=s(uC);Z4e=n(XOe,"STRONG",{});var rGt=s(Z4e);M$r=r(rGt,"xlm"),rGt.forEach(t),E$r=r(XOe," \u2014 "),oZ=n(XOe,"A",{href:!0});var tGt=s(oZ);C$r=r(tGt,"TFXLMWithLMHeadModel"),tGt.forEach(t),w$r=r(XOe," (XLM model)"),XOe.forEach(t),A$r=i(ge),bC=n(ge,"LI",{});var zOe=s(bC);eCe=n(zOe,"STRONG",{});var aGt=s(eCe);L$r=r(aGt,"xlm-roberta"),aGt.forEach(t),y$r=r(zOe," \u2014 "),rZ=n(zOe,"A",{href:!0});var nGt=s(rZ);x$r=r(nGt,"TFXLMRobertaForMaskedLM"),nGt.forEach(t),$$r=r(zOe," (XLM-RoBERTa model)"),zOe.forEach(t),ge.forEach(t),k$r=i(Ql),T(vC.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),aHe=i(f),Sc=n(f,"H2",{class:!0});var hJe=s(Sc);FC=n(hJe,"A",{id:!0,class:!0,href:!0});var sGt=s(FC);oCe=n(sGt,"SPAN",{});var lGt=s(oCe);T(d$.$$.fragment,lGt),lGt.forEach(t),sGt.forEach(t),S$r=i(hJe),rCe=n(hJe,"SPAN",{});var iGt=s(rCe);R$r=r(iGt,"TFAutoModelForSeq2SeqLM"),iGt.forEach(t),hJe.forEach(t),nHe=i(f),dr=n(f,"DIV",{class:!0});var Hl=s(dr);T(c$.$$.fragment,Hl),P$r=i(Hl),Rc=n(Hl,"P",{});var mne=s(Rc);B$r=r(mne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),tZ=n(mne,"A",{href:!0});var dGt=s(tZ);I$r=r(dGt,"from_pretrained()"),dGt.forEach(t),N$r=r(mne," class method or the "),aZ=n(mne,"A",{href:!0});var cGt=s(aZ);q$r=r(cGt,"from_config()"),cGt.forEach(t),j$r=r(mne,` class
method.`),mne.forEach(t),D$r=i(Hl),f$=n(Hl,"P",{});var pJe=s(f$);G$r=r(pJe,"This class cannot be instantiated directly using "),tCe=n(pJe,"CODE",{});var fGt=s(tCe);O$r=r(fGt,"__init__()"),fGt.forEach(t),V$r=r(pJe," (throws an error)."),pJe.forEach(t),X$r=i(Hl),Gt=n(Hl,"DIV",{class:!0});var oL=s(Gt);T(m$.$$.fragment,oL),z$r=i(oL),aCe=n(oL,"P",{});var mGt=s(aCe);W$r=r(mGt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),mGt.forEach(t),Q$r=i(oL),Pc=n(oL,"P",{});var gne=s(Pc);H$r=r(gne,`Note:
Loading a model from its configuration file does `),nCe=n(gne,"STRONG",{});var gGt=s(nCe);U$r=r(gGt,"not"),gGt.forEach(t),J$r=r(gne,` load the model weights. It only affects the
model\u2019s configuration. Use `),nZ=n(gne,"A",{href:!0});var hGt=s(nZ);Y$r=r(hGt,"from_pretrained()"),hGt.forEach(t),K$r=r(gne," to load the model weights."),gne.forEach(t),Z$r=i(oL),T(TC.$$.fragment,oL),oL.forEach(t),ekr=i(Hl),Nr=n(Hl,"DIV",{class:!0});var Ul=s(Nr);T(g$.$$.fragment,Ul),okr=i(Ul),sCe=n(Ul,"P",{});var pGt=s(sCe);rkr=r(pGt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),pGt.forEach(t),tkr=i(Ul),bn=n(Ul,"P",{});var rL=s(bn);akr=r(rL,"The model class to instantiate is selected based on the "),lCe=n(rL,"CODE",{});var _Gt=s(lCe);nkr=r(_Gt,"model_type"),_Gt.forEach(t),skr=r(rL,` property of the config object (either
passed as an argument or loaded from `),iCe=n(rL,"CODE",{});var uGt=s(iCe);lkr=r(uGt,"pretrained_model_name_or_path"),uGt.forEach(t),ikr=r(rL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dCe=n(rL,"CODE",{});var bGt=s(dCe);dkr=r(bGt,"pretrained_model_name_or_path"),bGt.forEach(t),ckr=r(rL,":"),rL.forEach(t),fkr=i(Ul),ye=n(Ul,"UL",{});var Ie=s(ye);MC=n(Ie,"LI",{});var WOe=s(MC);cCe=n(WOe,"STRONG",{});var vGt=s(cCe);mkr=r(vGt,"bart"),vGt.forEach(t),gkr=r(WOe," \u2014 "),sZ=n(WOe,"A",{href:!0});var FGt=s(sZ);hkr=r(FGt,"TFBartForConditionalGeneration"),FGt.forEach(t),pkr=r(WOe," (BART model)"),WOe.forEach(t),_kr=i(Ie),EC=n(Ie,"LI",{});var QOe=s(EC);fCe=n(QOe,"STRONG",{});var TGt=s(fCe);ukr=r(TGt,"blenderbot"),TGt.forEach(t),bkr=r(QOe," \u2014 "),lZ=n(QOe,"A",{href:!0});var MGt=s(lZ);vkr=r(MGt,"TFBlenderbotForConditionalGeneration"),MGt.forEach(t),Fkr=r(QOe," (Blenderbot model)"),QOe.forEach(t),Tkr=i(Ie),CC=n(Ie,"LI",{});var HOe=s(CC);mCe=n(HOe,"STRONG",{});var EGt=s(mCe);Mkr=r(EGt,"blenderbot-small"),EGt.forEach(t),Ekr=r(HOe," \u2014 "),iZ=n(HOe,"A",{href:!0});var CGt=s(iZ);Ckr=r(CGt,"TFBlenderbotSmallForConditionalGeneration"),CGt.forEach(t),wkr=r(HOe," (BlenderbotSmall model)"),HOe.forEach(t),Akr=i(Ie),wC=n(Ie,"LI",{});var UOe=s(wC);gCe=n(UOe,"STRONG",{});var wGt=s(gCe);Lkr=r(wGt,"encoder-decoder"),wGt.forEach(t),ykr=r(UOe," \u2014 "),dZ=n(UOe,"A",{href:!0});var AGt=s(dZ);xkr=r(AGt,"TFEncoderDecoderModel"),AGt.forEach(t),$kr=r(UOe," (Encoder decoder model)"),UOe.forEach(t),kkr=i(Ie),AC=n(Ie,"LI",{});var JOe=s(AC);hCe=n(JOe,"STRONG",{});var LGt=s(hCe);Skr=r(LGt,"led"),LGt.forEach(t),Rkr=r(JOe," \u2014 "),cZ=n(JOe,"A",{href:!0});var yGt=s(cZ);Pkr=r(yGt,"TFLEDForConditionalGeneration"),yGt.forEach(t),Bkr=r(JOe," (LED model)"),JOe.forEach(t),Ikr=i(Ie),LC=n(Ie,"LI",{});var YOe=s(LC);pCe=n(YOe,"STRONG",{});var xGt=s(pCe);Nkr=r(xGt,"marian"),xGt.forEach(t),qkr=r(YOe," \u2014 "),fZ=n(YOe,"A",{href:!0});var $Gt=s(fZ);jkr=r($Gt,"TFMarianMTModel"),$Gt.forEach(t),Dkr=r(YOe," (Marian model)"),YOe.forEach(t),Gkr=i(Ie),yC=n(Ie,"LI",{});var KOe=s(yC);_Ce=n(KOe,"STRONG",{});var kGt=s(_Ce);Okr=r(kGt,"mbart"),kGt.forEach(t),Vkr=r(KOe," \u2014 "),mZ=n(KOe,"A",{href:!0});var SGt=s(mZ);Xkr=r(SGt,"TFMBartForConditionalGeneration"),SGt.forEach(t),zkr=r(KOe," (mBART model)"),KOe.forEach(t),Wkr=i(Ie),xC=n(Ie,"LI",{});var ZOe=s(xC);uCe=n(ZOe,"STRONG",{});var RGt=s(uCe);Qkr=r(RGt,"mt5"),RGt.forEach(t),Hkr=r(ZOe," \u2014 "),gZ=n(ZOe,"A",{href:!0});var PGt=s(gZ);Ukr=r(PGt,"TFMT5ForConditionalGeneration"),PGt.forEach(t),Jkr=r(ZOe," (MT5 model)"),ZOe.forEach(t),Ykr=i(Ie),$C=n(Ie,"LI",{});var eVe=s($C);bCe=n(eVe,"STRONG",{});var BGt=s(bCe);Kkr=r(BGt,"pegasus"),BGt.forEach(t),Zkr=r(eVe," \u2014 "),hZ=n(eVe,"A",{href:!0});var IGt=s(hZ);eSr=r(IGt,"TFPegasusForConditionalGeneration"),IGt.forEach(t),oSr=r(eVe," (Pegasus model)"),eVe.forEach(t),rSr=i(Ie),kC=n(Ie,"LI",{});var oVe=s(kC);vCe=n(oVe,"STRONG",{});var NGt=s(vCe);tSr=r(NGt,"t5"),NGt.forEach(t),aSr=r(oVe," \u2014 "),pZ=n(oVe,"A",{href:!0});var qGt=s(pZ);nSr=r(qGt,"TFT5ForConditionalGeneration"),qGt.forEach(t),sSr=r(oVe," (T5 model)"),oVe.forEach(t),Ie.forEach(t),lSr=i(Ul),T(SC.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),sHe=i(f),Bc=n(f,"H2",{class:!0});var _Je=s(Bc);RC=n(_Je,"A",{id:!0,class:!0,href:!0});var jGt=s(RC);FCe=n(jGt,"SPAN",{});var DGt=s(FCe);T(h$.$$.fragment,DGt),DGt.forEach(t),jGt.forEach(t),iSr=i(_Je),TCe=n(_Je,"SPAN",{});var GGt=s(TCe);dSr=r(GGt,"TFAutoModelForSequenceClassification"),GGt.forEach(t),_Je.forEach(t),lHe=i(f),cr=n(f,"DIV",{class:!0});var Jl=s(cr);T(p$.$$.fragment,Jl),cSr=i(Jl),Ic=n(Jl,"P",{});var hne=s(Ic);fSr=r(hne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),_Z=n(hne,"A",{href:!0});var OGt=s(_Z);mSr=r(OGt,"from_pretrained()"),OGt.forEach(t),gSr=r(hne," class method or the "),uZ=n(hne,"A",{href:!0});var VGt=s(uZ);hSr=r(VGt,"from_config()"),VGt.forEach(t),pSr=r(hne,` class
method.`),hne.forEach(t),_Sr=i(Jl),_$=n(Jl,"P",{});var uJe=s(_$);uSr=r(uJe,"This class cannot be instantiated directly using "),MCe=n(uJe,"CODE",{});var XGt=s(MCe);bSr=r(XGt,"__init__()"),XGt.forEach(t),vSr=r(uJe," (throws an error)."),uJe.forEach(t),FSr=i(Jl),Ot=n(Jl,"DIV",{class:!0});var tL=s(Ot);T(u$.$$.fragment,tL),TSr=i(tL),ECe=n(tL,"P",{});var zGt=s(ECe);MSr=r(zGt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),zGt.forEach(t),ESr=i(tL),Nc=n(tL,"P",{});var pne=s(Nc);CSr=r(pne,`Note:
Loading a model from its configuration file does `),CCe=n(pne,"STRONG",{});var WGt=s(CCe);wSr=r(WGt,"not"),WGt.forEach(t),ASr=r(pne,` load the model weights. It only affects the
model\u2019s configuration. Use `),bZ=n(pne,"A",{href:!0});var QGt=s(bZ);LSr=r(QGt,"from_pretrained()"),QGt.forEach(t),ySr=r(pne," to load the model weights."),pne.forEach(t),xSr=i(tL),T(PC.$$.fragment,tL),tL.forEach(t),$Sr=i(Jl),qr=n(Jl,"DIV",{class:!0});var Yl=s(qr);T(b$.$$.fragment,Yl),kSr=i(Yl),wCe=n(Yl,"P",{});var HGt=s(wCe);SSr=r(HGt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),HGt.forEach(t),RSr=i(Yl),vn=n(Yl,"P",{});var aL=s(vn);PSr=r(aL,"The model class to instantiate is selected based on the "),ACe=n(aL,"CODE",{});var UGt=s(ACe);BSr=r(UGt,"model_type"),UGt.forEach(t),ISr=r(aL,` property of the config object (either
passed as an argument or loaded from `),LCe=n(aL,"CODE",{});var JGt=s(LCe);NSr=r(JGt,"pretrained_model_name_or_path"),JGt.forEach(t),qSr=r(aL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),yCe=n(aL,"CODE",{});var YGt=s(yCe);jSr=r(YGt,"pretrained_model_name_or_path"),YGt.forEach(t),DSr=r(aL,":"),aL.forEach(t),GSr=i(Yl),ae=n(Yl,"UL",{});var ne=s(ae);BC=n(ne,"LI",{});var rVe=s(BC);xCe=n(rVe,"STRONG",{});var KGt=s(xCe);OSr=r(KGt,"albert"),KGt.forEach(t),VSr=r(rVe," \u2014 "),vZ=n(rVe,"A",{href:!0});var ZGt=s(vZ);XSr=r(ZGt,"TFAlbertForSequenceClassification"),ZGt.forEach(t),zSr=r(rVe," (ALBERT model)"),rVe.forEach(t),WSr=i(ne),IC=n(ne,"LI",{});var tVe=s(IC);$Ce=n(tVe,"STRONG",{});var eOt=s($Ce);QSr=r(eOt,"bert"),eOt.forEach(t),HSr=r(tVe," \u2014 "),FZ=n(tVe,"A",{href:!0});var oOt=s(FZ);USr=r(oOt,"TFBertForSequenceClassification"),oOt.forEach(t),JSr=r(tVe," (BERT model)"),tVe.forEach(t),YSr=i(ne),NC=n(ne,"LI",{});var aVe=s(NC);kCe=n(aVe,"STRONG",{});var rOt=s(kCe);KSr=r(rOt,"camembert"),rOt.forEach(t),ZSr=r(aVe," \u2014 "),TZ=n(aVe,"A",{href:!0});var tOt=s(TZ);eRr=r(tOt,"TFCamembertForSequenceClassification"),tOt.forEach(t),oRr=r(aVe," (CamemBERT model)"),aVe.forEach(t),rRr=i(ne),qC=n(ne,"LI",{});var nVe=s(qC);SCe=n(nVe,"STRONG",{});var aOt=s(SCe);tRr=r(aOt,"convbert"),aOt.forEach(t),aRr=r(nVe," \u2014 "),MZ=n(nVe,"A",{href:!0});var nOt=s(MZ);nRr=r(nOt,"TFConvBertForSequenceClassification"),nOt.forEach(t),sRr=r(nVe," (ConvBERT model)"),nVe.forEach(t),lRr=i(ne),jC=n(ne,"LI",{});var sVe=s(jC);RCe=n(sVe,"STRONG",{});var sOt=s(RCe);iRr=r(sOt,"ctrl"),sOt.forEach(t),dRr=r(sVe," \u2014 "),EZ=n(sVe,"A",{href:!0});var lOt=s(EZ);cRr=r(lOt,"TFCTRLForSequenceClassification"),lOt.forEach(t),fRr=r(sVe," (CTRL model)"),sVe.forEach(t),mRr=i(ne),DC=n(ne,"LI",{});var lVe=s(DC);PCe=n(lVe,"STRONG",{});var iOt=s(PCe);gRr=r(iOt,"deberta"),iOt.forEach(t),hRr=r(lVe," \u2014 "),CZ=n(lVe,"A",{href:!0});var dOt=s(CZ);pRr=r(dOt,"TFDebertaForSequenceClassification"),dOt.forEach(t),_Rr=r(lVe," (DeBERTa model)"),lVe.forEach(t),uRr=i(ne),GC=n(ne,"LI",{});var iVe=s(GC);BCe=n(iVe,"STRONG",{});var cOt=s(BCe);bRr=r(cOt,"deberta-v2"),cOt.forEach(t),vRr=r(iVe," \u2014 "),wZ=n(iVe,"A",{href:!0});var fOt=s(wZ);FRr=r(fOt,"TFDebertaV2ForSequenceClassification"),fOt.forEach(t),TRr=r(iVe," (DeBERTa-v2 model)"),iVe.forEach(t),MRr=i(ne),OC=n(ne,"LI",{});var dVe=s(OC);ICe=n(dVe,"STRONG",{});var mOt=s(ICe);ERr=r(mOt,"distilbert"),mOt.forEach(t),CRr=r(dVe," \u2014 "),AZ=n(dVe,"A",{href:!0});var gOt=s(AZ);wRr=r(gOt,"TFDistilBertForSequenceClassification"),gOt.forEach(t),ARr=r(dVe," (DistilBERT model)"),dVe.forEach(t),LRr=i(ne),VC=n(ne,"LI",{});var cVe=s(VC);NCe=n(cVe,"STRONG",{});var hOt=s(NCe);yRr=r(hOt,"electra"),hOt.forEach(t),xRr=r(cVe," \u2014 "),LZ=n(cVe,"A",{href:!0});var pOt=s(LZ);$Rr=r(pOt,"TFElectraForSequenceClassification"),pOt.forEach(t),kRr=r(cVe," (ELECTRA model)"),cVe.forEach(t),SRr=i(ne),XC=n(ne,"LI",{});var fVe=s(XC);qCe=n(fVe,"STRONG",{});var _Ot=s(qCe);RRr=r(_Ot,"flaubert"),_Ot.forEach(t),PRr=r(fVe," \u2014 "),yZ=n(fVe,"A",{href:!0});var uOt=s(yZ);BRr=r(uOt,"TFFlaubertForSequenceClassification"),uOt.forEach(t),IRr=r(fVe," (FlauBERT model)"),fVe.forEach(t),NRr=i(ne),zC=n(ne,"LI",{});var mVe=s(zC);jCe=n(mVe,"STRONG",{});var bOt=s(jCe);qRr=r(bOt,"funnel"),bOt.forEach(t),jRr=r(mVe," \u2014 "),xZ=n(mVe,"A",{href:!0});var vOt=s(xZ);DRr=r(vOt,"TFFunnelForSequenceClassification"),vOt.forEach(t),GRr=r(mVe," (Funnel Transformer model)"),mVe.forEach(t),ORr=i(ne),WC=n(ne,"LI",{});var gVe=s(WC);DCe=n(gVe,"STRONG",{});var FOt=s(DCe);VRr=r(FOt,"gpt2"),FOt.forEach(t),XRr=r(gVe," \u2014 "),$Z=n(gVe,"A",{href:!0});var TOt=s($Z);zRr=r(TOt,"TFGPT2ForSequenceClassification"),TOt.forEach(t),WRr=r(gVe," (OpenAI GPT-2 model)"),gVe.forEach(t),QRr=i(ne),QC=n(ne,"LI",{});var hVe=s(QC);GCe=n(hVe,"STRONG",{});var MOt=s(GCe);HRr=r(MOt,"gptj"),MOt.forEach(t),URr=r(hVe," \u2014 "),kZ=n(hVe,"A",{href:!0});var EOt=s(kZ);JRr=r(EOt,"TFGPTJForSequenceClassification"),EOt.forEach(t),YRr=r(hVe," (GPT-J model)"),hVe.forEach(t),KRr=i(ne),HC=n(ne,"LI",{});var pVe=s(HC);OCe=n(pVe,"STRONG",{});var COt=s(OCe);ZRr=r(COt,"layoutlm"),COt.forEach(t),ePr=r(pVe," \u2014 "),SZ=n(pVe,"A",{href:!0});var wOt=s(SZ);oPr=r(wOt,"TFLayoutLMForSequenceClassification"),wOt.forEach(t),rPr=r(pVe," (LayoutLM model)"),pVe.forEach(t),tPr=i(ne),UC=n(ne,"LI",{});var _Ve=s(UC);VCe=n(_Ve,"STRONG",{});var AOt=s(VCe);aPr=r(AOt,"longformer"),AOt.forEach(t),nPr=r(_Ve," \u2014 "),RZ=n(_Ve,"A",{href:!0});var LOt=s(RZ);sPr=r(LOt,"TFLongformerForSequenceClassification"),LOt.forEach(t),lPr=r(_Ve," (Longformer model)"),_Ve.forEach(t),iPr=i(ne),JC=n(ne,"LI",{});var uVe=s(JC);XCe=n(uVe,"STRONG",{});var yOt=s(XCe);dPr=r(yOt,"mobilebert"),yOt.forEach(t),cPr=r(uVe," \u2014 "),PZ=n(uVe,"A",{href:!0});var xOt=s(PZ);fPr=r(xOt,"TFMobileBertForSequenceClassification"),xOt.forEach(t),mPr=r(uVe," (MobileBERT model)"),uVe.forEach(t),gPr=i(ne),YC=n(ne,"LI",{});var bVe=s(YC);zCe=n(bVe,"STRONG",{});var $Ot=s(zCe);hPr=r($Ot,"mpnet"),$Ot.forEach(t),pPr=r(bVe," \u2014 "),BZ=n(bVe,"A",{href:!0});var kOt=s(BZ);_Pr=r(kOt,"TFMPNetForSequenceClassification"),kOt.forEach(t),uPr=r(bVe," (MPNet model)"),bVe.forEach(t),bPr=i(ne),KC=n(ne,"LI",{});var vVe=s(KC);WCe=n(vVe,"STRONG",{});var SOt=s(WCe);vPr=r(SOt,"openai-gpt"),SOt.forEach(t),FPr=r(vVe," \u2014 "),IZ=n(vVe,"A",{href:!0});var ROt=s(IZ);TPr=r(ROt,"TFOpenAIGPTForSequenceClassification"),ROt.forEach(t),MPr=r(vVe," (OpenAI GPT model)"),vVe.forEach(t),EPr=i(ne),ZC=n(ne,"LI",{});var FVe=s(ZC);QCe=n(FVe,"STRONG",{});var POt=s(QCe);CPr=r(POt,"rembert"),POt.forEach(t),wPr=r(FVe," \u2014 "),NZ=n(FVe,"A",{href:!0});var BOt=s(NZ);APr=r(BOt,"TFRemBertForSequenceClassification"),BOt.forEach(t),LPr=r(FVe," (RemBERT model)"),FVe.forEach(t),yPr=i(ne),e3=n(ne,"LI",{});var TVe=s(e3);HCe=n(TVe,"STRONG",{});var IOt=s(HCe);xPr=r(IOt,"roberta"),IOt.forEach(t),$Pr=r(TVe," \u2014 "),qZ=n(TVe,"A",{href:!0});var NOt=s(qZ);kPr=r(NOt,"TFRobertaForSequenceClassification"),NOt.forEach(t),SPr=r(TVe," (RoBERTa model)"),TVe.forEach(t),RPr=i(ne),o3=n(ne,"LI",{});var MVe=s(o3);UCe=n(MVe,"STRONG",{});var qOt=s(UCe);PPr=r(qOt,"roformer"),qOt.forEach(t),BPr=r(MVe," \u2014 "),jZ=n(MVe,"A",{href:!0});var jOt=s(jZ);IPr=r(jOt,"TFRoFormerForSequenceClassification"),jOt.forEach(t),NPr=r(MVe," (RoFormer model)"),MVe.forEach(t),qPr=i(ne),r3=n(ne,"LI",{});var EVe=s(r3);JCe=n(EVe,"STRONG",{});var DOt=s(JCe);jPr=r(DOt,"tapas"),DOt.forEach(t),DPr=r(EVe," \u2014 "),DZ=n(EVe,"A",{href:!0});var GOt=s(DZ);GPr=r(GOt,"TFTapasForSequenceClassification"),GOt.forEach(t),OPr=r(EVe," (TAPAS model)"),EVe.forEach(t),VPr=i(ne),t3=n(ne,"LI",{});var CVe=s(t3);YCe=n(CVe,"STRONG",{});var OOt=s(YCe);XPr=r(OOt,"transfo-xl"),OOt.forEach(t),zPr=r(CVe," \u2014 "),GZ=n(CVe,"A",{href:!0});var VOt=s(GZ);WPr=r(VOt,"TFTransfoXLForSequenceClassification"),VOt.forEach(t),QPr=r(CVe," (Transformer-XL model)"),CVe.forEach(t),HPr=i(ne),a3=n(ne,"LI",{});var wVe=s(a3);KCe=n(wVe,"STRONG",{});var XOt=s(KCe);UPr=r(XOt,"xlm"),XOt.forEach(t),JPr=r(wVe," \u2014 "),OZ=n(wVe,"A",{href:!0});var zOt=s(OZ);YPr=r(zOt,"TFXLMForSequenceClassification"),zOt.forEach(t),KPr=r(wVe," (XLM model)"),wVe.forEach(t),ZPr=i(ne),n3=n(ne,"LI",{});var AVe=s(n3);ZCe=n(AVe,"STRONG",{});var WOt=s(ZCe);eBr=r(WOt,"xlm-roberta"),WOt.forEach(t),oBr=r(AVe," \u2014 "),VZ=n(AVe,"A",{href:!0});var QOt=s(VZ);rBr=r(QOt,"TFXLMRobertaForSequenceClassification"),QOt.forEach(t),tBr=r(AVe," (XLM-RoBERTa model)"),AVe.forEach(t),aBr=i(ne),s3=n(ne,"LI",{});var LVe=s(s3);e3e=n(LVe,"STRONG",{});var HOt=s(e3e);nBr=r(HOt,"xlnet"),HOt.forEach(t),sBr=r(LVe," \u2014 "),XZ=n(LVe,"A",{href:!0});var UOt=s(XZ);lBr=r(UOt,"TFXLNetForSequenceClassification"),UOt.forEach(t),iBr=r(LVe," (XLNet model)"),LVe.forEach(t),ne.forEach(t),dBr=i(Yl),T(l3.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),iHe=i(f),qc=n(f,"H2",{class:!0});var bJe=s(qc);i3=n(bJe,"A",{id:!0,class:!0,href:!0});var JOt=s(i3);o3e=n(JOt,"SPAN",{});var YOt=s(o3e);T(v$.$$.fragment,YOt),YOt.forEach(t),JOt.forEach(t),cBr=i(bJe),r3e=n(bJe,"SPAN",{});var KOt=s(r3e);fBr=r(KOt,"TFAutoModelForMultipleChoice"),KOt.forEach(t),bJe.forEach(t),dHe=i(f),fr=n(f,"DIV",{class:!0});var Kl=s(fr);T(F$.$$.fragment,Kl),mBr=i(Kl),jc=n(Kl,"P",{});var _ne=s(jc);gBr=r(_ne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),zZ=n(_ne,"A",{href:!0});var ZOt=s(zZ);hBr=r(ZOt,"from_pretrained()"),ZOt.forEach(t),pBr=r(_ne," class method or the "),WZ=n(_ne,"A",{href:!0});var eVt=s(WZ);_Br=r(eVt,"from_config()"),eVt.forEach(t),uBr=r(_ne,` class
method.`),_ne.forEach(t),bBr=i(Kl),T$=n(Kl,"P",{});var vJe=s(T$);vBr=r(vJe,"This class cannot be instantiated directly using "),t3e=n(vJe,"CODE",{});var oVt=s(t3e);FBr=r(oVt,"__init__()"),oVt.forEach(t),TBr=r(vJe," (throws an error)."),vJe.forEach(t),MBr=i(Kl),Vt=n(Kl,"DIV",{class:!0});var nL=s(Vt);T(M$.$$.fragment,nL),EBr=i(nL),a3e=n(nL,"P",{});var rVt=s(a3e);CBr=r(rVt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),rVt.forEach(t),wBr=i(nL),Dc=n(nL,"P",{});var une=s(Dc);ABr=r(une,`Note:
Loading a model from its configuration file does `),n3e=n(une,"STRONG",{});var tVt=s(n3e);LBr=r(tVt,"not"),tVt.forEach(t),yBr=r(une,` load the model weights. It only affects the
model\u2019s configuration. Use `),QZ=n(une,"A",{href:!0});var aVt=s(QZ);xBr=r(aVt,"from_pretrained()"),aVt.forEach(t),$Br=r(une," to load the model weights."),une.forEach(t),kBr=i(nL),T(d3.$$.fragment,nL),nL.forEach(t),SBr=i(Kl),jr=n(Kl,"DIV",{class:!0});var Zl=s(jr);T(E$.$$.fragment,Zl),RBr=i(Zl),s3e=n(Zl,"P",{});var nVt=s(s3e);PBr=r(nVt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),nVt.forEach(t),BBr=i(Zl),Fn=n(Zl,"P",{});var sL=s(Fn);IBr=r(sL,"The model class to instantiate is selected based on the "),l3e=n(sL,"CODE",{});var sVt=s(l3e);NBr=r(sVt,"model_type"),sVt.forEach(t),qBr=r(sL,` property of the config object (either
passed as an argument or loaded from `),i3e=n(sL,"CODE",{});var lVt=s(i3e);jBr=r(lVt,"pretrained_model_name_or_path"),lVt.forEach(t),DBr=r(sL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d3e=n(sL,"CODE",{});var iVt=s(d3e);GBr=r(iVt,"pretrained_model_name_or_path"),iVt.forEach(t),OBr=r(sL,":"),sL.forEach(t),VBr=i(Zl),ve=n(Zl,"UL",{});var Te=s(ve);c3=n(Te,"LI",{});var yVe=s(c3);c3e=n(yVe,"STRONG",{});var dVt=s(c3e);XBr=r(dVt,"albert"),dVt.forEach(t),zBr=r(yVe," \u2014 "),HZ=n(yVe,"A",{href:!0});var cVt=s(HZ);WBr=r(cVt,"TFAlbertForMultipleChoice"),cVt.forEach(t),QBr=r(yVe," (ALBERT model)"),yVe.forEach(t),HBr=i(Te),f3=n(Te,"LI",{});var xVe=s(f3);f3e=n(xVe,"STRONG",{});var fVt=s(f3e);UBr=r(fVt,"bert"),fVt.forEach(t),JBr=r(xVe," \u2014 "),UZ=n(xVe,"A",{href:!0});var mVt=s(UZ);YBr=r(mVt,"TFBertForMultipleChoice"),mVt.forEach(t),KBr=r(xVe," (BERT model)"),xVe.forEach(t),ZBr=i(Te),m3=n(Te,"LI",{});var $Ve=s(m3);m3e=n($Ve,"STRONG",{});var gVt=s(m3e);eIr=r(gVt,"camembert"),gVt.forEach(t),oIr=r($Ve," \u2014 "),JZ=n($Ve,"A",{href:!0});var hVt=s(JZ);rIr=r(hVt,"TFCamembertForMultipleChoice"),hVt.forEach(t),tIr=r($Ve," (CamemBERT model)"),$Ve.forEach(t),aIr=i(Te),g3=n(Te,"LI",{});var kVe=s(g3);g3e=n(kVe,"STRONG",{});var pVt=s(g3e);nIr=r(pVt,"convbert"),pVt.forEach(t),sIr=r(kVe," \u2014 "),YZ=n(kVe,"A",{href:!0});var _Vt=s(YZ);lIr=r(_Vt,"TFConvBertForMultipleChoice"),_Vt.forEach(t),iIr=r(kVe," (ConvBERT model)"),kVe.forEach(t),dIr=i(Te),h3=n(Te,"LI",{});var SVe=s(h3);h3e=n(SVe,"STRONG",{});var uVt=s(h3e);cIr=r(uVt,"distilbert"),uVt.forEach(t),fIr=r(SVe," \u2014 "),KZ=n(SVe,"A",{href:!0});var bVt=s(KZ);mIr=r(bVt,"TFDistilBertForMultipleChoice"),bVt.forEach(t),gIr=r(SVe," (DistilBERT model)"),SVe.forEach(t),hIr=i(Te),p3=n(Te,"LI",{});var RVe=s(p3);p3e=n(RVe,"STRONG",{});var vVt=s(p3e);pIr=r(vVt,"electra"),vVt.forEach(t),_Ir=r(RVe," \u2014 "),ZZ=n(RVe,"A",{href:!0});var FVt=s(ZZ);uIr=r(FVt,"TFElectraForMultipleChoice"),FVt.forEach(t),bIr=r(RVe," (ELECTRA model)"),RVe.forEach(t),vIr=i(Te),_3=n(Te,"LI",{});var PVe=s(_3);_3e=n(PVe,"STRONG",{});var TVt=s(_3e);FIr=r(TVt,"flaubert"),TVt.forEach(t),TIr=r(PVe," \u2014 "),eee=n(PVe,"A",{href:!0});var MVt=s(eee);MIr=r(MVt,"TFFlaubertForMultipleChoice"),MVt.forEach(t),EIr=r(PVe," (FlauBERT model)"),PVe.forEach(t),CIr=i(Te),u3=n(Te,"LI",{});var BVe=s(u3);u3e=n(BVe,"STRONG",{});var EVt=s(u3e);wIr=r(EVt,"funnel"),EVt.forEach(t),AIr=r(BVe," \u2014 "),oee=n(BVe,"A",{href:!0});var CVt=s(oee);LIr=r(CVt,"TFFunnelForMultipleChoice"),CVt.forEach(t),yIr=r(BVe," (Funnel Transformer model)"),BVe.forEach(t),xIr=i(Te),b3=n(Te,"LI",{});var IVe=s(b3);b3e=n(IVe,"STRONG",{});var wVt=s(b3e);$Ir=r(wVt,"longformer"),wVt.forEach(t),kIr=r(IVe," \u2014 "),ree=n(IVe,"A",{href:!0});var AVt=s(ree);SIr=r(AVt,"TFLongformerForMultipleChoice"),AVt.forEach(t),RIr=r(IVe," (Longformer model)"),IVe.forEach(t),PIr=i(Te),v3=n(Te,"LI",{});var NVe=s(v3);v3e=n(NVe,"STRONG",{});var LVt=s(v3e);BIr=r(LVt,"mobilebert"),LVt.forEach(t),IIr=r(NVe," \u2014 "),tee=n(NVe,"A",{href:!0});var yVt=s(tee);NIr=r(yVt,"TFMobileBertForMultipleChoice"),yVt.forEach(t),qIr=r(NVe," (MobileBERT model)"),NVe.forEach(t),jIr=i(Te),F3=n(Te,"LI",{});var qVe=s(F3);F3e=n(qVe,"STRONG",{});var xVt=s(F3e);DIr=r(xVt,"mpnet"),xVt.forEach(t),GIr=r(qVe," \u2014 "),aee=n(qVe,"A",{href:!0});var $Vt=s(aee);OIr=r($Vt,"TFMPNetForMultipleChoice"),$Vt.forEach(t),VIr=r(qVe," (MPNet model)"),qVe.forEach(t),XIr=i(Te),T3=n(Te,"LI",{});var jVe=s(T3);T3e=n(jVe,"STRONG",{});var kVt=s(T3e);zIr=r(kVt,"rembert"),kVt.forEach(t),WIr=r(jVe," \u2014 "),nee=n(jVe,"A",{href:!0});var SVt=s(nee);QIr=r(SVt,"TFRemBertForMultipleChoice"),SVt.forEach(t),HIr=r(jVe," (RemBERT model)"),jVe.forEach(t),UIr=i(Te),M3=n(Te,"LI",{});var DVe=s(M3);M3e=n(DVe,"STRONG",{});var RVt=s(M3e);JIr=r(RVt,"roberta"),RVt.forEach(t),YIr=r(DVe," \u2014 "),see=n(DVe,"A",{href:!0});var PVt=s(see);KIr=r(PVt,"TFRobertaForMultipleChoice"),PVt.forEach(t),ZIr=r(DVe," (RoBERTa model)"),DVe.forEach(t),eNr=i(Te),E3=n(Te,"LI",{});var GVe=s(E3);E3e=n(GVe,"STRONG",{});var BVt=s(E3e);oNr=r(BVt,"roformer"),BVt.forEach(t),rNr=r(GVe," \u2014 "),lee=n(GVe,"A",{href:!0});var IVt=s(lee);tNr=r(IVt,"TFRoFormerForMultipleChoice"),IVt.forEach(t),aNr=r(GVe," (RoFormer model)"),GVe.forEach(t),nNr=i(Te),C3=n(Te,"LI",{});var OVe=s(C3);C3e=n(OVe,"STRONG",{});var NVt=s(C3e);sNr=r(NVt,"xlm"),NVt.forEach(t),lNr=r(OVe," \u2014 "),iee=n(OVe,"A",{href:!0});var qVt=s(iee);iNr=r(qVt,"TFXLMForMultipleChoice"),qVt.forEach(t),dNr=r(OVe," (XLM model)"),OVe.forEach(t),cNr=i(Te),w3=n(Te,"LI",{});var VVe=s(w3);w3e=n(VVe,"STRONG",{});var jVt=s(w3e);fNr=r(jVt,"xlm-roberta"),jVt.forEach(t),mNr=r(VVe," \u2014 "),dee=n(VVe,"A",{href:!0});var DVt=s(dee);gNr=r(DVt,"TFXLMRobertaForMultipleChoice"),DVt.forEach(t),hNr=r(VVe," (XLM-RoBERTa model)"),VVe.forEach(t),pNr=i(Te),A3=n(Te,"LI",{});var XVe=s(A3);A3e=n(XVe,"STRONG",{});var GVt=s(A3e);_Nr=r(GVt,"xlnet"),GVt.forEach(t),uNr=r(XVe," \u2014 "),cee=n(XVe,"A",{href:!0});var OVt=s(cee);bNr=r(OVt,"TFXLNetForMultipleChoice"),OVt.forEach(t),vNr=r(XVe," (XLNet model)"),XVe.forEach(t),Te.forEach(t),FNr=i(Zl),T(L3.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),cHe=i(f),Gc=n(f,"H2",{class:!0});var FJe=s(Gc);y3=n(FJe,"A",{id:!0,class:!0,href:!0});var VVt=s(y3);L3e=n(VVt,"SPAN",{});var XVt=s(L3e);T(C$.$$.fragment,XVt),XVt.forEach(t),VVt.forEach(t),TNr=i(FJe),y3e=n(FJe,"SPAN",{});var zVt=s(y3e);MNr=r(zVt,"TFAutoModelForNextSentencePrediction"),zVt.forEach(t),FJe.forEach(t),fHe=i(f),mr=n(f,"DIV",{class:!0});var ei=s(mr);T(w$.$$.fragment,ei),ENr=i(ei),Oc=n(ei,"P",{});var bne=s(Oc);CNr=r(bne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),fee=n(bne,"A",{href:!0});var WVt=s(fee);wNr=r(WVt,"from_pretrained()"),WVt.forEach(t),ANr=r(bne," class method or the "),mee=n(bne,"A",{href:!0});var QVt=s(mee);LNr=r(QVt,"from_config()"),QVt.forEach(t),yNr=r(bne,` class
method.`),bne.forEach(t),xNr=i(ei),A$=n(ei,"P",{});var TJe=s(A$);$Nr=r(TJe,"This class cannot be instantiated directly using "),x3e=n(TJe,"CODE",{});var HVt=s(x3e);kNr=r(HVt,"__init__()"),HVt.forEach(t),SNr=r(TJe," (throws an error)."),TJe.forEach(t),RNr=i(ei),Xt=n(ei,"DIV",{class:!0});var lL=s(Xt);T(L$.$$.fragment,lL),PNr=i(lL),$3e=n(lL,"P",{});var UVt=s($3e);BNr=r(UVt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),UVt.forEach(t),INr=i(lL),Vc=n(lL,"P",{});var vne=s(Vc);NNr=r(vne,`Note:
Loading a model from its configuration file does `),k3e=n(vne,"STRONG",{});var JVt=s(k3e);qNr=r(JVt,"not"),JVt.forEach(t),jNr=r(vne,` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=n(vne,"A",{href:!0});var YVt=s(gee);DNr=r(YVt,"from_pretrained()"),YVt.forEach(t),GNr=r(vne," to load the model weights."),vne.forEach(t),ONr=i(lL),T(x3.$$.fragment,lL),lL.forEach(t),VNr=i(ei),Dr=n(ei,"DIV",{class:!0});var oi=s(Dr);T(y$.$$.fragment,oi),XNr=i(oi),S3e=n(oi,"P",{});var KVt=s(S3e);zNr=r(KVt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),KVt.forEach(t),WNr=i(oi),Tn=n(oi,"P",{});var iL=s(Tn);QNr=r(iL,"The model class to instantiate is selected based on the "),R3e=n(iL,"CODE",{});var ZVt=s(R3e);HNr=r(ZVt,"model_type"),ZVt.forEach(t),UNr=r(iL,` property of the config object (either
passed as an argument or loaded from `),P3e=n(iL,"CODE",{});var eXt=s(P3e);JNr=r(eXt,"pretrained_model_name_or_path"),eXt.forEach(t),YNr=r(iL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B3e=n(iL,"CODE",{});var oXt=s(B3e);KNr=r(oXt,"pretrained_model_name_or_path"),oXt.forEach(t),ZNr=r(iL,":"),iL.forEach(t),eqr=i(oi),x$=n(oi,"UL",{});var MJe=s(x$);$3=n(MJe,"LI",{});var zVe=s($3);I3e=n(zVe,"STRONG",{});var rXt=s(I3e);oqr=r(rXt,"bert"),rXt.forEach(t),rqr=r(zVe," \u2014 "),hee=n(zVe,"A",{href:!0});var tXt=s(hee);tqr=r(tXt,"TFBertForNextSentencePrediction"),tXt.forEach(t),aqr=r(zVe," (BERT model)"),zVe.forEach(t),nqr=i(MJe),k3=n(MJe,"LI",{});var WVe=s(k3);N3e=n(WVe,"STRONG",{});var aXt=s(N3e);sqr=r(aXt,"mobilebert"),aXt.forEach(t),lqr=r(WVe," \u2014 "),pee=n(WVe,"A",{href:!0});var nXt=s(pee);iqr=r(nXt,"TFMobileBertForNextSentencePrediction"),nXt.forEach(t),dqr=r(WVe," (MobileBERT model)"),WVe.forEach(t),MJe.forEach(t),cqr=i(oi),T(S3.$$.fragment,oi),oi.forEach(t),ei.forEach(t),mHe=i(f),Xc=n(f,"H2",{class:!0});var EJe=s(Xc);R3=n(EJe,"A",{id:!0,class:!0,href:!0});var sXt=s(R3);q3e=n(sXt,"SPAN",{});var lXt=s(q3e);T($$.$$.fragment,lXt),lXt.forEach(t),sXt.forEach(t),fqr=i(EJe),j3e=n(EJe,"SPAN",{});var iXt=s(j3e);mqr=r(iXt,"TFAutoModelForTableQuestionAnswering"),iXt.forEach(t),EJe.forEach(t),gHe=i(f),gr=n(f,"DIV",{class:!0});var ri=s(gr);T(k$.$$.fragment,ri),gqr=i(ri),zc=n(ri,"P",{});var Fne=s(zc);hqr=r(Fne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),_ee=n(Fne,"A",{href:!0});var dXt=s(_ee);pqr=r(dXt,"from_pretrained()"),dXt.forEach(t),_qr=r(Fne," class method or the "),uee=n(Fne,"A",{href:!0});var cXt=s(uee);uqr=r(cXt,"from_config()"),cXt.forEach(t),bqr=r(Fne,` class
method.`),Fne.forEach(t),vqr=i(ri),S$=n(ri,"P",{});var CJe=s(S$);Fqr=r(CJe,"This class cannot be instantiated directly using "),D3e=n(CJe,"CODE",{});var fXt=s(D3e);Tqr=r(fXt,"__init__()"),fXt.forEach(t),Mqr=r(CJe," (throws an error)."),CJe.forEach(t),Eqr=i(ri),zt=n(ri,"DIV",{class:!0});var dL=s(zt);T(R$.$$.fragment,dL),Cqr=i(dL),G3e=n(dL,"P",{});var mXt=s(G3e);wqr=r(mXt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),mXt.forEach(t),Aqr=i(dL),Wc=n(dL,"P",{});var Tne=s(Wc);Lqr=r(Tne,`Note:
Loading a model from its configuration file does `),O3e=n(Tne,"STRONG",{});var gXt=s(O3e);yqr=r(gXt,"not"),gXt.forEach(t),xqr=r(Tne,` load the model weights. It only affects the
model\u2019s configuration. Use `),bee=n(Tne,"A",{href:!0});var hXt=s(bee);$qr=r(hXt,"from_pretrained()"),hXt.forEach(t),kqr=r(Tne," to load the model weights."),Tne.forEach(t),Sqr=i(dL),T(P3.$$.fragment,dL),dL.forEach(t),Rqr=i(ri),Gr=n(ri,"DIV",{class:!0});var ti=s(Gr);T(P$.$$.fragment,ti),Pqr=i(ti),V3e=n(ti,"P",{});var pXt=s(V3e);Bqr=r(pXt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),pXt.forEach(t),Iqr=i(ti),Mn=n(ti,"P",{});var cL=s(Mn);Nqr=r(cL,"The model class to instantiate is selected based on the "),X3e=n(cL,"CODE",{});var _Xt=s(X3e);qqr=r(_Xt,"model_type"),_Xt.forEach(t),jqr=r(cL,` property of the config object (either
passed as an argument or loaded from `),z3e=n(cL,"CODE",{});var uXt=s(z3e);Dqr=r(uXt,"pretrained_model_name_or_path"),uXt.forEach(t),Gqr=r(cL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W3e=n(cL,"CODE",{});var bXt=s(W3e);Oqr=r(bXt,"pretrained_model_name_or_path"),bXt.forEach(t),Vqr=r(cL,":"),cL.forEach(t),Xqr=i(ti),Q3e=n(ti,"UL",{});var vXt=s(Q3e);B3=n(vXt,"LI",{});var QVe=s(B3);H3e=n(QVe,"STRONG",{});var FXt=s(H3e);zqr=r(FXt,"tapas"),FXt.forEach(t),Wqr=r(QVe," \u2014 "),vee=n(QVe,"A",{href:!0});var TXt=s(vee);Qqr=r(TXt,"TFTapasForQuestionAnswering"),TXt.forEach(t),Hqr=r(QVe," (TAPAS model)"),QVe.forEach(t),vXt.forEach(t),Uqr=i(ti),T(I3.$$.fragment,ti),ti.forEach(t),ri.forEach(t),hHe=i(f),Qc=n(f,"H2",{class:!0});var wJe=s(Qc);N3=n(wJe,"A",{id:!0,class:!0,href:!0});var MXt=s(N3);U3e=n(MXt,"SPAN",{});var EXt=s(U3e);T(B$.$$.fragment,EXt),EXt.forEach(t),MXt.forEach(t),Jqr=i(wJe),J3e=n(wJe,"SPAN",{});var CXt=s(J3e);Yqr=r(CXt,"TFAutoModelForTokenClassification"),CXt.forEach(t),wJe.forEach(t),pHe=i(f),hr=n(f,"DIV",{class:!0});var ai=s(hr);T(I$.$$.fragment,ai),Kqr=i(ai),Hc=n(ai,"P",{});var Mne=s(Hc);Zqr=r(Mne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Fee=n(Mne,"A",{href:!0});var wXt=s(Fee);ejr=r(wXt,"from_pretrained()"),wXt.forEach(t),ojr=r(Mne," class method or the "),Tee=n(Mne,"A",{href:!0});var AXt=s(Tee);rjr=r(AXt,"from_config()"),AXt.forEach(t),tjr=r(Mne,` class
method.`),Mne.forEach(t),ajr=i(ai),N$=n(ai,"P",{});var AJe=s(N$);njr=r(AJe,"This class cannot be instantiated directly using "),Y3e=n(AJe,"CODE",{});var LXt=s(Y3e);sjr=r(LXt,"__init__()"),LXt.forEach(t),ljr=r(AJe," (throws an error)."),AJe.forEach(t),ijr=i(ai),Wt=n(ai,"DIV",{class:!0});var fL=s(Wt);T(q$.$$.fragment,fL),djr=i(fL),K3e=n(fL,"P",{});var yXt=s(K3e);cjr=r(yXt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),yXt.forEach(t),fjr=i(fL),Uc=n(fL,"P",{});var Ene=s(Uc);mjr=r(Ene,`Note:
Loading a model from its configuration file does `),Z3e=n(Ene,"STRONG",{});var xXt=s(Z3e);gjr=r(xXt,"not"),xXt.forEach(t),hjr=r(Ene,` load the model weights. It only affects the
model\u2019s configuration. Use `),Mee=n(Ene,"A",{href:!0});var $Xt=s(Mee);pjr=r($Xt,"from_pretrained()"),$Xt.forEach(t),_jr=r(Ene," to load the model weights."),Ene.forEach(t),ujr=i(fL),T(q3.$$.fragment,fL),fL.forEach(t),bjr=i(ai),Or=n(ai,"DIV",{class:!0});var ni=s(Or);T(j$.$$.fragment,ni),vjr=i(ni),e5e=n(ni,"P",{});var kXt=s(e5e);Fjr=r(kXt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),kXt.forEach(t),Tjr=i(ni),En=n(ni,"P",{});var mL=s(En);Mjr=r(mL,"The model class to instantiate is selected based on the "),o5e=n(mL,"CODE",{});var SXt=s(o5e);Ejr=r(SXt,"model_type"),SXt.forEach(t),Cjr=r(mL,` property of the config object (either
passed as an argument or loaded from `),r5e=n(mL,"CODE",{});var RXt=s(r5e);wjr=r(RXt,"pretrained_model_name_or_path"),RXt.forEach(t),Ajr=r(mL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t5e=n(mL,"CODE",{});var PXt=s(t5e);Ljr=r(PXt,"pretrained_model_name_or_path"),PXt.forEach(t),yjr=r(mL,":"),mL.forEach(t),xjr=i(ni),de=n(ni,"UL",{});var he=s(de);j3=n(he,"LI",{});var HVe=s(j3);a5e=n(HVe,"STRONG",{});var BXt=s(a5e);$jr=r(BXt,"albert"),BXt.forEach(t),kjr=r(HVe," \u2014 "),Eee=n(HVe,"A",{href:!0});var IXt=s(Eee);Sjr=r(IXt,"TFAlbertForTokenClassification"),IXt.forEach(t),Rjr=r(HVe," (ALBERT model)"),HVe.forEach(t),Pjr=i(he),D3=n(he,"LI",{});var UVe=s(D3);n5e=n(UVe,"STRONG",{});var NXt=s(n5e);Bjr=r(NXt,"bert"),NXt.forEach(t),Ijr=r(UVe," \u2014 "),Cee=n(UVe,"A",{href:!0});var qXt=s(Cee);Njr=r(qXt,"TFBertForTokenClassification"),qXt.forEach(t),qjr=r(UVe," (BERT model)"),UVe.forEach(t),jjr=i(he),G3=n(he,"LI",{});var JVe=s(G3);s5e=n(JVe,"STRONG",{});var jXt=s(s5e);Djr=r(jXt,"camembert"),jXt.forEach(t),Gjr=r(JVe," \u2014 "),wee=n(JVe,"A",{href:!0});var DXt=s(wee);Ojr=r(DXt,"TFCamembertForTokenClassification"),DXt.forEach(t),Vjr=r(JVe," (CamemBERT model)"),JVe.forEach(t),Xjr=i(he),O3=n(he,"LI",{});var YVe=s(O3);l5e=n(YVe,"STRONG",{});var GXt=s(l5e);zjr=r(GXt,"convbert"),GXt.forEach(t),Wjr=r(YVe," \u2014 "),Aee=n(YVe,"A",{href:!0});var OXt=s(Aee);Qjr=r(OXt,"TFConvBertForTokenClassification"),OXt.forEach(t),Hjr=r(YVe," (ConvBERT model)"),YVe.forEach(t),Ujr=i(he),V3=n(he,"LI",{});var KVe=s(V3);i5e=n(KVe,"STRONG",{});var VXt=s(i5e);Jjr=r(VXt,"deberta"),VXt.forEach(t),Yjr=r(KVe," \u2014 "),Lee=n(KVe,"A",{href:!0});var XXt=s(Lee);Kjr=r(XXt,"TFDebertaForTokenClassification"),XXt.forEach(t),Zjr=r(KVe," (DeBERTa model)"),KVe.forEach(t),eDr=i(he),X3=n(he,"LI",{});var ZVe=s(X3);d5e=n(ZVe,"STRONG",{});var zXt=s(d5e);oDr=r(zXt,"deberta-v2"),zXt.forEach(t),rDr=r(ZVe," \u2014 "),yee=n(ZVe,"A",{href:!0});var WXt=s(yee);tDr=r(WXt,"TFDebertaV2ForTokenClassification"),WXt.forEach(t),aDr=r(ZVe," (DeBERTa-v2 model)"),ZVe.forEach(t),nDr=i(he),z3=n(he,"LI",{});var eXe=s(z3);c5e=n(eXe,"STRONG",{});var QXt=s(c5e);sDr=r(QXt,"distilbert"),QXt.forEach(t),lDr=r(eXe," \u2014 "),xee=n(eXe,"A",{href:!0});var HXt=s(xee);iDr=r(HXt,"TFDistilBertForTokenClassification"),HXt.forEach(t),dDr=r(eXe," (DistilBERT model)"),eXe.forEach(t),cDr=i(he),W3=n(he,"LI",{});var oXe=s(W3);f5e=n(oXe,"STRONG",{});var UXt=s(f5e);fDr=r(UXt,"electra"),UXt.forEach(t),mDr=r(oXe," \u2014 "),$ee=n(oXe,"A",{href:!0});var JXt=s($ee);gDr=r(JXt,"TFElectraForTokenClassification"),JXt.forEach(t),hDr=r(oXe," (ELECTRA model)"),oXe.forEach(t),pDr=i(he),Q3=n(he,"LI",{});var rXe=s(Q3);m5e=n(rXe,"STRONG",{});var YXt=s(m5e);_Dr=r(YXt,"flaubert"),YXt.forEach(t),uDr=r(rXe," \u2014 "),kee=n(rXe,"A",{href:!0});var KXt=s(kee);bDr=r(KXt,"TFFlaubertForTokenClassification"),KXt.forEach(t),vDr=r(rXe," (FlauBERT model)"),rXe.forEach(t),FDr=i(he),H3=n(he,"LI",{});var tXe=s(H3);g5e=n(tXe,"STRONG",{});var ZXt=s(g5e);TDr=r(ZXt,"funnel"),ZXt.forEach(t),MDr=r(tXe," \u2014 "),See=n(tXe,"A",{href:!0});var ezt=s(See);EDr=r(ezt,"TFFunnelForTokenClassification"),ezt.forEach(t),CDr=r(tXe," (Funnel Transformer model)"),tXe.forEach(t),wDr=i(he),U3=n(he,"LI",{});var aXe=s(U3);h5e=n(aXe,"STRONG",{});var ozt=s(h5e);ADr=r(ozt,"layoutlm"),ozt.forEach(t),LDr=r(aXe," \u2014 "),Ree=n(aXe,"A",{href:!0});var rzt=s(Ree);yDr=r(rzt,"TFLayoutLMForTokenClassification"),rzt.forEach(t),xDr=r(aXe," (LayoutLM model)"),aXe.forEach(t),$Dr=i(he),J3=n(he,"LI",{});var nXe=s(J3);p5e=n(nXe,"STRONG",{});var tzt=s(p5e);kDr=r(tzt,"longformer"),tzt.forEach(t),SDr=r(nXe," \u2014 "),Pee=n(nXe,"A",{href:!0});var azt=s(Pee);RDr=r(azt,"TFLongformerForTokenClassification"),azt.forEach(t),PDr=r(nXe," (Longformer model)"),nXe.forEach(t),BDr=i(he),Y3=n(he,"LI",{});var sXe=s(Y3);_5e=n(sXe,"STRONG",{});var nzt=s(_5e);IDr=r(nzt,"mobilebert"),nzt.forEach(t),NDr=r(sXe," \u2014 "),Bee=n(sXe,"A",{href:!0});var szt=s(Bee);qDr=r(szt,"TFMobileBertForTokenClassification"),szt.forEach(t),jDr=r(sXe," (MobileBERT model)"),sXe.forEach(t),DDr=i(he),K3=n(he,"LI",{});var lXe=s(K3);u5e=n(lXe,"STRONG",{});var lzt=s(u5e);GDr=r(lzt,"mpnet"),lzt.forEach(t),ODr=r(lXe," \u2014 "),Iee=n(lXe,"A",{href:!0});var izt=s(Iee);VDr=r(izt,"TFMPNetForTokenClassification"),izt.forEach(t),XDr=r(lXe," (MPNet model)"),lXe.forEach(t),zDr=i(he),Z3=n(he,"LI",{});var iXe=s(Z3);b5e=n(iXe,"STRONG",{});var dzt=s(b5e);WDr=r(dzt,"rembert"),dzt.forEach(t),QDr=r(iXe," \u2014 "),Nee=n(iXe,"A",{href:!0});var czt=s(Nee);HDr=r(czt,"TFRemBertForTokenClassification"),czt.forEach(t),UDr=r(iXe," (RemBERT model)"),iXe.forEach(t),JDr=i(he),e5=n(he,"LI",{});var dXe=s(e5);v5e=n(dXe,"STRONG",{});var fzt=s(v5e);YDr=r(fzt,"roberta"),fzt.forEach(t),KDr=r(dXe," \u2014 "),qee=n(dXe,"A",{href:!0});var mzt=s(qee);ZDr=r(mzt,"TFRobertaForTokenClassification"),mzt.forEach(t),eGr=r(dXe," (RoBERTa model)"),dXe.forEach(t),oGr=i(he),o5=n(he,"LI",{});var cXe=s(o5);F5e=n(cXe,"STRONG",{});var gzt=s(F5e);rGr=r(gzt,"roformer"),gzt.forEach(t),tGr=r(cXe," \u2014 "),jee=n(cXe,"A",{href:!0});var hzt=s(jee);aGr=r(hzt,"TFRoFormerForTokenClassification"),hzt.forEach(t),nGr=r(cXe," (RoFormer model)"),cXe.forEach(t),sGr=i(he),r5=n(he,"LI",{});var fXe=s(r5);T5e=n(fXe,"STRONG",{});var pzt=s(T5e);lGr=r(pzt,"xlm"),pzt.forEach(t),iGr=r(fXe," \u2014 "),Dee=n(fXe,"A",{href:!0});var _zt=s(Dee);dGr=r(_zt,"TFXLMForTokenClassification"),_zt.forEach(t),cGr=r(fXe," (XLM model)"),fXe.forEach(t),fGr=i(he),t5=n(he,"LI",{});var mXe=s(t5);M5e=n(mXe,"STRONG",{});var uzt=s(M5e);mGr=r(uzt,"xlm-roberta"),uzt.forEach(t),gGr=r(mXe," \u2014 "),Gee=n(mXe,"A",{href:!0});var bzt=s(Gee);hGr=r(bzt,"TFXLMRobertaForTokenClassification"),bzt.forEach(t),pGr=r(mXe," (XLM-RoBERTa model)"),mXe.forEach(t),_Gr=i(he),a5=n(he,"LI",{});var gXe=s(a5);E5e=n(gXe,"STRONG",{});var vzt=s(E5e);uGr=r(vzt,"xlnet"),vzt.forEach(t),bGr=r(gXe," \u2014 "),Oee=n(gXe,"A",{href:!0});var Fzt=s(Oee);vGr=r(Fzt,"TFXLNetForTokenClassification"),Fzt.forEach(t),FGr=r(gXe," (XLNet model)"),gXe.forEach(t),he.forEach(t),TGr=i(ni),T(n5.$$.fragment,ni),ni.forEach(t),ai.forEach(t),_He=i(f),Jc=n(f,"H2",{class:!0});var LJe=s(Jc);s5=n(LJe,"A",{id:!0,class:!0,href:!0});var Tzt=s(s5);C5e=n(Tzt,"SPAN",{});var Mzt=s(C5e);T(D$.$$.fragment,Mzt),Mzt.forEach(t),Tzt.forEach(t),MGr=i(LJe),w5e=n(LJe,"SPAN",{});var Ezt=s(w5e);EGr=r(Ezt,"TFAutoModelForQuestionAnswering"),Ezt.forEach(t),LJe.forEach(t),uHe=i(f),pr=n(f,"DIV",{class:!0});var si=s(pr);T(G$.$$.fragment,si),CGr=i(si),Yc=n(si,"P",{});var Cne=s(Yc);wGr=r(Cne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Vee=n(Cne,"A",{href:!0});var Czt=s(Vee);AGr=r(Czt,"from_pretrained()"),Czt.forEach(t),LGr=r(Cne," class method or the "),Xee=n(Cne,"A",{href:!0});var wzt=s(Xee);yGr=r(wzt,"from_config()"),wzt.forEach(t),xGr=r(Cne,` class
method.`),Cne.forEach(t),$Gr=i(si),O$=n(si,"P",{});var yJe=s(O$);kGr=r(yJe,"This class cannot be instantiated directly using "),A5e=n(yJe,"CODE",{});var Azt=s(A5e);SGr=r(Azt,"__init__()"),Azt.forEach(t),RGr=r(yJe," (throws an error)."),yJe.forEach(t),PGr=i(si),Qt=n(si,"DIV",{class:!0});var gL=s(Qt);T(V$.$$.fragment,gL),BGr=i(gL),L5e=n(gL,"P",{});var Lzt=s(L5e);IGr=r(Lzt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Lzt.forEach(t),NGr=i(gL),Kc=n(gL,"P",{});var wne=s(Kc);qGr=r(wne,`Note:
Loading a model from its configuration file does `),y5e=n(wne,"STRONG",{});var yzt=s(y5e);jGr=r(yzt,"not"),yzt.forEach(t),DGr=r(wne,` load the model weights. It only affects the
model\u2019s configuration. Use `),zee=n(wne,"A",{href:!0});var xzt=s(zee);GGr=r(xzt,"from_pretrained()"),xzt.forEach(t),OGr=r(wne," to load the model weights."),wne.forEach(t),VGr=i(gL),T(l5.$$.fragment,gL),gL.forEach(t),XGr=i(si),Vr=n(si,"DIV",{class:!0});var li=s(Vr);T(X$.$$.fragment,li),zGr=i(li),x5e=n(li,"P",{});var $zt=s(x5e);WGr=r($zt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$zt.forEach(t),QGr=i(li),Cn=n(li,"P",{});var hL=s(Cn);HGr=r(hL,"The model class to instantiate is selected based on the "),$5e=n(hL,"CODE",{});var kzt=s($5e);UGr=r(kzt,"model_type"),kzt.forEach(t),JGr=r(hL,` property of the config object (either
passed as an argument or loaded from `),k5e=n(hL,"CODE",{});var Szt=s(k5e);YGr=r(Szt,"pretrained_model_name_or_path"),Szt.forEach(t),KGr=r(hL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S5e=n(hL,"CODE",{});var Rzt=s(S5e);ZGr=r(Rzt,"pretrained_model_name_or_path"),Rzt.forEach(t),eOr=r(hL,":"),hL.forEach(t),oOr=i(li),ce=n(li,"UL",{});var pe=s(ce);i5=n(pe,"LI",{});var hXe=s(i5);R5e=n(hXe,"STRONG",{});var Pzt=s(R5e);rOr=r(Pzt,"albert"),Pzt.forEach(t),tOr=r(hXe," \u2014 "),Wee=n(hXe,"A",{href:!0});var Bzt=s(Wee);aOr=r(Bzt,"TFAlbertForQuestionAnswering"),Bzt.forEach(t),nOr=r(hXe," (ALBERT model)"),hXe.forEach(t),sOr=i(pe),d5=n(pe,"LI",{});var pXe=s(d5);P5e=n(pXe,"STRONG",{});var Izt=s(P5e);lOr=r(Izt,"bert"),Izt.forEach(t),iOr=r(pXe," \u2014 "),Qee=n(pXe,"A",{href:!0});var Nzt=s(Qee);dOr=r(Nzt,"TFBertForQuestionAnswering"),Nzt.forEach(t),cOr=r(pXe," (BERT model)"),pXe.forEach(t),fOr=i(pe),c5=n(pe,"LI",{});var _Xe=s(c5);B5e=n(_Xe,"STRONG",{});var qzt=s(B5e);mOr=r(qzt,"camembert"),qzt.forEach(t),gOr=r(_Xe," \u2014 "),Hee=n(_Xe,"A",{href:!0});var jzt=s(Hee);hOr=r(jzt,"TFCamembertForQuestionAnswering"),jzt.forEach(t),pOr=r(_Xe," (CamemBERT model)"),_Xe.forEach(t),_Or=i(pe),f5=n(pe,"LI",{});var uXe=s(f5);I5e=n(uXe,"STRONG",{});var Dzt=s(I5e);uOr=r(Dzt,"convbert"),Dzt.forEach(t),bOr=r(uXe," \u2014 "),Uee=n(uXe,"A",{href:!0});var Gzt=s(Uee);vOr=r(Gzt,"TFConvBertForQuestionAnswering"),Gzt.forEach(t),FOr=r(uXe," (ConvBERT model)"),uXe.forEach(t),TOr=i(pe),m5=n(pe,"LI",{});var bXe=s(m5);N5e=n(bXe,"STRONG",{});var Ozt=s(N5e);MOr=r(Ozt,"deberta"),Ozt.forEach(t),EOr=r(bXe," \u2014 "),Jee=n(bXe,"A",{href:!0});var Vzt=s(Jee);COr=r(Vzt,"TFDebertaForQuestionAnswering"),Vzt.forEach(t),wOr=r(bXe," (DeBERTa model)"),bXe.forEach(t),AOr=i(pe),g5=n(pe,"LI",{});var vXe=s(g5);q5e=n(vXe,"STRONG",{});var Xzt=s(q5e);LOr=r(Xzt,"deberta-v2"),Xzt.forEach(t),yOr=r(vXe," \u2014 "),Yee=n(vXe,"A",{href:!0});var zzt=s(Yee);xOr=r(zzt,"TFDebertaV2ForQuestionAnswering"),zzt.forEach(t),$Or=r(vXe," (DeBERTa-v2 model)"),vXe.forEach(t),kOr=i(pe),h5=n(pe,"LI",{});var FXe=s(h5);j5e=n(FXe,"STRONG",{});var Wzt=s(j5e);SOr=r(Wzt,"distilbert"),Wzt.forEach(t),ROr=r(FXe," \u2014 "),Kee=n(FXe,"A",{href:!0});var Qzt=s(Kee);POr=r(Qzt,"TFDistilBertForQuestionAnswering"),Qzt.forEach(t),BOr=r(FXe," (DistilBERT model)"),FXe.forEach(t),IOr=i(pe),p5=n(pe,"LI",{});var TXe=s(p5);D5e=n(TXe,"STRONG",{});var Hzt=s(D5e);NOr=r(Hzt,"electra"),Hzt.forEach(t),qOr=r(TXe," \u2014 "),Zee=n(TXe,"A",{href:!0});var Uzt=s(Zee);jOr=r(Uzt,"TFElectraForQuestionAnswering"),Uzt.forEach(t),DOr=r(TXe," (ELECTRA model)"),TXe.forEach(t),GOr=i(pe),_5=n(pe,"LI",{});var MXe=s(_5);G5e=n(MXe,"STRONG",{});var Jzt=s(G5e);OOr=r(Jzt,"flaubert"),Jzt.forEach(t),VOr=r(MXe," \u2014 "),eoe=n(MXe,"A",{href:!0});var Yzt=s(eoe);XOr=r(Yzt,"TFFlaubertForQuestionAnsweringSimple"),Yzt.forEach(t),zOr=r(MXe," (FlauBERT model)"),MXe.forEach(t),WOr=i(pe),u5=n(pe,"LI",{});var EXe=s(u5);O5e=n(EXe,"STRONG",{});var Kzt=s(O5e);QOr=r(Kzt,"funnel"),Kzt.forEach(t),HOr=r(EXe," \u2014 "),ooe=n(EXe,"A",{href:!0});var Zzt=s(ooe);UOr=r(Zzt,"TFFunnelForQuestionAnswering"),Zzt.forEach(t),JOr=r(EXe," (Funnel Transformer model)"),EXe.forEach(t),YOr=i(pe),b5=n(pe,"LI",{});var CXe=s(b5);V5e=n(CXe,"STRONG",{});var eWt=s(V5e);KOr=r(eWt,"gptj"),eWt.forEach(t),ZOr=r(CXe," \u2014 "),roe=n(CXe,"A",{href:!0});var oWt=s(roe);eVr=r(oWt,"TFGPTJForQuestionAnswering"),oWt.forEach(t),oVr=r(CXe," (GPT-J model)"),CXe.forEach(t),rVr=i(pe),v5=n(pe,"LI",{});var wXe=s(v5);X5e=n(wXe,"STRONG",{});var rWt=s(X5e);tVr=r(rWt,"longformer"),rWt.forEach(t),aVr=r(wXe," \u2014 "),toe=n(wXe,"A",{href:!0});var tWt=s(toe);nVr=r(tWt,"TFLongformerForQuestionAnswering"),tWt.forEach(t),sVr=r(wXe," (Longformer model)"),wXe.forEach(t),lVr=i(pe),F5=n(pe,"LI",{});var AXe=s(F5);z5e=n(AXe,"STRONG",{});var aWt=s(z5e);iVr=r(aWt,"mobilebert"),aWt.forEach(t),dVr=r(AXe," \u2014 "),aoe=n(AXe,"A",{href:!0});var nWt=s(aoe);cVr=r(nWt,"TFMobileBertForQuestionAnswering"),nWt.forEach(t),fVr=r(AXe," (MobileBERT model)"),AXe.forEach(t),mVr=i(pe),T5=n(pe,"LI",{});var LXe=s(T5);W5e=n(LXe,"STRONG",{});var sWt=s(W5e);gVr=r(sWt,"mpnet"),sWt.forEach(t),hVr=r(LXe," \u2014 "),noe=n(LXe,"A",{href:!0});var lWt=s(noe);pVr=r(lWt,"TFMPNetForQuestionAnswering"),lWt.forEach(t),_Vr=r(LXe," (MPNet model)"),LXe.forEach(t),uVr=i(pe),M5=n(pe,"LI",{});var yXe=s(M5);Q5e=n(yXe,"STRONG",{});var iWt=s(Q5e);bVr=r(iWt,"rembert"),iWt.forEach(t),vVr=r(yXe," \u2014 "),soe=n(yXe,"A",{href:!0});var dWt=s(soe);FVr=r(dWt,"TFRemBertForQuestionAnswering"),dWt.forEach(t),TVr=r(yXe," (RemBERT model)"),yXe.forEach(t),MVr=i(pe),E5=n(pe,"LI",{});var xXe=s(E5);H5e=n(xXe,"STRONG",{});var cWt=s(H5e);EVr=r(cWt,"roberta"),cWt.forEach(t),CVr=r(xXe," \u2014 "),loe=n(xXe,"A",{href:!0});var fWt=s(loe);wVr=r(fWt,"TFRobertaForQuestionAnswering"),fWt.forEach(t),AVr=r(xXe," (RoBERTa model)"),xXe.forEach(t),LVr=i(pe),C5=n(pe,"LI",{});var $Xe=s(C5);U5e=n($Xe,"STRONG",{});var mWt=s(U5e);yVr=r(mWt,"roformer"),mWt.forEach(t),xVr=r($Xe," \u2014 "),ioe=n($Xe,"A",{href:!0});var gWt=s(ioe);$Vr=r(gWt,"TFRoFormerForQuestionAnswering"),gWt.forEach(t),kVr=r($Xe," (RoFormer model)"),$Xe.forEach(t),SVr=i(pe),w5=n(pe,"LI",{});var kXe=s(w5);J5e=n(kXe,"STRONG",{});var hWt=s(J5e);RVr=r(hWt,"xlm"),hWt.forEach(t),PVr=r(kXe," \u2014 "),doe=n(kXe,"A",{href:!0});var pWt=s(doe);BVr=r(pWt,"TFXLMForQuestionAnsweringSimple"),pWt.forEach(t),IVr=r(kXe," (XLM model)"),kXe.forEach(t),NVr=i(pe),A5=n(pe,"LI",{});var SXe=s(A5);Y5e=n(SXe,"STRONG",{});var _Wt=s(Y5e);qVr=r(_Wt,"xlm-roberta"),_Wt.forEach(t),jVr=r(SXe," \u2014 "),coe=n(SXe,"A",{href:!0});var uWt=s(coe);DVr=r(uWt,"TFXLMRobertaForQuestionAnswering"),uWt.forEach(t),GVr=r(SXe," (XLM-RoBERTa model)"),SXe.forEach(t),OVr=i(pe),L5=n(pe,"LI",{});var RXe=s(L5);K5e=n(RXe,"STRONG",{});var bWt=s(K5e);VVr=r(bWt,"xlnet"),bWt.forEach(t),XVr=r(RXe," \u2014 "),foe=n(RXe,"A",{href:!0});var vWt=s(foe);zVr=r(vWt,"TFXLNetForQuestionAnsweringSimple"),vWt.forEach(t),WVr=r(RXe," (XLNet model)"),RXe.forEach(t),pe.forEach(t),QVr=i(li),T(y5.$$.fragment,li),li.forEach(t),si.forEach(t),bHe=i(f),Zc=n(f,"H2",{class:!0});var xJe=s(Zc);x5=n(xJe,"A",{id:!0,class:!0,href:!0});var FWt=s(x5);Z5e=n(FWt,"SPAN",{});var TWt=s(Z5e);T(z$.$$.fragment,TWt),TWt.forEach(t),FWt.forEach(t),HVr=i(xJe),e0e=n(xJe,"SPAN",{});var MWt=s(e0e);UVr=r(MWt,"TFAutoModelForVision2Seq"),MWt.forEach(t),xJe.forEach(t),vHe=i(f),_r=n(f,"DIV",{class:!0});var ii=s(_r);T(W$.$$.fragment,ii),JVr=i(ii),ef=n(ii,"P",{});var Ane=s(ef);YVr=r(Ane,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),moe=n(Ane,"A",{href:!0});var EWt=s(moe);KVr=r(EWt,"from_pretrained()"),EWt.forEach(t),ZVr=r(Ane," class method or the "),goe=n(Ane,"A",{href:!0});var CWt=s(goe);eXr=r(CWt,"from_config()"),CWt.forEach(t),oXr=r(Ane,` class
method.`),Ane.forEach(t),rXr=i(ii),Q$=n(ii,"P",{});var $Je=s(Q$);tXr=r($Je,"This class cannot be instantiated directly using "),o0e=n($Je,"CODE",{});var wWt=s(o0e);aXr=r(wWt,"__init__()"),wWt.forEach(t),nXr=r($Je," (throws an error)."),$Je.forEach(t),sXr=i(ii),Ht=n(ii,"DIV",{class:!0});var pL=s(Ht);T(H$.$$.fragment,pL),lXr=i(pL),r0e=n(pL,"P",{});var AWt=s(r0e);iXr=r(AWt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),AWt.forEach(t),dXr=i(pL),of=n(pL,"P",{});var Lne=s(of);cXr=r(Lne,`Note:
Loading a model from its configuration file does `),t0e=n(Lne,"STRONG",{});var LWt=s(t0e);fXr=r(LWt,"not"),LWt.forEach(t),mXr=r(Lne,` load the model weights. It only affects the
model\u2019s configuration. Use `),hoe=n(Lne,"A",{href:!0});var yWt=s(hoe);gXr=r(yWt,"from_pretrained()"),yWt.forEach(t),hXr=r(Lne," to load the model weights."),Lne.forEach(t),pXr=i(pL),T($5.$$.fragment,pL),pL.forEach(t),_Xr=i(ii),Xr=n(ii,"DIV",{class:!0});var di=s(Xr);T(U$.$$.fragment,di),uXr=i(di),a0e=n(di,"P",{});var xWt=s(a0e);bXr=r(xWt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),xWt.forEach(t),vXr=i(di),wn=n(di,"P",{});var _L=s(wn);FXr=r(_L,"The model class to instantiate is selected based on the "),n0e=n(_L,"CODE",{});var $Wt=s(n0e);TXr=r($Wt,"model_type"),$Wt.forEach(t),MXr=r(_L,` property of the config object (either
passed as an argument or loaded from `),s0e=n(_L,"CODE",{});var kWt=s(s0e);EXr=r(kWt,"pretrained_model_name_or_path"),kWt.forEach(t),CXr=r(_L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),l0e=n(_L,"CODE",{});var SWt=s(l0e);wXr=r(SWt,"pretrained_model_name_or_path"),SWt.forEach(t),AXr=r(_L,":"),_L.forEach(t),LXr=i(di),i0e=n(di,"UL",{});var RWt=s(i0e);k5=n(RWt,"LI",{});var PXe=s(k5);d0e=n(PXe,"STRONG",{});var PWt=s(d0e);yXr=r(PWt,"vision-encoder-decoder"),PWt.forEach(t),xXr=r(PXe," \u2014 "),poe=n(PXe,"A",{href:!0});var BWt=s(poe);$Xr=r(BWt,"TFVisionEncoderDecoderModel"),BWt.forEach(t),kXr=r(PXe," (Vision Encoder decoder model)"),PXe.forEach(t),RWt.forEach(t),SXr=i(di),T(S5.$$.fragment,di),di.forEach(t),ii.forEach(t),FHe=i(f),rf=n(f,"H2",{class:!0});var kJe=s(rf);R5=n(kJe,"A",{id:!0,class:!0,href:!0});var IWt=s(R5);c0e=n(IWt,"SPAN",{});var NWt=s(c0e);T(J$.$$.fragment,NWt),NWt.forEach(t),IWt.forEach(t),RXr=i(kJe),f0e=n(kJe,"SPAN",{});var qWt=s(f0e);PXr=r(qWt,"TFAutoModelForSpeechSeq2Seq"),qWt.forEach(t),kJe.forEach(t),THe=i(f),ur=n(f,"DIV",{class:!0});var ci=s(ur);T(Y$.$$.fragment,ci),BXr=i(ci),tf=n(ci,"P",{});var yne=s(tf);IXr=r(yne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),_oe=n(yne,"A",{href:!0});var jWt=s(_oe);NXr=r(jWt,"from_pretrained()"),jWt.forEach(t),qXr=r(yne," class method or the "),uoe=n(yne,"A",{href:!0});var DWt=s(uoe);jXr=r(DWt,"from_config()"),DWt.forEach(t),DXr=r(yne,` class
method.`),yne.forEach(t),GXr=i(ci),K$=n(ci,"P",{});var SJe=s(K$);OXr=r(SJe,"This class cannot be instantiated directly using "),m0e=n(SJe,"CODE",{});var GWt=s(m0e);VXr=r(GWt,"__init__()"),GWt.forEach(t),XXr=r(SJe," (throws an error)."),SJe.forEach(t),zXr=i(ci),Ut=n(ci,"DIV",{class:!0});var uL=s(Ut);T(Z$.$$.fragment,uL),WXr=i(uL),g0e=n(uL,"P",{});var OWt=s(g0e);QXr=r(OWt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),OWt.forEach(t),HXr=i(uL),af=n(uL,"P",{});var xne=s(af);UXr=r(xne,`Note:
Loading a model from its configuration file does `),h0e=n(xne,"STRONG",{});var VWt=s(h0e);JXr=r(VWt,"not"),VWt.forEach(t),YXr=r(xne,` load the model weights. It only affects the
model\u2019s configuration. Use `),boe=n(xne,"A",{href:!0});var XWt=s(boe);KXr=r(XWt,"from_pretrained()"),XWt.forEach(t),ZXr=r(xne," to load the model weights."),xne.forEach(t),ezr=i(uL),T(P5.$$.fragment,uL),uL.forEach(t),ozr=i(ci),zr=n(ci,"DIV",{class:!0});var fi=s(zr);T(ek.$$.fragment,fi),rzr=i(fi),p0e=n(fi,"P",{});var zWt=s(p0e);tzr=r(zWt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),zWt.forEach(t),azr=i(fi),An=n(fi,"P",{});var bL=s(An);nzr=r(bL,"The model class to instantiate is selected based on the "),_0e=n(bL,"CODE",{});var WWt=s(_0e);szr=r(WWt,"model_type"),WWt.forEach(t),lzr=r(bL,` property of the config object (either
passed as an argument or loaded from `),u0e=n(bL,"CODE",{});var QWt=s(u0e);izr=r(QWt,"pretrained_model_name_or_path"),QWt.forEach(t),dzr=r(bL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b0e=n(bL,"CODE",{});var HWt=s(b0e);czr=r(HWt,"pretrained_model_name_or_path"),HWt.forEach(t),fzr=r(bL,":"),bL.forEach(t),mzr=i(fi),v0e=n(fi,"UL",{});var UWt=s(v0e);B5=n(UWt,"LI",{});var BXe=s(B5);F0e=n(BXe,"STRONG",{});var JWt=s(F0e);gzr=r(JWt,"speech_to_text"),JWt.forEach(t),hzr=r(BXe," \u2014 "),voe=n(BXe,"A",{href:!0});var YWt=s(voe);pzr=r(YWt,"TFSpeech2TextForConditionalGeneration"),YWt.forEach(t),_zr=r(BXe," (Speech2Text model)"),BXe.forEach(t),UWt.forEach(t),uzr=i(fi),T(I5.$$.fragment,fi),fi.forEach(t),ci.forEach(t),MHe=i(f),nf=n(f,"H2",{class:!0});var RJe=s(nf);N5=n(RJe,"A",{id:!0,class:!0,href:!0});var KWt=s(N5);T0e=n(KWt,"SPAN",{});var ZWt=s(T0e);T(ok.$$.fragment,ZWt),ZWt.forEach(t),KWt.forEach(t),bzr=i(RJe),M0e=n(RJe,"SPAN",{});var eQt=s(M0e);vzr=r(eQt,"FlaxAutoModel"),eQt.forEach(t),RJe.forEach(t),EHe=i(f),br=n(f,"DIV",{class:!0});var mi=s(br);T(rk.$$.fragment,mi),Fzr=i(mi),sf=n(mi,"P",{});var $ne=s(sf);Tzr=r($ne,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Foe=n($ne,"A",{href:!0});var oQt=s(Foe);Mzr=r(oQt,"from_pretrained()"),oQt.forEach(t),Ezr=r($ne," class method or the "),Toe=n($ne,"A",{href:!0});var rQt=s(Toe);Czr=r(rQt,"from_config()"),rQt.forEach(t),wzr=r($ne,` class
method.`),$ne.forEach(t),Azr=i(mi),tk=n(mi,"P",{});var PJe=s(tk);Lzr=r(PJe,"This class cannot be instantiated directly using "),E0e=n(PJe,"CODE",{});var tQt=s(E0e);yzr=r(tQt,"__init__()"),tQt.forEach(t),xzr=r(PJe," (throws an error)."),PJe.forEach(t),$zr=i(mi),Jt=n(mi,"DIV",{class:!0});var vL=s(Jt);T(ak.$$.fragment,vL),kzr=i(vL),C0e=n(vL,"P",{});var aQt=s(C0e);Szr=r(aQt,"Instantiates one of the base model classes of the library from a configuration."),aQt.forEach(t),Rzr=i(vL),lf=n(vL,"P",{});var kne=s(lf);Pzr=r(kne,`Note:
Loading a model from its configuration file does `),w0e=n(kne,"STRONG",{});var nQt=s(w0e);Bzr=r(nQt,"not"),nQt.forEach(t),Izr=r(kne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Moe=n(kne,"A",{href:!0});var sQt=s(Moe);Nzr=r(sQt,"from_pretrained()"),sQt.forEach(t),qzr=r(kne," to load the model weights."),kne.forEach(t),jzr=i(vL),T(q5.$$.fragment,vL),vL.forEach(t),Dzr=i(mi),Wr=n(mi,"DIV",{class:!0});var gi=s(Wr);T(nk.$$.fragment,gi),Gzr=i(gi),A0e=n(gi,"P",{});var lQt=s(A0e);Ozr=r(lQt,"Instantiate one of the base model classes of the library from a pretrained model."),lQt.forEach(t),Vzr=i(gi),Ln=n(gi,"P",{});var FL=s(Ln);Xzr=r(FL,"The model class to instantiate is selected based on the "),L0e=n(FL,"CODE",{});var iQt=s(L0e);zzr=r(iQt,"model_type"),iQt.forEach(t),Wzr=r(FL,` property of the config object (either
passed as an argument or loaded from `),y0e=n(FL,"CODE",{});var dQt=s(y0e);Qzr=r(dQt,"pretrained_model_name_or_path"),dQt.forEach(t),Hzr=r(FL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x0e=n(FL,"CODE",{});var cQt=s(x0e);Uzr=r(cQt,"pretrained_model_name_or_path"),cQt.forEach(t),Jzr=r(FL,":"),FL.forEach(t),Yzr=i(gi),oe=n(gi,"UL",{});var te=s(oe);j5=n(te,"LI",{});var IXe=s(j5);$0e=n(IXe,"STRONG",{});var fQt=s($0e);Kzr=r(fQt,"albert"),fQt.forEach(t),Zzr=r(IXe," \u2014 "),Eoe=n(IXe,"A",{href:!0});var mQt=s(Eoe);eWr=r(mQt,"FlaxAlbertModel"),mQt.forEach(t),oWr=r(IXe," (ALBERT model)"),IXe.forEach(t),rWr=i(te),D5=n(te,"LI",{});var NXe=s(D5);k0e=n(NXe,"STRONG",{});var gQt=s(k0e);tWr=r(gQt,"bart"),gQt.forEach(t),aWr=r(NXe," \u2014 "),Coe=n(NXe,"A",{href:!0});var hQt=s(Coe);nWr=r(hQt,"FlaxBartModel"),hQt.forEach(t),sWr=r(NXe," (BART model)"),NXe.forEach(t),lWr=i(te),G5=n(te,"LI",{});var qXe=s(G5);S0e=n(qXe,"STRONG",{});var pQt=s(S0e);iWr=r(pQt,"beit"),pQt.forEach(t),dWr=r(qXe," \u2014 "),woe=n(qXe,"A",{href:!0});var _Qt=s(woe);cWr=r(_Qt,"FlaxBeitModel"),_Qt.forEach(t),fWr=r(qXe," (BEiT model)"),qXe.forEach(t),mWr=i(te),O5=n(te,"LI",{});var jXe=s(O5);R0e=n(jXe,"STRONG",{});var uQt=s(R0e);gWr=r(uQt,"bert"),uQt.forEach(t),hWr=r(jXe," \u2014 "),Aoe=n(jXe,"A",{href:!0});var bQt=s(Aoe);pWr=r(bQt,"FlaxBertModel"),bQt.forEach(t),_Wr=r(jXe," (BERT model)"),jXe.forEach(t),uWr=i(te),V5=n(te,"LI",{});var DXe=s(V5);P0e=n(DXe,"STRONG",{});var vQt=s(P0e);bWr=r(vQt,"big_bird"),vQt.forEach(t),vWr=r(DXe," \u2014 "),Loe=n(DXe,"A",{href:!0});var FQt=s(Loe);FWr=r(FQt,"FlaxBigBirdModel"),FQt.forEach(t),TWr=r(DXe," (BigBird model)"),DXe.forEach(t),MWr=i(te),X5=n(te,"LI",{});var GXe=s(X5);B0e=n(GXe,"STRONG",{});var TQt=s(B0e);EWr=r(TQt,"blenderbot"),TQt.forEach(t),CWr=r(GXe," \u2014 "),yoe=n(GXe,"A",{href:!0});var MQt=s(yoe);wWr=r(MQt,"FlaxBlenderbotModel"),MQt.forEach(t),AWr=r(GXe," (Blenderbot model)"),GXe.forEach(t),LWr=i(te),z5=n(te,"LI",{});var OXe=s(z5);I0e=n(OXe,"STRONG",{});var EQt=s(I0e);yWr=r(EQt,"blenderbot-small"),EQt.forEach(t),xWr=r(OXe," \u2014 "),xoe=n(OXe,"A",{href:!0});var CQt=s(xoe);$Wr=r(CQt,"FlaxBlenderbotSmallModel"),CQt.forEach(t),kWr=r(OXe," (BlenderbotSmall model)"),OXe.forEach(t),SWr=i(te),W5=n(te,"LI",{});var VXe=s(W5);N0e=n(VXe,"STRONG",{});var wQt=s(N0e);RWr=r(wQt,"clip"),wQt.forEach(t),PWr=r(VXe," \u2014 "),$oe=n(VXe,"A",{href:!0});var AQt=s($oe);BWr=r(AQt,"FlaxCLIPModel"),AQt.forEach(t),IWr=r(VXe," (CLIP model)"),VXe.forEach(t),NWr=i(te),Q5=n(te,"LI",{});var XXe=s(Q5);q0e=n(XXe,"STRONG",{});var LQt=s(q0e);qWr=r(LQt,"distilbert"),LQt.forEach(t),jWr=r(XXe," \u2014 "),koe=n(XXe,"A",{href:!0});var yQt=s(koe);DWr=r(yQt,"FlaxDistilBertModel"),yQt.forEach(t),GWr=r(XXe," (DistilBERT model)"),XXe.forEach(t),OWr=i(te),H5=n(te,"LI",{});var zXe=s(H5);j0e=n(zXe,"STRONG",{});var xQt=s(j0e);VWr=r(xQt,"dpt"),xQt.forEach(t),XWr=r(zXe," \u2014 "),Soe=n(zXe,"A",{href:!0});var $Qt=s(Soe);zWr=r($Qt,"FlaxDPTModel"),$Qt.forEach(t),WWr=r(zXe," (DPT model)"),zXe.forEach(t),QWr=i(te),U5=n(te,"LI",{});var WXe=s(U5);D0e=n(WXe,"STRONG",{});var kQt=s(D0e);HWr=r(kQt,"electra"),kQt.forEach(t),UWr=r(WXe," \u2014 "),Roe=n(WXe,"A",{href:!0});var SQt=s(Roe);JWr=r(SQt,"FlaxElectraModel"),SQt.forEach(t),YWr=r(WXe," (ELECTRA model)"),WXe.forEach(t),KWr=i(te),J5=n(te,"LI",{});var QXe=s(J5);G0e=n(QXe,"STRONG",{});var RQt=s(G0e);ZWr=r(RQt,"gpt2"),RQt.forEach(t),eQr=r(QXe," \u2014 "),Poe=n(QXe,"A",{href:!0});var PQt=s(Poe);oQr=r(PQt,"FlaxGPT2Model"),PQt.forEach(t),rQr=r(QXe," (OpenAI GPT-2 model)"),QXe.forEach(t),tQr=i(te),Y5=n(te,"LI",{});var HXe=s(Y5);O0e=n(HXe,"STRONG",{});var BQt=s(O0e);aQr=r(BQt,"gpt_neo"),BQt.forEach(t),nQr=r(HXe," \u2014 "),Boe=n(HXe,"A",{href:!0});var IQt=s(Boe);sQr=r(IQt,"FlaxGPTNeoModel"),IQt.forEach(t),lQr=r(HXe," (GPT Neo model)"),HXe.forEach(t),iQr=i(te),K5=n(te,"LI",{});var UXe=s(K5);V0e=n(UXe,"STRONG",{});var NQt=s(V0e);dQr=r(NQt,"gptj"),NQt.forEach(t),cQr=r(UXe," \u2014 "),Ioe=n(UXe,"A",{href:!0});var qQt=s(Ioe);fQr=r(qQt,"FlaxGPTJModel"),qQt.forEach(t),mQr=r(UXe," (GPT-J model)"),UXe.forEach(t),gQr=i(te),Z5=n(te,"LI",{});var JXe=s(Z5);X0e=n(JXe,"STRONG",{});var jQt=s(X0e);hQr=r(jQt,"longt5"),jQt.forEach(t),pQr=r(JXe," \u2014 "),Noe=n(JXe,"A",{href:!0});var DQt=s(Noe);_Qr=r(DQt,"FlaxLongT5Model"),DQt.forEach(t),uQr=r(JXe," (LongT5 model)"),JXe.forEach(t),bQr=i(te),e0=n(te,"LI",{});var YXe=s(e0);z0e=n(YXe,"STRONG",{});var GQt=s(z0e);vQr=r(GQt,"marian"),GQt.forEach(t),FQr=r(YXe," \u2014 "),qoe=n(YXe,"A",{href:!0});var OQt=s(qoe);TQr=r(OQt,"FlaxMarianModel"),OQt.forEach(t),MQr=r(YXe," (Marian model)"),YXe.forEach(t),EQr=i(te),o0=n(te,"LI",{});var KXe=s(o0);W0e=n(KXe,"STRONG",{});var VQt=s(W0e);CQr=r(VQt,"mbart"),VQt.forEach(t),wQr=r(KXe," \u2014 "),joe=n(KXe,"A",{href:!0});var XQt=s(joe);AQr=r(XQt,"FlaxMBartModel"),XQt.forEach(t),LQr=r(KXe," (mBART model)"),KXe.forEach(t),yQr=i(te),r0=n(te,"LI",{});var ZXe=s(r0);Q0e=n(ZXe,"STRONG",{});var zQt=s(Q0e);xQr=r(zQt,"mt5"),zQt.forEach(t),$Qr=r(ZXe," \u2014 "),Doe=n(ZXe,"A",{href:!0});var WQt=s(Doe);kQr=r(WQt,"FlaxMT5Model"),WQt.forEach(t),SQr=r(ZXe," (MT5 model)"),ZXe.forEach(t),RQr=i(te),t0=n(te,"LI",{});var eze=s(t0);H0e=n(eze,"STRONG",{});var QQt=s(H0e);PQr=r(QQt,"opt"),QQt.forEach(t),BQr=r(eze," \u2014 "),Goe=n(eze,"A",{href:!0});var HQt=s(Goe);IQr=r(HQt,"FlaxOPTModel"),HQt.forEach(t),NQr=r(eze," (OPT model)"),eze.forEach(t),qQr=i(te),a0=n(te,"LI",{});var oze=s(a0);U0e=n(oze,"STRONG",{});var UQt=s(U0e);jQr=r(UQt,"pegasus"),UQt.forEach(t),DQr=r(oze," \u2014 "),Ooe=n(oze,"A",{href:!0});var JQt=s(Ooe);GQr=r(JQt,"FlaxPegasusModel"),JQt.forEach(t),OQr=r(oze," (Pegasus model)"),oze.forEach(t),VQr=i(te),n0=n(te,"LI",{});var rze=s(n0);J0e=n(rze,"STRONG",{});var YQt=s(J0e);XQr=r(YQt,"roberta"),YQt.forEach(t),zQr=r(rze," \u2014 "),Voe=n(rze,"A",{href:!0});var KQt=s(Voe);WQr=r(KQt,"FlaxRobertaModel"),KQt.forEach(t),QQr=r(rze," (RoBERTa model)"),rze.forEach(t),HQr=i(te),s0=n(te,"LI",{});var tze=s(s0);Y0e=n(tze,"STRONG",{});var ZQt=s(Y0e);UQr=r(ZQt,"roformer"),ZQt.forEach(t),JQr=r(tze," \u2014 "),Xoe=n(tze,"A",{href:!0});var eHt=s(Xoe);YQr=r(eHt,"FlaxRoFormerModel"),eHt.forEach(t),KQr=r(tze," (RoFormer model)"),tze.forEach(t),ZQr=i(te),l0=n(te,"LI",{});var aze=s(l0);K0e=n(aze,"STRONG",{});var oHt=s(K0e);eHr=r(oHt,"t5"),oHt.forEach(t),oHr=r(aze," \u2014 "),zoe=n(aze,"A",{href:!0});var rHt=s(zoe);rHr=r(rHt,"FlaxT5Model"),rHt.forEach(t),tHr=r(aze," (T5 model)"),aze.forEach(t),aHr=i(te),i0=n(te,"LI",{});var nze=s(i0);Z0e=n(nze,"STRONG",{});var tHt=s(Z0e);nHr=r(tHt,"vision-text-dual-encoder"),tHt.forEach(t),sHr=r(nze," \u2014 "),Woe=n(nze,"A",{href:!0});var aHt=s(Woe);lHr=r(aHt,"FlaxVisionTextDualEncoderModel"),aHt.forEach(t),iHr=r(nze," (VisionTextDualEncoder model)"),nze.forEach(t),dHr=i(te),d0=n(te,"LI",{});var sze=s(d0);ewe=n(sze,"STRONG",{});var nHt=s(ewe);cHr=r(nHt,"vit"),nHt.forEach(t),fHr=r(sze," \u2014 "),Qoe=n(sze,"A",{href:!0});var sHt=s(Qoe);mHr=r(sHt,"FlaxViTModel"),sHt.forEach(t),gHr=r(sze," (ViT model)"),sze.forEach(t),hHr=i(te),c0=n(te,"LI",{});var lze=s(c0);owe=n(lze,"STRONG",{});var lHt=s(owe);pHr=r(lHt,"wav2vec2"),lHt.forEach(t),_Hr=r(lze," \u2014 "),Hoe=n(lze,"A",{href:!0});var iHt=s(Hoe);uHr=r(iHt,"FlaxWav2Vec2Model"),iHt.forEach(t),bHr=r(lze," (Wav2Vec2 model)"),lze.forEach(t),vHr=i(te),f0=n(te,"LI",{});var ize=s(f0);rwe=n(ize,"STRONG",{});var dHt=s(rwe);FHr=r(dHt,"xglm"),dHt.forEach(t),THr=r(ize," \u2014 "),Uoe=n(ize,"A",{href:!0});var cHt=s(Uoe);MHr=r(cHt,"FlaxXGLMModel"),cHt.forEach(t),EHr=r(ize," (XGLM model)"),ize.forEach(t),CHr=i(te),m0=n(te,"LI",{});var dze=s(m0);twe=n(dze,"STRONG",{});var fHt=s(twe);wHr=r(fHt,"xlm-roberta"),fHt.forEach(t),AHr=r(dze," \u2014 "),Joe=n(dze,"A",{href:!0});var mHt=s(Joe);LHr=r(mHt,"FlaxXLMRobertaModel"),mHt.forEach(t),yHr=r(dze," (XLM-RoBERTa model)"),dze.forEach(t),te.forEach(t),xHr=i(gi),T(g0.$$.fragment,gi),gi.forEach(t),mi.forEach(t),CHe=i(f),df=n(f,"H2",{class:!0});var BJe=s(df);h0=n(BJe,"A",{id:!0,class:!0,href:!0});var gHt=s(h0);awe=n(gHt,"SPAN",{});var hHt=s(awe);T(sk.$$.fragment,hHt),hHt.forEach(t),gHt.forEach(t),$Hr=i(BJe),nwe=n(BJe,"SPAN",{});var pHt=s(nwe);kHr=r(pHt,"FlaxAutoModelForCausalLM"),pHt.forEach(t),BJe.forEach(t),wHe=i(f),vr=n(f,"DIV",{class:!0});var hi=s(vr);T(lk.$$.fragment,hi),SHr=i(hi),cf=n(hi,"P",{});var Sne=s(cf);RHr=r(Sne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Yoe=n(Sne,"A",{href:!0});var _Ht=s(Yoe);PHr=r(_Ht,"from_pretrained()"),_Ht.forEach(t),BHr=r(Sne," class method or the "),Koe=n(Sne,"A",{href:!0});var uHt=s(Koe);IHr=r(uHt,"from_config()"),uHt.forEach(t),NHr=r(Sne,` class
method.`),Sne.forEach(t),qHr=i(hi),ik=n(hi,"P",{});var IJe=s(ik);jHr=r(IJe,"This class cannot be instantiated directly using "),swe=n(IJe,"CODE",{});var bHt=s(swe);DHr=r(bHt,"__init__()"),bHt.forEach(t),GHr=r(IJe," (throws an error)."),IJe.forEach(t),OHr=i(hi),Yt=n(hi,"DIV",{class:!0});var TL=s(Yt);T(dk.$$.fragment,TL),VHr=i(TL),lwe=n(TL,"P",{});var vHt=s(lwe);XHr=r(vHt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),vHt.forEach(t),zHr=i(TL),ff=n(TL,"P",{});var Rne=s(ff);WHr=r(Rne,`Note:
Loading a model from its configuration file does `),iwe=n(Rne,"STRONG",{});var FHt=s(iwe);QHr=r(FHt,"not"),FHt.forEach(t),HHr=r(Rne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Zoe=n(Rne,"A",{href:!0});var THt=s(Zoe);UHr=r(THt,"from_pretrained()"),THt.forEach(t),JHr=r(Rne," to load the model weights."),Rne.forEach(t),YHr=i(TL),T(p0.$$.fragment,TL),TL.forEach(t),KHr=i(hi),Qr=n(hi,"DIV",{class:!0});var pi=s(Qr);T(ck.$$.fragment,pi),ZHr=i(pi),dwe=n(pi,"P",{});var MHt=s(dwe);eUr=r(MHt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),MHt.forEach(t),oUr=i(pi),yn=n(pi,"P",{});var ML=s(yn);rUr=r(ML,"The model class to instantiate is selected based on the "),cwe=n(ML,"CODE",{});var EHt=s(cwe);tUr=r(EHt,"model_type"),EHt.forEach(t),aUr=r(ML,` property of the config object (either
passed as an argument or loaded from `),fwe=n(ML,"CODE",{});var CHt=s(fwe);nUr=r(CHt,"pretrained_model_name_or_path"),CHt.forEach(t),sUr=r(ML,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mwe=n(ML,"CODE",{});var wHt=s(mwe);lUr=r(wHt,"pretrained_model_name_or_path"),wHt.forEach(t),iUr=r(ML,":"),ML.forEach(t),dUr=i(pi),xe=n(pi,"UL",{});var Ne=s(xe);_0=n(Ne,"LI",{});var cze=s(_0);gwe=n(cze,"STRONG",{});var AHt=s(gwe);cUr=r(AHt,"bart"),AHt.forEach(t),fUr=r(cze," \u2014 "),ere=n(cze,"A",{href:!0});var LHt=s(ere);mUr=r(LHt,"FlaxBartForCausalLM"),LHt.forEach(t),gUr=r(cze," (BART model)"),cze.forEach(t),hUr=i(Ne),u0=n(Ne,"LI",{});var fze=s(u0);hwe=n(fze,"STRONG",{});var yHt=s(hwe);pUr=r(yHt,"bert"),yHt.forEach(t),_Ur=r(fze," \u2014 "),ore=n(fze,"A",{href:!0});var xHt=s(ore);uUr=r(xHt,"FlaxBertForCausalLM"),xHt.forEach(t),bUr=r(fze," (BERT model)"),fze.forEach(t),vUr=i(Ne),b0=n(Ne,"LI",{});var mze=s(b0);pwe=n(mze,"STRONG",{});var $Ht=s(pwe);FUr=r($Ht,"big_bird"),$Ht.forEach(t),TUr=r(mze," \u2014 "),rre=n(mze,"A",{href:!0});var kHt=s(rre);MUr=r(kHt,"FlaxBigBirdForCausalLM"),kHt.forEach(t),EUr=r(mze," (BigBird model)"),mze.forEach(t),CUr=i(Ne),v0=n(Ne,"LI",{});var gze=s(v0);_we=n(gze,"STRONG",{});var SHt=s(_we);wUr=r(SHt,"electra"),SHt.forEach(t),AUr=r(gze," \u2014 "),tre=n(gze,"A",{href:!0});var RHt=s(tre);LUr=r(RHt,"FlaxElectraForCausalLM"),RHt.forEach(t),yUr=r(gze," (ELECTRA model)"),gze.forEach(t),xUr=i(Ne),F0=n(Ne,"LI",{});var hze=s(F0);uwe=n(hze,"STRONG",{});var PHt=s(uwe);$Ur=r(PHt,"gpt2"),PHt.forEach(t),kUr=r(hze," \u2014 "),are=n(hze,"A",{href:!0});var BHt=s(are);SUr=r(BHt,"FlaxGPT2LMHeadModel"),BHt.forEach(t),RUr=r(hze," (OpenAI GPT-2 model)"),hze.forEach(t),PUr=i(Ne),T0=n(Ne,"LI",{});var pze=s(T0);bwe=n(pze,"STRONG",{});var IHt=s(bwe);BUr=r(IHt,"gpt_neo"),IHt.forEach(t),IUr=r(pze," \u2014 "),nre=n(pze,"A",{href:!0});var NHt=s(nre);NUr=r(NHt,"FlaxGPTNeoForCausalLM"),NHt.forEach(t),qUr=r(pze," (GPT Neo model)"),pze.forEach(t),jUr=i(Ne),M0=n(Ne,"LI",{});var _ze=s(M0);vwe=n(_ze,"STRONG",{});var qHt=s(vwe);DUr=r(qHt,"gptj"),qHt.forEach(t),GUr=r(_ze," \u2014 "),sre=n(_ze,"A",{href:!0});var jHt=s(sre);OUr=r(jHt,"FlaxGPTJForCausalLM"),jHt.forEach(t),VUr=r(_ze," (GPT-J model)"),_ze.forEach(t),XUr=i(Ne),E0=n(Ne,"LI",{});var uze=s(E0);Fwe=n(uze,"STRONG",{});var DHt=s(Fwe);zUr=r(DHt,"opt"),DHt.forEach(t),WUr=r(uze," \u2014 "),lre=n(uze,"A",{href:!0});var GHt=s(lre);QUr=r(GHt,"FlaxOPTForCausalLM"),GHt.forEach(t),HUr=r(uze," (OPT model)"),uze.forEach(t),UUr=i(Ne),C0=n(Ne,"LI",{});var bze=s(C0);Twe=n(bze,"STRONG",{});var OHt=s(Twe);JUr=r(OHt,"roberta"),OHt.forEach(t),YUr=r(bze," \u2014 "),ire=n(bze,"A",{href:!0});var VHt=s(ire);KUr=r(VHt,"FlaxRobertaForCausalLM"),VHt.forEach(t),ZUr=r(bze," (RoBERTa model)"),bze.forEach(t),eJr=i(Ne),w0=n(Ne,"LI",{});var vze=s(w0);Mwe=n(vze,"STRONG",{});var XHt=s(Mwe);oJr=r(XHt,"xglm"),XHt.forEach(t),rJr=r(vze," \u2014 "),dre=n(vze,"A",{href:!0});var zHt=s(dre);tJr=r(zHt,"FlaxXGLMForCausalLM"),zHt.forEach(t),aJr=r(vze," (XGLM model)"),vze.forEach(t),Ne.forEach(t),nJr=i(pi),T(A0.$$.fragment,pi),pi.forEach(t),hi.forEach(t),AHe=i(f),mf=n(f,"H2",{class:!0});var NJe=s(mf);L0=n(NJe,"A",{id:!0,class:!0,href:!0});var WHt=s(L0);Ewe=n(WHt,"SPAN",{});var QHt=s(Ewe);T(fk.$$.fragment,QHt),QHt.forEach(t),WHt.forEach(t),sJr=i(NJe),Cwe=n(NJe,"SPAN",{});var HHt=s(Cwe);lJr=r(HHt,"FlaxAutoModelForPreTraining"),HHt.forEach(t),NJe.forEach(t),LHe=i(f),Fr=n(f,"DIV",{class:!0});var _i=s(Fr);T(mk.$$.fragment,_i),iJr=i(_i),gf=n(_i,"P",{});var Pne=s(gf);dJr=r(Pne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),cre=n(Pne,"A",{href:!0});var UHt=s(cre);cJr=r(UHt,"from_pretrained()"),UHt.forEach(t),fJr=r(Pne," class method or the "),fre=n(Pne,"A",{href:!0});var JHt=s(fre);mJr=r(JHt,"from_config()"),JHt.forEach(t),gJr=r(Pne,` class
method.`),Pne.forEach(t),hJr=i(_i),gk=n(_i,"P",{});var qJe=s(gk);pJr=r(qJe,"This class cannot be instantiated directly using "),wwe=n(qJe,"CODE",{});var YHt=s(wwe);_Jr=r(YHt,"__init__()"),YHt.forEach(t),uJr=r(qJe," (throws an error)."),qJe.forEach(t),bJr=i(_i),Kt=n(_i,"DIV",{class:!0});var EL=s(Kt);T(hk.$$.fragment,EL),vJr=i(EL),Awe=n(EL,"P",{});var KHt=s(Awe);FJr=r(KHt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),KHt.forEach(t),TJr=i(EL),hf=n(EL,"P",{});var Bne=s(hf);MJr=r(Bne,`Note:
Loading a model from its configuration file does `),Lwe=n(Bne,"STRONG",{});var ZHt=s(Lwe);EJr=r(ZHt,"not"),ZHt.forEach(t),CJr=r(Bne,` load the model weights. It only affects the
model\u2019s configuration. Use `),mre=n(Bne,"A",{href:!0});var eUt=s(mre);wJr=r(eUt,"from_pretrained()"),eUt.forEach(t),AJr=r(Bne," to load the model weights."),Bne.forEach(t),LJr=i(EL),T(y0.$$.fragment,EL),EL.forEach(t),yJr=i(_i),Hr=n(_i,"DIV",{class:!0});var ui=s(Hr);T(pk.$$.fragment,ui),xJr=i(ui),ywe=n(ui,"P",{});var oUt=s(ywe);$Jr=r(oUt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),oUt.forEach(t),kJr=i(ui),xn=n(ui,"P",{});var CL=s(xn);SJr=r(CL,"The model class to instantiate is selected based on the "),xwe=n(CL,"CODE",{});var rUt=s(xwe);RJr=r(rUt,"model_type"),rUt.forEach(t),PJr=r(CL,` property of the config object (either
passed as an argument or loaded from `),$we=n(CL,"CODE",{});var tUt=s($we);BJr=r(tUt,"pretrained_model_name_or_path"),tUt.forEach(t),IJr=r(CL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=n(CL,"CODE",{});var aUt=s(kwe);NJr=r(aUt,"pretrained_model_name_or_path"),aUt.forEach(t),qJr=r(CL,":"),CL.forEach(t),jJr=i(ui),Ee=n(ui,"UL",{});var we=s(Ee);x0=n(we,"LI",{});var Fze=s(x0);Swe=n(Fze,"STRONG",{});var nUt=s(Swe);DJr=r(nUt,"albert"),nUt.forEach(t),GJr=r(Fze," \u2014 "),gre=n(Fze,"A",{href:!0});var sUt=s(gre);OJr=r(sUt,"FlaxAlbertForPreTraining"),sUt.forEach(t),VJr=r(Fze," (ALBERT model)"),Fze.forEach(t),XJr=i(we),$0=n(we,"LI",{});var Tze=s($0);Rwe=n(Tze,"STRONG",{});var lUt=s(Rwe);zJr=r(lUt,"bart"),lUt.forEach(t),WJr=r(Tze," \u2014 "),hre=n(Tze,"A",{href:!0});var iUt=s(hre);QJr=r(iUt,"FlaxBartForConditionalGeneration"),iUt.forEach(t),HJr=r(Tze," (BART model)"),Tze.forEach(t),UJr=i(we),k0=n(we,"LI",{});var Mze=s(k0);Pwe=n(Mze,"STRONG",{});var dUt=s(Pwe);JJr=r(dUt,"bert"),dUt.forEach(t),YJr=r(Mze," \u2014 "),pre=n(Mze,"A",{href:!0});var cUt=s(pre);KJr=r(cUt,"FlaxBertForPreTraining"),cUt.forEach(t),ZJr=r(Mze," (BERT model)"),Mze.forEach(t),eYr=i(we),S0=n(we,"LI",{});var Eze=s(S0);Bwe=n(Eze,"STRONG",{});var fUt=s(Bwe);oYr=r(fUt,"big_bird"),fUt.forEach(t),rYr=r(Eze," \u2014 "),_re=n(Eze,"A",{href:!0});var mUt=s(_re);tYr=r(mUt,"FlaxBigBirdForPreTraining"),mUt.forEach(t),aYr=r(Eze," (BigBird model)"),Eze.forEach(t),nYr=i(we),R0=n(we,"LI",{});var Cze=s(R0);Iwe=n(Cze,"STRONG",{});var gUt=s(Iwe);sYr=r(gUt,"electra"),gUt.forEach(t),lYr=r(Cze," \u2014 "),ure=n(Cze,"A",{href:!0});var hUt=s(ure);iYr=r(hUt,"FlaxElectraForPreTraining"),hUt.forEach(t),dYr=r(Cze," (ELECTRA model)"),Cze.forEach(t),cYr=i(we),P0=n(we,"LI",{});var wze=s(P0);Nwe=n(wze,"STRONG",{});var pUt=s(Nwe);fYr=r(pUt,"longt5"),pUt.forEach(t),mYr=r(wze," \u2014 "),bre=n(wze,"A",{href:!0});var _Ut=s(bre);gYr=r(_Ut,"FlaxLongT5ForConditionalGeneration"),_Ut.forEach(t),hYr=r(wze," (LongT5 model)"),wze.forEach(t),pYr=i(we),B0=n(we,"LI",{});var Aze=s(B0);qwe=n(Aze,"STRONG",{});var uUt=s(qwe);_Yr=r(uUt,"mbart"),uUt.forEach(t),uYr=r(Aze," \u2014 "),vre=n(Aze,"A",{href:!0});var bUt=s(vre);bYr=r(bUt,"FlaxMBartForConditionalGeneration"),bUt.forEach(t),vYr=r(Aze," (mBART model)"),Aze.forEach(t),FYr=i(we),I0=n(we,"LI",{});var Lze=s(I0);jwe=n(Lze,"STRONG",{});var vUt=s(jwe);TYr=r(vUt,"mt5"),vUt.forEach(t),MYr=r(Lze," \u2014 "),Fre=n(Lze,"A",{href:!0});var FUt=s(Fre);EYr=r(FUt,"FlaxMT5ForConditionalGeneration"),FUt.forEach(t),CYr=r(Lze," (MT5 model)"),Lze.forEach(t),wYr=i(we),N0=n(we,"LI",{});var yze=s(N0);Dwe=n(yze,"STRONG",{});var TUt=s(Dwe);AYr=r(TUt,"roberta"),TUt.forEach(t),LYr=r(yze," \u2014 "),Tre=n(yze,"A",{href:!0});var MUt=s(Tre);yYr=r(MUt,"FlaxRobertaForMaskedLM"),MUt.forEach(t),xYr=r(yze," (RoBERTa model)"),yze.forEach(t),$Yr=i(we),q0=n(we,"LI",{});var xze=s(q0);Gwe=n(xze,"STRONG",{});var EUt=s(Gwe);kYr=r(EUt,"roformer"),EUt.forEach(t),SYr=r(xze," \u2014 "),Mre=n(xze,"A",{href:!0});var CUt=s(Mre);RYr=r(CUt,"FlaxRoFormerForMaskedLM"),CUt.forEach(t),PYr=r(xze," (RoFormer model)"),xze.forEach(t),BYr=i(we),j0=n(we,"LI",{});var $ze=s(j0);Owe=n($ze,"STRONG",{});var wUt=s(Owe);IYr=r(wUt,"t5"),wUt.forEach(t),NYr=r($ze," \u2014 "),Ere=n($ze,"A",{href:!0});var AUt=s(Ere);qYr=r(AUt,"FlaxT5ForConditionalGeneration"),AUt.forEach(t),jYr=r($ze," (T5 model)"),$ze.forEach(t),DYr=i(we),D0=n(we,"LI",{});var kze=s(D0);Vwe=n(kze,"STRONG",{});var LUt=s(Vwe);GYr=r(LUt,"wav2vec2"),LUt.forEach(t),OYr=r(kze," \u2014 "),Cre=n(kze,"A",{href:!0});var yUt=s(Cre);VYr=r(yUt,"FlaxWav2Vec2ForPreTraining"),yUt.forEach(t),XYr=r(kze," (Wav2Vec2 model)"),kze.forEach(t),zYr=i(we),G0=n(we,"LI",{});var Sze=s(G0);Xwe=n(Sze,"STRONG",{});var xUt=s(Xwe);WYr=r(xUt,"xlm-roberta"),xUt.forEach(t),QYr=r(Sze," \u2014 "),wre=n(Sze,"A",{href:!0});var $Ut=s(wre);HYr=r($Ut,"FlaxXLMRobertaForMaskedLM"),$Ut.forEach(t),UYr=r(Sze," (XLM-RoBERTa model)"),Sze.forEach(t),we.forEach(t),JYr=i(ui),T(O0.$$.fragment,ui),ui.forEach(t),_i.forEach(t),yHe=i(f),pf=n(f,"H2",{class:!0});var jJe=s(pf);V0=n(jJe,"A",{id:!0,class:!0,href:!0});var kUt=s(V0);zwe=n(kUt,"SPAN",{});var SUt=s(zwe);T(_k.$$.fragment,SUt),SUt.forEach(t),kUt.forEach(t),YYr=i(jJe),Wwe=n(jJe,"SPAN",{});var RUt=s(Wwe);KYr=r(RUt,"FlaxAutoModelForMaskedLM"),RUt.forEach(t),jJe.forEach(t),xHe=i(f),Tr=n(f,"DIV",{class:!0});var bi=s(Tr);T(uk.$$.fragment,bi),ZYr=i(bi),_f=n(bi,"P",{});var Ine=s(_f);eKr=r(Ine,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),Are=n(Ine,"A",{href:!0});var PUt=s(Are);oKr=r(PUt,"from_pretrained()"),PUt.forEach(t),rKr=r(Ine," class method or the "),Lre=n(Ine,"A",{href:!0});var BUt=s(Lre);tKr=r(BUt,"from_config()"),BUt.forEach(t),aKr=r(Ine,` class
method.`),Ine.forEach(t),nKr=i(bi),bk=n(bi,"P",{});var DJe=s(bk);sKr=r(DJe,"This class cannot be instantiated directly using "),Qwe=n(DJe,"CODE",{});var IUt=s(Qwe);lKr=r(IUt,"__init__()"),IUt.forEach(t),iKr=r(DJe," (throws an error)."),DJe.forEach(t),dKr=i(bi),Zt=n(bi,"DIV",{class:!0});var wL=s(Zt);T(vk.$$.fragment,wL),cKr=i(wL),Hwe=n(wL,"P",{});var NUt=s(Hwe);fKr=r(NUt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),NUt.forEach(t),mKr=i(wL),uf=n(wL,"P",{});var Nne=s(uf);gKr=r(Nne,`Note:
Loading a model from its configuration file does `),Uwe=n(Nne,"STRONG",{});var qUt=s(Uwe);hKr=r(qUt,"not"),qUt.forEach(t),pKr=r(Nne,` load the model weights. It only affects the
model\u2019s configuration. Use `),yre=n(Nne,"A",{href:!0});var jUt=s(yre);_Kr=r(jUt,"from_pretrained()"),jUt.forEach(t),uKr=r(Nne," to load the model weights."),Nne.forEach(t),bKr=i(wL),T(X0.$$.fragment,wL),wL.forEach(t),vKr=i(bi),Ur=n(bi,"DIV",{class:!0});var vi=s(Ur);T(Fk.$$.fragment,vi),FKr=i(vi),Jwe=n(vi,"P",{});var DUt=s(Jwe);TKr=r(DUt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),DUt.forEach(t),MKr=i(vi),$n=n(vi,"P",{});var AL=s($n);EKr=r(AL,"The model class to instantiate is selected based on the "),Ywe=n(AL,"CODE",{});var GUt=s(Ywe);CKr=r(GUt,"model_type"),GUt.forEach(t),wKr=r(AL,` property of the config object (either
passed as an argument or loaded from `),Kwe=n(AL,"CODE",{});var OUt=s(Kwe);AKr=r(OUt,"pretrained_model_name_or_path"),OUt.forEach(t),LKr=r(AL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Zwe=n(AL,"CODE",{});var VUt=s(Zwe);yKr=r(VUt,"pretrained_model_name_or_path"),VUt.forEach(t),xKr=r(AL,":"),AL.forEach(t),$Kr=i(vi),$e=n(vi,"UL",{});var qe=s($e);z0=n(qe,"LI",{});var Rze=s(z0);e6e=n(Rze,"STRONG",{});var XUt=s(e6e);kKr=r(XUt,"albert"),XUt.forEach(t),SKr=r(Rze," \u2014 "),xre=n(Rze,"A",{href:!0});var zUt=s(xre);RKr=r(zUt,"FlaxAlbertForMaskedLM"),zUt.forEach(t),PKr=r(Rze," (ALBERT model)"),Rze.forEach(t),BKr=i(qe),W0=n(qe,"LI",{});var Pze=s(W0);o6e=n(Pze,"STRONG",{});var WUt=s(o6e);IKr=r(WUt,"bart"),WUt.forEach(t),NKr=r(Pze," \u2014 "),$re=n(Pze,"A",{href:!0});var QUt=s($re);qKr=r(QUt,"FlaxBartForConditionalGeneration"),QUt.forEach(t),jKr=r(Pze," (BART model)"),Pze.forEach(t),DKr=i(qe),Q0=n(qe,"LI",{});var Bze=s(Q0);r6e=n(Bze,"STRONG",{});var HUt=s(r6e);GKr=r(HUt,"bert"),HUt.forEach(t),OKr=r(Bze," \u2014 "),kre=n(Bze,"A",{href:!0});var UUt=s(kre);VKr=r(UUt,"FlaxBertForMaskedLM"),UUt.forEach(t),XKr=r(Bze," (BERT model)"),Bze.forEach(t),zKr=i(qe),H0=n(qe,"LI",{});var Ize=s(H0);t6e=n(Ize,"STRONG",{});var JUt=s(t6e);WKr=r(JUt,"big_bird"),JUt.forEach(t),QKr=r(Ize," \u2014 "),Sre=n(Ize,"A",{href:!0});var YUt=s(Sre);HKr=r(YUt,"FlaxBigBirdForMaskedLM"),YUt.forEach(t),UKr=r(Ize," (BigBird model)"),Ize.forEach(t),JKr=i(qe),U0=n(qe,"LI",{});var Nze=s(U0);a6e=n(Nze,"STRONG",{});var KUt=s(a6e);YKr=r(KUt,"distilbert"),KUt.forEach(t),KKr=r(Nze," \u2014 "),Rre=n(Nze,"A",{href:!0});var ZUt=s(Rre);ZKr=r(ZUt,"FlaxDistilBertForMaskedLM"),ZUt.forEach(t),eZr=r(Nze," (DistilBERT model)"),Nze.forEach(t),oZr=i(qe),J0=n(qe,"LI",{});var qze=s(J0);n6e=n(qze,"STRONG",{});var eJt=s(n6e);rZr=r(eJt,"electra"),eJt.forEach(t),tZr=r(qze," \u2014 "),Pre=n(qze,"A",{href:!0});var oJt=s(Pre);aZr=r(oJt,"FlaxElectraForMaskedLM"),oJt.forEach(t),nZr=r(qze," (ELECTRA model)"),qze.forEach(t),sZr=i(qe),Y0=n(qe,"LI",{});var jze=s(Y0);s6e=n(jze,"STRONG",{});var rJt=s(s6e);lZr=r(rJt,"mbart"),rJt.forEach(t),iZr=r(jze," \u2014 "),Bre=n(jze,"A",{href:!0});var tJt=s(Bre);dZr=r(tJt,"FlaxMBartForConditionalGeneration"),tJt.forEach(t),cZr=r(jze," (mBART model)"),jze.forEach(t),fZr=i(qe),K0=n(qe,"LI",{});var Dze=s(K0);l6e=n(Dze,"STRONG",{});var aJt=s(l6e);mZr=r(aJt,"roberta"),aJt.forEach(t),gZr=r(Dze," \u2014 "),Ire=n(Dze,"A",{href:!0});var nJt=s(Ire);hZr=r(nJt,"FlaxRobertaForMaskedLM"),nJt.forEach(t),pZr=r(Dze," (RoBERTa model)"),Dze.forEach(t),_Zr=i(qe),Z0=n(qe,"LI",{});var Gze=s(Z0);i6e=n(Gze,"STRONG",{});var sJt=s(i6e);uZr=r(sJt,"roformer"),sJt.forEach(t),bZr=r(Gze," \u2014 "),Nre=n(Gze,"A",{href:!0});var lJt=s(Nre);vZr=r(lJt,"FlaxRoFormerForMaskedLM"),lJt.forEach(t),FZr=r(Gze," (RoFormer model)"),Gze.forEach(t),TZr=i(qe),ew=n(qe,"LI",{});var Oze=s(ew);d6e=n(Oze,"STRONG",{});var iJt=s(d6e);MZr=r(iJt,"xlm-roberta"),iJt.forEach(t),EZr=r(Oze," \u2014 "),qre=n(Oze,"A",{href:!0});var dJt=s(qre);CZr=r(dJt,"FlaxXLMRobertaForMaskedLM"),dJt.forEach(t),wZr=r(Oze," (XLM-RoBERTa model)"),Oze.forEach(t),qe.forEach(t),AZr=i(vi),T(ow.$$.fragment,vi),vi.forEach(t),bi.forEach(t),$He=i(f),bf=n(f,"H2",{class:!0});var GJe=s(bf);rw=n(GJe,"A",{id:!0,class:!0,href:!0});var cJt=s(rw);c6e=n(cJt,"SPAN",{});var fJt=s(c6e);T(Tk.$$.fragment,fJt),fJt.forEach(t),cJt.forEach(t),LZr=i(GJe),f6e=n(GJe,"SPAN",{});var mJt=s(f6e);yZr=r(mJt,"FlaxAutoModelForSeq2SeqLM"),mJt.forEach(t),GJe.forEach(t),kHe=i(f),Mr=n(f,"DIV",{class:!0});var Fi=s(Mr);T(Mk.$$.fragment,Fi),xZr=i(Fi),vf=n(Fi,"P",{});var qne=s(vf);$Zr=r(qne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),jre=n(qne,"A",{href:!0});var gJt=s(jre);kZr=r(gJt,"from_pretrained()"),gJt.forEach(t),SZr=r(qne," class method or the "),Dre=n(qne,"A",{href:!0});var hJt=s(Dre);RZr=r(hJt,"from_config()"),hJt.forEach(t),PZr=r(qne,` class
method.`),qne.forEach(t),BZr=i(Fi),Ek=n(Fi,"P",{});var OJe=s(Ek);IZr=r(OJe,"This class cannot be instantiated directly using "),m6e=n(OJe,"CODE",{});var pJt=s(m6e);NZr=r(pJt,"__init__()"),pJt.forEach(t),qZr=r(OJe," (throws an error)."),OJe.forEach(t),jZr=i(Fi),ea=n(Fi,"DIV",{class:!0});var LL=s(ea);T(Ck.$$.fragment,LL),DZr=i(LL),g6e=n(LL,"P",{});var _Jt=s(g6e);GZr=r(_Jt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_Jt.forEach(t),OZr=i(LL),Ff=n(LL,"P",{});var jne=s(Ff);VZr=r(jne,`Note:
Loading a model from its configuration file does `),h6e=n(jne,"STRONG",{});var uJt=s(h6e);XZr=r(uJt,"not"),uJt.forEach(t),zZr=r(jne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Gre=n(jne,"A",{href:!0});var bJt=s(Gre);WZr=r(bJt,"from_pretrained()"),bJt.forEach(t),QZr=r(jne," to load the model weights."),jne.forEach(t),HZr=i(LL),T(tw.$$.fragment,LL),LL.forEach(t),UZr=i(Fi),Jr=n(Fi,"DIV",{class:!0});var Ti=s(Jr);T(wk.$$.fragment,Ti),JZr=i(Ti),p6e=n(Ti,"P",{});var vJt=s(p6e);YZr=r(vJt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),vJt.forEach(t),KZr=i(Ti),kn=n(Ti,"P",{});var yL=s(kn);ZZr=r(yL,"The model class to instantiate is selected based on the "),_6e=n(yL,"CODE",{});var FJt=s(_6e);eet=r(FJt,"model_type"),FJt.forEach(t),oet=r(yL,` property of the config object (either
passed as an argument or loaded from `),u6e=n(yL,"CODE",{});var TJt=s(u6e);ret=r(TJt,"pretrained_model_name_or_path"),TJt.forEach(t),tet=r(yL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),b6e=n(yL,"CODE",{});var MJt=s(b6e);aet=r(MJt,"pretrained_model_name_or_path"),MJt.forEach(t),net=r(yL,":"),yL.forEach(t),set=i(Ti),ke=n(Ti,"UL",{});var je=s(ke);aw=n(je,"LI",{});var Vze=s(aw);v6e=n(Vze,"STRONG",{});var EJt=s(v6e);iet=r(EJt,"bart"),EJt.forEach(t),det=r(Vze," \u2014 "),Ore=n(Vze,"A",{href:!0});var CJt=s(Ore);cet=r(CJt,"FlaxBartForConditionalGeneration"),CJt.forEach(t),fet=r(Vze," (BART model)"),Vze.forEach(t),met=i(je),nw=n(je,"LI",{});var Xze=s(nw);F6e=n(Xze,"STRONG",{});var wJt=s(F6e);get=r(wJt,"blenderbot"),wJt.forEach(t),het=r(Xze," \u2014 "),Vre=n(Xze,"A",{href:!0});var AJt=s(Vre);pet=r(AJt,"FlaxBlenderbotForConditionalGeneration"),AJt.forEach(t),_et=r(Xze," (Blenderbot model)"),Xze.forEach(t),uet=i(je),sw=n(je,"LI",{});var zze=s(sw);T6e=n(zze,"STRONG",{});var LJt=s(T6e);bet=r(LJt,"blenderbot-small"),LJt.forEach(t),vet=r(zze," \u2014 "),Xre=n(zze,"A",{href:!0});var yJt=s(Xre);Fet=r(yJt,"FlaxBlenderbotSmallForConditionalGeneration"),yJt.forEach(t),Tet=r(zze," (BlenderbotSmall model)"),zze.forEach(t),Met=i(je),lw=n(je,"LI",{});var Wze=s(lw);M6e=n(Wze,"STRONG",{});var xJt=s(M6e);Eet=r(xJt,"encoder-decoder"),xJt.forEach(t),Cet=r(Wze," \u2014 "),zre=n(Wze,"A",{href:!0});var $Jt=s(zre);wet=r($Jt,"FlaxEncoderDecoderModel"),$Jt.forEach(t),Aet=r(Wze," (Encoder decoder model)"),Wze.forEach(t),Let=i(je),iw=n(je,"LI",{});var Qze=s(iw);E6e=n(Qze,"STRONG",{});var kJt=s(E6e);yet=r(kJt,"longt5"),kJt.forEach(t),xet=r(Qze," \u2014 "),Wre=n(Qze,"A",{href:!0});var SJt=s(Wre);$et=r(SJt,"FlaxLongT5ForConditionalGeneration"),SJt.forEach(t),ket=r(Qze," (LongT5 model)"),Qze.forEach(t),Set=i(je),dw=n(je,"LI",{});var Hze=s(dw);C6e=n(Hze,"STRONG",{});var RJt=s(C6e);Ret=r(RJt,"marian"),RJt.forEach(t),Pet=r(Hze," \u2014 "),Qre=n(Hze,"A",{href:!0});var PJt=s(Qre);Bet=r(PJt,"FlaxMarianMTModel"),PJt.forEach(t),Iet=r(Hze," (Marian model)"),Hze.forEach(t),Net=i(je),cw=n(je,"LI",{});var Uze=s(cw);w6e=n(Uze,"STRONG",{});var BJt=s(w6e);qet=r(BJt,"mbart"),BJt.forEach(t),jet=r(Uze," \u2014 "),Hre=n(Uze,"A",{href:!0});var IJt=s(Hre);Det=r(IJt,"FlaxMBartForConditionalGeneration"),IJt.forEach(t),Get=r(Uze," (mBART model)"),Uze.forEach(t),Oet=i(je),fw=n(je,"LI",{});var Jze=s(fw);A6e=n(Jze,"STRONG",{});var NJt=s(A6e);Vet=r(NJt,"mt5"),NJt.forEach(t),Xet=r(Jze," \u2014 "),Ure=n(Jze,"A",{href:!0});var qJt=s(Ure);zet=r(qJt,"FlaxMT5ForConditionalGeneration"),qJt.forEach(t),Wet=r(Jze," (MT5 model)"),Jze.forEach(t),Qet=i(je),mw=n(je,"LI",{});var Yze=s(mw);L6e=n(Yze,"STRONG",{});var jJt=s(L6e);Het=r(jJt,"pegasus"),jJt.forEach(t),Uet=r(Yze," \u2014 "),Jre=n(Yze,"A",{href:!0});var DJt=s(Jre);Jet=r(DJt,"FlaxPegasusForConditionalGeneration"),DJt.forEach(t),Yet=r(Yze," (Pegasus model)"),Yze.forEach(t),Ket=i(je),gw=n(je,"LI",{});var Kze=s(gw);y6e=n(Kze,"STRONG",{});var GJt=s(y6e);Zet=r(GJt,"t5"),GJt.forEach(t),eot=r(Kze," \u2014 "),Yre=n(Kze,"A",{href:!0});var OJt=s(Yre);oot=r(OJt,"FlaxT5ForConditionalGeneration"),OJt.forEach(t),rot=r(Kze," (T5 model)"),Kze.forEach(t),je.forEach(t),tot=i(Ti),T(hw.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),SHe=i(f),Tf=n(f,"H2",{class:!0});var VJe=s(Tf);pw=n(VJe,"A",{id:!0,class:!0,href:!0});var VJt=s(pw);x6e=n(VJt,"SPAN",{});var XJt=s(x6e);T(Ak.$$.fragment,XJt),XJt.forEach(t),VJt.forEach(t),aot=i(VJe),$6e=n(VJe,"SPAN",{});var zJt=s($6e);not=r(zJt,"FlaxAutoModelForSequenceClassification"),zJt.forEach(t),VJe.forEach(t),RHe=i(f),Er=n(f,"DIV",{class:!0});var Mi=s(Er);T(Lk.$$.fragment,Mi),sot=i(Mi),Mf=n(Mi,"P",{});var Dne=s(Mf);lot=r(Dne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),Kre=n(Dne,"A",{href:!0});var WJt=s(Kre);iot=r(WJt,"from_pretrained()"),WJt.forEach(t),dot=r(Dne," class method or the "),Zre=n(Dne,"A",{href:!0});var QJt=s(Zre);cot=r(QJt,"from_config()"),QJt.forEach(t),fot=r(Dne,` class
method.`),Dne.forEach(t),mot=i(Mi),yk=n(Mi,"P",{});var XJe=s(yk);got=r(XJe,"This class cannot be instantiated directly using "),k6e=n(XJe,"CODE",{});var HJt=s(k6e);hot=r(HJt,"__init__()"),HJt.forEach(t),pot=r(XJe," (throws an error)."),XJe.forEach(t),_ot=i(Mi),oa=n(Mi,"DIV",{class:!0});var xL=s(oa);T(xk.$$.fragment,xL),uot=i(xL),S6e=n(xL,"P",{});var UJt=s(S6e);bot=r(UJt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),UJt.forEach(t),vot=i(xL),Ef=n(xL,"P",{});var Gne=s(Ef);Fot=r(Gne,`Note:
Loading a model from its configuration file does `),R6e=n(Gne,"STRONG",{});var JJt=s(R6e);Tot=r(JJt,"not"),JJt.forEach(t),Mot=r(Gne,` load the model weights. It only affects the
model\u2019s configuration. Use `),ete=n(Gne,"A",{href:!0});var YJt=s(ete);Eot=r(YJt,"from_pretrained()"),YJt.forEach(t),Cot=r(Gne," to load the model weights."),Gne.forEach(t),wot=i(xL),T(_w.$$.fragment,xL),xL.forEach(t),Aot=i(Mi),Yr=n(Mi,"DIV",{class:!0});var Ei=s(Yr);T($k.$$.fragment,Ei),Lot=i(Ei),P6e=n(Ei,"P",{});var KJt=s(P6e);yot=r(KJt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),KJt.forEach(t),xot=i(Ei),Sn=n(Ei,"P",{});var $L=s(Sn);$ot=r($L,"The model class to instantiate is selected based on the "),B6e=n($L,"CODE",{});var ZJt=s(B6e);kot=r(ZJt,"model_type"),ZJt.forEach(t),Sot=r($L,` property of the config object (either
passed as an argument or loaded from `),I6e=n($L,"CODE",{});var eYt=s(I6e);Rot=r(eYt,"pretrained_model_name_or_path"),eYt.forEach(t),Pot=r($L,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N6e=n($L,"CODE",{});var oYt=s(N6e);Bot=r(oYt,"pretrained_model_name_or_path"),oYt.forEach(t),Iot=r($L,":"),$L.forEach(t),Not=i(Ei),Se=n(Ei,"UL",{});var De=s(Se);uw=n(De,"LI",{});var Zze=s(uw);q6e=n(Zze,"STRONG",{});var rYt=s(q6e);qot=r(rYt,"albert"),rYt.forEach(t),jot=r(Zze," \u2014 "),ote=n(Zze,"A",{href:!0});var tYt=s(ote);Dot=r(tYt,"FlaxAlbertForSequenceClassification"),tYt.forEach(t),Got=r(Zze," (ALBERT model)"),Zze.forEach(t),Oot=i(De),bw=n(De,"LI",{});var eWe=s(bw);j6e=n(eWe,"STRONG",{});var aYt=s(j6e);Vot=r(aYt,"bart"),aYt.forEach(t),Xot=r(eWe," \u2014 "),rte=n(eWe,"A",{href:!0});var nYt=s(rte);zot=r(nYt,"FlaxBartForSequenceClassification"),nYt.forEach(t),Wot=r(eWe," (BART model)"),eWe.forEach(t),Qot=i(De),vw=n(De,"LI",{});var oWe=s(vw);D6e=n(oWe,"STRONG",{});var sYt=s(D6e);Hot=r(sYt,"bert"),sYt.forEach(t),Uot=r(oWe," \u2014 "),tte=n(oWe,"A",{href:!0});var lYt=s(tte);Jot=r(lYt,"FlaxBertForSequenceClassification"),lYt.forEach(t),Yot=r(oWe," (BERT model)"),oWe.forEach(t),Kot=i(De),Fw=n(De,"LI",{});var rWe=s(Fw);G6e=n(rWe,"STRONG",{});var iYt=s(G6e);Zot=r(iYt,"big_bird"),iYt.forEach(t),ert=r(rWe," \u2014 "),ate=n(rWe,"A",{href:!0});var dYt=s(ate);ort=r(dYt,"FlaxBigBirdForSequenceClassification"),dYt.forEach(t),rrt=r(rWe," (BigBird model)"),rWe.forEach(t),trt=i(De),Tw=n(De,"LI",{});var tWe=s(Tw);O6e=n(tWe,"STRONG",{});var cYt=s(O6e);art=r(cYt,"distilbert"),cYt.forEach(t),nrt=r(tWe," \u2014 "),nte=n(tWe,"A",{href:!0});var fYt=s(nte);srt=r(fYt,"FlaxDistilBertForSequenceClassification"),fYt.forEach(t),lrt=r(tWe," (DistilBERT model)"),tWe.forEach(t),irt=i(De),Mw=n(De,"LI",{});var aWe=s(Mw);V6e=n(aWe,"STRONG",{});var mYt=s(V6e);drt=r(mYt,"electra"),mYt.forEach(t),crt=r(aWe," \u2014 "),ste=n(aWe,"A",{href:!0});var gYt=s(ste);frt=r(gYt,"FlaxElectraForSequenceClassification"),gYt.forEach(t),mrt=r(aWe," (ELECTRA model)"),aWe.forEach(t),grt=i(De),Ew=n(De,"LI",{});var nWe=s(Ew);X6e=n(nWe,"STRONG",{});var hYt=s(X6e);hrt=r(hYt,"mbart"),hYt.forEach(t),prt=r(nWe," \u2014 "),lte=n(nWe,"A",{href:!0});var pYt=s(lte);_rt=r(pYt,"FlaxMBartForSequenceClassification"),pYt.forEach(t),urt=r(nWe," (mBART model)"),nWe.forEach(t),brt=i(De),Cw=n(De,"LI",{});var sWe=s(Cw);z6e=n(sWe,"STRONG",{});var _Yt=s(z6e);vrt=r(_Yt,"roberta"),_Yt.forEach(t),Frt=r(sWe," \u2014 "),ite=n(sWe,"A",{href:!0});var uYt=s(ite);Trt=r(uYt,"FlaxRobertaForSequenceClassification"),uYt.forEach(t),Mrt=r(sWe," (RoBERTa model)"),sWe.forEach(t),Ert=i(De),ww=n(De,"LI",{});var lWe=s(ww);W6e=n(lWe,"STRONG",{});var bYt=s(W6e);Crt=r(bYt,"roformer"),bYt.forEach(t),wrt=r(lWe," \u2014 "),dte=n(lWe,"A",{href:!0});var vYt=s(dte);Art=r(vYt,"FlaxRoFormerForSequenceClassification"),vYt.forEach(t),Lrt=r(lWe," (RoFormer model)"),lWe.forEach(t),yrt=i(De),Aw=n(De,"LI",{});var iWe=s(Aw);Q6e=n(iWe,"STRONG",{});var FYt=s(Q6e);xrt=r(FYt,"xlm-roberta"),FYt.forEach(t),$rt=r(iWe," \u2014 "),cte=n(iWe,"A",{href:!0});var TYt=s(cte);krt=r(TYt,"FlaxXLMRobertaForSequenceClassification"),TYt.forEach(t),Srt=r(iWe," (XLM-RoBERTa model)"),iWe.forEach(t),De.forEach(t),Rrt=i(Ei),T(Lw.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),PHe=i(f),Cf=n(f,"H2",{class:!0});var zJe=s(Cf);yw=n(zJe,"A",{id:!0,class:!0,href:!0});var MYt=s(yw);H6e=n(MYt,"SPAN",{});var EYt=s(H6e);T(kk.$$.fragment,EYt),EYt.forEach(t),MYt.forEach(t),Prt=i(zJe),U6e=n(zJe,"SPAN",{});var CYt=s(U6e);Brt=r(CYt,"FlaxAutoModelForQuestionAnswering"),CYt.forEach(t),zJe.forEach(t),BHe=i(f),Cr=n(f,"DIV",{class:!0});var Ci=s(Cr);T(Sk.$$.fragment,Ci),Irt=i(Ci),wf=n(Ci,"P",{});var One=s(wf);Nrt=r(One,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),fte=n(One,"A",{href:!0});var wYt=s(fte);qrt=r(wYt,"from_pretrained()"),wYt.forEach(t),jrt=r(One," class method or the "),mte=n(One,"A",{href:!0});var AYt=s(mte);Drt=r(AYt,"from_config()"),AYt.forEach(t),Grt=r(One,` class
method.`),One.forEach(t),Ort=i(Ci),Rk=n(Ci,"P",{});var WJe=s(Rk);Vrt=r(WJe,"This class cannot be instantiated directly using "),J6e=n(WJe,"CODE",{});var LYt=s(J6e);Xrt=r(LYt,"__init__()"),LYt.forEach(t),zrt=r(WJe," (throws an error)."),WJe.forEach(t),Wrt=i(Ci),ra=n(Ci,"DIV",{class:!0});var kL=s(ra);T(Pk.$$.fragment,kL),Qrt=i(kL),Y6e=n(kL,"P",{});var yYt=s(Y6e);Hrt=r(yYt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),yYt.forEach(t),Urt=i(kL),Af=n(kL,"P",{});var Vne=s(Af);Jrt=r(Vne,`Note:
Loading a model from its configuration file does `),K6e=n(Vne,"STRONG",{});var xYt=s(K6e);Yrt=r(xYt,"not"),xYt.forEach(t),Krt=r(Vne,` load the model weights. It only affects the
model\u2019s configuration. Use `),gte=n(Vne,"A",{href:!0});var $Yt=s(gte);Zrt=r($Yt,"from_pretrained()"),$Yt.forEach(t),ett=r(Vne," to load the model weights."),Vne.forEach(t),ott=i(kL),T(xw.$$.fragment,kL),kL.forEach(t),rtt=i(Ci),Kr=n(Ci,"DIV",{class:!0});var wi=s(Kr);T(Bk.$$.fragment,wi),ttt=i(wi),Z6e=n(wi,"P",{});var kYt=s(Z6e);att=r(kYt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),kYt.forEach(t),ntt=i(wi),Rn=n(wi,"P",{});var SL=s(Rn);stt=r(SL,"The model class to instantiate is selected based on the "),eAe=n(SL,"CODE",{});var SYt=s(eAe);ltt=r(SYt,"model_type"),SYt.forEach(t),itt=r(SL,` property of the config object (either
passed as an argument or loaded from `),oAe=n(SL,"CODE",{});var RYt=s(oAe);dtt=r(RYt,"pretrained_model_name_or_path"),RYt.forEach(t),ctt=r(SL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rAe=n(SL,"CODE",{});var PYt=s(rAe);ftt=r(PYt,"pretrained_model_name_or_path"),PYt.forEach(t),mtt=r(SL,":"),SL.forEach(t),gtt=i(wi),Re=n(wi,"UL",{});var Ge=s(Re);$w=n(Ge,"LI",{});var dWe=s($w);tAe=n(dWe,"STRONG",{});var BYt=s(tAe);htt=r(BYt,"albert"),BYt.forEach(t),ptt=r(dWe," \u2014 "),hte=n(dWe,"A",{href:!0});var IYt=s(hte);_tt=r(IYt,"FlaxAlbertForQuestionAnswering"),IYt.forEach(t),utt=r(dWe," (ALBERT model)"),dWe.forEach(t),btt=i(Ge),kw=n(Ge,"LI",{});var cWe=s(kw);aAe=n(cWe,"STRONG",{});var NYt=s(aAe);vtt=r(NYt,"bart"),NYt.forEach(t),Ftt=r(cWe," \u2014 "),pte=n(cWe,"A",{href:!0});var qYt=s(pte);Ttt=r(qYt,"FlaxBartForQuestionAnswering"),qYt.forEach(t),Mtt=r(cWe," (BART model)"),cWe.forEach(t),Ett=i(Ge),Sw=n(Ge,"LI",{});var fWe=s(Sw);nAe=n(fWe,"STRONG",{});var jYt=s(nAe);Ctt=r(jYt,"bert"),jYt.forEach(t),wtt=r(fWe," \u2014 "),_te=n(fWe,"A",{href:!0});var DYt=s(_te);Att=r(DYt,"FlaxBertForQuestionAnswering"),DYt.forEach(t),Ltt=r(fWe," (BERT model)"),fWe.forEach(t),ytt=i(Ge),Rw=n(Ge,"LI",{});var mWe=s(Rw);sAe=n(mWe,"STRONG",{});var GYt=s(sAe);xtt=r(GYt,"big_bird"),GYt.forEach(t),$tt=r(mWe," \u2014 "),ute=n(mWe,"A",{href:!0});var OYt=s(ute);ktt=r(OYt,"FlaxBigBirdForQuestionAnswering"),OYt.forEach(t),Stt=r(mWe," (BigBird model)"),mWe.forEach(t),Rtt=i(Ge),Pw=n(Ge,"LI",{});var gWe=s(Pw);lAe=n(gWe,"STRONG",{});var VYt=s(lAe);Ptt=r(VYt,"distilbert"),VYt.forEach(t),Btt=r(gWe," \u2014 "),bte=n(gWe,"A",{href:!0});var XYt=s(bte);Itt=r(XYt,"FlaxDistilBertForQuestionAnswering"),XYt.forEach(t),Ntt=r(gWe," (DistilBERT model)"),gWe.forEach(t),qtt=i(Ge),Bw=n(Ge,"LI",{});var hWe=s(Bw);iAe=n(hWe,"STRONG",{});var zYt=s(iAe);jtt=r(zYt,"electra"),zYt.forEach(t),Dtt=r(hWe," \u2014 "),vte=n(hWe,"A",{href:!0});var WYt=s(vte);Gtt=r(WYt,"FlaxElectraForQuestionAnswering"),WYt.forEach(t),Ott=r(hWe," (ELECTRA model)"),hWe.forEach(t),Vtt=i(Ge),Iw=n(Ge,"LI",{});var pWe=s(Iw);dAe=n(pWe,"STRONG",{});var QYt=s(dAe);Xtt=r(QYt,"mbart"),QYt.forEach(t),ztt=r(pWe," \u2014 "),Fte=n(pWe,"A",{href:!0});var HYt=s(Fte);Wtt=r(HYt,"FlaxMBartForQuestionAnswering"),HYt.forEach(t),Qtt=r(pWe," (mBART model)"),pWe.forEach(t),Htt=i(Ge),Nw=n(Ge,"LI",{});var _We=s(Nw);cAe=n(_We,"STRONG",{});var UYt=s(cAe);Utt=r(UYt,"roberta"),UYt.forEach(t),Jtt=r(_We," \u2014 "),Tte=n(_We,"A",{href:!0});var JYt=s(Tte);Ytt=r(JYt,"FlaxRobertaForQuestionAnswering"),JYt.forEach(t),Ktt=r(_We," (RoBERTa model)"),_We.forEach(t),Ztt=i(Ge),qw=n(Ge,"LI",{});var uWe=s(qw);fAe=n(uWe,"STRONG",{});var YYt=s(fAe);eat=r(YYt,"roformer"),YYt.forEach(t),oat=r(uWe," \u2014 "),Mte=n(uWe,"A",{href:!0});var KYt=s(Mte);rat=r(KYt,"FlaxRoFormerForQuestionAnswering"),KYt.forEach(t),tat=r(uWe," (RoFormer model)"),uWe.forEach(t),aat=i(Ge),jw=n(Ge,"LI",{});var bWe=s(jw);mAe=n(bWe,"STRONG",{});var ZYt=s(mAe);nat=r(ZYt,"xlm-roberta"),ZYt.forEach(t),sat=r(bWe," \u2014 "),Ete=n(bWe,"A",{href:!0});var eKt=s(Ete);lat=r(eKt,"FlaxXLMRobertaForQuestionAnswering"),eKt.forEach(t),iat=r(bWe," (XLM-RoBERTa model)"),bWe.forEach(t),Ge.forEach(t),dat=i(wi),T(Dw.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),IHe=i(f),Lf=n(f,"H2",{class:!0});var QJe=s(Lf);Gw=n(QJe,"A",{id:!0,class:!0,href:!0});var oKt=s(Gw);gAe=n(oKt,"SPAN",{});var rKt=s(gAe);T(Ik.$$.fragment,rKt),rKt.forEach(t),oKt.forEach(t),cat=i(QJe),hAe=n(QJe,"SPAN",{});var tKt=s(hAe);fat=r(tKt,"FlaxAutoModelForTokenClassification"),tKt.forEach(t),QJe.forEach(t),NHe=i(f),wr=n(f,"DIV",{class:!0});var Ai=s(wr);T(Nk.$$.fragment,Ai),mat=i(Ai),yf=n(Ai,"P",{});var Xne=s(yf);gat=r(Xne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Cte=n(Xne,"A",{href:!0});var aKt=s(Cte);hat=r(aKt,"from_pretrained()"),aKt.forEach(t),pat=r(Xne," class method or the "),wte=n(Xne,"A",{href:!0});var nKt=s(wte);_at=r(nKt,"from_config()"),nKt.forEach(t),uat=r(Xne,` class
method.`),Xne.forEach(t),bat=i(Ai),qk=n(Ai,"P",{});var HJe=s(qk);vat=r(HJe,"This class cannot be instantiated directly using "),pAe=n(HJe,"CODE",{});var sKt=s(pAe);Fat=r(sKt,"__init__()"),sKt.forEach(t),Tat=r(HJe," (throws an error)."),HJe.forEach(t),Mat=i(Ai),ta=n(Ai,"DIV",{class:!0});var RL=s(ta);T(jk.$$.fragment,RL),Eat=i(RL),_Ae=n(RL,"P",{});var lKt=s(_Ae);Cat=r(lKt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),lKt.forEach(t),wat=i(RL),xf=n(RL,"P",{});var zne=s(xf);Aat=r(zne,`Note:
Loading a model from its configuration file does `),uAe=n(zne,"STRONG",{});var iKt=s(uAe);Lat=r(iKt,"not"),iKt.forEach(t),yat=r(zne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Ate=n(zne,"A",{href:!0});var dKt=s(Ate);xat=r(dKt,"from_pretrained()"),dKt.forEach(t),$at=r(zne," to load the model weights."),zne.forEach(t),kat=i(RL),T(Ow.$$.fragment,RL),RL.forEach(t),Sat=i(Ai),Zr=n(Ai,"DIV",{class:!0});var Li=s(Zr);T(Dk.$$.fragment,Li),Rat=i(Li),bAe=n(Li,"P",{});var cKt=s(bAe);Pat=r(cKt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),cKt.forEach(t),Bat=i(Li),Pn=n(Li,"P",{});var PL=s(Pn);Iat=r(PL,"The model class to instantiate is selected based on the "),vAe=n(PL,"CODE",{});var fKt=s(vAe);Nat=r(fKt,"model_type"),fKt.forEach(t),qat=r(PL,` property of the config object (either
passed as an argument or loaded from `),FAe=n(PL,"CODE",{});var mKt=s(FAe);jat=r(mKt,"pretrained_model_name_or_path"),mKt.forEach(t),Dat=r(PL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TAe=n(PL,"CODE",{});var gKt=s(TAe);Gat=r(gKt,"pretrained_model_name_or_path"),gKt.forEach(t),Oat=r(PL,":"),PL.forEach(t),Vat=i(Li),Xe=n(Li,"UL",{});var Co=s(Xe);Vw=n(Co,"LI",{});var vWe=s(Vw);MAe=n(vWe,"STRONG",{});var hKt=s(MAe);Xat=r(hKt,"albert"),hKt.forEach(t),zat=r(vWe," \u2014 "),Lte=n(vWe,"A",{href:!0});var pKt=s(Lte);Wat=r(pKt,"FlaxAlbertForTokenClassification"),pKt.forEach(t),Qat=r(vWe," (ALBERT model)"),vWe.forEach(t),Hat=i(Co),Xw=n(Co,"LI",{});var FWe=s(Xw);EAe=n(FWe,"STRONG",{});var _Kt=s(EAe);Uat=r(_Kt,"bert"),_Kt.forEach(t),Jat=r(FWe," \u2014 "),yte=n(FWe,"A",{href:!0});var uKt=s(yte);Yat=r(uKt,"FlaxBertForTokenClassification"),uKt.forEach(t),Kat=r(FWe," (BERT model)"),FWe.forEach(t),Zat=i(Co),zw=n(Co,"LI",{});var TWe=s(zw);CAe=n(TWe,"STRONG",{});var bKt=s(CAe);ent=r(bKt,"big_bird"),bKt.forEach(t),ont=r(TWe," \u2014 "),xte=n(TWe,"A",{href:!0});var vKt=s(xte);rnt=r(vKt,"FlaxBigBirdForTokenClassification"),vKt.forEach(t),tnt=r(TWe," (BigBird model)"),TWe.forEach(t),ant=i(Co),Ww=n(Co,"LI",{});var MWe=s(Ww);wAe=n(MWe,"STRONG",{});var FKt=s(wAe);nnt=r(FKt,"distilbert"),FKt.forEach(t),snt=r(MWe," \u2014 "),$te=n(MWe,"A",{href:!0});var TKt=s($te);lnt=r(TKt,"FlaxDistilBertForTokenClassification"),TKt.forEach(t),int=r(MWe," (DistilBERT model)"),MWe.forEach(t),dnt=i(Co),Qw=n(Co,"LI",{});var EWe=s(Qw);AAe=n(EWe,"STRONG",{});var MKt=s(AAe);cnt=r(MKt,"electra"),MKt.forEach(t),fnt=r(EWe," \u2014 "),kte=n(EWe,"A",{href:!0});var EKt=s(kte);mnt=r(EKt,"FlaxElectraForTokenClassification"),EKt.forEach(t),gnt=r(EWe," (ELECTRA model)"),EWe.forEach(t),hnt=i(Co),Hw=n(Co,"LI",{});var CWe=s(Hw);LAe=n(CWe,"STRONG",{});var CKt=s(LAe);pnt=r(CKt,"roberta"),CKt.forEach(t),_nt=r(CWe," \u2014 "),Ste=n(CWe,"A",{href:!0});var wKt=s(Ste);unt=r(wKt,"FlaxRobertaForTokenClassification"),wKt.forEach(t),bnt=r(CWe," (RoBERTa model)"),CWe.forEach(t),vnt=i(Co),Uw=n(Co,"LI",{});var wWe=s(Uw);yAe=n(wWe,"STRONG",{});var AKt=s(yAe);Fnt=r(AKt,"roformer"),AKt.forEach(t),Tnt=r(wWe," \u2014 "),Rte=n(wWe,"A",{href:!0});var LKt=s(Rte);Mnt=r(LKt,"FlaxRoFormerForTokenClassification"),LKt.forEach(t),Ent=r(wWe," (RoFormer model)"),wWe.forEach(t),Cnt=i(Co),Jw=n(Co,"LI",{});var AWe=s(Jw);xAe=n(AWe,"STRONG",{});var yKt=s(xAe);wnt=r(yKt,"xlm-roberta"),yKt.forEach(t),Ant=r(AWe," \u2014 "),Pte=n(AWe,"A",{href:!0});var xKt=s(Pte);Lnt=r(xKt,"FlaxXLMRobertaForTokenClassification"),xKt.forEach(t),ynt=r(AWe," (XLM-RoBERTa model)"),AWe.forEach(t),Co.forEach(t),xnt=i(Li),T(Yw.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),qHe=i(f),$f=n(f,"H2",{class:!0});var UJe=s($f);Kw=n(UJe,"A",{id:!0,class:!0,href:!0});var $Kt=s(Kw);$Ae=n($Kt,"SPAN",{});var kKt=s($Ae);T(Gk.$$.fragment,kKt),kKt.forEach(t),$Kt.forEach(t),$nt=i(UJe),kAe=n(UJe,"SPAN",{});var SKt=s(kAe);knt=r(SKt,"FlaxAutoModelForMultipleChoice"),SKt.forEach(t),UJe.forEach(t),jHe=i(f),Ar=n(f,"DIV",{class:!0});var yi=s(Ar);T(Ok.$$.fragment,yi),Snt=i(yi),kf=n(yi,"P",{});var Wne=s(kf);Rnt=r(Wne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Bte=n(Wne,"A",{href:!0});var RKt=s(Bte);Pnt=r(RKt,"from_pretrained()"),RKt.forEach(t),Bnt=r(Wne," class method or the "),Ite=n(Wne,"A",{href:!0});var PKt=s(Ite);Int=r(PKt,"from_config()"),PKt.forEach(t),Nnt=r(Wne,` class
method.`),Wne.forEach(t),qnt=i(yi),Vk=n(yi,"P",{});var JJe=s(Vk);jnt=r(JJe,"This class cannot be instantiated directly using "),SAe=n(JJe,"CODE",{});var BKt=s(SAe);Dnt=r(BKt,"__init__()"),BKt.forEach(t),Gnt=r(JJe," (throws an error)."),JJe.forEach(t),Ont=i(yi),aa=n(yi,"DIV",{class:!0});var BL=s(aa);T(Xk.$$.fragment,BL),Vnt=i(BL),RAe=n(BL,"P",{});var IKt=s(RAe);Xnt=r(IKt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),IKt.forEach(t),znt=i(BL),Sf=n(BL,"P",{});var Qne=s(Sf);Wnt=r(Qne,`Note:
Loading a model from its configuration file does `),PAe=n(Qne,"STRONG",{});var NKt=s(PAe);Qnt=r(NKt,"not"),NKt.forEach(t),Hnt=r(Qne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Nte=n(Qne,"A",{href:!0});var qKt=s(Nte);Unt=r(qKt,"from_pretrained()"),qKt.forEach(t),Jnt=r(Qne," to load the model weights."),Qne.forEach(t),Ynt=i(BL),T(Zw.$$.fragment,BL),BL.forEach(t),Knt=i(yi),et=n(yi,"DIV",{class:!0});var xi=s(et);T(zk.$$.fragment,xi),Znt=i(xi),BAe=n(xi,"P",{});var jKt=s(BAe);est=r(jKt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),jKt.forEach(t),ost=i(xi),Bn=n(xi,"P",{});var IL=s(Bn);rst=r(IL,"The model class to instantiate is selected based on the "),IAe=n(IL,"CODE",{});var DKt=s(IAe);tst=r(DKt,"model_type"),DKt.forEach(t),ast=r(IL,` property of the config object (either
passed as an argument or loaded from `),NAe=n(IL,"CODE",{});var GKt=s(NAe);nst=r(GKt,"pretrained_model_name_or_path"),GKt.forEach(t),sst=r(IL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),qAe=n(IL,"CODE",{});var OKt=s(qAe);lst=r(OKt,"pretrained_model_name_or_path"),OKt.forEach(t),ist=r(IL,":"),IL.forEach(t),dst=i(xi),ze=n(xi,"UL",{});var wo=s(ze);e6=n(wo,"LI",{});var LWe=s(e6);jAe=n(LWe,"STRONG",{});var VKt=s(jAe);cst=r(VKt,"albert"),VKt.forEach(t),fst=r(LWe," \u2014 "),qte=n(LWe,"A",{href:!0});var XKt=s(qte);mst=r(XKt,"FlaxAlbertForMultipleChoice"),XKt.forEach(t),gst=r(LWe," (ALBERT model)"),LWe.forEach(t),hst=i(wo),o6=n(wo,"LI",{});var yWe=s(o6);DAe=n(yWe,"STRONG",{});var zKt=s(DAe);pst=r(zKt,"bert"),zKt.forEach(t),_st=r(yWe," \u2014 "),jte=n(yWe,"A",{href:!0});var WKt=s(jte);ust=r(WKt,"FlaxBertForMultipleChoice"),WKt.forEach(t),bst=r(yWe," (BERT model)"),yWe.forEach(t),vst=i(wo),r6=n(wo,"LI",{});var xWe=s(r6);GAe=n(xWe,"STRONG",{});var QKt=s(GAe);Fst=r(QKt,"big_bird"),QKt.forEach(t),Tst=r(xWe," \u2014 "),Dte=n(xWe,"A",{href:!0});var HKt=s(Dte);Mst=r(HKt,"FlaxBigBirdForMultipleChoice"),HKt.forEach(t),Est=r(xWe," (BigBird model)"),xWe.forEach(t),Cst=i(wo),t6=n(wo,"LI",{});var $We=s(t6);OAe=n($We,"STRONG",{});var UKt=s(OAe);wst=r(UKt,"distilbert"),UKt.forEach(t),Ast=r($We," \u2014 "),Gte=n($We,"A",{href:!0});var JKt=s(Gte);Lst=r(JKt,"FlaxDistilBertForMultipleChoice"),JKt.forEach(t),yst=r($We," (DistilBERT model)"),$We.forEach(t),xst=i(wo),a6=n(wo,"LI",{});var kWe=s(a6);VAe=n(kWe,"STRONG",{});var YKt=s(VAe);$st=r(YKt,"electra"),YKt.forEach(t),kst=r(kWe," \u2014 "),Ote=n(kWe,"A",{href:!0});var KKt=s(Ote);Sst=r(KKt,"FlaxElectraForMultipleChoice"),KKt.forEach(t),Rst=r(kWe," (ELECTRA model)"),kWe.forEach(t),Pst=i(wo),n6=n(wo,"LI",{});var SWe=s(n6);XAe=n(SWe,"STRONG",{});var ZKt=s(XAe);Bst=r(ZKt,"roberta"),ZKt.forEach(t),Ist=r(SWe," \u2014 "),Vte=n(SWe,"A",{href:!0});var eZt=s(Vte);Nst=r(eZt,"FlaxRobertaForMultipleChoice"),eZt.forEach(t),qst=r(SWe," (RoBERTa model)"),SWe.forEach(t),jst=i(wo),s6=n(wo,"LI",{});var RWe=s(s6);zAe=n(RWe,"STRONG",{});var oZt=s(zAe);Dst=r(oZt,"roformer"),oZt.forEach(t),Gst=r(RWe," \u2014 "),Xte=n(RWe,"A",{href:!0});var rZt=s(Xte);Ost=r(rZt,"FlaxRoFormerForMultipleChoice"),rZt.forEach(t),Vst=r(RWe," (RoFormer model)"),RWe.forEach(t),Xst=i(wo),l6=n(wo,"LI",{});var PWe=s(l6);WAe=n(PWe,"STRONG",{});var tZt=s(WAe);zst=r(tZt,"xlm-roberta"),tZt.forEach(t),Wst=r(PWe," \u2014 "),zte=n(PWe,"A",{href:!0});var aZt=s(zte);Qst=r(aZt,"FlaxXLMRobertaForMultipleChoice"),aZt.forEach(t),Hst=r(PWe," (XLM-RoBERTa model)"),PWe.forEach(t),wo.forEach(t),Ust=i(xi),T(i6.$$.fragment,xi),xi.forEach(t),yi.forEach(t),DHe=i(f),Rf=n(f,"H2",{class:!0});var YJe=s(Rf);d6=n(YJe,"A",{id:!0,class:!0,href:!0});var nZt=s(d6);QAe=n(nZt,"SPAN",{});var sZt=s(QAe);T(Wk.$$.fragment,sZt),sZt.forEach(t),nZt.forEach(t),Jst=i(YJe),HAe=n(YJe,"SPAN",{});var lZt=s(HAe);Yst=r(lZt,"FlaxAutoModelForNextSentencePrediction"),lZt.forEach(t),YJe.forEach(t),GHe=i(f),Lr=n(f,"DIV",{class:!0});var $i=s(Lr);T(Qk.$$.fragment,$i),Kst=i($i),Pf=n($i,"P",{});var Hne=s(Pf);Zst=r(Hne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Wte=n(Hne,"A",{href:!0});var iZt=s(Wte);elt=r(iZt,"from_pretrained()"),iZt.forEach(t),olt=r(Hne," class method or the "),Qte=n(Hne,"A",{href:!0});var dZt=s(Qte);rlt=r(dZt,"from_config()"),dZt.forEach(t),tlt=r(Hne,` class
method.`),Hne.forEach(t),alt=i($i),Hk=n($i,"P",{});var KJe=s(Hk);nlt=r(KJe,"This class cannot be instantiated directly using "),UAe=n(KJe,"CODE",{});var cZt=s(UAe);slt=r(cZt,"__init__()"),cZt.forEach(t),llt=r(KJe," (throws an error)."),KJe.forEach(t),ilt=i($i),na=n($i,"DIV",{class:!0});var NL=s(na);T(Uk.$$.fragment,NL),dlt=i(NL),JAe=n(NL,"P",{});var fZt=s(JAe);clt=r(fZt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),fZt.forEach(t),flt=i(NL),Bf=n(NL,"P",{});var Une=s(Bf);mlt=r(Une,`Note:
Loading a model from its configuration file does `),YAe=n(Une,"STRONG",{});var mZt=s(YAe);glt=r(mZt,"not"),mZt.forEach(t),hlt=r(Une,` load the model weights. It only affects the
model\u2019s configuration. Use `),Hte=n(Une,"A",{href:!0});var gZt=s(Hte);plt=r(gZt,"from_pretrained()"),gZt.forEach(t),_lt=r(Une," to load the model weights."),Une.forEach(t),ult=i(NL),T(c6.$$.fragment,NL),NL.forEach(t),blt=i($i),ot=n($i,"DIV",{class:!0});var ki=s(ot);T(Jk.$$.fragment,ki),vlt=i(ki),KAe=n(ki,"P",{});var hZt=s(KAe);Flt=r(hZt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),hZt.forEach(t),Tlt=i(ki),In=n(ki,"P",{});var qL=s(In);Mlt=r(qL,"The model class to instantiate is selected based on the "),ZAe=n(qL,"CODE",{});var pZt=s(ZAe);Elt=r(pZt,"model_type"),pZt.forEach(t),Clt=r(qL,` property of the config object (either
passed as an argument or loaded from `),eLe=n(qL,"CODE",{});var _Zt=s(eLe);wlt=r(_Zt,"pretrained_model_name_or_path"),_Zt.forEach(t),Alt=r(qL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oLe=n(qL,"CODE",{});var uZt=s(oLe);Llt=r(uZt,"pretrained_model_name_or_path"),uZt.forEach(t),ylt=r(qL,":"),qL.forEach(t),xlt=i(ki),rLe=n(ki,"UL",{});var bZt=s(rLe);f6=n(bZt,"LI",{});var BWe=s(f6);tLe=n(BWe,"STRONG",{});var vZt=s(tLe);$lt=r(vZt,"bert"),vZt.forEach(t),klt=r(BWe," \u2014 "),Ute=n(BWe,"A",{href:!0});var FZt=s(Ute);Slt=r(FZt,"FlaxBertForNextSentencePrediction"),FZt.forEach(t),Rlt=r(BWe," (BERT model)"),BWe.forEach(t),bZt.forEach(t),Plt=i(ki),T(m6.$$.fragment,ki),ki.forEach(t),$i.forEach(t),OHe=i(f),If=n(f,"H2",{class:!0});var ZJe=s(If);g6=n(ZJe,"A",{id:!0,class:!0,href:!0});var TZt=s(g6);aLe=n(TZt,"SPAN",{});var MZt=s(aLe);T(Yk.$$.fragment,MZt),MZt.forEach(t),TZt.forEach(t),Blt=i(ZJe),nLe=n(ZJe,"SPAN",{});var EZt=s(nLe);Ilt=r(EZt,"FlaxAutoModelForImageClassification"),EZt.forEach(t),ZJe.forEach(t),VHe=i(f),yr=n(f,"DIV",{class:!0});var Si=s(yr);T(Kk.$$.fragment,Si),Nlt=i(Si),Nf=n(Si,"P",{});var Jne=s(Nf);qlt=r(Jne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Jte=n(Jne,"A",{href:!0});var CZt=s(Jte);jlt=r(CZt,"from_pretrained()"),CZt.forEach(t),Dlt=r(Jne," class method or the "),Yte=n(Jne,"A",{href:!0});var wZt=s(Yte);Glt=r(wZt,"from_config()"),wZt.forEach(t),Olt=r(Jne,` class
method.`),Jne.forEach(t),Vlt=i(Si),Zk=n(Si,"P",{});var eYe=s(Zk);Xlt=r(eYe,"This class cannot be instantiated directly using "),sLe=n(eYe,"CODE",{});var AZt=s(sLe);zlt=r(AZt,"__init__()"),AZt.forEach(t),Wlt=r(eYe," (throws an error)."),eYe.forEach(t),Qlt=i(Si),sa=n(Si,"DIV",{class:!0});var jL=s(sa);T(eS.$$.fragment,jL),Hlt=i(jL),lLe=n(jL,"P",{});var LZt=s(lLe);Ult=r(LZt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),LZt.forEach(t),Jlt=i(jL),qf=n(jL,"P",{});var Yne=s(qf);Ylt=r(Yne,`Note:
Loading a model from its configuration file does `),iLe=n(Yne,"STRONG",{});var yZt=s(iLe);Klt=r(yZt,"not"),yZt.forEach(t),Zlt=r(Yne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Kte=n(Yne,"A",{href:!0});var xZt=s(Kte);eit=r(xZt,"from_pretrained()"),xZt.forEach(t),oit=r(Yne," to load the model weights."),Yne.forEach(t),rit=i(jL),T(h6.$$.fragment,jL),jL.forEach(t),tit=i(Si),rt=n(Si,"DIV",{class:!0});var Ri=s(rt);T(oS.$$.fragment,Ri),ait=i(Ri),dLe=n(Ri,"P",{});var $Zt=s(dLe);nit=r($Zt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),$Zt.forEach(t),sit=i(Ri),Nn=n(Ri,"P",{});var DL=s(Nn);lit=r(DL,"The model class to instantiate is selected based on the "),cLe=n(DL,"CODE",{});var kZt=s(cLe);iit=r(kZt,"model_type"),kZt.forEach(t),dit=r(DL,` property of the config object (either
passed as an argument or loaded from `),fLe=n(DL,"CODE",{});var SZt=s(fLe);cit=r(SZt,"pretrained_model_name_or_path"),SZt.forEach(t),fit=r(DL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mLe=n(DL,"CODE",{});var RZt=s(mLe);mit=r(RZt,"pretrained_model_name_or_path"),RZt.forEach(t),git=r(DL,":"),DL.forEach(t),hit=i(Ri),rS=n(Ri,"UL",{});var oYe=s(rS);p6=n(oYe,"LI",{});var IWe=s(p6);gLe=n(IWe,"STRONG",{});var PZt=s(gLe);pit=r(PZt,"beit"),PZt.forEach(t),_it=r(IWe," \u2014 "),Zte=n(IWe,"A",{href:!0});var BZt=s(Zte);uit=r(BZt,"FlaxBeitForImageClassification"),BZt.forEach(t),bit=r(IWe," (BEiT model)"),IWe.forEach(t),vit=i(oYe),_6=n(oYe,"LI",{});var NWe=s(_6);hLe=n(NWe,"STRONG",{});var IZt=s(hLe);Fit=r(IZt,"vit"),IZt.forEach(t),Tit=r(NWe," \u2014 "),eae=n(NWe,"A",{href:!0});var NZt=s(eae);Mit=r(NZt,"FlaxViTForImageClassification"),NZt.forEach(t),Eit=r(NWe," (ViT model)"),NWe.forEach(t),oYe.forEach(t),Cit=i(Ri),T(u6.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),XHe=i(f),jf=n(f,"H2",{class:!0});var rYe=s(jf);b6=n(rYe,"A",{id:!0,class:!0,href:!0});var qZt=s(b6);pLe=n(qZt,"SPAN",{});var jZt=s(pLe);T(tS.$$.fragment,jZt),jZt.forEach(t),qZt.forEach(t),wit=i(rYe),_Le=n(rYe,"SPAN",{});var DZt=s(_Le);Ait=r(DZt,"FlaxAutoModelForVision2Seq"),DZt.forEach(t),rYe.forEach(t),zHe=i(f),xr=n(f,"DIV",{class:!0});var Pi=s(xr);T(aS.$$.fragment,Pi),Lit=i(Pi),Df=n(Pi,"P",{});var Kne=s(Df);yit=r(Kne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),oae=n(Kne,"A",{href:!0});var GZt=s(oae);xit=r(GZt,"from_pretrained()"),GZt.forEach(t),$it=r(Kne," class method or the "),rae=n(Kne,"A",{href:!0});var OZt=s(rae);kit=r(OZt,"from_config()"),OZt.forEach(t),Sit=r(Kne,` class
method.`),Kne.forEach(t),Rit=i(Pi),nS=n(Pi,"P",{});var tYe=s(nS);Pit=r(tYe,"This class cannot be instantiated directly using "),uLe=n(tYe,"CODE",{});var VZt=s(uLe);Bit=r(VZt,"__init__()"),VZt.forEach(t),Iit=r(tYe," (throws an error)."),tYe.forEach(t),Nit=i(Pi),la=n(Pi,"DIV",{class:!0});var GL=s(la);T(sS.$$.fragment,GL),qit=i(GL),bLe=n(GL,"P",{});var XZt=s(bLe);jit=r(XZt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),XZt.forEach(t),Dit=i(GL),Gf=n(GL,"P",{});var Zne=s(Gf);Git=r(Zne,`Note:
Loading a model from its configuration file does `),vLe=n(Zne,"STRONG",{});var zZt=s(vLe);Oit=r(zZt,"not"),zZt.forEach(t),Vit=r(Zne,` load the model weights. It only affects the
model\u2019s configuration. Use `),tae=n(Zne,"A",{href:!0});var WZt=s(tae);Xit=r(WZt,"from_pretrained()"),WZt.forEach(t),zit=r(Zne," to load the model weights."),Zne.forEach(t),Wit=i(GL),T(v6.$$.fragment,GL),GL.forEach(t),Qit=i(Pi),tt=n(Pi,"DIV",{class:!0});var Bi=s(tt);T(lS.$$.fragment,Bi),Hit=i(Bi),FLe=n(Bi,"P",{});var QZt=s(FLe);Uit=r(QZt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),QZt.forEach(t),Jit=i(Bi),qn=n(Bi,"P",{});var OL=s(qn);Yit=r(OL,"The model class to instantiate is selected based on the "),TLe=n(OL,"CODE",{});var HZt=s(TLe);Kit=r(HZt,"model_type"),HZt.forEach(t),Zit=r(OL,` property of the config object (either
passed as an argument or loaded from `),MLe=n(OL,"CODE",{});var UZt=s(MLe);edt=r(UZt,"pretrained_model_name_or_path"),UZt.forEach(t),odt=r(OL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ELe=n(OL,"CODE",{});var JZt=s(ELe);rdt=r(JZt,"pretrained_model_name_or_path"),JZt.forEach(t),tdt=r(OL,":"),OL.forEach(t),adt=i(Bi),CLe=n(Bi,"UL",{});var YZt=s(CLe);F6=n(YZt,"LI",{});var qWe=s(F6);wLe=n(qWe,"STRONG",{});var KZt=s(wLe);ndt=r(KZt,"vision-encoder-decoder"),KZt.forEach(t),sdt=r(qWe," \u2014 "),aae=n(qWe,"A",{href:!0});var ZZt=s(aae);ldt=r(ZZt,"FlaxVisionEncoderDecoderModel"),ZZt.forEach(t),idt=r(qWe," (Vision Encoder decoder model)"),qWe.forEach(t),YZt.forEach(t),ddt=i(Bi),T(T6.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(lra)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Dn,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.AutoConfig"),c(On,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.AutoModel"),c(Vn,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.AutoTokenizer"),c(Oi,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertModel"),c(Uf,"id","extending-the-auto-classes"),c(Uf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uf,"href","#extending-the-auto-classes"),c(Vi,"class","relative group"),c(Yf,"id","transformers.AutoConfig"),c(Yf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yf,"href","#transformers.AutoConfig"),c(Xi,"class","relative group"),c(NR,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(qR,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertConfig"),c(jR,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartConfig"),c(DR,"href","/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitConfig"),c(GR,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertConfig"),c(OR,"href","/docs/transformers/pr_17779/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(VR,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdConfig"),c(XR,"href","/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(zR,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(WR,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(QR,"href","/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomConfig"),c(HR,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertConfig"),c(UR,"href","/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineConfig"),c(JR,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPConfig"),c(YR,"href","/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenConfig"),c(KR,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertConfig"),c(ZR,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextConfig"),c(eP,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLConfig"),c(oP,"href","/docs/transformers/pr_17779/en/model_doc/cvt#transformers.CvtConfig"),c(rP,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(tP,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(aP,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(nP,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaConfig"),c(sP,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(lP,"href","/docs/transformers/pr_17779/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(iP,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTConfig"),c(dP,"href","/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrConfig"),c(cP,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertConfig"),c(fP,"href","/docs/transformers/pr_17779/en/model_doc/dpr#transformers.DPRConfig"),c(mP,"href","/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTConfig"),c(gP,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraConfig"),c(hP,"href","/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(pP,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertConfig"),c(_P,"href","/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaConfig"),c(uP,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetConfig"),c(bP,"href","/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTConfig"),c(vP,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelConfig"),c(FP,"href","/docs/transformers/pr_17779/en/model_doc/glpn#transformers.GLPNConfig"),c(TP,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Config"),c(MP,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(EP,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(CP,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJConfig"),c(wP,"href","/docs/transformers/pr_17779/en/model_doc/groupvit#transformers.GroupViTConfig"),c(AP,"href","/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertConfig"),c(LP,"href","/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertConfig"),c(yP,"href","/docs/transformers/pr_17779/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(xP,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c($P,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(kP,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(SP,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDConfig"),c(RP,"href","/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitConfig"),c(PP,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerConfig"),c(BP,"href","/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5Config"),c(IP,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeConfig"),c(NP,"href","/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertConfig"),c(qP,"href","/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100Config"),c(jP,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianConfig"),c(DP,"href","/docs/transformers/pr_17779/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(GP,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartConfig"),c(OP,"href","/docs/transformers/pr_17779/en/model_doc/mctct#transformers.MCTCTConfig"),c(VP,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(XP,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(zP,"href","/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(WP,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetConfig"),c(QP,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Config"),c(HP,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpConfig"),c(UP,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaConfig"),c(JP,"href","/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(YP,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(KP,"href","/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTConfig"),c(ZP,"href","/docs/transformers/pr_17779/en/model_doc/owlvit#transformers.OwlViTConfig"),c(eB,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusConfig"),c(oB,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverConfig"),c(rB,"href","/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartConfig"),c(tB,"href","/docs/transformers/pr_17779/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(aB,"href","/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(nB,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(sB,"href","/docs/transformers/pr_17779/en/model_doc/rag#transformers.RagConfig"),c(lB,"href","/docs/transformers/pr_17779/en/model_doc/realm#transformers.RealmConfig"),c(iB,"href","/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerConfig"),c(dB,"href","/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetConfig"),c(cB,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertConfig"),c(fB,"href","/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetConfig"),c(mB,"href","/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertConfig"),c(gB,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaConfig"),c(hB,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerConfig"),c(pB,"href","/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerConfig"),c(_B,"href","/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWConfig"),c(uB,"href","/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDConfig"),c(bB,"href","/docs/transformers/pr_17779/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(vB,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(FB,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(TB,"href","/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterConfig"),c(MB,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(EB,"href","/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinConfig"),c(CB,"href","/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2Config"),c(wB,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Config"),c(AB,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasConfig"),c(LB,"href","/docs/transformers/pr_17779/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(yB,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(xB,"href","/docs/transformers/pr_17779/en/model_doc/trocr#transformers.TrOCRConfig"),c($B,"href","/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(kB,"href","/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(SB,"href","/docs/transformers/pr_17779/en/model_doc/van#transformers.VanConfig"),c(RB,"href","/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEConfig"),c(PB,"href","/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltConfig"),c(BB,"href","/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(IB,"href","/docs/transformers/pr_17779/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(NB,"href","/docs/transformers/pr_17779/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(qB,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTConfig"),c(jB,"href","/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(DB,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(GB,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(OB,"href","/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMConfig"),c(VB,"href","/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMConfig"),c(XB,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMConfig"),c(zB,"href","/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(WB,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(QB,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(HB,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetConfig"),c(UB,"href","/docs/transformers/pr_17779/en/model_doc/yolos#transformers.YolosConfig"),c(JB,"href","/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoConfig"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gh,"id","transformers.AutoTokenizer"),c(gh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gh,"href","#transformers.AutoTokenizer"),c(Wi,"class","relative group"),c(YB,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(KB,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertTokenizer"),c(ZB,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(eI,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartTokenizer"),c(oI,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartTokenizerFast"),c(rI,"href","/docs/transformers/pr_17779/en/model_doc/barthez#transformers.BarthezTokenizer"),c(tI,"href","/docs/transformers/pr_17779/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(aI,"href","/docs/transformers/pr_17779/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(nI,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizer"),c(sI,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizerFast"),c(lI,"href","/docs/transformers/pr_17779/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(iI,"href","/docs/transformers/pr_17779/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(dI,"href","/docs/transformers/pr_17779/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(cI,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(fI,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(mI,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(gI,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(hI,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(pI,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(_I,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(uI,"href","/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(bI,"href","/docs/transformers/pr_17779/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(vI,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertTokenizer"),c(FI,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(TI,"href","/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineTokenizer"),c(MI,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPTokenizer"),c(EI,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(CI,"href","/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(wI,"href","/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(AI,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(LI,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(yI,"href","/docs/transformers/pr_17779/en/model_doc/cpm#transformers.CpmTokenizer"),c(xI,"href","/docs/transformers/pr_17779/en/model_doc/cpm#transformers.CpmTokenizerFast"),c($I,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(kI,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaTokenizer"),c(SI,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(RI,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaTokenizer"),c(PI,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(BI,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(II,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(NI,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(qI,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(jI,"href","/docs/transformers/pr_17779/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(DI,"href","/docs/transformers/pr_17779/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(GI,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraTokenizer"),c(OI,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(VI,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(XI,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetTokenizer"),c(zI,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(WI,"href","/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(QI,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelTokenizer"),c(HI,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(UI,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(JI,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(YI,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(KI,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(ZI,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(eN,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(oN,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(rN,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPTokenizer"),c(tN,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(aN,"href","/docs/transformers/pr_17779/en/model_doc/herbert#transformers.HerbertTokenizer"),c(nN,"href","/docs/transformers/pr_17779/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(sN,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(lN,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaTokenizer"),c(iN,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(dN,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(cN,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(fN,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(mN,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(gN,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(hN,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(pN,"href","/docs/transformers/pr_17779/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(_N,"href","/docs/transformers/pr_17779/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(uN,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDTokenizer"),c(bN,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDTokenizerFast"),c(vN,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerTokenizer"),c(FN,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(TN,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.T5Tokenizer"),c(MN,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.T5TokenizerFast"),c(EN,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeTokenizer"),c(CN,"href","/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(wN,"href","/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(AN,"href","/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(LN,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianTokenizer"),c(yN,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartTokenizer"),c(xN,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartTokenizerFast"),c($N,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(kN,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(SN,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizer"),c(RN,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizerFast"),c(PN,"href","/docs/transformers/pr_17779/en/model_doc/mluke#transformers.MLukeTokenizer"),c(BN,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(IN,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(NN,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(qN,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(jN,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.T5Tokenizer"),c(DN,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.T5TokenizerFast"),c(GN,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpTokenizer"),c(ON,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(VN,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizer"),c(XN,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizerFast"),c(zN,"href","/docs/transformers/pr_17779/en/model_doc/nllb#transformers.NllbTokenizer"),c(WN,"href","/docs/transformers/pr_17779/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(QN,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertTokenizer"),c(HN,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(UN,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(JN,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(YN,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(KN,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPTokenizer"),c(ZN,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(eq,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(oq,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(rq,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(tq,"href","/docs/transformers/pr_17779/en/model_doc/phobert#transformers.PhobertTokenizer"),c(aq,"href","/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartTokenizer"),c(nq,"href","/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(sq,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizer"),c(lq,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizerFast"),c(iq,"href","/docs/transformers/pr_17779/en/model_doc/rag#transformers.RagTokenizer"),c(dq,"href","/docs/transformers/pr_17779/en/model_doc/realm#transformers.RealmTokenizer"),c(cq,"href","/docs/transformers/pr_17779/en/model_doc/realm#transformers.RealmTokenizerFast"),c(fq,"href","/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerTokenizer"),c(mq,"href","/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(gq,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertTokenizer"),c(hq,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(pq,"href","/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(_q,"href","/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(uq,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaTokenizer"),c(bq,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(vq,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(Fq,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(Tq,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(Mq,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(Eq,"href","/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterTokenizer"),c(Cq,"href","/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(wq,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(Aq,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(Lq,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.T5Tokenizer"),c(yq,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.T5TokenizerFast"),c(xq,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasTokenizer"),c($q,"href","/docs/transformers/pr_17779/en/model_doc/tapex#transformers.TapexTokenizer"),c(kq,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(Sq,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizer"),c(Rq,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizerFast"),c(Pq,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizer"),c(Bq,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertTokenizerFast"),c(Iq,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(Nq,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(qq,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(jq,"href","/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMTokenizer"),c(Dq,"href","/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(Gq,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMTokenizer"),c(Oq,"href","/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(Vq,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(Xq,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(zq,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaTokenizer"),c(Wq,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Qq,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(Hq,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(Uq,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertTokenizer"),c(Jq,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uh,"id","transformers.AutoFeatureExtractor"),c(Uh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uh,"href","#transformers.AutoFeatureExtractor"),c(Qi,"class","relative group"),c(Yq,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(Kq,"href","/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(Zq,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(ej,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(oj,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(rj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(tj,"href","/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(aj,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(nj,"href","/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(sj,"href","/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(lj,"href","/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(ij,"href","/docs/transformers/pr_17779/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(dj,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(cj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(fj,"href","/docs/transformers/pr_17779/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(mj,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(gj,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(hj,"href","/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(pj,"href","/docs/transformers/pr_17779/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(_j,"href","/docs/transformers/pr_17779/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(uj,"href","/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(bj,"href","/docs/transformers/pr_17779/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(vj,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(Fj,"href","/docs/transformers/pr_17779/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(Tj,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(Mj,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(Ej,"href","/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(Cj,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(wj,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Aj,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Lj,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yj,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(xj,"href","/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c($j,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kj,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Sj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(Rj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(Pj,"href","/docs/transformers/pr_17779/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ip,"id","transformers.AutoProcessor"),c(Ip,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ip,"href","#transformers.AutoProcessor"),c(Hi,"class","relative group"),c(Bj,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(Ij,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPProcessor"),c(Nj,"href","/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaProcessor"),c(qj,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPProcessor"),c(jj,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(Dj,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(Gj,"href","/docs/transformers/pr_17779/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(Oj,"href","/docs/transformers/pr_17779/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(Vj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Xj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zj,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(Wj,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(Qj,"href","/docs/transformers/pr_17779/en/model_doc/trocr#transformers.TrOCRProcessor"),c(Hj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Uj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Jj,"href","/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltProcessor"),c(Yj,"href","/docs/transformers/pr_17779/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(Kj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Zj,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eD,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n_,"id","transformers.AutoModel"),c(n_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n_,"href","#transformers.AutoModel"),c(Ji,"class","relative group"),c(oD,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rD,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tD,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aD,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertModel"),c(nD,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartModel"),c(sD,"href","/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitModel"),c(lD,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertModel"),c(iD,"href","/docs/transformers/pr_17779/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(dD,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdModel"),c(cD,"href","/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(fD,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(mD,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(gD,"href","/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomModel"),c(hD,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertModel"),c(pD,"href","/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineModel"),c(_D,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.CLIPModel"),c(uD,"href","/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenModel"),c(bD,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertModel"),c(vD,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextModel"),c(FD,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLModel"),c(TD,"href","/docs/transformers/pr_17779/en/model_doc/cvt#transformers.CvtModel"),c(MD,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(ED,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(CD,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(wD,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaModel"),c(AD,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(LD,"href","/docs/transformers/pr_17779/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(yD,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTModel"),c(xD,"href","/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrModel"),c($D,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertModel"),c(kD,"href","/docs/transformers/pr_17779/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(SD,"href","/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTModel"),c(RD,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraModel"),c(PD,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertModel"),c(BD,"href","/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaModel"),c(ID,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetModel"),c(ND,"href","/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTModel"),c(qD,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelModel"),c(jD,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelBaseModel"),c(DD,"href","/docs/transformers/pr_17779/en/model_doc/glpn#transformers.GLPNModel"),c(GD,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2Model"),c(OD,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(VD,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(XD,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJModel"),c(zD,"href","/docs/transformers/pr_17779/en/model_doc/groupvit#transformers.GroupViTModel"),c(WD,"href","/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertModel"),c(QD,"href","/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertModel"),c(HD,"href","/docs/transformers/pr_17779/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(UD,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(JD,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(YD,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(KD,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDModel"),c(ZD,"href","/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitModel"),c(eG,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerModel"),c(oG,"href","/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5Model"),c(rG,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeModel"),c(tG,"href","/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertModel"),c(aG,"href","/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100Model"),c(nG,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianModel"),c(sG,"href","/docs/transformers/pr_17779/en/model_doc/maskformer#transformers.MaskFormerModel"),c(lG,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartModel"),c(iG,"href","/docs/transformers/pr_17779/en/model_doc/mctct#transformers.MCTCTModel"),c(dG,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(cG,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertModel"),c(fG,"href","/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTModel"),c(mG,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetModel"),c(gG,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5Model"),c(hG,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpModel"),c(pG,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaModel"),c(_G,"href","/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100Model"),c(uG,"href","/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerModel"),c(bG,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(vG,"href","/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTModel"),c(FG,"href","/docs/transformers/pr_17779/en/model_doc/owlvit#transformers.OwlViTModel"),c(TG,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusModel"),c(MG,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverModel"),c(EG,"href","/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartModel"),c(CG,"href","/docs/transformers/pr_17779/en/model_doc/poolformer#transformers.PoolFormerModel"),c(wG,"href","/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(AG,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertModel"),c(LG,"href","/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerModel"),c(yG,"href","/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetModel"),c(xG,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertModel"),c($G,"href","/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetModel"),c(kG,"href","/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertModel"),c(SG,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaModel"),c(RG,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerModel"),c(PG,"href","/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerModel"),c(BG,"href","/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWModel"),c(IG,"href","/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDModel"),c(NG,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(qG,"href","/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterModel"),c(jG,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(DG,"href","/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinModel"),c(GG,"href","/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2Model"),c(OG,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5Model"),c(VG,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasModel"),c(XG,"href","/docs/transformers/pr_17779/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(zG,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(WG,"href","/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechModel"),c(QG,"href","/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(HG,"href","/docs/transformers/pr_17779/en/model_doc/van#transformers.VanModel"),c(UG,"href","/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEModel"),c(JG,"href","/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltModel"),c(YG,"href","/docs/transformers/pr_17779/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(KG,"href","/docs/transformers/pr_17779/en/model_doc/visual_bert#transformers.VisualBertModel"),c(ZG,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTModel"),c(eO,"href","/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(oO,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(rO,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(tO,"href","/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMModel"),c(aO,"href","/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMModel"),c(nO,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMModel"),c(sO,"href","/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(lO,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(iO,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(dO,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetModel"),c(cO,"href","/docs/transformers/pr_17779/en/model_doc/yolos#transformers.YolosModel"),c(fO,"href","/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p7,"id","transformers.AutoModelForPreTraining"),c(p7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p7,"href","#transformers.AutoModelForPreTraining"),c(Zi,"class","relative group"),c(mO,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gO,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hO,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pO,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForPreTraining"),c(_O,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(uO,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForPreTraining"),c(bO,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(vO,"href","/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomForCausalLM"),c(FO,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(TO,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(MO,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(EO,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(CO,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(wO,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(AO,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForPreTraining"),c(LO,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(yO,"href","/docs/transformers/pr_17779/en/model_doc/flava#transformers.FlavaForPreTraining"),c(xO,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForPreTraining"),c($O,"href","/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(kO,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(SO,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(RO,"href","/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(PO,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(BO,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(IO,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForMaskedLM"),c(NO,"href","/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(qO,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(jO,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(DO,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(GO,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(OO,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(VO,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(XO,"href","/docs/transformers/pr_17779/en/model_doc/retribert#transformers.RetriBertModel"),c(zO,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(WO,"href","/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(QO,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(HO,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(UO,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(JO,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(YO,"href","/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(KO,"href","/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(ZO,"href","/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(eV,"href","/docs/transformers/pr_17779/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(oV,"href","/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(rV,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(tV,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(aV,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(nV,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(sV,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(lV,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m1,"id","transformers.AutoModelForCausalLM"),c(m1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m1,"href","#transformers.AutoModelForCausalLM"),c(rd,"class","relative group"),c(iV,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dV,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cV,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fV,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForCausalLM"),c(mV,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertLMHeadModel"),c(gV,"href","/docs/transformers/pr_17779/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(hV,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(pV,"href","/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(_V,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(uV,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(bV,"href","/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomForCausalLM"),c(vV,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(FV,"href","/docs/transformers/pr_17779/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(TV,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(MV,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(EV,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForCausalLM"),c(CV,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wV,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(AV,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(LV,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(yV,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianForCausalLM"),c(xV,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForCausalLM"),c($V,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(kV,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForCausalLM"),c(SV,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(RV,"href","/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTForCausalLM"),c(PV,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(BV,"href","/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(IV,"href","/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(NV,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(qV,"href","/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(jV,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(DV,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(GV,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(OV,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(VV,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(XV,"href","/docs/transformers/pr_17779/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(zV,"href","/docs/transformers/pr_17779/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(WV,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(QV,"href","/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(HV,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(UV,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(JV,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(r2,"id","transformers.AutoModelForMaskedLM"),c(r2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(r2,"href","#transformers.AutoModelForMaskedLM"),c(nd,"class","relative group"),c(YV,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KV,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZV,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eX,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(oX,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(rX,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForMaskedLM"),c(tX,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(aX,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(nX,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(sX,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(lX,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(iX,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(dX,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(cX,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(fX,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(mX,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(gX,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(hX,"href","/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(pX,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(_X,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(uX,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForMaskedLM"),c(bX,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(vX,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(FX,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(TX,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(MX,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(EX,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(CX,"href","/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(wX,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(AX,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(LX,"href","/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(yX,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(xX,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c($X,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(kX,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(SX,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(RX,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(PX,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(BX,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(IX,"href","/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(X2,"id","transformers.AutoModelForSeq2SeqLM"),c(X2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(X2,"href","#transformers.AutoModelForSeq2SeqLM"),c(id,"class","relative group"),c(NX,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qX,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jX,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DX,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(GX,"href","/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(OX,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(VX,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(XX,"href","/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(zX,"href","/docs/transformers/pr_17779/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(WX,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(QX,"href","/docs/transformers/pr_17779/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(HX,"href","/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(UX,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.MarianMTModel"),c(JX,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(YX,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(KX,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(ZX,"href","/docs/transformers/pr_17779/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(ez,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(oz,"href","/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(rz,"href","/docs/transformers/pr_17779/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(tz,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(az,"href","/docs/transformers/pr_17779/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gb,"id","transformers.AutoModelForSequenceClassification"),c(gb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gb,"href","#transformers.AutoModelForSequenceClassification"),c(fd,"class","relative group"),c(nz,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sz,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lz,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iz,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(dz,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForSequenceClassification"),c(cz,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForSequenceClassification"),c(fz,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(mz,"href","/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(gz,"href","/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(hz,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(pz,"href","/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(_z,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(uz,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(bz,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(vz,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(Fz,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(Tz,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(Mz,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(Ez,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(Cz,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(wz,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(Az,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(Lz,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(yz,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(xz,"href","/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c($z,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(kz,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(Sz,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(Rz,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDForSequenceClassification"),c(Pz,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(Bz,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(Iz,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(Nz,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(qz,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(jz,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(Dz,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(Gz,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(Oz,"href","/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(Vz,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(Xz,"href","/docs/transformers/pr_17779/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(zz,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(Wz,"href","/docs/transformers/pr_17779/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(Qz,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(Hz,"href","/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(Uz,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(Jz,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(Yz,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(Kz,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(Zz,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(eW,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(oW,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(rW,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(tW,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(aW,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(nW,"href","/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pv,"id","transformers.AutoModelForMultipleChoice"),c(pv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pv,"href","#transformers.AutoModelForMultipleChoice"),c(hd,"class","relative group"),c(sW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dW,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(cW,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForMultipleChoice"),c(fW,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(mW,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(gW,"href","/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(hW,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(pW,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(_W,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(uW,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(bW,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(vW,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(FW,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(TW,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(MW,"href","/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(EW,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(CW,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(wW,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(AW,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(LW,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(yW,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(xW,"href","/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c($W,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(kW,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(SW,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(RW,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(PW,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(BW,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(IW,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(NW,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(qW,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(jW,"href","/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jv,"id","transformers.AutoModelForNextSentencePrediction"),c(Jv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Jv,"href","#transformers.AutoModelForNextSentencePrediction"),c(ud,"class","relative group"),c(DW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(GW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(OW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(VW,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(XW,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(zW,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(WW,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(QW,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(HW,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sF,"id","transformers.AutoModelForTokenClassification"),c(sF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sF,"href","#transformers.AutoModelForTokenClassification"),c(Fd,"class","relative group"),c(UW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(JW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(YW,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KW,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(ZW,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForTokenClassification"),c(eQ,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(oQ,"href","/docs/transformers/pr_17779/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(rQ,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(tQ,"href","/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineForTokenClassification"),c(aQ,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(nQ,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(sQ,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(lQ,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(iQ,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(dQ,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(cQ,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(fQ,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(mQ,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(gQ,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(hQ,"href","/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(pQ,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(_Q,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(uQ,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(bQ,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(vQ,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForTokenClassification"),c(FQ,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(TQ,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(MQ,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(EQ,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(CQ,"href","/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(wQ,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(AQ,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(LQ,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(yQ,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(xQ,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c($Q,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(kQ,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(SQ,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(RQ,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(PQ,"href","/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QF,"id","transformers.AutoModelForQuestionAnswering"),c(QF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QF,"href","#transformers.AutoModelForQuestionAnswering"),c(Ed,"class","relative group"),c(BQ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IQ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NQ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qQ,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(jQ,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(DQ,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(GQ,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(OQ,"href","/docs/transformers/pr_17779/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(VQ,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(XQ,"href","/docs/transformers/pr_17779/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(zQ,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(WQ,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(QQ,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(HQ,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(UQ,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(JQ,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(YQ,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(KQ,"href","/docs/transformers/pr_17779/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(ZQ,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(eH,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(oH,"href","/docs/transformers/pr_17779/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(rH,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(tH,"href","/docs/transformers/pr_17779/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(aH,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(nH,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(sH,"href","/docs/transformers/pr_17779/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(lH,"href","/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(iH,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(dH,"href","/docs/transformers/pr_17779/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(cH,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(fH,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(mH,"href","/docs/transformers/pr_17779/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(gH,"href","/docs/transformers/pr_17779/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(hH,"href","/docs/transformers/pr_17779/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(pH,"href","/docs/transformers/pr_17779/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(_H,"href","/docs/transformers/pr_17779/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(uH,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(bH,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(vH,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(FH,"href","/docs/transformers/pr_17779/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(TH,"href","/docs/transformers/pr_17779/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(MH,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(EH,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(CH,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(wH,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(AH,"href","/docs/transformers/pr_17779/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DT,"id","transformers.AutoModelForTableQuestionAnswering"),c(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DT,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Ad,"class","relative group"),c(LH,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yH,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(xH,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($H,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zT,"id","transformers.AutoModelForImageClassification"),c(zT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zT,"href","#transformers.AutoModelForImageClassification"),c(xd,"class","relative group"),c(kH,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(SH,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(RH,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(PH,"href","/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitForImageClassification"),c(BH,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(IH,"href","/docs/transformers/pr_17779/en/model_doc/cvt#transformers.CvtForImageClassification"),c(NH,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(qH,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTForImageClassification"),c(jH,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(DH,"href","/docs/transformers/pr_17779/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(GH,"href","/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitForImageClassification"),c(OH,"href","/docs/transformers/pr_17779/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(VH,"href","/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(XH,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(zH,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(WH,"href","/docs/transformers/pr_17779/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(QH,"href","/docs/transformers/pr_17779/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(HH,"href","/docs/transformers/pr_17779/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(UH,"href","/docs/transformers/pr_17779/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(JH,"href","/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(YH,"href","/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinForImageClassification"),c(KH,"href","/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(ZH,"href","/docs/transformers/pr_17779/en/model_doc/van#transformers.VanForImageClassification"),c(eU,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTForImageClassification"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d9,"id","transformers.AutoModelForVideoClassification"),c(d9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d9,"href","#transformers.AutoModelForVideoClassification"),c(Sd,"class","relative group"),c(oU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aU,"href","/docs/transformers/pr_17779/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h9,"id","transformers.AutoModelForVision2Seq"),c(h9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h9,"href","#transformers.AutoModelForVision2Seq"),c(Bd,"class","relative group"),c(nU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iU,"href","/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v9,"id","transformers.AutoModelForVisualQuestionAnswering"),c(v9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v9,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(qd,"class","relative group"),c(dU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mU,"href","/docs/transformers/pr_17779/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C9,"id","transformers.AutoModelForAudioClassification"),c(C9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C9,"href","#transformers.AutoModelForAudioClassification"),c(Gd,"class","relative group"),c(gU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_U,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(uU,"href","/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(bU,"href","/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(vU,"href","/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(FU,"href","/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(TU,"href","/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(MU,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(EU,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(CU,"href","/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N9,"id","transformers.AutoModelForAudioFrameClassification"),c(N9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N9,"href","#transformers.AutoModelForAudioFrameClassification"),c(Xd,"class","relative group"),c(wU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yU,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(xU,"href","/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c($U,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(kU,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(SU,"href","/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W9,"id","transformers.AutoModelForCTC"),c(W9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W9,"href","#transformers.AutoModelForCTC"),c(Qd,"class","relative group"),c(RU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IU,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(NU,"href","/docs/transformers/pr_17779/en/model_doc/hubert#transformers.HubertForCTC"),c(qU,"href","/docs/transformers/pr_17779/en/model_doc/mctct#transformers.MCTCTForCTC"),c(jU,"href","/docs/transformers/pr_17779/en/model_doc/sew#transformers.SEWForCTC"),c(DU,"href","/docs/transformers/pr_17779/en/model_doc/sew-d#transformers.SEWDForCTC"),c(GU,"href","/docs/transformers/pr_17779/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(OU,"href","/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(VU,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(XU,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(zU,"href","/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMForCTC"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sM,"id","transformers.AutoModelForSpeechSeq2Seq"),c(sM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sM,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Jd,"class","relative group"),c(WU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UU,"href","/docs/transformers/pr_17779/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(JU,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mM,"id","transformers.AutoModelForAudioXVector"),c(mM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mM,"href","#transformers.AutoModelForAudioXVector"),c(Zd,"class","relative group"),c(YU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZU,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eJ,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(oJ,"href","/docs/transformers/pr_17779/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(rJ,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(tJ,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(aJ,"href","/docs/transformers/pr_17779/en/model_doc/wavlm#transformers.WavLMForXVector"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TM,"id","transformers.AutoModelForMaskedImageModeling"),c(TM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TM,"href","#transformers.AutoModelForMaskedImageModeling"),c(rc,"class","relative group"),c(nJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iJ,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(dJ,"href","/docs/transformers/pr_17779/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(cJ,"href","/docs/transformers/pr_17779/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(fJ,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xM,"id","transformers.AutoModelForObjectDetection"),c(xM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xM,"href","#transformers.AutoModelForObjectDetection"),c(nc,"class","relative group"),c(mJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pJ,"href","/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrForObjectDetection"),c(_J,"href","/docs/transformers/pr_17779/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BM,"id","transformers.AutoModelForImageSegmentation"),c(BM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BM,"href","#transformers.AutoModelForImageSegmentation"),c(ic,"class","relative group"),c(uJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FJ,"href","/docs/transformers/pr_17779/en/model_doc/detr#transformers.DetrForSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DM,"id","transformers.AutoModelForSemanticSegmentation"),c(DM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DM,"href","#transformers.AutoModelForSemanticSegmentation"),c(fc,"class","relative group"),c(TJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(MJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(EJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(CJ,"href","/docs/transformers/pr_17779/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(wJ,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(AJ,"href","/docs/transformers/pr_17779/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(LJ,"href","/docs/transformers/pr_17779/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(yJ,"href","/docs/transformers/pr_17779/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UM,"id","transformers.AutoModelForInstanceSegmentation"),c(UM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UM,"href","#transformers.AutoModelForInstanceSegmentation"),c(hc,"class","relative group"),c(xJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($J,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SJ,"href","/docs/transformers/pr_17779/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eE,"id","transformers.TFAutoModel"),c(eE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eE,"href","#transformers.TFAutoModel"),c(uc,"class","relative group"),c(RJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(PJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(BJ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(IJ,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertModel"),c(NJ,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.TFBartModel"),c(qJ,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertModel"),c(jJ,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(DJ,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(GJ,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertModel"),c(OJ,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.TFCLIPModel"),c(VJ,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertModel"),c(XJ,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.TFConvNextModel"),c(zJ,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.TFCTRLModel"),c(WJ,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(QJ,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaModel"),c(HJ,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(UJ,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.TFDeiTModel"),c(JJ,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(YJ,"href","/docs/transformers/pr_17779/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(KJ,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraModel"),c(ZJ,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(eY,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelModel"),c(oY,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(rY,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.TFGPT2Model"),c(tY,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.TFGPTJModel"),c(aY,"href","/docs/transformers/pr_17779/en/model_doc/hubert#transformers.TFHubertModel"),c(nY,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(sY,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.TFLEDModel"),c(lY,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerModel"),c(iY,"href","/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.TFLxmertModel"),c(dY,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.TFMarianModel"),c(cY,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.TFMBartModel"),c(fY,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(mY,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetModel"),c(gY,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.TFMT5Model"),c(hY,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(pY,"href","/docs/transformers/pr_17779/en/model_doc/opt#transformers.TFOPTModel"),c(_Y,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.TFPegasusModel"),c(uY,"href","/docs/transformers/pr_17779/en/model_doc/regnet#transformers.TFRegNetModel"),c(bY,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertModel"),c(vY,"href","/docs/transformers/pr_17779/en/model_doc/resnet#transformers.TFResNetModel"),c(FY,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaModel"),c(TY,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerModel"),c(MY,"href","/docs/transformers/pr_17779/en/model_doc/segformer#transformers.TFSegformerModel"),c(EY,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(CY,"href","/docs/transformers/pr_17779/en/model_doc/swin#transformers.TFSwinModel"),c(wY,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.TFT5Model"),c(AY,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasModel"),c(LY,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(yY,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.TFViTModel"),c(xY,"href","/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c($Y,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(kY,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMModel"),c(SY,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(RY,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZE,"id","transformers.TFAutoModelForPreTraining"),c(ZE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZE,"href","#transformers.TFAutoModelForPreTraining"),c(Fc,"class","relative group"),c(PY,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(qY,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(jY,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForPreTraining"),c(DY,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(GY,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(OY,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(VY,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(XY,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(zY,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(WY,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(QY,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(HY,"href","/docs/transformers/pr_17779/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(UY,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(JY,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(YY,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(KY,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(ZY,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(eK,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(oK,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(rK,"href","/docs/transformers/pr_17779/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(tK,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(aK,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(nK,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w4,"id","transformers.TFAutoModelForCausalLM"),c(w4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w4,"href","#transformers.TFAutoModelForCausalLM"),c(Ec,"class","relative group"),c(sK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dK,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(cK,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(fK,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(mK,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(gK,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(hK,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(pK,"href","/docs/transformers/pr_17779/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(_K,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(uK,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(bK,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(vK,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(FK,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(TK,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G4,"id","transformers.TFAutoModelForImageClassification"),c(G4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G4,"href","#transformers.TFAutoModelForImageClassification"),c(Ac,"class","relative group"),c(MK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wK,"href","/docs/transformers/pr_17779/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(AK,"href","/docs/transformers/pr_17779/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(LK,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(yK,"href","/docs/transformers/pr_17779/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c(xK,"href","/docs/transformers/pr_17779/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c($K,"href","/docs/transformers/pr_17779/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(kK,"href","/docs/transformers/pr_17779/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(SK,"href","/docs/transformers/pr_17779/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(RK,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y4,"id","transformers.TFAutoModelForMaskedLM"),c(Y4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y4,"href","#transformers.TFAutoModelForMaskedLM"),c(xc,"class","relative group"),c(PK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(qK,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(jK,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(DK,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(GK,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(OK,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(VK,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(XK,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(zK,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(WK,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(QK,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(HK,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(UK,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(JK,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(YK,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(KK,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(ZK,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(eZ,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(oZ,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(rZ,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FC,"id","transformers.TFAutoModelForSeq2SeqLM"),c(FC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FC,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(Sc,"class","relative group"),c(tZ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aZ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nZ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sZ,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(lZ,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(iZ,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(dZ,"href","/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(cZ,"href","/docs/transformers/pr_17779/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(fZ,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.TFMarianMTModel"),c(mZ,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(gZ,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(hZ,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(pZ,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RC,"id","transformers.TFAutoModelForSequenceClassification"),c(RC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RC,"href","#transformers.TFAutoModelForSequenceClassification"),c(Bc,"class","relative group"),c(_Z,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uZ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bZ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vZ,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(FZ,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(TZ,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(MZ,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(EZ,"href","/docs/transformers/pr_17779/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(CZ,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(wZ,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(AZ,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(LZ,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(yZ,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(xZ,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c($Z,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(kZ,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(SZ,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(RZ,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(PZ,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(BZ,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(IZ,"href","/docs/transformers/pr_17779/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(NZ,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(qZ,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(jZ,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(DZ,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(GZ,"href","/docs/transformers/pr_17779/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(OZ,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(VZ,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(XZ,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i3,"id","transformers.TFAutoModelForMultipleChoice"),c(i3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i3,"href","#transformers.TFAutoModelForMultipleChoice"),c(qc,"class","relative group"),c(zZ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(WZ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(QZ,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HZ,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(UZ,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(JZ,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(YZ,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(KZ,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(ZZ,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(eee,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(oee,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(ree,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(tee,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(aee,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(nee,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(see,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(lee,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(iee,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(dee,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(cee,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y3,"id","transformers.TFAutoModelForNextSentencePrediction"),c(y3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y3,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Gc,"class","relative group"),c(fee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hee,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(pee,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R3,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(R3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R3,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Xc,"class","relative group"),c(_ee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(bee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vee,"href","/docs/transformers/pr_17779/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N3,"id","transformers.TFAutoModelForTokenClassification"),c(N3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N3,"href","#transformers.TFAutoModelForTokenClassification"),c(Qc,"class","relative group"),c(Fee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Mee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eee,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(Cee,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(wee,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(Aee,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(Lee,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(yee,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(xee,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c($ee,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(kee,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(See,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(Ree,"href","/docs/transformers/pr_17779/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(Pee,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(Bee,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(Iee,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(Nee,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(qee,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(jee,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Dee,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(Gee,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(Oee,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s5,"id","transformers.TFAutoModelForQuestionAnswering"),c(s5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s5,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Jc,"class","relative group"),c(Vee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zee,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wee,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Qee,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(Hee,"href","/docs/transformers/pr_17779/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Uee,"href","/docs/transformers/pr_17779/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(Jee,"href","/docs/transformers/pr_17779/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(Yee,"href","/docs/transformers/pr_17779/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(Kee,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(Zee,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(eoe,"href","/docs/transformers/pr_17779/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(ooe,"href","/docs/transformers/pr_17779/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(roe,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(toe,"href","/docs/transformers/pr_17779/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(aoe,"href","/docs/transformers/pr_17779/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(noe,"href","/docs/transformers/pr_17779/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(soe,"href","/docs/transformers/pr_17779/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(loe,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(ioe,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(doe,"href","/docs/transformers/pr_17779/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(coe,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(foe,"href","/docs/transformers/pr_17779/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x5,"id","transformers.TFAutoModelForVision2Seq"),c(x5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x5,"href","#transformers.TFAutoModelForVision2Seq"),c(Zc,"class","relative group"),c(moe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(goe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hoe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(poe,"href","/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R5,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(R5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R5,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(rf,"class","relative group"),c(_oe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(uoe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(boe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(voe,"href","/docs/transformers/pr_17779/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N5,"id","transformers.FlaxAutoModel"),c(N5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N5,"href","#transformers.FlaxAutoModel"),c(nf,"class","relative group"),c(Foe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Toe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Moe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Eoe,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertModel"),c(Coe,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartModel"),c(woe,"href","/docs/transformers/pr_17779/en/model_doc/beit#transformers.FlaxBeitModel"),c(Aoe,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertModel"),c(Loe,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(yoe,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(xoe,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c($oe,"href","/docs/transformers/pr_17779/en/model_doc/clip#transformers.FlaxCLIPModel"),c(koe,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(Soe,"href","/docs/transformers/pr_17779/en/model_doc/dpt#transformers.FlaxDPTModel"),c(Roe,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraModel"),c(Poe,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(Boe,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(Ioe,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(Noe,"href","/docs/transformers/pr_17779/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(qoe,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.FlaxMarianModel"),c(joe,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartModel"),c(Doe,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.FlaxMT5Model"),c(Goe,"href","/docs/transformers/pr_17779/en/model_doc/opt#transformers.FlaxOPTModel"),c(Ooe,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(Voe,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(Xoe,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(zoe,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.FlaxT5Model"),c(Woe,"href","/docs/transformers/pr_17779/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Qoe,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.FlaxViTModel"),c(Hoe,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Uoe,"href","/docs/transformers/pr_17779/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(Joe,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h0,"id","transformers.FlaxAutoModelForCausalLM"),c(h0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h0,"href","#transformers.FlaxAutoModelForCausalLM"),c(df,"class","relative group"),c(Yoe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Koe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Zoe,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ere,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(ore,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(rre,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(tre,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(are,"href","/docs/transformers/pr_17779/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(nre,"href","/docs/transformers/pr_17779/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(sre,"href","/docs/transformers/pr_17779/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(lre,"href","/docs/transformers/pr_17779/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(ire,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(dre,"href","/docs/transformers/pr_17779/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L0,"id","transformers.FlaxAutoModelForPreTraining"),c(L0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L0,"href","#transformers.FlaxAutoModelForPreTraining"),c(mf,"class","relative group"),c(cre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gre,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(hre,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(pre,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(_re,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(ure,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(bre,"href","/docs/transformers/pr_17779/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(vre,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Fre,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Tre,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Mre,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Ere,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Cre,"href","/docs/transformers/pr_17779/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(wre,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(V0,"id","transformers.FlaxAutoModelForMaskedLM"),c(V0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(V0,"href","#transformers.FlaxAutoModelForMaskedLM"),c(pf,"class","relative group"),c(Are,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xre,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c($re,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(kre,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(Sre,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Rre,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Pre,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Bre,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ire,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Nre,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(qre,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rw,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(rw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rw,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(bf,"class","relative group"),c(jre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Gre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ore,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Vre,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Xre,"href","/docs/transformers/pr_17779/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(zre,"href","/docs/transformers/pr_17779/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Wre,"href","/docs/transformers/pr_17779/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Qre,"href","/docs/transformers/pr_17779/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Hre,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Ure,"href","/docs/transformers/pr_17779/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Jre,"href","/docs/transformers/pr_17779/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(Yre,"href","/docs/transformers/pr_17779/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pw,"id","transformers.FlaxAutoModelForSequenceClassification"),c(pw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pw,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Tf,"class","relative group"),c(Kre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zre,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ete,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ote,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(rte,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(tte,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(ate,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(nte,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(ste,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(lte,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(ite,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(dte,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(cte,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yw,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(yw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yw,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Cf,"class","relative group"),c(fte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hte,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(pte,"href","/docs/transformers/pr_17779/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(_te,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(ute,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(bte,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(vte,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Fte,"href","/docs/transformers/pr_17779/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Tte,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Mte,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Ete,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Gw,"id","transformers.FlaxAutoModelForTokenClassification"),c(Gw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Gw,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Lf,"class","relative group"),c(Cte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Ate,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lte,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(yte,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(xte,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c($te,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(kte,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Ste,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Rte,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Pte,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Kw,"id","transformers.FlaxAutoModelForMultipleChoice"),c(Kw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Kw,"href","#transformers.FlaxAutoModelForMultipleChoice"),c($f,"class","relative group"),c(Bte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ite,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Nte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qte,"href","/docs/transformers/pr_17779/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(jte,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Dte,"href","/docs/transformers/pr_17779/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Gte,"href","/docs/transformers/pr_17779/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Ote,"href","/docs/transformers/pr_17779/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(Vte,"href","/docs/transformers/pr_17779/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Xte,"href","/docs/transformers/pr_17779/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(zte,"href","/docs/transformers/pr_17779/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d6,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(d6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d6,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Rf,"class","relative group"),c(Wte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Hte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ute,"href","/docs/transformers/pr_17779/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g6,"id","transformers.FlaxAutoModelForImageClassification"),c(g6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g6,"href","#transformers.FlaxAutoModelForImageClassification"),c(If,"class","relative group"),c(Jte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Kte,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zte,"href","/docs/transformers/pr_17779/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(eae,"href","/docs/transformers/pr_17779/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(b6,"id","transformers.FlaxAutoModelForVision2Seq"),c(b6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(b6,"href","#transformers.FlaxAutoModelForVision2Seq"),c(jf,"class","relative group"),c(oae,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rae,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tae,"href","/docs/transformers/pr_17779/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aae,"href","/docs/transformers/pr_17779/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Ao),e(Ao,Ii),b(f,zf,u),b(f,dt,u),e(dt,Ni),e(dt,qi),e(qi,VL),e(dt,Wf),b(f,Oe,u),b(f,Qe,u),e(Qe,ji),e(Qe,Dn),e(Dn,XL),e(Qe,Gn),e(Qe,On),e(On,zL),e(Qe,Di),e(Qe,Vn),e(Vn,WL),e(Qe,Gi),b(f,Qf,u),M(Ia,f,u),b(f,He,u),b(f,Ae,u),e(Ae,kR),e(Ae,Oi),e(Oi,SR),e(Ae,RR),b(f,Lo,u),b(f,Na,u),e(Na,PR),e(Na,Hf),e(Hf,BR),e(Na,aYe),b(f,jWe,u),b(f,Vi,u),e(Vi,Uf),e(Uf,ese),M(QL,ese,null),e(Vi,nYe),e(Vi,ose),e(ose,sYe),b(f,DWe,u),b(f,Xn,u),e(Xn,lYe),e(Xn,rse),e(rse,iYe),e(Xn,dYe),e(Xn,tse),e(tse,cYe),e(Xn,fYe),b(f,GWe,u),M(HL,f,u),b(f,OWe,u),b(f,IR,u),e(IR,mYe),b(f,VWe,u),M(Jf,f,u),b(f,XWe,u),b(f,Xi,u),e(Xi,Yf),e(Yf,ase),M(UL,ase,null),e(Xi,gYe),e(Xi,nse),e(nse,hYe),b(f,zWe,u),b(f,yo,u),M(JL,yo,null),e(yo,pYe),e(yo,YL),e(YL,_Ye),e(YL,NR),e(NR,uYe),e(YL,bYe),e(yo,vYe),e(yo,KL),e(KL,FYe),e(KL,sse),e(sse,TYe),e(KL,MYe),e(yo,EYe),e(yo,$r),M(ZL,$r,null),e($r,CYe),e($r,lse),e(lse,wYe),e($r,AYe),e($r,zi),e(zi,LYe),e(zi,ise),e(ise,yYe),e(zi,xYe),e(zi,dse),e(dse,$Ye),e(zi,kYe),e($r,SYe),e($r,A),e(A,Kf),e(Kf,cse),e(cse,RYe),e(Kf,PYe),e(Kf,qR),e(qR,BYe),e(Kf,IYe),e(A,NYe),e(A,Zf),e(Zf,fse),e(fse,qYe),e(Zf,jYe),e(Zf,jR),e(jR,DYe),e(Zf,GYe),e(A,OYe),e(A,em),e(em,mse),e(mse,VYe),e(em,XYe),e(em,DR),e(DR,zYe),e(em,WYe),e(A,QYe),e(A,om),e(om,gse),e(gse,HYe),e(om,UYe),e(om,GR),e(GR,JYe),e(om,YYe),e(A,KYe),e(A,rm),e(rm,hse),e(hse,ZYe),e(rm,eKe),e(rm,OR),e(OR,oKe),e(rm,rKe),e(A,tKe),e(A,tm),e(tm,pse),e(pse,aKe),e(tm,nKe),e(tm,VR),e(VR,sKe),e(tm,lKe),e(A,iKe),e(A,am),e(am,_se),e(_se,dKe),e(am,cKe),e(am,XR),e(XR,fKe),e(am,mKe),e(A,gKe),e(A,nm),e(nm,use),e(use,hKe),e(nm,pKe),e(nm,zR),e(zR,_Ke),e(nm,uKe),e(A,bKe),e(A,sm),e(sm,bse),e(bse,vKe),e(sm,FKe),e(sm,WR),e(WR,TKe),e(sm,MKe),e(A,EKe),e(A,lm),e(lm,vse),e(vse,CKe),e(lm,wKe),e(lm,QR),e(QR,AKe),e(lm,LKe),e(A,yKe),e(A,im),e(im,Fse),e(Fse,xKe),e(im,$Ke),e(im,HR),e(HR,kKe),e(im,SKe),e(A,RKe),e(A,dm),e(dm,Tse),e(Tse,PKe),e(dm,BKe),e(dm,UR),e(UR,IKe),e(dm,NKe),e(A,qKe),e(A,cm),e(cm,Mse),e(Mse,jKe),e(cm,DKe),e(cm,JR),e(JR,GKe),e(cm,OKe),e(A,VKe),e(A,fm),e(fm,Ese),e(Ese,XKe),e(fm,zKe),e(fm,YR),e(YR,WKe),e(fm,QKe),e(A,HKe),e(A,mm),e(mm,Cse),e(Cse,UKe),e(mm,JKe),e(mm,KR),e(KR,YKe),e(mm,KKe),e(A,ZKe),e(A,gm),e(gm,wse),e(wse,eZe),e(gm,oZe),e(gm,ZR),e(ZR,rZe),e(gm,tZe),e(A,aZe),e(A,hm),e(hm,Ase),e(Ase,nZe),e(hm,sZe),e(hm,eP),e(eP,lZe),e(hm,iZe),e(A,dZe),e(A,pm),e(pm,Lse),e(Lse,cZe),e(pm,fZe),e(pm,oP),e(oP,mZe),e(pm,gZe),e(A,hZe),e(A,_m),e(_m,yse),e(yse,pZe),e(_m,_Ze),e(_m,rP),e(rP,uZe),e(_m,bZe),e(A,vZe),e(A,um),e(um,xse),e(xse,FZe),e(um,TZe),e(um,tP),e(tP,MZe),e(um,EZe),e(A,CZe),e(A,bm),e(bm,$se),e($se,wZe),e(bm,AZe),e(bm,aP),e(aP,LZe),e(bm,yZe),e(A,xZe),e(A,vm),e(vm,kse),e(kse,$Ze),e(vm,kZe),e(vm,nP),e(nP,SZe),e(vm,RZe),e(A,PZe),e(A,Fm),e(Fm,Sse),e(Sse,BZe),e(Fm,IZe),e(Fm,sP),e(sP,NZe),e(Fm,qZe),e(A,jZe),e(A,Tm),e(Tm,Rse),e(Rse,DZe),e(Tm,GZe),e(Tm,lP),e(lP,OZe),e(Tm,VZe),e(A,XZe),e(A,Mm),e(Mm,Pse),e(Pse,zZe),e(Mm,WZe),e(Mm,iP),e(iP,QZe),e(Mm,HZe),e(A,UZe),e(A,Em),e(Em,Bse),e(Bse,JZe),e(Em,YZe),e(Em,dP),e(dP,KZe),e(Em,ZZe),e(A,eeo),e(A,Cm),e(Cm,Ise),e(Ise,oeo),e(Cm,reo),e(Cm,cP),e(cP,teo),e(Cm,aeo),e(A,neo),e(A,wm),e(wm,Nse),e(Nse,seo),e(wm,leo),e(wm,fP),e(fP,ieo),e(wm,deo),e(A,ceo),e(A,Am),e(Am,qse),e(qse,feo),e(Am,meo),e(Am,mP),e(mP,geo),e(Am,heo),e(A,peo),e(A,Lm),e(Lm,jse),e(jse,_eo),e(Lm,ueo),e(Lm,gP),e(gP,beo),e(Lm,veo),e(A,Feo),e(A,ym),e(ym,Dse),e(Dse,Teo),e(ym,Meo),e(ym,hP),e(hP,Eeo),e(ym,Ceo),e(A,weo),e(A,xm),e(xm,Gse),e(Gse,Aeo),e(xm,Leo),e(xm,pP),e(pP,yeo),e(xm,xeo),e(A,$eo),e(A,$m),e($m,Ose),e(Ose,keo),e($m,Seo),e($m,_P),e(_P,Reo),e($m,Peo),e(A,Beo),e(A,km),e(km,Vse),e(Vse,Ieo),e(km,Neo),e(km,uP),e(uP,qeo),e(km,jeo),e(A,Deo),e(A,Sm),e(Sm,Xse),e(Xse,Geo),e(Sm,Oeo),e(Sm,bP),e(bP,Veo),e(Sm,Xeo),e(A,zeo),e(A,Rm),e(Rm,zse),e(zse,Weo),e(Rm,Qeo),e(Rm,vP),e(vP,Heo),e(Rm,Ueo),e(A,Jeo),e(A,Pm),e(Pm,Wse),e(Wse,Yeo),e(Pm,Keo),e(Pm,FP),e(FP,Zeo),e(Pm,eoo),e(A,ooo),e(A,Bm),e(Bm,Qse),e(Qse,roo),e(Bm,too),e(Bm,TP),e(TP,aoo),e(Bm,noo),e(A,soo),e(A,Im),e(Im,Hse),e(Hse,loo),e(Im,ioo),e(Im,MP),e(MP,doo),e(Im,coo),e(A,foo),e(A,Nm),e(Nm,Use),e(Use,moo),e(Nm,goo),e(Nm,EP),e(EP,hoo),e(Nm,poo),e(A,_oo),e(A,qm),e(qm,Jse),e(Jse,uoo),e(qm,boo),e(qm,CP),e(CP,voo),e(qm,Foo),e(A,Too),e(A,jm),e(jm,Yse),e(Yse,Moo),e(jm,Eoo),e(jm,wP),e(wP,Coo),e(jm,woo),e(A,Aoo),e(A,Dm),e(Dm,Kse),e(Kse,Loo),e(Dm,yoo),e(Dm,AP),e(AP,xoo),e(Dm,$oo),e(A,koo),e(A,Gm),e(Gm,Zse),e(Zse,Soo),e(Gm,Roo),e(Gm,LP),e(LP,Poo),e(Gm,Boo),e(A,Ioo),e(A,Om),e(Om,ele),e(ele,Noo),e(Om,qoo),e(Om,yP),e(yP,joo),e(Om,Doo),e(A,Goo),e(A,Vm),e(Vm,ole),e(ole,Ooo),e(Vm,Voo),e(Vm,xP),e(xP,Xoo),e(Vm,zoo),e(A,Woo),e(A,Xm),e(Xm,rle),e(rle,Qoo),e(Xm,Hoo),e(Xm,$P),e($P,Uoo),e(Xm,Joo),e(A,Yoo),e(A,zm),e(zm,tle),e(tle,Koo),e(zm,Zoo),e(zm,kP),e(kP,ero),e(zm,oro),e(A,rro),e(A,Wm),e(Wm,ale),e(ale,tro),e(Wm,aro),e(Wm,SP),e(SP,nro),e(Wm,sro),e(A,lro),e(A,Qm),e(Qm,nle),e(nle,iro),e(Qm,dro),e(Qm,RP),e(RP,cro),e(Qm,fro),e(A,mro),e(A,Hm),e(Hm,sle),e(sle,gro),e(Hm,hro),e(Hm,PP),e(PP,pro),e(Hm,_ro),e(A,uro),e(A,Um),e(Um,lle),e(lle,bro),e(Um,vro),e(Um,BP),e(BP,Fro),e(Um,Tro),e(A,Mro),e(A,Jm),e(Jm,ile),e(ile,Ero),e(Jm,Cro),e(Jm,IP),e(IP,wro),e(Jm,Aro),e(A,Lro),e(A,Ym),e(Ym,dle),e(dle,yro),e(Ym,xro),e(Ym,NP),e(NP,$ro),e(Ym,kro),e(A,Sro),e(A,Km),e(Km,cle),e(cle,Rro),e(Km,Pro),e(Km,qP),e(qP,Bro),e(Km,Iro),e(A,Nro),e(A,Zm),e(Zm,fle),e(fle,qro),e(Zm,jro),e(Zm,jP),e(jP,Dro),e(Zm,Gro),e(A,Oro),e(A,eg),e(eg,mle),e(mle,Vro),e(eg,Xro),e(eg,DP),e(DP,zro),e(eg,Wro),e(A,Qro),e(A,og),e(og,gle),e(gle,Hro),e(og,Uro),e(og,GP),e(GP,Jro),e(og,Yro),e(A,Kro),e(A,rg),e(rg,hle),e(hle,Zro),e(rg,eto),e(rg,OP),e(OP,oto),e(rg,rto),e(A,tto),e(A,tg),e(tg,ple),e(ple,ato),e(tg,nto),e(tg,VP),e(VP,sto),e(tg,lto),e(A,ito),e(A,ag),e(ag,_le),e(_le,dto),e(ag,cto),e(ag,XP),e(XP,fto),e(ag,mto),e(A,gto),e(A,ng),e(ng,ule),e(ule,hto),e(ng,pto),e(ng,zP),e(zP,_to),e(ng,uto),e(A,bto),e(A,sg),e(sg,ble),e(ble,vto),e(sg,Fto),e(sg,WP),e(WP,Tto),e(sg,Mto),e(A,Eto),e(A,lg),e(lg,vle),e(vle,Cto),e(lg,wto),e(lg,QP),e(QP,Ato),e(lg,Lto),e(A,yto),e(A,ig),e(ig,Fle),e(Fle,xto),e(ig,$to),e(ig,HP),e(HP,kto),e(ig,Sto),e(A,Rto),e(A,dg),e(dg,Tle),e(Tle,Pto),e(dg,Bto),e(dg,UP),e(UP,Ito),e(dg,Nto),e(A,qto),e(A,cg),e(cg,Mle),e(Mle,jto),e(cg,Dto),e(cg,JP),e(JP,Gto),e(cg,Oto),e(A,Vto),e(A,fg),e(fg,Ele),e(Ele,Xto),e(fg,zto),e(fg,YP),e(YP,Wto),e(fg,Qto),e(A,Hto),e(A,mg),e(mg,Cle),e(Cle,Uto),e(mg,Jto),e(mg,KP),e(KP,Yto),e(mg,Kto),e(A,Zto),e(A,gg),e(gg,wle),e(wle,eao),e(gg,oao),e(gg,ZP),e(ZP,rao),e(gg,tao),e(A,aao),e(A,hg),e(hg,Ale),e(Ale,nao),e(hg,sao),e(hg,eB),e(eB,lao),e(hg,iao),e(A,dao),e(A,pg),e(pg,Lle),e(Lle,cao),e(pg,fao),e(pg,oB),e(oB,mao),e(pg,gao),e(A,hao),e(A,_g),e(_g,yle),e(yle,pao),e(_g,_ao),e(_g,rB),e(rB,uao),e(_g,bao),e(A,vao),e(A,ug),e(ug,xle),e(xle,Fao),e(ug,Tao),e(ug,tB),e(tB,Mao),e(ug,Eao),e(A,Cao),e(A,bg),e(bg,$le),e($le,wao),e(bg,Aao),e(bg,aB),e(aB,Lao),e(bg,yao),e(A,xao),e(A,vg),e(vg,kle),e(kle,$ao),e(vg,kao),e(vg,nB),e(nB,Sao),e(vg,Rao),e(A,Pao),e(A,Fg),e(Fg,Sle),e(Sle,Bao),e(Fg,Iao),e(Fg,sB),e(sB,Nao),e(Fg,qao),e(A,jao),e(A,Tg),e(Tg,Rle),e(Rle,Dao),e(Tg,Gao),e(Tg,lB),e(lB,Oao),e(Tg,Vao),e(A,Xao),e(A,Mg),e(Mg,Ple),e(Ple,zao),e(Mg,Wao),e(Mg,iB),e(iB,Qao),e(Mg,Hao),e(A,Uao),e(A,Eg),e(Eg,Ble),e(Ble,Jao),e(Eg,Yao),e(Eg,dB),e(dB,Kao),e(Eg,Zao),e(A,eno),e(A,Cg),e(Cg,Ile),e(Ile,ono),e(Cg,rno),e(Cg,cB),e(cB,tno),e(Cg,ano),e(A,nno),e(A,wg),e(wg,Nle),e(Nle,sno),e(wg,lno),e(wg,fB),e(fB,ino),e(wg,dno),e(A,cno),e(A,Ag),e(Ag,qle),e(qle,fno),e(Ag,mno),e(Ag,mB),e(mB,gno),e(Ag,hno),e(A,pno),e(A,Lg),e(Lg,jle),e(jle,_no),e(Lg,uno),e(Lg,gB),e(gB,bno),e(Lg,vno),e(A,Fno),e(A,yg),e(yg,Dle),e(Dle,Tno),e(yg,Mno),e(yg,hB),e(hB,Eno),e(yg,Cno),e(A,wno),e(A,xg),e(xg,Gle),e(Gle,Ano),e(xg,Lno),e(xg,pB),e(pB,yno),e(xg,xno),e(A,$no),e(A,$g),e($g,Ole),e(Ole,kno),e($g,Sno),e($g,_B),e(_B,Rno),e($g,Pno),e(A,Bno),e(A,kg),e(kg,Vle),e(Vle,Ino),e(kg,Nno),e(kg,uB),e(uB,qno),e(kg,jno),e(A,Dno),e(A,Sg),e(Sg,Xle),e(Xle,Gno),e(Sg,Ono),e(Sg,bB),e(bB,Vno),e(Sg,Xno),e(A,zno),e(A,Rg),e(Rg,zle),e(zle,Wno),e(Rg,Qno),e(Rg,vB),e(vB,Hno),e(Rg,Uno),e(A,Jno),e(A,Pg),e(Pg,Wle),e(Wle,Yno),e(Pg,Kno),e(Pg,FB),e(FB,Zno),e(Pg,eso),e(A,oso),e(A,Bg),e(Bg,Qle),e(Qle,rso),e(Bg,tso),e(Bg,TB),e(TB,aso),e(Bg,nso),e(A,sso),e(A,Ig),e(Ig,Hle),e(Hle,lso),e(Ig,iso),e(Ig,MB),e(MB,dso),e(Ig,cso),e(A,fso),e(A,Ng),e(Ng,Ule),e(Ule,mso),e(Ng,gso),e(Ng,EB),e(EB,hso),e(Ng,pso),e(A,_so),e(A,qg),e(qg,Jle),e(Jle,uso),e(qg,bso),e(qg,CB),e(CB,vso),e(qg,Fso),e(A,Tso),e(A,jg),e(jg,Yle),e(Yle,Mso),e(jg,Eso),e(jg,wB),e(wB,Cso),e(jg,wso),e(A,Aso),e(A,Dg),e(Dg,Kle),e(Kle,Lso),e(Dg,yso),e(Dg,AB),e(AB,xso),e(Dg,$so),e(A,kso),e(A,Gg),e(Gg,Zle),e(Zle,Sso),e(Gg,Rso),e(Gg,LB),e(LB,Pso),e(Gg,Bso),e(A,Iso),e(A,Og),e(Og,eie),e(eie,Nso),e(Og,qso),e(Og,yB),e(yB,jso),e(Og,Dso),e(A,Gso),e(A,Vg),e(Vg,oie),e(oie,Oso),e(Vg,Vso),e(Vg,xB),e(xB,Xso),e(Vg,zso),e(A,Wso),e(A,Xg),e(Xg,rie),e(rie,Qso),e(Xg,Hso),e(Xg,$B),e($B,Uso),e(Xg,Jso),e(A,Yso),e(A,zg),e(zg,tie),e(tie,Kso),e(zg,Zso),e(zg,kB),e(kB,elo),e(zg,olo),e(A,rlo),e(A,Wg),e(Wg,aie),e(aie,tlo),e(Wg,alo),e(Wg,SB),e(SB,nlo),e(Wg,slo),e(A,llo),e(A,Qg),e(Qg,nie),e(nie,ilo),e(Qg,dlo),e(Qg,RB),e(RB,clo),e(Qg,flo),e(A,mlo),e(A,Hg),e(Hg,sie),e(sie,glo),e(Hg,hlo),e(Hg,PB),e(PB,plo),e(Hg,_lo),e(A,ulo),e(A,Ug),e(Ug,lie),e(lie,blo),e(Ug,vlo),e(Ug,BB),e(BB,Flo),e(Ug,Tlo),e(A,Mlo),e(A,Jg),e(Jg,iie),e(iie,Elo),e(Jg,Clo),e(Jg,IB),e(IB,wlo),e(Jg,Alo),e(A,Llo),e(A,Yg),e(Yg,die),e(die,ylo),e(Yg,xlo),e(Yg,NB),e(NB,$lo),e(Yg,klo),e(A,Slo),e(A,Kg),e(Kg,cie),e(cie,Rlo),e(Kg,Plo),e(Kg,qB),e(qB,Blo),e(Kg,Ilo),e(A,Nlo),e(A,Zg),e(Zg,fie),e(fie,qlo),e(Zg,jlo),e(Zg,jB),e(jB,Dlo),e(Zg,Glo),e(A,Olo),e(A,eh),e(eh,mie),e(mie,Vlo),e(eh,Xlo),e(eh,DB),e(DB,zlo),e(eh,Wlo),e(A,Qlo),e(A,oh),e(oh,gie),e(gie,Hlo),e(oh,Ulo),e(oh,GB),e(GB,Jlo),e(oh,Ylo),e(A,Klo),e(A,rh),e(rh,hie),e(hie,Zlo),e(rh,eio),e(rh,OB),e(OB,oio),e(rh,rio),e(A,tio),e(A,th),e(th,pie),e(pie,aio),e(th,nio),e(th,VB),e(VB,sio),e(th,lio),e(A,iio),e(A,ah),e(ah,_ie),e(_ie,dio),e(ah,cio),e(ah,XB),e(XB,fio),e(ah,mio),e(A,gio),e(A,nh),e(nh,uie),e(uie,hio),e(nh,pio),e(nh,zB),e(zB,_io),e(nh,uio),e(A,bio),e(A,sh),e(sh,bie),e(bie,vio),e(sh,Fio),e(sh,WB),e(WB,Tio),e(sh,Mio),e(A,Eio),e(A,lh),e(lh,vie),e(vie,Cio),e(lh,wio),e(lh,QB),e(QB,Aio),e(lh,Lio),e(A,yio),e(A,ih),e(ih,Fie),e(Fie,xio),e(ih,$io),e(ih,HB),e(HB,kio),e(ih,Sio),e(A,Rio),e(A,dh),e(dh,Tie),e(Tie,Pio),e(dh,Bio),e(dh,UB),e(UB,Iio),e(dh,Nio),e(A,qio),e(A,ch),e(ch,Mie),e(Mie,jio),e(ch,Dio),e(ch,JB),e(JB,Gio),e(ch,Oio),e($r,Vio),M(fh,$r,null),e(yo,Xio),e(yo,mh),M(ey,mh,null),e(mh,zio),e(mh,Eie),e(Eie,Wio),b(f,WWe,u),b(f,Wi,u),e(Wi,gh),e(gh,Cie),M(oy,Cie,null),e(Wi,Qio),e(Wi,wie),e(wie,Hio),b(f,QWe,u),b(f,xo,u),M(ry,xo,null),e(xo,Uio),e(xo,ty),e(ty,Jio),e(ty,YB),e(YB,Yio),e(ty,Kio),e(xo,Zio),e(xo,ay),e(ay,edo),e(ay,Aie),e(Aie,odo),e(ay,rdo),e(xo,tdo),e(xo,kr),M(ny,kr,null),e(kr,ado),e(kr,Lie),e(Lie,ndo),e(kr,sdo),e(kr,qa),e(qa,ldo),e(qa,yie),e(yie,ido),e(qa,ddo),e(qa,xie),e(xie,cdo),e(qa,fdo),e(qa,$ie),e($ie,mdo),e(qa,gdo),e(kr,hdo),e(kr,k),e(k,zn),e(zn,kie),e(kie,pdo),e(zn,_do),e(zn,KB),e(KB,udo),e(zn,bdo),e(zn,ZB),e(ZB,vdo),e(zn,Fdo),e(k,Tdo),e(k,Wn),e(Wn,Sie),e(Sie,Mdo),e(Wn,Edo),e(Wn,eI),e(eI,Cdo),e(Wn,wdo),e(Wn,oI),e(oI,Ado),e(Wn,Ldo),e(k,ydo),e(k,Qn),e(Qn,Rie),e(Rie,xdo),e(Qn,$do),e(Qn,rI),e(rI,kdo),e(Qn,Sdo),e(Qn,tI),e(tI,Rdo),e(Qn,Pdo),e(k,Bdo),e(k,hh),e(hh,Pie),e(Pie,Ido),e(hh,Ndo),e(hh,aI),e(aI,qdo),e(hh,jdo),e(k,Ddo),e(k,Hn),e(Hn,Bie),e(Bie,Gdo),e(Hn,Odo),e(Hn,nI),e(nI,Vdo),e(Hn,Xdo),e(Hn,sI),e(sI,zdo),e(Hn,Wdo),e(k,Qdo),e(k,ph),e(ph,Iie),e(Iie,Hdo),e(ph,Udo),e(ph,lI),e(lI,Jdo),e(ph,Ydo),e(k,Kdo),e(k,_h),e(_h,Nie),e(Nie,Zdo),e(_h,eco),e(_h,iI),e(iI,oco),e(_h,rco),e(k,tco),e(k,uh),e(uh,qie),e(qie,aco),e(uh,nco),e(uh,dI),e(dI,sco),e(uh,lco),e(k,ico),e(k,Un),e(Un,jie),e(jie,dco),e(Un,cco),e(Un,cI),e(cI,fco),e(Un,mco),e(Un,fI),e(fI,gco),e(Un,hco),e(k,pco),e(k,Jn),e(Jn,Die),e(Die,_co),e(Jn,uco),e(Jn,mI),e(mI,bco),e(Jn,vco),e(Jn,gI),e(gI,Fco),e(Jn,Tco),e(k,Mco),e(k,Yn),e(Yn,Gie),e(Gie,Eco),e(Yn,Cco),e(Yn,hI),e(hI,wco),e(Yn,Aco),e(Yn,pI),e(pI,Lco),e(Yn,yco),e(k,xco),e(k,bh),e(bh,Oie),e(Oie,$co),e(bh,kco),e(bh,_I),e(_I,Sco),e(bh,Rco),e(k,Pco),e(k,vh),e(vh,Vie),e(Vie,Bco),e(vh,Ico),e(vh,uI),e(uI,Nco),e(vh,qco),e(k,jco),e(k,Fh),e(Fh,Xie),e(Xie,Dco),e(Fh,Gco),e(Fh,bI),e(bI,Oco),e(Fh,Vco),e(k,Xco),e(k,Kn),e(Kn,zie),e(zie,zco),e(Kn,Wco),e(Kn,vI),e(vI,Qco),e(Kn,Hco),e(Kn,FI),e(FI,Uco),e(Kn,Jco),e(k,Yco),e(k,Th),e(Th,Wie),e(Wie,Kco),e(Th,Zco),e(Th,TI),e(TI,efo),e(Th,ofo),e(k,rfo),e(k,Zn),e(Zn,Qie),e(Qie,tfo),e(Zn,afo),e(Zn,MI),e(MI,nfo),e(Zn,sfo),e(Zn,EI),e(EI,lfo),e(Zn,ifo),e(k,dfo),e(k,es),e(es,Hie),e(Hie,cfo),e(es,ffo),e(es,CI),e(CI,mfo),e(es,gfo),e(es,wI),e(wI,hfo),e(es,pfo),e(k,_fo),e(k,os),e(os,Uie),e(Uie,ufo),e(os,bfo),e(os,AI),e(AI,vfo),e(os,Ffo),e(os,LI),e(LI,Tfo),e(os,Mfo),e(k,Efo),e(k,rs),e(rs,Jie),e(Jie,Cfo),e(rs,wfo),e(rs,yI),e(yI,Afo),e(rs,Lfo),e(rs,xI),e(xI,yfo),e(rs,xfo),e(k,$fo),e(k,Mh),e(Mh,Yie),e(Yie,kfo),e(Mh,Sfo),e(Mh,$I),e($I,Rfo),e(Mh,Pfo),e(k,Bfo),e(k,ts),e(ts,Kie),e(Kie,Ifo),e(ts,Nfo),e(ts,kI),e(kI,qfo),e(ts,jfo),e(ts,SI),e(SI,Dfo),e(ts,Gfo),e(k,Ofo),e(k,as),e(as,Zie),e(Zie,Vfo),e(as,Xfo),e(as,RI),e(RI,zfo),e(as,Wfo),e(as,PI),e(PI,Qfo),e(as,Hfo),e(k,Ufo),e(k,ns),e(ns,ede),e(ede,Jfo),e(ns,Yfo),e(ns,BI),e(BI,Kfo),e(ns,Zfo),e(ns,II),e(II,emo),e(ns,omo),e(k,rmo),e(k,ss),e(ss,ode),e(ode,tmo),e(ss,amo),e(ss,NI),e(NI,nmo),e(ss,smo),e(ss,qI),e(qI,lmo),e(ss,imo),e(k,dmo),e(k,ls),e(ls,rde),e(rde,cmo),e(ls,fmo),e(ls,jI),e(jI,mmo),e(ls,gmo),e(ls,DI),e(DI,hmo),e(ls,pmo),e(k,_mo),e(k,is),e(is,tde),e(tde,umo),e(is,bmo),e(is,GI),e(GI,vmo),e(is,Fmo),e(is,OI),e(OI,Tmo),e(is,Mmo),e(k,Emo),e(k,Eh),e(Eh,ade),e(ade,Cmo),e(Eh,wmo),e(Eh,VI),e(VI,Amo),e(Eh,Lmo),e(k,ymo),e(k,ds),e(ds,nde),e(nde,xmo),e(ds,$mo),e(ds,XI),e(XI,kmo),e(ds,Smo),e(ds,zI),e(zI,Rmo),e(ds,Pmo),e(k,Bmo),e(k,Ch),e(Ch,sde),e(sde,Imo),e(Ch,Nmo),e(Ch,WI),e(WI,qmo),e(Ch,jmo),e(k,Dmo),e(k,cs),e(cs,lde),e(lde,Gmo),e(cs,Omo),e(cs,QI),e(QI,Vmo),e(cs,Xmo),e(cs,HI),e(HI,zmo),e(cs,Wmo),e(k,Qmo),e(k,fs),e(fs,ide),e(ide,Hmo),e(fs,Umo),e(fs,UI),e(UI,Jmo),e(fs,Ymo),e(fs,JI),e(JI,Kmo),e(fs,Zmo),e(k,ego),e(k,ms),e(ms,dde),e(dde,ogo),e(ms,rgo),e(ms,YI),e(YI,tgo),e(ms,ago),e(ms,KI),e(KI,ngo),e(ms,sgo),e(k,lgo),e(k,wh),e(wh,cde),e(cde,igo),e(wh,dgo),e(wh,ZI),e(ZI,cgo),e(wh,fgo),e(k,mgo),e(k,gs),e(gs,fde),e(fde,ggo),e(gs,hgo),e(gs,eN),e(eN,pgo),e(gs,_go),e(gs,oN),e(oN,ugo),e(gs,bgo),e(k,vgo),e(k,hs),e(hs,mde),e(mde,Fgo),e(hs,Tgo),e(hs,rN),e(rN,Mgo),e(hs,Ego),e(hs,tN),e(tN,Cgo),e(hs,wgo),e(k,Ago),e(k,ps),e(ps,gde),e(gde,Lgo),e(ps,ygo),e(ps,aN),e(aN,xgo),e(ps,$go),e(ps,nN),e(nN,kgo),e(ps,Sgo),e(k,Rgo),e(k,Ah),e(Ah,hde),e(hde,Pgo),e(Ah,Bgo),e(Ah,sN),e(sN,Igo),e(Ah,Ngo),e(k,qgo),e(k,_s),e(_s,pde),e(pde,jgo),e(_s,Dgo),e(_s,lN),e(lN,Ggo),e(_s,Ogo),e(_s,iN),e(iN,Vgo),e(_s,Xgo),e(k,zgo),e(k,us),e(us,_de),e(_de,Wgo),e(us,Qgo),e(us,dN),e(dN,Hgo),e(us,Ugo),e(us,cN),e(cN,Jgo),e(us,Ygo),e(k,Kgo),e(k,bs),e(bs,ude),e(ude,Zgo),e(bs,eho),e(bs,fN),e(fN,oho),e(bs,rho),e(bs,mN),e(mN,tho),e(bs,aho),e(k,nho),e(k,vs),e(vs,bde),e(bde,sho),e(vs,lho),e(vs,gN),e(gN,iho),e(vs,dho),e(vs,hN),e(hN,cho),e(vs,fho),e(k,mho),e(k,Fs),e(Fs,vde),e(vde,gho),e(Fs,hho),e(Fs,pN),e(pN,pho),e(Fs,_ho),e(Fs,_N),e(_N,uho),e(Fs,bho),e(k,vho),e(k,Ts),e(Ts,Fde),e(Fde,Fho),e(Ts,Tho),e(Ts,uN),e(uN,Mho),e(Ts,Eho),e(Ts,bN),e(bN,Cho),e(Ts,who),e(k,Aho),e(k,Ms),e(Ms,Tde),e(Tde,Lho),e(Ms,yho),e(Ms,vN),e(vN,xho),e(Ms,$ho),e(Ms,FN),e(FN,kho),e(Ms,Sho),e(k,Rho),e(k,Es),e(Es,Mde),e(Mde,Pho),e(Es,Bho),e(Es,TN),e(TN,Iho),e(Es,Nho),e(Es,MN),e(MN,qho),e(Es,jho),e(k,Dho),e(k,Lh),e(Lh,Ede),e(Ede,Gho),e(Lh,Oho),e(Lh,EN),e(EN,Vho),e(Lh,Xho),e(k,zho),e(k,Cs),e(Cs,Cde),e(Cde,Who),e(Cs,Qho),e(Cs,CN),e(CN,Hho),e(Cs,Uho),e(Cs,wN),e(wN,Jho),e(Cs,Yho),e(k,Kho),e(k,yh),e(yh,wde),e(wde,Zho),e(yh,epo),e(yh,AN),e(AN,opo),e(yh,rpo),e(k,tpo),e(k,xh),e(xh,Ade),e(Ade,apo),e(xh,npo),e(xh,LN),e(LN,spo),e(xh,lpo),e(k,ipo),e(k,ws),e(ws,Lde),e(Lde,dpo),e(ws,cpo),e(ws,yN),e(yN,fpo),e(ws,mpo),e(ws,xN),e(xN,gpo),e(ws,hpo),e(k,ppo),e(k,As),e(As,yde),e(yde,_po),e(As,upo),e(As,$N),e($N,bpo),e(As,vpo),e(As,kN),e(kN,Fpo),e(As,Tpo),e(k,Mpo),e(k,Ls),e(Ls,xde),e(xde,Epo),e(Ls,Cpo),e(Ls,SN),e(SN,wpo),e(Ls,Apo),e(Ls,RN),e(RN,Lpo),e(Ls,ypo),e(k,xpo),e(k,$h),e($h,$de),e($de,$po),e($h,kpo),e($h,PN),e(PN,Spo),e($h,Rpo),e(k,Ppo),e(k,ys),e(ys,kde),e(kde,Bpo),e(ys,Ipo),e(ys,BN),e(BN,Npo),e(ys,qpo),e(ys,IN),e(IN,jpo),e(ys,Dpo),e(k,Gpo),e(k,xs),e(xs,Sde),e(Sde,Opo),e(xs,Vpo),e(xs,NN),e(NN,Xpo),e(xs,zpo),e(xs,qN),e(qN,Wpo),e(xs,Qpo),e(k,Hpo),e(k,$s),e($s,Rde),e(Rde,Upo),e($s,Jpo),e($s,jN),e(jN,Ypo),e($s,Kpo),e($s,DN),e(DN,Zpo),e($s,e_o),e(k,o_o),e(k,ks),e(ks,Pde),e(Pde,r_o),e(ks,t_o),e(ks,GN),e(GN,a_o),e(ks,n_o),e(ks,ON),e(ON,s_o),e(ks,l_o),e(k,i_o),e(k,Ss),e(Ss,Bde),e(Bde,d_o),e(Ss,c_o),e(Ss,VN),e(VN,f_o),e(Ss,m_o),e(Ss,XN),e(XN,g_o),e(Ss,h_o),e(k,p_o),e(k,Rs),e(Rs,Ide),e(Ide,__o),e(Rs,u_o),e(Rs,zN),e(zN,b_o),e(Rs,v_o),e(Rs,WN),e(WN,F_o),e(Rs,T_o),e(k,M_o),e(k,Ps),e(Ps,Nde),e(Nde,E_o),e(Ps,C_o),e(Ps,QN),e(QN,w_o),e(Ps,A_o),e(Ps,HN),e(HN,L_o),e(Ps,y_o),e(k,x_o),e(k,Bs),e(Bs,qde),e(qde,$_o),e(Bs,k_o),e(Bs,UN),e(UN,S_o),e(Bs,R_o),e(Bs,JN),e(JN,P_o),e(Bs,B_o),e(k,I_o),e(k,kh),e(kh,jde),e(jde,N_o),e(kh,q_o),e(kh,YN),e(YN,j_o),e(kh,D_o),e(k,G_o),e(k,Is),e(Is,Dde),e(Dde,O_o),e(Is,V_o),e(Is,KN),e(KN,X_o),e(Is,z_o),e(Is,ZN),e(ZN,W_o),e(Is,Q_o),e(k,H_o),e(k,Ns),e(Ns,Gde),e(Gde,U_o),e(Ns,J_o),e(Ns,eq),e(eq,Y_o),e(Ns,K_o),e(Ns,oq),e(oq,Z_o),e(Ns,euo),e(k,ouo),e(k,Sh),e(Sh,Ode),e(Ode,ruo),e(Sh,tuo),e(Sh,rq),e(rq,auo),e(Sh,nuo),e(k,suo),e(k,Rh),e(Rh,Vde),e(Vde,luo),e(Rh,iuo),e(Rh,tq),e(tq,duo),e(Rh,cuo),e(k,fuo),e(k,Ph),e(Ph,Xde),e(Xde,muo),e(Ph,guo),e(Ph,aq),e(aq,huo),e(Ph,puo),e(k,_uo),e(k,Bh),e(Bh,zde),e(zde,uuo),e(Bh,buo),e(Bh,nq),e(nq,vuo),e(Bh,Fuo),e(k,Tuo),e(k,qs),e(qs,Wde),e(Wde,Muo),e(qs,Euo),e(qs,sq),e(sq,Cuo),e(qs,wuo),e(qs,lq),e(lq,Auo),e(qs,Luo),e(k,yuo),e(k,Ih),e(Ih,Qde),e(Qde,xuo),e(Ih,$uo),e(Ih,iq),e(iq,kuo),e(Ih,Suo),e(k,Ruo),e(k,js),e(js,Hde),e(Hde,Puo),e(js,Buo),e(js,dq),e(dq,Iuo),e(js,Nuo),e(js,cq),e(cq,quo),e(js,juo),e(k,Duo),e(k,Ds),e(Ds,Ude),e(Ude,Guo),e(Ds,Ouo),e(Ds,fq),e(fq,Vuo),e(Ds,Xuo),e(Ds,mq),e(mq,zuo),e(Ds,Wuo),e(k,Quo),e(k,Gs),e(Gs,Jde),e(Jde,Huo),e(Gs,Uuo),e(Gs,gq),e(gq,Juo),e(Gs,Yuo),e(Gs,hq),e(hq,Kuo),e(Gs,Zuo),e(k,e7o),e(k,Os),e(Os,Yde),e(Yde,o7o),e(Os,r7o),e(Os,pq),e(pq,t7o),e(Os,a7o),e(Os,_q),e(_q,n7o),e(Os,s7o),e(k,l7o),e(k,Vs),e(Vs,Kde),e(Kde,i7o),e(Vs,d7o),e(Vs,uq),e(uq,c7o),e(Vs,f7o),e(Vs,bq),e(bq,m7o),e(Vs,g7o),e(k,h7o),e(k,Xs),e(Xs,Zde),e(Zde,p7o),e(Xs,_7o),e(Xs,vq),e(vq,u7o),e(Xs,b7o),e(Xs,Fq),e(Fq,v7o),e(Xs,F7o),e(k,T7o),e(k,Nh),e(Nh,ece),e(ece,M7o),e(Nh,E7o),e(Nh,Tq),e(Tq,C7o),e(Nh,w7o),e(k,A7o),e(k,qh),e(qh,oce),e(oce,L7o),e(qh,y7o),e(qh,Mq),e(Mq,x7o),e(qh,$7o),e(k,k7o),e(k,zs),e(zs,rce),e(rce,S7o),e(zs,R7o),e(zs,Eq),e(Eq,P7o),e(zs,B7o),e(zs,Cq),e(Cq,I7o),e(zs,N7o),e(k,q7o),e(k,Ws),e(Ws,tce),e(tce,j7o),e(Ws,D7o),e(Ws,wq),e(wq,G7o),e(Ws,O7o),e(Ws,Aq),e(Aq,V7o),e(Ws,X7o),e(k,z7o),e(k,Qs),e(Qs,ace),e(ace,W7o),e(Qs,Q7o),e(Qs,Lq),e(Lq,H7o),e(Qs,U7o),e(Qs,yq),e(yq,J7o),e(Qs,Y7o),e(k,K7o),e(k,jh),e(jh,nce),e(nce,Z7o),e(jh,e1o),e(jh,xq),e(xq,o1o),e(jh,r1o),e(k,t1o),e(k,Dh),e(Dh,sce),e(sce,a1o),e(Dh,n1o),e(Dh,$q),e($q,s1o),e(Dh,l1o),e(k,i1o),e(k,Gh),e(Gh,lce),e(lce,d1o),e(Gh,c1o),e(Gh,kq),e(kq,f1o),e(Gh,m1o),e(k,g1o),e(k,Hs),e(Hs,ice),e(ice,h1o),e(Hs,p1o),e(Hs,Sq),e(Sq,_1o),e(Hs,u1o),e(Hs,Rq),e(Rq,b1o),e(Hs,v1o),e(k,F1o),e(k,Us),e(Us,dce),e(dce,T1o),e(Us,M1o),e(Us,Pq),e(Pq,E1o),e(Us,C1o),e(Us,Bq),e(Bq,w1o),e(Us,A1o),e(k,L1o),e(k,Oh),e(Oh,cce),e(cce,y1o),e(Oh,x1o),e(Oh,Iq),e(Iq,$1o),e(Oh,k1o),e(k,S1o),e(k,Vh),e(Vh,fce),e(fce,R1o),e(Vh,P1o),e(Vh,Nq),e(Nq,B1o),e(Vh,I1o),e(k,N1o),e(k,Xh),e(Xh,mce),e(mce,q1o),e(Xh,j1o),e(Xh,qq),e(qq,D1o),e(Xh,G1o),e(k,O1o),e(k,Js),e(Js,gce),e(gce,V1o),e(Js,X1o),e(Js,jq),e(jq,z1o),e(Js,W1o),e(Js,Dq),e(Dq,Q1o),e(Js,H1o),e(k,U1o),e(k,zh),e(zh,hce),e(hce,J1o),e(zh,Y1o),e(zh,Gq),e(Gq,K1o),e(zh,Z1o),e(k,e2o),e(k,Wh),e(Wh,pce),e(pce,o2o),e(Wh,r2o),e(Wh,Oq),e(Oq,t2o),e(Wh,a2o),e(k,n2o),e(k,Ys),e(Ys,_ce),e(_ce,s2o),e(Ys,l2o),e(Ys,Vq),e(Vq,i2o),e(Ys,d2o),e(Ys,Xq),e(Xq,c2o),e(Ys,f2o),e(k,m2o),e(k,Ks),e(Ks,uce),e(uce,g2o),e(Ks,h2o),e(Ks,zq),e(zq,p2o),e(Ks,_2o),e(Ks,Wq),e(Wq,u2o),e(Ks,b2o),e(k,v2o),e(k,Zs),e(Zs,bce),e(bce,F2o),e(Zs,T2o),e(Zs,Qq),e(Qq,M2o),e(Zs,E2o),e(Zs,Hq),e(Hq,C2o),e(Zs,w2o),e(k,A2o),e(k,el),e(el,vce),e(vce,L2o),e(el,y2o),e(el,Uq),e(Uq,x2o),e(el,$2o),e(el,Jq),e(Jq,k2o),e(el,S2o),e(kr,R2o),M(Qh,kr,null),e(xo,P2o),e(xo,Hh),M(sy,Hh,null),e(Hh,B2o),e(Hh,Fce),e(Fce,I2o),b(f,HWe,u),b(f,Qi,u),e(Qi,Uh),e(Uh,Tce),M(ly,Tce,null),e(Qi,N2o),e(Qi,Mce),e(Mce,q2o),b(f,UWe,u),b(f,$o,u),M(iy,$o,null),e($o,j2o),e($o,dy),e(dy,D2o),e(dy,Yq),e(Yq,G2o),e(dy,O2o),e($o,V2o),e($o,cy),e(cy,X2o),e(cy,Ece),e(Ece,z2o),e(cy,W2o),e($o,Q2o),e($o,Ue),M(fy,Ue,null),e(Ue,H2o),e(Ue,Cce),e(Cce,U2o),e(Ue,J2o),e(Ue,ja),e(ja,Y2o),e(ja,wce),e(wce,K2o),e(ja,Z2o),e(ja,Ace),e(Ace,ebo),e(ja,obo),e(ja,Lce),e(Lce,rbo),e(ja,tbo),e(Ue,abo),e(Ue,H),e(H,Jh),e(Jh,yce),e(yce,nbo),e(Jh,sbo),e(Jh,Kq),e(Kq,lbo),e(Jh,ibo),e(H,dbo),e(H,Yh),e(Yh,xce),e(xce,cbo),e(Yh,fbo),e(Yh,Zq),e(Zq,mbo),e(Yh,gbo),e(H,hbo),e(H,Kh),e(Kh,$ce),e($ce,pbo),e(Kh,_bo),e(Kh,ej),e(ej,ubo),e(Kh,bbo),e(H,vbo),e(H,Zh),e(Zh,kce),e(kce,Fbo),e(Zh,Tbo),e(Zh,oj),e(oj,Mbo),e(Zh,Ebo),e(H,Cbo),e(H,ep),e(ep,Sce),e(Sce,wbo),e(ep,Abo),e(ep,rj),e(rj,Lbo),e(ep,ybo),e(H,xbo),e(H,op),e(op,Rce),e(Rce,$bo),e(op,kbo),e(op,tj),e(tj,Sbo),e(op,Rbo),e(H,Pbo),e(H,rp),e(rp,Pce),e(Pce,Bbo),e(rp,Ibo),e(rp,aj),e(aj,Nbo),e(rp,qbo),e(H,jbo),e(H,tp),e(tp,Bce),e(Bce,Dbo),e(tp,Gbo),e(tp,nj),e(nj,Obo),e(tp,Vbo),e(H,Xbo),e(H,ap),e(ap,Ice),e(Ice,zbo),e(ap,Wbo),e(ap,sj),e(sj,Qbo),e(ap,Hbo),e(H,Ubo),e(H,np),e(np,Nce),e(Nce,Jbo),e(np,Ybo),e(np,lj),e(lj,Kbo),e(np,Zbo),e(H,evo),e(H,sp),e(sp,qce),e(qce,ovo),e(sp,rvo),e(sp,ij),e(ij,tvo),e(sp,avo),e(H,nvo),e(H,lp),e(lp,jce),e(jce,svo),e(lp,lvo),e(lp,dj),e(dj,ivo),e(lp,dvo),e(H,cvo),e(H,ip),e(ip,Dce),e(Dce,fvo),e(ip,mvo),e(ip,cj),e(cj,gvo),e(ip,hvo),e(H,pvo),e(H,dp),e(dp,Gce),e(Gce,_vo),e(dp,uvo),e(dp,fj),e(fj,bvo),e(dp,vvo),e(H,Fvo),e(H,cp),e(cp,Oce),e(Oce,Tvo),e(cp,Mvo),e(cp,mj),e(mj,Evo),e(cp,Cvo),e(H,wvo),e(H,fp),e(fp,Vce),e(Vce,Avo),e(fp,Lvo),e(fp,gj),e(gj,yvo),e(fp,xvo),e(H,$vo),e(H,mp),e(mp,Xce),e(Xce,kvo),e(mp,Svo),e(mp,hj),e(hj,Rvo),e(mp,Pvo),e(H,Bvo),e(H,gp),e(gp,zce),e(zce,Ivo),e(gp,Nvo),e(gp,pj),e(pj,qvo),e(gp,jvo),e(H,Dvo),e(H,hp),e(hp,Wce),e(Wce,Gvo),e(hp,Ovo),e(hp,_j),e(_j,Vvo),e(hp,Xvo),e(H,zvo),e(H,pp),e(pp,Qce),e(Qce,Wvo),e(pp,Qvo),e(pp,uj),e(uj,Hvo),e(pp,Uvo),e(H,Jvo),e(H,_p),e(_p,Hce),e(Hce,Yvo),e(_p,Kvo),e(_p,bj),e(bj,Zvo),e(_p,eFo),e(H,oFo),e(H,up),e(up,Uce),e(Uce,rFo),e(up,tFo),e(up,vj),e(vj,aFo),e(up,nFo),e(H,sFo),e(H,bp),e(bp,Jce),e(Jce,lFo),e(bp,iFo),e(bp,Fj),e(Fj,dFo),e(bp,cFo),e(H,fFo),e(H,vp),e(vp,Yce),e(Yce,mFo),e(vp,gFo),e(vp,Tj),e(Tj,hFo),e(vp,pFo),e(H,_Fo),e(H,Fp),e(Fp,Kce),e(Kce,uFo),e(Fp,bFo),e(Fp,Mj),e(Mj,vFo),e(Fp,FFo),e(H,TFo),e(H,Tp),e(Tp,Zce),e(Zce,MFo),e(Tp,EFo),e(Tp,Ej),e(Ej,CFo),e(Tp,wFo),e(H,AFo),e(H,Mp),e(Mp,efe),e(efe,LFo),e(Mp,yFo),e(Mp,Cj),e(Cj,xFo),e(Mp,$Fo),e(H,kFo),e(H,Ep),e(Ep,ofe),e(ofe,SFo),e(Ep,RFo),e(Ep,wj),e(wj,PFo),e(Ep,BFo),e(H,IFo),e(H,Cp),e(Cp,rfe),e(rfe,NFo),e(Cp,qFo),e(Cp,Aj),e(Aj,jFo),e(Cp,DFo),e(H,GFo),e(H,wp),e(wp,tfe),e(tfe,OFo),e(wp,VFo),e(wp,Lj),e(Lj,XFo),e(wp,zFo),e(H,WFo),e(H,Ap),e(Ap,afe),e(afe,QFo),e(Ap,HFo),e(Ap,yj),e(yj,UFo),e(Ap,JFo),e(H,YFo),e(H,Lp),e(Lp,nfe),e(nfe,KFo),e(Lp,ZFo),e(Lp,xj),e(xj,eTo),e(Lp,oTo),e(H,rTo),e(H,yp),e(yp,sfe),e(sfe,tTo),e(yp,aTo),e(yp,$j),e($j,nTo),e(yp,sTo),e(H,lTo),e(H,xp),e(xp,lfe),e(lfe,iTo),e(xp,dTo),e(xp,kj),e(kj,cTo),e(xp,fTo),e(H,mTo),e(H,$p),e($p,ife),e(ife,gTo),e($p,hTo),e($p,Sj),e(Sj,pTo),e($p,_To),e(H,uTo),e(H,kp),e(kp,dfe),e(dfe,bTo),e(kp,vTo),e(kp,Rj),e(Rj,FTo),e(kp,TTo),e(H,MTo),e(H,Sp),e(Sp,cfe),e(cfe,ETo),e(Sp,CTo),e(Sp,Pj),e(Pj,wTo),e(Sp,ATo),e(Ue,LTo),M(Rp,Ue,null),e(Ue,yTo),M(Pp,Ue,null),e($o,xTo),e($o,Bp),M(my,Bp,null),e(Bp,$To),e(Bp,ffe),e(ffe,kTo),b(f,JWe,u),b(f,Hi,u),e(Hi,Ip),e(Ip,mfe),M(gy,mfe,null),e(Hi,STo),e(Hi,gfe),e(gfe,RTo),b(f,YWe,u),b(f,ko,u),M(hy,ko,null),e(ko,PTo),e(ko,py),e(py,BTo),e(py,Bj),e(Bj,ITo),e(py,NTo),e(ko,qTo),e(ko,_y),e(_y,jTo),e(_y,hfe),e(hfe,DTo),e(_y,GTo),e(ko,OTo),e(ko,Je),M(uy,Je,null),e(Je,VTo),e(Je,pfe),e(pfe,XTo),e(Je,zTo),e(Je,Ui),e(Ui,WTo),e(Ui,_fe),e(_fe,QTo),e(Ui,HTo),e(Ui,ufe),e(ufe,UTo),e(Ui,JTo),e(Je,YTo),e(Je,fe),e(fe,Np),e(Np,bfe),e(bfe,KTo),e(Np,ZTo),e(Np,Ij),e(Ij,e9o),e(Np,o9o),e(fe,r9o),e(fe,qp),e(qp,vfe),e(vfe,t9o),e(qp,a9o),e(qp,Nj),e(Nj,n9o),e(qp,s9o),e(fe,l9o),e(fe,jp),e(jp,Ffe),e(Ffe,i9o),e(jp,d9o),e(jp,qj),e(qj,c9o),e(jp,f9o),e(fe,m9o),e(fe,Dp),e(Dp,Tfe),e(Tfe,g9o),e(Dp,h9o),e(Dp,jj),e(jj,p9o),e(Dp,_9o),e(fe,u9o),e(fe,Gp),e(Gp,Mfe),e(Mfe,b9o),e(Gp,v9o),e(Gp,Dj),e(Dj,F9o),e(Gp,T9o),e(fe,M9o),e(fe,Op),e(Op,Efe),e(Efe,E9o),e(Op,C9o),e(Op,Gj),e(Gj,w9o),e(Op,A9o),e(fe,L9o),e(fe,Vp),e(Vp,Cfe),e(Cfe,y9o),e(Vp,x9o),e(Vp,Oj),e(Oj,$9o),e(Vp,k9o),e(fe,S9o),e(fe,Xp),e(Xp,wfe),e(wfe,R9o),e(Xp,P9o),e(Xp,Vj),e(Vj,B9o),e(Xp,I9o),e(fe,N9o),e(fe,zp),e(zp,Afe),e(Afe,q9o),e(zp,j9o),e(zp,Xj),e(Xj,D9o),e(zp,G9o),e(fe,O9o),e(fe,Wp),e(Wp,Lfe),e(Lfe,V9o),e(Wp,X9o),e(Wp,zj),e(zj,z9o),e(Wp,W9o),e(fe,Q9o),e(fe,Qp),e(Qp,yfe),e(yfe,H9o),e(Qp,U9o),e(Qp,Wj),e(Wj,J9o),e(Qp,Y9o),e(fe,K9o),e(fe,Hp),e(Hp,xfe),e(xfe,Z9o),e(Hp,eMo),e(Hp,Qj),e(Qj,oMo),e(Hp,rMo),e(fe,tMo),e(fe,Up),e(Up,$fe),e($fe,aMo),e(Up,nMo),e(Up,Hj),e(Hj,sMo),e(Up,lMo),e(fe,iMo),e(fe,Jp),e(Jp,kfe),e(kfe,dMo),e(Jp,cMo),e(Jp,Uj),e(Uj,fMo),e(Jp,mMo),e(fe,gMo),e(fe,Yp),e(Yp,Sfe),e(Sfe,hMo),e(Yp,pMo),e(Yp,Jj),e(Jj,_Mo),e(Yp,uMo),e(fe,bMo),e(fe,Kp),e(Kp,Rfe),e(Rfe,vMo),e(Kp,FMo),e(Kp,Yj),e(Yj,TMo),e(Kp,MMo),e(fe,EMo),e(fe,Zp),e(Zp,Pfe),e(Pfe,CMo),e(Zp,wMo),e(Zp,Kj),e(Kj,AMo),e(Zp,LMo),e(fe,yMo),e(fe,e_),e(e_,Bfe),e(Bfe,xMo),e(e_,$Mo),e(e_,Zj),e(Zj,kMo),e(e_,SMo),e(fe,RMo),e(fe,o_),e(o_,Ife),e(Ife,PMo),e(o_,BMo),e(o_,eD),e(eD,IMo),e(o_,NMo),e(Je,qMo),M(r_,Je,null),e(Je,jMo),M(t_,Je,null),e(ko,DMo),e(ko,a_),M(by,a_,null),e(a_,GMo),e(a_,Nfe),e(Nfe,OMo),b(f,KWe,u),b(f,Ji,u),e(Ji,n_),e(n_,qfe),M(vy,qfe,null),e(Ji,VMo),e(Ji,jfe),e(jfe,XMo),b(f,ZWe,u),b(f,So,u),M(Fy,So,null),e(So,zMo),e(So,Yi),e(Yi,WMo),e(Yi,oD),e(oD,QMo),e(Yi,HMo),e(Yi,rD),e(rD,UMo),e(Yi,JMo),e(So,YMo),e(So,Ty),e(Ty,KMo),e(Ty,Dfe),e(Dfe,ZMo),e(Ty,eEo),e(So,oEo),e(So,ct),M(My,ct,null),e(ct,rEo),e(ct,Gfe),e(Gfe,tEo),e(ct,aEo),e(ct,Ki),e(Ki,nEo),e(Ki,Ofe),e(Ofe,sEo),e(Ki,lEo),e(Ki,tD),e(tD,iEo),e(Ki,dEo),e(ct,cEo),M(s_,ct,null),e(So,fEo),e(So,Ye),M(Ey,Ye,null),e(Ye,mEo),e(Ye,Vfe),e(Vfe,gEo),e(Ye,hEo),e(Ye,Da),e(Da,pEo),e(Da,Xfe),e(Xfe,_Eo),e(Da,uEo),e(Da,zfe),e(zfe,bEo),e(Da,vEo),e(Da,Wfe),e(Wfe,FEo),e(Da,TEo),e(Ye,MEo),e(Ye,y),e(y,l_),e(l_,Qfe),e(Qfe,EEo),e(l_,CEo),e(l_,aD),e(aD,wEo),e(l_,AEo),e(y,LEo),e(y,i_),e(i_,Hfe),e(Hfe,yEo),e(i_,xEo),e(i_,nD),e(nD,$Eo),e(i_,kEo),e(y,SEo),e(y,d_),e(d_,Ufe),e(Ufe,REo),e(d_,PEo),e(d_,sD),e(sD,BEo),e(d_,IEo),e(y,NEo),e(y,c_),e(c_,Jfe),e(Jfe,qEo),e(c_,jEo),e(c_,lD),e(lD,DEo),e(c_,GEo),e(y,OEo),e(y,f_),e(f_,Yfe),e(Yfe,VEo),e(f_,XEo),e(f_,iD),e(iD,zEo),e(f_,WEo),e(y,QEo),e(y,m_),e(m_,Kfe),e(Kfe,HEo),e(m_,UEo),e(m_,dD),e(dD,JEo),e(m_,YEo),e(y,KEo),e(y,g_),e(g_,Zfe),e(Zfe,ZEo),e(g_,e4o),e(g_,cD),e(cD,o4o),e(g_,r4o),e(y,t4o),e(y,h_),e(h_,eme),e(eme,a4o),e(h_,n4o),e(h_,fD),e(fD,s4o),e(h_,l4o),e(y,i4o),e(y,p_),e(p_,ome),e(ome,d4o),e(p_,c4o),e(p_,mD),e(mD,f4o),e(p_,m4o),e(y,g4o),e(y,__),e(__,rme),e(rme,h4o),e(__,p4o),e(__,gD),e(gD,_4o),e(__,u4o),e(y,b4o),e(y,u_),e(u_,tme),e(tme,v4o),e(u_,F4o),e(u_,hD),e(hD,T4o),e(u_,M4o),e(y,E4o),e(y,b_),e(b_,ame),e(ame,C4o),e(b_,w4o),e(b_,pD),e(pD,A4o),e(b_,L4o),e(y,y4o),e(y,v_),e(v_,nme),e(nme,x4o),e(v_,$4o),e(v_,_D),e(_D,k4o),e(v_,S4o),e(y,R4o),e(y,F_),e(F_,sme),e(sme,P4o),e(F_,B4o),e(F_,uD),e(uD,I4o),e(F_,N4o),e(y,q4o),e(y,T_),e(T_,lme),e(lme,j4o),e(T_,D4o),e(T_,bD),e(bD,G4o),e(T_,O4o),e(y,V4o),e(y,M_),e(M_,ime),e(ime,X4o),e(M_,z4o),e(M_,vD),e(vD,W4o),e(M_,Q4o),e(y,H4o),e(y,E_),e(E_,dme),e(dme,U4o),e(E_,J4o),e(E_,FD),e(FD,Y4o),e(E_,K4o),e(y,Z4o),e(y,C_),e(C_,cme),e(cme,eCo),e(C_,oCo),e(C_,TD),e(TD,rCo),e(C_,tCo),e(y,aCo),e(y,w_),e(w_,fme),e(fme,nCo),e(w_,sCo),e(w_,MD),e(MD,lCo),e(w_,iCo),e(y,dCo),e(y,A_),e(A_,mme),e(mme,cCo),e(A_,fCo),e(A_,ED),e(ED,mCo),e(A_,gCo),e(y,hCo),e(y,L_),e(L_,gme),e(gme,pCo),e(L_,_Co),e(L_,CD),e(CD,uCo),e(L_,bCo),e(y,vCo),e(y,y_),e(y_,hme),e(hme,FCo),e(y_,TCo),e(y_,wD),e(wD,MCo),e(y_,ECo),e(y,CCo),e(y,x_),e(x_,pme),e(pme,wCo),e(x_,ACo),e(x_,AD),e(AD,LCo),e(x_,yCo),e(y,xCo),e(y,$_),e($_,_me),e(_me,$Co),e($_,kCo),e($_,LD),e(LD,SCo),e($_,RCo),e(y,PCo),e(y,k_),e(k_,ume),e(ume,BCo),e(k_,ICo),e(k_,yD),e(yD,NCo),e(k_,qCo),e(y,jCo),e(y,S_),e(S_,bme),e(bme,DCo),e(S_,GCo),e(S_,xD),e(xD,OCo),e(S_,VCo),e(y,XCo),e(y,R_),e(R_,vme),e(vme,zCo),e(R_,WCo),e(R_,$D),e($D,QCo),e(R_,HCo),e(y,UCo),e(y,P_),e(P_,Fme),e(Fme,JCo),e(P_,YCo),e(P_,kD),e(kD,KCo),e(P_,ZCo),e(y,e3o),e(y,B_),e(B_,Tme),e(Tme,o3o),e(B_,r3o),e(B_,SD),e(SD,t3o),e(B_,a3o),e(y,n3o),e(y,I_),e(I_,Mme),e(Mme,s3o),e(I_,l3o),e(I_,RD),e(RD,i3o),e(I_,d3o),e(y,c3o),e(y,N_),e(N_,Eme),e(Eme,f3o),e(N_,m3o),e(N_,PD),e(PD,g3o),e(N_,h3o),e(y,p3o),e(y,q_),e(q_,Cme),e(Cme,_3o),e(q_,u3o),e(q_,BD),e(BD,b3o),e(q_,v3o),e(y,F3o),e(y,j_),e(j_,wme),e(wme,T3o),e(j_,M3o),e(j_,ID),e(ID,E3o),e(j_,C3o),e(y,w3o),e(y,D_),e(D_,Ame),e(Ame,A3o),e(D_,L3o),e(D_,ND),e(ND,y3o),e(D_,x3o),e(y,$3o),e(y,ol),e(ol,Lme),e(Lme,k3o),e(ol,S3o),e(ol,qD),e(qD,R3o),e(ol,P3o),e(ol,jD),e(jD,B3o),e(ol,I3o),e(y,N3o),e(y,G_),e(G_,yme),e(yme,q3o),e(G_,j3o),e(G_,DD),e(DD,D3o),e(G_,G3o),e(y,O3o),e(y,O_),e(O_,xme),e(xme,V3o),e(O_,X3o),e(O_,GD),e(GD,z3o),e(O_,W3o),e(y,Q3o),e(y,V_),e(V_,$me),e($me,H3o),e(V_,U3o),e(V_,OD),e(OD,J3o),e(V_,Y3o),e(y,K3o),e(y,X_),e(X_,kme),e(kme,Z3o),e(X_,e5o),e(X_,VD),e(VD,o5o),e(X_,r5o),e(y,t5o),e(y,z_),e(z_,Sme),e(Sme,a5o),e(z_,n5o),e(z_,XD),e(XD,s5o),e(z_,l5o),e(y,i5o),e(y,W_),e(W_,Rme),e(Rme,d5o),e(W_,c5o),e(W_,zD),e(zD,f5o),e(W_,m5o),e(y,g5o),e(y,Q_),e(Q_,Pme),e(Pme,h5o),e(Q_,p5o),e(Q_,WD),e(WD,_5o),e(Q_,u5o),e(y,b5o),e(y,H_),e(H_,Bme),e(Bme,v5o),e(H_,F5o),e(H_,QD),e(QD,T5o),e(H_,M5o),e(y,E5o),e(y,U_),e(U_,Ime),e(Ime,C5o),e(U_,w5o),e(U_,HD),e(HD,A5o),e(U_,L5o),e(y,y5o),e(y,J_),e(J_,Nme),e(Nme,x5o),e(J_,$5o),e(J_,UD),e(UD,k5o),e(J_,S5o),e(y,R5o),e(y,Y_),e(Y_,qme),e(qme,P5o),e(Y_,B5o),e(Y_,JD),e(JD,I5o),e(Y_,N5o),e(y,q5o),e(y,K_),e(K_,jme),e(jme,j5o),e(K_,D5o),e(K_,YD),e(YD,G5o),e(K_,O5o),e(y,V5o),e(y,Z_),e(Z_,Dme),e(Dme,X5o),e(Z_,z5o),e(Z_,KD),e(KD,W5o),e(Z_,Q5o),e(y,H5o),e(y,eu),e(eu,Gme),e(Gme,U5o),e(eu,J5o),e(eu,ZD),e(ZD,Y5o),e(eu,K5o),e(y,Z5o),e(y,ou),e(ou,Ome),e(Ome,e0o),e(ou,o0o),e(ou,eG),e(eG,r0o),e(ou,t0o),e(y,a0o),e(y,ru),e(ru,Vme),e(Vme,n0o),e(ru,s0o),e(ru,oG),e(oG,l0o),e(ru,i0o),e(y,d0o),e(y,tu),e(tu,Xme),e(Xme,c0o),e(tu,f0o),e(tu,rG),e(rG,m0o),e(tu,g0o),e(y,h0o),e(y,au),e(au,zme),e(zme,p0o),e(au,_0o),e(au,tG),e(tG,u0o),e(au,b0o),e(y,v0o),e(y,nu),e(nu,Wme),e(Wme,F0o),e(nu,T0o),e(nu,aG),e(aG,M0o),e(nu,E0o),e(y,C0o),e(y,su),e(su,Qme),e(Qme,w0o),e(su,A0o),e(su,nG),e(nG,L0o),e(su,y0o),e(y,x0o),e(y,lu),e(lu,Hme),e(Hme,$0o),e(lu,k0o),e(lu,sG),e(sG,S0o),e(lu,R0o),e(y,P0o),e(y,iu),e(iu,Ume),e(Ume,B0o),e(iu,I0o),e(iu,lG),e(lG,N0o),e(iu,q0o),e(y,j0o),e(y,du),e(du,Jme),e(Jme,D0o),e(du,G0o),e(du,iG),e(iG,O0o),e(du,V0o),e(y,X0o),e(y,cu),e(cu,Yme),e(Yme,z0o),e(cu,W0o),e(cu,dG),e(dG,Q0o),e(cu,H0o),e(y,U0o),e(y,fu),e(fu,Kme),e(Kme,J0o),e(fu,Y0o),e(fu,cG),e(cG,K0o),e(fu,Z0o),e(y,ewo),e(y,mu),e(mu,Zme),e(Zme,owo),e(mu,rwo),e(mu,fG),e(fG,two),e(mu,awo),e(y,nwo),e(y,gu),e(gu,ege),e(ege,swo),e(gu,lwo),e(gu,mG),e(mG,iwo),e(gu,dwo),e(y,cwo),e(y,hu),e(hu,oge),e(oge,fwo),e(hu,mwo),e(hu,gG),e(gG,gwo),e(hu,hwo),e(y,pwo),e(y,pu),e(pu,rge),e(rge,_wo),e(pu,uwo),e(pu,hG),e(hG,bwo),e(pu,vwo),e(y,Fwo),e(y,_u),e(_u,tge),e(tge,Two),e(_u,Mwo),e(_u,pG),e(pG,Ewo),e(_u,Cwo),e(y,wwo),e(y,uu),e(uu,age),e(age,Awo),e(uu,Lwo),e(uu,_G),e(_G,ywo),e(uu,xwo),e(y,$wo),e(y,bu),e(bu,nge),e(nge,kwo),e(bu,Swo),e(bu,uG),e(uG,Rwo),e(bu,Pwo),e(y,Bwo),e(y,vu),e(vu,sge),e(sge,Iwo),e(vu,Nwo),e(vu,bG),e(bG,qwo),e(vu,jwo),e(y,Dwo),e(y,Fu),e(Fu,lge),e(lge,Gwo),e(Fu,Owo),e(Fu,vG),e(vG,Vwo),e(Fu,Xwo),e(y,zwo),e(y,Tu),e(Tu,ige),e(ige,Wwo),e(Tu,Qwo),e(Tu,FG),e(FG,Hwo),e(Tu,Uwo),e(y,Jwo),e(y,Mu),e(Mu,dge),e(dge,Ywo),e(Mu,Kwo),e(Mu,TG),e(TG,Zwo),e(Mu,e6o),e(y,o6o),e(y,Eu),e(Eu,cge),e(cge,r6o),e(Eu,t6o),e(Eu,MG),e(MG,a6o),e(Eu,n6o),e(y,s6o),e(y,Cu),e(Cu,fge),e(fge,l6o),e(Cu,i6o),e(Cu,EG),e(EG,d6o),e(Cu,c6o),e(y,f6o),e(y,wu),e(wu,mge),e(mge,m6o),e(wu,g6o),e(wu,CG),e(CG,h6o),e(wu,p6o),e(y,_6o),e(y,Au),e(Au,gge),e(gge,u6o),e(Au,b6o),e(Au,wG),e(wG,v6o),e(Au,F6o),e(y,T6o),e(y,Lu),e(Lu,hge),e(hge,M6o),e(Lu,E6o),e(Lu,AG),e(AG,C6o),e(Lu,w6o),e(y,A6o),e(y,yu),e(yu,pge),e(pge,L6o),e(yu,y6o),e(yu,LG),e(LG,x6o),e(yu,$6o),e(y,k6o),e(y,xu),e(xu,_ge),e(_ge,S6o),e(xu,R6o),e(xu,yG),e(yG,P6o),e(xu,B6o),e(y,I6o),e(y,$u),e($u,uge),e(uge,N6o),e($u,q6o),e($u,xG),e(xG,j6o),e($u,D6o),e(y,G6o),e(y,ku),e(ku,bge),e(bge,O6o),e(ku,V6o),e(ku,$G),e($G,X6o),e(ku,z6o),e(y,W6o),e(y,Su),e(Su,vge),e(vge,Q6o),e(Su,H6o),e(Su,kG),e(kG,U6o),e(Su,J6o),e(y,Y6o),e(y,Ru),e(Ru,Fge),e(Fge,K6o),e(Ru,Z6o),e(Ru,SG),e(SG,eAo),e(Ru,oAo),e(y,rAo),e(y,Pu),e(Pu,Tge),e(Tge,tAo),e(Pu,aAo),e(Pu,RG),e(RG,nAo),e(Pu,sAo),e(y,lAo),e(y,Bu),e(Bu,Mge),e(Mge,iAo),e(Bu,dAo),e(Bu,PG),e(PG,cAo),e(Bu,fAo),e(y,mAo),e(y,Iu),e(Iu,Ege),e(Ege,gAo),e(Iu,hAo),e(Iu,BG),e(BG,pAo),e(Iu,_Ao),e(y,uAo),e(y,Nu),e(Nu,Cge),e(Cge,bAo),e(Nu,vAo),e(Nu,IG),e(IG,FAo),e(Nu,TAo),e(y,MAo),e(y,qu),e(qu,wge),e(wge,EAo),e(qu,CAo),e(qu,NG),e(NG,wAo),e(qu,AAo),e(y,LAo),e(y,ju),e(ju,Age),e(Age,yAo),e(ju,xAo),e(ju,qG),e(qG,$Ao),e(ju,kAo),e(y,SAo),e(y,Du),e(Du,Lge),e(Lge,RAo),e(Du,PAo),e(Du,jG),e(jG,BAo),e(Du,IAo),e(y,NAo),e(y,Gu),e(Gu,yge),e(yge,qAo),e(Gu,jAo),e(Gu,DG),e(DG,DAo),e(Gu,GAo),e(y,OAo),e(y,Ou),e(Ou,xge),e(xge,VAo),e(Ou,XAo),e(Ou,GG),e(GG,zAo),e(Ou,WAo),e(y,QAo),e(y,Vu),e(Vu,$ge),e($ge,HAo),e(Vu,UAo),e(Vu,OG),e(OG,JAo),e(Vu,YAo),e(y,KAo),e(y,Xu),e(Xu,kge),e(kge,ZAo),e(Xu,eLo),e(Xu,VG),e(VG,oLo),e(Xu,rLo),e(y,tLo),e(y,zu),e(zu,Sge),e(Sge,aLo),e(zu,nLo),e(zu,XG),e(XG,sLo),e(zu,lLo),e(y,iLo),e(y,Wu),e(Wu,Rge),e(Rge,dLo),e(Wu,cLo),e(Wu,zG),e(zG,fLo),e(Wu,mLo),e(y,gLo),e(y,Qu),e(Qu,Pge),e(Pge,hLo),e(Qu,pLo),e(Qu,WG),e(WG,_Lo),e(Qu,uLo),e(y,bLo),e(y,Hu),e(Hu,Bge),e(Bge,vLo),e(Hu,FLo),e(Hu,QG),e(QG,TLo),e(Hu,MLo),e(y,ELo),e(y,Uu),e(Uu,Ige),e(Ige,CLo),e(Uu,wLo),e(Uu,HG),e(HG,ALo),e(Uu,LLo),e(y,yLo),e(y,Ju),e(Ju,Nge),e(Nge,xLo),e(Ju,$Lo),e(Ju,UG),e(UG,kLo),e(Ju,SLo),e(y,RLo),e(y,Yu),e(Yu,qge),e(qge,PLo),e(Yu,BLo),e(Yu,JG),e(JG,ILo),e(Yu,NLo),e(y,qLo),e(y,Ku),e(Ku,jge),e(jge,jLo),e(Ku,DLo),e(Ku,YG),e(YG,GLo),e(Ku,OLo),e(y,VLo),e(y,Zu),e(Zu,Dge),e(Dge,XLo),e(Zu,zLo),e(Zu,KG),e(KG,WLo),e(Zu,QLo),e(y,HLo),e(y,e7),e(e7,Gge),e(Gge,ULo),e(e7,JLo),e(e7,ZG),e(ZG,YLo),e(e7,KLo),e(y,ZLo),e(y,o7),e(o7,Oge),e(Oge,eyo),e(o7,oyo),e(o7,eO),e(eO,ryo),e(o7,tyo),e(y,ayo),e(y,r7),e(r7,Vge),e(Vge,nyo),e(r7,syo),e(r7,oO),e(oO,lyo),e(r7,iyo),e(y,dyo),e(y,t7),e(t7,Xge),e(Xge,cyo),e(t7,fyo),e(t7,rO),e(rO,myo),e(t7,gyo),e(y,hyo),e(y,a7),e(a7,zge),e(zge,pyo),e(a7,_yo),e(a7,tO),e(tO,uyo),e(a7,byo),e(y,vyo),e(y,n7),e(n7,Wge),e(Wge,Fyo),e(n7,Tyo),e(n7,aO),e(aO,Myo),e(n7,Eyo),e(y,Cyo),e(y,s7),e(s7,Qge),e(Qge,wyo),e(s7,Ayo),e(s7,nO),e(nO,Lyo),e(s7,yyo),e(y,xyo),e(y,l7),e(l7,Hge),e(Hge,$yo),e(l7,kyo),e(l7,sO),e(sO,Syo),e(l7,Ryo),e(y,Pyo),e(y,i7),e(i7,Uge),e(Uge,Byo),e(i7,Iyo),e(i7,lO),e(lO,Nyo),e(i7,qyo),e(y,jyo),e(y,d7),e(d7,Jge),e(Jge,Dyo),e(d7,Gyo),e(d7,iO),e(iO,Oyo),e(d7,Vyo),e(y,Xyo),e(y,c7),e(c7,Yge),e(Yge,zyo),e(c7,Wyo),e(c7,dO),e(dO,Qyo),e(c7,Hyo),e(y,Uyo),e(y,f7),e(f7,Kge),e(Kge,Jyo),e(f7,Yyo),e(f7,cO),e(cO,Kyo),e(f7,Zyo),e(y,e8o),e(y,m7),e(m7,Zge),e(Zge,o8o),e(m7,r8o),e(m7,fO),e(fO,t8o),e(m7,a8o),e(Ye,n8o),e(Ye,g7),e(g7,s8o),e(g7,ehe),e(ehe,l8o),e(g7,i8o),e(g7,ohe),e(ohe,d8o),e(Ye,c8o),M(h7,Ye,null),b(f,eQe,u),b(f,Zi,u),e(Zi,p7),e(p7,rhe),M(Cy,rhe,null),e(Zi,f8o),e(Zi,the),e(the,m8o),b(f,oQe,u),b(f,Ro,u),M(wy,Ro,null),e(Ro,g8o),e(Ro,ed),e(ed,h8o),e(ed,mO),e(mO,p8o),e(ed,_8o),e(ed,gO),e(gO,u8o),e(ed,b8o),e(Ro,v8o),e(Ro,Ay),e(Ay,F8o),e(Ay,ahe),e(ahe,T8o),e(Ay,M8o),e(Ro,E8o),e(Ro,ft),M(Ly,ft,null),e(ft,C8o),e(ft,nhe),e(nhe,w8o),e(ft,A8o),e(ft,od),e(od,L8o),e(od,she),e(she,y8o),e(od,x8o),e(od,hO),e(hO,$8o),e(od,k8o),e(ft,S8o),M(_7,ft,null),e(Ro,R8o),e(Ro,Ke),M(yy,Ke,null),e(Ke,P8o),e(Ke,lhe),e(lhe,B8o),e(Ke,I8o),e(Ke,Ga),e(Ga,N8o),e(Ga,ihe),e(ihe,q8o),e(Ga,j8o),e(Ga,dhe),e(dhe,D8o),e(Ga,G8o),e(Ga,che),e(che,O8o),e(Ga,V8o),e(Ke,X8o),e(Ke,G),e(G,u7),e(u7,fhe),e(fhe,z8o),e(u7,W8o),e(u7,pO),e(pO,Q8o),e(u7,H8o),e(G,U8o),e(G,b7),e(b7,mhe),e(mhe,J8o),e(b7,Y8o),e(b7,_O),e(_O,K8o),e(b7,Z8o),e(G,exo),e(G,v7),e(v7,ghe),e(ghe,oxo),e(v7,rxo),e(v7,uO),e(uO,txo),e(v7,axo),e(G,nxo),e(G,F7),e(F7,hhe),e(hhe,sxo),e(F7,lxo),e(F7,bO),e(bO,ixo),e(F7,dxo),e(G,cxo),e(G,T7),e(T7,phe),e(phe,fxo),e(T7,mxo),e(T7,vO),e(vO,gxo),e(T7,hxo),e(G,pxo),e(G,M7),e(M7,_he),e(_he,_xo),e(M7,uxo),e(M7,FO),e(FO,bxo),e(M7,vxo),e(G,Fxo),e(G,E7),e(E7,uhe),e(uhe,Txo),e(E7,Mxo),e(E7,TO),e(TO,Exo),e(E7,Cxo),e(G,wxo),e(G,C7),e(C7,bhe),e(bhe,Axo),e(C7,Lxo),e(C7,MO),e(MO,yxo),e(C7,xxo),e(G,$xo),e(G,w7),e(w7,vhe),e(vhe,kxo),e(w7,Sxo),e(w7,EO),e(EO,Rxo),e(w7,Pxo),e(G,Bxo),e(G,A7),e(A7,Fhe),e(Fhe,Ixo),e(A7,Nxo),e(A7,CO),e(CO,qxo),e(A7,jxo),e(G,Dxo),e(G,L7),e(L7,The),e(The,Gxo),e(L7,Oxo),e(L7,wO),e(wO,Vxo),e(L7,Xxo),e(G,zxo),e(G,y7),e(y7,Mhe),e(Mhe,Wxo),e(y7,Qxo),e(y7,AO),e(AO,Hxo),e(y7,Uxo),e(G,Jxo),e(G,x7),e(x7,Ehe),e(Ehe,Yxo),e(x7,Kxo),e(x7,LO),e(LO,Zxo),e(x7,e$o),e(G,o$o),e(G,$7),e($7,Che),e(Che,r$o),e($7,t$o),e($7,yO),e(yO,a$o),e($7,n$o),e(G,s$o),e(G,k7),e(k7,whe),e(whe,l$o),e(k7,i$o),e(k7,xO),e(xO,d$o),e(k7,c$o),e(G,f$o),e(G,S7),e(S7,Ahe),e(Ahe,m$o),e(S7,g$o),e(S7,$O),e($O,h$o),e(S7,p$o),e(G,_$o),e(G,R7),e(R7,Lhe),e(Lhe,u$o),e(R7,b$o),e(R7,kO),e(kO,v$o),e(R7,F$o),e(G,T$o),e(G,P7),e(P7,yhe),e(yhe,M$o),e(P7,E$o),e(P7,SO),e(SO,C$o),e(P7,w$o),e(G,A$o),e(G,B7),e(B7,xhe),e(xhe,L$o),e(B7,y$o),e(B7,RO),e(RO,x$o),e(B7,$$o),e(G,k$o),e(G,I7),e(I7,$he),e($he,S$o),e(I7,R$o),e(I7,PO),e(PO,P$o),e(I7,B$o),e(G,I$o),e(G,N7),e(N7,khe),e(khe,N$o),e(N7,q$o),e(N7,BO),e(BO,j$o),e(N7,D$o),e(G,G$o),e(G,q7),e(q7,She),e(She,O$o),e(q7,V$o),e(q7,IO),e(IO,X$o),e(q7,z$o),e(G,W$o),e(G,j7),e(j7,Rhe),e(Rhe,Q$o),e(j7,H$o),e(j7,NO),e(NO,U$o),e(j7,J$o),e(G,Y$o),e(G,D7),e(D7,Phe),e(Phe,K$o),e(D7,Z$o),e(D7,qO),e(qO,eko),e(D7,oko),e(G,rko),e(G,G7),e(G7,Bhe),e(Bhe,tko),e(G7,ako),e(G7,jO),e(jO,nko),e(G7,sko),e(G,lko),e(G,O7),e(O7,Ihe),e(Ihe,iko),e(O7,dko),e(O7,DO),e(DO,cko),e(O7,fko),e(G,mko),e(G,V7),e(V7,Nhe),e(Nhe,gko),e(V7,hko),e(V7,GO),e(GO,pko),e(V7,_ko),e(G,uko),e(G,X7),e(X7,qhe),e(qhe,bko),e(X7,vko),e(X7,OO),e(OO,Fko),e(X7,Tko),e(G,Mko),e(G,z7),e(z7,jhe),e(jhe,Eko),e(z7,Cko),e(z7,VO),e(VO,wko),e(z7,Ako),e(G,Lko),e(G,W7),e(W7,Dhe),e(Dhe,yko),e(W7,xko),e(W7,XO),e(XO,$ko),e(W7,kko),e(G,Sko),e(G,Q7),e(Q7,Ghe),e(Ghe,Rko),e(Q7,Pko),e(Q7,zO),e(zO,Bko),e(Q7,Iko),e(G,Nko),e(G,H7),e(H7,Ohe),e(Ohe,qko),e(H7,jko),e(H7,WO),e(WO,Dko),e(H7,Gko),e(G,Oko),e(G,U7),e(U7,Vhe),e(Vhe,Vko),e(U7,Xko),e(U7,QO),e(QO,zko),e(U7,Wko),e(G,Qko),e(G,J7),e(J7,Xhe),e(Xhe,Hko),e(J7,Uko),e(J7,HO),e(HO,Jko),e(J7,Yko),e(G,Kko),e(G,Y7),e(Y7,zhe),e(zhe,Zko),e(Y7,eSo),e(Y7,UO),e(UO,oSo),e(Y7,rSo),e(G,tSo),e(G,K7),e(K7,Whe),e(Whe,aSo),e(K7,nSo),e(K7,JO),e(JO,sSo),e(K7,lSo),e(G,iSo),e(G,Z7),e(Z7,Qhe),e(Qhe,dSo),e(Z7,cSo),e(Z7,YO),e(YO,fSo),e(Z7,mSo),e(G,gSo),e(G,e1),e(e1,Hhe),e(Hhe,hSo),e(e1,pSo),e(e1,KO),e(KO,_So),e(e1,uSo),e(G,bSo),e(G,o1),e(o1,Uhe),e(Uhe,vSo),e(o1,FSo),e(o1,ZO),e(ZO,TSo),e(o1,MSo),e(G,ESo),e(G,r1),e(r1,Jhe),e(Jhe,CSo),e(r1,wSo),e(r1,eV),e(eV,ASo),e(r1,LSo),e(G,ySo),e(G,t1),e(t1,Yhe),e(Yhe,xSo),e(t1,$So),e(t1,oV),e(oV,kSo),e(t1,SSo),e(G,RSo),e(G,a1),e(a1,Khe),e(Khe,PSo),e(a1,BSo),e(a1,rV),e(rV,ISo),e(a1,NSo),e(G,qSo),e(G,n1),e(n1,Zhe),e(Zhe,jSo),e(n1,DSo),e(n1,tV),e(tV,GSo),e(n1,OSo),e(G,VSo),e(G,s1),e(s1,epe),e(epe,XSo),e(s1,zSo),e(s1,aV),e(aV,WSo),e(s1,QSo),e(G,HSo),e(G,l1),e(l1,ope),e(ope,USo),e(l1,JSo),e(l1,nV),e(nV,YSo),e(l1,KSo),e(G,ZSo),e(G,i1),e(i1,rpe),e(rpe,eRo),e(i1,oRo),e(i1,sV),e(sV,rRo),e(i1,tRo),e(G,aRo),e(G,d1),e(d1,tpe),e(tpe,nRo),e(d1,sRo),e(d1,lV),e(lV,lRo),e(d1,iRo),e(Ke,dRo),e(Ke,c1),e(c1,cRo),e(c1,ape),e(ape,fRo),e(c1,mRo),e(c1,npe),e(npe,gRo),e(Ke,hRo),M(f1,Ke,null),b(f,rQe,u),b(f,rd,u),e(rd,m1),e(m1,spe),M(xy,spe,null),e(rd,pRo),e(rd,lpe),e(lpe,_Ro),b(f,tQe,u),b(f,Po,u),M($y,Po,null),e(Po,uRo),e(Po,td),e(td,bRo),e(td,iV),e(iV,vRo),e(td,FRo),e(td,dV),e(dV,TRo),e(td,MRo),e(Po,ERo),e(Po,ky),e(ky,CRo),e(ky,ipe),e(ipe,wRo),e(ky,ARo),e(Po,LRo),e(Po,mt),M(Sy,mt,null),e(mt,yRo),e(mt,dpe),e(dpe,xRo),e(mt,$Ro),e(mt,ad),e(ad,kRo),e(ad,cpe),e(cpe,SRo),e(ad,RRo),e(ad,cV),e(cV,PRo),e(ad,BRo),e(mt,IRo),M(g1,mt,null),e(Po,NRo),e(Po,Ze),M(Ry,Ze,null),e(Ze,qRo),e(Ze,fpe),e(fpe,jRo),e(Ze,DRo),e(Ze,Oa),e(Oa,GRo),e(Oa,mpe),e(mpe,ORo),e(Oa,VRo),e(Oa,gpe),e(gpe,XRo),e(Oa,zRo),e(Oa,hpe),e(hpe,WRo),e(Oa,QRo),e(Ze,HRo),e(Ze,z),e(z,h1),e(h1,ppe),e(ppe,URo),e(h1,JRo),e(h1,fV),e(fV,YRo),e(h1,KRo),e(z,ZRo),e(z,p1),e(p1,_pe),e(_pe,ePo),e(p1,oPo),e(p1,mV),e(mV,rPo),e(p1,tPo),e(z,aPo),e(z,_1),e(_1,upe),e(upe,nPo),e(_1,sPo),e(_1,gV),e(gV,lPo),e(_1,iPo),e(z,dPo),e(z,u1),e(u1,bpe),e(bpe,cPo),e(u1,fPo),e(u1,hV),e(hV,mPo),e(u1,gPo),e(z,hPo),e(z,b1),e(b1,vpe),e(vpe,pPo),e(b1,_Po),e(b1,pV),e(pV,uPo),e(b1,bPo),e(z,vPo),e(z,v1),e(v1,Fpe),e(Fpe,FPo),e(v1,TPo),e(v1,_V),e(_V,MPo),e(v1,EPo),e(z,CPo),e(z,F1),e(F1,Tpe),e(Tpe,wPo),e(F1,APo),e(F1,uV),e(uV,LPo),e(F1,yPo),e(z,xPo),e(z,T1),e(T1,Mpe),e(Mpe,$Po),e(T1,kPo),e(T1,bV),e(bV,SPo),e(T1,RPo),e(z,PPo),e(z,M1),e(M1,Epe),e(Epe,BPo),e(M1,IPo),e(M1,vV),e(vV,NPo),e(M1,qPo),e(z,jPo),e(z,E1),e(E1,Cpe),e(Cpe,DPo),e(E1,GPo),e(E1,FV),e(FV,OPo),e(E1,VPo),e(z,XPo),e(z,C1),e(C1,wpe),e(wpe,zPo),e(C1,WPo),e(C1,TV),e(TV,QPo),e(C1,HPo),e(z,UPo),e(z,w1),e(w1,Ape),e(Ape,JPo),e(w1,YPo),e(w1,MV),e(MV,KPo),e(w1,ZPo),e(z,eBo),e(z,A1),e(A1,Lpe),e(Lpe,oBo),e(A1,rBo),e(A1,EV),e(EV,tBo),e(A1,aBo),e(z,nBo),e(z,L1),e(L1,ype),e(ype,sBo),e(L1,lBo),e(L1,CV),e(CV,iBo),e(L1,dBo),e(z,cBo),e(z,y1),e(y1,xpe),e(xpe,fBo),e(y1,mBo),e(y1,wV),e(wV,gBo),e(y1,hBo),e(z,pBo),e(z,x1),e(x1,$pe),e($pe,_Bo),e(x1,uBo),e(x1,AV),e(AV,bBo),e(x1,vBo),e(z,FBo),e(z,$1),e($1,kpe),e(kpe,TBo),e($1,MBo),e($1,LV),e(LV,EBo),e($1,CBo),e(z,wBo),e(z,k1),e(k1,Spe),e(Spe,ABo),e(k1,LBo),e(k1,yV),e(yV,yBo),e(k1,xBo),e(z,$Bo),e(z,S1),e(S1,Rpe),e(Rpe,kBo),e(S1,SBo),e(S1,xV),e(xV,RBo),e(S1,PBo),e(z,BBo),e(z,R1),e(R1,Ppe),e(Ppe,IBo),e(R1,NBo),e(R1,$V),e($V,qBo),e(R1,jBo),e(z,DBo),e(z,P1),e(P1,Bpe),e(Bpe,GBo),e(P1,OBo),e(P1,kV),e(kV,VBo),e(P1,XBo),e(z,zBo),e(z,B1),e(B1,Ipe),e(Ipe,WBo),e(B1,QBo),e(B1,SV),e(SV,HBo),e(B1,UBo),e(z,JBo),e(z,I1),e(I1,Npe),e(Npe,YBo),e(I1,KBo),e(I1,RV),e(RV,ZBo),e(I1,eIo),e(z,oIo),e(z,N1),e(N1,qpe),e(qpe,rIo),e(N1,tIo),e(N1,PV),e(PV,aIo),e(N1,nIo),e(z,sIo),e(z,q1),e(q1,jpe),e(jpe,lIo),e(q1,iIo),e(q1,BV),e(BV,dIo),e(q1,cIo),e(z,fIo),e(z,j1),e(j1,Dpe),e(Dpe,mIo),e(j1,gIo),e(j1,IV),e(IV,hIo),e(j1,pIo),e(z,_Io),e(z,D1),e(D1,Gpe),e(Gpe,uIo),e(D1,bIo),e(D1,NV),e(NV,vIo),e(D1,FIo),e(z,TIo),e(z,G1),e(G1,Ope),e(Ope,MIo),e(G1,EIo),e(G1,qV),e(qV,CIo),e(G1,wIo),e(z,AIo),e(z,O1),e(O1,Vpe),e(Vpe,LIo),e(O1,yIo),e(O1,jV),e(jV,xIo),e(O1,$Io),e(z,kIo),e(z,V1),e(V1,Xpe),e(Xpe,SIo),e(V1,RIo),e(V1,DV),e(DV,PIo),e(V1,BIo),e(z,IIo),e(z,X1),e(X1,zpe),e(zpe,NIo),e(X1,qIo),e(X1,GV),e(GV,jIo),e(X1,DIo),e(z,GIo),e(z,z1),e(z1,Wpe),e(Wpe,OIo),e(z1,VIo),e(z1,OV),e(OV,XIo),e(z1,zIo),e(z,WIo),e(z,W1),e(W1,Qpe),e(Qpe,QIo),e(W1,HIo),e(W1,VV),e(VV,UIo),e(W1,JIo),e(z,YIo),e(z,Q1),e(Q1,Hpe),e(Hpe,KIo),e(Q1,ZIo),e(Q1,XV),e(XV,eNo),e(Q1,oNo),e(z,rNo),e(z,H1),e(H1,Upe),e(Upe,tNo),e(H1,aNo),e(H1,zV),e(zV,nNo),e(H1,sNo),e(z,lNo),e(z,U1),e(U1,Jpe),e(Jpe,iNo),e(U1,dNo),e(U1,WV),e(WV,cNo),e(U1,fNo),e(z,mNo),e(z,J1),e(J1,Ype),e(Ype,gNo),e(J1,hNo),e(J1,QV),e(QV,pNo),e(J1,_No),e(z,uNo),e(z,Y1),e(Y1,Kpe),e(Kpe,bNo),e(Y1,vNo),e(Y1,HV),e(HV,FNo),e(Y1,TNo),e(z,MNo),e(z,K1),e(K1,Zpe),e(Zpe,ENo),e(K1,CNo),e(K1,UV),e(UV,wNo),e(K1,ANo),e(z,LNo),e(z,Z1),e(Z1,e_e),e(e_e,yNo),e(Z1,xNo),e(Z1,JV),e(JV,$No),e(Z1,kNo),e(Ze,SNo),e(Ze,e2),e(e2,RNo),e(e2,o_e),e(o_e,PNo),e(e2,BNo),e(e2,r_e),e(r_e,INo),e(Ze,NNo),M(o2,Ze,null),b(f,aQe,u),b(f,nd,u),e(nd,r2),e(r2,t_e),M(Py,t_e,null),e(nd,qNo),e(nd,a_e),e(a_e,jNo),b(f,nQe,u),b(f,Bo,u),M(By,Bo,null),e(Bo,DNo),e(Bo,sd),e(sd,GNo),e(sd,YV),e(YV,ONo),e(sd,VNo),e(sd,KV),e(KV,XNo),e(sd,zNo),e(Bo,WNo),e(Bo,Iy),e(Iy,QNo),e(Iy,n_e),e(n_e,HNo),e(Iy,UNo),e(Bo,JNo),e(Bo,gt),M(Ny,gt,null),e(gt,YNo),e(gt,s_e),e(s_e,KNo),e(gt,ZNo),e(gt,ld),e(ld,eqo),e(ld,l_e),e(l_e,oqo),e(ld,rqo),e(ld,ZV),e(ZV,tqo),e(ld,aqo),e(gt,nqo),M(t2,gt,null),e(Bo,sqo),e(Bo,eo),M(qy,eo,null),e(eo,lqo),e(eo,i_e),e(i_e,iqo),e(eo,dqo),e(eo,Va),e(Va,cqo),e(Va,d_e),e(d_e,fqo),e(Va,mqo),e(Va,c_e),e(c_e,gqo),e(Va,hqo),e(Va,f_e),e(f_e,pqo),e(Va,_qo),e(eo,uqo),e(eo,Q),e(Q,a2),e(a2,m_e),e(m_e,bqo),e(a2,vqo),e(a2,eX),e(eX,Fqo),e(a2,Tqo),e(Q,Mqo),e(Q,n2),e(n2,g_e),e(g_e,Eqo),e(n2,Cqo),e(n2,oX),e(oX,wqo),e(n2,Aqo),e(Q,Lqo),e(Q,s2),e(s2,h_e),e(h_e,yqo),e(s2,xqo),e(s2,rX),e(rX,$qo),e(s2,kqo),e(Q,Sqo),e(Q,l2),e(l2,p_e),e(p_e,Rqo),e(l2,Pqo),e(l2,tX),e(tX,Bqo),e(l2,Iqo),e(Q,Nqo),e(Q,i2),e(i2,__e),e(__e,qqo),e(i2,jqo),e(i2,aX),e(aX,Dqo),e(i2,Gqo),e(Q,Oqo),e(Q,d2),e(d2,u_e),e(u_e,Vqo),e(d2,Xqo),e(d2,nX),e(nX,zqo),e(d2,Wqo),e(Q,Qqo),e(Q,c2),e(c2,b_e),e(b_e,Hqo),e(c2,Uqo),e(c2,sX),e(sX,Jqo),e(c2,Yqo),e(Q,Kqo),e(Q,f2),e(f2,v_e),e(v_e,Zqo),e(f2,ejo),e(f2,lX),e(lX,ojo),e(f2,rjo),e(Q,tjo),e(Q,m2),e(m2,F_e),e(F_e,ajo),e(m2,njo),e(m2,iX),e(iX,sjo),e(m2,ljo),e(Q,ijo),e(Q,g2),e(g2,T_e),e(T_e,djo),e(g2,cjo),e(g2,dX),e(dX,fjo),e(g2,mjo),e(Q,gjo),e(Q,h2),e(h2,M_e),e(M_e,hjo),e(h2,pjo),e(h2,cX),e(cX,_jo),e(h2,ujo),e(Q,bjo),e(Q,p2),e(p2,E_e),e(E_e,vjo),e(p2,Fjo),e(p2,fX),e(fX,Tjo),e(p2,Mjo),e(Q,Ejo),e(Q,_2),e(_2,C_e),e(C_e,Cjo),e(_2,wjo),e(_2,mX),e(mX,Ajo),e(_2,Ljo),e(Q,yjo),e(Q,u2),e(u2,w_e),e(w_e,xjo),e(u2,$jo),e(u2,gX),e(gX,kjo),e(u2,Sjo),e(Q,Rjo),e(Q,b2),e(b2,A_e),e(A_e,Pjo),e(b2,Bjo),e(b2,hX),e(hX,Ijo),e(b2,Njo),e(Q,qjo),e(Q,v2),e(v2,L_e),e(L_e,jjo),e(v2,Djo),e(v2,pX),e(pX,Gjo),e(v2,Ojo),e(Q,Vjo),e(Q,F2),e(F2,y_e),e(y_e,Xjo),e(F2,zjo),e(F2,_X),e(_X,Wjo),e(F2,Qjo),e(Q,Hjo),e(Q,T2),e(T2,x_e),e(x_e,Ujo),e(T2,Jjo),e(T2,uX),e(uX,Yjo),e(T2,Kjo),e(Q,Zjo),e(Q,M2),e(M2,$_e),e($_e,eDo),e(M2,oDo),e(M2,bX),e(bX,rDo),e(M2,tDo),e(Q,aDo),e(Q,E2),e(E2,k_e),e(k_e,nDo),e(E2,sDo),e(E2,vX),e(vX,lDo),e(E2,iDo),e(Q,dDo),e(Q,C2),e(C2,S_e),e(S_e,cDo),e(C2,fDo),e(C2,FX),e(FX,mDo),e(C2,gDo),e(Q,hDo),e(Q,w2),e(w2,R_e),e(R_e,pDo),e(w2,_Do),e(w2,TX),e(TX,uDo),e(w2,bDo),e(Q,vDo),e(Q,A2),e(A2,P_e),e(P_e,FDo),e(A2,TDo),e(A2,MX),e(MX,MDo),e(A2,EDo),e(Q,CDo),e(Q,L2),e(L2,B_e),e(B_e,wDo),e(L2,ADo),e(L2,EX),e(EX,LDo),e(L2,yDo),e(Q,xDo),e(Q,y2),e(y2,I_e),e(I_e,$Do),e(y2,kDo),e(y2,CX),e(CX,SDo),e(y2,RDo),e(Q,PDo),e(Q,x2),e(x2,N_e),e(N_e,BDo),e(x2,IDo),e(x2,wX),e(wX,NDo),e(x2,qDo),e(Q,jDo),e(Q,$2),e($2,q_e),e(q_e,DDo),e($2,GDo),e($2,AX),e(AX,ODo),e($2,VDo),e(Q,XDo),e(Q,k2),e(k2,j_e),e(j_e,zDo),e(k2,WDo),e(k2,LX),e(LX,QDo),e(k2,HDo),e(Q,UDo),e(Q,S2),e(S2,D_e),e(D_e,JDo),e(S2,YDo),e(S2,yX),e(yX,KDo),e(S2,ZDo),e(Q,eGo),e(Q,R2),e(R2,G_e),e(G_e,oGo),e(R2,rGo),e(R2,xX),e(xX,tGo),e(R2,aGo),e(Q,nGo),e(Q,P2),e(P2,O_e),e(O_e,sGo),e(P2,lGo),e(P2,$X),e($X,iGo),e(P2,dGo),e(Q,cGo),e(Q,B2),e(B2,V_e),e(V_e,fGo),e(B2,mGo),e(B2,kX),e(kX,gGo),e(B2,hGo),e(Q,pGo),e(Q,I2),e(I2,X_e),e(X_e,_Go),e(I2,uGo),e(I2,SX),e(SX,bGo),e(I2,vGo),e(Q,FGo),e(Q,N2),e(N2,z_e),e(z_e,TGo),e(N2,MGo),e(N2,W_e),e(W_e,EGo),e(N2,CGo),e(Q,wGo),e(Q,q2),e(q2,Q_e),e(Q_e,AGo),e(q2,LGo),e(q2,RX),e(RX,yGo),e(q2,xGo),e(Q,$Go),e(Q,j2),e(j2,H_e),e(H_e,kGo),e(j2,SGo),e(j2,PX),e(PX,RGo),e(j2,PGo),e(Q,BGo),e(Q,D2),e(D2,U_e),e(U_e,IGo),e(D2,NGo),e(D2,BX),e(BX,qGo),e(D2,jGo),e(Q,DGo),e(Q,G2),e(G2,J_e),e(J_e,GGo),e(G2,OGo),e(G2,IX),e(IX,VGo),e(G2,XGo),e(eo,zGo),e(eo,O2),e(O2,WGo),e(O2,Y_e),e(Y_e,QGo),e(O2,HGo),e(O2,K_e),e(K_e,UGo),e(eo,JGo),M(V2,eo,null),b(f,sQe,u),b(f,id,u),e(id,X2),e(X2,Z_e),M(jy,Z_e,null),e(id,YGo),e(id,eue),e(eue,KGo),b(f,lQe,u),b(f,Io,u),M(Dy,Io,null),e(Io,ZGo),e(Io,dd),e(dd,eOo),e(dd,NX),e(NX,oOo),e(dd,rOo),e(dd,qX),e(qX,tOo),e(dd,aOo),e(Io,nOo),e(Io,Gy),e(Gy,sOo),e(Gy,oue),e(oue,lOo),e(Gy,iOo),e(Io,dOo),e(Io,ht),M(Oy,ht,null),e(ht,cOo),e(ht,rue),e(rue,fOo),e(ht,mOo),e(ht,cd),e(cd,gOo),e(cd,tue),e(tue,hOo),e(cd,pOo),e(cd,jX),e(jX,_Oo),e(cd,uOo),e(ht,bOo),M(z2,ht,null),e(Io,vOo),e(Io,oo),M(Vy,oo,null),e(oo,FOo),e(oo,aue),e(aue,TOo),e(oo,MOo),e(oo,Xa),e(Xa,EOo),e(Xa,nue),e(nue,COo),e(Xa,wOo),e(Xa,sue),e(sue,AOo),e(Xa,LOo),e(Xa,lue),e(lue,yOo),e(Xa,xOo),e(oo,$Oo),e(oo,me),e(me,W2),e(W2,iue),e(iue,kOo),e(W2,SOo),e(W2,DX),e(DX,ROo),e(W2,POo),e(me,BOo),e(me,Q2),e(Q2,due),e(due,IOo),e(Q2,NOo),e(Q2,GX),e(GX,qOo),e(Q2,jOo),e(me,DOo),e(me,H2),e(H2,cue),e(cue,GOo),e(H2,OOo),e(H2,OX),e(OX,VOo),e(H2,XOo),e(me,zOo),e(me,U2),e(U2,fue),e(fue,WOo),e(U2,QOo),e(U2,VX),e(VX,HOo),e(U2,UOo),e(me,JOo),e(me,J2),e(J2,mue),e(mue,YOo),e(J2,KOo),e(J2,XX),e(XX,ZOo),e(J2,eVo),e(me,oVo),e(me,Y2),e(Y2,gue),e(gue,rVo),e(Y2,tVo),e(Y2,zX),e(zX,aVo),e(Y2,nVo),e(me,sVo),e(me,K2),e(K2,hue),e(hue,lVo),e(K2,iVo),e(K2,WX),e(WX,dVo),e(K2,cVo),e(me,fVo),e(me,Z2),e(Z2,pue),e(pue,mVo),e(Z2,gVo),e(Z2,QX),e(QX,hVo),e(Z2,pVo),e(me,_Vo),e(me,eb),e(eb,_ue),e(_ue,uVo),e(eb,bVo),e(eb,HX),e(HX,vVo),e(eb,FVo),e(me,TVo),e(me,ob),e(ob,uue),e(uue,MVo),e(ob,EVo),e(ob,UX),e(UX,CVo),e(ob,wVo),e(me,AVo),e(me,rb),e(rb,bue),e(bue,LVo),e(rb,yVo),e(rb,JX),e(JX,xVo),e(rb,$Vo),e(me,kVo),e(me,tb),e(tb,vue),e(vue,SVo),e(tb,RVo),e(tb,YX),e(YX,PVo),e(tb,BVo),e(me,IVo),e(me,ab),e(ab,Fue),e(Fue,NVo),e(ab,qVo),e(ab,KX),e(KX,jVo),e(ab,DVo),e(me,GVo),e(me,nb),e(nb,Tue),e(Tue,OVo),e(nb,VVo),e(nb,ZX),e(ZX,XVo),e(nb,zVo),e(me,WVo),e(me,sb),e(sb,Mue),e(Mue,QVo),e(sb,HVo),e(sb,ez),e(ez,UVo),e(sb,JVo),e(me,YVo),e(me,lb),e(lb,Eue),e(Eue,KVo),e(lb,ZVo),e(lb,oz),e(oz,eXo),e(lb,oXo),e(me,rXo),e(me,ib),e(ib,Cue),e(Cue,tXo),e(ib,aXo),e(ib,rz),e(rz,nXo),e(ib,sXo),e(me,lXo),e(me,db),e(db,wue),e(wue,iXo),e(db,dXo),e(db,tz),e(tz,cXo),e(db,fXo),e(me,mXo),e(me,cb),e(cb,Aue),e(Aue,gXo),e(cb,hXo),e(cb,az),e(az,pXo),e(cb,_Xo),e(oo,uXo),e(oo,fb),e(fb,bXo),e(fb,Lue),e(Lue,vXo),e(fb,FXo),e(fb,yue),e(yue,TXo),e(oo,MXo),M(mb,oo,null),b(f,iQe,u),b(f,fd,u),e(fd,gb),e(gb,xue),M(Xy,xue,null),e(fd,EXo),e(fd,$ue),e($ue,CXo),b(f,dQe,u),b(f,No,u),M(zy,No,null),e(No,wXo),e(No,md),e(md,AXo),e(md,nz),e(nz,LXo),e(md,yXo),e(md,sz),e(sz,xXo),e(md,$Xo),e(No,kXo),e(No,Wy),e(Wy,SXo),e(Wy,kue),e(kue,RXo),e(Wy,PXo),e(No,BXo),e(No,pt),M(Qy,pt,null),e(pt,IXo),e(pt,Sue),e(Sue,NXo),e(pt,qXo),e(pt,gd),e(gd,jXo),e(gd,Rue),e(Rue,DXo),e(gd,GXo),e(gd,lz),e(lz,OXo),e(gd,VXo),e(pt,XXo),M(hb,pt,null),e(No,zXo),e(No,ro),M(Hy,ro,null),e(ro,WXo),e(ro,Pue),e(Pue,QXo),e(ro,HXo),e(ro,za),e(za,UXo),e(za,Bue),e(Bue,JXo),e(za,YXo),e(za,Iue),e(Iue,KXo),e(za,ZXo),e(za,Nue),e(Nue,ezo),e(za,ozo),e(ro,rzo),e(ro,B),e(B,pb),e(pb,que),e(que,tzo),e(pb,azo),e(pb,iz),e(iz,nzo),e(pb,szo),e(B,lzo),e(B,_b),e(_b,jue),e(jue,izo),e(_b,dzo),e(_b,dz),e(dz,czo),e(_b,fzo),e(B,mzo),e(B,ub),e(ub,Due),e(Due,gzo),e(ub,hzo),e(ub,cz),e(cz,pzo),e(ub,_zo),e(B,uzo),e(B,bb),e(bb,Gue),e(Gue,bzo),e(bb,vzo),e(bb,fz),e(fz,Fzo),e(bb,Tzo),e(B,Mzo),e(B,vb),e(vb,Oue),e(Oue,Ezo),e(vb,Czo),e(vb,mz),e(mz,wzo),e(vb,Azo),e(B,Lzo),e(B,Fb),e(Fb,Vue),e(Vue,yzo),e(Fb,xzo),e(Fb,gz),e(gz,$zo),e(Fb,kzo),e(B,Szo),e(B,Tb),e(Tb,Xue),e(Xue,Rzo),e(Tb,Pzo),e(Tb,hz),e(hz,Bzo),e(Tb,Izo),e(B,Nzo),e(B,Mb),e(Mb,zue),e(zue,qzo),e(Mb,jzo),e(Mb,pz),e(pz,Dzo),e(Mb,Gzo),e(B,Ozo),e(B,Eb),e(Eb,Wue),e(Wue,Vzo),e(Eb,Xzo),e(Eb,_z),e(_z,zzo),e(Eb,Wzo),e(B,Qzo),e(B,Cb),e(Cb,Que),e(Que,Hzo),e(Cb,Uzo),e(Cb,uz),e(uz,Jzo),e(Cb,Yzo),e(B,Kzo),e(B,wb),e(wb,Hue),e(Hue,Zzo),e(wb,eWo),e(wb,bz),e(bz,oWo),e(wb,rWo),e(B,tWo),e(B,Ab),e(Ab,Uue),e(Uue,aWo),e(Ab,nWo),e(Ab,vz),e(vz,sWo),e(Ab,lWo),e(B,iWo),e(B,Lb),e(Lb,Jue),e(Jue,dWo),e(Lb,cWo),e(Lb,Fz),e(Fz,fWo),e(Lb,mWo),e(B,gWo),e(B,yb),e(yb,Yue),e(Yue,hWo),e(yb,pWo),e(yb,Tz),e(Tz,_Wo),e(yb,uWo),e(B,bWo),e(B,xb),e(xb,Kue),e(Kue,vWo),e(xb,FWo),e(xb,Mz),e(Mz,TWo),e(xb,MWo),e(B,EWo),e(B,$b),e($b,Zue),e(Zue,CWo),e($b,wWo),e($b,Ez),e(Ez,AWo),e($b,LWo),e(B,yWo),e(B,kb),e(kb,e7e),e(e7e,xWo),e(kb,$Wo),e(kb,Cz),e(Cz,kWo),e(kb,SWo),e(B,RWo),e(B,Sb),e(Sb,o7e),e(o7e,PWo),e(Sb,BWo),e(Sb,wz),e(wz,IWo),e(Sb,NWo),e(B,qWo),e(B,Rb),e(Rb,r7e),e(r7e,jWo),e(Rb,DWo),e(Rb,Az),e(Az,GWo),e(Rb,OWo),e(B,VWo),e(B,Pb),e(Pb,t7e),e(t7e,XWo),e(Pb,zWo),e(Pb,Lz),e(Lz,WWo),e(Pb,QWo),e(B,HWo),e(B,Bb),e(Bb,a7e),e(a7e,UWo),e(Bb,JWo),e(Bb,yz),e(yz,YWo),e(Bb,KWo),e(B,ZWo),e(B,Ib),e(Ib,n7e),e(n7e,eQo),e(Ib,oQo),e(Ib,xz),e(xz,rQo),e(Ib,tQo),e(B,aQo),e(B,Nb),e(Nb,s7e),e(s7e,nQo),e(Nb,sQo),e(Nb,$z),e($z,lQo),e(Nb,iQo),e(B,dQo),e(B,qb),e(qb,l7e),e(l7e,cQo),e(qb,fQo),e(qb,kz),e(kz,mQo),e(qb,gQo),e(B,hQo),e(B,jb),e(jb,i7e),e(i7e,pQo),e(jb,_Qo),e(jb,Sz),e(Sz,uQo),e(jb,bQo),e(B,vQo),e(B,Db),e(Db,d7e),e(d7e,FQo),e(Db,TQo),e(Db,Rz),e(Rz,MQo),e(Db,EQo),e(B,CQo),e(B,Gb),e(Gb,c7e),e(c7e,wQo),e(Gb,AQo),e(Gb,Pz),e(Pz,LQo),e(Gb,yQo),e(B,xQo),e(B,Ob),e(Ob,f7e),e(f7e,$Qo),e(Ob,kQo),e(Ob,Bz),e(Bz,SQo),e(Ob,RQo),e(B,PQo),e(B,Vb),e(Vb,m7e),e(m7e,BQo),e(Vb,IQo),e(Vb,Iz),e(Iz,NQo),e(Vb,qQo),e(B,jQo),e(B,Xb),e(Xb,g7e),e(g7e,DQo),e(Xb,GQo),e(Xb,Nz),e(Nz,OQo),e(Xb,VQo),e(B,XQo),e(B,zb),e(zb,h7e),e(h7e,zQo),e(zb,WQo),e(zb,qz),e(qz,QQo),e(zb,HQo),e(B,UQo),e(B,Wb),e(Wb,p7e),e(p7e,JQo),e(Wb,YQo),e(Wb,jz),e(jz,KQo),e(Wb,ZQo),e(B,eHo),e(B,Qb),e(Qb,_7e),e(_7e,oHo),e(Qb,rHo),e(Qb,Dz),e(Dz,tHo),e(Qb,aHo),e(B,nHo),e(B,Hb),e(Hb,u7e),e(u7e,sHo),e(Hb,lHo),e(Hb,Gz),e(Gz,iHo),e(Hb,dHo),e(B,cHo),e(B,Ub),e(Ub,b7e),e(b7e,fHo),e(Ub,mHo),e(Ub,Oz),e(Oz,gHo),e(Ub,hHo),e(B,pHo),e(B,Jb),e(Jb,v7e),e(v7e,_Ho),e(Jb,uHo),e(Jb,Vz),e(Vz,bHo),e(Jb,vHo),e(B,FHo),e(B,Yb),e(Yb,F7e),e(F7e,THo),e(Yb,MHo),e(Yb,Xz),e(Xz,EHo),e(Yb,CHo),e(B,wHo),e(B,Kb),e(Kb,T7e),e(T7e,AHo),e(Kb,LHo),e(Kb,zz),e(zz,yHo),e(Kb,xHo),e(B,$Ho),e(B,Zb),e(Zb,M7e),e(M7e,kHo),e(Zb,SHo),e(Zb,Wz),e(Wz,RHo),e(Zb,PHo),e(B,BHo),e(B,ev),e(ev,E7e),e(E7e,IHo),e(ev,NHo),e(ev,Qz),e(Qz,qHo),e(ev,jHo),e(B,DHo),e(B,ov),e(ov,C7e),e(C7e,GHo),e(ov,OHo),e(ov,Hz),e(Hz,VHo),e(ov,XHo),e(B,zHo),e(B,rv),e(rv,w7e),e(w7e,WHo),e(rv,QHo),e(rv,Uz),e(Uz,HHo),e(rv,UHo),e(B,JHo),e(B,tv),e(tv,A7e),e(A7e,YHo),e(tv,KHo),e(tv,Jz),e(Jz,ZHo),e(tv,eUo),e(B,oUo),e(B,av),e(av,L7e),e(L7e,rUo),e(av,tUo),e(av,Yz),e(Yz,aUo),e(av,nUo),e(B,sUo),e(B,nv),e(nv,y7e),e(y7e,lUo),e(nv,iUo),e(nv,Kz),e(Kz,dUo),e(nv,cUo),e(B,fUo),e(B,sv),e(sv,x7e),e(x7e,mUo),e(sv,gUo),e(sv,Zz),e(Zz,hUo),e(sv,pUo),e(B,_Uo),e(B,lv),e(lv,$7e),e($7e,uUo),e(lv,bUo),e(lv,eW),e(eW,vUo),e(lv,FUo),e(B,TUo),e(B,iv),e(iv,k7e),e(k7e,MUo),e(iv,EUo),e(iv,oW),e(oW,CUo),e(iv,wUo),e(B,AUo),e(B,dv),e(dv,S7e),e(S7e,LUo),e(dv,yUo),e(dv,rW),e(rW,xUo),e(dv,$Uo),e(B,kUo),e(B,cv),e(cv,R7e),e(R7e,SUo),e(cv,RUo),e(cv,tW),e(tW,PUo),e(cv,BUo),e(B,IUo),e(B,fv),e(fv,P7e),e(P7e,NUo),e(fv,qUo),e(fv,aW),e(aW,jUo),e(fv,DUo),e(B,GUo),e(B,mv),e(mv,B7e),e(B7e,OUo),e(mv,VUo),e(mv,nW),e(nW,XUo),e(mv,zUo),e(ro,WUo),e(ro,gv),e(gv,QUo),e(gv,I7e),e(I7e,HUo),e(gv,UUo),e(gv,N7e),e(N7e,JUo),e(ro,YUo),M(hv,ro,null),b(f,cQe,u),b(f,hd,u),e(hd,pv),e(pv,q7e),M(Uy,q7e,null),e(hd,KUo),e(hd,j7e),e(j7e,ZUo),b(f,fQe,u),b(f,qo,u),M(Jy,qo,null),e(qo,eJo),e(qo,pd),e(pd,oJo),e(pd,sW),e(sW,rJo),e(pd,tJo),e(pd,lW),e(lW,aJo),e(pd,nJo),e(qo,sJo),e(qo,Yy),e(Yy,lJo),e(Yy,D7e),e(D7e,iJo),e(Yy,dJo),e(qo,cJo),e(qo,_t),M(Ky,_t,null),e(_t,fJo),e(_t,G7e),e(G7e,mJo),e(_t,gJo),e(_t,_d),e(_d,hJo),e(_d,O7e),e(O7e,pJo),e(_d,_Jo),e(_d,iW),e(iW,uJo),e(_d,bJo),e(_t,vJo),M(_v,_t,null),e(qo,FJo),e(qo,to),M(Zy,to,null),e(to,TJo),e(to,V7e),e(V7e,MJo),e(to,EJo),e(to,Wa),e(Wa,CJo),e(Wa,X7e),e(X7e,wJo),e(Wa,AJo),e(Wa,z7e),e(z7e,LJo),e(Wa,yJo),e(Wa,W7e),e(W7e,xJo),e(Wa,$Jo),e(to,kJo),e(to,Z),e(Z,uv),e(uv,Q7e),e(Q7e,SJo),e(uv,RJo),e(uv,dW),e(dW,PJo),e(uv,BJo),e(Z,IJo),e(Z,bv),e(bv,H7e),e(H7e,NJo),e(bv,qJo),e(bv,cW),e(cW,jJo),e(bv,DJo),e(Z,GJo),e(Z,vv),e(vv,U7e),e(U7e,OJo),e(vv,VJo),e(vv,fW),e(fW,XJo),e(vv,zJo),e(Z,WJo),e(Z,Fv),e(Fv,J7e),e(J7e,QJo),e(Fv,HJo),e(Fv,mW),e(mW,UJo),e(Fv,JJo),e(Z,YJo),e(Z,Tv),e(Tv,Y7e),e(Y7e,KJo),e(Tv,ZJo),e(Tv,gW),e(gW,eYo),e(Tv,oYo),e(Z,rYo),e(Z,Mv),e(Mv,K7e),e(K7e,tYo),e(Mv,aYo),e(Mv,hW),e(hW,nYo),e(Mv,sYo),e(Z,lYo),e(Z,Ev),e(Ev,Z7e),e(Z7e,iYo),e(Ev,dYo),e(Ev,pW),e(pW,cYo),e(Ev,fYo),e(Z,mYo),e(Z,Cv),e(Cv,e1e),e(e1e,gYo),e(Cv,hYo),e(Cv,_W),e(_W,pYo),e(Cv,_Yo),e(Z,uYo),e(Z,wv),e(wv,o1e),e(o1e,bYo),e(wv,vYo),e(wv,uW),e(uW,FYo),e(wv,TYo),e(Z,MYo),e(Z,Av),e(Av,r1e),e(r1e,EYo),e(Av,CYo),e(Av,bW),e(bW,wYo),e(Av,AYo),e(Z,LYo),e(Z,Lv),e(Lv,t1e),e(t1e,yYo),e(Lv,xYo),e(Lv,vW),e(vW,$Yo),e(Lv,kYo),e(Z,SYo),e(Z,yv),e(yv,a1e),e(a1e,RYo),e(yv,PYo),e(yv,FW),e(FW,BYo),e(yv,IYo),e(Z,NYo),e(Z,xv),e(xv,n1e),e(n1e,qYo),e(xv,jYo),e(xv,TW),e(TW,DYo),e(xv,GYo),e(Z,OYo),e(Z,$v),e($v,s1e),e(s1e,VYo),e($v,XYo),e($v,MW),e(MW,zYo),e($v,WYo),e(Z,QYo),e(Z,kv),e(kv,l1e),e(l1e,HYo),e(kv,UYo),e(kv,EW),e(EW,JYo),e(kv,YYo),e(Z,KYo),e(Z,Sv),e(Sv,i1e),e(i1e,ZYo),e(Sv,eKo),e(Sv,CW),e(CW,oKo),e(Sv,rKo),e(Z,tKo),e(Z,Rv),e(Rv,d1e),e(d1e,aKo),e(Rv,nKo),e(Rv,wW),e(wW,sKo),e(Rv,lKo),e(Z,iKo),e(Z,Pv),e(Pv,c1e),e(c1e,dKo),e(Pv,cKo),e(Pv,AW),e(AW,fKo),e(Pv,mKo),e(Z,gKo),e(Z,Bv),e(Bv,f1e),e(f1e,hKo),e(Bv,pKo),e(Bv,LW),e(LW,_Ko),e(Bv,uKo),e(Z,bKo),e(Z,Iv),e(Iv,m1e),e(m1e,vKo),e(Iv,FKo),e(Iv,yW),e(yW,TKo),e(Iv,MKo),e(Z,EKo),e(Z,Nv),e(Nv,g1e),e(g1e,CKo),e(Nv,wKo),e(Nv,xW),e(xW,AKo),e(Nv,LKo),e(Z,yKo),e(Z,qv),e(qv,h1e),e(h1e,xKo),e(qv,$Ko),e(qv,$W),e($W,kKo),e(qv,SKo),e(Z,RKo),e(Z,jv),e(jv,p1e),e(p1e,PKo),e(jv,BKo),e(jv,kW),e(kW,IKo),e(jv,NKo),e(Z,qKo),e(Z,Dv),e(Dv,_1e),e(_1e,jKo),e(Dv,DKo),e(Dv,SW),e(SW,GKo),e(Dv,OKo),e(Z,VKo),e(Z,Gv),e(Gv,u1e),e(u1e,XKo),e(Gv,zKo),e(Gv,RW),e(RW,WKo),e(Gv,QKo),e(Z,HKo),e(Z,Ov),e(Ov,b1e),e(b1e,UKo),e(Ov,JKo),e(Ov,PW),e(PW,YKo),e(Ov,KKo),e(Z,ZKo),e(Z,Vv),e(Vv,v1e),e(v1e,eZo),e(Vv,oZo),e(Vv,BW),e(BW,rZo),e(Vv,tZo),e(Z,aZo),e(Z,Xv),e(Xv,F1e),e(F1e,nZo),e(Xv,sZo),e(Xv,IW),e(IW,lZo),e(Xv,iZo),e(Z,dZo),e(Z,zv),e(zv,T1e),e(T1e,cZo),e(zv,fZo),e(zv,NW),e(NW,mZo),e(zv,gZo),e(Z,hZo),e(Z,Wv),e(Wv,M1e),e(M1e,pZo),e(Wv,_Zo),e(Wv,qW),e(qW,uZo),e(Wv,bZo),e(Z,vZo),e(Z,Qv),e(Qv,E1e),e(E1e,FZo),e(Qv,TZo),e(Qv,jW),e(jW,MZo),e(Qv,EZo),e(to,CZo),e(to,Hv),e(Hv,wZo),e(Hv,C1e),e(C1e,AZo),e(Hv,LZo),e(Hv,w1e),e(w1e,yZo),e(to,xZo),M(Uv,to,null),b(f,mQe,u),b(f,ud,u),e(ud,Jv),e(Jv,A1e),M(e8,A1e,null),e(ud,$Zo),e(ud,L1e),e(L1e,kZo),b(f,gQe,u),b(f,jo,u),M(o8,jo,null),e(jo,SZo),e(jo,bd),e(bd,RZo),e(bd,DW),e(DW,PZo),e(bd,BZo),e(bd,GW),e(GW,IZo),e(bd,NZo),e(jo,qZo),e(jo,r8),e(r8,jZo),e(r8,y1e),e(y1e,DZo),e(r8,GZo),e(jo,OZo),e(jo,ut),M(t8,ut,null),e(ut,VZo),e(ut,x1e),e(x1e,XZo),e(ut,zZo),e(ut,vd),e(vd,WZo),e(vd,$1e),e($1e,QZo),e(vd,HZo),e(vd,OW),e(OW,UZo),e(vd,JZo),e(ut,YZo),M(Yv,ut,null),e(jo,KZo),e(jo,ao),M(a8,ao,null),e(ao,ZZo),e(ao,k1e),e(k1e,eer),e(ao,oer),e(ao,Qa),e(Qa,rer),e(Qa,S1e),e(S1e,ter),e(Qa,aer),e(Qa,R1e),e(R1e,ner),e(Qa,ser),e(Qa,P1e),e(P1e,ler),e(Qa,ier),e(ao,der),e(ao,Do),e(Do,Kv),e(Kv,B1e),e(B1e,cer),e(Kv,fer),e(Kv,VW),e(VW,mer),e(Kv,ger),e(Do,her),e(Do,Zv),e(Zv,I1e),e(I1e,per),e(Zv,_er),e(Zv,XW),e(XW,uer),e(Zv,ber),e(Do,ver),e(Do,eF),e(eF,N1e),e(N1e,Fer),e(eF,Ter),e(eF,zW),e(zW,Mer),e(eF,Eer),e(Do,Cer),e(Do,oF),e(oF,q1e),e(q1e,wer),e(oF,Aer),e(oF,WW),e(WW,Ler),e(oF,yer),e(Do,xer),e(Do,rF),e(rF,j1e),e(j1e,$er),e(rF,ker),e(rF,QW),e(QW,Ser),e(rF,Rer),e(Do,Per),e(Do,tF),e(tF,D1e),e(D1e,Ber),e(tF,Ier),e(tF,HW),e(HW,Ner),e(tF,qer),e(ao,jer),e(ao,aF),e(aF,Der),e(aF,G1e),e(G1e,Ger),e(aF,Oer),e(aF,O1e),e(O1e,Ver),e(ao,Xer),M(nF,ao,null),b(f,hQe,u),b(f,Fd,u),e(Fd,sF),e(sF,V1e),M(n8,V1e,null),e(Fd,zer),e(Fd,X1e),e(X1e,Wer),b(f,pQe,u),b(f,Go,u),M(s8,Go,null),e(Go,Qer),e(Go,Td),e(Td,Her),e(Td,UW),e(UW,Uer),e(Td,Jer),e(Td,JW),e(JW,Yer),e(Td,Ker),e(Go,Zer),e(Go,l8),e(l8,eor),e(l8,z1e),e(z1e,oor),e(l8,ror),e(Go,tor),e(Go,bt),M(i8,bt,null),e(bt,aor),e(bt,W1e),e(W1e,nor),e(bt,sor),e(bt,Md),e(Md,lor),e(Md,Q1e),e(Q1e,ior),e(Md,dor),e(Md,YW),e(YW,cor),e(Md,mor),e(bt,gor),M(lF,bt,null),e(Go,hor),e(Go,no),M(d8,no,null),e(no,por),e(no,H1e),e(H1e,_or),e(no,uor),e(no,Ha),e(Ha,bor),e(Ha,U1e),e(U1e,vor),e(Ha,For),e(Ha,J1e),e(J1e,Tor),e(Ha,Mor),e(Ha,Y1e),e(Y1e,Eor),e(Ha,Cor),e(no,wor),e(no,U),e(U,iF),e(iF,K1e),e(K1e,Aor),e(iF,Lor),e(iF,KW),e(KW,yor),e(iF,xor),e(U,$or),e(U,dF),e(dF,Z1e),e(Z1e,kor),e(dF,Sor),e(dF,ZW),e(ZW,Ror),e(dF,Por),e(U,Bor),e(U,cF),e(cF,e2e),e(e2e,Ior),e(cF,Nor),e(cF,eQ),e(eQ,qor),e(cF,jor),e(U,Dor),e(U,fF),e(fF,o2e),e(o2e,Gor),e(fF,Oor),e(fF,oQ),e(oQ,Vor),e(fF,Xor),e(U,zor),e(U,mF),e(mF,r2e),e(r2e,Wor),e(mF,Qor),e(mF,rQ),e(rQ,Hor),e(mF,Uor),e(U,Jor),e(U,gF),e(gF,t2e),e(t2e,Yor),e(gF,Kor),e(gF,tQ),e(tQ,Zor),e(gF,err),e(U,orr),e(U,hF),e(hF,a2e),e(a2e,rrr),e(hF,trr),e(hF,aQ),e(aQ,arr),e(hF,nrr),e(U,srr),e(U,pF),e(pF,n2e),e(n2e,lrr),e(pF,irr),e(pF,nQ),e(nQ,drr),e(pF,crr),e(U,frr),e(U,_F),e(_F,s2e),e(s2e,mrr),e(_F,grr),e(_F,sQ),e(sQ,hrr),e(_F,prr),e(U,_rr),e(U,uF),e(uF,l2e),e(l2e,urr),e(uF,brr),e(uF,lQ),e(lQ,vrr),e(uF,Frr),e(U,Trr),e(U,bF),e(bF,i2e),e(i2e,Mrr),e(bF,Err),e(bF,iQ),e(iQ,Crr),e(bF,wrr),e(U,Arr),e(U,vF),e(vF,d2e),e(d2e,Lrr),e(vF,yrr),e(vF,dQ),e(dQ,xrr),e(vF,$rr),e(U,krr),e(U,FF),e(FF,c2e),e(c2e,Srr),e(FF,Rrr),e(FF,cQ),e(cQ,Prr),e(FF,Brr),e(U,Irr),e(U,TF),e(TF,f2e),e(f2e,Nrr),e(TF,qrr),e(TF,fQ),e(fQ,jrr),e(TF,Drr),e(U,Grr),e(U,MF),e(MF,m2e),e(m2e,Orr),e(MF,Vrr),e(MF,mQ),e(mQ,Xrr),e(MF,zrr),e(U,Wrr),e(U,EF),e(EF,g2e),e(g2e,Qrr),e(EF,Hrr),e(EF,gQ),e(gQ,Urr),e(EF,Jrr),e(U,Yrr),e(U,CF),e(CF,h2e),e(h2e,Krr),e(CF,Zrr),e(CF,hQ),e(hQ,etr),e(CF,otr),e(U,rtr),e(U,wF),e(wF,p2e),e(p2e,ttr),e(wF,atr),e(wF,pQ),e(pQ,ntr),e(wF,str),e(U,ltr),e(U,AF),e(AF,_2e),e(_2e,itr),e(AF,dtr),e(AF,_Q),e(_Q,ctr),e(AF,ftr),e(U,mtr),e(U,LF),e(LF,u2e),e(u2e,gtr),e(LF,htr),e(LF,uQ),e(uQ,ptr),e(LF,_tr),e(U,utr),e(U,yF),e(yF,b2e),e(b2e,btr),e(yF,vtr),e(yF,bQ),e(bQ,Ftr),e(yF,Ttr),e(U,Mtr),e(U,xF),e(xF,v2e),e(v2e,Etr),e(xF,Ctr),e(xF,vQ),e(vQ,wtr),e(xF,Atr),e(U,Ltr),e(U,$F),e($F,F2e),e(F2e,ytr),e($F,xtr),e($F,FQ),e(FQ,$tr),e($F,ktr),e(U,Str),e(U,kF),e(kF,T2e),e(T2e,Rtr),e(kF,Ptr),e(kF,TQ),e(TQ,Btr),e(kF,Itr),e(U,Ntr),e(U,SF),e(SF,M2e),e(M2e,qtr),e(SF,jtr),e(SF,MQ),e(MQ,Dtr),e(SF,Gtr),e(U,Otr),e(U,RF),e(RF,E2e),e(E2e,Vtr),e(RF,Xtr),e(RF,EQ),e(EQ,ztr),e(RF,Wtr),e(U,Qtr),e(U,PF),e(PF,C2e),e(C2e,Htr),e(PF,Utr),e(PF,CQ),e(CQ,Jtr),e(PF,Ytr),e(U,Ktr),e(U,BF),e(BF,w2e),e(w2e,Ztr),e(BF,ear),e(BF,wQ),e(wQ,oar),e(BF,rar),e(U,tar),e(U,IF),e(IF,A2e),e(A2e,aar),e(IF,nar),e(IF,AQ),e(AQ,sar),e(IF,lar),e(U,iar),e(U,NF),e(NF,L2e),e(L2e,dar),e(NF,car),e(NF,LQ),e(LQ,far),e(NF,mar),e(U,gar),e(U,qF),e(qF,y2e),e(y2e,har),e(qF,par),e(qF,yQ),e(yQ,_ar),e(qF,uar),e(U,bar),e(U,jF),e(jF,x2e),e(x2e,Far),e(jF,Tar),e(jF,xQ),e(xQ,Mar),e(jF,Ear),e(U,Car),e(U,DF),e(DF,$2e),e($2e,war),e(DF,Aar),e(DF,$Q),e($Q,Lar),e(DF,yar),e(U,xar),e(U,GF),e(GF,k2e),e(k2e,$ar),e(GF,kar),e(GF,kQ),e(kQ,Sar),e(GF,Rar),e(U,Par),e(U,OF),e(OF,S2e),e(S2e,Bar),e(OF,Iar),e(OF,SQ),e(SQ,Nar),e(OF,qar),e(U,jar),e(U,VF),e(VF,R2e),e(R2e,Dar),e(VF,Gar),e(VF,RQ),e(RQ,Oar),e(VF,Var),e(U,Xar),e(U,XF),e(XF,P2e),e(P2e,zar),e(XF,War),e(XF,PQ),e(PQ,Qar),e(XF,Har),e(no,Uar),e(no,zF),e(zF,Jar),e(zF,B2e),e(B2e,Yar),e(zF,Kar),e(zF,I2e),e(I2e,Zar),e(no,enr),M(WF,no,null),b(f,_Qe,u),b(f,Ed,u),e(Ed,QF),e(QF,N2e),M(c8,N2e,null),e(Ed,onr),e(Ed,q2e),e(q2e,rnr),b(f,uQe,u),b(f,Oo,u),M(f8,Oo,null),e(Oo,tnr),e(Oo,Cd),e(Cd,anr),e(Cd,BQ),e(BQ,nnr),e(Cd,snr),e(Cd,IQ),e(IQ,lnr),e(Cd,inr),e(Oo,dnr),e(Oo,m8),e(m8,cnr),e(m8,j2e),e(j2e,fnr),e(m8,mnr),e(Oo,gnr),e(Oo,vt),M(g8,vt,null),e(vt,hnr),e(vt,D2e),e(D2e,pnr),e(vt,_nr),e(vt,wd),e(wd,unr),e(wd,G2e),e(G2e,bnr),e(wd,vnr),e(wd,NQ),e(NQ,Fnr),e(wd,Tnr),e(vt,Mnr),M(HF,vt,null),e(Oo,Enr),e(Oo,so),M(h8,so,null),e(so,Cnr),e(so,O2e),e(O2e,wnr),e(so,Anr),e(so,Ua),e(Ua,Lnr),e(Ua,V2e),e(V2e,ynr),e(Ua,xnr),e(Ua,X2e),e(X2e,$nr),e(Ua,knr),e(Ua,z2e),e(z2e,Snr),e(Ua,Rnr),e(so,Pnr),e(so,V),e(V,UF),e(UF,W2e),e(W2e,Bnr),e(UF,Inr),e(UF,qQ),e(qQ,Nnr),e(UF,qnr),e(V,jnr),e(V,JF),e(JF,Q2e),e(Q2e,Dnr),e(JF,Gnr),e(JF,jQ),e(jQ,Onr),e(JF,Vnr),e(V,Xnr),e(V,YF),e(YF,H2e),e(H2e,znr),e(YF,Wnr),e(YF,DQ),e(DQ,Qnr),e(YF,Hnr),e(V,Unr),e(V,KF),e(KF,U2e),e(U2e,Jnr),e(KF,Ynr),e(KF,GQ),e(GQ,Knr),e(KF,Znr),e(V,esr),e(V,ZF),e(ZF,J2e),e(J2e,osr),e(ZF,rsr),e(ZF,OQ),e(OQ,tsr),e(ZF,asr),e(V,nsr),e(V,eT),e(eT,Y2e),e(Y2e,ssr),e(eT,lsr),e(eT,VQ),e(VQ,isr),e(eT,dsr),e(V,csr),e(V,oT),e(oT,K2e),e(K2e,fsr),e(oT,msr),e(oT,XQ),e(XQ,gsr),e(oT,hsr),e(V,psr),e(V,rT),e(rT,Z2e),e(Z2e,_sr),e(rT,usr),e(rT,zQ),e(zQ,bsr),e(rT,vsr),e(V,Fsr),e(V,tT),e(tT,ebe),e(ebe,Tsr),e(tT,Msr),e(tT,WQ),e(WQ,Esr),e(tT,Csr),e(V,wsr),e(V,aT),e(aT,obe),e(obe,Asr),e(aT,Lsr),e(aT,QQ),e(QQ,ysr),e(aT,xsr),e(V,$sr),e(V,nT),e(nT,rbe),e(rbe,ksr),e(nT,Ssr),e(nT,HQ),e(HQ,Rsr),e(nT,Psr),e(V,Bsr),e(V,sT),e(sT,tbe),e(tbe,Isr),e(sT,Nsr),e(sT,UQ),e(UQ,qsr),e(sT,jsr),e(V,Dsr),e(V,lT),e(lT,abe),e(abe,Gsr),e(lT,Osr),e(lT,JQ),e(JQ,Vsr),e(lT,Xsr),e(V,zsr),e(V,iT),e(iT,nbe),e(nbe,Wsr),e(iT,Qsr),e(iT,YQ),e(YQ,Hsr),e(iT,Usr),e(V,Jsr),e(V,dT),e(dT,sbe),e(sbe,Ysr),e(dT,Ksr),e(dT,KQ),e(KQ,Zsr),e(dT,elr),e(V,olr),e(V,cT),e(cT,lbe),e(lbe,rlr),e(cT,tlr),e(cT,ZQ),e(ZQ,alr),e(cT,nlr),e(V,slr),e(V,fT),e(fT,ibe),e(ibe,llr),e(fT,ilr),e(fT,eH),e(eH,dlr),e(fT,clr),e(V,flr),e(V,mT),e(mT,dbe),e(dbe,mlr),e(mT,glr),e(mT,oH),e(oH,hlr),e(mT,plr),e(V,_lr),e(V,gT),e(gT,cbe),e(cbe,ulr),e(gT,blr),e(gT,rH),e(rH,vlr),e(gT,Flr),e(V,Tlr),e(V,hT),e(hT,fbe),e(fbe,Mlr),e(hT,Elr),e(hT,tH),e(tH,Clr),e(hT,wlr),e(V,Alr),e(V,pT),e(pT,mbe),e(mbe,Llr),e(pT,ylr),e(pT,aH),e(aH,xlr),e(pT,$lr),e(V,klr),e(V,_T),e(_T,gbe),e(gbe,Slr),e(_T,Rlr),e(_T,nH),e(nH,Plr),e(_T,Blr),e(V,Ilr),e(V,uT),e(uT,hbe),e(hbe,Nlr),e(uT,qlr),e(uT,sH),e(sH,jlr),e(uT,Dlr),e(V,Glr),e(V,bT),e(bT,pbe),e(pbe,Olr),e(bT,Vlr),e(bT,lH),e(lH,Xlr),e(bT,zlr),e(V,Wlr),e(V,vT),e(vT,_be),e(_be,Qlr),e(vT,Hlr),e(vT,iH),e(iH,Ulr),e(vT,Jlr),e(V,Ylr),e(V,FT),e(FT,ube),e(ube,Klr),e(FT,Zlr),e(FT,dH),e(dH,eir),e(FT,oir),e(V,rir),e(V,TT),e(TT,bbe),e(bbe,tir),e(TT,air),e(TT,cH),e(cH,nir),e(TT,sir),e(V,lir),e(V,MT),e(MT,vbe),e(vbe,iir),e(MT,dir),e(MT,fH),e(fH,cir),e(MT,fir),e(V,mir),e(V,ET),e(ET,Fbe),e(Fbe,gir),e(ET,hir),e(ET,mH),e(mH,pir),e(ET,_ir),e(V,uir),e(V,CT),e(CT,Tbe),e(Tbe,bir),e(CT,vir),e(CT,gH),e(gH,Fir),e(CT,Tir),e(V,Mir),e(V,wT),e(wT,Mbe),e(Mbe,Eir),e(wT,Cir),e(wT,hH),e(hH,wir),e(wT,Air),e(V,Lir),e(V,AT),e(AT,Ebe),e(Ebe,yir),e(AT,xir),e(AT,pH),e(pH,$ir),e(AT,kir),e(V,Sir),e(V,LT),e(LT,Cbe),e(Cbe,Rir),e(LT,Pir),e(LT,_H),e(_H,Bir),e(LT,Iir),e(V,Nir),e(V,yT),e(yT,wbe),e(wbe,qir),e(yT,jir),e(yT,uH),e(uH,Dir),e(yT,Gir),e(V,Oir),e(V,xT),e(xT,Abe),e(Abe,Vir),e(xT,Xir),e(xT,bH),e(bH,zir),e(xT,Wir),e(V,Qir),e(V,$T),e($T,Lbe),e(Lbe,Hir),e($T,Uir),e($T,vH),e(vH,Jir),e($T,Yir),e(V,Kir),e(V,kT),e(kT,ybe),e(ybe,Zir),e(kT,edr),e(kT,FH),e(FH,odr),e(kT,rdr),e(V,tdr),e(V,ST),e(ST,xbe),e(xbe,adr),e(ST,ndr),e(ST,TH),e(TH,sdr),e(ST,ldr),e(V,idr),e(V,RT),e(RT,$be),e($be,ddr),e(RT,cdr),e(RT,MH),e(MH,fdr),e(RT,mdr),e(V,gdr),e(V,PT),e(PT,kbe),e(kbe,hdr),e(PT,pdr),e(PT,EH),e(EH,_dr),e(PT,udr),e(V,bdr),e(V,BT),e(BT,Sbe),e(Sbe,vdr),e(BT,Fdr),e(BT,CH),e(CH,Tdr),e(BT,Mdr),e(V,Edr),e(V,IT),e(IT,Rbe),e(Rbe,Cdr),e(IT,wdr),e(IT,wH),e(wH,Adr),e(IT,Ldr),e(V,ydr),e(V,NT),e(NT,Pbe),e(Pbe,xdr),e(NT,$dr),e(NT,AH),e(AH,kdr),e(NT,Sdr),e(so,Rdr),e(so,qT),e(qT,Pdr),e(qT,Bbe),e(Bbe,Bdr),e(qT,Idr),e(qT,Ibe),e(Ibe,Ndr),e(so,qdr),M(jT,so,null),b(f,bQe,u),b(f,Ad,u),e(Ad,DT),e(DT,Nbe),M(p8,Nbe,null),e(Ad,jdr),e(Ad,qbe),e(qbe,Ddr),b(f,vQe,u),b(f,Vo,u),M(_8,Vo,null),e(Vo,Gdr),e(Vo,Ld),e(Ld,Odr),e(Ld,LH),e(LH,Vdr),e(Ld,Xdr),e(Ld,yH),e(yH,zdr),e(Ld,Wdr),e(Vo,Qdr),e(Vo,u8),e(u8,Hdr),e(u8,jbe),e(jbe,Udr),e(u8,Jdr),e(Vo,Ydr),e(Vo,Ft),M(b8,Ft,null),e(Ft,Kdr),e(Ft,Dbe),e(Dbe,Zdr),e(Ft,ecr),e(Ft,yd),e(yd,ocr),e(yd,Gbe),e(Gbe,rcr),e(yd,tcr),e(yd,xH),e(xH,acr),e(yd,ncr),e(Ft,scr),M(GT,Ft,null),e(Vo,lcr),e(Vo,lo),M(v8,lo,null),e(lo,icr),e(lo,Obe),e(Obe,dcr),e(lo,ccr),e(lo,Ja),e(Ja,fcr),e(Ja,Vbe),e(Vbe,mcr),e(Ja,gcr),e(Ja,Xbe),e(Xbe,hcr),e(Ja,pcr),e(Ja,zbe),e(zbe,_cr),e(Ja,ucr),e(lo,bcr),e(lo,Wbe),e(Wbe,OT),e(OT,Qbe),e(Qbe,vcr),e(OT,Fcr),e(OT,$H),e($H,Tcr),e(OT,Mcr),e(lo,Ecr),e(lo,VT),e(VT,Ccr),e(VT,Hbe),e(Hbe,wcr),e(VT,Acr),e(VT,Ube),e(Ube,Lcr),e(lo,ycr),M(XT,lo,null),b(f,FQe,u),b(f,xd,u),e(xd,zT),e(zT,Jbe),M(F8,Jbe,null),e(xd,xcr),e(xd,Ybe),e(Ybe,$cr),b(f,TQe,u),b(f,Xo,u),M(T8,Xo,null),e(Xo,kcr),e(Xo,$d),e($d,Scr),e($d,kH),e(kH,Rcr),e($d,Pcr),e($d,SH),e(SH,Bcr),e($d,Icr),e(Xo,Ncr),e(Xo,M8),e(M8,qcr),e(M8,Kbe),e(Kbe,jcr),e(M8,Dcr),e(Xo,Gcr),e(Xo,Tt),M(E8,Tt,null),e(Tt,Ocr),e(Tt,Zbe),e(Zbe,Vcr),e(Tt,Xcr),e(Tt,kd),e(kd,zcr),e(kd,eve),e(eve,Wcr),e(kd,Qcr),e(kd,RH),e(RH,Hcr),e(kd,Ucr),e(Tt,Jcr),M(WT,Tt,null),e(Xo,Ycr),e(Xo,io),M(C8,io,null),e(io,Kcr),e(io,ove),e(ove,Zcr),e(io,efr),e(io,Ya),e(Ya,ofr),e(Ya,rve),e(rve,rfr),e(Ya,tfr),e(Ya,tve),e(tve,afr),e(Ya,nfr),e(Ya,ave),e(ave,sfr),e(Ya,lfr),e(io,ifr),e(io,be),e(be,QT),e(QT,nve),e(nve,dfr),e(QT,cfr),e(QT,PH),e(PH,ffr),e(QT,mfr),e(be,gfr),e(be,HT),e(HT,sve),e(sve,hfr),e(HT,pfr),e(HT,BH),e(BH,_fr),e(HT,ufr),e(be,bfr),e(be,UT),e(UT,lve),e(lve,vfr),e(UT,Ffr),e(UT,IH),e(IH,Tfr),e(UT,Mfr),e(be,Efr),e(be,JT),e(JT,ive),e(ive,Cfr),e(JT,wfr),e(JT,NH),e(NH,Afr),e(JT,Lfr),e(be,yfr),e(be,rl),e(rl,dve),e(dve,xfr),e(rl,$fr),e(rl,qH),e(qH,kfr),e(rl,Sfr),e(rl,jH),e(jH,Rfr),e(rl,Pfr),e(be,Bfr),e(be,YT),e(YT,cve),e(cve,Ifr),e(YT,Nfr),e(YT,DH),e(DH,qfr),e(YT,jfr),e(be,Dfr),e(be,tl),e(tl,fve),e(fve,Gfr),e(tl,Ofr),e(tl,GH),e(GH,Vfr),e(tl,Xfr),e(tl,OH),e(OH,zfr),e(tl,Wfr),e(be,Qfr),e(be,KT),e(KT,mve),e(mve,Hfr),e(KT,Ufr),e(KT,VH),e(VH,Jfr),e(KT,Yfr),e(be,Kfr),e(be,Mt),e(Mt,gve),e(gve,Zfr),e(Mt,emr),e(Mt,XH),e(XH,omr),e(Mt,rmr),e(Mt,zH),e(zH,tmr),e(Mt,amr),e(Mt,WH),e(WH,nmr),e(Mt,smr),e(be,lmr),e(be,ZT),e(ZT,hve),e(hve,imr),e(ZT,dmr),e(ZT,QH),e(QH,cmr),e(ZT,fmr),e(be,mmr),e(be,e9),e(e9,pve),e(pve,gmr),e(e9,hmr),e(e9,HH),e(HH,pmr),e(e9,_mr),e(be,umr),e(be,o9),e(o9,_ve),e(_ve,bmr),e(o9,vmr),e(o9,UH),e(UH,Fmr),e(o9,Tmr),e(be,Mmr),e(be,r9),e(r9,uve),e(uve,Emr),e(r9,Cmr),e(r9,JH),e(JH,wmr),e(r9,Amr),e(be,Lmr),e(be,t9),e(t9,bve),e(bve,ymr),e(t9,xmr),e(t9,YH),e(YH,$mr),e(t9,kmr),e(be,Smr),e(be,a9),e(a9,vve),e(vve,Rmr),e(a9,Pmr),e(a9,KH),e(KH,Bmr),e(a9,Imr),e(be,Nmr),e(be,n9),e(n9,Fve),e(Fve,qmr),e(n9,jmr),e(n9,ZH),e(ZH,Dmr),e(n9,Gmr),e(be,Omr),e(be,s9),e(s9,Tve),e(Tve,Vmr),e(s9,Xmr),e(s9,eU),e(eU,zmr),e(s9,Wmr),e(io,Qmr),e(io,l9),e(l9,Hmr),e(l9,Mve),e(Mve,Umr),e(l9,Jmr),e(l9,Eve),e(Eve,Ymr),e(io,Kmr),M(i9,io,null),b(f,MQe,u),b(f,Sd,u),e(Sd,d9),e(d9,Cve),M(w8,Cve,null),e(Sd,Zmr),e(Sd,wve),e(wve,egr),b(f,EQe,u),b(f,zo,u),M(A8,zo,null),e(zo,ogr),e(zo,Rd),e(Rd,rgr),e(Rd,oU),e(oU,tgr),e(Rd,agr),e(Rd,rU),e(rU,ngr),e(Rd,sgr),e(zo,lgr),e(zo,L8),e(L8,igr),e(L8,Ave),e(Ave,dgr),e(L8,cgr),e(zo,fgr),e(zo,Et),M(y8,Et,null),e(Et,mgr),e(Et,Lve),e(Lve,ggr),e(Et,hgr),e(Et,Pd),e(Pd,pgr),e(Pd,yve),e(yve,_gr),e(Pd,ugr),e(Pd,tU),e(tU,bgr),e(Pd,vgr),e(Et,Fgr),M(c9,Et,null),e(zo,Tgr),e(zo,co),M(x8,co,null),e(co,Mgr),e(co,xve),e(xve,Egr),e(co,Cgr),e(co,Ka),e(Ka,wgr),e(Ka,$ve),e($ve,Agr),e(Ka,Lgr),e(Ka,kve),e(kve,ygr),e(Ka,xgr),e(Ka,Sve),e(Sve,$gr),e(Ka,kgr),e(co,Sgr),e(co,Rve),e(Rve,f9),e(f9,Pve),e(Pve,Rgr),e(f9,Pgr),e(f9,aU),e(aU,Bgr),e(f9,Igr),e(co,Ngr),e(co,m9),e(m9,qgr),e(m9,Bve),e(Bve,jgr),e(m9,Dgr),e(m9,Ive),e(Ive,Ggr),e(co,Ogr),M(g9,co,null),b(f,CQe,u),b(f,Bd,u),e(Bd,h9),e(h9,Nve),M($8,Nve,null),e(Bd,Vgr),e(Bd,qve),e(qve,Xgr),b(f,wQe,u),b(f,Wo,u),M(k8,Wo,null),e(Wo,zgr),e(Wo,Id),e(Id,Wgr),e(Id,nU),e(nU,Qgr),e(Id,Hgr),e(Id,sU),e(sU,Ugr),e(Id,Jgr),e(Wo,Ygr),e(Wo,S8),e(S8,Kgr),e(S8,jve),e(jve,Zgr),e(S8,ehr),e(Wo,ohr),e(Wo,Ct),M(R8,Ct,null),e(Ct,rhr),e(Ct,Dve),e(Dve,thr),e(Ct,ahr),e(Ct,Nd),e(Nd,nhr),e(Nd,Gve),e(Gve,shr),e(Nd,lhr),e(Nd,lU),e(lU,ihr),e(Nd,dhr),e(Ct,chr),M(p9,Ct,null),e(Wo,fhr),e(Wo,fo),M(P8,fo,null),e(fo,mhr),e(fo,Ove),e(Ove,ghr),e(fo,hhr),e(fo,Za),e(Za,phr),e(Za,Vve),e(Vve,_hr),e(Za,uhr),e(Za,Xve),e(Xve,bhr),e(Za,vhr),e(Za,zve),e(zve,Fhr),e(Za,Thr),e(fo,Mhr),e(fo,Wve),e(Wve,_9),e(_9,Qve),e(Qve,Ehr),e(_9,Chr),e(_9,iU),e(iU,whr),e(_9,Ahr),e(fo,Lhr),e(fo,u9),e(u9,yhr),e(u9,Hve),e(Hve,xhr),e(u9,$hr),e(u9,Uve),e(Uve,khr),e(fo,Shr),M(b9,fo,null),b(f,AQe,u),b(f,qd,u),e(qd,v9),e(v9,Jve),M(B8,Jve,null),e(qd,Rhr),e(qd,Yve),e(Yve,Phr),b(f,LQe,u),b(f,Qo,u),M(I8,Qo,null),e(Qo,Bhr),e(Qo,jd),e(jd,Ihr),e(jd,dU),e(dU,Nhr),e(jd,qhr),e(jd,cU),e(cU,jhr),e(jd,Dhr),e(Qo,Ghr),e(Qo,N8),e(N8,Ohr),e(N8,Kve),e(Kve,Vhr),e(N8,Xhr),e(Qo,zhr),e(Qo,wt),M(q8,wt,null),e(wt,Whr),e(wt,Zve),e(Zve,Qhr),e(wt,Hhr),e(wt,Dd),e(Dd,Uhr),e(Dd,eFe),e(eFe,Jhr),e(Dd,Yhr),e(Dd,fU),e(fU,Khr),e(Dd,Zhr),e(wt,epr),M(F9,wt,null),e(Qo,opr),e(Qo,mo),M(j8,mo,null),e(mo,rpr),e(mo,oFe),e(oFe,tpr),e(mo,apr),e(mo,en),e(en,npr),e(en,rFe),e(rFe,spr),e(en,lpr),e(en,tFe),e(tFe,ipr),e(en,dpr),e(en,aFe),e(aFe,cpr),e(en,fpr),e(mo,mpr),e(mo,nFe),e(nFe,T9),e(T9,sFe),e(sFe,gpr),e(T9,hpr),e(T9,mU),e(mU,ppr),e(T9,_pr),e(mo,upr),e(mo,M9),e(M9,bpr),e(M9,lFe),e(lFe,vpr),e(M9,Fpr),e(M9,iFe),e(iFe,Tpr),e(mo,Mpr),M(E9,mo,null),b(f,yQe,u),b(f,Gd,u),e(Gd,C9),e(C9,dFe),M(D8,dFe,null),e(Gd,Epr),e(Gd,cFe),e(cFe,Cpr),b(f,xQe,u),b(f,Ho,u),M(G8,Ho,null),e(Ho,wpr),e(Ho,Od),e(Od,Apr),e(Od,gU),e(gU,Lpr),e(Od,ypr),e(Od,hU),e(hU,xpr),e(Od,$pr),e(Ho,kpr),e(Ho,O8),e(O8,Spr),e(O8,fFe),e(fFe,Rpr),e(O8,Ppr),e(Ho,Bpr),e(Ho,At),M(V8,At,null),e(At,Ipr),e(At,mFe),e(mFe,Npr),e(At,qpr),e(At,Vd),e(Vd,jpr),e(Vd,gFe),e(gFe,Dpr),e(Vd,Gpr),e(Vd,pU),e(pU,Opr),e(Vd,Vpr),e(At,Xpr),M(w9,At,null),e(Ho,zpr),e(Ho,go),M(X8,go,null),e(go,Wpr),e(go,hFe),e(hFe,Qpr),e(go,Hpr),e(go,on),e(on,Upr),e(on,pFe),e(pFe,Jpr),e(on,Ypr),e(on,_Fe),e(_Fe,Kpr),e(on,Zpr),e(on,uFe),e(uFe,e_r),e(on,o_r),e(go,r_r),e(go,Pe),e(Pe,A9),e(A9,bFe),e(bFe,t_r),e(A9,a_r),e(A9,_U),e(_U,n_r),e(A9,s_r),e(Pe,l_r),e(Pe,L9),e(L9,vFe),e(vFe,i_r),e(L9,d_r),e(L9,uU),e(uU,c_r),e(L9,f_r),e(Pe,m_r),e(Pe,y9),e(y9,FFe),e(FFe,g_r),e(y9,h_r),e(y9,bU),e(bU,p_r),e(y9,__r),e(Pe,u_r),e(Pe,x9),e(x9,TFe),e(TFe,b_r),e(x9,v_r),e(x9,vU),e(vU,F_r),e(x9,T_r),e(Pe,M_r),e(Pe,$9),e($9,MFe),e(MFe,E_r),e($9,C_r),e($9,FU),e(FU,w_r),e($9,A_r),e(Pe,L_r),e(Pe,k9),e(k9,EFe),e(EFe,y_r),e(k9,x_r),e(k9,TU),e(TU,$_r),e(k9,k_r),e(Pe,S_r),e(Pe,S9),e(S9,CFe),e(CFe,R_r),e(S9,P_r),e(S9,MU),e(MU,B_r),e(S9,I_r),e(Pe,N_r),e(Pe,R9),e(R9,wFe),e(wFe,q_r),e(R9,j_r),e(R9,EU),e(EU,D_r),e(R9,G_r),e(Pe,O_r),e(Pe,P9),e(P9,AFe),e(AFe,V_r),e(P9,X_r),e(P9,CU),e(CU,z_r),e(P9,W_r),e(go,Q_r),e(go,B9),e(B9,H_r),e(B9,LFe),e(LFe,U_r),e(B9,J_r),e(B9,yFe),e(yFe,Y_r),e(go,K_r),M(I9,go,null),b(f,$Qe,u),b(f,Xd,u),e(Xd,N9),e(N9,xFe),M(z8,xFe,null),e(Xd,Z_r),e(Xd,$Fe),e($Fe,eur),b(f,kQe,u),b(f,Uo,u),M(W8,Uo,null),e(Uo,our),e(Uo,zd),e(zd,rur),e(zd,wU),e(wU,tur),e(zd,aur),e(zd,AU),e(AU,nur),e(zd,sur),e(Uo,lur),e(Uo,Q8),e(Q8,iur),e(Q8,kFe),e(kFe,dur),e(Q8,cur),e(Uo,fur),e(Uo,Lt),M(H8,Lt,null),e(Lt,mur),e(Lt,SFe),e(SFe,gur),e(Lt,hur),e(Lt,Wd),e(Wd,pur),e(Wd,RFe),e(RFe,_ur),e(Wd,uur),e(Wd,LU),e(LU,bur),e(Wd,vur),e(Lt,Fur),M(q9,Lt,null),e(Uo,Tur),e(Uo,ho),M(U8,ho,null),e(ho,Mur),e(ho,PFe),e(PFe,Eur),e(ho,Cur),e(ho,rn),e(rn,wur),e(rn,BFe),e(BFe,Aur),e(rn,Lur),e(rn,IFe),e(IFe,yur),e(rn,xur),e(rn,NFe),e(NFe,$ur),e(rn,kur),e(ho,Sur),e(ho,at),e(at,j9),e(j9,qFe),e(qFe,Rur),e(j9,Pur),e(j9,yU),e(yU,Bur),e(j9,Iur),e(at,Nur),e(at,D9),e(D9,jFe),e(jFe,qur),e(D9,jur),e(D9,xU),e(xU,Dur),e(D9,Gur),e(at,Our),e(at,G9),e(G9,DFe),e(DFe,Vur),e(G9,Xur),e(G9,$U),e($U,zur),e(G9,Wur),e(at,Qur),e(at,O9),e(O9,GFe),e(GFe,Hur),e(O9,Uur),e(O9,kU),e(kU,Jur),e(O9,Yur),e(at,Kur),e(at,V9),e(V9,OFe),e(OFe,Zur),e(V9,e7r),e(V9,SU),e(SU,o7r),e(V9,r7r),e(ho,t7r),e(ho,X9),e(X9,a7r),e(X9,VFe),e(VFe,n7r),e(X9,s7r),e(X9,XFe),e(XFe,l7r),e(ho,i7r),M(z9,ho,null),b(f,SQe,u),b(f,Qd,u),e(Qd,W9),e(W9,zFe),M(J8,zFe,null),e(Qd,d7r),e(Qd,WFe),e(WFe,c7r),b(f,RQe,u),b(f,Jo,u),M(Y8,Jo,null),e(Jo,f7r),e(Jo,Hd),e(Hd,m7r),e(Hd,RU),e(RU,g7r),e(Hd,h7r),e(Hd,PU),e(PU,p7r),e(Hd,_7r),e(Jo,u7r),e(Jo,K8),e(K8,b7r),e(K8,QFe),e(QFe,v7r),e(K8,F7r),e(Jo,T7r),e(Jo,yt),M(Z8,yt,null),e(yt,M7r),e(yt,HFe),e(HFe,E7r),e(yt,C7r),e(yt,Ud),e(Ud,w7r),e(Ud,UFe),e(UFe,A7r),e(Ud,L7r),e(Ud,BU),e(BU,y7r),e(Ud,x7r),e(yt,$7r),M(Q9,yt,null),e(Jo,k7r),e(Jo,po),M(ex,po,null),e(po,S7r),e(po,JFe),e(JFe,R7r),e(po,P7r),e(po,tn),e(tn,B7r),e(tn,YFe),e(YFe,I7r),e(tn,N7r),e(tn,KFe),e(KFe,q7r),e(tn,j7r),e(tn,ZFe),e(ZFe,D7r),e(tn,G7r),e(po,O7r),e(po,Le),e(Le,H9),e(H9,eTe),e(eTe,V7r),e(H9,X7r),e(H9,IU),e(IU,z7r),e(H9,W7r),e(Le,Q7r),e(Le,U9),e(U9,oTe),e(oTe,H7r),e(U9,U7r),e(U9,NU),e(NU,J7r),e(U9,Y7r),e(Le,K7r),e(Le,J9),e(J9,rTe),e(rTe,Z7r),e(J9,e1r),e(J9,qU),e(qU,o1r),e(J9,r1r),e(Le,t1r),e(Le,Y9),e(Y9,tTe),e(tTe,a1r),e(Y9,n1r),e(Y9,jU),e(jU,s1r),e(Y9,l1r),e(Le,i1r),e(Le,K9),e(K9,aTe),e(aTe,d1r),e(K9,c1r),e(K9,DU),e(DU,f1r),e(K9,m1r),e(Le,g1r),e(Le,Z9),e(Z9,nTe),e(nTe,h1r),e(Z9,p1r),e(Z9,GU),e(GU,_1r),e(Z9,u1r),e(Le,b1r),e(Le,eM),e(eM,sTe),e(sTe,v1r),e(eM,F1r),e(eM,OU),e(OU,T1r),e(eM,M1r),e(Le,E1r),e(Le,oM),e(oM,lTe),e(lTe,C1r),e(oM,w1r),e(oM,VU),e(VU,A1r),e(oM,L1r),e(Le,y1r),e(Le,rM),e(rM,iTe),e(iTe,x1r),e(rM,$1r),e(rM,XU),e(XU,k1r),e(rM,S1r),e(Le,R1r),e(Le,tM),e(tM,dTe),e(dTe,P1r),e(tM,B1r),e(tM,zU),e(zU,I1r),e(tM,N1r),e(po,q1r),e(po,aM),e(aM,j1r),e(aM,cTe),e(cTe,D1r),e(aM,G1r),e(aM,fTe),e(fTe,O1r),e(po,V1r),M(nM,po,null),b(f,PQe,u),b(f,Jd,u),e(Jd,sM),e(sM,mTe),M(ox,mTe,null),e(Jd,X1r),e(Jd,gTe),e(gTe,z1r),b(f,BQe,u),b(f,Yo,u),M(rx,Yo,null),e(Yo,W1r),e(Yo,Yd),e(Yd,Q1r),e(Yd,WU),e(WU,H1r),e(Yd,U1r),e(Yd,QU),e(QU,J1r),e(Yd,Y1r),e(Yo,K1r),e(Yo,tx),e(tx,Z1r),e(tx,hTe),e(hTe,e2r),e(tx,o2r),e(Yo,r2r),e(Yo,xt),M(ax,xt,null),e(xt,t2r),e(xt,pTe),e(pTe,a2r),e(xt,n2r),e(xt,Kd),e(Kd,s2r),e(Kd,_Te),e(_Te,l2r),e(Kd,i2r),e(Kd,HU),e(HU,d2r),e(Kd,c2r),e(xt,f2r),M(lM,xt,null),e(Yo,m2r),e(Yo,_o),M(nx,_o,null),e(_o,g2r),e(_o,uTe),e(uTe,h2r),e(_o,p2r),e(_o,an),e(an,_2r),e(an,bTe),e(bTe,u2r),e(an,b2r),e(an,vTe),e(vTe,v2r),e(an,F2r),e(an,FTe),e(FTe,T2r),e(an,M2r),e(_o,E2r),e(_o,sx),e(sx,iM),e(iM,TTe),e(TTe,C2r),e(iM,w2r),e(iM,UU),e(UU,A2r),e(iM,L2r),e(sx,y2r),e(sx,dM),e(dM,MTe),e(MTe,x2r),e(dM,$2r),e(dM,JU),e(JU,k2r),e(dM,S2r),e(_o,R2r),e(_o,cM),e(cM,P2r),e(cM,ETe),e(ETe,B2r),e(cM,I2r),e(cM,CTe),e(CTe,N2r),e(_o,q2r),M(fM,_o,null),b(f,IQe,u),b(f,Zd,u),e(Zd,mM),e(mM,wTe),M(lx,wTe,null),e(Zd,j2r),e(Zd,ATe),e(ATe,D2r),b(f,NQe,u),b(f,Ko,u),M(ix,Ko,null),e(Ko,G2r),e(Ko,ec),e(ec,O2r),e(ec,YU),e(YU,V2r),e(ec,X2r),e(ec,KU),e(KU,z2r),e(ec,W2r),e(Ko,Q2r),e(Ko,dx),e(dx,H2r),e(dx,LTe),e(LTe,U2r),e(dx,J2r),e(Ko,Y2r),e(Ko,$t),M(cx,$t,null),e($t,K2r),e($t,yTe),e(yTe,Z2r),e($t,ebr),e($t,oc),e(oc,obr),e(oc,xTe),e(xTe,rbr),e(oc,tbr),e(oc,ZU),e(ZU,abr),e(oc,nbr),e($t,sbr),M(gM,$t,null),e(Ko,lbr),e(Ko,uo),M(fx,uo,null),e(uo,ibr),e(uo,$Te),e($Te,dbr),e(uo,cbr),e(uo,nn),e(nn,fbr),e(nn,kTe),e(kTe,mbr),e(nn,gbr),e(nn,STe),e(STe,hbr),e(nn,pbr),e(nn,RTe),e(RTe,_br),e(nn,ubr),e(uo,bbr),e(uo,nt),e(nt,hM),e(hM,PTe),e(PTe,vbr),e(hM,Fbr),e(hM,eJ),e(eJ,Tbr),e(hM,Mbr),e(nt,Ebr),e(nt,pM),e(pM,BTe),e(BTe,Cbr),e(pM,wbr),e(pM,oJ),e(oJ,Abr),e(pM,Lbr),e(nt,ybr),e(nt,_M),e(_M,ITe),e(ITe,xbr),e(_M,$br),e(_M,rJ),e(rJ,kbr),e(_M,Sbr),e(nt,Rbr),e(nt,uM),e(uM,NTe),e(NTe,Pbr),e(uM,Bbr),e(uM,tJ),e(tJ,Ibr),e(uM,Nbr),e(nt,qbr),e(nt,bM),e(bM,qTe),e(qTe,jbr),e(bM,Dbr),e(bM,aJ),e(aJ,Gbr),e(bM,Obr),e(uo,Vbr),e(uo,vM),e(vM,Xbr),e(vM,jTe),e(jTe,zbr),e(vM,Wbr),e(vM,DTe),e(DTe,Qbr),e(uo,Hbr),M(FM,uo,null),b(f,qQe,u),b(f,rc,u),e(rc,TM),e(TM,GTe),M(mx,GTe,null),e(rc,Ubr),e(rc,OTe),e(OTe,Jbr),b(f,jQe,u),b(f,Zo,u),M(gx,Zo,null),e(Zo,Ybr),e(Zo,tc),e(tc,Kbr),e(tc,nJ),e(nJ,Zbr),e(tc,evr),e(tc,sJ),e(sJ,ovr),e(tc,rvr),e(Zo,tvr),e(Zo,hx),e(hx,avr),e(hx,VTe),e(VTe,nvr),e(hx,svr),e(Zo,lvr),e(Zo,kt),M(px,kt,null),e(kt,ivr),e(kt,XTe),e(XTe,dvr),e(kt,cvr),e(kt,ac),e(ac,fvr),e(ac,zTe),e(zTe,mvr),e(ac,gvr),e(ac,lJ),e(lJ,hvr),e(ac,pvr),e(kt,_vr),M(MM,kt,null),e(Zo,uvr),e(Zo,bo),M(_x,bo,null),e(bo,bvr),e(bo,WTe),e(WTe,vvr),e(bo,Fvr),e(bo,sn),e(sn,Tvr),e(sn,QTe),e(QTe,Mvr),e(sn,Evr),e(sn,HTe),e(HTe,Cvr),e(sn,wvr),e(sn,UTe),e(UTe,Avr),e(sn,Lvr),e(bo,yvr),e(bo,ln),e(ln,EM),e(EM,JTe),e(JTe,xvr),e(EM,$vr),e(EM,iJ),e(iJ,kvr),e(EM,Svr),e(ln,Rvr),e(ln,CM),e(CM,YTe),e(YTe,Pvr),e(CM,Bvr),e(CM,dJ),e(dJ,Ivr),e(CM,Nvr),e(ln,qvr),e(ln,wM),e(wM,KTe),e(KTe,jvr),e(wM,Dvr),e(wM,cJ),e(cJ,Gvr),e(wM,Ovr),e(ln,Vvr),e(ln,AM),e(AM,ZTe),e(ZTe,Xvr),e(AM,zvr),e(AM,fJ),e(fJ,Wvr),e(AM,Qvr),e(bo,Hvr),e(bo,LM),e(LM,Uvr),e(LM,e9e),e(e9e,Jvr),e(LM,Yvr),e(LM,o9e),e(o9e,Kvr),e(bo,Zvr),M(yM,bo,null),b(f,DQe,u),b(f,nc,u),e(nc,xM),e(xM,r9e),M(ux,r9e,null),e(nc,eFr),e(nc,t9e),e(t9e,oFr),b(f,GQe,u),b(f,er,u),M(bx,er,null),e(er,rFr),e(er,sc),e(sc,tFr),e(sc,mJ),e(mJ,aFr),e(sc,nFr),e(sc,gJ),e(gJ,sFr),e(sc,lFr),e(er,iFr),e(er,vx),e(vx,dFr),e(vx,a9e),e(a9e,cFr),e(vx,fFr),e(er,mFr),e(er,St),M(Fx,St,null),e(St,gFr),e(St,n9e),e(n9e,hFr),e(St,pFr),e(St,lc),e(lc,_Fr),e(lc,s9e),e(s9e,uFr),e(lc,bFr),e(lc,hJ),e(hJ,vFr),e(lc,FFr),e(St,TFr),M($M,St,null),e(er,MFr),e(er,vo),M(Tx,vo,null),e(vo,EFr),e(vo,l9e),e(l9e,CFr),e(vo,wFr),e(vo,dn),e(dn,AFr),e(dn,i9e),e(i9e,LFr),e(dn,yFr),e(dn,d9e),e(d9e,xFr),e(dn,$Fr),e(dn,c9e),e(c9e,kFr),e(dn,SFr),e(vo,RFr),e(vo,Mx),e(Mx,kM),e(kM,f9e),e(f9e,PFr),e(kM,BFr),e(kM,pJ),e(pJ,IFr),e(kM,NFr),e(Mx,qFr),e(Mx,SM),e(SM,m9e),e(m9e,jFr),e(SM,DFr),e(SM,_J),e(_J,GFr),e(SM,OFr),e(vo,VFr),e(vo,RM),e(RM,XFr),e(RM,g9e),e(g9e,zFr),e(RM,WFr),e(RM,h9e),e(h9e,QFr),e(vo,HFr),M(PM,vo,null),b(f,OQe,u),b(f,ic,u),e(ic,BM),e(BM,p9e),M(Ex,p9e,null),e(ic,UFr),e(ic,_9e),e(_9e,JFr),b(f,VQe,u),b(f,or,u),M(Cx,or,null),e(or,YFr),e(or,dc),e(dc,KFr),e(dc,uJ),e(uJ,ZFr),e(dc,eTr),e(dc,bJ),e(bJ,oTr),e(dc,rTr),e(or,tTr),e(or,wx),e(wx,aTr),e(wx,u9e),e(u9e,nTr),e(wx,sTr),e(or,lTr),e(or,Rt),M(Ax,Rt,null),e(Rt,iTr),e(Rt,b9e),e(b9e,dTr),e(Rt,cTr),e(Rt,cc),e(cc,fTr),e(cc,v9e),e(v9e,mTr),e(cc,gTr),e(cc,vJ),e(vJ,hTr),e(cc,pTr),e(Rt,_Tr),M(IM,Rt,null),e(or,uTr),e(or,Fo),M(Lx,Fo,null),e(Fo,bTr),e(Fo,F9e),e(F9e,vTr),e(Fo,FTr),e(Fo,cn),e(cn,TTr),e(cn,T9e),e(T9e,MTr),e(cn,ETr),e(cn,M9e),e(M9e,CTr),e(cn,wTr),e(cn,E9e),e(E9e,ATr),e(cn,LTr),e(Fo,yTr),e(Fo,C9e),e(C9e,NM),e(NM,w9e),e(w9e,xTr),e(NM,$Tr),e(NM,FJ),e(FJ,kTr),e(NM,STr),e(Fo,RTr),e(Fo,qM),e(qM,PTr),e(qM,A9e),e(A9e,BTr),e(qM,ITr),e(qM,L9e),e(L9e,NTr),e(Fo,qTr),M(jM,Fo,null),b(f,XQe,u),b(f,fc,u),e(fc,DM),e(DM,y9e),M(yx,y9e,null),e(fc,jTr),e(fc,x9e),e(x9e,DTr),b(f,zQe,u),b(f,rr,u),M(xx,rr,null),e(rr,GTr),e(rr,mc),e(mc,OTr),e(mc,TJ),e(TJ,VTr),e(mc,XTr),e(mc,MJ),e(MJ,zTr),e(mc,WTr),e(rr,QTr),e(rr,$x),e($x,HTr),e($x,$9e),e($9e,UTr),e($x,JTr),e(rr,YTr),e(rr,Pt),M(kx,Pt,null),e(Pt,KTr),e(Pt,k9e),e(k9e,ZTr),e(Pt,e9r),e(Pt,gc),e(gc,o9r),e(gc,S9e),e(S9e,r9r),e(gc,t9r),e(gc,EJ),e(EJ,a9r),e(gc,n9r),e(Pt,s9r),M(GM,Pt,null),e(rr,l9r),e(rr,To),M(Sx,To,null),e(To,i9r),e(To,R9e),e(R9e,d9r),e(To,c9r),e(To,fn),e(fn,f9r),e(fn,P9e),e(P9e,m9r),e(fn,g9r),e(fn,B9e),e(B9e,h9r),e(fn,p9r),e(fn,I9e),e(I9e,_9r),e(fn,u9r),e(To,b9r),e(To,st),e(st,OM),e(OM,N9e),e(N9e,v9r),e(OM,F9r),e(OM,CJ),e(CJ,T9r),e(OM,M9r),e(st,E9r),e(st,VM),e(VM,q9e),e(q9e,C9r),e(VM,w9r),e(VM,wJ),e(wJ,A9r),e(VM,L9r),e(st,y9r),e(st,XM),e(XM,j9e),e(j9e,x9r),e(XM,$9r),e(XM,AJ),e(AJ,k9r),e(XM,S9r),e(st,R9r),e(st,zM),e(zM,D9e),e(D9e,P9r),e(zM,B9r),e(zM,LJ),e(LJ,I9r),e(zM,N9r),e(st,q9r),e(st,WM),e(WM,G9e),e(G9e,j9r),e(WM,D9r),e(WM,yJ),e(yJ,G9r),e(WM,O9r),e(To,V9r),e(To,QM),e(QM,X9r),e(QM,O9e),e(O9e,z9r),e(QM,W9r),e(QM,V9e),e(V9e,Q9r),e(To,H9r),M(HM,To,null),b(f,WQe,u),b(f,hc,u),e(hc,UM),e(UM,X9e),M(Rx,X9e,null),e(hc,U9r),e(hc,z9e),e(z9e,J9r),b(f,QQe,u),b(f,tr,u),M(Px,tr,null),e(tr,Y9r),e(tr,pc),e(pc,K9r),e(pc,xJ),e(xJ,Z9r),e(pc,eMr),e(pc,$J),e($J,oMr),e(pc,rMr),e(tr,tMr),e(tr,Bx),e(Bx,aMr),e(Bx,W9e),e(W9e,nMr),e(Bx,sMr),e(tr,lMr),e(tr,Bt),M(Ix,Bt,null),e(Bt,iMr),e(Bt,Q9e),e(Q9e,dMr),e(Bt,cMr),e(Bt,_c),e(_c,fMr),e(_c,H9e),e(H9e,mMr),e(_c,gMr),e(_c,kJ),e(kJ,hMr),e(_c,pMr),e(Bt,_Mr),M(JM,Bt,null),e(tr,uMr),e(tr,Mo),M(Nx,Mo,null),e(Mo,bMr),e(Mo,U9e),e(U9e,vMr),e(Mo,FMr),e(Mo,mn),e(mn,TMr),e(mn,J9e),e(J9e,MMr),e(mn,EMr),e(mn,Y9e),e(Y9e,CMr),e(mn,wMr),e(mn,K9e),e(K9e,AMr),e(mn,LMr),e(Mo,yMr),e(Mo,Z9e),e(Z9e,YM),e(YM,eMe),e(eMe,xMr),e(YM,$Mr),e(YM,SJ),e(SJ,kMr),e(YM,SMr),e(Mo,RMr),e(Mo,KM),e(KM,PMr),e(KM,oMe),e(oMe,BMr),e(KM,IMr),e(KM,rMe),e(rMe,NMr),e(Mo,qMr),M(ZM,Mo,null),b(f,HQe,u),b(f,uc,u),e(uc,eE),e(eE,tMe),M(qx,tMe,null),e(uc,jMr),e(uc,aMe),e(aMe,DMr),b(f,UQe,u),b(f,ar,u),M(jx,ar,null),e(ar,GMr),e(ar,bc),e(bc,OMr),e(bc,RJ),e(RJ,VMr),e(bc,XMr),e(bc,PJ),e(PJ,zMr),e(bc,WMr),e(ar,QMr),e(ar,Dx),e(Dx,HMr),e(Dx,nMe),e(nMe,UMr),e(Dx,JMr),e(ar,YMr),e(ar,It),M(Gx,It,null),e(It,KMr),e(It,sMe),e(sMe,ZMr),e(It,eEr),e(It,vc),e(vc,oEr),e(vc,lMe),e(lMe,rEr),e(vc,tEr),e(vc,BJ),e(BJ,aEr),e(vc,nEr),e(It,sEr),M(oE,It,null),e(ar,lEr),e(ar,Sr),M(Ox,Sr,null),e(Sr,iEr),e(Sr,iMe),e(iMe,dEr),e(Sr,cEr),e(Sr,gn),e(gn,fEr),e(gn,dMe),e(dMe,mEr),e(gn,gEr),e(gn,cMe),e(cMe,hEr),e(gn,pEr),e(gn,fMe),e(fMe,_Er),e(gn,uEr),e(Sr,bEr),e(Sr,q),e(q,rE),e(rE,mMe),e(mMe,vEr),e(rE,FEr),e(rE,IJ),e(IJ,TEr),e(rE,MEr),e(q,EEr),e(q,tE),e(tE,gMe),e(gMe,CEr),e(tE,wEr),e(tE,NJ),e(NJ,AEr),e(tE,LEr),e(q,yEr),e(q,aE),e(aE,hMe),e(hMe,xEr),e(aE,$Er),e(aE,qJ),e(qJ,kEr),e(aE,SEr),e(q,REr),e(q,nE),e(nE,pMe),e(pMe,PEr),e(nE,BEr),e(nE,jJ),e(jJ,IEr),e(nE,NEr),e(q,qEr),e(q,sE),e(sE,_Me),e(_Me,jEr),e(sE,DEr),e(sE,DJ),e(DJ,GEr),e(sE,OEr),e(q,VEr),e(q,lE),e(lE,uMe),e(uMe,XEr),e(lE,zEr),e(lE,GJ),e(GJ,WEr),e(lE,QEr),e(q,HEr),e(q,iE),e(iE,bMe),e(bMe,UEr),e(iE,JEr),e(iE,OJ),e(OJ,YEr),e(iE,KEr),e(q,ZEr),e(q,dE),e(dE,vMe),e(vMe,e4r),e(dE,o4r),e(dE,VJ),e(VJ,r4r),e(dE,t4r),e(q,a4r),e(q,cE),e(cE,FMe),e(FMe,n4r),e(cE,s4r),e(cE,XJ),e(XJ,l4r),e(cE,i4r),e(q,d4r),e(q,fE),e(fE,TMe),e(TMe,c4r),e(fE,f4r),e(fE,zJ),e(zJ,m4r),e(fE,g4r),e(q,h4r),e(q,mE),e(mE,MMe),e(MMe,p4r),e(mE,_4r),e(mE,WJ),e(WJ,u4r),e(mE,b4r),e(q,v4r),e(q,gE),e(gE,EMe),e(EMe,F4r),e(gE,T4r),e(gE,QJ),e(QJ,M4r),e(gE,E4r),e(q,C4r),e(q,hE),e(hE,CMe),e(CMe,w4r),e(hE,A4r),e(hE,HJ),e(HJ,L4r),e(hE,y4r),e(q,x4r),e(q,pE),e(pE,wMe),e(wMe,$4r),e(pE,k4r),e(pE,UJ),e(UJ,S4r),e(pE,R4r),e(q,P4r),e(q,_E),e(_E,AMe),e(AMe,B4r),e(_E,I4r),e(_E,JJ),e(JJ,N4r),e(_E,q4r),e(q,j4r),e(q,uE),e(uE,LMe),e(LMe,D4r),e(uE,G4r),e(uE,YJ),e(YJ,O4r),e(uE,V4r),e(q,X4r),e(q,bE),e(bE,yMe),e(yMe,z4r),e(bE,W4r),e(bE,KJ),e(KJ,Q4r),e(bE,H4r),e(q,U4r),e(q,vE),e(vE,xMe),e(xMe,J4r),e(vE,Y4r),e(vE,ZJ),e(ZJ,K4r),e(vE,Z4r),e(q,eCr),e(q,al),e(al,$Me),e($Me,oCr),e(al,rCr),e(al,eY),e(eY,tCr),e(al,aCr),e(al,oY),e(oY,nCr),e(al,sCr),e(q,lCr),e(q,FE),e(FE,kMe),e(kMe,iCr),e(FE,dCr),e(FE,rY),e(rY,cCr),e(FE,fCr),e(q,mCr),e(q,TE),e(TE,SMe),e(SMe,gCr),e(TE,hCr),e(TE,tY),e(tY,pCr),e(TE,_Cr),e(q,uCr),e(q,ME),e(ME,RMe),e(RMe,bCr),e(ME,vCr),e(ME,aY),e(aY,FCr),e(ME,TCr),e(q,MCr),e(q,EE),e(EE,PMe),e(PMe,ECr),e(EE,CCr),e(EE,nY),e(nY,wCr),e(EE,ACr),e(q,LCr),e(q,CE),e(CE,BMe),e(BMe,yCr),e(CE,xCr),e(CE,sY),e(sY,$Cr),e(CE,kCr),e(q,SCr),e(q,wE),e(wE,IMe),e(IMe,RCr),e(wE,PCr),e(wE,lY),e(lY,BCr),e(wE,ICr),e(q,NCr),e(q,AE),e(AE,NMe),e(NMe,qCr),e(AE,jCr),e(AE,iY),e(iY,DCr),e(AE,GCr),e(q,OCr),e(q,LE),e(LE,qMe),e(qMe,VCr),e(LE,XCr),e(LE,dY),e(dY,zCr),e(LE,WCr),e(q,QCr),e(q,yE),e(yE,jMe),e(jMe,HCr),e(yE,UCr),e(yE,cY),e(cY,JCr),e(yE,YCr),e(q,KCr),e(q,xE),e(xE,DMe),e(DMe,ZCr),e(xE,e3r),e(xE,fY),e(fY,o3r),e(xE,r3r),e(q,t3r),e(q,$E),e($E,GMe),e(GMe,a3r),e($E,n3r),e($E,mY),e(mY,s3r),e($E,l3r),e(q,i3r),e(q,kE),e(kE,OMe),e(OMe,d3r),e(kE,c3r),e(kE,gY),e(gY,f3r),e(kE,m3r),e(q,g3r),e(q,SE),e(SE,VMe),e(VMe,h3r),e(SE,p3r),e(SE,hY),e(hY,_3r),e(SE,u3r),e(q,b3r),e(q,RE),e(RE,XMe),e(XMe,v3r),e(RE,F3r),e(RE,pY),e(pY,T3r),e(RE,M3r),e(q,E3r),e(q,PE),e(PE,zMe),e(zMe,C3r),e(PE,w3r),e(PE,_Y),e(_Y,A3r),e(PE,L3r),e(q,y3r),e(q,BE),e(BE,WMe),e(WMe,x3r),e(BE,$3r),e(BE,uY),e(uY,k3r),e(BE,S3r),e(q,R3r),e(q,IE),e(IE,QMe),e(QMe,P3r),e(IE,B3r),e(IE,bY),e(bY,I3r),e(IE,N3r),e(q,q3r),e(q,NE),e(NE,HMe),e(HMe,j3r),e(NE,D3r),e(NE,vY),e(vY,G3r),e(NE,O3r),e(q,V3r),e(q,qE),e(qE,UMe),e(UMe,X3r),e(qE,z3r),e(qE,FY),e(FY,W3r),e(qE,Q3r),e(q,H3r),e(q,jE),e(jE,JMe),e(JMe,U3r),e(jE,J3r),e(jE,TY),e(TY,Y3r),e(jE,K3r),e(q,Z3r),e(q,DE),e(DE,YMe),e(YMe,e5r),e(DE,o5r),e(DE,MY),e(MY,r5r),e(DE,t5r),e(q,a5r),e(q,GE),e(GE,KMe),e(KMe,n5r),e(GE,s5r),e(GE,EY),e(EY,l5r),e(GE,i5r),e(q,d5r),e(q,OE),e(OE,ZMe),e(ZMe,c5r),e(OE,f5r),e(OE,CY),e(CY,m5r),e(OE,g5r),e(q,h5r),e(q,VE),e(VE,eEe),e(eEe,p5r),e(VE,_5r),e(VE,wY),e(wY,u5r),e(VE,b5r),e(q,v5r),e(q,XE),e(XE,oEe),e(oEe,F5r),e(XE,T5r),e(XE,AY),e(AY,M5r),e(XE,E5r),e(q,C5r),e(q,zE),e(zE,rEe),e(rEe,w5r),e(zE,A5r),e(zE,LY),e(LY,L5r),e(zE,y5r),e(q,x5r),e(q,WE),e(WE,tEe),e(tEe,$5r),e(WE,k5r),e(WE,yY),e(yY,S5r),e(WE,R5r),e(q,P5r),e(q,QE),e(QE,aEe),e(aEe,B5r),e(QE,I5r),e(QE,xY),e(xY,N5r),e(QE,q5r),e(q,j5r),e(q,HE),e(HE,nEe),e(nEe,D5r),e(HE,G5r),e(HE,$Y),e($Y,O5r),e(HE,V5r),e(q,X5r),e(q,UE),e(UE,sEe),e(sEe,z5r),e(UE,W5r),e(UE,kY),e(kY,Q5r),e(UE,H5r),e(q,U5r),e(q,JE),e(JE,lEe),e(lEe,J5r),e(JE,Y5r),e(JE,SY),e(SY,K5r),e(JE,Z5r),e(q,e0r),e(q,YE),e(YE,iEe),e(iEe,o0r),e(YE,r0r),e(YE,RY),e(RY,t0r),e(YE,a0r),e(Sr,n0r),M(KE,Sr,null),b(f,JQe,u),b(f,Fc,u),e(Fc,ZE),e(ZE,dEe),M(Vx,dEe,null),e(Fc,s0r),e(Fc,cEe),e(cEe,l0r),b(f,YQe,u),b(f,nr,u),M(Xx,nr,null),e(nr,i0r),e(nr,Tc),e(Tc,d0r),e(Tc,PY),e(PY,c0r),e(Tc,f0r),e(Tc,BY),e(BY,m0r),e(Tc,g0r),e(nr,h0r),e(nr,zx),e(zx,p0r),e(zx,fEe),e(fEe,_0r),e(zx,u0r),e(nr,b0r),e(nr,Nt),M(Wx,Nt,null),e(Nt,v0r),e(Nt,mEe),e(mEe,F0r),e(Nt,T0r),e(Nt,Mc),e(Mc,M0r),e(Mc,gEe),e(gEe,E0r),e(Mc,C0r),e(Mc,IY),e(IY,w0r),e(Mc,A0r),e(Nt,L0r),M(e4,Nt,null),e(nr,y0r),e(nr,Rr),M(Qx,Rr,null),e(Rr,x0r),e(Rr,hEe),e(hEe,$0r),e(Rr,k0r),e(Rr,hn),e(hn,S0r),e(hn,pEe),e(pEe,R0r),e(hn,P0r),e(hn,_Ee),e(_Ee,B0r),e(hn,I0r),e(hn,uEe),e(uEe,N0r),e(hn,q0r),e(Rr,j0r),e(Rr,se),e(se,o4),e(o4,bEe),e(bEe,D0r),e(o4,G0r),e(o4,NY),e(NY,O0r),e(o4,V0r),e(se,X0r),e(se,r4),e(r4,vEe),e(vEe,z0r),e(r4,W0r),e(r4,qY),e(qY,Q0r),e(r4,H0r),e(se,U0r),e(se,t4),e(t4,FEe),e(FEe,J0r),e(t4,Y0r),e(t4,jY),e(jY,K0r),e(t4,Z0r),e(se,ewr),e(se,a4),e(a4,TEe),e(TEe,owr),e(a4,rwr),e(a4,DY),e(DY,twr),e(a4,awr),e(se,nwr),e(se,n4),e(n4,MEe),e(MEe,swr),e(n4,lwr),e(n4,GY),e(GY,iwr),e(n4,dwr),e(se,cwr),e(se,s4),e(s4,EEe),e(EEe,fwr),e(s4,mwr),e(s4,OY),e(OY,gwr),e(s4,hwr),e(se,pwr),e(se,l4),e(l4,CEe),e(CEe,_wr),e(l4,uwr),e(l4,VY),e(VY,bwr),e(l4,vwr),e(se,Fwr),e(se,i4),e(i4,wEe),e(wEe,Twr),e(i4,Mwr),e(i4,XY),e(XY,Ewr),e(i4,Cwr),e(se,wwr),e(se,d4),e(d4,AEe),e(AEe,Awr),e(d4,Lwr),e(d4,zY),e(zY,ywr),e(d4,xwr),e(se,$wr),e(se,c4),e(c4,LEe),e(LEe,kwr),e(c4,Swr),e(c4,WY),e(WY,Rwr),e(c4,Pwr),e(se,Bwr),e(se,f4),e(f4,yEe),e(yEe,Iwr),e(f4,Nwr),e(f4,QY),e(QY,qwr),e(f4,jwr),e(se,Dwr),e(se,m4),e(m4,xEe),e(xEe,Gwr),e(m4,Owr),e(m4,HY),e(HY,Vwr),e(m4,Xwr),e(se,zwr),e(se,g4),e(g4,$Ee),e($Ee,Wwr),e(g4,Qwr),e(g4,UY),e(UY,Hwr),e(g4,Uwr),e(se,Jwr),e(se,h4),e(h4,kEe),e(kEe,Ywr),e(h4,Kwr),e(h4,JY),e(JY,Zwr),e(h4,e6r),e(se,o6r),e(se,p4),e(p4,SEe),e(SEe,r6r),e(p4,t6r),e(p4,YY),e(YY,a6r),e(p4,n6r),e(se,s6r),e(se,_4),e(_4,REe),e(REe,l6r),e(_4,i6r),e(_4,KY),e(KY,d6r),e(_4,c6r),e(se,f6r),e(se,u4),e(u4,PEe),e(PEe,m6r),e(u4,g6r),e(u4,ZY),e(ZY,h6r),e(u4,p6r),e(se,_6r),e(se,b4),e(b4,BEe),e(BEe,u6r),e(b4,b6r),e(b4,eK),e(eK,v6r),e(b4,F6r),e(se,T6r),e(se,v4),e(v4,IEe),e(IEe,M6r),e(v4,E6r),e(v4,oK),e(oK,C6r),e(v4,w6r),e(se,A6r),e(se,F4),e(F4,NEe),e(NEe,L6r),e(F4,y6r),e(F4,rK),e(rK,x6r),e(F4,$6r),e(se,k6r),e(se,T4),e(T4,qEe),e(qEe,S6r),e(T4,R6r),e(T4,tK),e(tK,P6r),e(T4,B6r),e(se,I6r),e(se,M4),e(M4,jEe),e(jEe,N6r),e(M4,q6r),e(M4,aK),e(aK,j6r),e(M4,D6r),e(se,G6r),e(se,E4),e(E4,DEe),e(DEe,O6r),e(E4,V6r),e(E4,nK),e(nK,X6r),e(E4,z6r),e(Rr,W6r),M(C4,Rr,null),b(f,KQe,u),b(f,Ec,u),e(Ec,w4),e(w4,GEe),M(Hx,GEe,null),e(Ec,Q6r),e(Ec,OEe),e(OEe,H6r),b(f,ZQe,u),b(f,sr,u),M(Ux,sr,null),e(sr,U6r),e(sr,Cc),e(Cc,J6r),e(Cc,sK),e(sK,Y6r),e(Cc,K6r),e(Cc,lK),e(lK,Z6r),e(Cc,eAr),e(sr,oAr),e(sr,Jx),e(Jx,rAr),e(Jx,VEe),e(VEe,tAr),e(Jx,aAr),e(sr,nAr),e(sr,qt),M(Yx,qt,null),e(qt,sAr),e(qt,XEe),e(XEe,lAr),e(qt,iAr),e(qt,wc),e(wc,dAr),e(wc,zEe),e(zEe,cAr),e(wc,fAr),e(wc,iK),e(iK,mAr),e(wc,gAr),e(qt,hAr),M(A4,qt,null),e(sr,pAr),e(sr,Pr),M(Kx,Pr,null),e(Pr,_Ar),e(Pr,WEe),e(WEe,uAr),e(Pr,bAr),e(Pr,pn),e(pn,vAr),e(pn,QEe),e(QEe,FAr),e(pn,TAr),e(pn,HEe),e(HEe,MAr),e(pn,EAr),e(pn,UEe),e(UEe,CAr),e(pn,wAr),e(Pr,AAr),e(Pr,Me),e(Me,L4),e(L4,JEe),e(JEe,LAr),e(L4,yAr),e(L4,dK),e(dK,xAr),e(L4,$Ar),e(Me,kAr),e(Me,y4),e(y4,YEe),e(YEe,SAr),e(y4,RAr),e(y4,cK),e(cK,PAr),e(y4,BAr),e(Me,IAr),e(Me,x4),e(x4,KEe),e(KEe,NAr),e(x4,qAr),e(x4,fK),e(fK,jAr),e(x4,DAr),e(Me,GAr),e(Me,$4),e($4,ZEe),e(ZEe,OAr),e($4,VAr),e($4,mK),e(mK,XAr),e($4,zAr),e(Me,WAr),e(Me,k4),e(k4,e4e),e(e4e,QAr),e(k4,HAr),e(k4,gK),e(gK,UAr),e(k4,JAr),e(Me,YAr),e(Me,S4),e(S4,o4e),e(o4e,KAr),e(S4,ZAr),e(S4,hK),e(hK,eLr),e(S4,oLr),e(Me,rLr),e(Me,R4),e(R4,r4e),e(r4e,tLr),e(R4,aLr),e(R4,pK),e(pK,nLr),e(R4,sLr),e(Me,lLr),e(Me,P4),e(P4,t4e),e(t4e,iLr),e(P4,dLr),e(P4,_K),e(_K,cLr),e(P4,fLr),e(Me,mLr),e(Me,B4),e(B4,a4e),e(a4e,gLr),e(B4,hLr),e(B4,uK),e(uK,pLr),e(B4,_Lr),e(Me,uLr),e(Me,I4),e(I4,n4e),e(n4e,bLr),e(I4,vLr),e(I4,bK),e(bK,FLr),e(I4,TLr),e(Me,MLr),e(Me,N4),e(N4,s4e),e(s4e,ELr),e(N4,CLr),e(N4,vK),e(vK,wLr),e(N4,ALr),e(Me,LLr),e(Me,q4),e(q4,l4e),e(l4e,yLr),e(q4,xLr),e(q4,FK),e(FK,$Lr),e(q4,kLr),e(Me,SLr),e(Me,j4),e(j4,i4e),e(i4e,RLr),e(j4,PLr),e(j4,TK),e(TK,BLr),e(j4,ILr),e(Pr,NLr),M(D4,Pr,null),b(f,eHe,u),b(f,Ac,u),e(Ac,G4),e(G4,d4e),M(Zx,d4e,null),e(Ac,qLr),e(Ac,c4e),e(c4e,jLr),b(f,oHe,u),b(f,lr,u),M(e$,lr,null),e(lr,DLr),e(lr,Lc),e(Lc,GLr),e(Lc,MK),e(MK,OLr),e(Lc,VLr),e(Lc,EK),e(EK,XLr),e(Lc,zLr),e(lr,WLr),e(lr,o$),e(o$,QLr),e(o$,f4e),e(f4e,HLr),e(o$,ULr),e(lr,JLr),e(lr,jt),M(r$,jt,null),e(jt,YLr),e(jt,m4e),e(m4e,KLr),e(jt,ZLr),e(jt,yc),e(yc,eyr),e(yc,g4e),e(g4e,oyr),e(yc,ryr),e(yc,CK),e(CK,tyr),e(yc,ayr),e(jt,nyr),M(O4,jt,null),e(lr,syr),e(lr,Br),M(t$,Br,null),e(Br,lyr),e(Br,h4e),e(h4e,iyr),e(Br,dyr),e(Br,_n),e(_n,cyr),e(_n,p4e),e(p4e,fyr),e(_n,myr),e(_n,_4e),e(_4e,gyr),e(_n,hyr),e(_n,u4e),e(u4e,pyr),e(_n,_yr),e(Br,uyr),e(Br,Ve),e(Ve,V4),e(V4,b4e),e(b4e,byr),e(V4,vyr),e(V4,wK),e(wK,Fyr),e(V4,Tyr),e(Ve,Myr),e(Ve,X4),e(X4,v4e),e(v4e,Eyr),e(X4,Cyr),e(X4,AK),e(AK,wyr),e(X4,Ayr),e(Ve,Lyr),e(Ve,nl),e(nl,F4e),e(F4e,yyr),e(nl,xyr),e(nl,LK),e(LK,$yr),e(nl,kyr),e(nl,yK),e(yK,Syr),e(nl,Ryr),e(Ve,Pyr),e(Ve,z4),e(z4,T4e),e(T4e,Byr),e(z4,Iyr),e(z4,xK),e(xK,Nyr),e(z4,qyr),e(Ve,jyr),e(Ve,W4),e(W4,M4e),e(M4e,Dyr),e(W4,Gyr),e(W4,$K),e($K,Oyr),e(W4,Vyr),e(Ve,Xyr),e(Ve,Q4),e(Q4,E4e),e(E4e,zyr),e(Q4,Wyr),e(Q4,kK),e(kK,Qyr),e(Q4,Hyr),e(Ve,Uyr),e(Ve,H4),e(H4,C4e),e(C4e,Jyr),e(H4,Yyr),e(H4,SK),e(SK,Kyr),e(H4,Zyr),e(Ve,e8r),e(Ve,U4),e(U4,w4e),e(w4e,o8r),e(U4,r8r),e(U4,RK),e(RK,t8r),e(U4,a8r),e(Br,n8r),M(J4,Br,null),b(f,rHe,u),b(f,xc,u),e(xc,Y4),e(Y4,A4e),M(a$,A4e,null),e(xc,s8r),e(xc,L4e),e(L4e,l8r),b(f,tHe,u),b(f,ir,u),M(n$,ir,null),e(ir,i8r),e(ir,$c),e($c,d8r),e($c,PK),e(PK,c8r),e($c,f8r),e($c,BK),e(BK,m8r),e($c,g8r),e(ir,h8r),e(ir,s$),e(s$,p8r),e(s$,y4e),e(y4e,_8r),e(s$,u8r),e(ir,b8r),e(ir,Dt),M(l$,Dt,null),e(Dt,v8r),e(Dt,x4e),e(x4e,F8r),e(Dt,T8r),e(Dt,kc),e(kc,M8r),e(kc,$4e),e($4e,E8r),e(kc,C8r),e(kc,IK),e(IK,w8r),e(kc,A8r),e(Dt,L8r),M(K4,Dt,null),e(ir,y8r),e(ir,Ir),M(i$,Ir,null),e(Ir,x8r),e(Ir,k4e),e(k4e,$8r),e(Ir,k8r),e(Ir,un),e(un,S8r),e(un,S4e),e(S4e,R8r),e(un,P8r),e(un,R4e),e(R4e,B8r),e(un,I8r),e(un,P4e),e(P4e,N8r),e(un,q8r),e(Ir,j8r),e(Ir,ie),e(ie,Z4),e(Z4,B4e),e(B4e,D8r),e(Z4,G8r),e(Z4,NK),e(NK,O8r),e(Z4,V8r),e(ie,X8r),e(ie,eC),e(eC,I4e),e(I4e,z8r),e(eC,W8r),e(eC,qK),e(qK,Q8r),e(eC,H8r),e(ie,U8r),e(ie,oC),e(oC,N4e),e(N4e,J8r),e(oC,Y8r),e(oC,jK),e(jK,K8r),e(oC,Z8r),e(ie,exr),e(ie,rC),e(rC,q4e),e(q4e,oxr),e(rC,rxr),e(rC,DK),e(DK,txr),e(rC,axr),e(ie,nxr),e(ie,tC),e(tC,j4e),e(j4e,sxr),e(tC,lxr),e(tC,GK),e(GK,ixr),e(tC,dxr),e(ie,cxr),e(ie,aC),e(aC,D4e),e(D4e,fxr),e(aC,mxr),e(aC,OK),e(OK,gxr),e(aC,hxr),e(ie,pxr),e(ie,nC),e(nC,G4e),e(G4e,_xr),e(nC,uxr),e(nC,VK),e(VK,bxr),e(nC,vxr),e(ie,Fxr),e(ie,sC),e(sC,O4e),e(O4e,Txr),e(sC,Mxr),e(sC,XK),e(XK,Exr),e(sC,Cxr),e(ie,wxr),e(ie,lC),e(lC,V4e),e(V4e,Axr),e(lC,Lxr),e(lC,zK),e(zK,yxr),e(lC,xxr),e(ie,$xr),e(ie,iC),e(iC,X4e),e(X4e,kxr),e(iC,Sxr),e(iC,WK),e(WK,Rxr),e(iC,Pxr),e(ie,Bxr),e(ie,dC),e(dC,z4e),e(z4e,Ixr),e(dC,Nxr),e(dC,QK),e(QK,qxr),e(dC,jxr),e(ie,Dxr),e(ie,cC),e(cC,W4e),e(W4e,Gxr),e(cC,Oxr),e(cC,HK),e(HK,Vxr),e(cC,Xxr),e(ie,zxr),e(ie,fC),e(fC,Q4e),e(Q4e,Wxr),e(fC,Qxr),e(fC,UK),e(UK,Hxr),e(fC,Uxr),e(ie,Jxr),e(ie,mC),e(mC,H4e),e(H4e,Yxr),e(mC,Kxr),e(mC,JK),e(JK,Zxr),e(mC,e$r),e(ie,o$r),e(ie,gC),e(gC,U4e),e(U4e,r$r),e(gC,t$r),e(gC,YK),e(YK,a$r),e(gC,n$r),e(ie,s$r),e(ie,hC),e(hC,J4e),e(J4e,l$r),e(hC,i$r),e(hC,KK),e(KK,d$r),e(hC,c$r),e(ie,f$r),e(ie,pC),e(pC,Y4e),e(Y4e,m$r),e(pC,g$r),e(pC,ZK),e(ZK,h$r),e(pC,p$r),e(ie,_$r),e(ie,_C),e(_C,K4e),e(K4e,u$r),e(_C,b$r),e(_C,eZ),e(eZ,v$r),e(_C,F$r),e(ie,T$r),e(ie,uC),e(uC,Z4e),e(Z4e,M$r),e(uC,E$r),e(uC,oZ),e(oZ,C$r),e(uC,w$r),e(ie,A$r),e(ie,bC),e(bC,eCe),e(eCe,L$r),e(bC,y$r),e(bC,rZ),e(rZ,x$r),e(bC,$$r),e(Ir,k$r),M(vC,Ir,null),b(f,aHe,u),b(f,Sc,u),e(Sc,FC),e(FC,oCe),M(d$,oCe,null),e(Sc,S$r),e(Sc,rCe),e(rCe,R$r),b(f,nHe,u),b(f,dr,u),M(c$,dr,null),e(dr,P$r),e(dr,Rc),e(Rc,B$r),e(Rc,tZ),e(tZ,I$r),e(Rc,N$r),e(Rc,aZ),e(aZ,q$r),e(Rc,j$r),e(dr,D$r),e(dr,f$),e(f$,G$r),e(f$,tCe),e(tCe,O$r),e(f$,V$r),e(dr,X$r),e(dr,Gt),M(m$,Gt,null),e(Gt,z$r),e(Gt,aCe),e(aCe,W$r),e(Gt,Q$r),e(Gt,Pc),e(Pc,H$r),e(Pc,nCe),e(nCe,U$r),e(Pc,J$r),e(Pc,nZ),e(nZ,Y$r),e(Pc,K$r),e(Gt,Z$r),M(TC,Gt,null),e(dr,ekr),e(dr,Nr),M(g$,Nr,null),e(Nr,okr),e(Nr,sCe),e(sCe,rkr),e(Nr,tkr),e(Nr,bn),e(bn,akr),e(bn,lCe),e(lCe,nkr),e(bn,skr),e(bn,iCe),e(iCe,lkr),e(bn,ikr),e(bn,dCe),e(dCe,dkr),e(bn,ckr),e(Nr,fkr),e(Nr,ye),e(ye,MC),e(MC,cCe),e(cCe,mkr),e(MC,gkr),e(MC,sZ),e(sZ,hkr),e(MC,pkr),e(ye,_kr),e(ye,EC),e(EC,fCe),e(fCe,ukr),e(EC,bkr),e(EC,lZ),e(lZ,vkr),e(EC,Fkr),e(ye,Tkr),e(ye,CC),e(CC,mCe),e(mCe,Mkr),e(CC,Ekr),e(CC,iZ),e(iZ,Ckr),e(CC,wkr),e(ye,Akr),e(ye,wC),e(wC,gCe),e(gCe,Lkr),e(wC,ykr),e(wC,dZ),e(dZ,xkr),e(wC,$kr),e(ye,kkr),e(ye,AC),e(AC,hCe),e(hCe,Skr),e(AC,Rkr),e(AC,cZ),e(cZ,Pkr),e(AC,Bkr),e(ye,Ikr),e(ye,LC),e(LC,pCe),e(pCe,Nkr),e(LC,qkr),e(LC,fZ),e(fZ,jkr),e(LC,Dkr),e(ye,Gkr),e(ye,yC),e(yC,_Ce),e(_Ce,Okr),e(yC,Vkr),e(yC,mZ),e(mZ,Xkr),e(yC,zkr),e(ye,Wkr),e(ye,xC),e(xC,uCe),e(uCe,Qkr),e(xC,Hkr),e(xC,gZ),e(gZ,Ukr),e(xC,Jkr),e(ye,Ykr),e(ye,$C),e($C,bCe),e(bCe,Kkr),e($C,Zkr),e($C,hZ),e(hZ,eSr),e($C,oSr),e(ye,rSr),e(ye,kC),e(kC,vCe),e(vCe,tSr),e(kC,aSr),e(kC,pZ),e(pZ,nSr),e(kC,sSr),e(Nr,lSr),M(SC,Nr,null),b(f,sHe,u),b(f,Bc,u),e(Bc,RC),e(RC,FCe),M(h$,FCe,null),e(Bc,iSr),e(Bc,TCe),e(TCe,dSr),b(f,lHe,u),b(f,cr,u),M(p$,cr,null),e(cr,cSr),e(cr,Ic),e(Ic,fSr),e(Ic,_Z),e(_Z,mSr),e(Ic,gSr),e(Ic,uZ),e(uZ,hSr),e(Ic,pSr),e(cr,_Sr),e(cr,_$),e(_$,uSr),e(_$,MCe),e(MCe,bSr),e(_$,vSr),e(cr,FSr),e(cr,Ot),M(u$,Ot,null),e(Ot,TSr),e(Ot,ECe),e(ECe,MSr),e(Ot,ESr),e(Ot,Nc),e(Nc,CSr),e(Nc,CCe),e(CCe,wSr),e(Nc,ASr),e(Nc,bZ),e(bZ,LSr),e(Nc,ySr),e(Ot,xSr),M(PC,Ot,null),e(cr,$Sr),e(cr,qr),M(b$,qr,null),e(qr,kSr),e(qr,wCe),e(wCe,SSr),e(qr,RSr),e(qr,vn),e(vn,PSr),e(vn,ACe),e(ACe,BSr),e(vn,ISr),e(vn,LCe),e(LCe,NSr),e(vn,qSr),e(vn,yCe),e(yCe,jSr),e(vn,DSr),e(qr,GSr),e(qr,ae),e(ae,BC),e(BC,xCe),e(xCe,OSr),e(BC,VSr),e(BC,vZ),e(vZ,XSr),e(BC,zSr),e(ae,WSr),e(ae,IC),e(IC,$Ce),e($Ce,QSr),e(IC,HSr),e(IC,FZ),e(FZ,USr),e(IC,JSr),e(ae,YSr),e(ae,NC),e(NC,kCe),e(kCe,KSr),e(NC,ZSr),e(NC,TZ),e(TZ,eRr),e(NC,oRr),e(ae,rRr),e(ae,qC),e(qC,SCe),e(SCe,tRr),e(qC,aRr),e(qC,MZ),e(MZ,nRr),e(qC,sRr),e(ae,lRr),e(ae,jC),e(jC,RCe),e(RCe,iRr),e(jC,dRr),e(jC,EZ),e(EZ,cRr),e(jC,fRr),e(ae,mRr),e(ae,DC),e(DC,PCe),e(PCe,gRr),e(DC,hRr),e(DC,CZ),e(CZ,pRr),e(DC,_Rr),e(ae,uRr),e(ae,GC),e(GC,BCe),e(BCe,bRr),e(GC,vRr),e(GC,wZ),e(wZ,FRr),e(GC,TRr),e(ae,MRr),e(ae,OC),e(OC,ICe),e(ICe,ERr),e(OC,CRr),e(OC,AZ),e(AZ,wRr),e(OC,ARr),e(ae,LRr),e(ae,VC),e(VC,NCe),e(NCe,yRr),e(VC,xRr),e(VC,LZ),e(LZ,$Rr),e(VC,kRr),e(ae,SRr),e(ae,XC),e(XC,qCe),e(qCe,RRr),e(XC,PRr),e(XC,yZ),e(yZ,BRr),e(XC,IRr),e(ae,NRr),e(ae,zC),e(zC,jCe),e(jCe,qRr),e(zC,jRr),e(zC,xZ),e(xZ,DRr),e(zC,GRr),e(ae,ORr),e(ae,WC),e(WC,DCe),e(DCe,VRr),e(WC,XRr),e(WC,$Z),e($Z,zRr),e(WC,WRr),e(ae,QRr),e(ae,QC),e(QC,GCe),e(GCe,HRr),e(QC,URr),e(QC,kZ),e(kZ,JRr),e(QC,YRr),e(ae,KRr),e(ae,HC),e(HC,OCe),e(OCe,ZRr),e(HC,ePr),e(HC,SZ),e(SZ,oPr),e(HC,rPr),e(ae,tPr),e(ae,UC),e(UC,VCe),e(VCe,aPr),e(UC,nPr),e(UC,RZ),e(RZ,sPr),e(UC,lPr),e(ae,iPr),e(ae,JC),e(JC,XCe),e(XCe,dPr),e(JC,cPr),e(JC,PZ),e(PZ,fPr),e(JC,mPr),e(ae,gPr),e(ae,YC),e(YC,zCe),e(zCe,hPr),e(YC,pPr),e(YC,BZ),e(BZ,_Pr),e(YC,uPr),e(ae,bPr),e(ae,KC),e(KC,WCe),e(WCe,vPr),e(KC,FPr),e(KC,IZ),e(IZ,TPr),e(KC,MPr),e(ae,EPr),e(ae,ZC),e(ZC,QCe),e(QCe,CPr),e(ZC,wPr),e(ZC,NZ),e(NZ,APr),e(ZC,LPr),e(ae,yPr),e(ae,e3),e(e3,HCe),e(HCe,xPr),e(e3,$Pr),e(e3,qZ),e(qZ,kPr),e(e3,SPr),e(ae,RPr),e(ae,o3),e(o3,UCe),e(UCe,PPr),e(o3,BPr),e(o3,jZ),e(jZ,IPr),e(o3,NPr),e(ae,qPr),e(ae,r3),e(r3,JCe),e(JCe,jPr),e(r3,DPr),e(r3,DZ),e(DZ,GPr),e(r3,OPr),e(ae,VPr),e(ae,t3),e(t3,YCe),e(YCe,XPr),e(t3,zPr),e(t3,GZ),e(GZ,WPr),e(t3,QPr),e(ae,HPr),e(ae,a3),e(a3,KCe),e(KCe,UPr),e(a3,JPr),e(a3,OZ),e(OZ,YPr),e(a3,KPr),e(ae,ZPr),e(ae,n3),e(n3,ZCe),e(ZCe,eBr),e(n3,oBr),e(n3,VZ),e(VZ,rBr),e(n3,tBr),e(ae,aBr),e(ae,s3),e(s3,e3e),e(e3e,nBr),e(s3,sBr),e(s3,XZ),e(XZ,lBr),e(s3,iBr),e(qr,dBr),M(l3,qr,null),b(f,iHe,u),b(f,qc,u),e(qc,i3),e(i3,o3e),M(v$,o3e,null),e(qc,cBr),e(qc,r3e),e(r3e,fBr),b(f,dHe,u),b(f,fr,u),M(F$,fr,null),e(fr,mBr),e(fr,jc),e(jc,gBr),e(jc,zZ),e(zZ,hBr),e(jc,pBr),e(jc,WZ),e(WZ,_Br),e(jc,uBr),e(fr,bBr),e(fr,T$),e(T$,vBr),e(T$,t3e),e(t3e,FBr),e(T$,TBr),e(fr,MBr),e(fr,Vt),M(M$,Vt,null),e(Vt,EBr),e(Vt,a3e),e(a3e,CBr),e(Vt,wBr),e(Vt,Dc),e(Dc,ABr),e(Dc,n3e),e(n3e,LBr),e(Dc,yBr),e(Dc,QZ),e(QZ,xBr),e(Dc,$Br),e(Vt,kBr),M(d3,Vt,null),e(fr,SBr),e(fr,jr),M(E$,jr,null),e(jr,RBr),e(jr,s3e),e(s3e,PBr),e(jr,BBr),e(jr,Fn),e(Fn,IBr),e(Fn,l3e),e(l3e,NBr),e(Fn,qBr),e(Fn,i3e),e(i3e,jBr),e(Fn,DBr),e(Fn,d3e),e(d3e,GBr),e(Fn,OBr),e(jr,VBr),e(jr,ve),e(ve,c3),e(c3,c3e),e(c3e,XBr),e(c3,zBr),e(c3,HZ),e(HZ,WBr),e(c3,QBr),e(ve,HBr),e(ve,f3),e(f3,f3e),e(f3e,UBr),e(f3,JBr),e(f3,UZ),e(UZ,YBr),e(f3,KBr),e(ve,ZBr),e(ve,m3),e(m3,m3e),e(m3e,eIr),e(m3,oIr),e(m3,JZ),e(JZ,rIr),e(m3,tIr),e(ve,aIr),e(ve,g3),e(g3,g3e),e(g3e,nIr),e(g3,sIr),e(g3,YZ),e(YZ,lIr),e(g3,iIr),e(ve,dIr),e(ve,h3),e(h3,h3e),e(h3e,cIr),e(h3,fIr),e(h3,KZ),e(KZ,mIr),e(h3,gIr),e(ve,hIr),e(ve,p3),e(p3,p3e),e(p3e,pIr),e(p3,_Ir),e(p3,ZZ),e(ZZ,uIr),e(p3,bIr),e(ve,vIr),e(ve,_3),e(_3,_3e),e(_3e,FIr),e(_3,TIr),e(_3,eee),e(eee,MIr),e(_3,EIr),e(ve,CIr),e(ve,u3),e(u3,u3e),e(u3e,wIr),e(u3,AIr),e(u3,oee),e(oee,LIr),e(u3,yIr),e(ve,xIr),e(ve,b3),e(b3,b3e),e(b3e,$Ir),e(b3,kIr),e(b3,ree),e(ree,SIr),e(b3,RIr),e(ve,PIr),e(ve,v3),e(v3,v3e),e(v3e,BIr),e(v3,IIr),e(v3,tee),e(tee,NIr),e(v3,qIr),e(ve,jIr),e(ve,F3),e(F3,F3e),e(F3e,DIr),e(F3,GIr),e(F3,aee),e(aee,OIr),e(F3,VIr),e(ve,XIr),e(ve,T3),e(T3,T3e),e(T3e,zIr),e(T3,WIr),e(T3,nee),e(nee,QIr),e(T3,HIr),e(ve,UIr),e(ve,M3),e(M3,M3e),e(M3e,JIr),e(M3,YIr),e(M3,see),e(see,KIr),e(M3,ZIr),e(ve,eNr),e(ve,E3),e(E3,E3e),e(E3e,oNr),e(E3,rNr),e(E3,lee),e(lee,tNr),e(E3,aNr),e(ve,nNr),e(ve,C3),e(C3,C3e),e(C3e,sNr),e(C3,lNr),e(C3,iee),e(iee,iNr),e(C3,dNr),e(ve,cNr),e(ve,w3),e(w3,w3e),e(w3e,fNr),e(w3,mNr),e(w3,dee),e(dee,gNr),e(w3,hNr),e(ve,pNr),e(ve,A3),e(A3,A3e),e(A3e,_Nr),e(A3,uNr),e(A3,cee),e(cee,bNr),e(A3,vNr),e(jr,FNr),M(L3,jr,null),b(f,cHe,u),b(f,Gc,u),e(Gc,y3),e(y3,L3e),M(C$,L3e,null),e(Gc,TNr),e(Gc,y3e),e(y3e,MNr),b(f,fHe,u),b(f,mr,u),M(w$,mr,null),e(mr,ENr),e(mr,Oc),e(Oc,CNr),e(Oc,fee),e(fee,wNr),e(Oc,ANr),e(Oc,mee),e(mee,LNr),e(Oc,yNr),e(mr,xNr),e(mr,A$),e(A$,$Nr),e(A$,x3e),e(x3e,kNr),e(A$,SNr),e(mr,RNr),e(mr,Xt),M(L$,Xt,null),e(Xt,PNr),e(Xt,$3e),e($3e,BNr),e(Xt,INr),e(Xt,Vc),e(Vc,NNr),e(Vc,k3e),e(k3e,qNr),e(Vc,jNr),e(Vc,gee),e(gee,DNr),e(Vc,GNr),e(Xt,ONr),M(x3,Xt,null),e(mr,VNr),e(mr,Dr),M(y$,Dr,null),e(Dr,XNr),e(Dr,S3e),e(S3e,zNr),e(Dr,WNr),e(Dr,Tn),e(Tn,QNr),e(Tn,R3e),e(R3e,HNr),e(Tn,UNr),e(Tn,P3e),e(P3e,JNr),e(Tn,YNr),e(Tn,B3e),e(B3e,KNr),e(Tn,ZNr),e(Dr,eqr),e(Dr,x$),e(x$,$3),e($3,I3e),e(I3e,oqr),e($3,rqr),e($3,hee),e(hee,tqr),e($3,aqr),e(x$,nqr),e(x$,k3),e(k3,N3e),e(N3e,sqr),e(k3,lqr),e(k3,pee),e(pee,iqr),e(k3,dqr),e(Dr,cqr),M(S3,Dr,null),b(f,mHe,u),b(f,Xc,u),e(Xc,R3),e(R3,q3e),M($$,q3e,null),e(Xc,fqr),e(Xc,j3e),e(j3e,mqr),b(f,gHe,u),b(f,gr,u),M(k$,gr,null),e(gr,gqr),e(gr,zc),e(zc,hqr),e(zc,_ee),e(_ee,pqr),e(zc,_qr),e(zc,uee),e(uee,uqr),e(zc,bqr),e(gr,vqr),e(gr,S$),e(S$,Fqr),e(S$,D3e),e(D3e,Tqr),e(S$,Mqr),e(gr,Eqr),e(gr,zt),M(R$,zt,null),e(zt,Cqr),e(zt,G3e),e(G3e,wqr),e(zt,Aqr),e(zt,Wc),e(Wc,Lqr),e(Wc,O3e),e(O3e,yqr),e(Wc,xqr),e(Wc,bee),e(bee,$qr),e(Wc,kqr),e(zt,Sqr),M(P3,zt,null),e(gr,Rqr),e(gr,Gr),M(P$,Gr,null),e(Gr,Pqr),e(Gr,V3e),e(V3e,Bqr),e(Gr,Iqr),e(Gr,Mn),e(Mn,Nqr),e(Mn,X3e),e(X3e,qqr),e(Mn,jqr),e(Mn,z3e),e(z3e,Dqr),e(Mn,Gqr),e(Mn,W3e),e(W3e,Oqr),e(Mn,Vqr),e(Gr,Xqr),e(Gr,Q3e),e(Q3e,B3),e(B3,H3e),e(H3e,zqr),e(B3,Wqr),e(B3,vee),e(vee,Qqr),e(B3,Hqr),e(Gr,Uqr),M(I3,Gr,null),b(f,hHe,u),b(f,Qc,u),e(Qc,N3),e(N3,U3e),M(B$,U3e,null),e(Qc,Jqr),e(Qc,J3e),e(J3e,Yqr),b(f,pHe,u),b(f,hr,u),M(I$,hr,null),e(hr,Kqr),e(hr,Hc),e(Hc,Zqr),e(Hc,Fee),e(Fee,ejr),e(Hc,ojr),e(Hc,Tee),e(Tee,rjr),e(Hc,tjr),e(hr,ajr),e(hr,N$),e(N$,njr),e(N$,Y3e),e(Y3e,sjr),e(N$,ljr),e(hr,ijr),e(hr,Wt),M(q$,Wt,null),e(Wt,djr),e(Wt,K3e),e(K3e,cjr),e(Wt,fjr),e(Wt,Uc),e(Uc,mjr),e(Uc,Z3e),e(Z3e,gjr),e(Uc,hjr),e(Uc,Mee),e(Mee,pjr),e(Uc,_jr),e(Wt,ujr),M(q3,Wt,null),e(hr,bjr),e(hr,Or),M(j$,Or,null),e(Or,vjr),e(Or,e5e),e(e5e,Fjr),e(Or,Tjr),e(Or,En),e(En,Mjr),e(En,o5e),e(o5e,Ejr),e(En,Cjr),e(En,r5e),e(r5e,wjr),e(En,Ajr),e(En,t5e),e(t5e,Ljr),e(En,yjr),e(Or,xjr),e(Or,de),e(de,j3),e(j3,a5e),e(a5e,$jr),e(j3,kjr),e(j3,Eee),e(Eee,Sjr),e(j3,Rjr),e(de,Pjr),e(de,D3),e(D3,n5e),e(n5e,Bjr),e(D3,Ijr),e(D3,Cee),e(Cee,Njr),e(D3,qjr),e(de,jjr),e(de,G3),e(G3,s5e),e(s5e,Djr),e(G3,Gjr),e(G3,wee),e(wee,Ojr),e(G3,Vjr),e(de,Xjr),e(de,O3),e(O3,l5e),e(l5e,zjr),e(O3,Wjr),e(O3,Aee),e(Aee,Qjr),e(O3,Hjr),e(de,Ujr),e(de,V3),e(V3,i5e),e(i5e,Jjr),e(V3,Yjr),e(V3,Lee),e(Lee,Kjr),e(V3,Zjr),e(de,eDr),e(de,X3),e(X3,d5e),e(d5e,oDr),e(X3,rDr),e(X3,yee),e(yee,tDr),e(X3,aDr),e(de,nDr),e(de,z3),e(z3,c5e),e(c5e,sDr),e(z3,lDr),e(z3,xee),e(xee,iDr),e(z3,dDr),e(de,cDr),e(de,W3),e(W3,f5e),e(f5e,fDr),e(W3,mDr),e(W3,$ee),e($ee,gDr),e(W3,hDr),e(de,pDr),e(de,Q3),e(Q3,m5e),e(m5e,_Dr),e(Q3,uDr),e(Q3,kee),e(kee,bDr),e(Q3,vDr),e(de,FDr),e(de,H3),e(H3,g5e),e(g5e,TDr),e(H3,MDr),e(H3,See),e(See,EDr),e(H3,CDr),e(de,wDr),e(de,U3),e(U3,h5e),e(h5e,ADr),e(U3,LDr),e(U3,Ree),e(Ree,yDr),e(U3,xDr),e(de,$Dr),e(de,J3),e(J3,p5e),e(p5e,kDr),e(J3,SDr),e(J3,Pee),e(Pee,RDr),e(J3,PDr),e(de,BDr),e(de,Y3),e(Y3,_5e),e(_5e,IDr),e(Y3,NDr),e(Y3,Bee),e(Bee,qDr),e(Y3,jDr),e(de,DDr),e(de,K3),e(K3,u5e),e(u5e,GDr),e(K3,ODr),e(K3,Iee),e(Iee,VDr),e(K3,XDr),e(de,zDr),e(de,Z3),e(Z3,b5e),e(b5e,WDr),e(Z3,QDr),e(Z3,Nee),e(Nee,HDr),e(Z3,UDr),e(de,JDr),e(de,e5),e(e5,v5e),e(v5e,YDr),e(e5,KDr),e(e5,qee),e(qee,ZDr),e(e5,eGr),e(de,oGr),e(de,o5),e(o5,F5e),e(F5e,rGr),e(o5,tGr),e(o5,jee),e(jee,aGr),e(o5,nGr),e(de,sGr),e(de,r5),e(r5,T5e),e(T5e,lGr),e(r5,iGr),e(r5,Dee),e(Dee,dGr),e(r5,cGr),e(de,fGr),e(de,t5),e(t5,M5e),e(M5e,mGr),e(t5,gGr),e(t5,Gee),e(Gee,hGr),e(t5,pGr),e(de,_Gr),e(de,a5),e(a5,E5e),e(E5e,uGr),e(a5,bGr),e(a5,Oee),e(Oee,vGr),e(a5,FGr),e(Or,TGr),M(n5,Or,null),b(f,_He,u),b(f,Jc,u),e(Jc,s5),e(s5,C5e),M(D$,C5e,null),e(Jc,MGr),e(Jc,w5e),e(w5e,EGr),b(f,uHe,u),b(f,pr,u),M(G$,pr,null),e(pr,CGr),e(pr,Yc),e(Yc,wGr),e(Yc,Vee),e(Vee,AGr),e(Yc,LGr),e(Yc,Xee),e(Xee,yGr),e(Yc,xGr),e(pr,$Gr),e(pr,O$),e(O$,kGr),e(O$,A5e),e(A5e,SGr),e(O$,RGr),e(pr,PGr),e(pr,Qt),M(V$,Qt,null),e(Qt,BGr),e(Qt,L5e),e(L5e,IGr),e(Qt,NGr),e(Qt,Kc),e(Kc,qGr),e(Kc,y5e),e(y5e,jGr),e(Kc,DGr),e(Kc,zee),e(zee,GGr),e(Kc,OGr),e(Qt,VGr),M(l5,Qt,null),e(pr,XGr),e(pr,Vr),M(X$,Vr,null),e(Vr,zGr),e(Vr,x5e),e(x5e,WGr),e(Vr,QGr),e(Vr,Cn),e(Cn,HGr),e(Cn,$5e),e($5e,UGr),e(Cn,JGr),e(Cn,k5e),e(k5e,YGr),e(Cn,KGr),e(Cn,S5e),e(S5e,ZGr),e(Cn,eOr),e(Vr,oOr),e(Vr,ce),e(ce,i5),e(i5,R5e),e(R5e,rOr),e(i5,tOr),e(i5,Wee),e(Wee,aOr),e(i5,nOr),e(ce,sOr),e(ce,d5),e(d5,P5e),e(P5e,lOr),e(d5,iOr),e(d5,Qee),e(Qee,dOr),e(d5,cOr),e(ce,fOr),e(ce,c5),e(c5,B5e),e(B5e,mOr),e(c5,gOr),e(c5,Hee),e(Hee,hOr),e(c5,pOr),e(ce,_Or),e(ce,f5),e(f5,I5e),e(I5e,uOr),e(f5,bOr),e(f5,Uee),e(Uee,vOr),e(f5,FOr),e(ce,TOr),e(ce,m5),e(m5,N5e),e(N5e,MOr),e(m5,EOr),e(m5,Jee),e(Jee,COr),e(m5,wOr),e(ce,AOr),e(ce,g5),e(g5,q5e),e(q5e,LOr),e(g5,yOr),e(g5,Yee),e(Yee,xOr),e(g5,$Or),e(ce,kOr),e(ce,h5),e(h5,j5e),e(j5e,SOr),e(h5,ROr),e(h5,Kee),e(Kee,POr),e(h5,BOr),e(ce,IOr),e(ce,p5),e(p5,D5e),e(D5e,NOr),e(p5,qOr),e(p5,Zee),e(Zee,jOr),e(p5,DOr),e(ce,GOr),e(ce,_5),e(_5,G5e),e(G5e,OOr),e(_5,VOr),e(_5,eoe),e(eoe,XOr),e(_5,zOr),e(ce,WOr),e(ce,u5),e(u5,O5e),e(O5e,QOr),e(u5,HOr),e(u5,ooe),e(ooe,UOr),e(u5,JOr),e(ce,YOr),e(ce,b5),e(b5,V5e),e(V5e,KOr),e(b5,ZOr),e(b5,roe),e(roe,eVr),e(b5,oVr),e(ce,rVr),e(ce,v5),e(v5,X5e),e(X5e,tVr),e(v5,aVr),e(v5,toe),e(toe,nVr),e(v5,sVr),e(ce,lVr),e(ce,F5),e(F5,z5e),e(z5e,iVr),e(F5,dVr),e(F5,aoe),e(aoe,cVr),e(F5,fVr),e(ce,mVr),e(ce,T5),e(T5,W5e),e(W5e,gVr),e(T5,hVr),e(T5,noe),e(noe,pVr),e(T5,_Vr),e(ce,uVr),e(ce,M5),e(M5,Q5e),e(Q5e,bVr),e(M5,vVr),e(M5,soe),e(soe,FVr),e(M5,TVr),e(ce,MVr),e(ce,E5),e(E5,H5e),e(H5e,EVr),e(E5,CVr),e(E5,loe),e(loe,wVr),e(E5,AVr),e(ce,LVr),e(ce,C5),e(C5,U5e),e(U5e,yVr),e(C5,xVr),e(C5,ioe),e(ioe,$Vr),e(C5,kVr),e(ce,SVr),e(ce,w5),e(w5,J5e),e(J5e,RVr),e(w5,PVr),e(w5,doe),e(doe,BVr),e(w5,IVr),e(ce,NVr),e(ce,A5),e(A5,Y5e),e(Y5e,qVr),e(A5,jVr),e(A5,coe),e(coe,DVr),e(A5,GVr),e(ce,OVr),e(ce,L5),e(L5,K5e),e(K5e,VVr),e(L5,XVr),e(L5,foe),e(foe,zVr),e(L5,WVr),e(Vr,QVr),M(y5,Vr,null),b(f,bHe,u),b(f,Zc,u),e(Zc,x5),e(x5,Z5e),M(z$,Z5e,null),e(Zc,HVr),e(Zc,e0e),e(e0e,UVr),b(f,vHe,u),b(f,_r,u),M(W$,_r,null),e(_r,JVr),e(_r,ef),e(ef,YVr),e(ef,moe),e(moe,KVr),e(ef,ZVr),e(ef,goe),e(goe,eXr),e(ef,oXr),e(_r,rXr),e(_r,Q$),e(Q$,tXr),e(Q$,o0e),e(o0e,aXr),e(Q$,nXr),e(_r,sXr),e(_r,Ht),M(H$,Ht,null),e(Ht,lXr),e(Ht,r0e),e(r0e,iXr),e(Ht,dXr),e(Ht,of),e(of,cXr),e(of,t0e),e(t0e,fXr),e(of,mXr),e(of,hoe),e(hoe,gXr),e(of,hXr),e(Ht,pXr),M($5,Ht,null),e(_r,_Xr),e(_r,Xr),M(U$,Xr,null),e(Xr,uXr),e(Xr,a0e),e(a0e,bXr),e(Xr,vXr),e(Xr,wn),e(wn,FXr),e(wn,n0e),e(n0e,TXr),e(wn,MXr),e(wn,s0e),e(s0e,EXr),e(wn,CXr),e(wn,l0e),e(l0e,wXr),e(wn,AXr),e(Xr,LXr),e(Xr,i0e),e(i0e,k5),e(k5,d0e),e(d0e,yXr),e(k5,xXr),e(k5,poe),e(poe,$Xr),e(k5,kXr),e(Xr,SXr),M(S5,Xr,null),b(f,FHe,u),b(f,rf,u),e(rf,R5),e(R5,c0e),M(J$,c0e,null),e(rf,RXr),e(rf,f0e),e(f0e,PXr),b(f,THe,u),b(f,ur,u),M(Y$,ur,null),e(ur,BXr),e(ur,tf),e(tf,IXr),e(tf,_oe),e(_oe,NXr),e(tf,qXr),e(tf,uoe),e(uoe,jXr),e(tf,DXr),e(ur,GXr),e(ur,K$),e(K$,OXr),e(K$,m0e),e(m0e,VXr),e(K$,XXr),e(ur,zXr),e(ur,Ut),M(Z$,Ut,null),e(Ut,WXr),e(Ut,g0e),e(g0e,QXr),e(Ut,HXr),e(Ut,af),e(af,UXr),e(af,h0e),e(h0e,JXr),e(af,YXr),e(af,boe),e(boe,KXr),e(af,ZXr),e(Ut,ezr),M(P5,Ut,null),e(ur,ozr),e(ur,zr),M(ek,zr,null),e(zr,rzr),e(zr,p0e),e(p0e,tzr),e(zr,azr),e(zr,An),e(An,nzr),e(An,_0e),e(_0e,szr),e(An,lzr),e(An,u0e),e(u0e,izr),e(An,dzr),e(An,b0e),e(b0e,czr),e(An,fzr),e(zr,mzr),e(zr,v0e),e(v0e,B5),e(B5,F0e),e(F0e,gzr),e(B5,hzr),e(B5,voe),e(voe,pzr),e(B5,_zr),e(zr,uzr),M(I5,zr,null),b(f,MHe,u),b(f,nf,u),e(nf,N5),e(N5,T0e),M(ok,T0e,null),e(nf,bzr),e(nf,M0e),e(M0e,vzr),b(f,EHe,u),b(f,br,u),M(rk,br,null),e(br,Fzr),e(br,sf),e(sf,Tzr),e(sf,Foe),e(Foe,Mzr),e(sf,Ezr),e(sf,Toe),e(Toe,Czr),e(sf,wzr),e(br,Azr),e(br,tk),e(tk,Lzr),e(tk,E0e),e(E0e,yzr),e(tk,xzr),e(br,$zr),e(br,Jt),M(ak,Jt,null),e(Jt,kzr),e(Jt,C0e),e(C0e,Szr),e(Jt,Rzr),e(Jt,lf),e(lf,Pzr),e(lf,w0e),e(w0e,Bzr),e(lf,Izr),e(lf,Moe),e(Moe,Nzr),e(lf,qzr),e(Jt,jzr),M(q5,Jt,null),e(br,Dzr),e(br,Wr),M(nk,Wr,null),e(Wr,Gzr),e(Wr,A0e),e(A0e,Ozr),e(Wr,Vzr),e(Wr,Ln),e(Ln,Xzr),e(Ln,L0e),e(L0e,zzr),e(Ln,Wzr),e(Ln,y0e),e(y0e,Qzr),e(Ln,Hzr),e(Ln,x0e),e(x0e,Uzr),e(Ln,Jzr),e(Wr,Yzr),e(Wr,oe),e(oe,j5),e(j5,$0e),e($0e,Kzr),e(j5,Zzr),e(j5,Eoe),e(Eoe,eWr),e(j5,oWr),e(oe,rWr),e(oe,D5),e(D5,k0e),e(k0e,tWr),e(D5,aWr),e(D5,Coe),e(Coe,nWr),e(D5,sWr),e(oe,lWr),e(oe,G5),e(G5,S0e),e(S0e,iWr),e(G5,dWr),e(G5,woe),e(woe,cWr),e(G5,fWr),e(oe,mWr),e(oe,O5),e(O5,R0e),e(R0e,gWr),e(O5,hWr),e(O5,Aoe),e(Aoe,pWr),e(O5,_Wr),e(oe,uWr),e(oe,V5),e(V5,P0e),e(P0e,bWr),e(V5,vWr),e(V5,Loe),e(Loe,FWr),e(V5,TWr),e(oe,MWr),e(oe,X5),e(X5,B0e),e(B0e,EWr),e(X5,CWr),e(X5,yoe),e(yoe,wWr),e(X5,AWr),e(oe,LWr),e(oe,z5),e(z5,I0e),e(I0e,yWr),e(z5,xWr),e(z5,xoe),e(xoe,$Wr),e(z5,kWr),e(oe,SWr),e(oe,W5),e(W5,N0e),e(N0e,RWr),e(W5,PWr),e(W5,$oe),e($oe,BWr),e(W5,IWr),e(oe,NWr),e(oe,Q5),e(Q5,q0e),e(q0e,qWr),e(Q5,jWr),e(Q5,koe),e(koe,DWr),e(Q5,GWr),e(oe,OWr),e(oe,H5),e(H5,j0e),e(j0e,VWr),e(H5,XWr),e(H5,Soe),e(Soe,zWr),e(H5,WWr),e(oe,QWr),e(oe,U5),e(U5,D0e),e(D0e,HWr),e(U5,UWr),e(U5,Roe),e(Roe,JWr),e(U5,YWr),e(oe,KWr),e(oe,J5),e(J5,G0e),e(G0e,ZWr),e(J5,eQr),e(J5,Poe),e(Poe,oQr),e(J5,rQr),e(oe,tQr),e(oe,Y5),e(Y5,O0e),e(O0e,aQr),e(Y5,nQr),e(Y5,Boe),e(Boe,sQr),e(Y5,lQr),e(oe,iQr),e(oe,K5),e(K5,V0e),e(V0e,dQr),e(K5,cQr),e(K5,Ioe),e(Ioe,fQr),e(K5,mQr),e(oe,gQr),e(oe,Z5),e(Z5,X0e),e(X0e,hQr),e(Z5,pQr),e(Z5,Noe),e(Noe,_Qr),e(Z5,uQr),e(oe,bQr),e(oe,e0),e(e0,z0e),e(z0e,vQr),e(e0,FQr),e(e0,qoe),e(qoe,TQr),e(e0,MQr),e(oe,EQr),e(oe,o0),e(o0,W0e),e(W0e,CQr),e(o0,wQr),e(o0,joe),e(joe,AQr),e(o0,LQr),e(oe,yQr),e(oe,r0),e(r0,Q0e),e(Q0e,xQr),e(r0,$Qr),e(r0,Doe),e(Doe,kQr),e(r0,SQr),e(oe,RQr),e(oe,t0),e(t0,H0e),e(H0e,PQr),e(t0,BQr),e(t0,Goe),e(Goe,IQr),e(t0,NQr),e(oe,qQr),e(oe,a0),e(a0,U0e),e(U0e,jQr),e(a0,DQr),e(a0,Ooe),e(Ooe,GQr),e(a0,OQr),e(oe,VQr),e(oe,n0),e(n0,J0e),e(J0e,XQr),e(n0,zQr),e(n0,Voe),e(Voe,WQr),e(n0,QQr),e(oe,HQr),e(oe,s0),e(s0,Y0e),e(Y0e,UQr),e(s0,JQr),e(s0,Xoe),e(Xoe,YQr),e(s0,KQr),e(oe,ZQr),e(oe,l0),e(l0,K0e),e(K0e,eHr),e(l0,oHr),e(l0,zoe),e(zoe,rHr),e(l0,tHr),e(oe,aHr),e(oe,i0),e(i0,Z0e),e(Z0e,nHr),e(i0,sHr),e(i0,Woe),e(Woe,lHr),e(i0,iHr),e(oe,dHr),e(oe,d0),e(d0,ewe),e(ewe,cHr),e(d0,fHr),e(d0,Qoe),e(Qoe,mHr),e(d0,gHr),e(oe,hHr),e(oe,c0),e(c0,owe),e(owe,pHr),e(c0,_Hr),e(c0,Hoe),e(Hoe,uHr),e(c0,bHr),e(oe,vHr),e(oe,f0),e(f0,rwe),e(rwe,FHr),e(f0,THr),e(f0,Uoe),e(Uoe,MHr),e(f0,EHr),e(oe,CHr),e(oe,m0),e(m0,twe),e(twe,wHr),e(m0,AHr),e(m0,Joe),e(Joe,LHr),e(m0,yHr),e(Wr,xHr),M(g0,Wr,null),b(f,CHe,u),b(f,df,u),e(df,h0),e(h0,awe),M(sk,awe,null),e(df,$Hr),e(df,nwe),e(nwe,kHr),b(f,wHe,u),b(f,vr,u),M(lk,vr,null),e(vr,SHr),e(vr,cf),e(cf,RHr),e(cf,Yoe),e(Yoe,PHr),e(cf,BHr),e(cf,Koe),e(Koe,IHr),e(cf,NHr),e(vr,qHr),e(vr,ik),e(ik,jHr),e(ik,swe),e(swe,DHr),e(ik,GHr),e(vr,OHr),e(vr,Yt),M(dk,Yt,null),e(Yt,VHr),e(Yt,lwe),e(lwe,XHr),e(Yt,zHr),e(Yt,ff),e(ff,WHr),e(ff,iwe),e(iwe,QHr),e(ff,HHr),e(ff,Zoe),e(Zoe,UHr),e(ff,JHr),e(Yt,YHr),M(p0,Yt,null),e(vr,KHr),e(vr,Qr),M(ck,Qr,null),e(Qr,ZHr),e(Qr,dwe),e(dwe,eUr),e(Qr,oUr),e(Qr,yn),e(yn,rUr),e(yn,cwe),e(cwe,tUr),e(yn,aUr),e(yn,fwe),e(fwe,nUr),e(yn,sUr),e(yn,mwe),e(mwe,lUr),e(yn,iUr),e(Qr,dUr),e(Qr,xe),e(xe,_0),e(_0,gwe),e(gwe,cUr),e(_0,fUr),e(_0,ere),e(ere,mUr),e(_0,gUr),e(xe,hUr),e(xe,u0),e(u0,hwe),e(hwe,pUr),e(u0,_Ur),e(u0,ore),e(ore,uUr),e(u0,bUr),e(xe,vUr),e(xe,b0),e(b0,pwe),e(pwe,FUr),e(b0,TUr),e(b0,rre),e(rre,MUr),e(b0,EUr),e(xe,CUr),e(xe,v0),e(v0,_we),e(_we,wUr),e(v0,AUr),e(v0,tre),e(tre,LUr),e(v0,yUr),e(xe,xUr),e(xe,F0),e(F0,uwe),e(uwe,$Ur),e(F0,kUr),e(F0,are),e(are,SUr),e(F0,RUr),e(xe,PUr),e(xe,T0),e(T0,bwe),e(bwe,BUr),e(T0,IUr),e(T0,nre),e(nre,NUr),e(T0,qUr),e(xe,jUr),e(xe,M0),e(M0,vwe),e(vwe,DUr),e(M0,GUr),e(M0,sre),e(sre,OUr),e(M0,VUr),e(xe,XUr),e(xe,E0),e(E0,Fwe),e(Fwe,zUr),e(E0,WUr),e(E0,lre),e(lre,QUr),e(E0,HUr),e(xe,UUr),e(xe,C0),e(C0,Twe),e(Twe,JUr),e(C0,YUr),e(C0,ire),e(ire,KUr),e(C0,ZUr),e(xe,eJr),e(xe,w0),e(w0,Mwe),e(Mwe,oJr),e(w0,rJr),e(w0,dre),e(dre,tJr),e(w0,aJr),e(Qr,nJr),M(A0,Qr,null),b(f,AHe,u),b(f,mf,u),e(mf,L0),e(L0,Ewe),M(fk,Ewe,null),e(mf,sJr),e(mf,Cwe),e(Cwe,lJr),b(f,LHe,u),b(f,Fr,u),M(mk,Fr,null),e(Fr,iJr),e(Fr,gf),e(gf,dJr),e(gf,cre),e(cre,cJr),e(gf,fJr),e(gf,fre),e(fre,mJr),e(gf,gJr),e(Fr,hJr),e(Fr,gk),e(gk,pJr),e(gk,wwe),e(wwe,_Jr),e(gk,uJr),e(Fr,bJr),e(Fr,Kt),M(hk,Kt,null),e(Kt,vJr),e(Kt,Awe),e(Awe,FJr),e(Kt,TJr),e(Kt,hf),e(hf,MJr),e(hf,Lwe),e(Lwe,EJr),e(hf,CJr),e(hf,mre),e(mre,wJr),e(hf,AJr),e(Kt,LJr),M(y0,Kt,null),e(Fr,yJr),e(Fr,Hr),M(pk,Hr,null),e(Hr,xJr),e(Hr,ywe),e(ywe,$Jr),e(Hr,kJr),e(Hr,xn),e(xn,SJr),e(xn,xwe),e(xwe,RJr),e(xn,PJr),e(xn,$we),e($we,BJr),e(xn,IJr),e(xn,kwe),e(kwe,NJr),e(xn,qJr),e(Hr,jJr),e(Hr,Ee),e(Ee,x0),e(x0,Swe),e(Swe,DJr),e(x0,GJr),e(x0,gre),e(gre,OJr),e(x0,VJr),e(Ee,XJr),e(Ee,$0),e($0,Rwe),e(Rwe,zJr),e($0,WJr),e($0,hre),e(hre,QJr),e($0,HJr),e(Ee,UJr),e(Ee,k0),e(k0,Pwe),e(Pwe,JJr),e(k0,YJr),e(k0,pre),e(pre,KJr),e(k0,ZJr),e(Ee,eYr),e(Ee,S0),e(S0,Bwe),e(Bwe,oYr),e(S0,rYr),e(S0,_re),e(_re,tYr),e(S0,aYr),e(Ee,nYr),e(Ee,R0),e(R0,Iwe),e(Iwe,sYr),e(R0,lYr),e(R0,ure),e(ure,iYr),e(R0,dYr),e(Ee,cYr),e(Ee,P0),e(P0,Nwe),e(Nwe,fYr),e(P0,mYr),e(P0,bre),e(bre,gYr),e(P0,hYr),e(Ee,pYr),e(Ee,B0),e(B0,qwe),e(qwe,_Yr),e(B0,uYr),e(B0,vre),e(vre,bYr),e(B0,vYr),e(Ee,FYr),e(Ee,I0),e(I0,jwe),e(jwe,TYr),e(I0,MYr),e(I0,Fre),e(Fre,EYr),e(I0,CYr),e(Ee,wYr),e(Ee,N0),e(N0,Dwe),e(Dwe,AYr),e(N0,LYr),e(N0,Tre),e(Tre,yYr),e(N0,xYr),e(Ee,$Yr),e(Ee,q0),e(q0,Gwe),e(Gwe,kYr),e(q0,SYr),e(q0,Mre),e(Mre,RYr),e(q0,PYr),e(Ee,BYr),e(Ee,j0),e(j0,Owe),e(Owe,IYr),e(j0,NYr),e(j0,Ere),e(Ere,qYr),e(j0,jYr),e(Ee,DYr),e(Ee,D0),e(D0,Vwe),e(Vwe,GYr),e(D0,OYr),e(D0,Cre),e(Cre,VYr),e(D0,XYr),e(Ee,zYr),e(Ee,G0),e(G0,Xwe),e(Xwe,WYr),e(G0,QYr),e(G0,wre),e(wre,HYr),e(G0,UYr),e(Hr,JYr),M(O0,Hr,null),b(f,yHe,u),b(f,pf,u),e(pf,V0),e(V0,zwe),M(_k,zwe,null),e(pf,YYr),e(pf,Wwe),e(Wwe,KYr),b(f,xHe,u),b(f,Tr,u),M(uk,Tr,null),e(Tr,ZYr),e(Tr,_f),e(_f,eKr),e(_f,Are),e(Are,oKr),e(_f,rKr),e(_f,Lre),e(Lre,tKr),e(_f,aKr),e(Tr,nKr),e(Tr,bk),e(bk,sKr),e(bk,Qwe),e(Qwe,lKr),e(bk,iKr),e(Tr,dKr),e(Tr,Zt),M(vk,Zt,null),e(Zt,cKr),e(Zt,Hwe),e(Hwe,fKr),e(Zt,mKr),e(Zt,uf),e(uf,gKr),e(uf,Uwe),e(Uwe,hKr),e(uf,pKr),e(uf,yre),e(yre,_Kr),e(uf,uKr),e(Zt,bKr),M(X0,Zt,null),e(Tr,vKr),e(Tr,Ur),M(Fk,Ur,null),e(Ur,FKr),e(Ur,Jwe),e(Jwe,TKr),e(Ur,MKr),e(Ur,$n),e($n,EKr),e($n,Ywe),e(Ywe,CKr),e($n,wKr),e($n,Kwe),e(Kwe,AKr),e($n,LKr),e($n,Zwe),e(Zwe,yKr),e($n,xKr),e(Ur,$Kr),e(Ur,$e),e($e,z0),e(z0,e6e),e(e6e,kKr),e(z0,SKr),e(z0,xre),e(xre,RKr),e(z0,PKr),e($e,BKr),e($e,W0),e(W0,o6e),e(o6e,IKr),e(W0,NKr),e(W0,$re),e($re,qKr),e(W0,jKr),e($e,DKr),e($e,Q0),e(Q0,r6e),e(r6e,GKr),e(Q0,OKr),e(Q0,kre),e(kre,VKr),e(Q0,XKr),e($e,zKr),e($e,H0),e(H0,t6e),e(t6e,WKr),e(H0,QKr),e(H0,Sre),e(Sre,HKr),e(H0,UKr),e($e,JKr),e($e,U0),e(U0,a6e),e(a6e,YKr),e(U0,KKr),e(U0,Rre),e(Rre,ZKr),e(U0,eZr),e($e,oZr),e($e,J0),e(J0,n6e),e(n6e,rZr),e(J0,tZr),e(J0,Pre),e(Pre,aZr),e(J0,nZr),e($e,sZr),e($e,Y0),e(Y0,s6e),e(s6e,lZr),e(Y0,iZr),e(Y0,Bre),e(Bre,dZr),e(Y0,cZr),e($e,fZr),e($e,K0),e(K0,l6e),e(l6e,mZr),e(K0,gZr),e(K0,Ire),e(Ire,hZr),e(K0,pZr),e($e,_Zr),e($e,Z0),e(Z0,i6e),e(i6e,uZr),e(Z0,bZr),e(Z0,Nre),e(Nre,vZr),e(Z0,FZr),e($e,TZr),e($e,ew),e(ew,d6e),e(d6e,MZr),e(ew,EZr),e(ew,qre),e(qre,CZr),e(ew,wZr),e(Ur,AZr),M(ow,Ur,null),b(f,$He,u),b(f,bf,u),e(bf,rw),e(rw,c6e),M(Tk,c6e,null),e(bf,LZr),e(bf,f6e),e(f6e,yZr),b(f,kHe,u),b(f,Mr,u),M(Mk,Mr,null),e(Mr,xZr),e(Mr,vf),e(vf,$Zr),e(vf,jre),e(jre,kZr),e(vf,SZr),e(vf,Dre),e(Dre,RZr),e(vf,PZr),e(Mr,BZr),e(Mr,Ek),e(Ek,IZr),e(Ek,m6e),e(m6e,NZr),e(Ek,qZr),e(Mr,jZr),e(Mr,ea),M(Ck,ea,null),e(ea,DZr),e(ea,g6e),e(g6e,GZr),e(ea,OZr),e(ea,Ff),e(Ff,VZr),e(Ff,h6e),e(h6e,XZr),e(Ff,zZr),e(Ff,Gre),e(Gre,WZr),e(Ff,QZr),e(ea,HZr),M(tw,ea,null),e(Mr,UZr),e(Mr,Jr),M(wk,Jr,null),e(Jr,JZr),e(Jr,p6e),e(p6e,YZr),e(Jr,KZr),e(Jr,kn),e(kn,ZZr),e(kn,_6e),e(_6e,eet),e(kn,oet),e(kn,u6e),e(u6e,ret),e(kn,tet),e(kn,b6e),e(b6e,aet),e(kn,net),e(Jr,set),e(Jr,ke),e(ke,aw),e(aw,v6e),e(v6e,iet),e(aw,det),e(aw,Ore),e(Ore,cet),e(aw,fet),e(ke,met),e(ke,nw),e(nw,F6e),e(F6e,get),e(nw,het),e(nw,Vre),e(Vre,pet),e(nw,_et),e(ke,uet),e(ke,sw),e(sw,T6e),e(T6e,bet),e(sw,vet),e(sw,Xre),e(Xre,Fet),e(sw,Tet),e(ke,Met),e(ke,lw),e(lw,M6e),e(M6e,Eet),e(lw,Cet),e(lw,zre),e(zre,wet),e(lw,Aet),e(ke,Let),e(ke,iw),e(iw,E6e),e(E6e,yet),e(iw,xet),e(iw,Wre),e(Wre,$et),e(iw,ket),e(ke,Set),e(ke,dw),e(dw,C6e),e(C6e,Ret),e(dw,Pet),e(dw,Qre),e(Qre,Bet),e(dw,Iet),e(ke,Net),e(ke,cw),e(cw,w6e),e(w6e,qet),e(cw,jet),e(cw,Hre),e(Hre,Det),e(cw,Get),e(ke,Oet),e(ke,fw),e(fw,A6e),e(A6e,Vet),e(fw,Xet),e(fw,Ure),e(Ure,zet),e(fw,Wet),e(ke,Qet),e(ke,mw),e(mw,L6e),e(L6e,Het),e(mw,Uet),e(mw,Jre),e(Jre,Jet),e(mw,Yet),e(ke,Ket),e(ke,gw),e(gw,y6e),e(y6e,Zet),e(gw,eot),e(gw,Yre),e(Yre,oot),e(gw,rot),e(Jr,tot),M(hw,Jr,null),b(f,SHe,u),b(f,Tf,u),e(Tf,pw),e(pw,x6e),M(Ak,x6e,null),e(Tf,aot),e(Tf,$6e),e($6e,not),b(f,RHe,u),b(f,Er,u),M(Lk,Er,null),e(Er,sot),e(Er,Mf),e(Mf,lot),e(Mf,Kre),e(Kre,iot),e(Mf,dot),e(Mf,Zre),e(Zre,cot),e(Mf,fot),e(Er,mot),e(Er,yk),e(yk,got),e(yk,k6e),e(k6e,hot),e(yk,pot),e(Er,_ot),e(Er,oa),M(xk,oa,null),e(oa,uot),e(oa,S6e),e(S6e,bot),e(oa,vot),e(oa,Ef),e(Ef,Fot),e(Ef,R6e),e(R6e,Tot),e(Ef,Mot),e(Ef,ete),e(ete,Eot),e(Ef,Cot),e(oa,wot),M(_w,oa,null),e(Er,Aot),e(Er,Yr),M($k,Yr,null),e(Yr,Lot),e(Yr,P6e),e(P6e,yot),e(Yr,xot),e(Yr,Sn),e(Sn,$ot),e(Sn,B6e),e(B6e,kot),e(Sn,Sot),e(Sn,I6e),e(I6e,Rot),e(Sn,Pot),e(Sn,N6e),e(N6e,Bot),e(Sn,Iot),e(Yr,Not),e(Yr,Se),e(Se,uw),e(uw,q6e),e(q6e,qot),e(uw,jot),e(uw,ote),e(ote,Dot),e(uw,Got),e(Se,Oot),e(Se,bw),e(bw,j6e),e(j6e,Vot),e(bw,Xot),e(bw,rte),e(rte,zot),e(bw,Wot),e(Se,Qot),e(Se,vw),e(vw,D6e),e(D6e,Hot),e(vw,Uot),e(vw,tte),e(tte,Jot),e(vw,Yot),e(Se,Kot),e(Se,Fw),e(Fw,G6e),e(G6e,Zot),e(Fw,ert),e(Fw,ate),e(ate,ort),e(Fw,rrt),e(Se,trt),e(Se,Tw),e(Tw,O6e),e(O6e,art),e(Tw,nrt),e(Tw,nte),e(nte,srt),e(Tw,lrt),e(Se,irt),e(Se,Mw),e(Mw,V6e),e(V6e,drt),e(Mw,crt),e(Mw,ste),e(ste,frt),e(Mw,mrt),e(Se,grt),e(Se,Ew),e(Ew,X6e),e(X6e,hrt),e(Ew,prt),e(Ew,lte),e(lte,_rt),e(Ew,urt),e(Se,brt),e(Se,Cw),e(Cw,z6e),e(z6e,vrt),e(Cw,Frt),e(Cw,ite),e(ite,Trt),e(Cw,Mrt),e(Se,Ert),e(Se,ww),e(ww,W6e),e(W6e,Crt),e(ww,wrt),e(ww,dte),e(dte,Art),e(ww,Lrt),e(Se,yrt),e(Se,Aw),e(Aw,Q6e),e(Q6e,xrt),e(Aw,$rt),e(Aw,cte),e(cte,krt),e(Aw,Srt),e(Yr,Rrt),M(Lw,Yr,null),b(f,PHe,u),b(f,Cf,u),e(Cf,yw),e(yw,H6e),M(kk,H6e,null),e(Cf,Prt),e(Cf,U6e),e(U6e,Brt),b(f,BHe,u),b(f,Cr,u),M(Sk,Cr,null),e(Cr,Irt),e(Cr,wf),e(wf,Nrt),e(wf,fte),e(fte,qrt),e(wf,jrt),e(wf,mte),e(mte,Drt),e(wf,Grt),e(Cr,Ort),e(Cr,Rk),e(Rk,Vrt),e(Rk,J6e),e(J6e,Xrt),e(Rk,zrt),e(Cr,Wrt),e(Cr,ra),M(Pk,ra,null),e(ra,Qrt),e(ra,Y6e),e(Y6e,Hrt),e(ra,Urt),e(ra,Af),e(Af,Jrt),e(Af,K6e),e(K6e,Yrt),e(Af,Krt),e(Af,gte),e(gte,Zrt),e(Af,ett),e(ra,ott),M(xw,ra,null),e(Cr,rtt),e(Cr,Kr),M(Bk,Kr,null),e(Kr,ttt),e(Kr,Z6e),e(Z6e,att),e(Kr,ntt),e(Kr,Rn),e(Rn,stt),e(Rn,eAe),e(eAe,ltt),e(Rn,itt),e(Rn,oAe),e(oAe,dtt),e(Rn,ctt),e(Rn,rAe),e(rAe,ftt),e(Rn,mtt),e(Kr,gtt),e(Kr,Re),e(Re,$w),e($w,tAe),e(tAe,htt),e($w,ptt),e($w,hte),e(hte,_tt),e($w,utt),e(Re,btt),e(Re,kw),e(kw,aAe),e(aAe,vtt),e(kw,Ftt),e(kw,pte),e(pte,Ttt),e(kw,Mtt),e(Re,Ett),e(Re,Sw),e(Sw,nAe),e(nAe,Ctt),e(Sw,wtt),e(Sw,_te),e(_te,Att),e(Sw,Ltt),e(Re,ytt),e(Re,Rw),e(Rw,sAe),e(sAe,xtt),e(Rw,$tt),e(Rw,ute),e(ute,ktt),e(Rw,Stt),e(Re,Rtt),e(Re,Pw),e(Pw,lAe),e(lAe,Ptt),e(Pw,Btt),e(Pw,bte),e(bte,Itt),e(Pw,Ntt),e(Re,qtt),e(Re,Bw),e(Bw,iAe),e(iAe,jtt),e(Bw,Dtt),e(Bw,vte),e(vte,Gtt),e(Bw,Ott),e(Re,Vtt),e(Re,Iw),e(Iw,dAe),e(dAe,Xtt),e(Iw,ztt),e(Iw,Fte),e(Fte,Wtt),e(Iw,Qtt),e(Re,Htt),e(Re,Nw),e(Nw,cAe),e(cAe,Utt),e(Nw,Jtt),e(Nw,Tte),e(Tte,Ytt),e(Nw,Ktt),e(Re,Ztt),e(Re,qw),e(qw,fAe),e(fAe,eat),e(qw,oat),e(qw,Mte),e(Mte,rat),e(qw,tat),e(Re,aat),e(Re,jw),e(jw,mAe),e(mAe,nat),e(jw,sat),e(jw,Ete),e(Ete,lat),e(jw,iat),e(Kr,dat),M(Dw,Kr,null),b(f,IHe,u),b(f,Lf,u),e(Lf,Gw),e(Gw,gAe),M(Ik,gAe,null),e(Lf,cat),e(Lf,hAe),e(hAe,fat),b(f,NHe,u),b(f,wr,u),M(Nk,wr,null),e(wr,mat),e(wr,yf),e(yf,gat),e(yf,Cte),e(Cte,hat),e(yf,pat),e(yf,wte),e(wte,_at),e(yf,uat),e(wr,bat),e(wr,qk),e(qk,vat),e(qk,pAe),e(pAe,Fat),e(qk,Tat),e(wr,Mat),e(wr,ta),M(jk,ta,null),e(ta,Eat),e(ta,_Ae),e(_Ae,Cat),e(ta,wat),e(ta,xf),e(xf,Aat),e(xf,uAe),e(uAe,Lat),e(xf,yat),e(xf,Ate),e(Ate,xat),e(xf,$at),e(ta,kat),M(Ow,ta,null),e(wr,Sat),e(wr,Zr),M(Dk,Zr,null),e(Zr,Rat),e(Zr,bAe),e(bAe,Pat),e(Zr,Bat),e(Zr,Pn),e(Pn,Iat),e(Pn,vAe),e(vAe,Nat),e(Pn,qat),e(Pn,FAe),e(FAe,jat),e(Pn,Dat),e(Pn,TAe),e(TAe,Gat),e(Pn,Oat),e(Zr,Vat),e(Zr,Xe),e(Xe,Vw),e(Vw,MAe),e(MAe,Xat),e(Vw,zat),e(Vw,Lte),e(Lte,Wat),e(Vw,Qat),e(Xe,Hat),e(Xe,Xw),e(Xw,EAe),e(EAe,Uat),e(Xw,Jat),e(Xw,yte),e(yte,Yat),e(Xw,Kat),e(Xe,Zat),e(Xe,zw),e(zw,CAe),e(CAe,ent),e(zw,ont),e(zw,xte),e(xte,rnt),e(zw,tnt),e(Xe,ant),e(Xe,Ww),e(Ww,wAe),e(wAe,nnt),e(Ww,snt),e(Ww,$te),e($te,lnt),e(Ww,int),e(Xe,dnt),e(Xe,Qw),e(Qw,AAe),e(AAe,cnt),e(Qw,fnt),e(Qw,kte),e(kte,mnt),e(Qw,gnt),e(Xe,hnt),e(Xe,Hw),e(Hw,LAe),e(LAe,pnt),e(Hw,_nt),e(Hw,Ste),e(Ste,unt),e(Hw,bnt),e(Xe,vnt),e(Xe,Uw),e(Uw,yAe),e(yAe,Fnt),e(Uw,Tnt),e(Uw,Rte),e(Rte,Mnt),e(Uw,Ent),e(Xe,Cnt),e(Xe,Jw),e(Jw,xAe),e(xAe,wnt),e(Jw,Ant),e(Jw,Pte),e(Pte,Lnt),e(Jw,ynt),e(Zr,xnt),M(Yw,Zr,null),b(f,qHe,u),b(f,$f,u),e($f,Kw),e(Kw,$Ae),M(Gk,$Ae,null),e($f,$nt),e($f,kAe),e(kAe,knt),b(f,jHe,u),b(f,Ar,u),M(Ok,Ar,null),e(Ar,Snt),e(Ar,kf),e(kf,Rnt),e(kf,Bte),e(Bte,Pnt),e(kf,Bnt),e(kf,Ite),e(Ite,Int),e(kf,Nnt),e(Ar,qnt),e(Ar,Vk),e(Vk,jnt),e(Vk,SAe),e(SAe,Dnt),e(Vk,Gnt),e(Ar,Ont),e(Ar,aa),M(Xk,aa,null),e(aa,Vnt),e(aa,RAe),e(RAe,Xnt),e(aa,znt),e(aa,Sf),e(Sf,Wnt),e(Sf,PAe),e(PAe,Qnt),e(Sf,Hnt),e(Sf,Nte),e(Nte,Unt),e(Sf,Jnt),e(aa,Ynt),M(Zw,aa,null),e(Ar,Knt),e(Ar,et),M(zk,et,null),e(et,Znt),e(et,BAe),e(BAe,est),e(et,ost),e(et,Bn),e(Bn,rst),e(Bn,IAe),e(IAe,tst),e(Bn,ast),e(Bn,NAe),e(NAe,nst),e(Bn,sst),e(Bn,qAe),e(qAe,lst),e(Bn,ist),e(et,dst),e(et,ze),e(ze,e6),e(e6,jAe),e(jAe,cst),e(e6,fst),e(e6,qte),e(qte,mst),e(e6,gst),e(ze,hst),e(ze,o6),e(o6,DAe),e(DAe,pst),e(o6,_st),e(o6,jte),e(jte,ust),e(o6,bst),e(ze,vst),e(ze,r6),e(r6,GAe),e(GAe,Fst),e(r6,Tst),e(r6,Dte),e(Dte,Mst),e(r6,Est),e(ze,Cst),e(ze,t6),e(t6,OAe),e(OAe,wst),e(t6,Ast),e(t6,Gte),e(Gte,Lst),e(t6,yst),e(ze,xst),e(ze,a6),e(a6,VAe),e(VAe,$st),e(a6,kst),e(a6,Ote),e(Ote,Sst),e(a6,Rst),e(ze,Pst),e(ze,n6),e(n6,XAe),e(XAe,Bst),e(n6,Ist),e(n6,Vte),e(Vte,Nst),e(n6,qst),e(ze,jst),e(ze,s6),e(s6,zAe),e(zAe,Dst),e(s6,Gst),e(s6,Xte),e(Xte,Ost),e(s6,Vst),e(ze,Xst),e(ze,l6),e(l6,WAe),e(WAe,zst),e(l6,Wst),e(l6,zte),e(zte,Qst),e(l6,Hst),e(et,Ust),M(i6,et,null),b(f,DHe,u),b(f,Rf,u),e(Rf,d6),e(d6,QAe),M(Wk,QAe,null),e(Rf,Jst),e(Rf,HAe),e(HAe,Yst),b(f,GHe,u),b(f,Lr,u),M(Qk,Lr,null),e(Lr,Kst),e(Lr,Pf),e(Pf,Zst),e(Pf,Wte),e(Wte,elt),e(Pf,olt),e(Pf,Qte),e(Qte,rlt),e(Pf,tlt),e(Lr,alt),e(Lr,Hk),e(Hk,nlt),e(Hk,UAe),e(UAe,slt),e(Hk,llt),e(Lr,ilt),e(Lr,na),M(Uk,na,null),e(na,dlt),e(na,JAe),e(JAe,clt),e(na,flt),e(na,Bf),e(Bf,mlt),e(Bf,YAe),e(YAe,glt),e(Bf,hlt),e(Bf,Hte),e(Hte,plt),e(Bf,_lt),e(na,ult),M(c6,na,null),e(Lr,blt),e(Lr,ot),M(Jk,ot,null),e(ot,vlt),e(ot,KAe),e(KAe,Flt),e(ot,Tlt),e(ot,In),e(In,Mlt),e(In,ZAe),e(ZAe,Elt),e(In,Clt),e(In,eLe),e(eLe,wlt),e(In,Alt),e(In,oLe),e(oLe,Llt),e(In,ylt),e(ot,xlt),e(ot,rLe),e(rLe,f6),e(f6,tLe),e(tLe,$lt),e(f6,klt),e(f6,Ute),e(Ute,Slt),e(f6,Rlt),e(ot,Plt),M(m6,ot,null),b(f,OHe,u),b(f,If,u),e(If,g6),e(g6,aLe),M(Yk,aLe,null),e(If,Blt),e(If,nLe),e(nLe,Ilt),b(f,VHe,u),b(f,yr,u),M(Kk,yr,null),e(yr,Nlt),e(yr,Nf),e(Nf,qlt),e(Nf,Jte),e(Jte,jlt),e(Nf,Dlt),e(Nf,Yte),e(Yte,Glt),e(Nf,Olt),e(yr,Vlt),e(yr,Zk),e(Zk,Xlt),e(Zk,sLe),e(sLe,zlt),e(Zk,Wlt),e(yr,Qlt),e(yr,sa),M(eS,sa,null),e(sa,Hlt),e(sa,lLe),e(lLe,Ult),e(sa,Jlt),e(sa,qf),e(qf,Ylt),e(qf,iLe),e(iLe,Klt),e(qf,Zlt),e(qf,Kte),e(Kte,eit),e(qf,oit),e(sa,rit),M(h6,sa,null),e(yr,tit),e(yr,rt),M(oS,rt,null),e(rt,ait),e(rt,dLe),e(dLe,nit),e(rt,sit),e(rt,Nn),e(Nn,lit),e(Nn,cLe),e(cLe,iit),e(Nn,dit),e(Nn,fLe),e(fLe,cit),e(Nn,fit),e(Nn,mLe),e(mLe,mit),e(Nn,git),e(rt,hit),e(rt,rS),e(rS,p6),e(p6,gLe),e(gLe,pit),e(p6,_it),e(p6,Zte),e(Zte,uit),e(p6,bit),e(rS,vit),e(rS,_6),e(_6,hLe),e(hLe,Fit),e(_6,Tit),e(_6,eae),e(eae,Mit),e(_6,Eit),e(rt,Cit),M(u6,rt,null),b(f,XHe,u),b(f,jf,u),e(jf,b6),e(b6,pLe),M(tS,pLe,null),e(jf,wit),e(jf,_Le),e(_Le,Ait),b(f,zHe,u),b(f,xr,u),M(aS,xr,null),e(xr,Lit),e(xr,Df),e(Df,yit),e(Df,oae),e(oae,xit),e(Df,$it),e(Df,rae),e(rae,kit),e(Df,Sit),e(xr,Rit),e(xr,nS),e(nS,Pit),e(nS,uLe),e(uLe,Bit),e(nS,Iit),e(xr,Nit),e(xr,la),M(sS,la,null),e(la,qit),e(la,bLe),e(bLe,jit),e(la,Dit),e(la,Gf),e(Gf,Git),e(Gf,vLe),e(vLe,Oit),e(Gf,Vit),e(Gf,tae),e(tae,Xit),e(Gf,zit),e(la,Wit),M(v6,la,null),e(xr,Qit),e(xr,tt),M(lS,tt,null),e(tt,Hit),e(tt,FLe),e(FLe,Uit),e(tt,Jit),e(tt,qn),e(qn,Yit),e(qn,TLe),e(TLe,Kit),e(qn,Zit),e(qn,MLe),e(MLe,edt),e(qn,odt),e(qn,ELe),e(ELe,rdt),e(qn,tdt),e(tt,adt),e(tt,CLe),e(CLe,F6),e(F6,wLe),e(wLe,ndt),e(F6,sdt),e(F6,aae),e(aae,ldt),e(F6,idt),e(tt,ddt),M(T6,tt,null),WHe=!0},p(f,[u]){const iS={};u&2&&(iS.$$scope={dirty:u,ctx:f}),Jf.$set(iS);const ALe={};u&2&&(ALe.$$scope={dirty:u,ctx:f}),fh.$set(ALe);const LLe={};u&2&&(LLe.$$scope={dirty:u,ctx:f}),Qh.$set(LLe);const yLe={};u&2&&(yLe.$$scope={dirty:u,ctx:f}),Rp.$set(yLe);const dS={};u&2&&(dS.$$scope={dirty:u,ctx:f}),Pp.$set(dS);const xLe={};u&2&&(xLe.$$scope={dirty:u,ctx:f}),r_.$set(xLe);const jn={};u&2&&(jn.$$scope={dirty:u,ctx:f}),t_.$set(jn);const $Le={};u&2&&($Le.$$scope={dirty:u,ctx:f}),s_.$set($Le);const kLe={};u&2&&(kLe.$$scope={dirty:u,ctx:f}),h7.$set(kLe);const SLe={};u&2&&(SLe.$$scope={dirty:u,ctx:f}),_7.$set(SLe);const cS={};u&2&&(cS.$$scope={dirty:u,ctx:f}),f1.$set(cS);const RLe={};u&2&&(RLe.$$scope={dirty:u,ctx:f}),g1.$set(RLe);const fS={};u&2&&(fS.$$scope={dirty:u,ctx:f}),o2.$set(fS);const PLe={};u&2&&(PLe.$$scope={dirty:u,ctx:f}),t2.$set(PLe);const mS={};u&2&&(mS.$$scope={dirty:u,ctx:f}),V2.$set(mS);const BLe={};u&2&&(BLe.$$scope={dirty:u,ctx:f}),z2.$set(BLe);const ILe={};u&2&&(ILe.$$scope={dirty:u,ctx:f}),mb.$set(ILe);const NLe={};u&2&&(NLe.$$scope={dirty:u,ctx:f}),hb.$set(NLe);const Of={};u&2&&(Of.$$scope={dirty:u,ctx:f}),hv.$set(Of);const qLe={};u&2&&(qLe.$$scope={dirty:u,ctx:f}),_v.$set(qLe);const jLe={};u&2&&(jLe.$$scope={dirty:u,ctx:f}),Uv.$set(jLe);const DLe={};u&2&&(DLe.$$scope={dirty:u,ctx:f}),Yv.$set(DLe);const gS={};u&2&&(gS.$$scope={dirty:u,ctx:f}),nF.$set(gS);const GLe={};u&2&&(GLe.$$scope={dirty:u,ctx:f}),lF.$set(GLe);const OLe={};u&2&&(OLe.$$scope={dirty:u,ctx:f}),WF.$set(OLe);const VLe={};u&2&&(VLe.$$scope={dirty:u,ctx:f}),HF.$set(VLe);const lt={};u&2&&(lt.$$scope={dirty:u,ctx:f}),jT.$set(lt);const hS={};u&2&&(hS.$$scope={dirty:u,ctx:f}),GT.$set(hS);const XLe={};u&2&&(XLe.$$scope={dirty:u,ctx:f}),XT.$set(XLe);const pS={};u&2&&(pS.$$scope={dirty:u,ctx:f}),WT.$set(pS);const zLe={};u&2&&(zLe.$$scope={dirty:u,ctx:f}),i9.$set(zLe);const it={};u&2&&(it.$$scope={dirty:u,ctx:f}),c9.$set(it);const WLe={};u&2&&(WLe.$$scope={dirty:u,ctx:f}),g9.$set(WLe);const Vf={};u&2&&(Vf.$$scope={dirty:u,ctx:f}),p9.$set(Vf);const QLe={};u&2&&(QLe.$$scope={dirty:u,ctx:f}),b9.$set(QLe);const HLe={};u&2&&(HLe.$$scope={dirty:u,ctx:f}),F9.$set(HLe);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),E9.$set(L);const M6={};u&2&&(M6.$$scope={dirty:u,ctx:f}),w9.$set(M6);const ULe={};u&2&&(ULe.$$scope={dirty:u,ctx:f}),I9.$set(ULe);const JLe={};u&2&&(JLe.$$scope={dirty:u,ctx:f}),q9.$set(JLe);const E6={};u&2&&(E6.$$scope={dirty:u,ctx:f}),z9.$set(E6);const YLe={};u&2&&(YLe.$$scope={dirty:u,ctx:f}),Q9.$set(YLe);const KLe={};u&2&&(KLe.$$scope={dirty:u,ctx:f}),nM.$set(KLe);const C6={};u&2&&(C6.$$scope={dirty:u,ctx:f}),lM.$set(C6);const ZLe={};u&2&&(ZLe.$$scope={dirty:u,ctx:f}),fM.$set(ZLe);const eye={};u&2&&(eye.$$scope={dirty:u,ctx:f}),gM.$set(eye);const w6={};u&2&&(w6.$$scope={dirty:u,ctx:f}),FM.$set(w6);const oye={};u&2&&(oye.$$scope={dirty:u,ctx:f}),MM.$set(oye);const rye={};u&2&&(rye.$$scope={dirty:u,ctx:f}),yM.$set(rye);const A6={};u&2&&(A6.$$scope={dirty:u,ctx:f}),$M.$set(A6);const tye={};u&2&&(tye.$$scope={dirty:u,ctx:f}),PM.$set(tye);const aye={};u&2&&(aye.$$scope={dirty:u,ctx:f}),IM.$set(aye);const L6={};u&2&&(L6.$$scope={dirty:u,ctx:f}),jM.$set(L6);const nye={};u&2&&(nye.$$scope={dirty:u,ctx:f}),GM.$set(nye);const sye={};u&2&&(sye.$$scope={dirty:u,ctx:f}),HM.$set(sye);const y6={};u&2&&(y6.$$scope={dirty:u,ctx:f}),JM.$set(y6);const lye={};u&2&&(lye.$$scope={dirty:u,ctx:f}),ZM.$set(lye);const iye={};u&2&&(iye.$$scope={dirty:u,ctx:f}),oE.$set(iye);const x6={};u&2&&(x6.$$scope={dirty:u,ctx:f}),KE.$set(x6);const dye={};u&2&&(dye.$$scope={dirty:u,ctx:f}),e4.$set(dye);const cye={};u&2&&(cye.$$scope={dirty:u,ctx:f}),C4.$set(cye);const $6={};u&2&&($6.$$scope={dirty:u,ctx:f}),A4.$set($6);const fye={};u&2&&(fye.$$scope={dirty:u,ctx:f}),D4.$set(fye);const mye={};u&2&&(mye.$$scope={dirty:u,ctx:f}),O4.$set(mye);const k6={};u&2&&(k6.$$scope={dirty:u,ctx:f}),J4.$set(k6);const gye={};u&2&&(gye.$$scope={dirty:u,ctx:f}),K4.$set(gye);const hye={};u&2&&(hye.$$scope={dirty:u,ctx:f}),vC.$set(hye);const S6={};u&2&&(S6.$$scope={dirty:u,ctx:f}),TC.$set(S6);const pye={};u&2&&(pye.$$scope={dirty:u,ctx:f}),SC.$set(pye);const _ye={};u&2&&(_ye.$$scope={dirty:u,ctx:f}),PC.$set(_ye);const R6={};u&2&&(R6.$$scope={dirty:u,ctx:f}),l3.$set(R6);const uye={};u&2&&(uye.$$scope={dirty:u,ctx:f}),d3.$set(uye);const bye={};u&2&&(bye.$$scope={dirty:u,ctx:f}),L3.$set(bye);const P6={};u&2&&(P6.$$scope={dirty:u,ctx:f}),x3.$set(P6);const vye={};u&2&&(vye.$$scope={dirty:u,ctx:f}),S3.$set(vye);const Fye={};u&2&&(Fye.$$scope={dirty:u,ctx:f}),P3.$set(Fye);const B6={};u&2&&(B6.$$scope={dirty:u,ctx:f}),I3.$set(B6);const Tye={};u&2&&(Tye.$$scope={dirty:u,ctx:f}),q3.$set(Tye);const Mye={};u&2&&(Mye.$$scope={dirty:u,ctx:f}),n5.$set(Mye);const I6={};u&2&&(I6.$$scope={dirty:u,ctx:f}),l5.$set(I6);const Eye={};u&2&&(Eye.$$scope={dirty:u,ctx:f}),y5.$set(Eye);const Cye={};u&2&&(Cye.$$scope={dirty:u,ctx:f}),$5.$set(Cye);const N6={};u&2&&(N6.$$scope={dirty:u,ctx:f}),S5.$set(N6);const wye={};u&2&&(wye.$$scope={dirty:u,ctx:f}),P5.$set(wye);const Aye={};u&2&&(Aye.$$scope={dirty:u,ctx:f}),I5.$set(Aye);const q6={};u&2&&(q6.$$scope={dirty:u,ctx:f}),q5.$set(q6);const Lye={};u&2&&(Lye.$$scope={dirty:u,ctx:f}),g0.$set(Lye);const yye={};u&2&&(yye.$$scope={dirty:u,ctx:f}),p0.$set(yye);const j6={};u&2&&(j6.$$scope={dirty:u,ctx:f}),A0.$set(j6);const xye={};u&2&&(xye.$$scope={dirty:u,ctx:f}),y0.$set(xye);const $ye={};u&2&&($ye.$$scope={dirty:u,ctx:f}),O0.$set($ye);const D6={};u&2&&(D6.$$scope={dirty:u,ctx:f}),X0.$set(D6);const kye={};u&2&&(kye.$$scope={dirty:u,ctx:f}),ow.$set(kye);const Sye={};u&2&&(Sye.$$scope={dirty:u,ctx:f}),tw.$set(Sye);const G6={};u&2&&(G6.$$scope={dirty:u,ctx:f}),hw.$set(G6);const Rye={};u&2&&(Rye.$$scope={dirty:u,ctx:f}),_w.$set(Rye);const Pye={};u&2&&(Pye.$$scope={dirty:u,ctx:f}),Lw.$set(Pye);const O6={};u&2&&(O6.$$scope={dirty:u,ctx:f}),xw.$set(O6);const Bye={};u&2&&(Bye.$$scope={dirty:u,ctx:f}),Dw.$set(Bye);const Iye={};u&2&&(Iye.$$scope={dirty:u,ctx:f}),Ow.$set(Iye);const V6={};u&2&&(V6.$$scope={dirty:u,ctx:f}),Yw.$set(V6);const Nye={};u&2&&(Nye.$$scope={dirty:u,ctx:f}),Zw.$set(Nye);const qye={};u&2&&(qye.$$scope={dirty:u,ctx:f}),i6.$set(qye);const X6={};u&2&&(X6.$$scope={dirty:u,ctx:f}),c6.$set(X6);const jye={};u&2&&(jye.$$scope={dirty:u,ctx:f}),m6.$set(jye);const Dye={};u&2&&(Dye.$$scope={dirty:u,ctx:f}),h6.$set(Dye);const z6={};u&2&&(z6.$$scope={dirty:u,ctx:f}),u6.$set(z6);const Gye={};u&2&&(Gye.$$scope={dirty:u,ctx:f}),v6.$set(Gye);const Oye={};u&2&&(Oye.$$scope={dirty:u,ctx:f}),T6.$set(Oye)},i(f){WHe||(E(d.$$.fragment,f),E(Ia.$$.fragment,f),E(QL.$$.fragment,f),E(HL.$$.fragment,f),E(Jf.$$.fragment,f),E(UL.$$.fragment,f),E(JL.$$.fragment,f),E(ZL.$$.fragment,f),E(fh.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ry.$$.fragment,f),E(ny.$$.fragment,f),E(Qh.$$.fragment,f),E(sy.$$.fragment,f),E(ly.$$.fragment,f),E(iy.$$.fragment,f),E(fy.$$.fragment,f),E(Rp.$$.fragment,f),E(Pp.$$.fragment,f),E(my.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(uy.$$.fragment,f),E(r_.$$.fragment,f),E(t_.$$.fragment,f),E(by.$$.fragment,f),E(vy.$$.fragment,f),E(Fy.$$.fragment,f),E(My.$$.fragment,f),E(s_.$$.fragment,f),E(Ey.$$.fragment,f),E(h7.$$.fragment,f),E(Cy.$$.fragment,f),E(wy.$$.fragment,f),E(Ly.$$.fragment,f),E(_7.$$.fragment,f),E(yy.$$.fragment,f),E(f1.$$.fragment,f),E(xy.$$.fragment,f),E($y.$$.fragment,f),E(Sy.$$.fragment,f),E(g1.$$.fragment,f),E(Ry.$$.fragment,f),E(o2.$$.fragment,f),E(Py.$$.fragment,f),E(By.$$.fragment,f),E(Ny.$$.fragment,f),E(t2.$$.fragment,f),E(qy.$$.fragment,f),E(V2.$$.fragment,f),E(jy.$$.fragment,f),E(Dy.$$.fragment,f),E(Oy.$$.fragment,f),E(z2.$$.fragment,f),E(Vy.$$.fragment,f),E(mb.$$.fragment,f),E(Xy.$$.fragment,f),E(zy.$$.fragment,f),E(Qy.$$.fragment,f),E(hb.$$.fragment,f),E(Hy.$$.fragment,f),E(hv.$$.fragment,f),E(Uy.$$.fragment,f),E(Jy.$$.fragment,f),E(Ky.$$.fragment,f),E(_v.$$.fragment,f),E(Zy.$$.fragment,f),E(Uv.$$.fragment,f),E(e8.$$.fragment,f),E(o8.$$.fragment,f),E(t8.$$.fragment,f),E(Yv.$$.fragment,f),E(a8.$$.fragment,f),E(nF.$$.fragment,f),E(n8.$$.fragment,f),E(s8.$$.fragment,f),E(i8.$$.fragment,f),E(lF.$$.fragment,f),E(d8.$$.fragment,f),E(WF.$$.fragment,f),E(c8.$$.fragment,f),E(f8.$$.fragment,f),E(g8.$$.fragment,f),E(HF.$$.fragment,f),E(h8.$$.fragment,f),E(jT.$$.fragment,f),E(p8.$$.fragment,f),E(_8.$$.fragment,f),E(b8.$$.fragment,f),E(GT.$$.fragment,f),E(v8.$$.fragment,f),E(XT.$$.fragment,f),E(F8.$$.fragment,f),E(T8.$$.fragment,f),E(E8.$$.fragment,f),E(WT.$$.fragment,f),E(C8.$$.fragment,f),E(i9.$$.fragment,f),E(w8.$$.fragment,f),E(A8.$$.fragment,f),E(y8.$$.fragment,f),E(c9.$$.fragment,f),E(x8.$$.fragment,f),E(g9.$$.fragment,f),E($8.$$.fragment,f),E(k8.$$.fragment,f),E(R8.$$.fragment,f),E(p9.$$.fragment,f),E(P8.$$.fragment,f),E(b9.$$.fragment,f),E(B8.$$.fragment,f),E(I8.$$.fragment,f),E(q8.$$.fragment,f),E(F9.$$.fragment,f),E(j8.$$.fragment,f),E(E9.$$.fragment,f),E(D8.$$.fragment,f),E(G8.$$.fragment,f),E(V8.$$.fragment,f),E(w9.$$.fragment,f),E(X8.$$.fragment,f),E(I9.$$.fragment,f),E(z8.$$.fragment,f),E(W8.$$.fragment,f),E(H8.$$.fragment,f),E(q9.$$.fragment,f),E(U8.$$.fragment,f),E(z9.$$.fragment,f),E(J8.$$.fragment,f),E(Y8.$$.fragment,f),E(Z8.$$.fragment,f),E(Q9.$$.fragment,f),E(ex.$$.fragment,f),E(nM.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(lM.$$.fragment,f),E(nx.$$.fragment,f),E(fM.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(gM.$$.fragment,f),E(fx.$$.fragment,f),E(FM.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(MM.$$.fragment,f),E(_x.$$.fragment,f),E(yM.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E($M.$$.fragment,f),E(Tx.$$.fragment,f),E(PM.$$.fragment,f),E(Ex.$$.fragment,f),E(Cx.$$.fragment,f),E(Ax.$$.fragment,f),E(IM.$$.fragment,f),E(Lx.$$.fragment,f),E(jM.$$.fragment,f),E(yx.$$.fragment,f),E(xx.$$.fragment,f),E(kx.$$.fragment,f),E(GM.$$.fragment,f),E(Sx.$$.fragment,f),E(HM.$$.fragment,f),E(Rx.$$.fragment,f),E(Px.$$.fragment,f),E(Ix.$$.fragment,f),E(JM.$$.fragment,f),E(Nx.$$.fragment,f),E(ZM.$$.fragment,f),E(qx.$$.fragment,f),E(jx.$$.fragment,f),E(Gx.$$.fragment,f),E(oE.$$.fragment,f),E(Ox.$$.fragment,f),E(KE.$$.fragment,f),E(Vx.$$.fragment,f),E(Xx.$$.fragment,f),E(Wx.$$.fragment,f),E(e4.$$.fragment,f),E(Qx.$$.fragment,f),E(C4.$$.fragment,f),E(Hx.$$.fragment,f),E(Ux.$$.fragment,f),E(Yx.$$.fragment,f),E(A4.$$.fragment,f),E(Kx.$$.fragment,f),E(D4.$$.fragment,f),E(Zx.$$.fragment,f),E(e$.$$.fragment,f),E(r$.$$.fragment,f),E(O4.$$.fragment,f),E(t$.$$.fragment,f),E(J4.$$.fragment,f),E(a$.$$.fragment,f),E(n$.$$.fragment,f),E(l$.$$.fragment,f),E(K4.$$.fragment,f),E(i$.$$.fragment,f),E(vC.$$.fragment,f),E(d$.$$.fragment,f),E(c$.$$.fragment,f),E(m$.$$.fragment,f),E(TC.$$.fragment,f),E(g$.$$.fragment,f),E(SC.$$.fragment,f),E(h$.$$.fragment,f),E(p$.$$.fragment,f),E(u$.$$.fragment,f),E(PC.$$.fragment,f),E(b$.$$.fragment,f),E(l3.$$.fragment,f),E(v$.$$.fragment,f),E(F$.$$.fragment,f),E(M$.$$.fragment,f),E(d3.$$.fragment,f),E(E$.$$.fragment,f),E(L3.$$.fragment,f),E(C$.$$.fragment,f),E(w$.$$.fragment,f),E(L$.$$.fragment,f),E(x3.$$.fragment,f),E(y$.$$.fragment,f),E(S3.$$.fragment,f),E($$.$$.fragment,f),E(k$.$$.fragment,f),E(R$.$$.fragment,f),E(P3.$$.fragment,f),E(P$.$$.fragment,f),E(I3.$$.fragment,f),E(B$.$$.fragment,f),E(I$.$$.fragment,f),E(q$.$$.fragment,f),E(q3.$$.fragment,f),E(j$.$$.fragment,f),E(n5.$$.fragment,f),E(D$.$$.fragment,f),E(G$.$$.fragment,f),E(V$.$$.fragment,f),E(l5.$$.fragment,f),E(X$.$$.fragment,f),E(y5.$$.fragment,f),E(z$.$$.fragment,f),E(W$.$$.fragment,f),E(H$.$$.fragment,f),E($5.$$.fragment,f),E(U$.$$.fragment,f),E(S5.$$.fragment,f),E(J$.$$.fragment,f),E(Y$.$$.fragment,f),E(Z$.$$.fragment,f),E(P5.$$.fragment,f),E(ek.$$.fragment,f),E(I5.$$.fragment,f),E(ok.$$.fragment,f),E(rk.$$.fragment,f),E(ak.$$.fragment,f),E(q5.$$.fragment,f),E(nk.$$.fragment,f),E(g0.$$.fragment,f),E(sk.$$.fragment,f),E(lk.$$.fragment,f),E(dk.$$.fragment,f),E(p0.$$.fragment,f),E(ck.$$.fragment,f),E(A0.$$.fragment,f),E(fk.$$.fragment,f),E(mk.$$.fragment,f),E(hk.$$.fragment,f),E(y0.$$.fragment,f),E(pk.$$.fragment,f),E(O0.$$.fragment,f),E(_k.$$.fragment,f),E(uk.$$.fragment,f),E(vk.$$.fragment,f),E(X0.$$.fragment,f),E(Fk.$$.fragment,f),E(ow.$$.fragment,f),E(Tk.$$.fragment,f),E(Mk.$$.fragment,f),E(Ck.$$.fragment,f),E(tw.$$.fragment,f),E(wk.$$.fragment,f),E(hw.$$.fragment,f),E(Ak.$$.fragment,f),E(Lk.$$.fragment,f),E(xk.$$.fragment,f),E(_w.$$.fragment,f),E($k.$$.fragment,f),E(Lw.$$.fragment,f),E(kk.$$.fragment,f),E(Sk.$$.fragment,f),E(Pk.$$.fragment,f),E(xw.$$.fragment,f),E(Bk.$$.fragment,f),E(Dw.$$.fragment,f),E(Ik.$$.fragment,f),E(Nk.$$.fragment,f),E(jk.$$.fragment,f),E(Ow.$$.fragment,f),E(Dk.$$.fragment,f),E(Yw.$$.fragment,f),E(Gk.$$.fragment,f),E(Ok.$$.fragment,f),E(Xk.$$.fragment,f),E(Zw.$$.fragment,f),E(zk.$$.fragment,f),E(i6.$$.fragment,f),E(Wk.$$.fragment,f),E(Qk.$$.fragment,f),E(Uk.$$.fragment,f),E(c6.$$.fragment,f),E(Jk.$$.fragment,f),E(m6.$$.fragment,f),E(Yk.$$.fragment,f),E(Kk.$$.fragment,f),E(eS.$$.fragment,f),E(h6.$$.fragment,f),E(oS.$$.fragment,f),E(u6.$$.fragment,f),E(tS.$$.fragment,f),E(aS.$$.fragment,f),E(sS.$$.fragment,f),E(v6.$$.fragment,f),E(lS.$$.fragment,f),E(T6.$$.fragment,f),WHe=!0)},o(f){C(d.$$.fragment,f),C(Ia.$$.fragment,f),C(QL.$$.fragment,f),C(HL.$$.fragment,f),C(Jf.$$.fragment,f),C(UL.$$.fragment,f),C(JL.$$.fragment,f),C(ZL.$$.fragment,f),C(fh.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ry.$$.fragment,f),C(ny.$$.fragment,f),C(Qh.$$.fragment,f),C(sy.$$.fragment,f),C(ly.$$.fragment,f),C(iy.$$.fragment,f),C(fy.$$.fragment,f),C(Rp.$$.fragment,f),C(Pp.$$.fragment,f),C(my.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(uy.$$.fragment,f),C(r_.$$.fragment,f),C(t_.$$.fragment,f),C(by.$$.fragment,f),C(vy.$$.fragment,f),C(Fy.$$.fragment,f),C(My.$$.fragment,f),C(s_.$$.fragment,f),C(Ey.$$.fragment,f),C(h7.$$.fragment,f),C(Cy.$$.fragment,f),C(wy.$$.fragment,f),C(Ly.$$.fragment,f),C(_7.$$.fragment,f),C(yy.$$.fragment,f),C(f1.$$.fragment,f),C(xy.$$.fragment,f),C($y.$$.fragment,f),C(Sy.$$.fragment,f),C(g1.$$.fragment,f),C(Ry.$$.fragment,f),C(o2.$$.fragment,f),C(Py.$$.fragment,f),C(By.$$.fragment,f),C(Ny.$$.fragment,f),C(t2.$$.fragment,f),C(qy.$$.fragment,f),C(V2.$$.fragment,f),C(jy.$$.fragment,f),C(Dy.$$.fragment,f),C(Oy.$$.fragment,f),C(z2.$$.fragment,f),C(Vy.$$.fragment,f),C(mb.$$.fragment,f),C(Xy.$$.fragment,f),C(zy.$$.fragment,f),C(Qy.$$.fragment,f),C(hb.$$.fragment,f),C(Hy.$$.fragment,f),C(hv.$$.fragment,f),C(Uy.$$.fragment,f),C(Jy.$$.fragment,f),C(Ky.$$.fragment,f),C(_v.$$.fragment,f),C(Zy.$$.fragment,f),C(Uv.$$.fragment,f),C(e8.$$.fragment,f),C(o8.$$.fragment,f),C(t8.$$.fragment,f),C(Yv.$$.fragment,f),C(a8.$$.fragment,f),C(nF.$$.fragment,f),C(n8.$$.fragment,f),C(s8.$$.fragment,f),C(i8.$$.fragment,f),C(lF.$$.fragment,f),C(d8.$$.fragment,f),C(WF.$$.fragment,f),C(c8.$$.fragment,f),C(f8.$$.fragment,f),C(g8.$$.fragment,f),C(HF.$$.fragment,f),C(h8.$$.fragment,f),C(jT.$$.fragment,f),C(p8.$$.fragment,f),C(_8.$$.fragment,f),C(b8.$$.fragment,f),C(GT.$$.fragment,f),C(v8.$$.fragment,f),C(XT.$$.fragment,f),C(F8.$$.fragment,f),C(T8.$$.fragment,f),C(E8.$$.fragment,f),C(WT.$$.fragment,f),C(C8.$$.fragment,f),C(i9.$$.fragment,f),C(w8.$$.fragment,f),C(A8.$$.fragment,f),C(y8.$$.fragment,f),C(c9.$$.fragment,f),C(x8.$$.fragment,f),C(g9.$$.fragment,f),C($8.$$.fragment,f),C(k8.$$.fragment,f),C(R8.$$.fragment,f),C(p9.$$.fragment,f),C(P8.$$.fragment,f),C(b9.$$.fragment,f),C(B8.$$.fragment,f),C(I8.$$.fragment,f),C(q8.$$.fragment,f),C(F9.$$.fragment,f),C(j8.$$.fragment,f),C(E9.$$.fragment,f),C(D8.$$.fragment,f),C(G8.$$.fragment,f),C(V8.$$.fragment,f),C(w9.$$.fragment,f),C(X8.$$.fragment,f),C(I9.$$.fragment,f),C(z8.$$.fragment,f),C(W8.$$.fragment,f),C(H8.$$.fragment,f),C(q9.$$.fragment,f),C(U8.$$.fragment,f),C(z9.$$.fragment,f),C(J8.$$.fragment,f),C(Y8.$$.fragment,f),C(Z8.$$.fragment,f),C(Q9.$$.fragment,f),C(ex.$$.fragment,f),C(nM.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(lM.$$.fragment,f),C(nx.$$.fragment,f),C(fM.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(gM.$$.fragment,f),C(fx.$$.fragment,f),C(FM.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(MM.$$.fragment,f),C(_x.$$.fragment,f),C(yM.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C($M.$$.fragment,f),C(Tx.$$.fragment,f),C(PM.$$.fragment,f),C(Ex.$$.fragment,f),C(Cx.$$.fragment,f),C(Ax.$$.fragment,f),C(IM.$$.fragment,f),C(Lx.$$.fragment,f),C(jM.$$.fragment,f),C(yx.$$.fragment,f),C(xx.$$.fragment,f),C(kx.$$.fragment,f),C(GM.$$.fragment,f),C(Sx.$$.fragment,f),C(HM.$$.fragment,f),C(Rx.$$.fragment,f),C(Px.$$.fragment,f),C(Ix.$$.fragment,f),C(JM.$$.fragment,f),C(Nx.$$.fragment,f),C(ZM.$$.fragment,f),C(qx.$$.fragment,f),C(jx.$$.fragment,f),C(Gx.$$.fragment,f),C(oE.$$.fragment,f),C(Ox.$$.fragment,f),C(KE.$$.fragment,f),C(Vx.$$.fragment,f),C(Xx.$$.fragment,f),C(Wx.$$.fragment,f),C(e4.$$.fragment,f),C(Qx.$$.fragment,f),C(C4.$$.fragment,f),C(Hx.$$.fragment,f),C(Ux.$$.fragment,f),C(Yx.$$.fragment,f),C(A4.$$.fragment,f),C(Kx.$$.fragment,f),C(D4.$$.fragment,f),C(Zx.$$.fragment,f),C(e$.$$.fragment,f),C(r$.$$.fragment,f),C(O4.$$.fragment,f),C(t$.$$.fragment,f),C(J4.$$.fragment,f),C(a$.$$.fragment,f),C(n$.$$.fragment,f),C(l$.$$.fragment,f),C(K4.$$.fragment,f),C(i$.$$.fragment,f),C(vC.$$.fragment,f),C(d$.$$.fragment,f),C(c$.$$.fragment,f),C(m$.$$.fragment,f),C(TC.$$.fragment,f),C(g$.$$.fragment,f),C(SC.$$.fragment,f),C(h$.$$.fragment,f),C(p$.$$.fragment,f),C(u$.$$.fragment,f),C(PC.$$.fragment,f),C(b$.$$.fragment,f),C(l3.$$.fragment,f),C(v$.$$.fragment,f),C(F$.$$.fragment,f),C(M$.$$.fragment,f),C(d3.$$.fragment,f),C(E$.$$.fragment,f),C(L3.$$.fragment,f),C(C$.$$.fragment,f),C(w$.$$.fragment,f),C(L$.$$.fragment,f),C(x3.$$.fragment,f),C(y$.$$.fragment,f),C(S3.$$.fragment,f),C($$.$$.fragment,f),C(k$.$$.fragment,f),C(R$.$$.fragment,f),C(P3.$$.fragment,f),C(P$.$$.fragment,f),C(I3.$$.fragment,f),C(B$.$$.fragment,f),C(I$.$$.fragment,f),C(q$.$$.fragment,f),C(q3.$$.fragment,f),C(j$.$$.fragment,f),C(n5.$$.fragment,f),C(D$.$$.fragment,f),C(G$.$$.fragment,f),C(V$.$$.fragment,f),C(l5.$$.fragment,f),C(X$.$$.fragment,f),C(y5.$$.fragment,f),C(z$.$$.fragment,f),C(W$.$$.fragment,f),C(H$.$$.fragment,f),C($5.$$.fragment,f),C(U$.$$.fragment,f),C(S5.$$.fragment,f),C(J$.$$.fragment,f),C(Y$.$$.fragment,f),C(Z$.$$.fragment,f),C(P5.$$.fragment,f),C(ek.$$.fragment,f),C(I5.$$.fragment,f),C(ok.$$.fragment,f),C(rk.$$.fragment,f),C(ak.$$.fragment,f),C(q5.$$.fragment,f),C(nk.$$.fragment,f),C(g0.$$.fragment,f),C(sk.$$.fragment,f),C(lk.$$.fragment,f),C(dk.$$.fragment,f),C(p0.$$.fragment,f),C(ck.$$.fragment,f),C(A0.$$.fragment,f),C(fk.$$.fragment,f),C(mk.$$.fragment,f),C(hk.$$.fragment,f),C(y0.$$.fragment,f),C(pk.$$.fragment,f),C(O0.$$.fragment,f),C(_k.$$.fragment,f),C(uk.$$.fragment,f),C(vk.$$.fragment,f),C(X0.$$.fragment,f),C(Fk.$$.fragment,f),C(ow.$$.fragment,f),C(Tk.$$.fragment,f),C(Mk.$$.fragment,f),C(Ck.$$.fragment,f),C(tw.$$.fragment,f),C(wk.$$.fragment,f),C(hw.$$.fragment,f),C(Ak.$$.fragment,f),C(Lk.$$.fragment,f),C(xk.$$.fragment,f),C(_w.$$.fragment,f),C($k.$$.fragment,f),C(Lw.$$.fragment,f),C(kk.$$.fragment,f),C(Sk.$$.fragment,f),C(Pk.$$.fragment,f),C(xw.$$.fragment,f),C(Bk.$$.fragment,f),C(Dw.$$.fragment,f),C(Ik.$$.fragment,f),C(Nk.$$.fragment,f),C(jk.$$.fragment,f),C(Ow.$$.fragment,f),C(Dk.$$.fragment,f),C(Yw.$$.fragment,f),C(Gk.$$.fragment,f),C(Ok.$$.fragment,f),C(Xk.$$.fragment,f),C(Zw.$$.fragment,f),C(zk.$$.fragment,f),C(i6.$$.fragment,f),C(Wk.$$.fragment,f),C(Qk.$$.fragment,f),C(Uk.$$.fragment,f),C(c6.$$.fragment,f),C(Jk.$$.fragment,f),C(m6.$$.fragment,f),C(Yk.$$.fragment,f),C(Kk.$$.fragment,f),C(eS.$$.fragment,f),C(h6.$$.fragment,f),C(oS.$$.fragment,f),C(u6.$$.fragment,f),C(tS.$$.fragment,f),C(aS.$$.fragment,f),C(sS.$$.fragment,f),C(v6.$$.fragment,f),C(lS.$$.fragment,f),C(T6.$$.fragment,f),WHe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(zf),f&&t(dt),f&&t(Oe),f&&t(Qe),f&&t(Qf),w(Ia,f),f&&t(He),f&&t(Ae),f&&t(Lo),f&&t(Na),f&&t(jWe),f&&t(Vi),w(QL),f&&t(DWe),f&&t(Xn),f&&t(GWe),w(HL,f),f&&t(OWe),f&&t(IR),f&&t(VWe),w(Jf,f),f&&t(XWe),f&&t(Xi),w(UL),f&&t(zWe),f&&t(yo),w(JL),w(ZL),w(fh),w(ey),f&&t(WWe),f&&t(Wi),w(oy),f&&t(QWe),f&&t(xo),w(ry),w(ny),w(Qh),w(sy),f&&t(HWe),f&&t(Qi),w(ly),f&&t(UWe),f&&t($o),w(iy),w(fy),w(Rp),w(Pp),w(my),f&&t(JWe),f&&t(Hi),w(gy),f&&t(YWe),f&&t(ko),w(hy),w(uy),w(r_),w(t_),w(by),f&&t(KWe),f&&t(Ji),w(vy),f&&t(ZWe),f&&t(So),w(Fy),w(My),w(s_),w(Ey),w(h7),f&&t(eQe),f&&t(Zi),w(Cy),f&&t(oQe),f&&t(Ro),w(wy),w(Ly),w(_7),w(yy),w(f1),f&&t(rQe),f&&t(rd),w(xy),f&&t(tQe),f&&t(Po),w($y),w(Sy),w(g1),w(Ry),w(o2),f&&t(aQe),f&&t(nd),w(Py),f&&t(nQe),f&&t(Bo),w(By),w(Ny),w(t2),w(qy),w(V2),f&&t(sQe),f&&t(id),w(jy),f&&t(lQe),f&&t(Io),w(Dy),w(Oy),w(z2),w(Vy),w(mb),f&&t(iQe),f&&t(fd),w(Xy),f&&t(dQe),f&&t(No),w(zy),w(Qy),w(hb),w(Hy),w(hv),f&&t(cQe),f&&t(hd),w(Uy),f&&t(fQe),f&&t(qo),w(Jy),w(Ky),w(_v),w(Zy),w(Uv),f&&t(mQe),f&&t(ud),w(e8),f&&t(gQe),f&&t(jo),w(o8),w(t8),w(Yv),w(a8),w(nF),f&&t(hQe),f&&t(Fd),w(n8),f&&t(pQe),f&&t(Go),w(s8),w(i8),w(lF),w(d8),w(WF),f&&t(_Qe),f&&t(Ed),w(c8),f&&t(uQe),f&&t(Oo),w(f8),w(g8),w(HF),w(h8),w(jT),f&&t(bQe),f&&t(Ad),w(p8),f&&t(vQe),f&&t(Vo),w(_8),w(b8),w(GT),w(v8),w(XT),f&&t(FQe),f&&t(xd),w(F8),f&&t(TQe),f&&t(Xo),w(T8),w(E8),w(WT),w(C8),w(i9),f&&t(MQe),f&&t(Sd),w(w8),f&&t(EQe),f&&t(zo),w(A8),w(y8),w(c9),w(x8),w(g9),f&&t(CQe),f&&t(Bd),w($8),f&&t(wQe),f&&t(Wo),w(k8),w(R8),w(p9),w(P8),w(b9),f&&t(AQe),f&&t(qd),w(B8),f&&t(LQe),f&&t(Qo),w(I8),w(q8),w(F9),w(j8),w(E9),f&&t(yQe),f&&t(Gd),w(D8),f&&t(xQe),f&&t(Ho),w(G8),w(V8),w(w9),w(X8),w(I9),f&&t($Qe),f&&t(Xd),w(z8),f&&t(kQe),f&&t(Uo),w(W8),w(H8),w(q9),w(U8),w(z9),f&&t(SQe),f&&t(Qd),w(J8),f&&t(RQe),f&&t(Jo),w(Y8),w(Z8),w(Q9),w(ex),w(nM),f&&t(PQe),f&&t(Jd),w(ox),f&&t(BQe),f&&t(Yo),w(rx),w(ax),w(lM),w(nx),w(fM),f&&t(IQe),f&&t(Zd),w(lx),f&&t(NQe),f&&t(Ko),w(ix),w(cx),w(gM),w(fx),w(FM),f&&t(qQe),f&&t(rc),w(mx),f&&t(jQe),f&&t(Zo),w(gx),w(px),w(MM),w(_x),w(yM),f&&t(DQe),f&&t(nc),w(ux),f&&t(GQe),f&&t(er),w(bx),w(Fx),w($M),w(Tx),w(PM),f&&t(OQe),f&&t(ic),w(Ex),f&&t(VQe),f&&t(or),w(Cx),w(Ax),w(IM),w(Lx),w(jM),f&&t(XQe),f&&t(fc),w(yx),f&&t(zQe),f&&t(rr),w(xx),w(kx),w(GM),w(Sx),w(HM),f&&t(WQe),f&&t(hc),w(Rx),f&&t(QQe),f&&t(tr),w(Px),w(Ix),w(JM),w(Nx),w(ZM),f&&t(HQe),f&&t(uc),w(qx),f&&t(UQe),f&&t(ar),w(jx),w(Gx),w(oE),w(Ox),w(KE),f&&t(JQe),f&&t(Fc),w(Vx),f&&t(YQe),f&&t(nr),w(Xx),w(Wx),w(e4),w(Qx),w(C4),f&&t(KQe),f&&t(Ec),w(Hx),f&&t(ZQe),f&&t(sr),w(Ux),w(Yx),w(A4),w(Kx),w(D4),f&&t(eHe),f&&t(Ac),w(Zx),f&&t(oHe),f&&t(lr),w(e$),w(r$),w(O4),w(t$),w(J4),f&&t(rHe),f&&t(xc),w(a$),f&&t(tHe),f&&t(ir),w(n$),w(l$),w(K4),w(i$),w(vC),f&&t(aHe),f&&t(Sc),w(d$),f&&t(nHe),f&&t(dr),w(c$),w(m$),w(TC),w(g$),w(SC),f&&t(sHe),f&&t(Bc),w(h$),f&&t(lHe),f&&t(cr),w(p$),w(u$),w(PC),w(b$),w(l3),f&&t(iHe),f&&t(qc),w(v$),f&&t(dHe),f&&t(fr),w(F$),w(M$),w(d3),w(E$),w(L3),f&&t(cHe),f&&t(Gc),w(C$),f&&t(fHe),f&&t(mr),w(w$),w(L$),w(x3),w(y$),w(S3),f&&t(mHe),f&&t(Xc),w($$),f&&t(gHe),f&&t(gr),w(k$),w(R$),w(P3),w(P$),w(I3),f&&t(hHe),f&&t(Qc),w(B$),f&&t(pHe),f&&t(hr),w(I$),w(q$),w(q3),w(j$),w(n5),f&&t(_He),f&&t(Jc),w(D$),f&&t(uHe),f&&t(pr),w(G$),w(V$),w(l5),w(X$),w(y5),f&&t(bHe),f&&t(Zc),w(z$),f&&t(vHe),f&&t(_r),w(W$),w(H$),w($5),w(U$),w(S5),f&&t(FHe),f&&t(rf),w(J$),f&&t(THe),f&&t(ur),w(Y$),w(Z$),w(P5),w(ek),w(I5),f&&t(MHe),f&&t(nf),w(ok),f&&t(EHe),f&&t(br),w(rk),w(ak),w(q5),w(nk),w(g0),f&&t(CHe),f&&t(df),w(sk),f&&t(wHe),f&&t(vr),w(lk),w(dk),w(p0),w(ck),w(A0),f&&t(AHe),f&&t(mf),w(fk),f&&t(LHe),f&&t(Fr),w(mk),w(hk),w(y0),w(pk),w(O0),f&&t(yHe),f&&t(pf),w(_k),f&&t(xHe),f&&t(Tr),w(uk),w(vk),w(X0),w(Fk),w(ow),f&&t($He),f&&t(bf),w(Tk),f&&t(kHe),f&&t(Mr),w(Mk),w(Ck),w(tw),w(wk),w(hw),f&&t(SHe),f&&t(Tf),w(Ak),f&&t(RHe),f&&t(Er),w(Lk),w(xk),w(_w),w($k),w(Lw),f&&t(PHe),f&&t(Cf),w(kk),f&&t(BHe),f&&t(Cr),w(Sk),w(Pk),w(xw),w(Bk),w(Dw),f&&t(IHe),f&&t(Lf),w(Ik),f&&t(NHe),f&&t(wr),w(Nk),w(jk),w(Ow),w(Dk),w(Yw),f&&t(qHe),f&&t($f),w(Gk),f&&t(jHe),f&&t(Ar),w(Ok),w(Xk),w(Zw),w(zk),w(i6),f&&t(DHe),f&&t(Rf),w(Wk),f&&t(GHe),f&&t(Lr),w(Qk),w(Uk),w(c6),w(Jk),w(m6),f&&t(OHe),f&&t(If),w(Yk),f&&t(VHe),f&&t(yr),w(Kk),w(eS),w(h6),w(oS),w(u6),f&&t(XHe),f&&t(jf),w(tS),f&&t(zHe),f&&t(xr),w(aS),w(sS),w(v6),w(lS),w(T6)}}}const lra={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function ira($){return aea(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class pra extends eea{constructor(g){super();oea(this,g,ira,sra,rea,{})}}export{pra as default,lra as metadata};
