import{S as fea,i as mea,s as gea,e as a,k as l,w as F,t as o,M as hea,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as pea,L as N}from"../../chunks/vendor-hf-doc-builder.js";import{T as vdt}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as I}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function _ea($){let g,v,p,m,_,d,h,Ao,Ii,zf,dt,Ni,qi,XL,Wf,Oe,Qe,ji,Dn,zL,Gn,On,WL,Di,Vn,QL,Gi,Qf,Ia;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Ao=o(`, make sure its
`),Ii=a("code"),zf=o("model_type"),dt=o(" attribute is set to the same key you use when registering the config (here "),Ni=a("code"),qi=o('"new-model"'),XL=o(")."),Wf=l(),Oe=a("p"),Qe=o("Likewise, if your "),ji=a("code"),Dn=o("NewModel"),zL=o(" is a subclass of "),Gn=a("a"),On=o("PreTrainedModel"),WL=o(`, make sure its
`),Di=a("code"),Vn=o("config_class"),QL=o(` attribute is set to the same class you use when registering the model (here
`),Gi=a("code"),Qf=o("NewModelConfig"),Ia=o(")."),this.h()},l(He){g=n(He,"P",{});var Le=s(g);v=r(Le,"If your "),p=n(Le,"CODE",{});var SR=s(p);m=r(SR,"NewModelConfig"),SR.forEach(t),_=r(Le," is a subclass of "),d=n(Le,"CODE",{});var Oi=s(d);h=r(Oi,"PretrainedConfig"),Oi.forEach(t),Ao=r(Le,`, make sure its
`),Ii=n(Le,"CODE",{});var RR=s(Ii);zf=r(RR,"model_type"),RR.forEach(t),dt=r(Le," attribute is set to the same key you use when registering the config (here "),Ni=n(Le,"CODE",{});var PR=s(Ni);qi=r(PR,'"new-model"'),PR.forEach(t),XL=r(Le,")."),Le.forEach(t),Wf=i(He),Oe=n(He,"P",{});var Lo=s(Oe);Qe=r(Lo,"Likewise, if your "),ji=n(Lo,"CODE",{});var Na=s(ji);Dn=r(Na,"NewModel"),Na.forEach(t),zL=r(Lo," is a subclass of "),Gn=n(Lo,"A",{href:!0});var BR=s(Gn);On=r(BR,"PreTrainedModel"),BR.forEach(t),WL=r(Lo,`, make sure its
`),Di=n(Lo,"CODE",{});var Hf=s(Di);Vn=r(Hf,"config_class"),Hf.forEach(t),QL=r(Lo,` attribute is set to the same class you use when registering the model (here
`),Gi=n(Lo,"CODE",{});var IR=s(Gi);Qf=r(IR,"NewModelConfig"),IR.forEach(t),Ia=r(Lo,")."),Lo.forEach(t),this.h()},h(){c(Gn,"href","/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel")},m(He,Le){b(He,g,Le),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Ao),e(g,Ii),e(Ii,zf),e(g,dt),e(g,Ni),e(Ni,qi),e(g,XL),b(He,Wf,Le),b(He,Oe,Le),e(Oe,Qe),e(Oe,ji),e(ji,Dn),e(Oe,zL),e(Oe,Gn),e(Gn,On),e(Oe,WL),e(Oe,Di),e(Di,Vn),e(Oe,QL),e(Oe,Gi),e(Gi,Qf),e(Oe,Ia)},d(He){He&&t(g),He&&t(Wf),He&&t(Oe)}}}function uea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vea($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Ao=s(p);m=r(Ao,"use_auth_token=True"),Ao.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function Fea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Tea($){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Ao=s(p);m=r(Ao,"use_auth_token=True"),Ao.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function Mea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Eea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Cea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Aea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Lea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $ea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Sea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Rea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Pea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Bea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Iea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Nea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Dea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Gea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Oea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Vea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Wea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVideoClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVideoClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVideoClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVideoClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVideoClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVideoClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Jea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Kea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zea($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ooa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function roa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function toa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function noa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function soa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function loa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ioa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function doa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function coa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function foa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function moa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function goa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function poa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _oa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function boa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function voa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Foa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Toa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Moa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Eoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Coa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function woa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Aoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Loa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $oa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function koa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Soa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Roa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Poa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Boa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ioa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Noa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function joa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Doa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Goa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Ooa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Voa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Xoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Woa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Qoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Hoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Uoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Joa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Yoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Koa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function Zoa($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function era($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ora($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ara($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ira($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _ra($){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:N,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ura($){let g,v,p,m,_,d,h,Ao,Ii,zf,dt,Ni,qi,XL,Wf,Oe,Qe,ji,Dn,zL,Gn,On,WL,Di,Vn,QL,Gi,Qf,Ia,He,Le,SR,Oi,RR,PR,Lo,Na,BR,Hf,IR,iYe,VWe,Vi,Uf,rse,HL,dYe,tse,cYe,XWe,Xn,fYe,ase,mYe,gYe,nse,hYe,pYe,zWe,UL,WWe,NR,_Ye,QWe,Jf,HWe,Xi,Yf,sse,JL,uYe,lse,bYe,UWe,yo,YL,vYe,KL,FYe,qR,TYe,MYe,EYe,ZL,CYe,ise,wYe,AYe,LYe,$r,ey,yYe,dse,xYe,$Ye,zi,kYe,cse,SYe,RYe,fse,PYe,BYe,IYe,A,Kf,mse,NYe,qYe,jR,jYe,DYe,GYe,Zf,gse,OYe,VYe,DR,XYe,zYe,WYe,em,hse,QYe,HYe,GR,UYe,JYe,YYe,om,pse,KYe,ZYe,OR,eKe,oKe,rKe,rm,_se,tKe,aKe,VR,nKe,sKe,lKe,tm,use,iKe,dKe,XR,cKe,fKe,mKe,am,bse,gKe,hKe,zR,pKe,_Ke,uKe,nm,vse,bKe,vKe,WR,FKe,TKe,MKe,sm,Fse,EKe,CKe,QR,wKe,AKe,LKe,lm,Tse,yKe,xKe,HR,$Ke,kKe,SKe,im,Mse,RKe,PKe,UR,BKe,IKe,NKe,dm,Ese,qKe,jKe,JR,DKe,GKe,OKe,cm,Cse,VKe,XKe,YR,zKe,WKe,QKe,fm,wse,HKe,UKe,KR,JKe,YKe,KKe,mm,Ase,ZKe,eZe,ZR,oZe,rZe,tZe,gm,Lse,aZe,nZe,eP,sZe,lZe,iZe,hm,yse,dZe,cZe,oP,fZe,mZe,gZe,pm,xse,hZe,pZe,rP,_Ze,uZe,bZe,_m,$se,vZe,FZe,tP,TZe,MZe,EZe,um,kse,CZe,wZe,aP,AZe,LZe,yZe,bm,Sse,xZe,$Ze,nP,kZe,SZe,RZe,vm,Rse,PZe,BZe,sP,IZe,NZe,qZe,Fm,Pse,jZe,DZe,lP,GZe,OZe,VZe,Tm,Bse,XZe,zZe,iP,WZe,QZe,HZe,Mm,Ise,UZe,JZe,dP,YZe,KZe,ZZe,Em,Nse,eeo,oeo,cP,reo,teo,aeo,Cm,qse,neo,seo,fP,leo,ieo,deo,wm,jse,ceo,feo,mP,meo,geo,heo,Am,Dse,peo,_eo,gP,ueo,beo,veo,Lm,Gse,Feo,Teo,hP,Meo,Eeo,Ceo,ym,Ose,weo,Aeo,pP,Leo,yeo,xeo,xm,Vse,$eo,keo,_P,Seo,Reo,Peo,$m,Xse,Beo,Ieo,uP,Neo,qeo,jeo,km,zse,Deo,Geo,bP,Oeo,Veo,Xeo,Sm,Wse,zeo,Weo,vP,Qeo,Heo,Ueo,Rm,Qse,Jeo,Yeo,FP,Keo,Zeo,eoo,Pm,Hse,ooo,roo,TP,too,aoo,noo,Bm,Use,soo,loo,MP,ioo,doo,coo,Im,Jse,foo,moo,EP,goo,hoo,poo,Nm,Yse,_oo,uoo,CP,boo,voo,Foo,qm,Kse,Too,Moo,wP,Eoo,Coo,woo,jm,Zse,Aoo,Loo,AP,yoo,xoo,$oo,Dm,ele,koo,Soo,LP,Roo,Poo,Boo,Gm,ole,Ioo,Noo,yP,qoo,joo,Doo,Om,rle,Goo,Ooo,xP,Voo,Xoo,zoo,Vm,tle,Woo,Qoo,$P,Hoo,Uoo,Joo,Xm,ale,Yoo,Koo,kP,Zoo,ero,oro,zm,nle,rro,tro,SP,aro,nro,sro,Wm,sle,lro,iro,RP,dro,cro,fro,Qm,lle,mro,gro,PP,hro,pro,_ro,Hm,ile,uro,bro,BP,vro,Fro,Tro,Um,dle,Mro,Ero,IP,Cro,wro,Aro,Jm,cle,Lro,yro,NP,xro,$ro,kro,Ym,fle,Sro,Rro,qP,Pro,Bro,Iro,Km,mle,Nro,qro,jP,jro,Dro,Gro,Zm,gle,Oro,Vro,DP,Xro,zro,Wro,eg,hle,Qro,Hro,GP,Uro,Jro,Yro,og,ple,Kro,Zro,OP,eto,oto,rto,rg,_le,tto,ato,VP,nto,sto,lto,tg,ule,ito,dto,XP,cto,fto,mto,ag,ble,gto,hto,zP,pto,_to,uto,ng,vle,bto,vto,WP,Fto,Tto,Mto,sg,Fle,Eto,Cto,QP,wto,Ato,Lto,lg,Tle,yto,xto,HP,$to,kto,Sto,ig,Mle,Rto,Pto,UP,Bto,Ito,Nto,dg,Ele,qto,jto,JP,Dto,Gto,Oto,cg,Cle,Vto,Xto,YP,zto,Wto,Qto,fg,wle,Hto,Uto,KP,Jto,Yto,Kto,mg,Ale,Zto,eao,ZP,oao,rao,tao,gg,Lle,aao,nao,eB,sao,lao,iao,hg,yle,dao,cao,oB,fao,mao,gao,pg,xle,hao,pao,rB,_ao,uao,bao,_g,$le,vao,Fao,tB,Tao,Mao,Eao,ug,kle,Cao,wao,aB,Aao,Lao,yao,bg,Sle,xao,$ao,nB,kao,Sao,Rao,vg,Rle,Pao,Bao,sB,Iao,Nao,qao,Fg,Ple,jao,Dao,lB,Gao,Oao,Vao,Tg,Ble,Xao,zao,iB,Wao,Qao,Hao,Mg,Ile,Uao,Jao,dB,Yao,Kao,Zao,Eg,Nle,eno,ono,cB,rno,tno,ano,Cg,qle,nno,sno,fB,lno,ino,dno,wg,jle,cno,fno,mB,mno,gno,hno,Ag,Dle,pno,_no,gB,uno,bno,vno,Lg,Gle,Fno,Tno,hB,Mno,Eno,Cno,yg,Ole,wno,Ano,pB,Lno,yno,xno,xg,Vle,$no,kno,_B,Sno,Rno,Pno,$g,Xle,Bno,Ino,uB,Nno,qno,jno,kg,zle,Dno,Gno,bB,Ono,Vno,Xno,Sg,Wle,zno,Wno,vB,Qno,Hno,Uno,Rg,Qle,Jno,Yno,FB,Kno,Zno,eso,Pg,Hle,oso,rso,TB,tso,aso,nso,Bg,Ule,sso,lso,MB,iso,dso,cso,Ig,Jle,fso,mso,EB,gso,hso,pso,Ng,Yle,_so,uso,CB,bso,vso,Fso,qg,Kle,Tso,Mso,wB,Eso,Cso,wso,jg,Zle,Aso,Lso,AB,yso,xso,$so,Dg,eie,kso,Sso,LB,Rso,Pso,Bso,Gg,oie,Iso,Nso,yB,qso,jso,Dso,Og,rie,Gso,Oso,xB,Vso,Xso,zso,Vg,tie,Wso,Qso,$B,Hso,Uso,Jso,Xg,aie,Yso,Kso,kB,Zso,elo,olo,zg,nie,rlo,tlo,SB,alo,nlo,slo,Wg,sie,llo,ilo,RB,dlo,clo,flo,Qg,lie,mlo,glo,PB,hlo,plo,_lo,Hg,iie,ulo,blo,BB,vlo,Flo,Tlo,Ug,die,Mlo,Elo,IB,Clo,wlo,Alo,Jg,cie,Llo,ylo,NB,xlo,$lo,klo,Yg,fie,Slo,Rlo,qB,Plo,Blo,Ilo,Kg,mie,Nlo,qlo,jB,jlo,Dlo,Glo,Zg,gie,Olo,Vlo,DB,Xlo,zlo,Wlo,eh,hie,Qlo,Hlo,GB,Ulo,Jlo,Ylo,oh,pie,Klo,Zlo,OB,eio,oio,rio,rh,_ie,tio,aio,VB,nio,sio,lio,th,uie,iio,dio,XB,cio,fio,mio,ah,bie,gio,hio,zB,pio,_io,uio,nh,vie,bio,vio,WB,Fio,Tio,Mio,sh,Fie,Eio,Cio,QB,wio,Aio,Lio,lh,Tie,yio,xio,HB,$io,kio,Sio,ih,Mie,Rio,Pio,UB,Bio,Iio,Nio,dh,Eie,qio,jio,JB,Dio,Gio,Oio,ch,Cie,Vio,Xio,YB,zio,Wio,Qio,fh,Hio,mh,oy,Uio,wie,Jio,JWe,Wi,gh,Aie,ry,Yio,Lie,Kio,YWe,xo,ty,Zio,ay,edo,KB,odo,rdo,tdo,ny,ado,yie,ndo,sdo,ldo,kr,sy,ido,xie,ddo,cdo,qa,fdo,$ie,mdo,gdo,kie,hdo,pdo,Sie,_do,udo,bdo,k,zn,Rie,vdo,Fdo,ZB,Tdo,Mdo,eI,Edo,Cdo,wdo,Wn,Pie,Ado,Ldo,oI,ydo,xdo,rI,$do,kdo,Sdo,Qn,Bie,Rdo,Pdo,tI,Bdo,Ido,aI,Ndo,qdo,jdo,hh,Iie,Ddo,Gdo,nI,Odo,Vdo,Xdo,Hn,Nie,zdo,Wdo,sI,Qdo,Hdo,lI,Udo,Jdo,Ydo,ph,qie,Kdo,Zdo,iI,eco,oco,rco,_h,jie,tco,aco,dI,nco,sco,lco,uh,Die,ico,dco,cI,cco,fco,mco,Un,Gie,gco,hco,fI,pco,_co,mI,uco,bco,vco,Jn,Oie,Fco,Tco,gI,Mco,Eco,hI,Cco,wco,Aco,Yn,Vie,Lco,yco,pI,xco,$co,_I,kco,Sco,Rco,bh,Xie,Pco,Bco,uI,Ico,Nco,qco,vh,zie,jco,Dco,bI,Gco,Oco,Vco,Fh,Wie,Xco,zco,vI,Wco,Qco,Hco,Kn,Qie,Uco,Jco,FI,Yco,Kco,TI,Zco,efo,ofo,Th,Hie,rfo,tfo,MI,afo,nfo,sfo,Zn,Uie,lfo,ifo,EI,dfo,cfo,CI,ffo,mfo,gfo,es,Jie,hfo,pfo,wI,_fo,ufo,AI,bfo,vfo,Ffo,os,Yie,Tfo,Mfo,LI,Efo,Cfo,yI,wfo,Afo,Lfo,rs,Kie,yfo,xfo,xI,$fo,kfo,$I,Sfo,Rfo,Pfo,Mh,Zie,Bfo,Ifo,kI,Nfo,qfo,jfo,ts,ede,Dfo,Gfo,SI,Ofo,Vfo,RI,Xfo,zfo,Wfo,as,ode,Qfo,Hfo,PI,Ufo,Jfo,BI,Yfo,Kfo,Zfo,ns,rde,emo,omo,II,rmo,tmo,NI,amo,nmo,smo,ss,tde,lmo,imo,qI,dmo,cmo,jI,fmo,mmo,gmo,ls,ade,hmo,pmo,DI,_mo,umo,GI,bmo,vmo,Fmo,is,nde,Tmo,Mmo,OI,Emo,Cmo,VI,wmo,Amo,Lmo,Eh,sde,ymo,xmo,XI,$mo,kmo,Smo,ds,lde,Rmo,Pmo,zI,Bmo,Imo,WI,Nmo,qmo,jmo,Ch,ide,Dmo,Gmo,QI,Omo,Vmo,Xmo,cs,dde,zmo,Wmo,HI,Qmo,Hmo,UI,Umo,Jmo,Ymo,fs,cde,Kmo,Zmo,JI,ego,ogo,YI,rgo,tgo,ago,ms,fde,ngo,sgo,KI,lgo,igo,ZI,dgo,cgo,fgo,wh,mde,mgo,ggo,eN,hgo,pgo,_go,gs,gde,ugo,bgo,oN,vgo,Fgo,rN,Tgo,Mgo,Ego,hs,hde,Cgo,wgo,tN,Ago,Lgo,aN,ygo,xgo,$go,ps,pde,kgo,Sgo,nN,Rgo,Pgo,sN,Bgo,Igo,Ngo,Ah,_de,qgo,jgo,lN,Dgo,Ggo,Ogo,_s,ude,Vgo,Xgo,iN,zgo,Wgo,dN,Qgo,Hgo,Ugo,us,bde,Jgo,Ygo,cN,Kgo,Zgo,fN,eho,oho,rho,bs,vde,tho,aho,mN,nho,sho,gN,lho,iho,dho,vs,Fde,cho,fho,hN,mho,gho,pN,hho,pho,_ho,Fs,Tde,uho,bho,_N,vho,Fho,uN,Tho,Mho,Eho,Ts,Mde,Cho,who,bN,Aho,Lho,vN,yho,xho,$ho,Ms,Ede,kho,Sho,FN,Rho,Pho,TN,Bho,Iho,Nho,Es,Cde,qho,jho,MN,Dho,Gho,EN,Oho,Vho,Xho,Lh,wde,zho,Who,CN,Qho,Hho,Uho,Cs,Ade,Jho,Yho,wN,Kho,Zho,AN,epo,opo,rpo,yh,Lde,tpo,apo,LN,npo,spo,lpo,xh,yde,ipo,dpo,yN,cpo,fpo,mpo,ws,xde,gpo,hpo,xN,ppo,_po,$N,upo,bpo,vpo,As,$de,Fpo,Tpo,kN,Mpo,Epo,SN,Cpo,wpo,Apo,Ls,kde,Lpo,ypo,RN,xpo,$po,PN,kpo,Spo,Rpo,$h,Sde,Ppo,Bpo,BN,Ipo,Npo,qpo,ys,Rde,jpo,Dpo,IN,Gpo,Opo,NN,Vpo,Xpo,zpo,xs,Pde,Wpo,Qpo,qN,Hpo,Upo,jN,Jpo,Ypo,Kpo,$s,Bde,Zpo,e_o,DN,o_o,r_o,GN,t_o,a_o,n_o,ks,Ide,s_o,l_o,ON,i_o,d_o,VN,c_o,f_o,m_o,Ss,Nde,g_o,h_o,XN,p_o,__o,zN,u_o,b_o,v_o,Rs,qde,F_o,T_o,WN,M_o,E_o,QN,C_o,w_o,A_o,Ps,jde,L_o,y_o,HN,x_o,$_o,UN,k_o,S_o,R_o,Bs,Dde,P_o,B_o,JN,I_o,N_o,YN,q_o,j_o,D_o,kh,Gde,G_o,O_o,KN,V_o,X_o,z_o,Is,Ode,W_o,Q_o,ZN,H_o,U_o,eq,J_o,Y_o,K_o,Ns,Vde,Z_o,euo,oq,ouo,ruo,rq,tuo,auo,nuo,Sh,Xde,suo,luo,tq,iuo,duo,cuo,Rh,zde,fuo,muo,aq,guo,huo,puo,Ph,Wde,_uo,uuo,nq,buo,vuo,Fuo,Bh,Qde,Tuo,Muo,sq,Euo,Cuo,wuo,qs,Hde,Auo,Luo,lq,yuo,xuo,iq,$uo,kuo,Suo,Ih,Ude,Ruo,Puo,dq,Buo,Iuo,Nuo,js,Jde,quo,juo,cq,Duo,Guo,fq,Ouo,Vuo,Xuo,Ds,Yde,zuo,Wuo,mq,Quo,Huo,gq,Uuo,Juo,Yuo,Gs,Kde,Kuo,Zuo,hq,e2o,o2o,pq,r2o,t2o,a2o,Os,Zde,n2o,s2o,_q,l2o,i2o,uq,d2o,c2o,f2o,Vs,ece,m2o,g2o,bq,h2o,p2o,vq,_2o,u2o,b2o,Xs,oce,v2o,F2o,Fq,T2o,M2o,Tq,E2o,C2o,w2o,Nh,rce,A2o,L2o,Mq,y2o,x2o,$2o,qh,tce,k2o,S2o,Eq,R2o,P2o,B2o,zs,ace,I2o,N2o,Cq,q2o,j2o,wq,D2o,G2o,O2o,Ws,nce,V2o,X2o,Aq,z2o,W2o,Lq,Q2o,H2o,U2o,Qs,sce,J2o,Y2o,yq,K2o,Z2o,xq,e1o,o1o,r1o,jh,lce,t1o,a1o,$q,n1o,s1o,l1o,Dh,ice,i1o,d1o,kq,c1o,f1o,m1o,Gh,dce,g1o,h1o,Sq,p1o,_1o,u1o,Hs,cce,b1o,v1o,Rq,F1o,T1o,Pq,M1o,E1o,C1o,Us,fce,w1o,A1o,Bq,L1o,y1o,Iq,x1o,$1o,k1o,Oh,mce,S1o,R1o,Nq,P1o,B1o,I1o,Vh,gce,N1o,q1o,qq,j1o,D1o,G1o,Xh,hce,O1o,V1o,jq,X1o,z1o,W1o,Js,pce,Q1o,H1o,Dq,U1o,J1o,Gq,Y1o,K1o,Z1o,zh,_ce,ebo,obo,Oq,rbo,tbo,abo,Wh,uce,nbo,sbo,Vq,lbo,ibo,dbo,Ys,bce,cbo,fbo,Xq,mbo,gbo,zq,hbo,pbo,_bo,Ks,vce,ubo,bbo,Wq,vbo,Fbo,Qq,Tbo,Mbo,Ebo,Zs,Fce,Cbo,wbo,Hq,Abo,Lbo,Uq,ybo,xbo,$bo,el,Tce,kbo,Sbo,Jq,Rbo,Pbo,Yq,Bbo,Ibo,Nbo,Qh,qbo,Hh,ly,jbo,Mce,Dbo,KWe,Qi,Uh,Ece,iy,Gbo,Cce,Obo,ZWe,$o,dy,Vbo,cy,Xbo,Kq,zbo,Wbo,Qbo,fy,Hbo,wce,Ubo,Jbo,Ybo,Ue,my,Kbo,Ace,Zbo,evo,ja,ovo,Lce,rvo,tvo,yce,avo,nvo,xce,svo,lvo,ivo,H,Jh,$ce,dvo,cvo,Zq,fvo,mvo,gvo,Yh,kce,hvo,pvo,ej,_vo,uvo,bvo,Kh,Sce,vvo,Fvo,oj,Tvo,Mvo,Evo,Zh,Rce,Cvo,wvo,rj,Avo,Lvo,yvo,ep,Pce,xvo,$vo,tj,kvo,Svo,Rvo,op,Bce,Pvo,Bvo,aj,Ivo,Nvo,qvo,rp,Ice,jvo,Dvo,nj,Gvo,Ovo,Vvo,tp,Nce,Xvo,zvo,sj,Wvo,Qvo,Hvo,ap,qce,Uvo,Jvo,lj,Yvo,Kvo,Zvo,np,jce,e0o,o0o,ij,r0o,t0o,a0o,sp,Dce,n0o,s0o,dj,l0o,i0o,d0o,lp,Gce,c0o,f0o,cj,m0o,g0o,h0o,ip,Oce,p0o,_0o,fj,u0o,b0o,v0o,dp,Vce,F0o,T0o,mj,M0o,E0o,C0o,cp,Xce,w0o,A0o,gj,L0o,y0o,x0o,fp,zce,$0o,k0o,hj,S0o,R0o,P0o,mp,Wce,B0o,I0o,pj,N0o,q0o,j0o,gp,Qce,D0o,G0o,_j,O0o,V0o,X0o,hp,Hce,z0o,W0o,uj,Q0o,H0o,U0o,pp,Uce,J0o,Y0o,bj,K0o,Z0o,eFo,_p,Jce,oFo,rFo,vj,tFo,aFo,nFo,up,Yce,sFo,lFo,Fj,iFo,dFo,cFo,bp,Kce,fFo,mFo,Tj,gFo,hFo,pFo,vp,Zce,_Fo,uFo,Mj,bFo,vFo,FFo,Fp,efe,TFo,MFo,Ej,EFo,CFo,wFo,Tp,ofe,AFo,LFo,Cj,yFo,xFo,$Fo,Mp,rfe,kFo,SFo,wj,RFo,PFo,BFo,Ep,tfe,IFo,NFo,Aj,qFo,jFo,DFo,Cp,afe,GFo,OFo,Lj,VFo,XFo,zFo,wp,nfe,WFo,QFo,yj,HFo,UFo,JFo,Ap,sfe,YFo,KFo,xj,ZFo,eTo,oTo,Lp,lfe,rTo,tTo,$j,aTo,nTo,sTo,yp,ife,lTo,iTo,kj,dTo,cTo,fTo,xp,dfe,mTo,gTo,Sj,hTo,pTo,_To,$p,cfe,uTo,bTo,Rj,vTo,FTo,TTo,kp,ffe,MTo,ETo,Pj,CTo,wTo,ATo,Sp,mfe,LTo,yTo,Bj,xTo,$To,kTo,Rp,STo,Pp,RTo,Bp,gy,PTo,gfe,BTo,eQe,Hi,Ip,hfe,hy,ITo,pfe,NTo,oQe,ko,py,qTo,_y,jTo,Ij,DTo,GTo,OTo,uy,VTo,_fe,XTo,zTo,WTo,Je,by,QTo,ufe,HTo,UTo,Ui,JTo,bfe,YTo,KTo,vfe,ZTo,e8o,o8o,fe,Np,Ffe,r8o,t8o,Nj,a8o,n8o,s8o,qp,Tfe,l8o,i8o,qj,d8o,c8o,f8o,jp,Mfe,m8o,g8o,jj,h8o,p8o,_8o,Dp,Efe,u8o,b8o,Dj,v8o,F8o,T8o,Gp,Cfe,M8o,E8o,Gj,C8o,w8o,A8o,Op,wfe,L8o,y8o,Oj,x8o,$8o,k8o,Vp,Afe,S8o,R8o,Vj,P8o,B8o,I8o,Xp,Lfe,N8o,q8o,Xj,j8o,D8o,G8o,zp,yfe,O8o,V8o,zj,X8o,z8o,W8o,Wp,xfe,Q8o,H8o,Wj,U8o,J8o,Y8o,Qp,$fe,K8o,Z8o,Qj,eMo,oMo,rMo,Hp,kfe,tMo,aMo,Hj,nMo,sMo,lMo,Up,Sfe,iMo,dMo,Uj,cMo,fMo,mMo,Jp,Rfe,gMo,hMo,Jj,pMo,_Mo,uMo,Yp,Pfe,bMo,vMo,Yj,FMo,TMo,MMo,Kp,Bfe,EMo,CMo,Kj,wMo,AMo,LMo,Zp,Ife,yMo,xMo,Zj,$Mo,kMo,SMo,e_,Nfe,RMo,PMo,eD,BMo,IMo,NMo,o_,qfe,qMo,jMo,oD,DMo,GMo,OMo,r_,VMo,t_,XMo,a_,vy,zMo,jfe,WMo,rQe,Ji,n_,Dfe,Fy,QMo,Gfe,HMo,tQe,So,Ty,UMo,Yi,JMo,rD,YMo,KMo,tD,ZMo,eEo,oEo,My,rEo,Ofe,tEo,aEo,nEo,ct,Ey,sEo,Vfe,lEo,iEo,Ki,dEo,Xfe,cEo,fEo,aD,mEo,gEo,hEo,s_,pEo,Ye,Cy,_Eo,zfe,uEo,bEo,Da,vEo,Wfe,FEo,TEo,Qfe,MEo,EEo,Hfe,CEo,wEo,AEo,y,l_,Ufe,LEo,yEo,nD,xEo,$Eo,kEo,i_,Jfe,SEo,REo,sD,PEo,BEo,IEo,d_,Yfe,NEo,qEo,lD,jEo,DEo,GEo,c_,Kfe,OEo,VEo,iD,XEo,zEo,WEo,f_,Zfe,QEo,HEo,dD,UEo,JEo,YEo,m_,eme,KEo,ZEo,cD,e4o,o4o,r4o,g_,ome,t4o,a4o,fD,n4o,s4o,l4o,h_,rme,i4o,d4o,mD,c4o,f4o,m4o,p_,tme,g4o,h4o,gD,p4o,_4o,u4o,__,ame,b4o,v4o,hD,F4o,T4o,M4o,u_,nme,E4o,C4o,pD,w4o,A4o,L4o,b_,sme,y4o,x4o,_D,$4o,k4o,S4o,v_,lme,R4o,P4o,uD,B4o,I4o,N4o,F_,ime,q4o,j4o,bD,D4o,G4o,O4o,T_,dme,V4o,X4o,vD,z4o,W4o,Q4o,M_,cme,H4o,U4o,FD,J4o,Y4o,K4o,E_,fme,Z4o,eCo,TD,oCo,rCo,tCo,C_,mme,aCo,nCo,MD,sCo,lCo,iCo,w_,gme,dCo,cCo,ED,fCo,mCo,gCo,A_,hme,hCo,pCo,CD,_Co,uCo,bCo,L_,pme,vCo,FCo,wD,TCo,MCo,ECo,y_,_me,CCo,wCo,AD,ACo,LCo,yCo,x_,ume,xCo,$Co,LD,kCo,SCo,RCo,$_,bme,PCo,BCo,yD,ICo,NCo,qCo,k_,vme,jCo,DCo,xD,GCo,OCo,VCo,S_,Fme,XCo,zCo,$D,WCo,QCo,HCo,R_,Tme,UCo,JCo,kD,YCo,KCo,ZCo,P_,Mme,e5o,o5o,SD,r5o,t5o,a5o,B_,Eme,n5o,s5o,RD,l5o,i5o,d5o,I_,Cme,c5o,f5o,PD,m5o,g5o,h5o,N_,wme,p5o,_5o,BD,u5o,b5o,v5o,q_,Ame,F5o,T5o,ID,M5o,E5o,C5o,j_,Lme,w5o,A5o,ND,L5o,y5o,x5o,D_,yme,$5o,k5o,qD,S5o,R5o,P5o,ol,xme,B5o,I5o,jD,N5o,q5o,DD,j5o,D5o,G5o,G_,$me,O5o,V5o,GD,X5o,z5o,W5o,O_,kme,Q5o,H5o,OD,U5o,J5o,Y5o,V_,Sme,K5o,Z5o,VD,e3o,o3o,r3o,X_,Rme,t3o,a3o,XD,n3o,s3o,l3o,z_,Pme,i3o,d3o,zD,c3o,f3o,m3o,W_,Bme,g3o,h3o,WD,p3o,_3o,u3o,Q_,Ime,b3o,v3o,QD,F3o,T3o,M3o,H_,Nme,E3o,C3o,HD,w3o,A3o,L3o,U_,qme,y3o,x3o,UD,$3o,k3o,S3o,J_,jme,R3o,P3o,JD,B3o,I3o,N3o,Y_,Dme,q3o,j3o,YD,D3o,G3o,O3o,K_,Gme,V3o,X3o,KD,z3o,W3o,Q3o,Z_,Ome,H3o,U3o,ZD,J3o,Y3o,K3o,eu,Vme,Z3o,ewo,eG,owo,rwo,two,ou,Xme,awo,nwo,oG,swo,lwo,iwo,ru,zme,dwo,cwo,rG,fwo,mwo,gwo,tu,Wme,hwo,pwo,tG,_wo,uwo,bwo,au,Qme,vwo,Fwo,aG,Two,Mwo,Ewo,nu,Hme,Cwo,wwo,nG,Awo,Lwo,ywo,su,Ume,xwo,$wo,sG,kwo,Swo,Rwo,lu,Jme,Pwo,Bwo,lG,Iwo,Nwo,qwo,iu,Yme,jwo,Dwo,iG,Gwo,Owo,Vwo,du,Kme,Xwo,zwo,dG,Wwo,Qwo,Hwo,cu,Zme,Uwo,Jwo,cG,Ywo,Kwo,Zwo,fu,ege,e6o,o6o,fG,r6o,t6o,a6o,mu,oge,n6o,s6o,mG,l6o,i6o,d6o,gu,rge,c6o,f6o,gG,m6o,g6o,h6o,hu,tge,p6o,_6o,hG,u6o,b6o,v6o,pu,age,F6o,T6o,pG,M6o,E6o,C6o,_u,nge,w6o,A6o,_G,L6o,y6o,x6o,uu,sge,$6o,k6o,uG,S6o,R6o,P6o,bu,lge,B6o,I6o,bG,N6o,q6o,j6o,vu,ige,D6o,G6o,vG,O6o,V6o,X6o,Fu,dge,z6o,W6o,FG,Q6o,H6o,U6o,Tu,cge,J6o,Y6o,TG,K6o,Z6o,eAo,Mu,fge,oAo,rAo,MG,tAo,aAo,nAo,Eu,mge,sAo,lAo,EG,iAo,dAo,cAo,Cu,gge,fAo,mAo,CG,gAo,hAo,pAo,wu,hge,_Ao,uAo,wG,bAo,vAo,FAo,Au,pge,TAo,MAo,AG,EAo,CAo,wAo,Lu,_ge,AAo,LAo,LG,yAo,xAo,$Ao,yu,uge,kAo,SAo,yG,RAo,PAo,BAo,xu,bge,IAo,NAo,xG,qAo,jAo,DAo,$u,vge,GAo,OAo,$G,VAo,XAo,zAo,ku,Fge,WAo,QAo,kG,HAo,UAo,JAo,Su,Tge,YAo,KAo,SG,ZAo,e7o,o7o,Ru,Mge,r7o,t7o,RG,a7o,n7o,s7o,Pu,Ege,l7o,i7o,PG,d7o,c7o,f7o,Bu,Cge,m7o,g7o,BG,h7o,p7o,_7o,Iu,wge,u7o,b7o,IG,v7o,F7o,T7o,Nu,Age,M7o,E7o,NG,C7o,w7o,A7o,qu,Lge,L7o,y7o,qG,x7o,$7o,k7o,ju,yge,S7o,R7o,jG,P7o,B7o,I7o,Du,xge,N7o,q7o,DG,j7o,D7o,G7o,Gu,$ge,O7o,V7o,GG,X7o,z7o,W7o,Ou,kge,Q7o,H7o,OG,U7o,J7o,Y7o,Vu,Sge,K7o,Z7o,VG,eLo,oLo,rLo,Xu,Rge,tLo,aLo,XG,nLo,sLo,lLo,zu,Pge,iLo,dLo,zG,cLo,fLo,mLo,Wu,Bge,gLo,hLo,WG,pLo,_Lo,uLo,Qu,Ige,bLo,vLo,QG,FLo,TLo,MLo,Hu,Nge,ELo,CLo,HG,wLo,ALo,LLo,Uu,qge,yLo,xLo,UG,$Lo,kLo,SLo,Ju,jge,RLo,PLo,JG,BLo,ILo,NLo,Yu,Dge,qLo,jLo,YG,DLo,GLo,OLo,Ku,Gge,VLo,XLo,KG,zLo,WLo,QLo,Zu,Oge,HLo,ULo,ZG,JLo,YLo,KLo,e2,Vge,ZLo,eyo,eO,oyo,ryo,tyo,o2,Xge,ayo,nyo,oO,syo,lyo,iyo,r2,zge,dyo,cyo,rO,fyo,myo,gyo,t2,Wge,hyo,pyo,tO,_yo,uyo,byo,a2,Qge,vyo,Fyo,aO,Tyo,Myo,Eyo,n2,Hge,Cyo,wyo,nO,Ayo,Lyo,yyo,s2,Uge,xyo,$yo,sO,kyo,Syo,Ryo,l2,Jge,Pyo,Byo,lO,Iyo,Nyo,qyo,i2,Yge,jyo,Dyo,iO,Gyo,Oyo,Vyo,d2,Kge,Xyo,zyo,dO,Wyo,Qyo,Hyo,c2,Zge,Uyo,Jyo,cO,Yyo,Kyo,Zyo,f2,ehe,e9o,o9o,fO,r9o,t9o,a9o,m2,ohe,n9o,s9o,mO,l9o,i9o,d9o,g2,c9o,rhe,f9o,m9o,the,g9o,h9o,h2,aQe,Zi,p2,ahe,wy,p9o,nhe,_9o,nQe,Ro,Ay,u9o,ed,b9o,gO,v9o,F9o,hO,T9o,M9o,E9o,Ly,C9o,she,w9o,A9o,L9o,ft,yy,y9o,lhe,x9o,$9o,od,k9o,ihe,S9o,R9o,pO,P9o,B9o,I9o,_2,N9o,Ke,xy,q9o,dhe,j9o,D9o,Ga,G9o,che,O9o,V9o,fhe,X9o,z9o,mhe,W9o,Q9o,H9o,G,u2,ghe,U9o,J9o,_O,Y9o,K9o,Z9o,b2,hhe,exo,oxo,uO,rxo,txo,axo,v2,phe,nxo,sxo,bO,lxo,ixo,dxo,F2,_he,cxo,fxo,vO,mxo,gxo,hxo,T2,uhe,pxo,_xo,FO,uxo,bxo,vxo,M2,bhe,Fxo,Txo,TO,Mxo,Exo,Cxo,E2,vhe,wxo,Axo,MO,Lxo,yxo,xxo,C2,Fhe,$xo,kxo,EO,Sxo,Rxo,Pxo,w2,The,Bxo,Ixo,CO,Nxo,qxo,jxo,A2,Mhe,Dxo,Gxo,wO,Oxo,Vxo,Xxo,L2,Ehe,zxo,Wxo,AO,Qxo,Hxo,Uxo,y2,Che,Jxo,Yxo,LO,Kxo,Zxo,e$o,x2,whe,o$o,r$o,yO,t$o,a$o,n$o,$2,Ahe,s$o,l$o,xO,i$o,d$o,c$o,k2,Lhe,f$o,m$o,$O,g$o,h$o,p$o,S2,yhe,_$o,u$o,kO,b$o,v$o,F$o,R2,xhe,T$o,M$o,SO,E$o,C$o,w$o,P2,$he,A$o,L$o,RO,y$o,x$o,$$o,B2,khe,k$o,S$o,PO,R$o,P$o,B$o,I2,She,I$o,N$o,BO,q$o,j$o,D$o,N2,Rhe,G$o,O$o,IO,V$o,X$o,z$o,q2,Phe,W$o,Q$o,NO,H$o,U$o,J$o,j2,Bhe,Y$o,K$o,qO,Z$o,eko,oko,D2,Ihe,rko,tko,jO,ako,nko,sko,G2,Nhe,lko,iko,DO,dko,cko,fko,O2,qhe,mko,gko,GO,hko,pko,_ko,V2,jhe,uko,bko,OO,vko,Fko,Tko,X2,Dhe,Mko,Eko,VO,Cko,wko,Ako,z2,Ghe,Lko,yko,XO,xko,$ko,kko,W2,Ohe,Sko,Rko,zO,Pko,Bko,Iko,Q2,Vhe,Nko,qko,WO,jko,Dko,Gko,H2,Xhe,Oko,Vko,QO,Xko,zko,Wko,U2,zhe,Qko,Hko,HO,Uko,Jko,Yko,J2,Whe,Kko,Zko,UO,eSo,oSo,rSo,Y2,Qhe,tSo,aSo,JO,nSo,sSo,lSo,K2,Hhe,iSo,dSo,YO,cSo,fSo,mSo,Z2,Uhe,gSo,hSo,KO,pSo,_So,uSo,e1,Jhe,bSo,vSo,ZO,FSo,TSo,MSo,o1,Yhe,ESo,CSo,eV,wSo,ASo,LSo,r1,Khe,ySo,xSo,oV,$So,kSo,SSo,t1,Zhe,RSo,PSo,rV,BSo,ISo,NSo,a1,epe,qSo,jSo,tV,DSo,GSo,OSo,n1,ope,VSo,XSo,aV,zSo,WSo,QSo,s1,rpe,HSo,USo,nV,JSo,YSo,KSo,l1,tpe,ZSo,eRo,sV,oRo,rRo,tRo,i1,ape,aRo,nRo,lV,sRo,lRo,iRo,d1,npe,dRo,cRo,iV,fRo,mRo,gRo,c1,hRo,spe,pRo,_Ro,lpe,uRo,bRo,f1,sQe,rd,m1,ipe,$y,vRo,dpe,FRo,lQe,Po,ky,TRo,td,MRo,dV,ERo,CRo,cV,wRo,ARo,LRo,Sy,yRo,cpe,xRo,$Ro,kRo,mt,Ry,SRo,fpe,RRo,PRo,ad,BRo,mpe,IRo,NRo,fV,qRo,jRo,DRo,g1,GRo,Ze,Py,ORo,gpe,VRo,XRo,Oa,zRo,hpe,WRo,QRo,ppe,HRo,URo,_pe,JRo,YRo,KRo,z,h1,upe,ZRo,ePo,mV,oPo,rPo,tPo,p1,bpe,aPo,nPo,gV,sPo,lPo,iPo,_1,vpe,dPo,cPo,hV,fPo,mPo,gPo,u1,Fpe,hPo,pPo,pV,_Po,uPo,bPo,b1,Tpe,vPo,FPo,_V,TPo,MPo,EPo,v1,Mpe,CPo,wPo,uV,APo,LPo,yPo,F1,Epe,xPo,$Po,bV,kPo,SPo,RPo,T1,Cpe,PPo,BPo,vV,IPo,NPo,qPo,M1,wpe,jPo,DPo,FV,GPo,OPo,VPo,E1,Ape,XPo,zPo,TV,WPo,QPo,HPo,C1,Lpe,UPo,JPo,MV,YPo,KPo,ZPo,w1,ype,eBo,oBo,EV,rBo,tBo,aBo,A1,xpe,nBo,sBo,CV,lBo,iBo,dBo,L1,$pe,cBo,fBo,wV,mBo,gBo,hBo,y1,kpe,pBo,_Bo,AV,uBo,bBo,vBo,x1,Spe,FBo,TBo,LV,MBo,EBo,CBo,$1,Rpe,wBo,ABo,yV,LBo,yBo,xBo,k1,Ppe,$Bo,kBo,xV,SBo,RBo,PBo,S1,Bpe,BBo,IBo,$V,NBo,qBo,jBo,R1,Ipe,DBo,GBo,kV,OBo,VBo,XBo,P1,Npe,zBo,WBo,SV,QBo,HBo,UBo,B1,qpe,JBo,YBo,RV,KBo,ZBo,eIo,I1,jpe,oIo,rIo,PV,tIo,aIo,nIo,N1,Dpe,sIo,lIo,BV,iIo,dIo,cIo,q1,Gpe,fIo,mIo,IV,gIo,hIo,pIo,j1,Ope,_Io,uIo,NV,bIo,vIo,FIo,D1,Vpe,TIo,MIo,qV,EIo,CIo,wIo,G1,Xpe,AIo,LIo,jV,yIo,xIo,$Io,O1,zpe,kIo,SIo,DV,RIo,PIo,BIo,V1,Wpe,IIo,NIo,GV,qIo,jIo,DIo,X1,Qpe,GIo,OIo,OV,VIo,XIo,zIo,z1,Hpe,WIo,QIo,VV,HIo,UIo,JIo,W1,Upe,YIo,KIo,XV,ZIo,eNo,oNo,Q1,Jpe,rNo,tNo,zV,aNo,nNo,sNo,H1,Ype,lNo,iNo,WV,dNo,cNo,fNo,U1,Kpe,mNo,gNo,QV,hNo,pNo,_No,J1,Zpe,uNo,bNo,HV,vNo,FNo,TNo,Y1,e_e,MNo,ENo,UV,CNo,wNo,ANo,K1,o_e,LNo,yNo,JV,xNo,$No,kNo,Z1,r_e,SNo,RNo,YV,PNo,BNo,INo,eb,NNo,t_e,qNo,jNo,a_e,DNo,GNo,ob,iQe,nd,rb,n_e,By,ONo,s_e,VNo,dQe,Bo,Iy,XNo,sd,zNo,KV,WNo,QNo,ZV,HNo,UNo,JNo,Ny,YNo,l_e,KNo,ZNo,eqo,gt,qy,oqo,i_e,rqo,tqo,ld,aqo,d_e,nqo,sqo,eX,lqo,iqo,dqo,tb,cqo,eo,jy,fqo,c_e,mqo,gqo,Va,hqo,f_e,pqo,_qo,m_e,uqo,bqo,g_e,vqo,Fqo,Tqo,Q,ab,h_e,Mqo,Eqo,oX,Cqo,wqo,Aqo,nb,p_e,Lqo,yqo,rX,xqo,$qo,kqo,sb,__e,Sqo,Rqo,tX,Pqo,Bqo,Iqo,lb,u_e,Nqo,qqo,aX,jqo,Dqo,Gqo,ib,b_e,Oqo,Vqo,nX,Xqo,zqo,Wqo,db,v_e,Qqo,Hqo,sX,Uqo,Jqo,Yqo,cb,F_e,Kqo,Zqo,lX,ejo,ojo,rjo,fb,T_e,tjo,ajo,iX,njo,sjo,ljo,mb,M_e,ijo,djo,dX,cjo,fjo,mjo,gb,E_e,gjo,hjo,cX,pjo,_jo,ujo,hb,C_e,bjo,vjo,fX,Fjo,Tjo,Mjo,pb,w_e,Ejo,Cjo,mX,wjo,Ajo,Ljo,_b,A_e,yjo,xjo,gX,$jo,kjo,Sjo,ub,L_e,Rjo,Pjo,hX,Bjo,Ijo,Njo,bb,y_e,qjo,jjo,pX,Djo,Gjo,Ojo,vb,x_e,Vjo,Xjo,_X,zjo,Wjo,Qjo,Fb,$_e,Hjo,Ujo,uX,Jjo,Yjo,Kjo,Tb,k_e,Zjo,eDo,bX,oDo,rDo,tDo,Mb,S_e,aDo,nDo,vX,sDo,lDo,iDo,Eb,R_e,dDo,cDo,FX,fDo,mDo,gDo,Cb,P_e,hDo,pDo,TX,_Do,uDo,bDo,wb,B_e,vDo,FDo,MX,TDo,MDo,EDo,Ab,I_e,CDo,wDo,EX,ADo,LDo,yDo,Lb,N_e,xDo,$Do,CX,kDo,SDo,RDo,yb,q_e,PDo,BDo,wX,IDo,NDo,qDo,xb,j_e,jDo,DDo,AX,GDo,ODo,VDo,$b,D_e,XDo,zDo,LX,WDo,QDo,HDo,kb,G_e,UDo,JDo,yX,YDo,KDo,ZDo,Sb,O_e,eGo,oGo,xX,rGo,tGo,aGo,Rb,V_e,nGo,sGo,$X,lGo,iGo,dGo,Pb,X_e,cGo,fGo,kX,mGo,gGo,hGo,Bb,z_e,pGo,_Go,SX,uGo,bGo,vGo,Ib,W_e,FGo,TGo,RX,MGo,EGo,CGo,Nb,Q_e,wGo,AGo,H_e,LGo,yGo,xGo,qb,U_e,$Go,kGo,PX,SGo,RGo,PGo,jb,J_e,BGo,IGo,BX,NGo,qGo,jGo,Db,Y_e,DGo,GGo,IX,OGo,VGo,XGo,Gb,K_e,zGo,WGo,NX,QGo,HGo,UGo,Ob,JGo,Z_e,YGo,KGo,eue,ZGo,eOo,Vb,cQe,id,Xb,oue,Dy,oOo,rue,rOo,fQe,Io,Gy,tOo,dd,aOo,qX,nOo,sOo,jX,lOo,iOo,dOo,Oy,cOo,tue,fOo,mOo,gOo,ht,Vy,hOo,aue,pOo,_Oo,cd,uOo,nue,bOo,vOo,DX,FOo,TOo,MOo,zb,EOo,oo,Xy,COo,sue,wOo,AOo,Xa,LOo,lue,yOo,xOo,iue,$Oo,kOo,due,SOo,ROo,POo,me,Wb,cue,BOo,IOo,GX,NOo,qOo,jOo,Qb,fue,DOo,GOo,OX,OOo,VOo,XOo,Hb,mue,zOo,WOo,VX,QOo,HOo,UOo,Ub,gue,JOo,YOo,XX,KOo,ZOo,eVo,Jb,hue,oVo,rVo,zX,tVo,aVo,nVo,Yb,pue,sVo,lVo,WX,iVo,dVo,cVo,Kb,_ue,fVo,mVo,QX,gVo,hVo,pVo,Zb,uue,_Vo,uVo,HX,bVo,vVo,FVo,ev,bue,TVo,MVo,UX,EVo,CVo,wVo,ov,vue,AVo,LVo,JX,yVo,xVo,$Vo,rv,Fue,kVo,SVo,YX,RVo,PVo,BVo,tv,Tue,IVo,NVo,KX,qVo,jVo,DVo,av,Mue,GVo,OVo,ZX,VVo,XVo,zVo,nv,Eue,WVo,QVo,ez,HVo,UVo,JVo,sv,Cue,YVo,KVo,oz,ZVo,eXo,oXo,lv,wue,rXo,tXo,rz,aXo,nXo,sXo,iv,Aue,lXo,iXo,tz,dXo,cXo,fXo,dv,Lue,mXo,gXo,az,hXo,pXo,_Xo,cv,yue,uXo,bXo,nz,vXo,FXo,TXo,fv,MXo,xue,EXo,CXo,$ue,wXo,AXo,mv,mQe,fd,gv,kue,zy,LXo,Sue,yXo,gQe,No,Wy,xXo,md,$Xo,sz,kXo,SXo,lz,RXo,PXo,BXo,Qy,IXo,Rue,NXo,qXo,jXo,pt,Hy,DXo,Pue,GXo,OXo,gd,VXo,Bue,XXo,zXo,iz,WXo,QXo,HXo,hv,UXo,ro,Uy,JXo,Iue,YXo,KXo,za,ZXo,Nue,ezo,ozo,que,rzo,tzo,jue,azo,nzo,szo,B,pv,Due,lzo,izo,dz,dzo,czo,fzo,_v,Gue,mzo,gzo,cz,hzo,pzo,_zo,uv,Oue,uzo,bzo,fz,vzo,Fzo,Tzo,bv,Vue,Mzo,Ezo,mz,Czo,wzo,Azo,vv,Xue,Lzo,yzo,gz,xzo,$zo,kzo,Fv,zue,Szo,Rzo,hz,Pzo,Bzo,Izo,Tv,Wue,Nzo,qzo,pz,jzo,Dzo,Gzo,Mv,Que,Ozo,Vzo,_z,Xzo,zzo,Wzo,Ev,Hue,Qzo,Hzo,uz,Uzo,Jzo,Yzo,Cv,Uue,Kzo,Zzo,bz,eWo,oWo,rWo,wv,Jue,tWo,aWo,vz,nWo,sWo,lWo,Av,Yue,iWo,dWo,Fz,cWo,fWo,mWo,Lv,Kue,gWo,hWo,Tz,pWo,_Wo,uWo,yv,Zue,bWo,vWo,Mz,FWo,TWo,MWo,xv,e2e,EWo,CWo,Ez,wWo,AWo,LWo,$v,o2e,yWo,xWo,Cz,$Wo,kWo,SWo,kv,r2e,RWo,PWo,wz,BWo,IWo,NWo,Sv,t2e,qWo,jWo,Az,DWo,GWo,OWo,Rv,a2e,VWo,XWo,Lz,zWo,WWo,QWo,Pv,n2e,HWo,UWo,yz,JWo,YWo,KWo,Bv,s2e,ZWo,eQo,xz,oQo,rQo,tQo,Iv,l2e,aQo,nQo,$z,sQo,lQo,iQo,Nv,i2e,dQo,cQo,kz,fQo,mQo,gQo,qv,d2e,hQo,pQo,Sz,_Qo,uQo,bQo,jv,c2e,vQo,FQo,Rz,TQo,MQo,EQo,Dv,f2e,CQo,wQo,Pz,AQo,LQo,yQo,Gv,m2e,xQo,$Qo,Bz,kQo,SQo,RQo,Ov,g2e,PQo,BQo,Iz,IQo,NQo,qQo,Vv,h2e,jQo,DQo,Nz,GQo,OQo,VQo,Xv,p2e,XQo,zQo,qz,WQo,QQo,HQo,zv,_2e,UQo,JQo,jz,YQo,KQo,ZQo,Wv,u2e,eHo,oHo,Dz,rHo,tHo,aHo,Qv,b2e,nHo,sHo,Gz,lHo,iHo,dHo,Hv,v2e,cHo,fHo,Oz,mHo,gHo,hHo,Uv,F2e,pHo,_Ho,Vz,uHo,bHo,vHo,Jv,T2e,FHo,THo,Xz,MHo,EHo,CHo,Yv,M2e,wHo,AHo,zz,LHo,yHo,xHo,Kv,E2e,$Ho,kHo,Wz,SHo,RHo,PHo,Zv,C2e,BHo,IHo,Qz,NHo,qHo,jHo,e0,w2e,DHo,GHo,Hz,OHo,VHo,XHo,o0,A2e,zHo,WHo,Uz,QHo,HHo,UHo,r0,L2e,JHo,YHo,Jz,KHo,ZHo,eUo,t0,y2e,oUo,rUo,Yz,tUo,aUo,nUo,a0,x2e,sUo,lUo,Kz,iUo,dUo,cUo,n0,$2e,fUo,mUo,Zz,gUo,hUo,pUo,s0,k2e,_Uo,uUo,eW,bUo,vUo,FUo,l0,S2e,TUo,MUo,oW,EUo,CUo,wUo,i0,R2e,AUo,LUo,rW,yUo,xUo,$Uo,d0,P2e,kUo,SUo,tW,RUo,PUo,BUo,c0,B2e,IUo,NUo,aW,qUo,jUo,DUo,f0,I2e,GUo,OUo,nW,VUo,XUo,zUo,m0,N2e,WUo,QUo,sW,HUo,UUo,JUo,g0,YUo,q2e,KUo,ZUo,j2e,eJo,oJo,h0,hQe,hd,p0,D2e,Jy,rJo,G2e,tJo,pQe,qo,Yy,aJo,pd,nJo,lW,sJo,lJo,iW,iJo,dJo,cJo,Ky,fJo,O2e,mJo,gJo,hJo,_t,Zy,pJo,V2e,_Jo,uJo,_d,bJo,X2e,vJo,FJo,dW,TJo,MJo,EJo,_0,CJo,to,e9,wJo,z2e,AJo,LJo,Wa,yJo,W2e,xJo,$Jo,Q2e,kJo,SJo,H2e,RJo,PJo,BJo,Z,u0,U2e,IJo,NJo,cW,qJo,jJo,DJo,b0,J2e,GJo,OJo,fW,VJo,XJo,zJo,v0,Y2e,WJo,QJo,mW,HJo,UJo,JJo,F0,K2e,YJo,KJo,gW,ZJo,eYo,oYo,T0,Z2e,rYo,tYo,hW,aYo,nYo,sYo,M0,e1e,lYo,iYo,pW,dYo,cYo,fYo,E0,o1e,mYo,gYo,_W,hYo,pYo,_Yo,C0,r1e,uYo,bYo,uW,vYo,FYo,TYo,w0,t1e,MYo,EYo,bW,CYo,wYo,AYo,A0,a1e,LYo,yYo,vW,xYo,$Yo,kYo,L0,n1e,SYo,RYo,FW,PYo,BYo,IYo,y0,s1e,NYo,qYo,TW,jYo,DYo,GYo,x0,l1e,OYo,VYo,MW,XYo,zYo,WYo,$0,i1e,QYo,HYo,EW,UYo,JYo,YYo,k0,d1e,KYo,ZYo,CW,eKo,oKo,rKo,S0,c1e,tKo,aKo,wW,nKo,sKo,lKo,R0,f1e,iKo,dKo,AW,cKo,fKo,mKo,P0,m1e,gKo,hKo,LW,pKo,_Ko,uKo,B0,g1e,bKo,vKo,yW,FKo,TKo,MKo,I0,h1e,EKo,CKo,xW,wKo,AKo,LKo,N0,p1e,yKo,xKo,$W,$Ko,kKo,SKo,q0,_1e,RKo,PKo,kW,BKo,IKo,NKo,j0,u1e,qKo,jKo,SW,DKo,GKo,OKo,D0,b1e,VKo,XKo,RW,zKo,WKo,QKo,G0,v1e,HKo,UKo,PW,JKo,YKo,KKo,O0,F1e,ZKo,eZo,BW,oZo,rZo,tZo,V0,T1e,aZo,nZo,IW,sZo,lZo,iZo,X0,M1e,dZo,cZo,NW,fZo,mZo,gZo,z0,E1e,hZo,pZo,qW,_Zo,uZo,bZo,W0,C1e,vZo,FZo,jW,TZo,MZo,EZo,Q0,w1e,CZo,wZo,DW,AZo,LZo,yZo,H0,xZo,A1e,$Zo,kZo,L1e,SZo,RZo,U0,_Qe,ud,J0,y1e,o9,PZo,x1e,BZo,uQe,jo,r9,IZo,bd,NZo,GW,qZo,jZo,OW,DZo,GZo,OZo,t9,VZo,$1e,XZo,zZo,WZo,ut,a9,QZo,k1e,HZo,UZo,vd,JZo,S1e,YZo,KZo,VW,ZZo,eer,oer,Y0,rer,ao,n9,ter,R1e,aer,ner,Qa,ser,P1e,ler,ier,B1e,der,cer,I1e,fer,mer,ger,Do,K0,N1e,her,per,XW,_er,uer,ber,Z0,q1e,ver,Fer,zW,Ter,Mer,Eer,eF,j1e,Cer,wer,WW,Aer,Ler,yer,oF,D1e,xer,$er,QW,ker,Ser,Rer,rF,G1e,Per,Ber,HW,Ier,Ner,qer,tF,O1e,jer,Der,UW,Ger,Oer,Ver,aF,Xer,V1e,zer,Wer,X1e,Qer,Her,nF,bQe,Fd,sF,z1e,s9,Uer,W1e,Jer,vQe,Go,l9,Yer,Td,Ker,JW,Zer,eor,YW,oor,ror,tor,i9,aor,Q1e,nor,sor,lor,bt,d9,ior,H1e,dor,cor,Md,mor,U1e,gor,hor,KW,por,_or,uor,lF,bor,no,c9,vor,J1e,For,Tor,Ha,Mor,Y1e,Eor,Cor,K1e,wor,Aor,Z1e,Lor,yor,xor,U,iF,ebe,$or,kor,ZW,Sor,Ror,Por,dF,obe,Bor,Ior,eQ,Nor,qor,jor,cF,rbe,Dor,Gor,oQ,Oor,Vor,Xor,fF,tbe,zor,Wor,rQ,Qor,Hor,Uor,mF,abe,Jor,Yor,tQ,Kor,Zor,err,gF,nbe,orr,rrr,aQ,trr,arr,nrr,hF,sbe,srr,lrr,nQ,irr,drr,crr,pF,lbe,frr,mrr,sQ,grr,hrr,prr,_F,ibe,_rr,urr,lQ,brr,vrr,Frr,uF,dbe,Trr,Mrr,iQ,Err,Crr,wrr,bF,cbe,Arr,Lrr,dQ,yrr,xrr,$rr,vF,fbe,krr,Srr,cQ,Rrr,Prr,Brr,FF,mbe,Irr,Nrr,fQ,qrr,jrr,Drr,TF,gbe,Grr,Orr,mQ,Vrr,Xrr,zrr,MF,hbe,Wrr,Qrr,gQ,Hrr,Urr,Jrr,EF,pbe,Yrr,Krr,hQ,Zrr,etr,otr,CF,_be,rtr,ttr,pQ,atr,ntr,str,wF,ube,ltr,itr,_Q,dtr,ctr,ftr,AF,bbe,mtr,gtr,uQ,htr,ptr,_tr,LF,vbe,utr,btr,bQ,vtr,Ftr,Ttr,yF,Fbe,Mtr,Etr,vQ,Ctr,wtr,Atr,xF,Tbe,Ltr,ytr,FQ,xtr,$tr,ktr,$F,Mbe,Str,Rtr,TQ,Ptr,Btr,Itr,kF,Ebe,Ntr,qtr,MQ,jtr,Dtr,Gtr,SF,Cbe,Otr,Vtr,EQ,Xtr,ztr,Wtr,RF,wbe,Qtr,Htr,CQ,Utr,Jtr,Ytr,PF,Abe,Ktr,Ztr,wQ,ear,oar,rar,BF,Lbe,tar,aar,AQ,nar,sar,lar,IF,ybe,iar,dar,LQ,car,far,mar,NF,xbe,gar,har,yQ,par,_ar,uar,qF,$be,bar,Far,xQ,Tar,Mar,Ear,jF,kbe,Car,war,$Q,Aar,Lar,yar,DF,Sbe,xar,$ar,kQ,kar,Sar,Rar,GF,Rbe,Par,Bar,SQ,Iar,Nar,qar,OF,Pbe,jar,Dar,RQ,Gar,Oar,Var,VF,Bbe,Xar,zar,PQ,War,Qar,Har,XF,Ibe,Uar,Jar,BQ,Yar,Kar,Zar,zF,enr,Nbe,onr,rnr,qbe,tnr,anr,WF,FQe,Ed,QF,jbe,f9,nnr,Dbe,snr,TQe,Oo,m9,lnr,Cd,inr,IQ,dnr,cnr,NQ,fnr,mnr,gnr,g9,hnr,Gbe,pnr,_nr,unr,vt,h9,bnr,Obe,vnr,Fnr,wd,Tnr,Vbe,Mnr,Enr,qQ,Cnr,wnr,Anr,HF,Lnr,so,p9,ynr,Xbe,xnr,$nr,Ua,knr,zbe,Snr,Rnr,Wbe,Pnr,Bnr,Qbe,Inr,Nnr,qnr,V,UF,Hbe,jnr,Dnr,jQ,Gnr,Onr,Vnr,JF,Ube,Xnr,znr,DQ,Wnr,Qnr,Hnr,YF,Jbe,Unr,Jnr,GQ,Ynr,Knr,Znr,KF,Ybe,esr,osr,OQ,rsr,tsr,asr,ZF,Kbe,nsr,ssr,VQ,lsr,isr,dsr,eT,Zbe,csr,fsr,XQ,msr,gsr,hsr,oT,eve,psr,_sr,zQ,usr,bsr,vsr,rT,ove,Fsr,Tsr,WQ,Msr,Esr,Csr,tT,rve,wsr,Asr,QQ,Lsr,ysr,xsr,aT,tve,$sr,ksr,HQ,Ssr,Rsr,Psr,nT,ave,Bsr,Isr,UQ,Nsr,qsr,jsr,sT,nve,Dsr,Gsr,JQ,Osr,Vsr,Xsr,lT,sve,zsr,Wsr,YQ,Qsr,Hsr,Usr,iT,lve,Jsr,Ysr,KQ,Ksr,Zsr,elr,dT,ive,olr,rlr,ZQ,tlr,alr,nlr,cT,dve,slr,llr,eH,ilr,dlr,clr,fT,cve,flr,mlr,oH,glr,hlr,plr,mT,fve,_lr,ulr,rH,blr,vlr,Flr,gT,mve,Tlr,Mlr,tH,Elr,Clr,wlr,hT,gve,Alr,Llr,aH,ylr,xlr,$lr,pT,hve,klr,Slr,nH,Rlr,Plr,Blr,_T,pve,Ilr,Nlr,sH,qlr,jlr,Dlr,uT,_ve,Glr,Olr,lH,Vlr,Xlr,zlr,bT,uve,Wlr,Qlr,iH,Hlr,Ulr,Jlr,vT,bve,Ylr,Klr,dH,Zlr,eir,oir,FT,vve,rir,tir,cH,air,nir,sir,TT,Fve,lir,iir,fH,dir,cir,fir,MT,Tve,mir,gir,mH,hir,pir,_ir,ET,Mve,uir,bir,gH,vir,Fir,Tir,CT,Eve,Mir,Eir,hH,Cir,wir,Air,wT,Cve,Lir,yir,pH,xir,$ir,kir,AT,wve,Sir,Rir,_H,Pir,Bir,Iir,LT,Ave,Nir,qir,uH,jir,Dir,Gir,yT,Lve,Oir,Vir,bH,Xir,zir,Wir,xT,yve,Qir,Hir,vH,Uir,Jir,Yir,$T,xve,Kir,Zir,FH,edr,odr,rdr,kT,$ve,tdr,adr,TH,ndr,sdr,ldr,ST,kve,idr,ddr,MH,cdr,fdr,mdr,RT,Sve,gdr,hdr,EH,pdr,_dr,udr,PT,Rve,bdr,vdr,CH,Fdr,Tdr,Mdr,BT,Pve,Edr,Cdr,wH,wdr,Adr,Ldr,IT,Bve,ydr,xdr,AH,$dr,kdr,Sdr,NT,Ive,Rdr,Pdr,LH,Bdr,Idr,Ndr,qT,qdr,Nve,jdr,Ddr,qve,Gdr,Odr,jT,MQe,Ad,DT,jve,_9,Vdr,Dve,Xdr,EQe,Vo,u9,zdr,Ld,Wdr,yH,Qdr,Hdr,xH,Udr,Jdr,Ydr,b9,Kdr,Gve,Zdr,ecr,ocr,Ft,v9,rcr,Ove,tcr,acr,yd,ncr,Vve,scr,lcr,$H,icr,dcr,ccr,GT,fcr,lo,F9,mcr,Xve,gcr,hcr,Ja,pcr,zve,_cr,ucr,Wve,bcr,vcr,Qve,Fcr,Tcr,Mcr,Hve,OT,Uve,Ecr,Ccr,kH,wcr,Acr,Lcr,VT,ycr,Jve,xcr,$cr,Yve,kcr,Scr,XT,CQe,xd,zT,Kve,T9,Rcr,Zve,Pcr,wQe,Xo,M9,Bcr,$d,Icr,SH,Ncr,qcr,RH,jcr,Dcr,Gcr,E9,Ocr,e0e,Vcr,Xcr,zcr,Tt,C9,Wcr,o0e,Qcr,Hcr,kd,Ucr,r0e,Jcr,Ycr,PH,Kcr,Zcr,efr,WT,ofr,io,w9,rfr,t0e,tfr,afr,Ya,nfr,a0e,sfr,lfr,n0e,ifr,dfr,s0e,cfr,ffr,mfr,be,QT,l0e,gfr,hfr,BH,pfr,_fr,ufr,HT,i0e,bfr,vfr,IH,Ffr,Tfr,Mfr,UT,d0e,Efr,Cfr,NH,wfr,Afr,Lfr,JT,c0e,yfr,xfr,qH,$fr,kfr,Sfr,rl,f0e,Rfr,Pfr,jH,Bfr,Ifr,DH,Nfr,qfr,jfr,YT,m0e,Dfr,Gfr,GH,Ofr,Vfr,Xfr,tl,g0e,zfr,Wfr,OH,Qfr,Hfr,VH,Ufr,Jfr,Yfr,KT,h0e,Kfr,Zfr,XH,emr,omr,rmr,Mt,p0e,tmr,amr,zH,nmr,smr,WH,lmr,imr,QH,dmr,cmr,fmr,ZT,_0e,mmr,gmr,HH,hmr,pmr,_mr,e8,u0e,umr,bmr,UH,vmr,Fmr,Tmr,o8,b0e,Mmr,Emr,JH,Cmr,wmr,Amr,r8,v0e,Lmr,ymr,YH,xmr,$mr,kmr,t8,F0e,Smr,Rmr,KH,Pmr,Bmr,Imr,a8,T0e,Nmr,qmr,ZH,jmr,Dmr,Gmr,n8,M0e,Omr,Vmr,eU,Xmr,zmr,Wmr,s8,E0e,Qmr,Hmr,oU,Umr,Jmr,Ymr,l8,Kmr,C0e,Zmr,egr,w0e,ogr,rgr,i8,AQe,Sd,d8,A0e,A9,tgr,L0e,agr,LQe,zo,L9,ngr,Rd,sgr,rU,lgr,igr,tU,dgr,cgr,fgr,y9,mgr,y0e,ggr,hgr,pgr,Et,x9,_gr,x0e,ugr,bgr,Pd,vgr,$0e,Fgr,Tgr,aU,Mgr,Egr,Cgr,c8,wgr,co,$9,Agr,k0e,Lgr,ygr,Ka,xgr,S0e,$gr,kgr,R0e,Sgr,Rgr,P0e,Pgr,Bgr,Igr,B0e,f8,I0e,Ngr,qgr,nU,jgr,Dgr,Ggr,m8,Ogr,N0e,Vgr,Xgr,q0e,zgr,Wgr,g8,yQe,Bd,h8,j0e,k9,Qgr,D0e,Hgr,xQe,Wo,S9,Ugr,Id,Jgr,sU,Ygr,Kgr,lU,Zgr,ehr,ohr,R9,rhr,G0e,thr,ahr,nhr,Ct,P9,shr,O0e,lhr,ihr,Nd,dhr,V0e,chr,fhr,iU,mhr,ghr,hhr,p8,phr,fo,B9,_hr,X0e,uhr,bhr,Za,vhr,z0e,Fhr,Thr,W0e,Mhr,Ehr,Q0e,Chr,whr,Ahr,H0e,_8,U0e,Lhr,yhr,dU,xhr,$hr,khr,u8,Shr,J0e,Rhr,Phr,Y0e,Bhr,Ihr,b8,$Qe,qd,v8,K0e,I9,Nhr,Z0e,qhr,kQe,Qo,N9,jhr,jd,Dhr,cU,Ghr,Ohr,fU,Vhr,Xhr,zhr,q9,Whr,eFe,Qhr,Hhr,Uhr,wt,j9,Jhr,oFe,Yhr,Khr,Dd,Zhr,rFe,epr,opr,mU,rpr,tpr,apr,F8,npr,mo,D9,spr,tFe,lpr,ipr,en,dpr,aFe,cpr,fpr,nFe,mpr,gpr,sFe,hpr,ppr,_pr,lFe,T8,iFe,upr,bpr,gU,vpr,Fpr,Tpr,M8,Mpr,dFe,Epr,Cpr,cFe,wpr,Apr,E8,SQe,Gd,C8,fFe,G9,Lpr,mFe,ypr,RQe,Ho,O9,xpr,Od,$pr,hU,kpr,Spr,pU,Rpr,Ppr,Bpr,V9,Ipr,gFe,Npr,qpr,jpr,At,X9,Dpr,hFe,Gpr,Opr,Vd,Vpr,pFe,Xpr,zpr,_U,Wpr,Qpr,Hpr,w8,Upr,go,z9,Jpr,_Fe,Ypr,Kpr,on,Zpr,uFe,e_r,o_r,bFe,r_r,t_r,vFe,a_r,n_r,s_r,Be,A8,FFe,l_r,i_r,uU,d_r,c_r,f_r,L8,TFe,m_r,g_r,bU,h_r,p_r,__r,y8,MFe,u_r,b_r,vU,v_r,F_r,T_r,x8,EFe,M_r,E_r,FU,C_r,w_r,A_r,$8,CFe,L_r,y_r,TU,x_r,$_r,k_r,k8,wFe,S_r,R_r,MU,P_r,B_r,I_r,S8,AFe,N_r,q_r,EU,j_r,D_r,G_r,R8,LFe,O_r,V_r,CU,X_r,z_r,W_r,P8,yFe,Q_r,H_r,wU,U_r,J_r,Y_r,B8,K_r,xFe,Z_r,eur,$Fe,our,rur,I8,PQe,Xd,N8,kFe,W9,tur,SFe,aur,BQe,Uo,Q9,nur,zd,sur,AU,lur,iur,LU,dur,cur,fur,H9,mur,RFe,gur,hur,pur,Lt,U9,_ur,PFe,uur,bur,Wd,vur,BFe,Fur,Tur,yU,Mur,Eur,Cur,q8,wur,ho,J9,Aur,IFe,Lur,yur,rn,xur,NFe,$ur,kur,qFe,Sur,Rur,jFe,Pur,Bur,Iur,at,j8,DFe,Nur,qur,xU,jur,Dur,Gur,D8,GFe,Our,Vur,$U,Xur,zur,Wur,G8,OFe,Qur,Hur,kU,Uur,Jur,Yur,O8,VFe,Kur,Zur,SU,e2r,o2r,r2r,V8,XFe,t2r,a2r,RU,n2r,s2r,l2r,X8,i2r,zFe,d2r,c2r,WFe,f2r,m2r,z8,IQe,Qd,W8,QFe,Y9,g2r,HFe,h2r,NQe,Jo,K9,p2r,Hd,_2r,PU,u2r,b2r,BU,v2r,F2r,T2r,Z9,M2r,UFe,E2r,C2r,w2r,yt,ex,A2r,JFe,L2r,y2r,Ud,x2r,YFe,$2r,k2r,IU,S2r,R2r,P2r,Q8,B2r,po,ox,I2r,KFe,N2r,q2r,tn,j2r,ZFe,D2r,G2r,eTe,O2r,V2r,oTe,X2r,z2r,W2r,ye,H8,rTe,Q2r,H2r,NU,U2r,J2r,Y2r,U8,tTe,K2r,Z2r,qU,e1r,o1r,r1r,J8,aTe,t1r,a1r,jU,n1r,s1r,l1r,Y8,nTe,i1r,d1r,DU,c1r,f1r,m1r,K8,sTe,g1r,h1r,GU,p1r,_1r,u1r,Z8,lTe,b1r,v1r,OU,F1r,T1r,M1r,eM,iTe,E1r,C1r,VU,w1r,A1r,L1r,oM,dTe,y1r,x1r,XU,$1r,k1r,S1r,rM,cTe,R1r,P1r,zU,B1r,I1r,N1r,tM,fTe,q1r,j1r,WU,D1r,G1r,O1r,aM,V1r,mTe,X1r,z1r,gTe,W1r,Q1r,nM,qQe,Jd,sM,hTe,rx,H1r,pTe,U1r,jQe,Yo,tx,J1r,Yd,Y1r,QU,K1r,Z1r,HU,ebr,obr,rbr,ax,tbr,_Te,abr,nbr,sbr,xt,nx,lbr,uTe,ibr,dbr,Kd,cbr,bTe,fbr,mbr,UU,gbr,hbr,pbr,lM,_br,_o,sx,ubr,vTe,bbr,vbr,an,Fbr,FTe,Tbr,Mbr,TTe,Ebr,Cbr,MTe,wbr,Abr,Lbr,lx,iM,ETe,ybr,xbr,JU,$br,kbr,Sbr,dM,CTe,Rbr,Pbr,YU,Bbr,Ibr,Nbr,cM,qbr,wTe,jbr,Dbr,ATe,Gbr,Obr,fM,DQe,Zd,mM,LTe,ix,Vbr,yTe,Xbr,GQe,Ko,dx,zbr,ec,Wbr,KU,Qbr,Hbr,ZU,Ubr,Jbr,Ybr,cx,Kbr,xTe,Zbr,evr,ovr,$t,fx,rvr,$Te,tvr,avr,oc,nvr,kTe,svr,lvr,eJ,ivr,dvr,cvr,gM,fvr,uo,mx,mvr,STe,gvr,hvr,nn,pvr,RTe,_vr,uvr,PTe,bvr,vvr,BTe,Fvr,Tvr,Mvr,nt,hM,ITe,Evr,Cvr,oJ,wvr,Avr,Lvr,pM,NTe,yvr,xvr,rJ,$vr,kvr,Svr,_M,qTe,Rvr,Pvr,tJ,Bvr,Ivr,Nvr,uM,jTe,qvr,jvr,aJ,Dvr,Gvr,Ovr,bM,DTe,Vvr,Xvr,nJ,zvr,Wvr,Qvr,vM,Hvr,GTe,Uvr,Jvr,OTe,Yvr,Kvr,FM,OQe,rc,TM,VTe,gx,Zvr,XTe,e0r,VQe,Zo,hx,o0r,tc,r0r,sJ,t0r,a0r,lJ,n0r,s0r,l0r,px,i0r,zTe,d0r,c0r,f0r,kt,_x,m0r,WTe,g0r,h0r,ac,p0r,QTe,_0r,u0r,iJ,b0r,v0r,F0r,MM,T0r,bo,ux,M0r,HTe,E0r,C0r,sn,w0r,UTe,A0r,L0r,JTe,y0r,x0r,YTe,$0r,k0r,S0r,ln,EM,KTe,R0r,P0r,dJ,B0r,I0r,N0r,CM,ZTe,q0r,j0r,cJ,D0r,G0r,O0r,wM,e8e,V0r,X0r,fJ,z0r,W0r,Q0r,AM,o8e,H0r,U0r,mJ,J0r,Y0r,K0r,LM,Z0r,r8e,eFr,oFr,t8e,rFr,tFr,yM,XQe,nc,xM,a8e,bx,aFr,n8e,nFr,zQe,er,vx,sFr,sc,lFr,gJ,iFr,dFr,hJ,cFr,fFr,mFr,Fx,gFr,s8e,hFr,pFr,_Fr,St,Tx,uFr,l8e,bFr,vFr,lc,FFr,i8e,TFr,MFr,pJ,EFr,CFr,wFr,$M,AFr,vo,Mx,LFr,d8e,yFr,xFr,dn,$Fr,c8e,kFr,SFr,f8e,RFr,PFr,m8e,BFr,IFr,NFr,Ex,kM,g8e,qFr,jFr,_J,DFr,GFr,OFr,SM,h8e,VFr,XFr,uJ,zFr,WFr,QFr,RM,HFr,p8e,UFr,JFr,_8e,YFr,KFr,PM,WQe,ic,BM,u8e,Cx,ZFr,b8e,eTr,QQe,or,wx,oTr,dc,rTr,bJ,tTr,aTr,vJ,nTr,sTr,lTr,Ax,iTr,v8e,dTr,cTr,fTr,Rt,Lx,mTr,F8e,gTr,hTr,cc,pTr,T8e,_Tr,uTr,FJ,bTr,vTr,FTr,IM,TTr,Fo,yx,MTr,M8e,ETr,CTr,cn,wTr,E8e,ATr,LTr,C8e,yTr,xTr,w8e,$Tr,kTr,STr,A8e,NM,L8e,RTr,PTr,TJ,BTr,ITr,NTr,qM,qTr,y8e,jTr,DTr,x8e,GTr,OTr,jM,HQe,fc,DM,$8e,xx,VTr,k8e,XTr,UQe,rr,$x,zTr,mc,WTr,MJ,QTr,HTr,EJ,UTr,JTr,YTr,kx,KTr,S8e,ZTr,e8r,o8r,Pt,Sx,r8r,R8e,t8r,a8r,gc,n8r,P8e,s8r,l8r,CJ,i8r,d8r,c8r,GM,f8r,To,Rx,m8r,B8e,g8r,h8r,fn,p8r,I8e,_8r,u8r,N8e,b8r,v8r,q8e,F8r,T8r,M8r,st,OM,j8e,E8r,C8r,wJ,w8r,A8r,L8r,VM,D8e,y8r,x8r,AJ,$8r,k8r,S8r,XM,G8e,R8r,P8r,LJ,B8r,I8r,N8r,zM,O8e,q8r,j8r,yJ,D8r,G8r,O8r,WM,V8e,V8r,X8r,xJ,z8r,W8r,Q8r,QM,H8r,X8e,U8r,J8r,z8e,Y8r,K8r,HM,JQe,hc,UM,W8e,Px,Z8r,Q8e,eMr,YQe,tr,Bx,oMr,pc,rMr,$J,tMr,aMr,kJ,nMr,sMr,lMr,Ix,iMr,H8e,dMr,cMr,fMr,Bt,Nx,mMr,U8e,gMr,hMr,_c,pMr,J8e,_Mr,uMr,SJ,bMr,vMr,FMr,JM,TMr,Mo,qx,MMr,Y8e,EMr,CMr,mn,wMr,K8e,AMr,LMr,Z8e,yMr,xMr,eMe,$Mr,kMr,SMr,oMe,YM,rMe,RMr,PMr,RJ,BMr,IMr,NMr,KM,qMr,tMe,jMr,DMr,aMe,GMr,OMr,ZM,KQe,uc,eE,nMe,jx,VMr,sMe,XMr,ZQe,ar,Dx,zMr,bc,WMr,PJ,QMr,HMr,BJ,UMr,JMr,YMr,Gx,KMr,lMe,ZMr,eEr,oEr,It,Ox,rEr,iMe,tEr,aEr,vc,nEr,dMe,sEr,lEr,IJ,iEr,dEr,cEr,oE,fEr,Sr,Vx,mEr,cMe,gEr,hEr,gn,pEr,fMe,_Er,uEr,mMe,bEr,vEr,gMe,FEr,TEr,MEr,q,rE,hMe,EEr,CEr,NJ,wEr,AEr,LEr,tE,pMe,yEr,xEr,qJ,$Er,kEr,SEr,aE,_Me,REr,PEr,jJ,BEr,IEr,NEr,nE,uMe,qEr,jEr,DJ,DEr,GEr,OEr,sE,bMe,VEr,XEr,GJ,zEr,WEr,QEr,lE,vMe,HEr,UEr,OJ,JEr,YEr,KEr,iE,FMe,ZEr,e4r,VJ,o4r,r4r,t4r,dE,TMe,a4r,n4r,XJ,s4r,l4r,i4r,cE,MMe,d4r,c4r,zJ,f4r,m4r,g4r,fE,EMe,h4r,p4r,WJ,_4r,u4r,b4r,mE,CMe,v4r,F4r,QJ,T4r,M4r,E4r,gE,wMe,C4r,w4r,HJ,A4r,L4r,y4r,hE,AMe,x4r,$4r,UJ,k4r,S4r,R4r,pE,LMe,P4r,B4r,JJ,I4r,N4r,q4r,_E,yMe,j4r,D4r,YJ,G4r,O4r,V4r,uE,xMe,X4r,z4r,KJ,W4r,Q4r,H4r,bE,$Me,U4r,J4r,ZJ,Y4r,K4r,Z4r,vE,kMe,eCr,oCr,eY,rCr,tCr,aCr,al,SMe,nCr,sCr,oY,lCr,iCr,rY,dCr,cCr,fCr,FE,RMe,mCr,gCr,tY,hCr,pCr,_Cr,TE,PMe,uCr,bCr,aY,vCr,FCr,TCr,ME,BMe,MCr,ECr,nY,CCr,wCr,ACr,EE,IMe,LCr,yCr,sY,xCr,$Cr,kCr,CE,NMe,SCr,RCr,lY,PCr,BCr,ICr,wE,qMe,NCr,qCr,iY,jCr,DCr,GCr,AE,jMe,OCr,VCr,dY,XCr,zCr,WCr,LE,DMe,QCr,HCr,cY,UCr,JCr,YCr,yE,GMe,KCr,ZCr,fY,e5r,o5r,r5r,xE,OMe,t5r,a5r,mY,n5r,s5r,l5r,$E,VMe,i5r,d5r,gY,c5r,f5r,m5r,kE,XMe,g5r,h5r,hY,p5r,_5r,u5r,SE,zMe,b5r,v5r,pY,F5r,T5r,M5r,RE,WMe,E5r,C5r,_Y,w5r,A5r,L5r,PE,QMe,y5r,x5r,uY,$5r,k5r,S5r,BE,HMe,R5r,P5r,bY,B5r,I5r,N5r,IE,UMe,q5r,j5r,vY,D5r,G5r,O5r,NE,JMe,V5r,X5r,FY,z5r,W5r,Q5r,qE,YMe,H5r,U5r,TY,J5r,Y5r,K5r,jE,KMe,Z5r,e3r,MY,o3r,r3r,t3r,DE,ZMe,a3r,n3r,EY,s3r,l3r,i3r,GE,eEe,d3r,c3r,CY,f3r,m3r,g3r,OE,oEe,h3r,p3r,wY,_3r,u3r,b3r,VE,rEe,v3r,F3r,AY,T3r,M3r,E3r,XE,tEe,C3r,w3r,LY,A3r,L3r,y3r,zE,aEe,x3r,$3r,yY,k3r,S3r,R3r,WE,nEe,P3r,B3r,xY,I3r,N3r,q3r,QE,sEe,j3r,D3r,$Y,G3r,O3r,V3r,HE,lEe,X3r,z3r,kY,W3r,Q3r,H3r,UE,iEe,U3r,J3r,SY,Y3r,K3r,Z3r,JE,dEe,ewr,owr,RY,rwr,twr,awr,YE,cEe,nwr,swr,PY,lwr,iwr,dwr,KE,eHe,Fc,ZE,fEe,Xx,cwr,mEe,fwr,oHe,nr,zx,mwr,Tc,gwr,BY,hwr,pwr,IY,_wr,uwr,bwr,Wx,vwr,gEe,Fwr,Twr,Mwr,Nt,Qx,Ewr,hEe,Cwr,wwr,Mc,Awr,pEe,Lwr,ywr,NY,xwr,$wr,kwr,e4,Swr,Rr,Hx,Rwr,_Ee,Pwr,Bwr,hn,Iwr,uEe,Nwr,qwr,bEe,jwr,Dwr,vEe,Gwr,Owr,Vwr,se,o4,FEe,Xwr,zwr,qY,Wwr,Qwr,Hwr,r4,TEe,Uwr,Jwr,jY,Ywr,Kwr,Zwr,t4,MEe,e6r,o6r,DY,r6r,t6r,a6r,a4,EEe,n6r,s6r,GY,l6r,i6r,d6r,n4,CEe,c6r,f6r,OY,m6r,g6r,h6r,s4,wEe,p6r,_6r,VY,u6r,b6r,v6r,l4,AEe,F6r,T6r,XY,M6r,E6r,C6r,i4,LEe,w6r,A6r,zY,L6r,y6r,x6r,d4,yEe,$6r,k6r,WY,S6r,R6r,P6r,c4,xEe,B6r,I6r,QY,N6r,q6r,j6r,f4,$Ee,D6r,G6r,HY,O6r,V6r,X6r,m4,kEe,z6r,W6r,UY,Q6r,H6r,U6r,g4,SEe,J6r,Y6r,JY,K6r,Z6r,eAr,h4,REe,oAr,rAr,YY,tAr,aAr,nAr,p4,PEe,sAr,lAr,KY,iAr,dAr,cAr,_4,BEe,fAr,mAr,ZY,gAr,hAr,pAr,u4,IEe,_Ar,uAr,eK,bAr,vAr,FAr,b4,NEe,TAr,MAr,oK,EAr,CAr,wAr,v4,qEe,AAr,LAr,rK,yAr,xAr,$Ar,F4,jEe,kAr,SAr,tK,RAr,PAr,BAr,T4,DEe,IAr,NAr,aK,qAr,jAr,DAr,M4,GEe,GAr,OAr,nK,VAr,XAr,zAr,E4,OEe,WAr,QAr,sK,HAr,UAr,JAr,C4,rHe,Ec,w4,VEe,Ux,YAr,XEe,KAr,tHe,sr,Jx,ZAr,Cc,e7r,lK,o7r,r7r,iK,t7r,a7r,n7r,Yx,s7r,zEe,l7r,i7r,d7r,qt,Kx,c7r,WEe,f7r,m7r,wc,g7r,QEe,h7r,p7r,dK,_7r,u7r,b7r,A4,v7r,Pr,Zx,F7r,HEe,T7r,M7r,pn,E7r,UEe,C7r,w7r,JEe,A7r,L7r,YEe,y7r,x7r,$7r,Me,L4,KEe,k7r,S7r,cK,R7r,P7r,B7r,y4,ZEe,I7r,N7r,fK,q7r,j7r,D7r,x4,e4e,G7r,O7r,mK,V7r,X7r,z7r,$4,o4e,W7r,Q7r,gK,H7r,U7r,J7r,k4,r4e,Y7r,K7r,hK,Z7r,eLr,oLr,S4,t4e,rLr,tLr,pK,aLr,nLr,sLr,R4,a4e,lLr,iLr,_K,dLr,cLr,fLr,P4,n4e,mLr,gLr,uK,hLr,pLr,_Lr,B4,s4e,uLr,bLr,bK,vLr,FLr,TLr,I4,l4e,MLr,ELr,vK,CLr,wLr,ALr,N4,i4e,LLr,yLr,FK,xLr,$Lr,kLr,q4,d4e,SLr,RLr,TK,PLr,BLr,ILr,j4,c4e,NLr,qLr,MK,jLr,DLr,GLr,D4,aHe,Ac,G4,f4e,e$,OLr,m4e,VLr,nHe,lr,o$,XLr,Lc,zLr,EK,WLr,QLr,CK,HLr,ULr,JLr,r$,YLr,g4e,KLr,ZLr,eyr,jt,t$,oyr,h4e,ryr,tyr,yc,ayr,p4e,nyr,syr,wK,lyr,iyr,dyr,O4,cyr,Br,a$,fyr,_4e,myr,gyr,_n,hyr,u4e,pyr,_yr,b4e,uyr,byr,v4e,vyr,Fyr,Tyr,Ve,V4,F4e,Myr,Eyr,AK,Cyr,wyr,Ayr,X4,T4e,Lyr,yyr,LK,xyr,$yr,kyr,nl,M4e,Syr,Ryr,yK,Pyr,Byr,xK,Iyr,Nyr,qyr,z4,E4e,jyr,Dyr,$K,Gyr,Oyr,Vyr,W4,C4e,Xyr,zyr,kK,Wyr,Qyr,Hyr,Q4,w4e,Uyr,Jyr,SK,Yyr,Kyr,Zyr,H4,A4e,e9r,o9r,RK,r9r,t9r,a9r,U4,L4e,n9r,s9r,PK,l9r,i9r,d9r,J4,sHe,xc,Y4,y4e,n$,c9r,x4e,f9r,lHe,ir,s$,m9r,$c,g9r,BK,h9r,p9r,IK,_9r,u9r,b9r,l$,v9r,$4e,F9r,T9r,M9r,Dt,i$,E9r,k4e,C9r,w9r,kc,A9r,S4e,L9r,y9r,NK,x9r,$9r,k9r,K4,S9r,Ir,d$,R9r,R4e,P9r,B9r,un,I9r,P4e,N9r,q9r,B4e,j9r,D9r,I4e,G9r,O9r,V9r,ie,Z4,N4e,X9r,z9r,qK,W9r,Q9r,H9r,eC,q4e,U9r,J9r,jK,Y9r,K9r,Z9r,oC,j4e,exr,oxr,DK,rxr,txr,axr,rC,D4e,nxr,sxr,GK,lxr,ixr,dxr,tC,G4e,cxr,fxr,OK,mxr,gxr,hxr,aC,O4e,pxr,_xr,VK,uxr,bxr,vxr,nC,V4e,Fxr,Txr,XK,Mxr,Exr,Cxr,sC,X4e,wxr,Axr,zK,Lxr,yxr,xxr,lC,z4e,$xr,kxr,WK,Sxr,Rxr,Pxr,iC,W4e,Bxr,Ixr,QK,Nxr,qxr,jxr,dC,Q4e,Dxr,Gxr,HK,Oxr,Vxr,Xxr,cC,H4e,zxr,Wxr,UK,Qxr,Hxr,Uxr,fC,U4e,Jxr,Yxr,JK,Kxr,Zxr,e$r,mC,J4e,o$r,r$r,YK,t$r,a$r,n$r,gC,Y4e,s$r,l$r,KK,i$r,d$r,c$r,hC,K4e,f$r,m$r,ZK,g$r,h$r,p$r,pC,Z4e,_$r,u$r,eZ,b$r,v$r,F$r,_C,eCe,T$r,M$r,oZ,E$r,C$r,w$r,uC,oCe,A$r,L$r,rZ,y$r,x$r,$$r,bC,rCe,k$r,S$r,tZ,R$r,P$r,B$r,vC,iHe,Sc,FC,tCe,c$,I$r,aCe,N$r,dHe,dr,f$,q$r,Rc,j$r,aZ,D$r,G$r,nZ,O$r,V$r,X$r,m$,z$r,nCe,W$r,Q$r,H$r,Gt,g$,U$r,sCe,J$r,Y$r,Pc,K$r,lCe,Z$r,ekr,sZ,okr,rkr,tkr,TC,akr,Nr,h$,nkr,iCe,skr,lkr,bn,ikr,dCe,dkr,ckr,cCe,fkr,mkr,fCe,gkr,hkr,pkr,xe,MC,mCe,_kr,ukr,lZ,bkr,vkr,Fkr,EC,gCe,Tkr,Mkr,iZ,Ekr,Ckr,wkr,CC,hCe,Akr,Lkr,dZ,ykr,xkr,$kr,wC,pCe,kkr,Skr,cZ,Rkr,Pkr,Bkr,AC,_Ce,Ikr,Nkr,fZ,qkr,jkr,Dkr,LC,uCe,Gkr,Okr,mZ,Vkr,Xkr,zkr,yC,bCe,Wkr,Qkr,gZ,Hkr,Ukr,Jkr,xC,vCe,Ykr,Kkr,hZ,Zkr,eSr,oSr,$C,FCe,rSr,tSr,pZ,aSr,nSr,sSr,kC,TCe,lSr,iSr,_Z,dSr,cSr,fSr,SC,cHe,Bc,RC,MCe,p$,mSr,ECe,gSr,fHe,cr,_$,hSr,Ic,pSr,uZ,_Sr,uSr,bZ,bSr,vSr,FSr,u$,TSr,CCe,MSr,ESr,CSr,Ot,b$,wSr,wCe,ASr,LSr,Nc,ySr,ACe,xSr,$Sr,vZ,kSr,SSr,RSr,PC,PSr,qr,v$,BSr,LCe,ISr,NSr,vn,qSr,yCe,jSr,DSr,xCe,GSr,OSr,$Ce,VSr,XSr,zSr,ae,BC,kCe,WSr,QSr,FZ,HSr,USr,JSr,IC,SCe,YSr,KSr,TZ,ZSr,eRr,oRr,NC,RCe,rRr,tRr,MZ,aRr,nRr,sRr,qC,PCe,lRr,iRr,EZ,dRr,cRr,fRr,jC,BCe,mRr,gRr,CZ,hRr,pRr,_Rr,DC,ICe,uRr,bRr,wZ,vRr,FRr,TRr,GC,NCe,MRr,ERr,AZ,CRr,wRr,ARr,OC,qCe,LRr,yRr,LZ,xRr,$Rr,kRr,VC,jCe,SRr,RRr,yZ,PRr,BRr,IRr,XC,DCe,NRr,qRr,xZ,jRr,DRr,GRr,zC,GCe,ORr,VRr,$Z,XRr,zRr,WRr,WC,OCe,QRr,HRr,kZ,URr,JRr,YRr,QC,VCe,KRr,ZRr,SZ,ePr,oPr,rPr,HC,XCe,tPr,aPr,RZ,nPr,sPr,lPr,UC,zCe,iPr,dPr,PZ,cPr,fPr,mPr,JC,WCe,gPr,hPr,BZ,pPr,_Pr,uPr,YC,QCe,bPr,vPr,IZ,FPr,TPr,MPr,KC,HCe,EPr,CPr,NZ,wPr,APr,LPr,ZC,UCe,yPr,xPr,qZ,$Pr,kPr,SPr,e5,JCe,RPr,PPr,jZ,BPr,IPr,NPr,o5,YCe,qPr,jPr,DZ,DPr,GPr,OPr,r5,KCe,VPr,XPr,GZ,zPr,WPr,QPr,t5,ZCe,HPr,UPr,OZ,JPr,YPr,KPr,a5,e5e,ZPr,eBr,VZ,oBr,rBr,tBr,n5,o5e,aBr,nBr,XZ,sBr,lBr,iBr,s5,r5e,dBr,cBr,zZ,fBr,mBr,gBr,l5,mHe,qc,i5,t5e,F$,hBr,a5e,pBr,gHe,fr,T$,_Br,jc,uBr,WZ,bBr,vBr,QZ,FBr,TBr,MBr,M$,EBr,n5e,CBr,wBr,ABr,Vt,E$,LBr,s5e,yBr,xBr,Dc,$Br,l5e,kBr,SBr,HZ,RBr,PBr,BBr,d5,IBr,jr,C$,NBr,i5e,qBr,jBr,Fn,DBr,d5e,GBr,OBr,c5e,VBr,XBr,f5e,zBr,WBr,QBr,ve,c5,m5e,HBr,UBr,UZ,JBr,YBr,KBr,f5,g5e,ZBr,eIr,JZ,oIr,rIr,tIr,m5,h5e,aIr,nIr,YZ,sIr,lIr,iIr,g5,p5e,dIr,cIr,KZ,fIr,mIr,gIr,h5,_5e,hIr,pIr,ZZ,_Ir,uIr,bIr,p5,u5e,vIr,FIr,eee,TIr,MIr,EIr,_5,b5e,CIr,wIr,oee,AIr,LIr,yIr,u5,v5e,xIr,$Ir,ree,kIr,SIr,RIr,b5,F5e,PIr,BIr,tee,IIr,NIr,qIr,v5,T5e,jIr,DIr,aee,GIr,OIr,VIr,F5,M5e,XIr,zIr,nee,WIr,QIr,HIr,T5,E5e,UIr,JIr,see,YIr,KIr,ZIr,M5,C5e,eNr,oNr,lee,rNr,tNr,aNr,E5,w5e,nNr,sNr,iee,lNr,iNr,dNr,C5,A5e,cNr,fNr,dee,mNr,gNr,hNr,w5,L5e,pNr,_Nr,cee,uNr,bNr,vNr,A5,y5e,FNr,TNr,fee,MNr,ENr,CNr,L5,hHe,Gc,y5,x5e,w$,wNr,$5e,ANr,pHe,mr,A$,LNr,Oc,yNr,mee,xNr,$Nr,gee,kNr,SNr,RNr,L$,PNr,k5e,BNr,INr,NNr,Xt,y$,qNr,S5e,jNr,DNr,Vc,GNr,R5e,ONr,VNr,hee,XNr,zNr,WNr,x5,QNr,Dr,x$,HNr,P5e,UNr,JNr,Tn,YNr,B5e,KNr,ZNr,I5e,eqr,oqr,N5e,rqr,tqr,aqr,$$,$5,q5e,nqr,sqr,pee,lqr,iqr,dqr,k5,j5e,cqr,fqr,_ee,mqr,gqr,hqr,S5,_He,Xc,R5,D5e,k$,pqr,G5e,_qr,uHe,gr,S$,uqr,zc,bqr,uee,vqr,Fqr,bee,Tqr,Mqr,Eqr,R$,Cqr,O5e,wqr,Aqr,Lqr,zt,P$,yqr,V5e,xqr,$qr,Wc,kqr,X5e,Sqr,Rqr,vee,Pqr,Bqr,Iqr,P5,Nqr,Gr,B$,qqr,z5e,jqr,Dqr,Mn,Gqr,W5e,Oqr,Vqr,Q5e,Xqr,zqr,H5e,Wqr,Qqr,Hqr,U5e,B5,J5e,Uqr,Jqr,Fee,Yqr,Kqr,Zqr,I5,bHe,Qc,N5,Y5e,I$,ejr,K5e,ojr,vHe,hr,N$,rjr,Hc,tjr,Tee,ajr,njr,Mee,sjr,ljr,ijr,q$,djr,Z5e,cjr,fjr,mjr,Wt,j$,gjr,e3e,hjr,pjr,Uc,_jr,o3e,ujr,bjr,Eee,vjr,Fjr,Tjr,q5,Mjr,Or,D$,Ejr,r3e,Cjr,wjr,En,Ajr,t3e,Ljr,yjr,a3e,xjr,$jr,n3e,kjr,Sjr,Rjr,de,j5,s3e,Pjr,Bjr,Cee,Ijr,Njr,qjr,D5,l3e,jjr,Djr,wee,Gjr,Ojr,Vjr,G5,i3e,Xjr,zjr,Aee,Wjr,Qjr,Hjr,O5,d3e,Ujr,Jjr,Lee,Yjr,Kjr,Zjr,V5,c3e,eDr,oDr,yee,rDr,tDr,aDr,X5,f3e,nDr,sDr,xee,lDr,iDr,dDr,z5,m3e,cDr,fDr,$ee,mDr,gDr,hDr,W5,g3e,pDr,_Dr,kee,uDr,bDr,vDr,Q5,h3e,FDr,TDr,See,MDr,EDr,CDr,H5,p3e,wDr,ADr,Ree,LDr,yDr,xDr,U5,_3e,$Dr,kDr,Pee,SDr,RDr,PDr,J5,u3e,BDr,IDr,Bee,NDr,qDr,jDr,Y5,b3e,DDr,GDr,Iee,ODr,VDr,XDr,K5,v3e,zDr,WDr,Nee,QDr,HDr,UDr,Z5,F3e,JDr,YDr,qee,KDr,ZDr,eGr,e3,T3e,oGr,rGr,jee,tGr,aGr,nGr,o3,M3e,sGr,lGr,Dee,iGr,dGr,cGr,r3,E3e,fGr,mGr,Gee,gGr,hGr,pGr,t3,C3e,_Gr,uGr,Oee,bGr,vGr,FGr,a3,w3e,TGr,MGr,Vee,EGr,CGr,wGr,n3,FHe,Jc,s3,A3e,G$,AGr,L3e,LGr,THe,pr,O$,yGr,Yc,xGr,Xee,$Gr,kGr,zee,SGr,RGr,PGr,V$,BGr,y3e,IGr,NGr,qGr,Qt,X$,jGr,x3e,DGr,GGr,Kc,OGr,$3e,VGr,XGr,Wee,zGr,WGr,QGr,l3,HGr,Vr,z$,UGr,k3e,JGr,YGr,Cn,KGr,S3e,ZGr,eOr,R3e,oOr,rOr,P3e,tOr,aOr,nOr,ce,i3,B3e,sOr,lOr,Qee,iOr,dOr,cOr,d3,I3e,fOr,mOr,Hee,gOr,hOr,pOr,c3,N3e,_Or,uOr,Uee,bOr,vOr,FOr,f3,q3e,TOr,MOr,Jee,EOr,COr,wOr,m3,j3e,AOr,LOr,Yee,yOr,xOr,$Or,g3,D3e,kOr,SOr,Kee,ROr,POr,BOr,h3,G3e,IOr,NOr,Zee,qOr,jOr,DOr,p3,O3e,GOr,OOr,eoe,VOr,XOr,zOr,_3,V3e,WOr,QOr,ooe,HOr,UOr,JOr,u3,X3e,YOr,KOr,roe,ZOr,eVr,oVr,b3,z3e,rVr,tVr,toe,aVr,nVr,sVr,v3,W3e,lVr,iVr,aoe,dVr,cVr,fVr,F3,Q3e,mVr,gVr,noe,hVr,pVr,_Vr,T3,H3e,uVr,bVr,soe,vVr,FVr,TVr,M3,U3e,MVr,EVr,loe,CVr,wVr,AVr,E3,J3e,LVr,yVr,ioe,xVr,$Vr,kVr,C3,Y3e,SVr,RVr,doe,PVr,BVr,IVr,w3,K3e,NVr,qVr,coe,jVr,DVr,GVr,A3,Z3e,OVr,VVr,foe,XVr,zVr,WVr,L3,ewe,QVr,HVr,moe,UVr,JVr,YVr,y3,MHe,Zc,x3,owe,W$,KVr,rwe,ZVr,EHe,_r,Q$,eXr,ef,oXr,goe,rXr,tXr,hoe,aXr,nXr,sXr,H$,lXr,twe,iXr,dXr,cXr,Ht,U$,fXr,awe,mXr,gXr,of,hXr,nwe,pXr,_Xr,poe,uXr,bXr,vXr,$3,FXr,Xr,J$,TXr,swe,MXr,EXr,wn,CXr,lwe,wXr,AXr,iwe,LXr,yXr,dwe,xXr,$Xr,kXr,cwe,k3,fwe,SXr,RXr,_oe,PXr,BXr,IXr,S3,CHe,rf,R3,mwe,Y$,NXr,gwe,qXr,wHe,ur,K$,jXr,tf,DXr,uoe,GXr,OXr,boe,VXr,XXr,zXr,Z$,WXr,hwe,QXr,HXr,UXr,Ut,ek,JXr,pwe,YXr,KXr,af,ZXr,_we,ezr,ozr,voe,rzr,tzr,azr,P3,nzr,zr,ok,szr,uwe,lzr,izr,An,dzr,bwe,czr,fzr,vwe,mzr,gzr,Fwe,hzr,pzr,_zr,Twe,B3,Mwe,uzr,bzr,Foe,vzr,Fzr,Tzr,I3,AHe,nf,N3,Ewe,rk,Mzr,Cwe,Ezr,LHe,br,tk,Czr,sf,wzr,Toe,Azr,Lzr,Moe,yzr,xzr,$zr,ak,kzr,wwe,Szr,Rzr,Pzr,Jt,nk,Bzr,Awe,Izr,Nzr,lf,qzr,Lwe,jzr,Dzr,Eoe,Gzr,Ozr,Vzr,q3,Xzr,Wr,sk,zzr,ywe,Wzr,Qzr,Ln,Hzr,xwe,Uzr,Jzr,$we,Yzr,Kzr,kwe,Zzr,eWr,oWr,oe,j3,Swe,rWr,tWr,Coe,aWr,nWr,sWr,D3,Rwe,lWr,iWr,woe,dWr,cWr,fWr,G3,Pwe,mWr,gWr,Aoe,hWr,pWr,_Wr,O3,Bwe,uWr,bWr,Loe,vWr,FWr,TWr,V3,Iwe,MWr,EWr,yoe,CWr,wWr,AWr,X3,Nwe,LWr,yWr,xoe,xWr,$Wr,kWr,z3,qwe,SWr,RWr,$oe,PWr,BWr,IWr,W3,jwe,NWr,qWr,koe,jWr,DWr,GWr,Q3,Dwe,OWr,VWr,Soe,XWr,zWr,WWr,H3,Gwe,QWr,HWr,Roe,UWr,JWr,YWr,U3,Owe,KWr,ZWr,Poe,eQr,oQr,rQr,J3,Vwe,tQr,aQr,Boe,nQr,sQr,lQr,Y3,Xwe,iQr,dQr,Ioe,cQr,fQr,mQr,K3,zwe,gQr,hQr,Noe,pQr,_Qr,uQr,Z3,Wwe,bQr,vQr,qoe,FQr,TQr,MQr,ew,Qwe,EQr,CQr,joe,wQr,AQr,LQr,ow,Hwe,yQr,xQr,Doe,$Qr,kQr,SQr,rw,Uwe,RQr,PQr,Goe,BQr,IQr,NQr,tw,Jwe,qQr,jQr,Ooe,DQr,GQr,OQr,aw,Ywe,VQr,XQr,Voe,zQr,WQr,QQr,nw,Kwe,HQr,UQr,Xoe,JQr,YQr,KQr,sw,Zwe,ZQr,eHr,zoe,oHr,rHr,tHr,lw,e6e,aHr,nHr,Woe,sHr,lHr,iHr,iw,o6e,dHr,cHr,Qoe,fHr,mHr,gHr,dw,r6e,hHr,pHr,Hoe,_Hr,uHr,bHr,cw,t6e,vHr,FHr,Uoe,THr,MHr,EHr,fw,a6e,CHr,wHr,Joe,AHr,LHr,yHr,mw,n6e,xHr,$Hr,Yoe,kHr,SHr,RHr,gw,yHe,df,hw,s6e,lk,PHr,l6e,BHr,xHe,vr,ik,IHr,cf,NHr,Koe,qHr,jHr,Zoe,DHr,GHr,OHr,dk,VHr,i6e,XHr,zHr,WHr,Yt,ck,QHr,d6e,HHr,UHr,ff,JHr,c6e,YHr,KHr,ere,ZHr,eUr,oUr,pw,rUr,Qr,fk,tUr,f6e,aUr,nUr,yn,sUr,m6e,lUr,iUr,g6e,dUr,cUr,h6e,fUr,mUr,gUr,Ae,_w,p6e,hUr,pUr,ore,_Ur,uUr,bUr,uw,_6e,vUr,FUr,rre,TUr,MUr,EUr,bw,u6e,CUr,wUr,tre,AUr,LUr,yUr,vw,b6e,xUr,$Ur,are,kUr,SUr,RUr,Fw,v6e,PUr,BUr,nre,IUr,NUr,qUr,Tw,F6e,jUr,DUr,sre,GUr,OUr,VUr,Mw,T6e,XUr,zUr,lre,WUr,QUr,HUr,Ew,M6e,UUr,JUr,ire,YUr,KUr,ZUr,Cw,E6e,eJr,oJr,dre,rJr,tJr,aJr,ww,C6e,nJr,sJr,cre,lJr,iJr,dJr,Aw,w6e,cJr,fJr,fre,mJr,gJr,hJr,Lw,$He,mf,yw,A6e,mk,pJr,L6e,_Jr,kHe,Fr,gk,uJr,gf,bJr,mre,vJr,FJr,gre,TJr,MJr,EJr,hk,CJr,y6e,wJr,AJr,LJr,Kt,pk,yJr,x6e,xJr,$Jr,hf,kJr,$6e,SJr,RJr,hre,PJr,BJr,IJr,xw,NJr,Hr,_k,qJr,k6e,jJr,DJr,xn,GJr,S6e,OJr,VJr,R6e,XJr,zJr,P6e,WJr,QJr,HJr,Ee,$w,B6e,UJr,JJr,pre,YJr,KJr,ZJr,kw,I6e,eYr,oYr,_re,rYr,tYr,aYr,Sw,N6e,nYr,sYr,ure,lYr,iYr,dYr,Rw,q6e,cYr,fYr,bre,mYr,gYr,hYr,Pw,j6e,pYr,_Yr,vre,uYr,bYr,vYr,Bw,D6e,FYr,TYr,Fre,MYr,EYr,CYr,Iw,G6e,wYr,AYr,Tre,LYr,yYr,xYr,Nw,O6e,$Yr,kYr,Mre,SYr,RYr,PYr,qw,V6e,BYr,IYr,Ere,NYr,qYr,jYr,jw,X6e,DYr,GYr,Cre,OYr,VYr,XYr,Dw,z6e,zYr,WYr,wre,QYr,HYr,UYr,Gw,W6e,JYr,YYr,Are,KYr,ZYr,eKr,Ow,Q6e,oKr,rKr,Lre,tKr,aKr,nKr,Vw,SHe,pf,Xw,H6e,uk,sKr,U6e,lKr,RHe,Tr,bk,iKr,_f,dKr,yre,cKr,fKr,xre,mKr,gKr,hKr,vk,pKr,J6e,_Kr,uKr,bKr,Zt,Fk,vKr,Y6e,FKr,TKr,uf,MKr,K6e,EKr,CKr,$re,wKr,AKr,LKr,zw,yKr,Ur,Tk,xKr,Z6e,$Kr,kKr,$n,SKr,eAe,RKr,PKr,oAe,BKr,IKr,rAe,NKr,qKr,jKr,$e,Ww,tAe,DKr,GKr,kre,OKr,VKr,XKr,Qw,aAe,zKr,WKr,Sre,QKr,HKr,UKr,Hw,nAe,JKr,YKr,Rre,KKr,ZKr,eZr,Uw,sAe,oZr,rZr,Pre,tZr,aZr,nZr,Jw,lAe,sZr,lZr,Bre,iZr,dZr,cZr,Yw,iAe,fZr,mZr,Ire,gZr,hZr,pZr,Kw,dAe,_Zr,uZr,Nre,bZr,vZr,FZr,Zw,cAe,TZr,MZr,qre,EZr,CZr,wZr,e6,fAe,AZr,LZr,jre,yZr,xZr,$Zr,o6,mAe,kZr,SZr,Dre,RZr,PZr,BZr,r6,PHe,bf,t6,gAe,Mk,IZr,hAe,NZr,BHe,Mr,Ek,qZr,vf,jZr,Gre,DZr,GZr,Ore,OZr,VZr,XZr,Ck,zZr,pAe,WZr,QZr,HZr,ea,wk,UZr,_Ae,JZr,YZr,Ff,KZr,uAe,ZZr,eet,Vre,oet,ret,tet,a6,aet,Jr,Ak,net,bAe,set,iet,kn,det,vAe,cet,fet,FAe,met,get,TAe,het,pet,_et,ke,n6,MAe,uet,bet,Xre,vet,Fet,Tet,s6,EAe,Met,Eet,zre,Cet,wet,Aet,l6,CAe,Let,yet,Wre,xet,$et,ket,i6,wAe,Set,Ret,Qre,Pet,Bet,Iet,d6,AAe,Net,qet,Hre,jet,Det,Get,c6,LAe,Oet,Vet,Ure,Xet,zet,Wet,f6,yAe,Qet,Het,Jre,Uet,Jet,Yet,m6,xAe,Ket,Zet,Yre,eot,oot,rot,g6,$Ae,tot,aot,Kre,not,sot,lot,h6,kAe,iot,dot,Zre,cot,fot,mot,p6,IHe,Tf,_6,SAe,Lk,got,RAe,hot,NHe,Er,yk,pot,Mf,_ot,ete,uot,bot,ote,vot,Fot,Tot,xk,Mot,PAe,Eot,Cot,wot,oa,$k,Aot,BAe,Lot,yot,Ef,xot,IAe,$ot,kot,rte,Sot,Rot,Pot,u6,Bot,Yr,kk,Iot,NAe,Not,qot,Sn,jot,qAe,Dot,Got,jAe,Oot,Vot,DAe,Xot,zot,Wot,Se,b6,GAe,Qot,Hot,tte,Uot,Jot,Yot,v6,OAe,Kot,Zot,ate,ert,ort,rrt,F6,VAe,trt,art,nte,nrt,srt,lrt,T6,XAe,irt,drt,ste,crt,frt,mrt,M6,zAe,grt,hrt,lte,prt,_rt,urt,E6,WAe,brt,vrt,ite,Frt,Trt,Mrt,C6,QAe,Ert,Crt,dte,wrt,Art,Lrt,w6,HAe,yrt,xrt,cte,$rt,krt,Srt,A6,UAe,Rrt,Prt,fte,Brt,Irt,Nrt,L6,JAe,qrt,jrt,mte,Drt,Grt,Ort,y6,qHe,Cf,x6,YAe,Sk,Vrt,KAe,Xrt,jHe,Cr,Rk,zrt,wf,Wrt,gte,Qrt,Hrt,hte,Urt,Jrt,Yrt,Pk,Krt,ZAe,Zrt,ett,ott,ra,Bk,rtt,e7e,ttt,att,Af,ntt,o7e,stt,ltt,pte,itt,dtt,ctt,$6,ftt,Kr,Ik,mtt,r7e,gtt,htt,Rn,ptt,t7e,_tt,utt,a7e,btt,vtt,n7e,Ftt,Ttt,Mtt,Re,k6,s7e,Ett,Ctt,_te,wtt,Att,Ltt,S6,l7e,ytt,xtt,ute,$tt,ktt,Stt,R6,i7e,Rtt,Ptt,bte,Btt,Itt,Ntt,P6,d7e,qtt,jtt,vte,Dtt,Gtt,Ott,B6,c7e,Vtt,Xtt,Fte,ztt,Wtt,Qtt,I6,f7e,Htt,Utt,Tte,Jtt,Ytt,Ktt,N6,m7e,Ztt,eat,Mte,oat,rat,tat,q6,g7e,aat,nat,Ete,sat,lat,iat,j6,h7e,dat,cat,Cte,fat,mat,gat,D6,p7e,hat,pat,wte,_at,uat,bat,G6,DHe,Lf,O6,_7e,Nk,vat,u7e,Fat,GHe,wr,qk,Tat,yf,Mat,Ate,Eat,Cat,Lte,wat,Aat,Lat,jk,yat,b7e,xat,$at,kat,ta,Dk,Sat,v7e,Rat,Pat,xf,Bat,F7e,Iat,Nat,yte,qat,jat,Dat,V6,Gat,Zr,Gk,Oat,T7e,Vat,Xat,Pn,zat,M7e,Wat,Qat,E7e,Hat,Uat,C7e,Jat,Yat,Kat,Xe,X6,w7e,Zat,ent,xte,ont,rnt,tnt,z6,A7e,ant,nnt,$te,snt,lnt,int,W6,L7e,dnt,cnt,kte,fnt,mnt,gnt,Q6,y7e,hnt,pnt,Ste,_nt,unt,bnt,H6,x7e,vnt,Fnt,Rte,Tnt,Mnt,Ent,U6,$7e,Cnt,wnt,Pte,Ant,Lnt,ynt,J6,k7e,xnt,$nt,Bte,knt,Snt,Rnt,Y6,S7e,Pnt,Bnt,Ite,Int,Nnt,qnt,K6,OHe,$f,Z6,R7e,Ok,jnt,P7e,Dnt,VHe,Ar,Vk,Gnt,kf,Ont,Nte,Vnt,Xnt,qte,znt,Wnt,Qnt,Xk,Hnt,B7e,Unt,Jnt,Ynt,aa,zk,Knt,I7e,Znt,est,Sf,ost,N7e,rst,tst,jte,ast,nst,sst,eA,lst,et,Wk,ist,q7e,dst,cst,Bn,fst,j7e,mst,gst,D7e,hst,pst,G7e,_st,ust,bst,ze,oA,O7e,vst,Fst,Dte,Tst,Mst,Est,rA,V7e,Cst,wst,Gte,Ast,Lst,yst,tA,X7e,xst,$st,Ote,kst,Sst,Rst,aA,z7e,Pst,Bst,Vte,Ist,Nst,qst,nA,W7e,jst,Dst,Xte,Gst,Ost,Vst,sA,Q7e,Xst,zst,zte,Wst,Qst,Hst,lA,H7e,Ust,Jst,Wte,Yst,Kst,Zst,iA,U7e,elt,olt,Qte,rlt,tlt,alt,dA,XHe,Rf,cA,J7e,Qk,nlt,Y7e,slt,zHe,Lr,Hk,llt,Pf,ilt,Hte,dlt,clt,Ute,flt,mlt,glt,Uk,hlt,K7e,plt,_lt,ult,na,Jk,blt,Z7e,vlt,Flt,Bf,Tlt,eLe,Mlt,Elt,Jte,Clt,wlt,Alt,fA,Llt,ot,Yk,ylt,oLe,xlt,$lt,In,klt,rLe,Slt,Rlt,tLe,Plt,Blt,aLe,Ilt,Nlt,qlt,nLe,mA,sLe,jlt,Dlt,Yte,Glt,Olt,Vlt,gA,WHe,If,hA,lLe,Kk,Xlt,iLe,zlt,QHe,yr,Zk,Wlt,Nf,Qlt,Kte,Hlt,Ult,Zte,Jlt,Ylt,Klt,eS,Zlt,dLe,eit,oit,rit,sa,oS,tit,cLe,ait,nit,qf,sit,fLe,lit,iit,eae,dit,cit,fit,pA,mit,rt,rS,git,mLe,hit,pit,Nn,_it,gLe,uit,bit,hLe,vit,Fit,pLe,Tit,Mit,Eit,tS,_A,_Le,Cit,wit,oae,Ait,Lit,yit,uA,uLe,xit,$it,rae,kit,Sit,Rit,bA,HHe,jf,vA,bLe,aS,Pit,vLe,Bit,UHe,xr,nS,Iit,Df,Nit,tae,qit,jit,aae,Dit,Git,Oit,sS,Vit,FLe,Xit,zit,Wit,la,lS,Qit,TLe,Hit,Uit,Gf,Jit,MLe,Yit,Kit,nae,Zit,edt,odt,FA,rdt,tt,iS,tdt,ELe,adt,ndt,qn,sdt,CLe,ldt,idt,wLe,ddt,cdt,ALe,fdt,mdt,gdt,LLe,TA,yLe,hdt,pdt,sae,_dt,udt,bdt,MA,JHe;return d=new re({}),Ia=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),HL=new re({}),UL=new P({props:{code:`from transformers import AutoConfig, AutoModel

AutoConfig.register("new-model", NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Jf=new vdt({props:{warning:!0,$$slots:{default:[_ea]},$$scope:{ctx:$}}}),JL=new re({}),YL=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/configuration_auto.py#L620"}}),ey=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/configuration_auto.py#L643"}}),fh=new I({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[uea]},$$scope:{ctx:$}}}),oy=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/configuration_auto.py#L766"}}),ry=new re({}),ty=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/tokenization_auto.py#L411"}}),sy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_18022/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/tokenization_auto.py#L425"}}),Qh=new I({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[bea]},$$scope:{ctx:$}}}),ly=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/tokenization_auto.py#L624"}}),iy=new re({}),dy=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/feature_extraction_auto.py#L198"}}),my=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_18022/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/feature_extraction_auto.py#L212"}}),Rp=new vdt({props:{$$slots:{default:[vea]},$$scope:{ctx:$}}}),Pp=new I({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[Fea]},$$scope:{ctx:$}}}),gy=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/feature_extraction_auto.py#L339"}}),hy=new re({}),py=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/processing_auto.py#L90"}}),by=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/processing_auto.py#L104"}}),r_=new vdt({props:{$$slots:{default:[Tea]},$$scope:{ctx:$}}}),t_=new I({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[Mea]},$$scope:{ctx:$}}}),vy=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/processing_auto.py#L257"}}),Fy=new re({}),Ty=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L807"}}),Ey=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenModel">CodeGenModel</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/groupvit#transformers.GroupViTConfig">GroupViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/groupvit#transformers.GroupViTModel">GroupViTModel</a> (GroupViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTModel">MobileViTModel</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpModel">MvpModel</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/owlvit#transformers.OwlViTConfig">OwlViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/owlvit#transformers.OwlViTModel">OwlViTModel</a> (OWL-ViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2Model">Swinv2Model</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEModel">VideoMAEModel</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),s_=new I({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[Eea]},$$scope:{ctx:$}}}),Cy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),h2=new I({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[Cea]},$$scope:{ctx:$}}}),wy=new re({}),Ay=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L814"}}),yy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEForPreTraining">VideoMAEForPreTraining</a> (VideoMAE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),_2=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[wea]},$$scope:{ctx:$}}}),xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),f1=new I({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Aea]},$$scope:{ctx:$}}}),$y=new re({}),ky=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L829"}}),Ry=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenConfig">CodeGenConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenForCausalLM">CodeGenForCausalLM</a> (CodeGen model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForCausalLM">MvpForCausalLM</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),g1=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[Lea]},$$scope:{ctx:$}}}),Py=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),ob=new I({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[yea]},$$scope:{ctx:$}}}),By=new re({}),Iy=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L836"}}),qy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),tb=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[xea]},$$scope:{ctx:$}}}),jy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),Vb=new I({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[$ea]},$$scope:{ctx:$}}}),Dy=new re({}),Gy=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L843"}}),Vy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForConditionalGeneration">MvpForConditionalGeneration</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),zb=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[kea]},$$scope:{ctx:$}}}),Xy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),mv=new I({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[Sea]},$$scope:{ctx:$}}}),zy=new re({}),Wy=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L852"}}),Hy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForSequenceClassification">LukeForSequenceClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForSequenceClassification">MvpForSequenceClassification</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTForSequenceClassification">OPTForSequenceClassification</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),hv=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[Rea]},$$scope:{ctx:$}}}),Uy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),h0=new I({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Pea]},$$scope:{ctx:$}}}),Jy=new re({}),Yy=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L897"}}),Zy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForMultipleChoice">LukeForMultipleChoice</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),_0=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[Bea]},$$scope:{ctx:$}}}),e9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),U0=new I({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Iea]},$$scope:{ctx:$}}}),o9=new re({}),r9=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L904"}}),a9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),Y0=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Nea]},$$scope:{ctx:$}}}),n9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),nF=new I({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[qea]},$$scope:{ctx:$}}}),s9=new re({}),l9=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L890"}}),d9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForTokenClassification">LukeForTokenClassification</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),lF=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[jea]},$$scope:{ctx:$}}}),c9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),WF=new I({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Dea]},$$scope:{ctx:$}}}),f9=new re({}),m9=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L861"}}),h9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForQuestionAnswering">LukeForQuestionAnswering</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpConfig">MvpConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForQuestionAnswering">MvpForQuestionAnswering</a> (MVP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),HF=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Gea]},$$scope:{ctx:$}}}),p9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),jT=new I({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Oea]},$$scope:{ctx:$}}}),_9=new re({}),u9=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L868"}}),v9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),GT=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Vea]},$$scope:{ctx:$}}}),F9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),XT=new I({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[Xea]},$$scope:{ctx:$}}}),T9=new re({}),M9=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L913"}}),C9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTForImageClassification">MobileViTForImageClassification</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2ForImageClassification">Swinv2ForImageClassification</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),WT=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[zea]},$$scope:{ctx:$}}}),w9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),i8=new I({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Wea]},$$scope:{ctx:$}}}),A9=new re({}),L9=new R({props:{name:"class transformers.AutoModelForVideoClassification",anchor:"transformers.AutoModelForVideoClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L952"}}),x9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVideoClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEConfig">VideoMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEForVideoClassification">VideoMAEForVideoClassification</a> (VideoMAE model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),c8=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_config.example",$$slots:{default:[Qea]},$$scope:{ctx:$}}}),$9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVideoClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),g8=new I({props:{anchor:"transformers.AutoModelForVideoClassification.from_pretrained.example",$$slots:{default:[Hea]},$$scope:{ctx:$}}}),k9=new re({}),S9=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L959"}}),P9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),p8=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[Uea]},$$scope:{ctx:$}}}),B9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),b8=new I({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Jea]},$$scope:{ctx:$}}}),I9=new re({}),N9=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L879"}}),j9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),F8=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[Yea]},$$scope:{ctx:$}}}),D9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),E8=new I({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[Kea]},$$scope:{ctx:$}}}),G9=new re({}),O9=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L966"}}),X9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),w8=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[Zea]},$$scope:{ctx:$}}}),z9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),I8=new I({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[eoa]},$$scope:{ctx:$}}}),W9=new re({}),Q9=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L989"}}),U9=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),q8=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[ooa]},$$scope:{ctx:$}}}),J9=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),z8=new I({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[roa]},$$scope:{ctx:$}}}),Y9=new re({}),K9=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L973"}}),ex=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),Q8=new I({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[toa]},$$scope:{ctx:$}}}),ox=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),nM=new I({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[aoa]},$$scope:{ctx:$}}}),rx=new re({}),tx=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L980"}}),nx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),lM=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[noa]},$$scope:{ctx:$}}}),sx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),fM=new I({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[soa]},$$scope:{ctx:$}}}),ix=new re({}),dx=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L998"}}),fx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),gM=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[loa]},$$scope:{ctx:$}}}),mx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),FM=new I({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[ioa]},$$scope:{ctx:$}}}),gx=new re({}),hx=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L1005"}}),_x=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2Config">Swinv2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling">Swinv2ForMaskedImageModeling</a> (Swin Transformer V2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),MM=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[doa]},$$scope:{ctx:$}}}),ux=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),yM=new I({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[coa]},$$scope:{ctx:$}}}),bx=new re({}),vx=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L945"}}),Tx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),$M=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[foa]},$$scope:{ctx:$}}}),Mx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),PM=new I({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[moa]},$$scope:{ctx:$}}}),Cx=new re({}),wx=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L920"}}),Lx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),IM=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[goa]},$$scope:{ctx:$}}}),yx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),jM=new I({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[hoa]},$$scope:{ctx:$}}}),xx=new re({}),$x=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L927"}}),Sx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTConfig">MobileViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation">MobileViTForSemanticSegmentation</a> (MobileViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),GM=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[poa]},$$scope:{ctx:$}}}),Rx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),HM=new I({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[_oa]},$$scope:{ctx:$}}}),Px=new re({}),Bx=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_auto.py#L936"}}),Nx=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),JM=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[uoa]},$$scope:{ctx:$}}}),qx=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),ZM=new I({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[boa]},$$scope:{ctx:$}}}),jx=new re({}),Dx=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L416"}}),Ox=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.TFDeiTModel">TFDeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/regnet#transformers.TFRegNetModel">TFRegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/resnet#transformers.TFResNetModel">TFResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.TFSegformerModel">TFSegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),oE=new I({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[voa]},$$scope:{ctx:$}}}),Vx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),KE=new I({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[Foa]},$$scope:{ctx:$}}}),Xx=new re({}),zx=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L423"}}),Qx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),e4=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[Toa]},$$scope:{ctx:$}}}),Hx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),C4=new I({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Moa]},$$scope:{ctx:$}}}),Ux=new re({}),Jx=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L438"}}),Kx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),A4=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[Eoa]},$$scope:{ctx:$}}}),Zx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),D4=new I({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Coa]},$$scope:{ctx:$}}}),e$=new re({}),o$=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L454"}}),t$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.TFDeiTForImageClassification">TFDeiTForImageClassification</a> or <a href="/docs/transformers/pr_18022/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher">TFDeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/regnet#transformers.TFRegNetForImageClassification">TFRegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/resnet#transformers.TFResNetForImageClassification">TFResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/segformer#transformers.TFSegformerForImageClassification">TFSegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),O4=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[woa]},$$scope:{ctx:$}}}),a$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),J4=new I({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[Aoa]},$$scope:{ctx:$}}}),n$=new re({}),s$=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L479"}}),i$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),K4=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[Loa]},$$scope:{ctx:$}}}),d$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),vC=new I({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[yoa]},$$scope:{ctx:$}}}),c$=new re({}),f$=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L486"}}),g$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),TC=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[xoa]},$$scope:{ctx:$}}}),h$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),SC=new I({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[$oa]},$$scope:{ctx:$}}}),p$=new re({}),_$=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L495"}}),b$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),PC=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[koa]},$$scope:{ctx:$}}}),v$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),l5=new I({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[Soa]},$$scope:{ctx:$}}}),F$=new re({}),T$=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L531"}}),E$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),d5=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[Roa]},$$scope:{ctx:$}}}),C$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),L5=new I({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[Poa]},$$scope:{ctx:$}}}),w$=new re({}),A$=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L538"}}),y$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),x5=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[Boa]},$$scope:{ctx:$}}}),x$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),S5=new I({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[Ioa]},$$scope:{ctx:$}}}),k$=new re({}),S$=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L511"}}),P$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),P5=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[Noa]},$$scope:{ctx:$}}}),B$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),I5=new I({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[qoa]},$$scope:{ctx:$}}}),I$=new re({}),N$=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L522"}}),j$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),q5=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[joa]},$$scope:{ctx:$}}}),D$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),n3=new I({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[Doa]},$$scope:{ctx:$}}}),G$=new re({}),O$=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L504"}}),X$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),l3=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[Goa]},$$scope:{ctx:$}}}),z$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),y3=new I({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[Ooa]},$$scope:{ctx:$}}}),W$=new re({}),Q$=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L472"}}),U$=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),$3=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[Voa]},$$scope:{ctx:$}}}),J$=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),S3=new I({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[Xoa]},$$scope:{ctx:$}}}),Y$=new re({}),K$=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_tf_auto.py#L547"}}),ek=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),P3=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[zoa]},$$scope:{ctx:$}}}),ok=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),I3=new I({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[Woa]},$$scope:{ctx:$}}}),rk=new re({}),tk=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L248"}}),nk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.FlaxBloomModel">FlaxBloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),q3=new I({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[Qoa]},$$scope:{ctx:$}}}),sk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),gw=new I({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[Hoa]},$$scope:{ctx:$}}}),lk=new re({}),ik=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L262"}}),ck=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bloom#transformers.FlaxBloomForCausalLM">FlaxBloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),pw=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[Uoa]},$$scope:{ctx:$}}}),fk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),Lw=new I({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[Joa]},$$scope:{ctx:$}}}),mk=new re({}),gk=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L255"}}),pk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),xw=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[Yoa]},$$scope:{ctx:$}}}),_k=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),Vw=new I({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[Koa]},$$scope:{ctx:$}}}),uk=new re({}),bk=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L269"}}),Fk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),zw=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[Zoa]},$$scope:{ctx:$}}}),Tk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),r6=new I({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[era]},$$scope:{ctx:$}}}),Mk=new re({}),Ek=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L276"}}),wk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),a6=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[ora]},$$scope:{ctx:$}}}),Ak=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),p6=new I({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[rra]},$$scope:{ctx:$}}}),Lk=new re({}),yk=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L285"}}),$k=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),u6=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[tra]},$$scope:{ctx:$}}}),kk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),y6=new I({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[ara]},$$scope:{ctx:$}}}),Sk=new re({}),Rk=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L294"}}),Bk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),$6=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[nra]},$$scope:{ctx:$}}}),Ik=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),G6=new I({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[sra]},$$scope:{ctx:$}}}),Nk=new re({}),qk=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L301"}}),Dk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),V6=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[lra]},$$scope:{ctx:$}}}),Gk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),K6=new I({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[ira]},$$scope:{ctx:$}}}),Ok=new re({}),Vk=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L310"}}),zk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),eA=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[dra]},$$scope:{ctx:$}}}),Wk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),dA=new I({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[cra]},$$scope:{ctx:$}}}),Qk=new re({}),Hk=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L317"}}),Jk=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),fA=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[fra]},$$scope:{ctx:$}}}),Yk=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),gA=new I({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[mra]},$$scope:{ctx:$}}}),Kk=new re({}),Zk=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L326"}}),oS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),pA=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[gra]},$$scope:{ctx:$}}}),rS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),bA=new I({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[hra]},$$scope:{ctx:$}}}),aS=new re({}),nS=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/modeling_flax_auto.py#L335"}}),lS=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L389"}}),FA=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[pra]},$$scope:{ctx:$}}}),iS=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_18022/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_18022/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_18022/src/transformers/models/auto/auto_factory.py#L417"}}),MA=new I({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[_ra]},$$scope:{ctx:$}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Ao=a("span"),Ii=o("Auto Classes"),zf=l(),dt=a("p"),Ni=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),qi=a("code"),XL=o("from_pretrained()"),Wf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),ji=o("Instantiating one of "),Dn=a("a"),zL=o("AutoConfig"),Gn=o(", "),On=a("a"),WL=o("AutoModel"),Di=o(`, and
`),Vn=a("a"),QL=o("AutoTokenizer"),Gi=o(" will directly create a class of the relevant architecture. For instance"),Qf=l(),F(Ia.$$.fragment),He=l(),Le=a("p"),SR=o("will create a model that is an instance of "),Oi=a("a"),RR=o("BertModel"),PR=o("."),Lo=l(),Na=a("p"),BR=o("There is one class of "),Hf=a("code"),IR=o("AutoModel"),iYe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),VWe=l(),Vi=a("h2"),Uf=a("a"),rse=a("span"),F(HL.$$.fragment),dYe=l(),tse=a("span"),cYe=o("Extending the Auto Classes"),XWe=l(),Xn=a("p"),fYe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ase=a("code"),mYe=o("NewModel"),gYe=o(", make sure you have a "),nse=a("code"),hYe=o("NewModelConfig"),pYe=o(` then you can add those to the auto
classes like this:`),zWe=l(),F(UL.$$.fragment),WWe=l(),NR=a("p"),_Ye=o("You will then be able to use the auto classes like you would usually do!"),QWe=l(),F(Jf.$$.fragment),HWe=l(),Xi=a("h2"),Yf=a("a"),sse=a("span"),F(JL.$$.fragment),uYe=l(),lse=a("span"),bYe=o("AutoConfig"),UWe=l(),yo=a("div"),F(YL.$$.fragment),vYe=l(),KL=a("p"),FYe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),qR=a("a"),TYe=o("from_pretrained()"),MYe=o(" class method."),EYe=l(),ZL=a("p"),CYe=o("This class cannot be instantiated directly using "),ise=a("code"),wYe=o("__init__()"),AYe=o(" (throws an error)."),LYe=l(),$r=a("div"),F(ey.$$.fragment),yYe=l(),dse=a("p"),xYe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),$Ye=l(),zi=a("p"),kYe=o("The configuration class to instantiate is selected based on the "),cse=a("code"),SYe=o("model_type"),RYe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),fse=a("code"),PYe=o("pretrained_model_name_or_path"),BYe=o(":"),IYe=l(),A=a("ul"),Kf=a("li"),mse=a("strong"),NYe=o("albert"),qYe=o(" \u2014 "),jR=a("a"),jYe=o("AlbertConfig"),DYe=o(" (ALBERT model)"),GYe=l(),Zf=a("li"),gse=a("strong"),OYe=o("bart"),VYe=o(" \u2014 "),DR=a("a"),XYe=o("BartConfig"),zYe=o(" (BART model)"),WYe=l(),em=a("li"),hse=a("strong"),QYe=o("beit"),HYe=o(" \u2014 "),GR=a("a"),UYe=o("BeitConfig"),JYe=o(" (BEiT model)"),YYe=l(),om=a("li"),pse=a("strong"),KYe=o("bert"),ZYe=o(" \u2014 "),OR=a("a"),eKe=o("BertConfig"),oKe=o(" (BERT model)"),rKe=l(),rm=a("li"),_se=a("strong"),tKe=o("bert-generation"),aKe=o(" \u2014 "),VR=a("a"),nKe=o("BertGenerationConfig"),sKe=o(" (Bert Generation model)"),lKe=l(),tm=a("li"),use=a("strong"),iKe=o("big_bird"),dKe=o(" \u2014 "),XR=a("a"),cKe=o("BigBirdConfig"),fKe=o(" (BigBird model)"),mKe=l(),am=a("li"),bse=a("strong"),gKe=o("bigbird_pegasus"),hKe=o(" \u2014 "),zR=a("a"),pKe=o("BigBirdPegasusConfig"),_Ke=o(" (BigBird-Pegasus model)"),uKe=l(),nm=a("li"),vse=a("strong"),bKe=o("blenderbot"),vKe=o(" \u2014 "),WR=a("a"),FKe=o("BlenderbotConfig"),TKe=o(" (Blenderbot model)"),MKe=l(),sm=a("li"),Fse=a("strong"),EKe=o("blenderbot-small"),CKe=o(" \u2014 "),QR=a("a"),wKe=o("BlenderbotSmallConfig"),AKe=o(" (BlenderbotSmall model)"),LKe=l(),lm=a("li"),Tse=a("strong"),yKe=o("bloom"),xKe=o(" \u2014 "),HR=a("a"),$Ke=o("BloomConfig"),kKe=o(" (BLOOM model)"),SKe=l(),im=a("li"),Mse=a("strong"),RKe=o("camembert"),PKe=o(" \u2014 "),UR=a("a"),BKe=o("CamembertConfig"),IKe=o(" (CamemBERT model)"),NKe=l(),dm=a("li"),Ese=a("strong"),qKe=o("canine"),jKe=o(" \u2014 "),JR=a("a"),DKe=o("CanineConfig"),GKe=o(" (CANINE model)"),OKe=l(),cm=a("li"),Cse=a("strong"),VKe=o("clip"),XKe=o(" \u2014 "),YR=a("a"),zKe=o("CLIPConfig"),WKe=o(" (CLIP model)"),QKe=l(),fm=a("li"),wse=a("strong"),HKe=o("codegen"),UKe=o(" \u2014 "),KR=a("a"),JKe=o("CodeGenConfig"),YKe=o(" (CodeGen model)"),KKe=l(),mm=a("li"),Ase=a("strong"),ZKe=o("convbert"),eZe=o(" \u2014 "),ZR=a("a"),oZe=o("ConvBertConfig"),rZe=o(" (ConvBERT model)"),tZe=l(),gm=a("li"),Lse=a("strong"),aZe=o("convnext"),nZe=o(" \u2014 "),eP=a("a"),sZe=o("ConvNextConfig"),lZe=o(" (ConvNeXT model)"),iZe=l(),hm=a("li"),yse=a("strong"),dZe=o("ctrl"),cZe=o(" \u2014 "),oP=a("a"),fZe=o("CTRLConfig"),mZe=o(" (CTRL model)"),gZe=l(),pm=a("li"),xse=a("strong"),hZe=o("cvt"),pZe=o(" \u2014 "),rP=a("a"),_Ze=o("CvtConfig"),uZe=o(" (CvT model)"),bZe=l(),_m=a("li"),$se=a("strong"),vZe=o("data2vec-audio"),FZe=o(" \u2014 "),tP=a("a"),TZe=o("Data2VecAudioConfig"),MZe=o(" (Data2VecAudio model)"),EZe=l(),um=a("li"),kse=a("strong"),CZe=o("data2vec-text"),wZe=o(" \u2014 "),aP=a("a"),AZe=o("Data2VecTextConfig"),LZe=o(" (Data2VecText model)"),yZe=l(),bm=a("li"),Sse=a("strong"),xZe=o("data2vec-vision"),$Ze=o(" \u2014 "),nP=a("a"),kZe=o("Data2VecVisionConfig"),SZe=o(" (Data2VecVision model)"),RZe=l(),vm=a("li"),Rse=a("strong"),PZe=o("deberta"),BZe=o(" \u2014 "),sP=a("a"),IZe=o("DebertaConfig"),NZe=o(" (DeBERTa model)"),qZe=l(),Fm=a("li"),Pse=a("strong"),jZe=o("deberta-v2"),DZe=o(" \u2014 "),lP=a("a"),GZe=o("DebertaV2Config"),OZe=o(" (DeBERTa-v2 model)"),VZe=l(),Tm=a("li"),Bse=a("strong"),XZe=o("decision_transformer"),zZe=o(" \u2014 "),iP=a("a"),WZe=o("DecisionTransformerConfig"),QZe=o(" (Decision Transformer model)"),HZe=l(),Mm=a("li"),Ise=a("strong"),UZe=o("deit"),JZe=o(" \u2014 "),dP=a("a"),YZe=o("DeiTConfig"),KZe=o(" (DeiT model)"),ZZe=l(),Em=a("li"),Nse=a("strong"),eeo=o("detr"),oeo=o(" \u2014 "),cP=a("a"),reo=o("DetrConfig"),teo=o(" (DETR model)"),aeo=l(),Cm=a("li"),qse=a("strong"),neo=o("distilbert"),seo=o(" \u2014 "),fP=a("a"),leo=o("DistilBertConfig"),ieo=o(" (DistilBERT model)"),deo=l(),wm=a("li"),jse=a("strong"),ceo=o("dpr"),feo=o(" \u2014 "),mP=a("a"),meo=o("DPRConfig"),geo=o(" (DPR model)"),heo=l(),Am=a("li"),Dse=a("strong"),peo=o("dpt"),_eo=o(" \u2014 "),gP=a("a"),ueo=o("DPTConfig"),beo=o(" (DPT model)"),veo=l(),Lm=a("li"),Gse=a("strong"),Feo=o("electra"),Teo=o(" \u2014 "),hP=a("a"),Meo=o("ElectraConfig"),Eeo=o(" (ELECTRA model)"),Ceo=l(),ym=a("li"),Ose=a("strong"),weo=o("encoder-decoder"),Aeo=o(" \u2014 "),pP=a("a"),Leo=o("EncoderDecoderConfig"),yeo=o(" (Encoder decoder model)"),xeo=l(),xm=a("li"),Vse=a("strong"),$eo=o("flaubert"),keo=o(" \u2014 "),_P=a("a"),Seo=o("FlaubertConfig"),Reo=o(" (FlauBERT model)"),Peo=l(),$m=a("li"),Xse=a("strong"),Beo=o("flava"),Ieo=o(" \u2014 "),uP=a("a"),Neo=o("FlavaConfig"),qeo=o(" (FLAVA model)"),jeo=l(),km=a("li"),zse=a("strong"),Deo=o("fnet"),Geo=o(" \u2014 "),bP=a("a"),Oeo=o("FNetConfig"),Veo=o(" (FNet model)"),Xeo=l(),Sm=a("li"),Wse=a("strong"),zeo=o("fsmt"),Weo=o(" \u2014 "),vP=a("a"),Qeo=o("FSMTConfig"),Heo=o(" (FairSeq Machine-Translation model)"),Ueo=l(),Rm=a("li"),Qse=a("strong"),Jeo=o("funnel"),Yeo=o(" \u2014 "),FP=a("a"),Keo=o("FunnelConfig"),Zeo=o(" (Funnel Transformer model)"),eoo=l(),Pm=a("li"),Hse=a("strong"),ooo=o("glpn"),roo=o(" \u2014 "),TP=a("a"),too=o("GLPNConfig"),aoo=o(" (GLPN model)"),noo=l(),Bm=a("li"),Use=a("strong"),soo=o("gpt2"),loo=o(" \u2014 "),MP=a("a"),ioo=o("GPT2Config"),doo=o(" (OpenAI GPT-2 model)"),coo=l(),Im=a("li"),Jse=a("strong"),foo=o("gpt_neo"),moo=o(" \u2014 "),EP=a("a"),goo=o("GPTNeoConfig"),hoo=o(" (GPT Neo model)"),poo=l(),Nm=a("li"),Yse=a("strong"),_oo=o("gpt_neox"),uoo=o(" \u2014 "),CP=a("a"),boo=o("GPTNeoXConfig"),voo=o(" (GPT NeoX model)"),Foo=l(),qm=a("li"),Kse=a("strong"),Too=o("gptj"),Moo=o(" \u2014 "),wP=a("a"),Eoo=o("GPTJConfig"),Coo=o(" (GPT-J model)"),woo=l(),jm=a("li"),Zse=a("strong"),Aoo=o("groupvit"),Loo=o(" \u2014 "),AP=a("a"),yoo=o("GroupViTConfig"),xoo=o(" (GroupViT model)"),$oo=l(),Dm=a("li"),ele=a("strong"),koo=o("hubert"),Soo=o(" \u2014 "),LP=a("a"),Roo=o("HubertConfig"),Poo=o(" (Hubert model)"),Boo=l(),Gm=a("li"),ole=a("strong"),Ioo=o("ibert"),Noo=o(" \u2014 "),yP=a("a"),qoo=o("IBertConfig"),joo=o(" (I-BERT model)"),Doo=l(),Om=a("li"),rle=a("strong"),Goo=o("imagegpt"),Ooo=o(" \u2014 "),xP=a("a"),Voo=o("ImageGPTConfig"),Xoo=o(" (ImageGPT model)"),zoo=l(),Vm=a("li"),tle=a("strong"),Woo=o("layoutlm"),Qoo=o(" \u2014 "),$P=a("a"),Hoo=o("LayoutLMConfig"),Uoo=o(" (LayoutLM model)"),Joo=l(),Xm=a("li"),ale=a("strong"),Yoo=o("layoutlmv2"),Koo=o(" \u2014 "),kP=a("a"),Zoo=o("LayoutLMv2Config"),ero=o(" (LayoutLMv2 model)"),oro=l(),zm=a("li"),nle=a("strong"),rro=o("layoutlmv3"),tro=o(" \u2014 "),SP=a("a"),aro=o("LayoutLMv3Config"),nro=o(" (LayoutLMv3 model)"),sro=l(),Wm=a("li"),sle=a("strong"),lro=o("led"),iro=o(" \u2014 "),RP=a("a"),dro=o("LEDConfig"),cro=o(" (LED model)"),fro=l(),Qm=a("li"),lle=a("strong"),mro=o("levit"),gro=o(" \u2014 "),PP=a("a"),hro=o("LevitConfig"),pro=o(" (LeViT model)"),_ro=l(),Hm=a("li"),ile=a("strong"),uro=o("longformer"),bro=o(" \u2014 "),BP=a("a"),vro=o("LongformerConfig"),Fro=o(" (Longformer model)"),Tro=l(),Um=a("li"),dle=a("strong"),Mro=o("longt5"),Ero=o(" \u2014 "),IP=a("a"),Cro=o("LongT5Config"),wro=o(" (LongT5 model)"),Aro=l(),Jm=a("li"),cle=a("strong"),Lro=o("luke"),yro=o(" \u2014 "),NP=a("a"),xro=o("LukeConfig"),$ro=o(" (LUKE model)"),kro=l(),Ym=a("li"),fle=a("strong"),Sro=o("lxmert"),Rro=o(" \u2014 "),qP=a("a"),Pro=o("LxmertConfig"),Bro=o(" (LXMERT model)"),Iro=l(),Km=a("li"),mle=a("strong"),Nro=o("m2m_100"),qro=o(" \u2014 "),jP=a("a"),jro=o("M2M100Config"),Dro=o(" (M2M100 model)"),Gro=l(),Zm=a("li"),gle=a("strong"),Oro=o("marian"),Vro=o(" \u2014 "),DP=a("a"),Xro=o("MarianConfig"),zro=o(" (Marian model)"),Wro=l(),eg=a("li"),hle=a("strong"),Qro=o("maskformer"),Hro=o(" \u2014 "),GP=a("a"),Uro=o("MaskFormerConfig"),Jro=o(" (MaskFormer model)"),Yro=l(),og=a("li"),ple=a("strong"),Kro=o("mbart"),Zro=o(" \u2014 "),OP=a("a"),eto=o("MBartConfig"),oto=o(" (mBART model)"),rto=l(),rg=a("li"),_le=a("strong"),tto=o("mctct"),ato=o(" \u2014 "),VP=a("a"),nto=o("MCTCTConfig"),sto=o(" (M-CTC-T model)"),lto=l(),tg=a("li"),ule=a("strong"),ito=o("megatron-bert"),dto=o(" \u2014 "),XP=a("a"),cto=o("MegatronBertConfig"),fto=o(" (Megatron-BERT model)"),mto=l(),ag=a("li"),ble=a("strong"),gto=o("mobilebert"),hto=o(" \u2014 "),zP=a("a"),pto=o("MobileBertConfig"),_to=o(" (MobileBERT model)"),uto=l(),ng=a("li"),vle=a("strong"),bto=o("mobilevit"),vto=o(" \u2014 "),WP=a("a"),Fto=o("MobileViTConfig"),Tto=o(" (MobileViT model)"),Mto=l(),sg=a("li"),Fle=a("strong"),Eto=o("mpnet"),Cto=o(" \u2014 "),QP=a("a"),wto=o("MPNetConfig"),Ato=o(" (MPNet model)"),Lto=l(),lg=a("li"),Tle=a("strong"),yto=o("mt5"),xto=o(" \u2014 "),HP=a("a"),$to=o("MT5Config"),kto=o(" (MT5 model)"),Sto=l(),ig=a("li"),Mle=a("strong"),Rto=o("mvp"),Pto=o(" \u2014 "),UP=a("a"),Bto=o("MvpConfig"),Ito=o(" (MVP model)"),Nto=l(),dg=a("li"),Ele=a("strong"),qto=o("nezha"),jto=o(" \u2014 "),JP=a("a"),Dto=o("NezhaConfig"),Gto=o(" (Nezha model)"),Oto=l(),cg=a("li"),Cle=a("strong"),Vto=o("nystromformer"),Xto=o(" \u2014 "),YP=a("a"),zto=o("NystromformerConfig"),Wto=o(" (Nystr\xF6mformer model)"),Qto=l(),fg=a("li"),wle=a("strong"),Hto=o("openai-gpt"),Uto=o(" \u2014 "),KP=a("a"),Jto=o("OpenAIGPTConfig"),Yto=o(" (OpenAI GPT model)"),Kto=l(),mg=a("li"),Ale=a("strong"),Zto=o("opt"),eao=o(" \u2014 "),ZP=a("a"),oao=o("OPTConfig"),rao=o(" (OPT model)"),tao=l(),gg=a("li"),Lle=a("strong"),aao=o("owlvit"),nao=o(" \u2014 "),eB=a("a"),sao=o("OwlViTConfig"),lao=o(" (OWL-ViT model)"),iao=l(),hg=a("li"),yle=a("strong"),dao=o("pegasus"),cao=o(" \u2014 "),oB=a("a"),fao=o("PegasusConfig"),mao=o(" (Pegasus model)"),gao=l(),pg=a("li"),xle=a("strong"),hao=o("perceiver"),pao=o(" \u2014 "),rB=a("a"),_ao=o("PerceiverConfig"),uao=o(" (Perceiver model)"),bao=l(),_g=a("li"),$le=a("strong"),vao=o("plbart"),Fao=o(" \u2014 "),tB=a("a"),Tao=o("PLBartConfig"),Mao=o(" (PLBart model)"),Eao=l(),ug=a("li"),kle=a("strong"),Cao=o("poolformer"),wao=o(" \u2014 "),aB=a("a"),Aao=o("PoolFormerConfig"),Lao=o(" (PoolFormer model)"),yao=l(),bg=a("li"),Sle=a("strong"),xao=o("prophetnet"),$ao=o(" \u2014 "),nB=a("a"),kao=o("ProphetNetConfig"),Sao=o(" (ProphetNet model)"),Rao=l(),vg=a("li"),Rle=a("strong"),Pao=o("qdqbert"),Bao=o(" \u2014 "),sB=a("a"),Iao=o("QDQBertConfig"),Nao=o(" (QDQBert model)"),qao=l(),Fg=a("li"),Ple=a("strong"),jao=o("rag"),Dao=o(" \u2014 "),lB=a("a"),Gao=o("RagConfig"),Oao=o(" (RAG model)"),Vao=l(),Tg=a("li"),Ble=a("strong"),Xao=o("realm"),zao=o(" \u2014 "),iB=a("a"),Wao=o("RealmConfig"),Qao=o(" (REALM model)"),Hao=l(),Mg=a("li"),Ile=a("strong"),Uao=o("reformer"),Jao=o(" \u2014 "),dB=a("a"),Yao=o("ReformerConfig"),Kao=o(" (Reformer model)"),Zao=l(),Eg=a("li"),Nle=a("strong"),eno=o("regnet"),ono=o(" \u2014 "),cB=a("a"),rno=o("RegNetConfig"),tno=o(" (RegNet model)"),ano=l(),Cg=a("li"),qle=a("strong"),nno=o("rembert"),sno=o(" \u2014 "),fB=a("a"),lno=o("RemBertConfig"),ino=o(" (RemBERT model)"),dno=l(),wg=a("li"),jle=a("strong"),cno=o("resnet"),fno=o(" \u2014 "),mB=a("a"),mno=o("ResNetConfig"),gno=o(" (ResNet model)"),hno=l(),Ag=a("li"),Dle=a("strong"),pno=o("retribert"),_no=o(" \u2014 "),gB=a("a"),uno=o("RetriBertConfig"),bno=o(" (RetriBERT model)"),vno=l(),Lg=a("li"),Gle=a("strong"),Fno=o("roberta"),Tno=o(" \u2014 "),hB=a("a"),Mno=o("RobertaConfig"),Eno=o(" (RoBERTa model)"),Cno=l(),yg=a("li"),Ole=a("strong"),wno=o("roformer"),Ano=o(" \u2014 "),pB=a("a"),Lno=o("RoFormerConfig"),yno=o(" (RoFormer model)"),xno=l(),xg=a("li"),Vle=a("strong"),$no=o("segformer"),kno=o(" \u2014 "),_B=a("a"),Sno=o("SegformerConfig"),Rno=o(" (SegFormer model)"),Pno=l(),$g=a("li"),Xle=a("strong"),Bno=o("sew"),Ino=o(" \u2014 "),uB=a("a"),Nno=o("SEWConfig"),qno=o(" (SEW model)"),jno=l(),kg=a("li"),zle=a("strong"),Dno=o("sew-d"),Gno=o(" \u2014 "),bB=a("a"),Ono=o("SEWDConfig"),Vno=o(" (SEW-D model)"),Xno=l(),Sg=a("li"),Wle=a("strong"),zno=o("speech-encoder-decoder"),Wno=o(" \u2014 "),vB=a("a"),Qno=o("SpeechEncoderDecoderConfig"),Hno=o(" (Speech Encoder decoder model)"),Uno=l(),Rg=a("li"),Qle=a("strong"),Jno=o("speech_to_text"),Yno=o(" \u2014 "),FB=a("a"),Kno=o("Speech2TextConfig"),Zno=o(" (Speech2Text model)"),eso=l(),Pg=a("li"),Hle=a("strong"),oso=o("speech_to_text_2"),rso=o(" \u2014 "),TB=a("a"),tso=o("Speech2Text2Config"),aso=o(" (Speech2Text2 model)"),nso=l(),Bg=a("li"),Ule=a("strong"),sso=o("splinter"),lso=o(" \u2014 "),MB=a("a"),iso=o("SplinterConfig"),dso=o(" (Splinter model)"),cso=l(),Ig=a("li"),Jle=a("strong"),fso=o("squeezebert"),mso=o(" \u2014 "),EB=a("a"),gso=o("SqueezeBertConfig"),hso=o(" (SqueezeBERT model)"),pso=l(),Ng=a("li"),Yle=a("strong"),_so=o("swin"),uso=o(" \u2014 "),CB=a("a"),bso=o("SwinConfig"),vso=o(" (Swin Transformer model)"),Fso=l(),qg=a("li"),Kle=a("strong"),Tso=o("swinv2"),Mso=o(" \u2014 "),wB=a("a"),Eso=o("Swinv2Config"),Cso=o(" (Swin Transformer V2 model)"),wso=l(),jg=a("li"),Zle=a("strong"),Aso=o("t5"),Lso=o(" \u2014 "),AB=a("a"),yso=o("T5Config"),xso=o(" (T5 model)"),$so=l(),Dg=a("li"),eie=a("strong"),kso=o("tapas"),Sso=o(" \u2014 "),LB=a("a"),Rso=o("TapasConfig"),Pso=o(" (TAPAS model)"),Bso=l(),Gg=a("li"),oie=a("strong"),Iso=o("trajectory_transformer"),Nso=o(" \u2014 "),yB=a("a"),qso=o("TrajectoryTransformerConfig"),jso=o(" (Trajectory Transformer model)"),Dso=l(),Og=a("li"),rie=a("strong"),Gso=o("transfo-xl"),Oso=o(" \u2014 "),xB=a("a"),Vso=o("TransfoXLConfig"),Xso=o(" (Transformer-XL model)"),zso=l(),Vg=a("li"),tie=a("strong"),Wso=o("trocr"),Qso=o(" \u2014 "),$B=a("a"),Hso=o("TrOCRConfig"),Uso=o(" (TrOCR model)"),Jso=l(),Xg=a("li"),aie=a("strong"),Yso=o("unispeech"),Kso=o(" \u2014 "),kB=a("a"),Zso=o("UniSpeechConfig"),elo=o(" (UniSpeech model)"),olo=l(),zg=a("li"),nie=a("strong"),rlo=o("unispeech-sat"),tlo=o(" \u2014 "),SB=a("a"),alo=o("UniSpeechSatConfig"),nlo=o(" (UniSpeechSat model)"),slo=l(),Wg=a("li"),sie=a("strong"),llo=o("van"),ilo=o(" \u2014 "),RB=a("a"),dlo=o("VanConfig"),clo=o(" (VAN model)"),flo=l(),Qg=a("li"),lie=a("strong"),mlo=o("videomae"),glo=o(" \u2014 "),PB=a("a"),hlo=o("VideoMAEConfig"),plo=o(" (VideoMAE model)"),_lo=l(),Hg=a("li"),iie=a("strong"),ulo=o("vilt"),blo=o(" \u2014 "),BB=a("a"),vlo=o("ViltConfig"),Flo=o(" (ViLT model)"),Tlo=l(),Ug=a("li"),die=a("strong"),Mlo=o("vision-encoder-decoder"),Elo=o(" \u2014 "),IB=a("a"),Clo=o("VisionEncoderDecoderConfig"),wlo=o(" (Vision Encoder decoder model)"),Alo=l(),Jg=a("li"),cie=a("strong"),Llo=o("vision-text-dual-encoder"),ylo=o(" \u2014 "),NB=a("a"),xlo=o("VisionTextDualEncoderConfig"),$lo=o(" (VisionTextDualEncoder model)"),klo=l(),Yg=a("li"),fie=a("strong"),Slo=o("visual_bert"),Rlo=o(" \u2014 "),qB=a("a"),Plo=o("VisualBertConfig"),Blo=o(" (VisualBERT model)"),Ilo=l(),Kg=a("li"),mie=a("strong"),Nlo=o("vit"),qlo=o(" \u2014 "),jB=a("a"),jlo=o("ViTConfig"),Dlo=o(" (ViT model)"),Glo=l(),Zg=a("li"),gie=a("strong"),Olo=o("vit_mae"),Vlo=o(" \u2014 "),DB=a("a"),Xlo=o("ViTMAEConfig"),zlo=o(" (ViTMAE model)"),Wlo=l(),eh=a("li"),hie=a("strong"),Qlo=o("wav2vec2"),Hlo=o(" \u2014 "),GB=a("a"),Ulo=o("Wav2Vec2Config"),Jlo=o(" (Wav2Vec2 model)"),Ylo=l(),oh=a("li"),pie=a("strong"),Klo=o("wav2vec2-conformer"),Zlo=o(" \u2014 "),OB=a("a"),eio=o("Wav2Vec2ConformerConfig"),oio=o(" (Wav2Vec2-Conformer model)"),rio=l(),rh=a("li"),_ie=a("strong"),tio=o("wavlm"),aio=o(" \u2014 "),VB=a("a"),nio=o("WavLMConfig"),sio=o(" (WavLM model)"),lio=l(),th=a("li"),uie=a("strong"),iio=o("xglm"),dio=o(" \u2014 "),XB=a("a"),cio=o("XGLMConfig"),fio=o(" (XGLM model)"),mio=l(),ah=a("li"),bie=a("strong"),gio=o("xlm"),hio=o(" \u2014 "),zB=a("a"),pio=o("XLMConfig"),_io=o(" (XLM model)"),uio=l(),nh=a("li"),vie=a("strong"),bio=o("xlm-prophetnet"),vio=o(" \u2014 "),WB=a("a"),Fio=o("XLMProphetNetConfig"),Tio=o(" (XLM-ProphetNet model)"),Mio=l(),sh=a("li"),Fie=a("strong"),Eio=o("xlm-roberta"),Cio=o(" \u2014 "),QB=a("a"),wio=o("XLMRobertaConfig"),Aio=o(" (XLM-RoBERTa model)"),Lio=l(),lh=a("li"),Tie=a("strong"),yio=o("xlm-roberta-xl"),xio=o(" \u2014 "),HB=a("a"),$io=o("XLMRobertaXLConfig"),kio=o(" (XLM-RoBERTa-XL model)"),Sio=l(),ih=a("li"),Mie=a("strong"),Rio=o("xlnet"),Pio=o(" \u2014 "),UB=a("a"),Bio=o("XLNetConfig"),Iio=o(" (XLNet model)"),Nio=l(),dh=a("li"),Eie=a("strong"),qio=o("yolos"),jio=o(" \u2014 "),JB=a("a"),Dio=o("YolosConfig"),Gio=o(" (YOLOS model)"),Oio=l(),ch=a("li"),Cie=a("strong"),Vio=o("yoso"),Xio=o(" \u2014 "),YB=a("a"),zio=o("YosoConfig"),Wio=o(" (YOSO model)"),Qio=l(),F(fh.$$.fragment),Hio=l(),mh=a("div"),F(oy.$$.fragment),Uio=l(),wie=a("p"),Jio=o("Register a new configuration for this class."),JWe=l(),Wi=a("h2"),gh=a("a"),Aie=a("span"),F(ry.$$.fragment),Yio=l(),Lie=a("span"),Kio=o("AutoTokenizer"),YWe=l(),xo=a("div"),F(ty.$$.fragment),Zio=l(),ay=a("p"),edo=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),KB=a("a"),odo=o("AutoTokenizer.from_pretrained()"),rdo=o(" class method."),tdo=l(),ny=a("p"),ado=o("This class cannot be instantiated directly using "),yie=a("code"),ndo=o("__init__()"),sdo=o(" (throws an error)."),ldo=l(),kr=a("div"),F(sy.$$.fragment),ido=l(),xie=a("p"),ddo=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),cdo=l(),qa=a("p"),fdo=o("The tokenizer class to instantiate is selected based on the "),$ie=a("code"),mdo=o("model_type"),gdo=o(` property of the config object (either
passed as an argument or loaded from `),kie=a("code"),hdo=o("pretrained_model_name_or_path"),pdo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sie=a("code"),_do=o("pretrained_model_name_or_path"),udo=o(":"),bdo=l(),k=a("ul"),zn=a("li"),Rie=a("strong"),vdo=o("albert"),Fdo=o(" \u2014 "),ZB=a("a"),Tdo=o("AlbertTokenizer"),Mdo=o(" or "),eI=a("a"),Edo=o("AlbertTokenizerFast"),Cdo=o(" (ALBERT model)"),wdo=l(),Wn=a("li"),Pie=a("strong"),Ado=o("bart"),Ldo=o(" \u2014 "),oI=a("a"),ydo=o("BartTokenizer"),xdo=o(" or "),rI=a("a"),$do=o("BartTokenizerFast"),kdo=o(" (BART model)"),Sdo=l(),Qn=a("li"),Bie=a("strong"),Rdo=o("barthez"),Pdo=o(" \u2014 "),tI=a("a"),Bdo=o("BarthezTokenizer"),Ido=o(" or "),aI=a("a"),Ndo=o("BarthezTokenizerFast"),qdo=o(" (BARThez model)"),jdo=l(),hh=a("li"),Iie=a("strong"),Ddo=o("bartpho"),Gdo=o(" \u2014 "),nI=a("a"),Odo=o("BartphoTokenizer"),Vdo=o(" (BARTpho model)"),Xdo=l(),Hn=a("li"),Nie=a("strong"),zdo=o("bert"),Wdo=o(" \u2014 "),sI=a("a"),Qdo=o("BertTokenizer"),Hdo=o(" or "),lI=a("a"),Udo=o("BertTokenizerFast"),Jdo=o(" (BERT model)"),Ydo=l(),ph=a("li"),qie=a("strong"),Kdo=o("bert-generation"),Zdo=o(" \u2014 "),iI=a("a"),eco=o("BertGenerationTokenizer"),oco=o(" (Bert Generation model)"),rco=l(),_h=a("li"),jie=a("strong"),tco=o("bert-japanese"),aco=o(" \u2014 "),dI=a("a"),nco=o("BertJapaneseTokenizer"),sco=o(" (BertJapanese model)"),lco=l(),uh=a("li"),Die=a("strong"),ico=o("bertweet"),dco=o(" \u2014 "),cI=a("a"),cco=o("BertweetTokenizer"),fco=o(" (BERTweet model)"),mco=l(),Un=a("li"),Gie=a("strong"),gco=o("big_bird"),hco=o(" \u2014 "),fI=a("a"),pco=o("BigBirdTokenizer"),_co=o(" or "),mI=a("a"),uco=o("BigBirdTokenizerFast"),bco=o(" (BigBird model)"),vco=l(),Jn=a("li"),Oie=a("strong"),Fco=o("bigbird_pegasus"),Tco=o(" \u2014 "),gI=a("a"),Mco=o("PegasusTokenizer"),Eco=o(" or "),hI=a("a"),Cco=o("PegasusTokenizerFast"),wco=o(" (BigBird-Pegasus model)"),Aco=l(),Yn=a("li"),Vie=a("strong"),Lco=o("blenderbot"),yco=o(" \u2014 "),pI=a("a"),xco=o("BlenderbotTokenizer"),$co=o(" or "),_I=a("a"),kco=o("BlenderbotTokenizerFast"),Sco=o(" (Blenderbot model)"),Rco=l(),bh=a("li"),Xie=a("strong"),Pco=o("blenderbot-small"),Bco=o(" \u2014 "),uI=a("a"),Ico=o("BlenderbotSmallTokenizer"),Nco=o(" (BlenderbotSmall model)"),qco=l(),vh=a("li"),zie=a("strong"),jco=o("bloom"),Dco=o(" \u2014 "),bI=a("a"),Gco=o("BloomTokenizerFast"),Oco=o(" (BLOOM model)"),Vco=l(),Fh=a("li"),Wie=a("strong"),Xco=o("byt5"),zco=o(" \u2014 "),vI=a("a"),Wco=o("ByT5Tokenizer"),Qco=o(" (ByT5 model)"),Hco=l(),Kn=a("li"),Qie=a("strong"),Uco=o("camembert"),Jco=o(" \u2014 "),FI=a("a"),Yco=o("CamembertTokenizer"),Kco=o(" or "),TI=a("a"),Zco=o("CamembertTokenizerFast"),efo=o(" (CamemBERT model)"),ofo=l(),Th=a("li"),Hie=a("strong"),rfo=o("canine"),tfo=o(" \u2014 "),MI=a("a"),afo=o("CanineTokenizer"),nfo=o(" (CANINE model)"),sfo=l(),Zn=a("li"),Uie=a("strong"),lfo=o("clip"),ifo=o(" \u2014 "),EI=a("a"),dfo=o("CLIPTokenizer"),cfo=o(" or "),CI=a("a"),ffo=o("CLIPTokenizerFast"),mfo=o(" (CLIP model)"),gfo=l(),es=a("li"),Jie=a("strong"),hfo=o("codegen"),pfo=o(" \u2014 "),wI=a("a"),_fo=o("CodeGenTokenizer"),ufo=o(" or "),AI=a("a"),bfo=o("CodeGenTokenizerFast"),vfo=o(" (CodeGen model)"),Ffo=l(),os=a("li"),Yie=a("strong"),Tfo=o("convbert"),Mfo=o(" \u2014 "),LI=a("a"),Efo=o("ConvBertTokenizer"),Cfo=o(" or "),yI=a("a"),wfo=o("ConvBertTokenizerFast"),Afo=o(" (ConvBERT model)"),Lfo=l(),rs=a("li"),Kie=a("strong"),yfo=o("cpm"),xfo=o(" \u2014 "),xI=a("a"),$fo=o("CpmTokenizer"),kfo=o(" or "),$I=a("a"),Sfo=o("CpmTokenizerFast"),Rfo=o(" (CPM model)"),Pfo=l(),Mh=a("li"),Zie=a("strong"),Bfo=o("ctrl"),Ifo=o(" \u2014 "),kI=a("a"),Nfo=o("CTRLTokenizer"),qfo=o(" (CTRL model)"),jfo=l(),ts=a("li"),ede=a("strong"),Dfo=o("data2vec-text"),Gfo=o(" \u2014 "),SI=a("a"),Ofo=o("RobertaTokenizer"),Vfo=o(" or "),RI=a("a"),Xfo=o("RobertaTokenizerFast"),zfo=o(" (Data2VecText model)"),Wfo=l(),as=a("li"),ode=a("strong"),Qfo=o("deberta"),Hfo=o(" \u2014 "),PI=a("a"),Ufo=o("DebertaTokenizer"),Jfo=o(" or "),BI=a("a"),Yfo=o("DebertaTokenizerFast"),Kfo=o(" (DeBERTa model)"),Zfo=l(),ns=a("li"),rde=a("strong"),emo=o("deberta-v2"),omo=o(" \u2014 "),II=a("a"),rmo=o("DebertaV2Tokenizer"),tmo=o(" or "),NI=a("a"),amo=o("DebertaV2TokenizerFast"),nmo=o(" (DeBERTa-v2 model)"),smo=l(),ss=a("li"),tde=a("strong"),lmo=o("distilbert"),imo=o(" \u2014 "),qI=a("a"),dmo=o("DistilBertTokenizer"),cmo=o(" or "),jI=a("a"),fmo=o("DistilBertTokenizerFast"),mmo=o(" (DistilBERT model)"),gmo=l(),ls=a("li"),ade=a("strong"),hmo=o("dpr"),pmo=o(" \u2014 "),DI=a("a"),_mo=o("DPRQuestionEncoderTokenizer"),umo=o(" or "),GI=a("a"),bmo=o("DPRQuestionEncoderTokenizerFast"),vmo=o(" (DPR model)"),Fmo=l(),is=a("li"),nde=a("strong"),Tmo=o("electra"),Mmo=o(" \u2014 "),OI=a("a"),Emo=o("ElectraTokenizer"),Cmo=o(" or "),VI=a("a"),wmo=o("ElectraTokenizerFast"),Amo=o(" (ELECTRA model)"),Lmo=l(),Eh=a("li"),sde=a("strong"),ymo=o("flaubert"),xmo=o(" \u2014 "),XI=a("a"),$mo=o("FlaubertTokenizer"),kmo=o(" (FlauBERT model)"),Smo=l(),ds=a("li"),lde=a("strong"),Rmo=o("fnet"),Pmo=o(" \u2014 "),zI=a("a"),Bmo=o("FNetTokenizer"),Imo=o(" or "),WI=a("a"),Nmo=o("FNetTokenizerFast"),qmo=o(" (FNet model)"),jmo=l(),Ch=a("li"),ide=a("strong"),Dmo=o("fsmt"),Gmo=o(" \u2014 "),QI=a("a"),Omo=o("FSMTTokenizer"),Vmo=o(" (FairSeq Machine-Translation model)"),Xmo=l(),cs=a("li"),dde=a("strong"),zmo=o("funnel"),Wmo=o(" \u2014 "),HI=a("a"),Qmo=o("FunnelTokenizer"),Hmo=o(" or "),UI=a("a"),Umo=o("FunnelTokenizerFast"),Jmo=o(" (Funnel Transformer model)"),Ymo=l(),fs=a("li"),cde=a("strong"),Kmo=o("gpt2"),Zmo=o(" \u2014 "),JI=a("a"),ego=o("GPT2Tokenizer"),ogo=o(" or "),YI=a("a"),rgo=o("GPT2TokenizerFast"),tgo=o(" (OpenAI GPT-2 model)"),ago=l(),ms=a("li"),fde=a("strong"),ngo=o("gpt_neo"),sgo=o(" \u2014 "),KI=a("a"),lgo=o("GPT2Tokenizer"),igo=o(" or "),ZI=a("a"),dgo=o("GPT2TokenizerFast"),cgo=o(" (GPT Neo model)"),fgo=l(),wh=a("li"),mde=a("strong"),mgo=o("gpt_neox"),ggo=o(" \u2014 "),eN=a("a"),hgo=o("GPTNeoXTokenizerFast"),pgo=o(" (GPT NeoX model)"),_go=l(),gs=a("li"),gde=a("strong"),ugo=o("gptj"),bgo=o(" \u2014 "),oN=a("a"),vgo=o("GPT2Tokenizer"),Fgo=o(" or "),rN=a("a"),Tgo=o("GPT2TokenizerFast"),Mgo=o(" (GPT-J model)"),Ego=l(),hs=a("li"),hde=a("strong"),Cgo=o("groupvit"),wgo=o(" \u2014 "),tN=a("a"),Ago=o("CLIPTokenizer"),Lgo=o(" or "),aN=a("a"),ygo=o("CLIPTokenizerFast"),xgo=o(" (GroupViT model)"),$go=l(),ps=a("li"),pde=a("strong"),kgo=o("herbert"),Sgo=o(" \u2014 "),nN=a("a"),Rgo=o("HerbertTokenizer"),Pgo=o(" or "),sN=a("a"),Bgo=o("HerbertTokenizerFast"),Igo=o(" (HerBERT model)"),Ngo=l(),Ah=a("li"),_de=a("strong"),qgo=o("hubert"),jgo=o(" \u2014 "),lN=a("a"),Dgo=o("Wav2Vec2CTCTokenizer"),Ggo=o(" (Hubert model)"),Ogo=l(),_s=a("li"),ude=a("strong"),Vgo=o("ibert"),Xgo=o(" \u2014 "),iN=a("a"),zgo=o("RobertaTokenizer"),Wgo=o(" or "),dN=a("a"),Qgo=o("RobertaTokenizerFast"),Hgo=o(" (I-BERT model)"),Ugo=l(),us=a("li"),bde=a("strong"),Jgo=o("layoutlm"),Ygo=o(" \u2014 "),cN=a("a"),Kgo=o("LayoutLMTokenizer"),Zgo=o(" or "),fN=a("a"),eho=o("LayoutLMTokenizerFast"),oho=o(" (LayoutLM model)"),rho=l(),bs=a("li"),vde=a("strong"),tho=o("layoutlmv2"),aho=o(" \u2014 "),mN=a("a"),nho=o("LayoutLMv2Tokenizer"),sho=o(" or "),gN=a("a"),lho=o("LayoutLMv2TokenizerFast"),iho=o(" (LayoutLMv2 model)"),dho=l(),vs=a("li"),Fde=a("strong"),cho=o("layoutlmv3"),fho=o(" \u2014 "),hN=a("a"),mho=o("LayoutLMv3Tokenizer"),gho=o(" or "),pN=a("a"),hho=o("LayoutLMv3TokenizerFast"),pho=o(" (LayoutLMv3 model)"),_ho=l(),Fs=a("li"),Tde=a("strong"),uho=o("layoutxlm"),bho=o(" \u2014 "),_N=a("a"),vho=o("LayoutXLMTokenizer"),Fho=o(" or "),uN=a("a"),Tho=o("LayoutXLMTokenizerFast"),Mho=o(" (LayoutXLM model)"),Eho=l(),Ts=a("li"),Mde=a("strong"),Cho=o("led"),who=o(" \u2014 "),bN=a("a"),Aho=o("LEDTokenizer"),Lho=o(" or "),vN=a("a"),yho=o("LEDTokenizerFast"),xho=o(" (LED model)"),$ho=l(),Ms=a("li"),Ede=a("strong"),kho=o("longformer"),Sho=o(" \u2014 "),FN=a("a"),Rho=o("LongformerTokenizer"),Pho=o(" or "),TN=a("a"),Bho=o("LongformerTokenizerFast"),Iho=o(" (Longformer model)"),Nho=l(),Es=a("li"),Cde=a("strong"),qho=o("longt5"),jho=o(" \u2014 "),MN=a("a"),Dho=o("T5Tokenizer"),Gho=o(" or "),EN=a("a"),Oho=o("T5TokenizerFast"),Vho=o(" (LongT5 model)"),Xho=l(),Lh=a("li"),wde=a("strong"),zho=o("luke"),Who=o(" \u2014 "),CN=a("a"),Qho=o("LukeTokenizer"),Hho=o(" (LUKE model)"),Uho=l(),Cs=a("li"),Ade=a("strong"),Jho=o("lxmert"),Yho=o(" \u2014 "),wN=a("a"),Kho=o("LxmertTokenizer"),Zho=o(" or "),AN=a("a"),epo=o("LxmertTokenizerFast"),opo=o(" (LXMERT model)"),rpo=l(),yh=a("li"),Lde=a("strong"),tpo=o("m2m_100"),apo=o(" \u2014 "),LN=a("a"),npo=o("M2M100Tokenizer"),spo=o(" (M2M100 model)"),lpo=l(),xh=a("li"),yde=a("strong"),ipo=o("marian"),dpo=o(" \u2014 "),yN=a("a"),cpo=o("MarianTokenizer"),fpo=o(" (Marian model)"),mpo=l(),ws=a("li"),xde=a("strong"),gpo=o("mbart"),hpo=o(" \u2014 "),xN=a("a"),ppo=o("MBartTokenizer"),_po=o(" or "),$N=a("a"),upo=o("MBartTokenizerFast"),bpo=o(" (mBART model)"),vpo=l(),As=a("li"),$de=a("strong"),Fpo=o("mbart50"),Tpo=o(" \u2014 "),kN=a("a"),Mpo=o("MBart50Tokenizer"),Epo=o(" or "),SN=a("a"),Cpo=o("MBart50TokenizerFast"),wpo=o(" (mBART-50 model)"),Apo=l(),Ls=a("li"),kde=a("strong"),Lpo=o("megatron-bert"),ypo=o(" \u2014 "),RN=a("a"),xpo=o("BertTokenizer"),$po=o(" or "),PN=a("a"),kpo=o("BertTokenizerFast"),Spo=o(" (Megatron-BERT model)"),Rpo=l(),$h=a("li"),Sde=a("strong"),Ppo=o("mluke"),Bpo=o(" \u2014 "),BN=a("a"),Ipo=o("MLukeTokenizer"),Npo=o(" (mLUKE model)"),qpo=l(),ys=a("li"),Rde=a("strong"),jpo=o("mobilebert"),Dpo=o(" \u2014 "),IN=a("a"),Gpo=o("MobileBertTokenizer"),Opo=o(" or "),NN=a("a"),Vpo=o("MobileBertTokenizerFast"),Xpo=o(" (MobileBERT model)"),zpo=l(),xs=a("li"),Pde=a("strong"),Wpo=o("mpnet"),Qpo=o(" \u2014 "),qN=a("a"),Hpo=o("MPNetTokenizer"),Upo=o(" or "),jN=a("a"),Jpo=o("MPNetTokenizerFast"),Ypo=o(" (MPNet model)"),Kpo=l(),$s=a("li"),Bde=a("strong"),Zpo=o("mt5"),e_o=o(" \u2014 "),DN=a("a"),o_o=o("MT5Tokenizer"),r_o=o(" or "),GN=a("a"),t_o=o("MT5TokenizerFast"),a_o=o(" (MT5 model)"),n_o=l(),ks=a("li"),Ide=a("strong"),s_o=o("mvp"),l_o=o(" \u2014 "),ON=a("a"),i_o=o("MvpTokenizer"),d_o=o(" or "),VN=a("a"),c_o=o("MvpTokenizerFast"),f_o=o(" (MVP model)"),m_o=l(),Ss=a("li"),Nde=a("strong"),g_o=o("nezha"),h_o=o(" \u2014 "),XN=a("a"),p_o=o("BertTokenizer"),__o=o(" or "),zN=a("a"),u_o=o("BertTokenizerFast"),b_o=o(" (Nezha model)"),v_o=l(),Rs=a("li"),qde=a("strong"),F_o=o("nllb"),T_o=o(" \u2014 "),WN=a("a"),M_o=o("NllbTokenizer"),E_o=o(" or "),QN=a("a"),C_o=o("NllbTokenizerFast"),w_o=o(" (NLLB model)"),A_o=l(),Ps=a("li"),jde=a("strong"),L_o=o("nystromformer"),y_o=o(" \u2014 "),HN=a("a"),x_o=o("AlbertTokenizer"),$_o=o(" or "),UN=a("a"),k_o=o("AlbertTokenizerFast"),S_o=o(" (Nystr\xF6mformer model)"),R_o=l(),Bs=a("li"),Dde=a("strong"),P_o=o("openai-gpt"),B_o=o(" \u2014 "),JN=a("a"),I_o=o("OpenAIGPTTokenizer"),N_o=o(" or "),YN=a("a"),q_o=o("OpenAIGPTTokenizerFast"),j_o=o(" (OpenAI GPT model)"),D_o=l(),kh=a("li"),Gde=a("strong"),G_o=o("opt"),O_o=o(" \u2014 "),KN=a("a"),V_o=o("GPT2Tokenizer"),X_o=o(" (OPT model)"),z_o=l(),Is=a("li"),Ode=a("strong"),W_o=o("owlvit"),Q_o=o(" \u2014 "),ZN=a("a"),H_o=o("CLIPTokenizer"),U_o=o(" or "),eq=a("a"),J_o=o("CLIPTokenizerFast"),Y_o=o(" (OWL-ViT model)"),K_o=l(),Ns=a("li"),Vde=a("strong"),Z_o=o("pegasus"),euo=o(" \u2014 "),oq=a("a"),ouo=o("PegasusTokenizer"),ruo=o(" or "),rq=a("a"),tuo=o("PegasusTokenizerFast"),auo=o(" (Pegasus model)"),nuo=l(),Sh=a("li"),Xde=a("strong"),suo=o("perceiver"),luo=o(" \u2014 "),tq=a("a"),iuo=o("PerceiverTokenizer"),duo=o(" (Perceiver model)"),cuo=l(),Rh=a("li"),zde=a("strong"),fuo=o("phobert"),muo=o(" \u2014 "),aq=a("a"),guo=o("PhobertTokenizer"),huo=o(" (PhoBERT model)"),puo=l(),Ph=a("li"),Wde=a("strong"),_uo=o("plbart"),uuo=o(" \u2014 "),nq=a("a"),buo=o("PLBartTokenizer"),vuo=o(" (PLBart model)"),Fuo=l(),Bh=a("li"),Qde=a("strong"),Tuo=o("prophetnet"),Muo=o(" \u2014 "),sq=a("a"),Euo=o("ProphetNetTokenizer"),Cuo=o(" (ProphetNet model)"),wuo=l(),qs=a("li"),Hde=a("strong"),Auo=o("qdqbert"),Luo=o(" \u2014 "),lq=a("a"),yuo=o("BertTokenizer"),xuo=o(" or "),iq=a("a"),$uo=o("BertTokenizerFast"),kuo=o(" (QDQBert model)"),Suo=l(),Ih=a("li"),Ude=a("strong"),Ruo=o("rag"),Puo=o(" \u2014 "),dq=a("a"),Buo=o("RagTokenizer"),Iuo=o(" (RAG model)"),Nuo=l(),js=a("li"),Jde=a("strong"),quo=o("realm"),juo=o(" \u2014 "),cq=a("a"),Duo=o("RealmTokenizer"),Guo=o(" or "),fq=a("a"),Ouo=o("RealmTokenizerFast"),Vuo=o(" (REALM model)"),Xuo=l(),Ds=a("li"),Yde=a("strong"),zuo=o("reformer"),Wuo=o(" \u2014 "),mq=a("a"),Quo=o("ReformerTokenizer"),Huo=o(" or "),gq=a("a"),Uuo=o("ReformerTokenizerFast"),Juo=o(" (Reformer model)"),Yuo=l(),Gs=a("li"),Kde=a("strong"),Kuo=o("rembert"),Zuo=o(" \u2014 "),hq=a("a"),e2o=o("RemBertTokenizer"),o2o=o(" or "),pq=a("a"),r2o=o("RemBertTokenizerFast"),t2o=o(" (RemBERT model)"),a2o=l(),Os=a("li"),Zde=a("strong"),n2o=o("retribert"),s2o=o(" \u2014 "),_q=a("a"),l2o=o("RetriBertTokenizer"),i2o=o(" or "),uq=a("a"),d2o=o("RetriBertTokenizerFast"),c2o=o(" (RetriBERT model)"),f2o=l(),Vs=a("li"),ece=a("strong"),m2o=o("roberta"),g2o=o(" \u2014 "),bq=a("a"),h2o=o("RobertaTokenizer"),p2o=o(" or "),vq=a("a"),_2o=o("RobertaTokenizerFast"),u2o=o(" (RoBERTa model)"),b2o=l(),Xs=a("li"),oce=a("strong"),v2o=o("roformer"),F2o=o(" \u2014 "),Fq=a("a"),T2o=o("RoFormerTokenizer"),M2o=o(" or "),Tq=a("a"),E2o=o("RoFormerTokenizerFast"),C2o=o(" (RoFormer model)"),w2o=l(),Nh=a("li"),rce=a("strong"),A2o=o("speech_to_text"),L2o=o(" \u2014 "),Mq=a("a"),y2o=o("Speech2TextTokenizer"),x2o=o(" (Speech2Text model)"),$2o=l(),qh=a("li"),tce=a("strong"),k2o=o("speech_to_text_2"),S2o=o(" \u2014 "),Eq=a("a"),R2o=o("Speech2Text2Tokenizer"),P2o=o(" (Speech2Text2 model)"),B2o=l(),zs=a("li"),ace=a("strong"),I2o=o("splinter"),N2o=o(" \u2014 "),Cq=a("a"),q2o=o("SplinterTokenizer"),j2o=o(" or "),wq=a("a"),D2o=o("SplinterTokenizerFast"),G2o=o(" (Splinter model)"),O2o=l(),Ws=a("li"),nce=a("strong"),V2o=o("squeezebert"),X2o=o(" \u2014 "),Aq=a("a"),z2o=o("SqueezeBertTokenizer"),W2o=o(" or "),Lq=a("a"),Q2o=o("SqueezeBertTokenizerFast"),H2o=o(" (SqueezeBERT model)"),U2o=l(),Qs=a("li"),sce=a("strong"),J2o=o("t5"),Y2o=o(" \u2014 "),yq=a("a"),K2o=o("T5Tokenizer"),Z2o=o(" or "),xq=a("a"),e1o=o("T5TokenizerFast"),o1o=o(" (T5 model)"),r1o=l(),jh=a("li"),lce=a("strong"),t1o=o("tapas"),a1o=o(" \u2014 "),$q=a("a"),n1o=o("TapasTokenizer"),s1o=o(" (TAPAS model)"),l1o=l(),Dh=a("li"),ice=a("strong"),i1o=o("tapex"),d1o=o(" \u2014 "),kq=a("a"),c1o=o("TapexTokenizer"),f1o=o(" (TAPEX model)"),m1o=l(),Gh=a("li"),dce=a("strong"),g1o=o("transfo-xl"),h1o=o(" \u2014 "),Sq=a("a"),p1o=o("TransfoXLTokenizer"),_1o=o(" (Transformer-XL model)"),u1o=l(),Hs=a("li"),cce=a("strong"),b1o=o("vilt"),v1o=o(" \u2014 "),Rq=a("a"),F1o=o("BertTokenizer"),T1o=o(" or "),Pq=a("a"),M1o=o("BertTokenizerFast"),E1o=o(" (ViLT model)"),C1o=l(),Us=a("li"),fce=a("strong"),w1o=o("visual_bert"),A1o=o(" \u2014 "),Bq=a("a"),L1o=o("BertTokenizer"),y1o=o(" or "),Iq=a("a"),x1o=o("BertTokenizerFast"),$1o=o(" (VisualBERT model)"),k1o=l(),Oh=a("li"),mce=a("strong"),S1o=o("wav2vec2"),R1o=o(" \u2014 "),Nq=a("a"),P1o=o("Wav2Vec2CTCTokenizer"),B1o=o(" (Wav2Vec2 model)"),I1o=l(),Vh=a("li"),gce=a("strong"),N1o=o("wav2vec2-conformer"),q1o=o(" \u2014 "),qq=a("a"),j1o=o("Wav2Vec2CTCTokenizer"),D1o=o(" (Wav2Vec2-Conformer model)"),G1o=l(),Xh=a("li"),hce=a("strong"),O1o=o("wav2vec2_phoneme"),V1o=o(" \u2014 "),jq=a("a"),X1o=o("Wav2Vec2PhonemeCTCTokenizer"),z1o=o(" (Wav2Vec2Phoneme model)"),W1o=l(),Js=a("li"),pce=a("strong"),Q1o=o("xglm"),H1o=o(" \u2014 "),Dq=a("a"),U1o=o("XGLMTokenizer"),J1o=o(" or "),Gq=a("a"),Y1o=o("XGLMTokenizerFast"),K1o=o(" (XGLM model)"),Z1o=l(),zh=a("li"),_ce=a("strong"),ebo=o("xlm"),obo=o(" \u2014 "),Oq=a("a"),rbo=o("XLMTokenizer"),tbo=o(" (XLM model)"),abo=l(),Wh=a("li"),uce=a("strong"),nbo=o("xlm-prophetnet"),sbo=o(" \u2014 "),Vq=a("a"),lbo=o("XLMProphetNetTokenizer"),ibo=o(" (XLM-ProphetNet model)"),dbo=l(),Ys=a("li"),bce=a("strong"),cbo=o("xlm-roberta"),fbo=o(" \u2014 "),Xq=a("a"),mbo=o("XLMRobertaTokenizer"),gbo=o(" or "),zq=a("a"),hbo=o("XLMRobertaTokenizerFast"),pbo=o(" (XLM-RoBERTa model)"),_bo=l(),Ks=a("li"),vce=a("strong"),ubo=o("xlm-roberta-xl"),bbo=o(" \u2014 "),Wq=a("a"),vbo=o("RobertaTokenizer"),Fbo=o(" or "),Qq=a("a"),Tbo=o("RobertaTokenizerFast"),Mbo=o(" (XLM-RoBERTa-XL model)"),Ebo=l(),Zs=a("li"),Fce=a("strong"),Cbo=o("xlnet"),wbo=o(" \u2014 "),Hq=a("a"),Abo=o("XLNetTokenizer"),Lbo=o(" or "),Uq=a("a"),ybo=o("XLNetTokenizerFast"),xbo=o(" (XLNet model)"),$bo=l(),el=a("li"),Tce=a("strong"),kbo=o("yoso"),Sbo=o(" \u2014 "),Jq=a("a"),Rbo=o("AlbertTokenizer"),Pbo=o(" or "),Yq=a("a"),Bbo=o("AlbertTokenizerFast"),Ibo=o(" (YOSO model)"),Nbo=l(),F(Qh.$$.fragment),qbo=l(),Hh=a("div"),F(ly.$$.fragment),jbo=l(),Mce=a("p"),Dbo=o("Register a new tokenizer in this mapping."),KWe=l(),Qi=a("h2"),Uh=a("a"),Ece=a("span"),F(iy.$$.fragment),Gbo=l(),Cce=a("span"),Obo=o("AutoFeatureExtractor"),ZWe=l(),$o=a("div"),F(dy.$$.fragment),Vbo=l(),cy=a("p"),Xbo=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),Kq=a("a"),zbo=o("AutoFeatureExtractor.from_pretrained()"),Wbo=o(" class method."),Qbo=l(),fy=a("p"),Hbo=o("This class cannot be instantiated directly using "),wce=a("code"),Ubo=o("__init__()"),Jbo=o(" (throws an error)."),Ybo=l(),Ue=a("div"),F(my.$$.fragment),Kbo=l(),Ace=a("p"),Zbo=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),evo=l(),ja=a("p"),ovo=o("The feature extractor class to instantiate is selected based on the "),Lce=a("code"),rvo=o("model_type"),tvo=o(` property of the config object
(either passed as an argument or loaded from `),yce=a("code"),avo=o("pretrained_model_name_or_path"),nvo=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),xce=a("code"),svo=o("pretrained_model_name_or_path"),lvo=o(":"),ivo=l(),H=a("ul"),Jh=a("li"),$ce=a("strong"),dvo=o("beit"),cvo=o(" \u2014 "),Zq=a("a"),fvo=o("BeitFeatureExtractor"),mvo=o(" (BEiT model)"),gvo=l(),Yh=a("li"),kce=a("strong"),hvo=o("clip"),pvo=o(" \u2014 "),ej=a("a"),_vo=o("CLIPFeatureExtractor"),uvo=o(" (CLIP model)"),bvo=l(),Kh=a("li"),Sce=a("strong"),vvo=o("convnext"),Fvo=o(" \u2014 "),oj=a("a"),Tvo=o("ConvNextFeatureExtractor"),Mvo=o(" (ConvNeXT model)"),Evo=l(),Zh=a("li"),Rce=a("strong"),Cvo=o("cvt"),wvo=o(" \u2014 "),rj=a("a"),Avo=o("ConvNextFeatureExtractor"),Lvo=o(" (CvT model)"),yvo=l(),ep=a("li"),Pce=a("strong"),xvo=o("data2vec-audio"),$vo=o(" \u2014 "),tj=a("a"),kvo=o("Wav2Vec2FeatureExtractor"),Svo=o(" (Data2VecAudio model)"),Rvo=l(),op=a("li"),Bce=a("strong"),Pvo=o("data2vec-vision"),Bvo=o(" \u2014 "),aj=a("a"),Ivo=o("BeitFeatureExtractor"),Nvo=o(" (Data2VecVision model)"),qvo=l(),rp=a("li"),Ice=a("strong"),jvo=o("deit"),Dvo=o(" \u2014 "),nj=a("a"),Gvo=o("DeiTFeatureExtractor"),Ovo=o(" (DeiT model)"),Vvo=l(),tp=a("li"),Nce=a("strong"),Xvo=o("detr"),zvo=o(" \u2014 "),sj=a("a"),Wvo=o("DetrFeatureExtractor"),Qvo=o(" (DETR model)"),Hvo=l(),ap=a("li"),qce=a("strong"),Uvo=o("dpt"),Jvo=o(" \u2014 "),lj=a("a"),Yvo=o("DPTFeatureExtractor"),Kvo=o(" (DPT model)"),Zvo=l(),np=a("li"),jce=a("strong"),e0o=o("flava"),o0o=o(" \u2014 "),ij=a("a"),r0o=o("FlavaFeatureExtractor"),t0o=o(" (FLAVA model)"),a0o=l(),sp=a("li"),Dce=a("strong"),n0o=o("glpn"),s0o=o(" \u2014 "),dj=a("a"),l0o=o("GLPNFeatureExtractor"),i0o=o(" (GLPN model)"),d0o=l(),lp=a("li"),Gce=a("strong"),c0o=o("groupvit"),f0o=o(" \u2014 "),cj=a("a"),m0o=o("CLIPFeatureExtractor"),g0o=o(" (GroupViT model)"),h0o=l(),ip=a("li"),Oce=a("strong"),p0o=o("hubert"),_0o=o(" \u2014 "),fj=a("a"),u0o=o("Wav2Vec2FeatureExtractor"),b0o=o(" (Hubert model)"),v0o=l(),dp=a("li"),Vce=a("strong"),F0o=o("imagegpt"),T0o=o(" \u2014 "),mj=a("a"),M0o=o("ImageGPTFeatureExtractor"),E0o=o(" (ImageGPT model)"),C0o=l(),cp=a("li"),Xce=a("strong"),w0o=o("layoutlmv2"),A0o=o(" \u2014 "),gj=a("a"),L0o=o("LayoutLMv2FeatureExtractor"),y0o=o(" (LayoutLMv2 model)"),x0o=l(),fp=a("li"),zce=a("strong"),$0o=o("layoutlmv3"),k0o=o(" \u2014 "),hj=a("a"),S0o=o("LayoutLMv3FeatureExtractor"),R0o=o(" (LayoutLMv3 model)"),P0o=l(),mp=a("li"),Wce=a("strong"),B0o=o("levit"),I0o=o(" \u2014 "),pj=a("a"),N0o=o("LevitFeatureExtractor"),q0o=o(" (LeViT model)"),j0o=l(),gp=a("li"),Qce=a("strong"),D0o=o("maskformer"),G0o=o(" \u2014 "),_j=a("a"),O0o=o("MaskFormerFeatureExtractor"),V0o=o(" (MaskFormer model)"),X0o=l(),hp=a("li"),Hce=a("strong"),z0o=o("mctct"),W0o=o(" \u2014 "),uj=a("a"),Q0o=o("MCTCTFeatureExtractor"),H0o=o(" (M-CTC-T model)"),U0o=l(),pp=a("li"),Uce=a("strong"),J0o=o("mobilevit"),Y0o=o(" \u2014 "),bj=a("a"),K0o=o("MobileViTFeatureExtractor"),Z0o=o(" (MobileViT model)"),eFo=l(),_p=a("li"),Jce=a("strong"),oFo=o("owlvit"),rFo=o(" \u2014 "),vj=a("a"),tFo=o("OwlViTFeatureExtractor"),aFo=o(" (OWL-ViT model)"),nFo=l(),up=a("li"),Yce=a("strong"),sFo=o("perceiver"),lFo=o(" \u2014 "),Fj=a("a"),iFo=o("PerceiverFeatureExtractor"),dFo=o(" (Perceiver model)"),cFo=l(),bp=a("li"),Kce=a("strong"),fFo=o("poolformer"),mFo=o(" \u2014 "),Tj=a("a"),gFo=o("PoolFormerFeatureExtractor"),hFo=o(" (PoolFormer model)"),pFo=l(),vp=a("li"),Zce=a("strong"),_Fo=o("regnet"),uFo=o(" \u2014 "),Mj=a("a"),bFo=o("ConvNextFeatureExtractor"),vFo=o(" (RegNet model)"),FFo=l(),Fp=a("li"),efe=a("strong"),TFo=o("resnet"),MFo=o(" \u2014 "),Ej=a("a"),EFo=o("ConvNextFeatureExtractor"),CFo=o(" (ResNet model)"),wFo=l(),Tp=a("li"),ofe=a("strong"),AFo=o("segformer"),LFo=o(" \u2014 "),Cj=a("a"),yFo=o("SegformerFeatureExtractor"),xFo=o(" (SegFormer model)"),$Fo=l(),Mp=a("li"),rfe=a("strong"),kFo=o("speech_to_text"),SFo=o(" \u2014 "),wj=a("a"),RFo=o("Speech2TextFeatureExtractor"),PFo=o(" (Speech2Text model)"),BFo=l(),Ep=a("li"),tfe=a("strong"),IFo=o("swin"),NFo=o(" \u2014 "),Aj=a("a"),qFo=o("ViTFeatureExtractor"),jFo=o(" (Swin Transformer model)"),DFo=l(),Cp=a("li"),afe=a("strong"),GFo=o("swinv2"),OFo=o(" \u2014 "),Lj=a("a"),VFo=o("ViTFeatureExtractor"),XFo=o(" (Swin Transformer V2 model)"),zFo=l(),wp=a("li"),nfe=a("strong"),WFo=o("van"),QFo=o(" \u2014 "),yj=a("a"),HFo=o("ConvNextFeatureExtractor"),UFo=o(" (VAN model)"),JFo=l(),Ap=a("li"),sfe=a("strong"),YFo=o("videomae"),KFo=o(" \u2014 "),xj=a("a"),ZFo=o("ViTFeatureExtractor"),eTo=o(" (VideoMAE model)"),oTo=l(),Lp=a("li"),lfe=a("strong"),rTo=o("vilt"),tTo=o(" \u2014 "),$j=a("a"),aTo=o("ViltFeatureExtractor"),nTo=o(" (ViLT model)"),sTo=l(),yp=a("li"),ife=a("strong"),lTo=o("vit"),iTo=o(" \u2014 "),kj=a("a"),dTo=o("ViTFeatureExtractor"),cTo=o(" (ViT model)"),fTo=l(),xp=a("li"),dfe=a("strong"),mTo=o("vit_mae"),gTo=o(" \u2014 "),Sj=a("a"),hTo=o("ViTFeatureExtractor"),pTo=o(" (ViTMAE model)"),_To=l(),$p=a("li"),cfe=a("strong"),uTo=o("wav2vec2"),bTo=o(" \u2014 "),Rj=a("a"),vTo=o("Wav2Vec2FeatureExtractor"),FTo=o(" (Wav2Vec2 model)"),TTo=l(),kp=a("li"),ffe=a("strong"),MTo=o("wav2vec2-conformer"),ETo=o(" \u2014 "),Pj=a("a"),CTo=o("Wav2Vec2FeatureExtractor"),wTo=o(" (Wav2Vec2-Conformer model)"),ATo=l(),Sp=a("li"),mfe=a("strong"),LTo=o("yolos"),yTo=o(" \u2014 "),Bj=a("a"),xTo=o("YolosFeatureExtractor"),$To=o(" (YOLOS model)"),kTo=l(),F(Rp.$$.fragment),STo=l(),F(Pp.$$.fragment),RTo=l(),Bp=a("div"),F(gy.$$.fragment),PTo=l(),gfe=a("p"),BTo=o("Register a new feature extractor for this class."),eQe=l(),Hi=a("h2"),Ip=a("a"),hfe=a("span"),F(hy.$$.fragment),ITo=l(),pfe=a("span"),NTo=o("AutoProcessor"),oQe=l(),ko=a("div"),F(py.$$.fragment),qTo=l(),_y=a("p"),jTo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Ij=a("a"),DTo=o("AutoProcessor.from_pretrained()"),GTo=o(" class method."),OTo=l(),uy=a("p"),VTo=o("This class cannot be instantiated directly using "),_fe=a("code"),XTo=o("__init__()"),zTo=o(" (throws an error)."),WTo=l(),Je=a("div"),F(by.$$.fragment),QTo=l(),ufe=a("p"),HTo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),UTo=l(),Ui=a("p"),JTo=o("The processor class to instantiate is selected based on the "),bfe=a("code"),YTo=o("model_type"),KTo=o(` property of the config object (either
passed as an argument or loaded from `),vfe=a("code"),ZTo=o("pretrained_model_name_or_path"),e8o=o(" if possible):"),o8o=l(),fe=a("ul"),Np=a("li"),Ffe=a("strong"),r8o=o("clip"),t8o=o(" \u2014 "),Nj=a("a"),a8o=o("CLIPProcessor"),n8o=o(" (CLIP model)"),s8o=l(),qp=a("li"),Tfe=a("strong"),l8o=o("flava"),i8o=o(" \u2014 "),qj=a("a"),d8o=o("FlavaProcessor"),c8o=o(" (FLAVA model)"),f8o=l(),jp=a("li"),Mfe=a("strong"),m8o=o("groupvit"),g8o=o(" \u2014 "),jj=a("a"),h8o=o("CLIPProcessor"),p8o=o(" (GroupViT model)"),_8o=l(),Dp=a("li"),Efe=a("strong"),u8o=o("layoutlmv2"),b8o=o(" \u2014 "),Dj=a("a"),v8o=o("LayoutLMv2Processor"),F8o=o(" (LayoutLMv2 model)"),T8o=l(),Gp=a("li"),Cfe=a("strong"),M8o=o("layoutlmv3"),E8o=o(" \u2014 "),Gj=a("a"),C8o=o("LayoutLMv3Processor"),w8o=o(" (LayoutLMv3 model)"),A8o=l(),Op=a("li"),wfe=a("strong"),L8o=o("layoutxlm"),y8o=o(" \u2014 "),Oj=a("a"),x8o=o("LayoutXLMProcessor"),$8o=o(" (LayoutXLM model)"),k8o=l(),Vp=a("li"),Afe=a("strong"),S8o=o("owlvit"),R8o=o(" \u2014 "),Vj=a("a"),P8o=o("OwlViTProcessor"),B8o=o(" (OWL-ViT model)"),I8o=l(),Xp=a("li"),Lfe=a("strong"),N8o=o("sew"),q8o=o(" \u2014 "),Xj=a("a"),j8o=o("Wav2Vec2Processor"),D8o=o(" (SEW model)"),G8o=l(),zp=a("li"),yfe=a("strong"),O8o=o("sew-d"),V8o=o(" \u2014 "),zj=a("a"),X8o=o("Wav2Vec2Processor"),z8o=o(" (SEW-D model)"),W8o=l(),Wp=a("li"),xfe=a("strong"),Q8o=o("speech_to_text"),H8o=o(" \u2014 "),Wj=a("a"),U8o=o("Speech2TextProcessor"),J8o=o(" (Speech2Text model)"),Y8o=l(),Qp=a("li"),$fe=a("strong"),K8o=o("speech_to_text_2"),Z8o=o(" \u2014 "),Qj=a("a"),eMo=o("Speech2Text2Processor"),oMo=o(" (Speech2Text2 model)"),rMo=l(),Hp=a("li"),kfe=a("strong"),tMo=o("trocr"),aMo=o(" \u2014 "),Hj=a("a"),nMo=o("TrOCRProcessor"),sMo=o(" (TrOCR model)"),lMo=l(),Up=a("li"),Sfe=a("strong"),iMo=o("unispeech"),dMo=o(" \u2014 "),Uj=a("a"),cMo=o("Wav2Vec2Processor"),fMo=o(" (UniSpeech model)"),mMo=l(),Jp=a("li"),Rfe=a("strong"),gMo=o("unispeech-sat"),hMo=o(" \u2014 "),Jj=a("a"),pMo=o("Wav2Vec2Processor"),_Mo=o(" (UniSpeechSat model)"),uMo=l(),Yp=a("li"),Pfe=a("strong"),bMo=o("vilt"),vMo=o(" \u2014 "),Yj=a("a"),FMo=o("ViltProcessor"),TMo=o(" (ViLT model)"),MMo=l(),Kp=a("li"),Bfe=a("strong"),EMo=o("vision-text-dual-encoder"),CMo=o(" \u2014 "),Kj=a("a"),wMo=o("VisionTextDualEncoderProcessor"),AMo=o(" (VisionTextDualEncoder model)"),LMo=l(),Zp=a("li"),Ife=a("strong"),yMo=o("wav2vec2"),xMo=o(" \u2014 "),Zj=a("a"),$Mo=o("Wav2Vec2Processor"),kMo=o(" (Wav2Vec2 model)"),SMo=l(),e_=a("li"),Nfe=a("strong"),RMo=o("wav2vec2-conformer"),PMo=o(" \u2014 "),eD=a("a"),BMo=o("Wav2Vec2Processor"),IMo=o(" (Wav2Vec2-Conformer model)"),NMo=l(),o_=a("li"),qfe=a("strong"),qMo=o("wavlm"),jMo=o(" \u2014 "),oD=a("a"),DMo=o("Wav2Vec2Processor"),GMo=o(" (WavLM model)"),OMo=l(),F(r_.$$.fragment),VMo=l(),F(t_.$$.fragment),XMo=l(),a_=a("div"),F(vy.$$.fragment),zMo=l(),jfe=a("p"),WMo=o("Register a new processor for this class."),rQe=l(),Ji=a("h2"),n_=a("a"),Dfe=a("span"),F(Fy.$$.fragment),QMo=l(),Gfe=a("span"),HMo=o("AutoModel"),tQe=l(),So=a("div"),F(Ty.$$.fragment),UMo=l(),Yi=a("p"),JMo=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rD=a("a"),YMo=o("from_pretrained()"),KMo=o(" class method or the "),tD=a("a"),ZMo=o("from_config()"),eEo=o(` class
method.`),oEo=l(),My=a("p"),rEo=o("This class cannot be instantiated directly using "),Ofe=a("code"),tEo=o("__init__()"),aEo=o(" (throws an error)."),nEo=l(),ct=a("div"),F(Ey.$$.fragment),sEo=l(),Vfe=a("p"),lEo=o("Instantiates one of the base model classes of the library from a configuration."),iEo=l(),Ki=a("p"),dEo=o(`Note:
Loading a model from its configuration file does `),Xfe=a("strong"),cEo=o("not"),fEo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aD=a("a"),mEo=o("from_pretrained()"),gEo=o(" to load the model weights."),hEo=l(),F(s_.$$.fragment),pEo=l(),Ye=a("div"),F(Cy.$$.fragment),_Eo=l(),zfe=a("p"),uEo=o("Instantiate one of the base model classes of the library from a pretrained model."),bEo=l(),Da=a("p"),vEo=o("The model class to instantiate is selected based on the "),Wfe=a("code"),FEo=o("model_type"),TEo=o(` property of the config object (either
passed as an argument or loaded from `),Qfe=a("code"),MEo=o("pretrained_model_name_or_path"),EEo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hfe=a("code"),CEo=o("pretrained_model_name_or_path"),wEo=o(":"),AEo=l(),y=a("ul"),l_=a("li"),Ufe=a("strong"),LEo=o("albert"),yEo=o(" \u2014 "),nD=a("a"),xEo=o("AlbertModel"),$Eo=o(" (ALBERT model)"),kEo=l(),i_=a("li"),Jfe=a("strong"),SEo=o("bart"),REo=o(" \u2014 "),sD=a("a"),PEo=o("BartModel"),BEo=o(" (BART model)"),IEo=l(),d_=a("li"),Yfe=a("strong"),NEo=o("beit"),qEo=o(" \u2014 "),lD=a("a"),jEo=o("BeitModel"),DEo=o(" (BEiT model)"),GEo=l(),c_=a("li"),Kfe=a("strong"),OEo=o("bert"),VEo=o(" \u2014 "),iD=a("a"),XEo=o("BertModel"),zEo=o(" (BERT model)"),WEo=l(),f_=a("li"),Zfe=a("strong"),QEo=o("bert-generation"),HEo=o(" \u2014 "),dD=a("a"),UEo=o("BertGenerationEncoder"),JEo=o(" (Bert Generation model)"),YEo=l(),m_=a("li"),eme=a("strong"),KEo=o("big_bird"),ZEo=o(" \u2014 "),cD=a("a"),e4o=o("BigBirdModel"),o4o=o(" (BigBird model)"),r4o=l(),g_=a("li"),ome=a("strong"),t4o=o("bigbird_pegasus"),a4o=o(" \u2014 "),fD=a("a"),n4o=o("BigBirdPegasusModel"),s4o=o(" (BigBird-Pegasus model)"),l4o=l(),h_=a("li"),rme=a("strong"),i4o=o("blenderbot"),d4o=o(" \u2014 "),mD=a("a"),c4o=o("BlenderbotModel"),f4o=o(" (Blenderbot model)"),m4o=l(),p_=a("li"),tme=a("strong"),g4o=o("blenderbot-small"),h4o=o(" \u2014 "),gD=a("a"),p4o=o("BlenderbotSmallModel"),_4o=o(" (BlenderbotSmall model)"),u4o=l(),__=a("li"),ame=a("strong"),b4o=o("bloom"),v4o=o(" \u2014 "),hD=a("a"),F4o=o("BloomModel"),T4o=o(" (BLOOM model)"),M4o=l(),u_=a("li"),nme=a("strong"),E4o=o("camembert"),C4o=o(" \u2014 "),pD=a("a"),w4o=o("CamembertModel"),A4o=o(" (CamemBERT model)"),L4o=l(),b_=a("li"),sme=a("strong"),y4o=o("canine"),x4o=o(" \u2014 "),_D=a("a"),$4o=o("CanineModel"),k4o=o(" (CANINE model)"),S4o=l(),v_=a("li"),lme=a("strong"),R4o=o("clip"),P4o=o(" \u2014 "),uD=a("a"),B4o=o("CLIPModel"),I4o=o(" (CLIP model)"),N4o=l(),F_=a("li"),ime=a("strong"),q4o=o("codegen"),j4o=o(" \u2014 "),bD=a("a"),D4o=o("CodeGenModel"),G4o=o(" (CodeGen model)"),O4o=l(),T_=a("li"),dme=a("strong"),V4o=o("convbert"),X4o=o(" \u2014 "),vD=a("a"),z4o=o("ConvBertModel"),W4o=o(" (ConvBERT model)"),Q4o=l(),M_=a("li"),cme=a("strong"),H4o=o("convnext"),U4o=o(" \u2014 "),FD=a("a"),J4o=o("ConvNextModel"),Y4o=o(" (ConvNeXT model)"),K4o=l(),E_=a("li"),fme=a("strong"),Z4o=o("ctrl"),eCo=o(" \u2014 "),TD=a("a"),oCo=o("CTRLModel"),rCo=o(" (CTRL model)"),tCo=l(),C_=a("li"),mme=a("strong"),aCo=o("cvt"),nCo=o(" \u2014 "),MD=a("a"),sCo=o("CvtModel"),lCo=o(" (CvT model)"),iCo=l(),w_=a("li"),gme=a("strong"),dCo=o("data2vec-audio"),cCo=o(" \u2014 "),ED=a("a"),fCo=o("Data2VecAudioModel"),mCo=o(" (Data2VecAudio model)"),gCo=l(),A_=a("li"),hme=a("strong"),hCo=o("data2vec-text"),pCo=o(" \u2014 "),CD=a("a"),_Co=o("Data2VecTextModel"),uCo=o(" (Data2VecText model)"),bCo=l(),L_=a("li"),pme=a("strong"),vCo=o("data2vec-vision"),FCo=o(" \u2014 "),wD=a("a"),TCo=o("Data2VecVisionModel"),MCo=o(" (Data2VecVision model)"),ECo=l(),y_=a("li"),_me=a("strong"),CCo=o("deberta"),wCo=o(" \u2014 "),AD=a("a"),ACo=o("DebertaModel"),LCo=o(" (DeBERTa model)"),yCo=l(),x_=a("li"),ume=a("strong"),xCo=o("deberta-v2"),$Co=o(" \u2014 "),LD=a("a"),kCo=o("DebertaV2Model"),SCo=o(" (DeBERTa-v2 model)"),RCo=l(),$_=a("li"),bme=a("strong"),PCo=o("decision_transformer"),BCo=o(" \u2014 "),yD=a("a"),ICo=o("DecisionTransformerModel"),NCo=o(" (Decision Transformer model)"),qCo=l(),k_=a("li"),vme=a("strong"),jCo=o("deit"),DCo=o(" \u2014 "),xD=a("a"),GCo=o("DeiTModel"),OCo=o(" (DeiT model)"),VCo=l(),S_=a("li"),Fme=a("strong"),XCo=o("detr"),zCo=o(" \u2014 "),$D=a("a"),WCo=o("DetrModel"),QCo=o(" (DETR model)"),HCo=l(),R_=a("li"),Tme=a("strong"),UCo=o("distilbert"),JCo=o(" \u2014 "),kD=a("a"),YCo=o("DistilBertModel"),KCo=o(" (DistilBERT model)"),ZCo=l(),P_=a("li"),Mme=a("strong"),e5o=o("dpr"),o5o=o(" \u2014 "),SD=a("a"),r5o=o("DPRQuestionEncoder"),t5o=o(" (DPR model)"),a5o=l(),B_=a("li"),Eme=a("strong"),n5o=o("dpt"),s5o=o(" \u2014 "),RD=a("a"),l5o=o("DPTModel"),i5o=o(" (DPT model)"),d5o=l(),I_=a("li"),Cme=a("strong"),c5o=o("electra"),f5o=o(" \u2014 "),PD=a("a"),m5o=o("ElectraModel"),g5o=o(" (ELECTRA model)"),h5o=l(),N_=a("li"),wme=a("strong"),p5o=o("flaubert"),_5o=o(" \u2014 "),BD=a("a"),u5o=o("FlaubertModel"),b5o=o(" (FlauBERT model)"),v5o=l(),q_=a("li"),Ame=a("strong"),F5o=o("flava"),T5o=o(" \u2014 "),ID=a("a"),M5o=o("FlavaModel"),E5o=o(" (FLAVA model)"),C5o=l(),j_=a("li"),Lme=a("strong"),w5o=o("fnet"),A5o=o(" \u2014 "),ND=a("a"),L5o=o("FNetModel"),y5o=o(" (FNet model)"),x5o=l(),D_=a("li"),yme=a("strong"),$5o=o("fsmt"),k5o=o(" \u2014 "),qD=a("a"),S5o=o("FSMTModel"),R5o=o(" (FairSeq Machine-Translation model)"),P5o=l(),ol=a("li"),xme=a("strong"),B5o=o("funnel"),I5o=o(" \u2014 "),jD=a("a"),N5o=o("FunnelModel"),q5o=o(" or "),DD=a("a"),j5o=o("FunnelBaseModel"),D5o=o(" (Funnel Transformer model)"),G5o=l(),G_=a("li"),$me=a("strong"),O5o=o("glpn"),V5o=o(" \u2014 "),GD=a("a"),X5o=o("GLPNModel"),z5o=o(" (GLPN model)"),W5o=l(),O_=a("li"),kme=a("strong"),Q5o=o("gpt2"),H5o=o(" \u2014 "),OD=a("a"),U5o=o("GPT2Model"),J5o=o(" (OpenAI GPT-2 model)"),Y5o=l(),V_=a("li"),Sme=a("strong"),K5o=o("gpt_neo"),Z5o=o(" \u2014 "),VD=a("a"),e3o=o("GPTNeoModel"),o3o=o(" (GPT Neo model)"),r3o=l(),X_=a("li"),Rme=a("strong"),t3o=o("gpt_neox"),a3o=o(" \u2014 "),XD=a("a"),n3o=o("GPTNeoXModel"),s3o=o(" (GPT NeoX model)"),l3o=l(),z_=a("li"),Pme=a("strong"),i3o=o("gptj"),d3o=o(" \u2014 "),zD=a("a"),c3o=o("GPTJModel"),f3o=o(" (GPT-J model)"),m3o=l(),W_=a("li"),Bme=a("strong"),g3o=o("groupvit"),h3o=o(" \u2014 "),WD=a("a"),p3o=o("GroupViTModel"),_3o=o(" (GroupViT model)"),u3o=l(),Q_=a("li"),Ime=a("strong"),b3o=o("hubert"),v3o=o(" \u2014 "),QD=a("a"),F3o=o("HubertModel"),T3o=o(" (Hubert model)"),M3o=l(),H_=a("li"),Nme=a("strong"),E3o=o("ibert"),C3o=o(" \u2014 "),HD=a("a"),w3o=o("IBertModel"),A3o=o(" (I-BERT model)"),L3o=l(),U_=a("li"),qme=a("strong"),y3o=o("imagegpt"),x3o=o(" \u2014 "),UD=a("a"),$3o=o("ImageGPTModel"),k3o=o(" (ImageGPT model)"),S3o=l(),J_=a("li"),jme=a("strong"),R3o=o("layoutlm"),P3o=o(" \u2014 "),JD=a("a"),B3o=o("LayoutLMModel"),I3o=o(" (LayoutLM model)"),N3o=l(),Y_=a("li"),Dme=a("strong"),q3o=o("layoutlmv2"),j3o=o(" \u2014 "),YD=a("a"),D3o=o("LayoutLMv2Model"),G3o=o(" (LayoutLMv2 model)"),O3o=l(),K_=a("li"),Gme=a("strong"),V3o=o("layoutlmv3"),X3o=o(" \u2014 "),KD=a("a"),z3o=o("LayoutLMv3Model"),W3o=o(" (LayoutLMv3 model)"),Q3o=l(),Z_=a("li"),Ome=a("strong"),H3o=o("led"),U3o=o(" \u2014 "),ZD=a("a"),J3o=o("LEDModel"),Y3o=o(" (LED model)"),K3o=l(),eu=a("li"),Vme=a("strong"),Z3o=o("levit"),ewo=o(" \u2014 "),eG=a("a"),owo=o("LevitModel"),rwo=o(" (LeViT model)"),two=l(),ou=a("li"),Xme=a("strong"),awo=o("longformer"),nwo=o(" \u2014 "),oG=a("a"),swo=o("LongformerModel"),lwo=o(" (Longformer model)"),iwo=l(),ru=a("li"),zme=a("strong"),dwo=o("longt5"),cwo=o(" \u2014 "),rG=a("a"),fwo=o("LongT5Model"),mwo=o(" (LongT5 model)"),gwo=l(),tu=a("li"),Wme=a("strong"),hwo=o("luke"),pwo=o(" \u2014 "),tG=a("a"),_wo=o("LukeModel"),uwo=o(" (LUKE model)"),bwo=l(),au=a("li"),Qme=a("strong"),vwo=o("lxmert"),Fwo=o(" \u2014 "),aG=a("a"),Two=o("LxmertModel"),Mwo=o(" (LXMERT model)"),Ewo=l(),nu=a("li"),Hme=a("strong"),Cwo=o("m2m_100"),wwo=o(" \u2014 "),nG=a("a"),Awo=o("M2M100Model"),Lwo=o(" (M2M100 model)"),ywo=l(),su=a("li"),Ume=a("strong"),xwo=o("marian"),$wo=o(" \u2014 "),sG=a("a"),kwo=o("MarianModel"),Swo=o(" (Marian model)"),Rwo=l(),lu=a("li"),Jme=a("strong"),Pwo=o("maskformer"),Bwo=o(" \u2014 "),lG=a("a"),Iwo=o("MaskFormerModel"),Nwo=o(" (MaskFormer model)"),qwo=l(),iu=a("li"),Yme=a("strong"),jwo=o("mbart"),Dwo=o(" \u2014 "),iG=a("a"),Gwo=o("MBartModel"),Owo=o(" (mBART model)"),Vwo=l(),du=a("li"),Kme=a("strong"),Xwo=o("mctct"),zwo=o(" \u2014 "),dG=a("a"),Wwo=o("MCTCTModel"),Qwo=o(" (M-CTC-T model)"),Hwo=l(),cu=a("li"),Zme=a("strong"),Uwo=o("megatron-bert"),Jwo=o(" \u2014 "),cG=a("a"),Ywo=o("MegatronBertModel"),Kwo=o(" (Megatron-BERT model)"),Zwo=l(),fu=a("li"),ege=a("strong"),e6o=o("mobilebert"),o6o=o(" \u2014 "),fG=a("a"),r6o=o("MobileBertModel"),t6o=o(" (MobileBERT model)"),a6o=l(),mu=a("li"),oge=a("strong"),n6o=o("mobilevit"),s6o=o(" \u2014 "),mG=a("a"),l6o=o("MobileViTModel"),i6o=o(" (MobileViT model)"),d6o=l(),gu=a("li"),rge=a("strong"),c6o=o("mpnet"),f6o=o(" \u2014 "),gG=a("a"),m6o=o("MPNetModel"),g6o=o(" (MPNet model)"),h6o=l(),hu=a("li"),tge=a("strong"),p6o=o("mt5"),_6o=o(" \u2014 "),hG=a("a"),u6o=o("MT5Model"),b6o=o(" (MT5 model)"),v6o=l(),pu=a("li"),age=a("strong"),F6o=o("mvp"),T6o=o(" \u2014 "),pG=a("a"),M6o=o("MvpModel"),E6o=o(" (MVP model)"),C6o=l(),_u=a("li"),nge=a("strong"),w6o=o("nezha"),A6o=o(" \u2014 "),_G=a("a"),L6o=o("NezhaModel"),y6o=o(" (Nezha model)"),x6o=l(),uu=a("li"),sge=a("strong"),$6o=o("nllb"),k6o=o(" \u2014 "),uG=a("a"),S6o=o("M2M100Model"),R6o=o(" (NLLB model)"),P6o=l(),bu=a("li"),lge=a("strong"),B6o=o("nystromformer"),I6o=o(" \u2014 "),bG=a("a"),N6o=o("NystromformerModel"),q6o=o(" (Nystr\xF6mformer model)"),j6o=l(),vu=a("li"),ige=a("strong"),D6o=o("openai-gpt"),G6o=o(" \u2014 "),vG=a("a"),O6o=o("OpenAIGPTModel"),V6o=o(" (OpenAI GPT model)"),X6o=l(),Fu=a("li"),dge=a("strong"),z6o=o("opt"),W6o=o(" \u2014 "),FG=a("a"),Q6o=o("OPTModel"),H6o=o(" (OPT model)"),U6o=l(),Tu=a("li"),cge=a("strong"),J6o=o("owlvit"),Y6o=o(" \u2014 "),TG=a("a"),K6o=o("OwlViTModel"),Z6o=o(" (OWL-ViT model)"),eAo=l(),Mu=a("li"),fge=a("strong"),oAo=o("pegasus"),rAo=o(" \u2014 "),MG=a("a"),tAo=o("PegasusModel"),aAo=o(" (Pegasus model)"),nAo=l(),Eu=a("li"),mge=a("strong"),sAo=o("perceiver"),lAo=o(" \u2014 "),EG=a("a"),iAo=o("PerceiverModel"),dAo=o(" (Perceiver model)"),cAo=l(),Cu=a("li"),gge=a("strong"),fAo=o("plbart"),mAo=o(" \u2014 "),CG=a("a"),gAo=o("PLBartModel"),hAo=o(" (PLBart model)"),pAo=l(),wu=a("li"),hge=a("strong"),_Ao=o("poolformer"),uAo=o(" \u2014 "),wG=a("a"),bAo=o("PoolFormerModel"),vAo=o(" (PoolFormer model)"),FAo=l(),Au=a("li"),pge=a("strong"),TAo=o("prophetnet"),MAo=o(" \u2014 "),AG=a("a"),EAo=o("ProphetNetModel"),CAo=o(" (ProphetNet model)"),wAo=l(),Lu=a("li"),_ge=a("strong"),AAo=o("qdqbert"),LAo=o(" \u2014 "),LG=a("a"),yAo=o("QDQBertModel"),xAo=o(" (QDQBert model)"),$Ao=l(),yu=a("li"),uge=a("strong"),kAo=o("reformer"),SAo=o(" \u2014 "),yG=a("a"),RAo=o("ReformerModel"),PAo=o(" (Reformer model)"),BAo=l(),xu=a("li"),bge=a("strong"),IAo=o("regnet"),NAo=o(" \u2014 "),xG=a("a"),qAo=o("RegNetModel"),jAo=o(" (RegNet model)"),DAo=l(),$u=a("li"),vge=a("strong"),GAo=o("rembert"),OAo=o(" \u2014 "),$G=a("a"),VAo=o("RemBertModel"),XAo=o(" (RemBERT model)"),zAo=l(),ku=a("li"),Fge=a("strong"),WAo=o("resnet"),QAo=o(" \u2014 "),kG=a("a"),HAo=o("ResNetModel"),UAo=o(" (ResNet model)"),JAo=l(),Su=a("li"),Tge=a("strong"),YAo=o("retribert"),KAo=o(" \u2014 "),SG=a("a"),ZAo=o("RetriBertModel"),e7o=o(" (RetriBERT model)"),o7o=l(),Ru=a("li"),Mge=a("strong"),r7o=o("roberta"),t7o=o(" \u2014 "),RG=a("a"),a7o=o("RobertaModel"),n7o=o(" (RoBERTa model)"),s7o=l(),Pu=a("li"),Ege=a("strong"),l7o=o("roformer"),i7o=o(" \u2014 "),PG=a("a"),d7o=o("RoFormerModel"),c7o=o(" (RoFormer model)"),f7o=l(),Bu=a("li"),Cge=a("strong"),m7o=o("segformer"),g7o=o(" \u2014 "),BG=a("a"),h7o=o("SegformerModel"),p7o=o(" (SegFormer model)"),_7o=l(),Iu=a("li"),wge=a("strong"),u7o=o("sew"),b7o=o(" \u2014 "),IG=a("a"),v7o=o("SEWModel"),F7o=o(" (SEW model)"),T7o=l(),Nu=a("li"),Age=a("strong"),M7o=o("sew-d"),E7o=o(" \u2014 "),NG=a("a"),C7o=o("SEWDModel"),w7o=o(" (SEW-D model)"),A7o=l(),qu=a("li"),Lge=a("strong"),L7o=o("speech_to_text"),y7o=o(" \u2014 "),qG=a("a"),x7o=o("Speech2TextModel"),$7o=o(" (Speech2Text model)"),k7o=l(),ju=a("li"),yge=a("strong"),S7o=o("splinter"),R7o=o(" \u2014 "),jG=a("a"),P7o=o("SplinterModel"),B7o=o(" (Splinter model)"),I7o=l(),Du=a("li"),xge=a("strong"),N7o=o("squeezebert"),q7o=o(" \u2014 "),DG=a("a"),j7o=o("SqueezeBertModel"),D7o=o(" (SqueezeBERT model)"),G7o=l(),Gu=a("li"),$ge=a("strong"),O7o=o("swin"),V7o=o(" \u2014 "),GG=a("a"),X7o=o("SwinModel"),z7o=o(" (Swin Transformer model)"),W7o=l(),Ou=a("li"),kge=a("strong"),Q7o=o("swinv2"),H7o=o(" \u2014 "),OG=a("a"),U7o=o("Swinv2Model"),J7o=o(" (Swin Transformer V2 model)"),Y7o=l(),Vu=a("li"),Sge=a("strong"),K7o=o("t5"),Z7o=o(" \u2014 "),VG=a("a"),eLo=o("T5Model"),oLo=o(" (T5 model)"),rLo=l(),Xu=a("li"),Rge=a("strong"),tLo=o("tapas"),aLo=o(" \u2014 "),XG=a("a"),nLo=o("TapasModel"),sLo=o(" (TAPAS model)"),lLo=l(),zu=a("li"),Pge=a("strong"),iLo=o("trajectory_transformer"),dLo=o(" \u2014 "),zG=a("a"),cLo=o("TrajectoryTransformerModel"),fLo=o(" (Trajectory Transformer model)"),mLo=l(),Wu=a("li"),Bge=a("strong"),gLo=o("transfo-xl"),hLo=o(" \u2014 "),WG=a("a"),pLo=o("TransfoXLModel"),_Lo=o(" (Transformer-XL model)"),uLo=l(),Qu=a("li"),Ige=a("strong"),bLo=o("unispeech"),vLo=o(" \u2014 "),QG=a("a"),FLo=o("UniSpeechModel"),TLo=o(" (UniSpeech model)"),MLo=l(),Hu=a("li"),Nge=a("strong"),ELo=o("unispeech-sat"),CLo=o(" \u2014 "),HG=a("a"),wLo=o("UniSpeechSatModel"),ALo=o(" (UniSpeechSat model)"),LLo=l(),Uu=a("li"),qge=a("strong"),yLo=o("van"),xLo=o(" \u2014 "),UG=a("a"),$Lo=o("VanModel"),kLo=o(" (VAN model)"),SLo=l(),Ju=a("li"),jge=a("strong"),RLo=o("videomae"),PLo=o(" \u2014 "),JG=a("a"),BLo=o("VideoMAEModel"),ILo=o(" (VideoMAE model)"),NLo=l(),Yu=a("li"),Dge=a("strong"),qLo=o("vilt"),jLo=o(" \u2014 "),YG=a("a"),DLo=o("ViltModel"),GLo=o(" (ViLT model)"),OLo=l(),Ku=a("li"),Gge=a("strong"),VLo=o("vision-text-dual-encoder"),XLo=o(" \u2014 "),KG=a("a"),zLo=o("VisionTextDualEncoderModel"),WLo=o(" (VisionTextDualEncoder model)"),QLo=l(),Zu=a("li"),Oge=a("strong"),HLo=o("visual_bert"),ULo=o(" \u2014 "),ZG=a("a"),JLo=o("VisualBertModel"),YLo=o(" (VisualBERT model)"),KLo=l(),e2=a("li"),Vge=a("strong"),ZLo=o("vit"),eyo=o(" \u2014 "),eO=a("a"),oyo=o("ViTModel"),ryo=o(" (ViT model)"),tyo=l(),o2=a("li"),Xge=a("strong"),ayo=o("vit_mae"),nyo=o(" \u2014 "),oO=a("a"),syo=o("ViTMAEModel"),lyo=o(" (ViTMAE model)"),iyo=l(),r2=a("li"),zge=a("strong"),dyo=o("wav2vec2"),cyo=o(" \u2014 "),rO=a("a"),fyo=o("Wav2Vec2Model"),myo=o(" (Wav2Vec2 model)"),gyo=l(),t2=a("li"),Wge=a("strong"),hyo=o("wav2vec2-conformer"),pyo=o(" \u2014 "),tO=a("a"),_yo=o("Wav2Vec2ConformerModel"),uyo=o(" (Wav2Vec2-Conformer model)"),byo=l(),a2=a("li"),Qge=a("strong"),vyo=o("wavlm"),Fyo=o(" \u2014 "),aO=a("a"),Tyo=o("WavLMModel"),Myo=o(" (WavLM model)"),Eyo=l(),n2=a("li"),Hge=a("strong"),Cyo=o("xglm"),wyo=o(" \u2014 "),nO=a("a"),Ayo=o("XGLMModel"),Lyo=o(" (XGLM model)"),yyo=l(),s2=a("li"),Uge=a("strong"),xyo=o("xlm"),$yo=o(" \u2014 "),sO=a("a"),kyo=o("XLMModel"),Syo=o(" (XLM model)"),Ryo=l(),l2=a("li"),Jge=a("strong"),Pyo=o("xlm-prophetnet"),Byo=o(" \u2014 "),lO=a("a"),Iyo=o("XLMProphetNetModel"),Nyo=o(" (XLM-ProphetNet model)"),qyo=l(),i2=a("li"),Yge=a("strong"),jyo=o("xlm-roberta"),Dyo=o(" \u2014 "),iO=a("a"),Gyo=o("XLMRobertaModel"),Oyo=o(" (XLM-RoBERTa model)"),Vyo=l(),d2=a("li"),Kge=a("strong"),Xyo=o("xlm-roberta-xl"),zyo=o(" \u2014 "),dO=a("a"),Wyo=o("XLMRobertaXLModel"),Qyo=o(" (XLM-RoBERTa-XL model)"),Hyo=l(),c2=a("li"),Zge=a("strong"),Uyo=o("xlnet"),Jyo=o(" \u2014 "),cO=a("a"),Yyo=o("XLNetModel"),Kyo=o(" (XLNet model)"),Zyo=l(),f2=a("li"),ehe=a("strong"),e9o=o("yolos"),o9o=o(" \u2014 "),fO=a("a"),r9o=o("YolosModel"),t9o=o(" (YOLOS model)"),a9o=l(),m2=a("li"),ohe=a("strong"),n9o=o("yoso"),s9o=o(" \u2014 "),mO=a("a"),l9o=o("YosoModel"),i9o=o(" (YOSO model)"),d9o=l(),g2=a("p"),c9o=o("The model is set in evaluation mode by default using "),rhe=a("code"),f9o=o("model.eval()"),m9o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),the=a("code"),g9o=o("model.train()"),h9o=l(),F(h2.$$.fragment),aQe=l(),Zi=a("h2"),p2=a("a"),ahe=a("span"),F(wy.$$.fragment),p9o=l(),nhe=a("span"),_9o=o("AutoModelForPreTraining"),nQe=l(),Ro=a("div"),F(Ay.$$.fragment),u9o=l(),ed=a("p"),b9o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gO=a("a"),v9o=o("from_pretrained()"),F9o=o(" class method or the "),hO=a("a"),T9o=o("from_config()"),M9o=o(` class
method.`),E9o=l(),Ly=a("p"),C9o=o("This class cannot be instantiated directly using "),she=a("code"),w9o=o("__init__()"),A9o=o(" (throws an error)."),L9o=l(),ft=a("div"),F(yy.$$.fragment),y9o=l(),lhe=a("p"),x9o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$9o=l(),od=a("p"),k9o=o(`Note:
Loading a model from its configuration file does `),ihe=a("strong"),S9o=o("not"),R9o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pO=a("a"),P9o=o("from_pretrained()"),B9o=o(" to load the model weights."),I9o=l(),F(_2.$$.fragment),N9o=l(),Ke=a("div"),F(xy.$$.fragment),q9o=l(),dhe=a("p"),j9o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),D9o=l(),Ga=a("p"),G9o=o("The model class to instantiate is selected based on the "),che=a("code"),O9o=o("model_type"),V9o=o(` property of the config object (either
passed as an argument or loaded from `),fhe=a("code"),X9o=o("pretrained_model_name_or_path"),z9o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mhe=a("code"),W9o=o("pretrained_model_name_or_path"),Q9o=o(":"),H9o=l(),G=a("ul"),u2=a("li"),ghe=a("strong"),U9o=o("albert"),J9o=o(" \u2014 "),_O=a("a"),Y9o=o("AlbertForPreTraining"),K9o=o(" (ALBERT model)"),Z9o=l(),b2=a("li"),hhe=a("strong"),exo=o("bart"),oxo=o(" \u2014 "),uO=a("a"),rxo=o("BartForConditionalGeneration"),txo=o(" (BART model)"),axo=l(),v2=a("li"),phe=a("strong"),nxo=o("bert"),sxo=o(" \u2014 "),bO=a("a"),lxo=o("BertForPreTraining"),ixo=o(" (BERT model)"),dxo=l(),F2=a("li"),_he=a("strong"),cxo=o("big_bird"),fxo=o(" \u2014 "),vO=a("a"),mxo=o("BigBirdForPreTraining"),gxo=o(" (BigBird model)"),hxo=l(),T2=a("li"),uhe=a("strong"),pxo=o("bloom"),_xo=o(" \u2014 "),FO=a("a"),uxo=o("BloomForCausalLM"),bxo=o(" (BLOOM model)"),vxo=l(),M2=a("li"),bhe=a("strong"),Fxo=o("camembert"),Txo=o(" \u2014 "),TO=a("a"),Mxo=o("CamembertForMaskedLM"),Exo=o(" (CamemBERT model)"),Cxo=l(),E2=a("li"),vhe=a("strong"),wxo=o("ctrl"),Axo=o(" \u2014 "),MO=a("a"),Lxo=o("CTRLLMHeadModel"),yxo=o(" (CTRL model)"),xxo=l(),C2=a("li"),Fhe=a("strong"),$xo=o("data2vec-text"),kxo=o(" \u2014 "),EO=a("a"),Sxo=o("Data2VecTextForMaskedLM"),Rxo=o(" (Data2VecText model)"),Pxo=l(),w2=a("li"),The=a("strong"),Bxo=o("deberta"),Ixo=o(" \u2014 "),CO=a("a"),Nxo=o("DebertaForMaskedLM"),qxo=o(" (DeBERTa model)"),jxo=l(),A2=a("li"),Mhe=a("strong"),Dxo=o("deberta-v2"),Gxo=o(" \u2014 "),wO=a("a"),Oxo=o("DebertaV2ForMaskedLM"),Vxo=o(" (DeBERTa-v2 model)"),Xxo=l(),L2=a("li"),Ehe=a("strong"),zxo=o("distilbert"),Wxo=o(" \u2014 "),AO=a("a"),Qxo=o("DistilBertForMaskedLM"),Hxo=o(" (DistilBERT model)"),Uxo=l(),y2=a("li"),Che=a("strong"),Jxo=o("electra"),Yxo=o(" \u2014 "),LO=a("a"),Kxo=o("ElectraForPreTraining"),Zxo=o(" (ELECTRA model)"),e$o=l(),x2=a("li"),whe=a("strong"),o$o=o("flaubert"),r$o=o(" \u2014 "),yO=a("a"),t$o=o("FlaubertWithLMHeadModel"),a$o=o(" (FlauBERT model)"),n$o=l(),$2=a("li"),Ahe=a("strong"),s$o=o("flava"),l$o=o(" \u2014 "),xO=a("a"),i$o=o("FlavaForPreTraining"),d$o=o(" (FLAVA model)"),c$o=l(),k2=a("li"),Lhe=a("strong"),f$o=o("fnet"),m$o=o(" \u2014 "),$O=a("a"),g$o=o("FNetForPreTraining"),h$o=o(" (FNet model)"),p$o=l(),S2=a("li"),yhe=a("strong"),_$o=o("fsmt"),u$o=o(" \u2014 "),kO=a("a"),b$o=o("FSMTForConditionalGeneration"),v$o=o(" (FairSeq Machine-Translation model)"),F$o=l(),R2=a("li"),xhe=a("strong"),T$o=o("funnel"),M$o=o(" \u2014 "),SO=a("a"),E$o=o("FunnelForPreTraining"),C$o=o(" (Funnel Transformer model)"),w$o=l(),P2=a("li"),$he=a("strong"),A$o=o("gpt2"),L$o=o(" \u2014 "),RO=a("a"),y$o=o("GPT2LMHeadModel"),x$o=o(" (OpenAI GPT-2 model)"),$$o=l(),B2=a("li"),khe=a("strong"),k$o=o("ibert"),S$o=o(" \u2014 "),PO=a("a"),R$o=o("IBertForMaskedLM"),P$o=o(" (I-BERT model)"),B$o=l(),I2=a("li"),She=a("strong"),I$o=o("layoutlm"),N$o=o(" \u2014 "),BO=a("a"),q$o=o("LayoutLMForMaskedLM"),j$o=o(" (LayoutLM model)"),D$o=l(),N2=a("li"),Rhe=a("strong"),G$o=o("longformer"),O$o=o(" \u2014 "),IO=a("a"),V$o=o("LongformerForMaskedLM"),X$o=o(" (Longformer model)"),z$o=l(),q2=a("li"),Phe=a("strong"),W$o=o("luke"),Q$o=o(" \u2014 "),NO=a("a"),H$o=o("LukeForMaskedLM"),U$o=o(" (LUKE model)"),J$o=l(),j2=a("li"),Bhe=a("strong"),Y$o=o("lxmert"),K$o=o(" \u2014 "),qO=a("a"),Z$o=o("LxmertForPreTraining"),eko=o(" (LXMERT model)"),oko=l(),D2=a("li"),Ihe=a("strong"),rko=o("megatron-bert"),tko=o(" \u2014 "),jO=a("a"),ako=o("MegatronBertForPreTraining"),nko=o(" (Megatron-BERT model)"),sko=l(),G2=a("li"),Nhe=a("strong"),lko=o("mobilebert"),iko=o(" \u2014 "),DO=a("a"),dko=o("MobileBertForPreTraining"),cko=o(" (MobileBERT model)"),fko=l(),O2=a("li"),qhe=a("strong"),mko=o("mpnet"),gko=o(" \u2014 "),GO=a("a"),hko=o("MPNetForMaskedLM"),pko=o(" (MPNet model)"),_ko=l(),V2=a("li"),jhe=a("strong"),uko=o("mvp"),bko=o(" \u2014 "),OO=a("a"),vko=o("MvpForConditionalGeneration"),Fko=o(" (MVP model)"),Tko=l(),X2=a("li"),Dhe=a("strong"),Mko=o("nezha"),Eko=o(" \u2014 "),VO=a("a"),Cko=o("NezhaForPreTraining"),wko=o(" (Nezha model)"),Ako=l(),z2=a("li"),Ghe=a("strong"),Lko=o("openai-gpt"),yko=o(" \u2014 "),XO=a("a"),xko=o("OpenAIGPTLMHeadModel"),$ko=o(" (OpenAI GPT model)"),kko=l(),W2=a("li"),Ohe=a("strong"),Sko=o("retribert"),Rko=o(" \u2014 "),zO=a("a"),Pko=o("RetriBertModel"),Bko=o(" (RetriBERT model)"),Iko=l(),Q2=a("li"),Vhe=a("strong"),Nko=o("roberta"),qko=o(" \u2014 "),WO=a("a"),jko=o("RobertaForMaskedLM"),Dko=o(" (RoBERTa model)"),Gko=l(),H2=a("li"),Xhe=a("strong"),Oko=o("splinter"),Vko=o(" \u2014 "),QO=a("a"),Xko=o("SplinterForPreTraining"),zko=o(" (Splinter model)"),Wko=l(),U2=a("li"),zhe=a("strong"),Qko=o("squeezebert"),Hko=o(" \u2014 "),HO=a("a"),Uko=o("SqueezeBertForMaskedLM"),Jko=o(" (SqueezeBERT model)"),Yko=l(),J2=a("li"),Whe=a("strong"),Kko=o("t5"),Zko=o(" \u2014 "),UO=a("a"),eSo=o("T5ForConditionalGeneration"),oSo=o(" (T5 model)"),rSo=l(),Y2=a("li"),Qhe=a("strong"),tSo=o("tapas"),aSo=o(" \u2014 "),JO=a("a"),nSo=o("TapasForMaskedLM"),sSo=o(" (TAPAS model)"),lSo=l(),K2=a("li"),Hhe=a("strong"),iSo=o("transfo-xl"),dSo=o(" \u2014 "),YO=a("a"),cSo=o("TransfoXLLMHeadModel"),fSo=o(" (Transformer-XL model)"),mSo=l(),Z2=a("li"),Uhe=a("strong"),gSo=o("unispeech"),hSo=o(" \u2014 "),KO=a("a"),pSo=o("UniSpeechForPreTraining"),_So=o(" (UniSpeech model)"),uSo=l(),e1=a("li"),Jhe=a("strong"),bSo=o("unispeech-sat"),vSo=o(" \u2014 "),ZO=a("a"),FSo=o("UniSpeechSatForPreTraining"),TSo=o(" (UniSpeechSat model)"),MSo=l(),o1=a("li"),Yhe=a("strong"),ESo=o("videomae"),CSo=o(" \u2014 "),eV=a("a"),wSo=o("VideoMAEForPreTraining"),ASo=o(" (VideoMAE model)"),LSo=l(),r1=a("li"),Khe=a("strong"),ySo=o("visual_bert"),xSo=o(" \u2014 "),oV=a("a"),$So=o("VisualBertForPreTraining"),kSo=o(" (VisualBERT model)"),SSo=l(),t1=a("li"),Zhe=a("strong"),RSo=o("vit_mae"),PSo=o(" \u2014 "),rV=a("a"),BSo=o("ViTMAEForPreTraining"),ISo=o(" (ViTMAE model)"),NSo=l(),a1=a("li"),epe=a("strong"),qSo=o("wav2vec2"),jSo=o(" \u2014 "),tV=a("a"),DSo=o("Wav2Vec2ForPreTraining"),GSo=o(" (Wav2Vec2 model)"),OSo=l(),n1=a("li"),ope=a("strong"),VSo=o("wav2vec2-conformer"),XSo=o(" \u2014 "),aV=a("a"),zSo=o("Wav2Vec2ConformerForPreTraining"),WSo=o(" (Wav2Vec2-Conformer model)"),QSo=l(),s1=a("li"),rpe=a("strong"),HSo=o("xlm"),USo=o(" \u2014 "),nV=a("a"),JSo=o("XLMWithLMHeadModel"),YSo=o(" (XLM model)"),KSo=l(),l1=a("li"),tpe=a("strong"),ZSo=o("xlm-roberta"),eRo=o(" \u2014 "),sV=a("a"),oRo=o("XLMRobertaForMaskedLM"),rRo=o(" (XLM-RoBERTa model)"),tRo=l(),i1=a("li"),ape=a("strong"),aRo=o("xlm-roberta-xl"),nRo=o(" \u2014 "),lV=a("a"),sRo=o("XLMRobertaXLForMaskedLM"),lRo=o(" (XLM-RoBERTa-XL model)"),iRo=l(),d1=a("li"),npe=a("strong"),dRo=o("xlnet"),cRo=o(" \u2014 "),iV=a("a"),fRo=o("XLNetLMHeadModel"),mRo=o(" (XLNet model)"),gRo=l(),c1=a("p"),hRo=o("The model is set in evaluation mode by default using "),spe=a("code"),pRo=o("model.eval()"),_Ro=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lpe=a("code"),uRo=o("model.train()"),bRo=l(),F(f1.$$.fragment),sQe=l(),rd=a("h2"),m1=a("a"),ipe=a("span"),F($y.$$.fragment),vRo=l(),dpe=a("span"),FRo=o("AutoModelForCausalLM"),lQe=l(),Po=a("div"),F(ky.$$.fragment),TRo=l(),td=a("p"),MRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),dV=a("a"),ERo=o("from_pretrained()"),CRo=o(" class method or the "),cV=a("a"),wRo=o("from_config()"),ARo=o(` class
method.`),LRo=l(),Sy=a("p"),yRo=o("This class cannot be instantiated directly using "),cpe=a("code"),xRo=o("__init__()"),$Ro=o(" (throws an error)."),kRo=l(),mt=a("div"),F(Ry.$$.fragment),SRo=l(),fpe=a("p"),RRo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),PRo=l(),ad=a("p"),BRo=o(`Note:
Loading a model from its configuration file does `),mpe=a("strong"),IRo=o("not"),NRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),fV=a("a"),qRo=o("from_pretrained()"),jRo=o(" to load the model weights."),DRo=l(),F(g1.$$.fragment),GRo=l(),Ze=a("div"),F(Py.$$.fragment),ORo=l(),gpe=a("p"),VRo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),XRo=l(),Oa=a("p"),zRo=o("The model class to instantiate is selected based on the "),hpe=a("code"),WRo=o("model_type"),QRo=o(` property of the config object (either
passed as an argument or loaded from `),ppe=a("code"),HRo=o("pretrained_model_name_or_path"),URo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_pe=a("code"),JRo=o("pretrained_model_name_or_path"),YRo=o(":"),KRo=l(),z=a("ul"),h1=a("li"),upe=a("strong"),ZRo=o("bart"),ePo=o(" \u2014 "),mV=a("a"),oPo=o("BartForCausalLM"),rPo=o(" (BART model)"),tPo=l(),p1=a("li"),bpe=a("strong"),aPo=o("bert"),nPo=o(" \u2014 "),gV=a("a"),sPo=o("BertLMHeadModel"),lPo=o(" (BERT model)"),iPo=l(),_1=a("li"),vpe=a("strong"),dPo=o("bert-generation"),cPo=o(" \u2014 "),hV=a("a"),fPo=o("BertGenerationDecoder"),mPo=o(" (Bert Generation model)"),gPo=l(),u1=a("li"),Fpe=a("strong"),hPo=o("big_bird"),pPo=o(" \u2014 "),pV=a("a"),_Po=o("BigBirdForCausalLM"),uPo=o(" (BigBird model)"),bPo=l(),b1=a("li"),Tpe=a("strong"),vPo=o("bigbird_pegasus"),FPo=o(" \u2014 "),_V=a("a"),TPo=o("BigBirdPegasusForCausalLM"),MPo=o(" (BigBird-Pegasus model)"),EPo=l(),v1=a("li"),Mpe=a("strong"),CPo=o("blenderbot"),wPo=o(" \u2014 "),uV=a("a"),APo=o("BlenderbotForCausalLM"),LPo=o(" (Blenderbot model)"),yPo=l(),F1=a("li"),Epe=a("strong"),xPo=o("blenderbot-small"),$Po=o(" \u2014 "),bV=a("a"),kPo=o("BlenderbotSmallForCausalLM"),SPo=o(" (BlenderbotSmall model)"),RPo=l(),T1=a("li"),Cpe=a("strong"),PPo=o("bloom"),BPo=o(" \u2014 "),vV=a("a"),IPo=o("BloomForCausalLM"),NPo=o(" (BLOOM model)"),qPo=l(),M1=a("li"),wpe=a("strong"),jPo=o("camembert"),DPo=o(" \u2014 "),FV=a("a"),GPo=o("CamembertForCausalLM"),OPo=o(" (CamemBERT model)"),VPo=l(),E1=a("li"),Ape=a("strong"),XPo=o("codegen"),zPo=o(" \u2014 "),TV=a("a"),WPo=o("CodeGenForCausalLM"),QPo=o(" (CodeGen model)"),HPo=l(),C1=a("li"),Lpe=a("strong"),UPo=o("ctrl"),JPo=o(" \u2014 "),MV=a("a"),YPo=o("CTRLLMHeadModel"),KPo=o(" (CTRL model)"),ZPo=l(),w1=a("li"),ype=a("strong"),eBo=o("data2vec-text"),oBo=o(" \u2014 "),EV=a("a"),rBo=o("Data2VecTextForCausalLM"),tBo=o(" (Data2VecText model)"),aBo=l(),A1=a("li"),xpe=a("strong"),nBo=o("electra"),sBo=o(" \u2014 "),CV=a("a"),lBo=o("ElectraForCausalLM"),iBo=o(" (ELECTRA model)"),dBo=l(),L1=a("li"),$pe=a("strong"),cBo=o("gpt2"),fBo=o(" \u2014 "),wV=a("a"),mBo=o("GPT2LMHeadModel"),gBo=o(" (OpenAI GPT-2 model)"),hBo=l(),y1=a("li"),kpe=a("strong"),pBo=o("gpt_neo"),_Bo=o(" \u2014 "),AV=a("a"),uBo=o("GPTNeoForCausalLM"),bBo=o(" (GPT Neo model)"),vBo=l(),x1=a("li"),Spe=a("strong"),FBo=o("gpt_neox"),TBo=o(" \u2014 "),LV=a("a"),MBo=o("GPTNeoXForCausalLM"),EBo=o(" (GPT NeoX model)"),CBo=l(),$1=a("li"),Rpe=a("strong"),wBo=o("gptj"),ABo=o(" \u2014 "),yV=a("a"),LBo=o("GPTJForCausalLM"),yBo=o(" (GPT-J model)"),xBo=l(),k1=a("li"),Ppe=a("strong"),$Bo=o("marian"),kBo=o(" \u2014 "),xV=a("a"),SBo=o("MarianForCausalLM"),RBo=o(" (Marian model)"),PBo=l(),S1=a("li"),Bpe=a("strong"),BBo=o("mbart"),IBo=o(" \u2014 "),$V=a("a"),NBo=o("MBartForCausalLM"),qBo=o(" (mBART model)"),jBo=l(),R1=a("li"),Ipe=a("strong"),DBo=o("megatron-bert"),GBo=o(" \u2014 "),kV=a("a"),OBo=o("MegatronBertForCausalLM"),VBo=o(" (Megatron-BERT model)"),XBo=l(),P1=a("li"),Npe=a("strong"),zBo=o("mvp"),WBo=o(" \u2014 "),SV=a("a"),QBo=o("MvpForCausalLM"),HBo=o(" (MVP model)"),UBo=l(),B1=a("li"),qpe=a("strong"),JBo=o("openai-gpt"),YBo=o(" \u2014 "),RV=a("a"),KBo=o("OpenAIGPTLMHeadModel"),ZBo=o(" (OpenAI GPT model)"),eIo=l(),I1=a("li"),jpe=a("strong"),oIo=o("opt"),rIo=o(" \u2014 "),PV=a("a"),tIo=o("OPTForCausalLM"),aIo=o(" (OPT model)"),nIo=l(),N1=a("li"),Dpe=a("strong"),sIo=o("pegasus"),lIo=o(" \u2014 "),BV=a("a"),iIo=o("PegasusForCausalLM"),dIo=o(" (Pegasus model)"),cIo=l(),q1=a("li"),Gpe=a("strong"),fIo=o("plbart"),mIo=o(" \u2014 "),IV=a("a"),gIo=o("PLBartForCausalLM"),hIo=o(" (PLBart model)"),pIo=l(),j1=a("li"),Ope=a("strong"),_Io=o("prophetnet"),uIo=o(" \u2014 "),NV=a("a"),bIo=o("ProphetNetForCausalLM"),vIo=o(" (ProphetNet model)"),FIo=l(),D1=a("li"),Vpe=a("strong"),TIo=o("qdqbert"),MIo=o(" \u2014 "),qV=a("a"),EIo=o("QDQBertLMHeadModel"),CIo=o(" (QDQBert model)"),wIo=l(),G1=a("li"),Xpe=a("strong"),AIo=o("reformer"),LIo=o(" \u2014 "),jV=a("a"),yIo=o("ReformerModelWithLMHead"),xIo=o(" (Reformer model)"),$Io=l(),O1=a("li"),zpe=a("strong"),kIo=o("rembert"),SIo=o(" \u2014 "),DV=a("a"),RIo=o("RemBertForCausalLM"),PIo=o(" (RemBERT model)"),BIo=l(),V1=a("li"),Wpe=a("strong"),IIo=o("roberta"),NIo=o(" \u2014 "),GV=a("a"),qIo=o("RobertaForCausalLM"),jIo=o(" (RoBERTa model)"),DIo=l(),X1=a("li"),Qpe=a("strong"),GIo=o("roformer"),OIo=o(" \u2014 "),OV=a("a"),VIo=o("RoFormerForCausalLM"),XIo=o(" (RoFormer model)"),zIo=l(),z1=a("li"),Hpe=a("strong"),WIo=o("speech_to_text_2"),QIo=o(" \u2014 "),VV=a("a"),HIo=o("Speech2Text2ForCausalLM"),UIo=o(" (Speech2Text2 model)"),JIo=l(),W1=a("li"),Upe=a("strong"),YIo=o("transfo-xl"),KIo=o(" \u2014 "),XV=a("a"),ZIo=o("TransfoXLLMHeadModel"),eNo=o(" (Transformer-XL model)"),oNo=l(),Q1=a("li"),Jpe=a("strong"),rNo=o("trocr"),tNo=o(" \u2014 "),zV=a("a"),aNo=o("TrOCRForCausalLM"),nNo=o(" (TrOCR model)"),sNo=l(),H1=a("li"),Ype=a("strong"),lNo=o("xglm"),iNo=o(" \u2014 "),WV=a("a"),dNo=o("XGLMForCausalLM"),cNo=o(" (XGLM model)"),fNo=l(),U1=a("li"),Kpe=a("strong"),mNo=o("xlm"),gNo=o(" \u2014 "),QV=a("a"),hNo=o("XLMWithLMHeadModel"),pNo=o(" (XLM model)"),_No=l(),J1=a("li"),Zpe=a("strong"),uNo=o("xlm-prophetnet"),bNo=o(" \u2014 "),HV=a("a"),vNo=o("XLMProphetNetForCausalLM"),FNo=o(" (XLM-ProphetNet model)"),TNo=l(),Y1=a("li"),e_e=a("strong"),MNo=o("xlm-roberta"),ENo=o(" \u2014 "),UV=a("a"),CNo=o("XLMRobertaForCausalLM"),wNo=o(" (XLM-RoBERTa model)"),ANo=l(),K1=a("li"),o_e=a("strong"),LNo=o("xlm-roberta-xl"),yNo=o(" \u2014 "),JV=a("a"),xNo=o("XLMRobertaXLForCausalLM"),$No=o(" (XLM-RoBERTa-XL model)"),kNo=l(),Z1=a("li"),r_e=a("strong"),SNo=o("xlnet"),RNo=o(" \u2014 "),YV=a("a"),PNo=o("XLNetLMHeadModel"),BNo=o(" (XLNet model)"),INo=l(),eb=a("p"),NNo=o("The model is set in evaluation mode by default using "),t_e=a("code"),qNo=o("model.eval()"),jNo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a_e=a("code"),DNo=o("model.train()"),GNo=l(),F(ob.$$.fragment),iQe=l(),nd=a("h2"),rb=a("a"),n_e=a("span"),F(By.$$.fragment),ONo=l(),s_e=a("span"),VNo=o("AutoModelForMaskedLM"),dQe=l(),Bo=a("div"),F(Iy.$$.fragment),XNo=l(),sd=a("p"),zNo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),KV=a("a"),WNo=o("from_pretrained()"),QNo=o(" class method or the "),ZV=a("a"),HNo=o("from_config()"),UNo=o(` class
method.`),JNo=l(),Ny=a("p"),YNo=o("This class cannot be instantiated directly using "),l_e=a("code"),KNo=o("__init__()"),ZNo=o(" (throws an error)."),eqo=l(),gt=a("div"),F(qy.$$.fragment),oqo=l(),i_e=a("p"),rqo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),tqo=l(),ld=a("p"),aqo=o(`Note:
Loading a model from its configuration file does `),d_e=a("strong"),nqo=o("not"),sqo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eX=a("a"),lqo=o("from_pretrained()"),iqo=o(" to load the model weights."),dqo=l(),F(tb.$$.fragment),cqo=l(),eo=a("div"),F(jy.$$.fragment),fqo=l(),c_e=a("p"),mqo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),gqo=l(),Va=a("p"),hqo=o("The model class to instantiate is selected based on the "),f_e=a("code"),pqo=o("model_type"),_qo=o(` property of the config object (either
passed as an argument or loaded from `),m_e=a("code"),uqo=o("pretrained_model_name_or_path"),bqo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g_e=a("code"),vqo=o("pretrained_model_name_or_path"),Fqo=o(":"),Tqo=l(),Q=a("ul"),ab=a("li"),h_e=a("strong"),Mqo=o("albert"),Eqo=o(" \u2014 "),oX=a("a"),Cqo=o("AlbertForMaskedLM"),wqo=o(" (ALBERT model)"),Aqo=l(),nb=a("li"),p_e=a("strong"),Lqo=o("bart"),yqo=o(" \u2014 "),rX=a("a"),xqo=o("BartForConditionalGeneration"),$qo=o(" (BART model)"),kqo=l(),sb=a("li"),__e=a("strong"),Sqo=o("bert"),Rqo=o(" \u2014 "),tX=a("a"),Pqo=o("BertForMaskedLM"),Bqo=o(" (BERT model)"),Iqo=l(),lb=a("li"),u_e=a("strong"),Nqo=o("big_bird"),qqo=o(" \u2014 "),aX=a("a"),jqo=o("BigBirdForMaskedLM"),Dqo=o(" (BigBird model)"),Gqo=l(),ib=a("li"),b_e=a("strong"),Oqo=o("camembert"),Vqo=o(" \u2014 "),nX=a("a"),Xqo=o("CamembertForMaskedLM"),zqo=o(" (CamemBERT model)"),Wqo=l(),db=a("li"),v_e=a("strong"),Qqo=o("convbert"),Hqo=o(" \u2014 "),sX=a("a"),Uqo=o("ConvBertForMaskedLM"),Jqo=o(" (ConvBERT model)"),Yqo=l(),cb=a("li"),F_e=a("strong"),Kqo=o("data2vec-text"),Zqo=o(" \u2014 "),lX=a("a"),ejo=o("Data2VecTextForMaskedLM"),ojo=o(" (Data2VecText model)"),rjo=l(),fb=a("li"),T_e=a("strong"),tjo=o("deberta"),ajo=o(" \u2014 "),iX=a("a"),njo=o("DebertaForMaskedLM"),sjo=o(" (DeBERTa model)"),ljo=l(),mb=a("li"),M_e=a("strong"),ijo=o("deberta-v2"),djo=o(" \u2014 "),dX=a("a"),cjo=o("DebertaV2ForMaskedLM"),fjo=o(" (DeBERTa-v2 model)"),mjo=l(),gb=a("li"),E_e=a("strong"),gjo=o("distilbert"),hjo=o(" \u2014 "),cX=a("a"),pjo=o("DistilBertForMaskedLM"),_jo=o(" (DistilBERT model)"),ujo=l(),hb=a("li"),C_e=a("strong"),bjo=o("electra"),vjo=o(" \u2014 "),fX=a("a"),Fjo=o("ElectraForMaskedLM"),Tjo=o(" (ELECTRA model)"),Mjo=l(),pb=a("li"),w_e=a("strong"),Ejo=o("flaubert"),Cjo=o(" \u2014 "),mX=a("a"),wjo=o("FlaubertWithLMHeadModel"),Ajo=o(" (FlauBERT model)"),Ljo=l(),_b=a("li"),A_e=a("strong"),yjo=o("fnet"),xjo=o(" \u2014 "),gX=a("a"),$jo=o("FNetForMaskedLM"),kjo=o(" (FNet model)"),Sjo=l(),ub=a("li"),L_e=a("strong"),Rjo=o("funnel"),Pjo=o(" \u2014 "),hX=a("a"),Bjo=o("FunnelForMaskedLM"),Ijo=o(" (Funnel Transformer model)"),Njo=l(),bb=a("li"),y_e=a("strong"),qjo=o("ibert"),jjo=o(" \u2014 "),pX=a("a"),Djo=o("IBertForMaskedLM"),Gjo=o(" (I-BERT model)"),Ojo=l(),vb=a("li"),x_e=a("strong"),Vjo=o("layoutlm"),Xjo=o(" \u2014 "),_X=a("a"),zjo=o("LayoutLMForMaskedLM"),Wjo=o(" (LayoutLM model)"),Qjo=l(),Fb=a("li"),$_e=a("strong"),Hjo=o("longformer"),Ujo=o(" \u2014 "),uX=a("a"),Jjo=o("LongformerForMaskedLM"),Yjo=o(" (Longformer model)"),Kjo=l(),Tb=a("li"),k_e=a("strong"),Zjo=o("luke"),eDo=o(" \u2014 "),bX=a("a"),oDo=o("LukeForMaskedLM"),rDo=o(" (LUKE model)"),tDo=l(),Mb=a("li"),S_e=a("strong"),aDo=o("mbart"),nDo=o(" \u2014 "),vX=a("a"),sDo=o("MBartForConditionalGeneration"),lDo=o(" (mBART model)"),iDo=l(),Eb=a("li"),R_e=a("strong"),dDo=o("megatron-bert"),cDo=o(" \u2014 "),FX=a("a"),fDo=o("MegatronBertForMaskedLM"),mDo=o(" (Megatron-BERT model)"),gDo=l(),Cb=a("li"),P_e=a("strong"),hDo=o("mobilebert"),pDo=o(" \u2014 "),TX=a("a"),_Do=o("MobileBertForMaskedLM"),uDo=o(" (MobileBERT model)"),bDo=l(),wb=a("li"),B_e=a("strong"),vDo=o("mpnet"),FDo=o(" \u2014 "),MX=a("a"),TDo=o("MPNetForMaskedLM"),MDo=o(" (MPNet model)"),EDo=l(),Ab=a("li"),I_e=a("strong"),CDo=o("mvp"),wDo=o(" \u2014 "),EX=a("a"),ADo=o("MvpForConditionalGeneration"),LDo=o(" (MVP model)"),yDo=l(),Lb=a("li"),N_e=a("strong"),xDo=o("nezha"),$Do=o(" \u2014 "),CX=a("a"),kDo=o("NezhaForMaskedLM"),SDo=o(" (Nezha model)"),RDo=l(),yb=a("li"),q_e=a("strong"),PDo=o("nystromformer"),BDo=o(" \u2014 "),wX=a("a"),IDo=o("NystromformerForMaskedLM"),NDo=o(" (Nystr\xF6mformer model)"),qDo=l(),xb=a("li"),j_e=a("strong"),jDo=o("perceiver"),DDo=o(" \u2014 "),AX=a("a"),GDo=o("PerceiverForMaskedLM"),ODo=o(" (Perceiver model)"),VDo=l(),$b=a("li"),D_e=a("strong"),XDo=o("qdqbert"),zDo=o(" \u2014 "),LX=a("a"),WDo=o("QDQBertForMaskedLM"),QDo=o(" (QDQBert model)"),HDo=l(),kb=a("li"),G_e=a("strong"),UDo=o("reformer"),JDo=o(" \u2014 "),yX=a("a"),YDo=o("ReformerForMaskedLM"),KDo=o(" (Reformer model)"),ZDo=l(),Sb=a("li"),O_e=a("strong"),eGo=o("rembert"),oGo=o(" \u2014 "),xX=a("a"),rGo=o("RemBertForMaskedLM"),tGo=o(" (RemBERT model)"),aGo=l(),Rb=a("li"),V_e=a("strong"),nGo=o("roberta"),sGo=o(" \u2014 "),$X=a("a"),lGo=o("RobertaForMaskedLM"),iGo=o(" (RoBERTa model)"),dGo=l(),Pb=a("li"),X_e=a("strong"),cGo=o("roformer"),fGo=o(" \u2014 "),kX=a("a"),mGo=o("RoFormerForMaskedLM"),gGo=o(" (RoFormer model)"),hGo=l(),Bb=a("li"),z_e=a("strong"),pGo=o("squeezebert"),_Go=o(" \u2014 "),SX=a("a"),uGo=o("SqueezeBertForMaskedLM"),bGo=o(" (SqueezeBERT model)"),vGo=l(),Ib=a("li"),W_e=a("strong"),FGo=o("tapas"),TGo=o(" \u2014 "),RX=a("a"),MGo=o("TapasForMaskedLM"),EGo=o(" (TAPAS model)"),CGo=l(),Nb=a("li"),Q_e=a("strong"),wGo=o("wav2vec2"),AGo=o(" \u2014 "),H_e=a("code"),LGo=o("Wav2Vec2ForMaskedLM"),yGo=o(" (Wav2Vec2 model)"),xGo=l(),qb=a("li"),U_e=a("strong"),$Go=o("xlm"),kGo=o(" \u2014 "),PX=a("a"),SGo=o("XLMWithLMHeadModel"),RGo=o(" (XLM model)"),PGo=l(),jb=a("li"),J_e=a("strong"),BGo=o("xlm-roberta"),IGo=o(" \u2014 "),BX=a("a"),NGo=o("XLMRobertaForMaskedLM"),qGo=o(" (XLM-RoBERTa model)"),jGo=l(),Db=a("li"),Y_e=a("strong"),DGo=o("xlm-roberta-xl"),GGo=o(" \u2014 "),IX=a("a"),OGo=o("XLMRobertaXLForMaskedLM"),VGo=o(" (XLM-RoBERTa-XL model)"),XGo=l(),Gb=a("li"),K_e=a("strong"),zGo=o("yoso"),WGo=o(" \u2014 "),NX=a("a"),QGo=o("YosoForMaskedLM"),HGo=o(" (YOSO model)"),UGo=l(),Ob=a("p"),JGo=o("The model is set in evaluation mode by default using "),Z_e=a("code"),YGo=o("model.eval()"),KGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eue=a("code"),ZGo=o("model.train()"),eOo=l(),F(Vb.$$.fragment),cQe=l(),id=a("h2"),Xb=a("a"),oue=a("span"),F(Dy.$$.fragment),oOo=l(),rue=a("span"),rOo=o("AutoModelForSeq2SeqLM"),fQe=l(),Io=a("div"),F(Gy.$$.fragment),tOo=l(),dd=a("p"),aOo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qX=a("a"),nOo=o("from_pretrained()"),sOo=o(" class method or the "),jX=a("a"),lOo=o("from_config()"),iOo=o(` class
method.`),dOo=l(),Oy=a("p"),cOo=o("This class cannot be instantiated directly using "),tue=a("code"),fOo=o("__init__()"),mOo=o(" (throws an error)."),gOo=l(),ht=a("div"),F(Vy.$$.fragment),hOo=l(),aue=a("p"),pOo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),_Oo=l(),cd=a("p"),uOo=o(`Note:
Loading a model from its configuration file does `),nue=a("strong"),bOo=o("not"),vOo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DX=a("a"),FOo=o("from_pretrained()"),TOo=o(" to load the model weights."),MOo=l(),F(zb.$$.fragment),EOo=l(),oo=a("div"),F(Xy.$$.fragment),COo=l(),sue=a("p"),wOo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),AOo=l(),Xa=a("p"),LOo=o("The model class to instantiate is selected based on the "),lue=a("code"),yOo=o("model_type"),xOo=o(` property of the config object (either
passed as an argument or loaded from `),iue=a("code"),$Oo=o("pretrained_model_name_or_path"),kOo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),due=a("code"),SOo=o("pretrained_model_name_or_path"),ROo=o(":"),POo=l(),me=a("ul"),Wb=a("li"),cue=a("strong"),BOo=o("bart"),IOo=o(" \u2014 "),GX=a("a"),NOo=o("BartForConditionalGeneration"),qOo=o(" (BART model)"),jOo=l(),Qb=a("li"),fue=a("strong"),DOo=o("bigbird_pegasus"),GOo=o(" \u2014 "),OX=a("a"),OOo=o("BigBirdPegasusForConditionalGeneration"),VOo=o(" (BigBird-Pegasus model)"),XOo=l(),Hb=a("li"),mue=a("strong"),zOo=o("blenderbot"),WOo=o(" \u2014 "),VX=a("a"),QOo=o("BlenderbotForConditionalGeneration"),HOo=o(" (Blenderbot model)"),UOo=l(),Ub=a("li"),gue=a("strong"),JOo=o("blenderbot-small"),YOo=o(" \u2014 "),XX=a("a"),KOo=o("BlenderbotSmallForConditionalGeneration"),ZOo=o(" (BlenderbotSmall model)"),eVo=l(),Jb=a("li"),hue=a("strong"),oVo=o("encoder-decoder"),rVo=o(" \u2014 "),zX=a("a"),tVo=o("EncoderDecoderModel"),aVo=o(" (Encoder decoder model)"),nVo=l(),Yb=a("li"),pue=a("strong"),sVo=o("fsmt"),lVo=o(" \u2014 "),WX=a("a"),iVo=o("FSMTForConditionalGeneration"),dVo=o(" (FairSeq Machine-Translation model)"),cVo=l(),Kb=a("li"),_ue=a("strong"),fVo=o("led"),mVo=o(" \u2014 "),QX=a("a"),gVo=o("LEDForConditionalGeneration"),hVo=o(" (LED model)"),pVo=l(),Zb=a("li"),uue=a("strong"),_Vo=o("longt5"),uVo=o(" \u2014 "),HX=a("a"),bVo=o("LongT5ForConditionalGeneration"),vVo=o(" (LongT5 model)"),FVo=l(),ev=a("li"),bue=a("strong"),TVo=o("m2m_100"),MVo=o(" \u2014 "),UX=a("a"),EVo=o("M2M100ForConditionalGeneration"),CVo=o(" (M2M100 model)"),wVo=l(),ov=a("li"),vue=a("strong"),AVo=o("marian"),LVo=o(" \u2014 "),JX=a("a"),yVo=o("MarianMTModel"),xVo=o(" (Marian model)"),$Vo=l(),rv=a("li"),Fue=a("strong"),kVo=o("mbart"),SVo=o(" \u2014 "),YX=a("a"),RVo=o("MBartForConditionalGeneration"),PVo=o(" (mBART model)"),BVo=l(),tv=a("li"),Tue=a("strong"),IVo=o("mt5"),NVo=o(" \u2014 "),KX=a("a"),qVo=o("MT5ForConditionalGeneration"),jVo=o(" (MT5 model)"),DVo=l(),av=a("li"),Mue=a("strong"),GVo=o("mvp"),OVo=o(" \u2014 "),ZX=a("a"),VVo=o("MvpForConditionalGeneration"),XVo=o(" (MVP model)"),zVo=l(),nv=a("li"),Eue=a("strong"),WVo=o("nllb"),QVo=o(" \u2014 "),ez=a("a"),HVo=o("M2M100ForConditionalGeneration"),UVo=o(" (NLLB model)"),JVo=l(),sv=a("li"),Cue=a("strong"),YVo=o("pegasus"),KVo=o(" \u2014 "),oz=a("a"),ZVo=o("PegasusForConditionalGeneration"),eXo=o(" (Pegasus model)"),oXo=l(),lv=a("li"),wue=a("strong"),rXo=o("plbart"),tXo=o(" \u2014 "),rz=a("a"),aXo=o("PLBartForConditionalGeneration"),nXo=o(" (PLBart model)"),sXo=l(),iv=a("li"),Aue=a("strong"),lXo=o("prophetnet"),iXo=o(" \u2014 "),tz=a("a"),dXo=o("ProphetNetForConditionalGeneration"),cXo=o(" (ProphetNet model)"),fXo=l(),dv=a("li"),Lue=a("strong"),mXo=o("t5"),gXo=o(" \u2014 "),az=a("a"),hXo=o("T5ForConditionalGeneration"),pXo=o(" (T5 model)"),_Xo=l(),cv=a("li"),yue=a("strong"),uXo=o("xlm-prophetnet"),bXo=o(" \u2014 "),nz=a("a"),vXo=o("XLMProphetNetForConditionalGeneration"),FXo=o(" (XLM-ProphetNet model)"),TXo=l(),fv=a("p"),MXo=o("The model is set in evaluation mode by default using "),xue=a("code"),EXo=o("model.eval()"),CXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$ue=a("code"),wXo=o("model.train()"),AXo=l(),F(mv.$$.fragment),mQe=l(),fd=a("h2"),gv=a("a"),kue=a("span"),F(zy.$$.fragment),LXo=l(),Sue=a("span"),yXo=o("AutoModelForSequenceClassification"),gQe=l(),No=a("div"),F(Wy.$$.fragment),xXo=l(),md=a("p"),$Xo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),sz=a("a"),kXo=o("from_pretrained()"),SXo=o(" class method or the "),lz=a("a"),RXo=o("from_config()"),PXo=o(` class
method.`),BXo=l(),Qy=a("p"),IXo=o("This class cannot be instantiated directly using "),Rue=a("code"),NXo=o("__init__()"),qXo=o(" (throws an error)."),jXo=l(),pt=a("div"),F(Hy.$$.fragment),DXo=l(),Pue=a("p"),GXo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),OXo=l(),gd=a("p"),VXo=o(`Note:
Loading a model from its configuration file does `),Bue=a("strong"),XXo=o("not"),zXo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=a("a"),WXo=o("from_pretrained()"),QXo=o(" to load the model weights."),HXo=l(),F(hv.$$.fragment),UXo=l(),ro=a("div"),F(Uy.$$.fragment),JXo=l(),Iue=a("p"),YXo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),KXo=l(),za=a("p"),ZXo=o("The model class to instantiate is selected based on the "),Nue=a("code"),ezo=o("model_type"),ozo=o(` property of the config object (either
passed as an argument or loaded from `),que=a("code"),rzo=o("pretrained_model_name_or_path"),tzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jue=a("code"),azo=o("pretrained_model_name_or_path"),nzo=o(":"),szo=l(),B=a("ul"),pv=a("li"),Due=a("strong"),lzo=o("albert"),izo=o(" \u2014 "),dz=a("a"),dzo=o("AlbertForSequenceClassification"),czo=o(" (ALBERT model)"),fzo=l(),_v=a("li"),Gue=a("strong"),mzo=o("bart"),gzo=o(" \u2014 "),cz=a("a"),hzo=o("BartForSequenceClassification"),pzo=o(" (BART model)"),_zo=l(),uv=a("li"),Oue=a("strong"),uzo=o("bert"),bzo=o(" \u2014 "),fz=a("a"),vzo=o("BertForSequenceClassification"),Fzo=o(" (BERT model)"),Tzo=l(),bv=a("li"),Vue=a("strong"),Mzo=o("big_bird"),Ezo=o(" \u2014 "),mz=a("a"),Czo=o("BigBirdForSequenceClassification"),wzo=o(" (BigBird model)"),Azo=l(),vv=a("li"),Xue=a("strong"),Lzo=o("bigbird_pegasus"),yzo=o(" \u2014 "),gz=a("a"),xzo=o("BigBirdPegasusForSequenceClassification"),$zo=o(" (BigBird-Pegasus model)"),kzo=l(),Fv=a("li"),zue=a("strong"),Szo=o("bloom"),Rzo=o(" \u2014 "),hz=a("a"),Pzo=o("BloomForSequenceClassification"),Bzo=o(" (BLOOM model)"),Izo=l(),Tv=a("li"),Wue=a("strong"),Nzo=o("camembert"),qzo=o(" \u2014 "),pz=a("a"),jzo=o("CamembertForSequenceClassification"),Dzo=o(" (CamemBERT model)"),Gzo=l(),Mv=a("li"),Que=a("strong"),Ozo=o("canine"),Vzo=o(" \u2014 "),_z=a("a"),Xzo=o("CanineForSequenceClassification"),zzo=o(" (CANINE model)"),Wzo=l(),Ev=a("li"),Hue=a("strong"),Qzo=o("convbert"),Hzo=o(" \u2014 "),uz=a("a"),Uzo=o("ConvBertForSequenceClassification"),Jzo=o(" (ConvBERT model)"),Yzo=l(),Cv=a("li"),Uue=a("strong"),Kzo=o("ctrl"),Zzo=o(" \u2014 "),bz=a("a"),eWo=o("CTRLForSequenceClassification"),oWo=o(" (CTRL model)"),rWo=l(),wv=a("li"),Jue=a("strong"),tWo=o("data2vec-text"),aWo=o(" \u2014 "),vz=a("a"),nWo=o("Data2VecTextForSequenceClassification"),sWo=o(" (Data2VecText model)"),lWo=l(),Av=a("li"),Yue=a("strong"),iWo=o("deberta"),dWo=o(" \u2014 "),Fz=a("a"),cWo=o("DebertaForSequenceClassification"),fWo=o(" (DeBERTa model)"),mWo=l(),Lv=a("li"),Kue=a("strong"),gWo=o("deberta-v2"),hWo=o(" \u2014 "),Tz=a("a"),pWo=o("DebertaV2ForSequenceClassification"),_Wo=o(" (DeBERTa-v2 model)"),uWo=l(),yv=a("li"),Zue=a("strong"),bWo=o("distilbert"),vWo=o(" \u2014 "),Mz=a("a"),FWo=o("DistilBertForSequenceClassification"),TWo=o(" (DistilBERT model)"),MWo=l(),xv=a("li"),e2e=a("strong"),EWo=o("electra"),CWo=o(" \u2014 "),Ez=a("a"),wWo=o("ElectraForSequenceClassification"),AWo=o(" (ELECTRA model)"),LWo=l(),$v=a("li"),o2e=a("strong"),yWo=o("flaubert"),xWo=o(" \u2014 "),Cz=a("a"),$Wo=o("FlaubertForSequenceClassification"),kWo=o(" (FlauBERT model)"),SWo=l(),kv=a("li"),r2e=a("strong"),RWo=o("fnet"),PWo=o(" \u2014 "),wz=a("a"),BWo=o("FNetForSequenceClassification"),IWo=o(" (FNet model)"),NWo=l(),Sv=a("li"),t2e=a("strong"),qWo=o("funnel"),jWo=o(" \u2014 "),Az=a("a"),DWo=o("FunnelForSequenceClassification"),GWo=o(" (Funnel Transformer model)"),OWo=l(),Rv=a("li"),a2e=a("strong"),VWo=o("gpt2"),XWo=o(" \u2014 "),Lz=a("a"),zWo=o("GPT2ForSequenceClassification"),WWo=o(" (OpenAI GPT-2 model)"),QWo=l(),Pv=a("li"),n2e=a("strong"),HWo=o("gpt_neo"),UWo=o(" \u2014 "),yz=a("a"),JWo=o("GPTNeoForSequenceClassification"),YWo=o(" (GPT Neo model)"),KWo=l(),Bv=a("li"),s2e=a("strong"),ZWo=o("gptj"),eQo=o(" \u2014 "),xz=a("a"),oQo=o("GPTJForSequenceClassification"),rQo=o(" (GPT-J model)"),tQo=l(),Iv=a("li"),l2e=a("strong"),aQo=o("ibert"),nQo=o(" \u2014 "),$z=a("a"),sQo=o("IBertForSequenceClassification"),lQo=o(" (I-BERT model)"),iQo=l(),Nv=a("li"),i2e=a("strong"),dQo=o("layoutlm"),cQo=o(" \u2014 "),kz=a("a"),fQo=o("LayoutLMForSequenceClassification"),mQo=o(" (LayoutLM model)"),gQo=l(),qv=a("li"),d2e=a("strong"),hQo=o("layoutlmv2"),pQo=o(" \u2014 "),Sz=a("a"),_Qo=o("LayoutLMv2ForSequenceClassification"),uQo=o(" (LayoutLMv2 model)"),bQo=l(),jv=a("li"),c2e=a("strong"),vQo=o("layoutlmv3"),FQo=o(" \u2014 "),Rz=a("a"),TQo=o("LayoutLMv3ForSequenceClassification"),MQo=o(" (LayoutLMv3 model)"),EQo=l(),Dv=a("li"),f2e=a("strong"),CQo=o("led"),wQo=o(" \u2014 "),Pz=a("a"),AQo=o("LEDForSequenceClassification"),LQo=o(" (LED model)"),yQo=l(),Gv=a("li"),m2e=a("strong"),xQo=o("longformer"),$Qo=o(" \u2014 "),Bz=a("a"),kQo=o("LongformerForSequenceClassification"),SQo=o(" (Longformer model)"),RQo=l(),Ov=a("li"),g2e=a("strong"),PQo=o("luke"),BQo=o(" \u2014 "),Iz=a("a"),IQo=o("LukeForSequenceClassification"),NQo=o(" (LUKE model)"),qQo=l(),Vv=a("li"),h2e=a("strong"),jQo=o("mbart"),DQo=o(" \u2014 "),Nz=a("a"),GQo=o("MBartForSequenceClassification"),OQo=o(" (mBART model)"),VQo=l(),Xv=a("li"),p2e=a("strong"),XQo=o("megatron-bert"),zQo=o(" \u2014 "),qz=a("a"),WQo=o("MegatronBertForSequenceClassification"),QQo=o(" (Megatron-BERT model)"),HQo=l(),zv=a("li"),_2e=a("strong"),UQo=o("mobilebert"),JQo=o(" \u2014 "),jz=a("a"),YQo=o("MobileBertForSequenceClassification"),KQo=o(" (MobileBERT model)"),ZQo=l(),Wv=a("li"),u2e=a("strong"),eHo=o("mpnet"),oHo=o(" \u2014 "),Dz=a("a"),rHo=o("MPNetForSequenceClassification"),tHo=o(" (MPNet model)"),aHo=l(),Qv=a("li"),b2e=a("strong"),nHo=o("mvp"),sHo=o(" \u2014 "),Gz=a("a"),lHo=o("MvpForSequenceClassification"),iHo=o(" (MVP model)"),dHo=l(),Hv=a("li"),v2e=a("strong"),cHo=o("nezha"),fHo=o(" \u2014 "),Oz=a("a"),mHo=o("NezhaForSequenceClassification"),gHo=o(" (Nezha model)"),hHo=l(),Uv=a("li"),F2e=a("strong"),pHo=o("nystromformer"),_Ho=o(" \u2014 "),Vz=a("a"),uHo=o("NystromformerForSequenceClassification"),bHo=o(" (Nystr\xF6mformer model)"),vHo=l(),Jv=a("li"),T2e=a("strong"),FHo=o("openai-gpt"),THo=o(" \u2014 "),Xz=a("a"),MHo=o("OpenAIGPTForSequenceClassification"),EHo=o(" (OpenAI GPT model)"),CHo=l(),Yv=a("li"),M2e=a("strong"),wHo=o("opt"),AHo=o(" \u2014 "),zz=a("a"),LHo=o("OPTForSequenceClassification"),yHo=o(" (OPT model)"),xHo=l(),Kv=a("li"),E2e=a("strong"),$Ho=o("perceiver"),kHo=o(" \u2014 "),Wz=a("a"),SHo=o("PerceiverForSequenceClassification"),RHo=o(" (Perceiver model)"),PHo=l(),Zv=a("li"),C2e=a("strong"),BHo=o("plbart"),IHo=o(" \u2014 "),Qz=a("a"),NHo=o("PLBartForSequenceClassification"),qHo=o(" (PLBart model)"),jHo=l(),e0=a("li"),w2e=a("strong"),DHo=o("qdqbert"),GHo=o(" \u2014 "),Hz=a("a"),OHo=o("QDQBertForSequenceClassification"),VHo=o(" (QDQBert model)"),XHo=l(),o0=a("li"),A2e=a("strong"),zHo=o("reformer"),WHo=o(" \u2014 "),Uz=a("a"),QHo=o("ReformerForSequenceClassification"),HHo=o(" (Reformer model)"),UHo=l(),r0=a("li"),L2e=a("strong"),JHo=o("rembert"),YHo=o(" \u2014 "),Jz=a("a"),KHo=o("RemBertForSequenceClassification"),ZHo=o(" (RemBERT model)"),eUo=l(),t0=a("li"),y2e=a("strong"),oUo=o("roberta"),rUo=o(" \u2014 "),Yz=a("a"),tUo=o("RobertaForSequenceClassification"),aUo=o(" (RoBERTa model)"),nUo=l(),a0=a("li"),x2e=a("strong"),sUo=o("roformer"),lUo=o(" \u2014 "),Kz=a("a"),iUo=o("RoFormerForSequenceClassification"),dUo=o(" (RoFormer model)"),cUo=l(),n0=a("li"),$2e=a("strong"),fUo=o("squeezebert"),mUo=o(" \u2014 "),Zz=a("a"),gUo=o("SqueezeBertForSequenceClassification"),hUo=o(" (SqueezeBERT model)"),pUo=l(),s0=a("li"),k2e=a("strong"),_Uo=o("tapas"),uUo=o(" \u2014 "),eW=a("a"),bUo=o("TapasForSequenceClassification"),vUo=o(" (TAPAS model)"),FUo=l(),l0=a("li"),S2e=a("strong"),TUo=o("transfo-xl"),MUo=o(" \u2014 "),oW=a("a"),EUo=o("TransfoXLForSequenceClassification"),CUo=o(" (Transformer-XL model)"),wUo=l(),i0=a("li"),R2e=a("strong"),AUo=o("xlm"),LUo=o(" \u2014 "),rW=a("a"),yUo=o("XLMForSequenceClassification"),xUo=o(" (XLM model)"),$Uo=l(),d0=a("li"),P2e=a("strong"),kUo=o("xlm-roberta"),SUo=o(" \u2014 "),tW=a("a"),RUo=o("XLMRobertaForSequenceClassification"),PUo=o(" (XLM-RoBERTa model)"),BUo=l(),c0=a("li"),B2e=a("strong"),IUo=o("xlm-roberta-xl"),NUo=o(" \u2014 "),aW=a("a"),qUo=o("XLMRobertaXLForSequenceClassification"),jUo=o(" (XLM-RoBERTa-XL model)"),DUo=l(),f0=a("li"),I2e=a("strong"),GUo=o("xlnet"),OUo=o(" \u2014 "),nW=a("a"),VUo=o("XLNetForSequenceClassification"),XUo=o(" (XLNet model)"),zUo=l(),m0=a("li"),N2e=a("strong"),WUo=o("yoso"),QUo=o(" \u2014 "),sW=a("a"),HUo=o("YosoForSequenceClassification"),UUo=o(" (YOSO model)"),JUo=l(),g0=a("p"),YUo=o("The model is set in evaluation mode by default using "),q2e=a("code"),KUo=o("model.eval()"),ZUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j2e=a("code"),eJo=o("model.train()"),oJo=l(),F(h0.$$.fragment),hQe=l(),hd=a("h2"),p0=a("a"),D2e=a("span"),F(Jy.$$.fragment),rJo=l(),G2e=a("span"),tJo=o("AutoModelForMultipleChoice"),pQe=l(),qo=a("div"),F(Yy.$$.fragment),aJo=l(),pd=a("p"),nJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),lW=a("a"),sJo=o("from_pretrained()"),lJo=o(" class method or the "),iW=a("a"),iJo=o("from_config()"),dJo=o(` class
method.`),cJo=l(),Ky=a("p"),fJo=o("This class cannot be instantiated directly using "),O2e=a("code"),mJo=o("__init__()"),gJo=o(" (throws an error)."),hJo=l(),_t=a("div"),F(Zy.$$.fragment),pJo=l(),V2e=a("p"),_Jo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),uJo=l(),_d=a("p"),bJo=o(`Note:
Loading a model from its configuration file does `),X2e=a("strong"),vJo=o("not"),FJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dW=a("a"),TJo=o("from_pretrained()"),MJo=o(" to load the model weights."),EJo=l(),F(_0.$$.fragment),CJo=l(),to=a("div"),F(e9.$$.fragment),wJo=l(),z2e=a("p"),AJo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),LJo=l(),Wa=a("p"),yJo=o("The model class to instantiate is selected based on the "),W2e=a("code"),xJo=o("model_type"),$Jo=o(` property of the config object (either
passed as an argument or loaded from `),Q2e=a("code"),kJo=o("pretrained_model_name_or_path"),SJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H2e=a("code"),RJo=o("pretrained_model_name_or_path"),PJo=o(":"),BJo=l(),Z=a("ul"),u0=a("li"),U2e=a("strong"),IJo=o("albert"),NJo=o(" \u2014 "),cW=a("a"),qJo=o("AlbertForMultipleChoice"),jJo=o(" (ALBERT model)"),DJo=l(),b0=a("li"),J2e=a("strong"),GJo=o("bert"),OJo=o(" \u2014 "),fW=a("a"),VJo=o("BertForMultipleChoice"),XJo=o(" (BERT model)"),zJo=l(),v0=a("li"),Y2e=a("strong"),WJo=o("big_bird"),QJo=o(" \u2014 "),mW=a("a"),HJo=o("BigBirdForMultipleChoice"),UJo=o(" (BigBird model)"),JJo=l(),F0=a("li"),K2e=a("strong"),YJo=o("camembert"),KJo=o(" \u2014 "),gW=a("a"),ZJo=o("CamembertForMultipleChoice"),eYo=o(" (CamemBERT model)"),oYo=l(),T0=a("li"),Z2e=a("strong"),rYo=o("canine"),tYo=o(" \u2014 "),hW=a("a"),aYo=o("CanineForMultipleChoice"),nYo=o(" (CANINE model)"),sYo=l(),M0=a("li"),e1e=a("strong"),lYo=o("convbert"),iYo=o(" \u2014 "),pW=a("a"),dYo=o("ConvBertForMultipleChoice"),cYo=o(" (ConvBERT model)"),fYo=l(),E0=a("li"),o1e=a("strong"),mYo=o("data2vec-text"),gYo=o(" \u2014 "),_W=a("a"),hYo=o("Data2VecTextForMultipleChoice"),pYo=o(" (Data2VecText model)"),_Yo=l(),C0=a("li"),r1e=a("strong"),uYo=o("deberta-v2"),bYo=o(" \u2014 "),uW=a("a"),vYo=o("DebertaV2ForMultipleChoice"),FYo=o(" (DeBERTa-v2 model)"),TYo=l(),w0=a("li"),t1e=a("strong"),MYo=o("distilbert"),EYo=o(" \u2014 "),bW=a("a"),CYo=o("DistilBertForMultipleChoice"),wYo=o(" (DistilBERT model)"),AYo=l(),A0=a("li"),a1e=a("strong"),LYo=o("electra"),yYo=o(" \u2014 "),vW=a("a"),xYo=o("ElectraForMultipleChoice"),$Yo=o(" (ELECTRA model)"),kYo=l(),L0=a("li"),n1e=a("strong"),SYo=o("flaubert"),RYo=o(" \u2014 "),FW=a("a"),PYo=o("FlaubertForMultipleChoice"),BYo=o(" (FlauBERT model)"),IYo=l(),y0=a("li"),s1e=a("strong"),NYo=o("fnet"),qYo=o(" \u2014 "),TW=a("a"),jYo=o("FNetForMultipleChoice"),DYo=o(" (FNet model)"),GYo=l(),x0=a("li"),l1e=a("strong"),OYo=o("funnel"),VYo=o(" \u2014 "),MW=a("a"),XYo=o("FunnelForMultipleChoice"),zYo=o(" (Funnel Transformer model)"),WYo=l(),$0=a("li"),i1e=a("strong"),QYo=o("ibert"),HYo=o(" \u2014 "),EW=a("a"),UYo=o("IBertForMultipleChoice"),JYo=o(" (I-BERT model)"),YYo=l(),k0=a("li"),d1e=a("strong"),KYo=o("longformer"),ZYo=o(" \u2014 "),CW=a("a"),eKo=o("LongformerForMultipleChoice"),oKo=o(" (Longformer model)"),rKo=l(),S0=a("li"),c1e=a("strong"),tKo=o("luke"),aKo=o(" \u2014 "),wW=a("a"),nKo=o("LukeForMultipleChoice"),sKo=o(" (LUKE model)"),lKo=l(),R0=a("li"),f1e=a("strong"),iKo=o("megatron-bert"),dKo=o(" \u2014 "),AW=a("a"),cKo=o("MegatronBertForMultipleChoice"),fKo=o(" (Megatron-BERT model)"),mKo=l(),P0=a("li"),m1e=a("strong"),gKo=o("mobilebert"),hKo=o(" \u2014 "),LW=a("a"),pKo=o("MobileBertForMultipleChoice"),_Ko=o(" (MobileBERT model)"),uKo=l(),B0=a("li"),g1e=a("strong"),bKo=o("mpnet"),vKo=o(" \u2014 "),yW=a("a"),FKo=o("MPNetForMultipleChoice"),TKo=o(" (MPNet model)"),MKo=l(),I0=a("li"),h1e=a("strong"),EKo=o("nezha"),CKo=o(" \u2014 "),xW=a("a"),wKo=o("NezhaForMultipleChoice"),AKo=o(" (Nezha model)"),LKo=l(),N0=a("li"),p1e=a("strong"),yKo=o("nystromformer"),xKo=o(" \u2014 "),$W=a("a"),$Ko=o("NystromformerForMultipleChoice"),kKo=o(" (Nystr\xF6mformer model)"),SKo=l(),q0=a("li"),_1e=a("strong"),RKo=o("qdqbert"),PKo=o(" \u2014 "),kW=a("a"),BKo=o("QDQBertForMultipleChoice"),IKo=o(" (QDQBert model)"),NKo=l(),j0=a("li"),u1e=a("strong"),qKo=o("rembert"),jKo=o(" \u2014 "),SW=a("a"),DKo=o("RemBertForMultipleChoice"),GKo=o(" (RemBERT model)"),OKo=l(),D0=a("li"),b1e=a("strong"),VKo=o("roberta"),XKo=o(" \u2014 "),RW=a("a"),zKo=o("RobertaForMultipleChoice"),WKo=o(" (RoBERTa model)"),QKo=l(),G0=a("li"),v1e=a("strong"),HKo=o("roformer"),UKo=o(" \u2014 "),PW=a("a"),JKo=o("RoFormerForMultipleChoice"),YKo=o(" (RoFormer model)"),KKo=l(),O0=a("li"),F1e=a("strong"),ZKo=o("squeezebert"),eZo=o(" \u2014 "),BW=a("a"),oZo=o("SqueezeBertForMultipleChoice"),rZo=o(" (SqueezeBERT model)"),tZo=l(),V0=a("li"),T1e=a("strong"),aZo=o("xlm"),nZo=o(" \u2014 "),IW=a("a"),sZo=o("XLMForMultipleChoice"),lZo=o(" (XLM model)"),iZo=l(),X0=a("li"),M1e=a("strong"),dZo=o("xlm-roberta"),cZo=o(" \u2014 "),NW=a("a"),fZo=o("XLMRobertaForMultipleChoice"),mZo=o(" (XLM-RoBERTa model)"),gZo=l(),z0=a("li"),E1e=a("strong"),hZo=o("xlm-roberta-xl"),pZo=o(" \u2014 "),qW=a("a"),_Zo=o("XLMRobertaXLForMultipleChoice"),uZo=o(" (XLM-RoBERTa-XL model)"),bZo=l(),W0=a("li"),C1e=a("strong"),vZo=o("xlnet"),FZo=o(" \u2014 "),jW=a("a"),TZo=o("XLNetForMultipleChoice"),MZo=o(" (XLNet model)"),EZo=l(),Q0=a("li"),w1e=a("strong"),CZo=o("yoso"),wZo=o(" \u2014 "),DW=a("a"),AZo=o("YosoForMultipleChoice"),LZo=o(" (YOSO model)"),yZo=l(),H0=a("p"),xZo=o("The model is set in evaluation mode by default using "),A1e=a("code"),$Zo=o("model.eval()"),kZo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L1e=a("code"),SZo=o("model.train()"),RZo=l(),F(U0.$$.fragment),_Qe=l(),ud=a("h2"),J0=a("a"),y1e=a("span"),F(o9.$$.fragment),PZo=l(),x1e=a("span"),BZo=o("AutoModelForNextSentencePrediction"),uQe=l(),jo=a("div"),F(r9.$$.fragment),IZo=l(),bd=a("p"),NZo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),GW=a("a"),qZo=o("from_pretrained()"),jZo=o(" class method or the "),OW=a("a"),DZo=o("from_config()"),GZo=o(` class
method.`),OZo=l(),t9=a("p"),VZo=o("This class cannot be instantiated directly using "),$1e=a("code"),XZo=o("__init__()"),zZo=o(" (throws an error)."),WZo=l(),ut=a("div"),F(a9.$$.fragment),QZo=l(),k1e=a("p"),HZo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),UZo=l(),vd=a("p"),JZo=o(`Note:
Loading a model from its configuration file does `),S1e=a("strong"),YZo=o("not"),KZo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=a("a"),ZZo=o("from_pretrained()"),eer=o(" to load the model weights."),oer=l(),F(Y0.$$.fragment),rer=l(),ao=a("div"),F(n9.$$.fragment),ter=l(),R1e=a("p"),aer=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),ner=l(),Qa=a("p"),ser=o("The model class to instantiate is selected based on the "),P1e=a("code"),ler=o("model_type"),ier=o(` property of the config object (either
passed as an argument or loaded from `),B1e=a("code"),der=o("pretrained_model_name_or_path"),cer=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=a("code"),fer=o("pretrained_model_name_or_path"),mer=o(":"),ger=l(),Do=a("ul"),K0=a("li"),N1e=a("strong"),her=o("bert"),per=o(" \u2014 "),XW=a("a"),_er=o("BertForNextSentencePrediction"),uer=o(" (BERT model)"),ber=l(),Z0=a("li"),q1e=a("strong"),ver=o("fnet"),Fer=o(" \u2014 "),zW=a("a"),Ter=o("FNetForNextSentencePrediction"),Mer=o(" (FNet model)"),Eer=l(),eF=a("li"),j1e=a("strong"),Cer=o("megatron-bert"),wer=o(" \u2014 "),WW=a("a"),Aer=o("MegatronBertForNextSentencePrediction"),Ler=o(" (Megatron-BERT model)"),yer=l(),oF=a("li"),D1e=a("strong"),xer=o("mobilebert"),$er=o(" \u2014 "),QW=a("a"),ker=o("MobileBertForNextSentencePrediction"),Ser=o(" (MobileBERT model)"),Rer=l(),rF=a("li"),G1e=a("strong"),Per=o("nezha"),Ber=o(" \u2014 "),HW=a("a"),Ier=o("NezhaForNextSentencePrediction"),Ner=o(" (Nezha model)"),qer=l(),tF=a("li"),O1e=a("strong"),jer=o("qdqbert"),Der=o(" \u2014 "),UW=a("a"),Ger=o("QDQBertForNextSentencePrediction"),Oer=o(" (QDQBert model)"),Ver=l(),aF=a("p"),Xer=o("The model is set in evaluation mode by default using "),V1e=a("code"),zer=o("model.eval()"),Wer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X1e=a("code"),Qer=o("model.train()"),Her=l(),F(nF.$$.fragment),bQe=l(),Fd=a("h2"),sF=a("a"),z1e=a("span"),F(s9.$$.fragment),Uer=l(),W1e=a("span"),Jer=o("AutoModelForTokenClassification"),vQe=l(),Go=a("div"),F(l9.$$.fragment),Yer=l(),Td=a("p"),Ker=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),JW=a("a"),Zer=o("from_pretrained()"),eor=o(" class method or the "),YW=a("a"),oor=o("from_config()"),ror=o(` class
method.`),tor=l(),i9=a("p"),aor=o("This class cannot be instantiated directly using "),Q1e=a("code"),nor=o("__init__()"),sor=o(" (throws an error)."),lor=l(),bt=a("div"),F(d9.$$.fragment),ior=l(),H1e=a("p"),dor=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),cor=l(),Md=a("p"),mor=o(`Note:
Loading a model from its configuration file does `),U1e=a("strong"),gor=o("not"),hor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KW=a("a"),por=o("from_pretrained()"),_or=o(" to load the model weights."),uor=l(),F(lF.$$.fragment),bor=l(),no=a("div"),F(c9.$$.fragment),vor=l(),J1e=a("p"),For=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Tor=l(),Ha=a("p"),Mor=o("The model class to instantiate is selected based on the "),Y1e=a("code"),Eor=o("model_type"),Cor=o(` property of the config object (either
passed as an argument or loaded from `),K1e=a("code"),wor=o("pretrained_model_name_or_path"),Aor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=a("code"),Lor=o("pretrained_model_name_or_path"),yor=o(":"),xor=l(),U=a("ul"),iF=a("li"),ebe=a("strong"),$or=o("albert"),kor=o(" \u2014 "),ZW=a("a"),Sor=o("AlbertForTokenClassification"),Ror=o(" (ALBERT model)"),Por=l(),dF=a("li"),obe=a("strong"),Bor=o("bert"),Ior=o(" \u2014 "),eQ=a("a"),Nor=o("BertForTokenClassification"),qor=o(" (BERT model)"),jor=l(),cF=a("li"),rbe=a("strong"),Dor=o("big_bird"),Gor=o(" \u2014 "),oQ=a("a"),Oor=o("BigBirdForTokenClassification"),Vor=o(" (BigBird model)"),Xor=l(),fF=a("li"),tbe=a("strong"),zor=o("bloom"),Wor=o(" \u2014 "),rQ=a("a"),Qor=o("BloomForTokenClassification"),Hor=o(" (BLOOM model)"),Uor=l(),mF=a("li"),abe=a("strong"),Jor=o("camembert"),Yor=o(" \u2014 "),tQ=a("a"),Kor=o("CamembertForTokenClassification"),Zor=o(" (CamemBERT model)"),err=l(),gF=a("li"),nbe=a("strong"),orr=o("canine"),rrr=o(" \u2014 "),aQ=a("a"),trr=o("CanineForTokenClassification"),arr=o(" (CANINE model)"),nrr=l(),hF=a("li"),sbe=a("strong"),srr=o("convbert"),lrr=o(" \u2014 "),nQ=a("a"),irr=o("ConvBertForTokenClassification"),drr=o(" (ConvBERT model)"),crr=l(),pF=a("li"),lbe=a("strong"),frr=o("data2vec-text"),mrr=o(" \u2014 "),sQ=a("a"),grr=o("Data2VecTextForTokenClassification"),hrr=o(" (Data2VecText model)"),prr=l(),_F=a("li"),ibe=a("strong"),_rr=o("deberta"),urr=o(" \u2014 "),lQ=a("a"),brr=o("DebertaForTokenClassification"),vrr=o(" (DeBERTa model)"),Frr=l(),uF=a("li"),dbe=a("strong"),Trr=o("deberta-v2"),Mrr=o(" \u2014 "),iQ=a("a"),Err=o("DebertaV2ForTokenClassification"),Crr=o(" (DeBERTa-v2 model)"),wrr=l(),bF=a("li"),cbe=a("strong"),Arr=o("distilbert"),Lrr=o(" \u2014 "),dQ=a("a"),yrr=o("DistilBertForTokenClassification"),xrr=o(" (DistilBERT model)"),$rr=l(),vF=a("li"),fbe=a("strong"),krr=o("electra"),Srr=o(" \u2014 "),cQ=a("a"),Rrr=o("ElectraForTokenClassification"),Prr=o(" (ELECTRA model)"),Brr=l(),FF=a("li"),mbe=a("strong"),Irr=o("flaubert"),Nrr=o(" \u2014 "),fQ=a("a"),qrr=o("FlaubertForTokenClassification"),jrr=o(" (FlauBERT model)"),Drr=l(),TF=a("li"),gbe=a("strong"),Grr=o("fnet"),Orr=o(" \u2014 "),mQ=a("a"),Vrr=o("FNetForTokenClassification"),Xrr=o(" (FNet model)"),zrr=l(),MF=a("li"),hbe=a("strong"),Wrr=o("funnel"),Qrr=o(" \u2014 "),gQ=a("a"),Hrr=o("FunnelForTokenClassification"),Urr=o(" (Funnel Transformer model)"),Jrr=l(),EF=a("li"),pbe=a("strong"),Yrr=o("gpt2"),Krr=o(" \u2014 "),hQ=a("a"),Zrr=o("GPT2ForTokenClassification"),etr=o(" (OpenAI GPT-2 model)"),otr=l(),CF=a("li"),_be=a("strong"),rtr=o("ibert"),ttr=o(" \u2014 "),pQ=a("a"),atr=o("IBertForTokenClassification"),ntr=o(" (I-BERT model)"),str=l(),wF=a("li"),ube=a("strong"),ltr=o("layoutlm"),itr=o(" \u2014 "),_Q=a("a"),dtr=o("LayoutLMForTokenClassification"),ctr=o(" (LayoutLM model)"),ftr=l(),AF=a("li"),bbe=a("strong"),mtr=o("layoutlmv2"),gtr=o(" \u2014 "),uQ=a("a"),htr=o("LayoutLMv2ForTokenClassification"),ptr=o(" (LayoutLMv2 model)"),_tr=l(),LF=a("li"),vbe=a("strong"),utr=o("layoutlmv3"),btr=o(" \u2014 "),bQ=a("a"),vtr=o("LayoutLMv3ForTokenClassification"),Ftr=o(" (LayoutLMv3 model)"),Ttr=l(),yF=a("li"),Fbe=a("strong"),Mtr=o("longformer"),Etr=o(" \u2014 "),vQ=a("a"),Ctr=o("LongformerForTokenClassification"),wtr=o(" (Longformer model)"),Atr=l(),xF=a("li"),Tbe=a("strong"),Ltr=o("luke"),ytr=o(" \u2014 "),FQ=a("a"),xtr=o("LukeForTokenClassification"),$tr=o(" (LUKE model)"),ktr=l(),$F=a("li"),Mbe=a("strong"),Str=o("megatron-bert"),Rtr=o(" \u2014 "),TQ=a("a"),Ptr=o("MegatronBertForTokenClassification"),Btr=o(" (Megatron-BERT model)"),Itr=l(),kF=a("li"),Ebe=a("strong"),Ntr=o("mobilebert"),qtr=o(" \u2014 "),MQ=a("a"),jtr=o("MobileBertForTokenClassification"),Dtr=o(" (MobileBERT model)"),Gtr=l(),SF=a("li"),Cbe=a("strong"),Otr=o("mpnet"),Vtr=o(" \u2014 "),EQ=a("a"),Xtr=o("MPNetForTokenClassification"),ztr=o(" (MPNet model)"),Wtr=l(),RF=a("li"),wbe=a("strong"),Qtr=o("nezha"),Htr=o(" \u2014 "),CQ=a("a"),Utr=o("NezhaForTokenClassification"),Jtr=o(" (Nezha model)"),Ytr=l(),PF=a("li"),Abe=a("strong"),Ktr=o("nystromformer"),Ztr=o(" \u2014 "),wQ=a("a"),ear=o("NystromformerForTokenClassification"),oar=o(" (Nystr\xF6mformer model)"),rar=l(),BF=a("li"),Lbe=a("strong"),tar=o("qdqbert"),aar=o(" \u2014 "),AQ=a("a"),nar=o("QDQBertForTokenClassification"),sar=o(" (QDQBert model)"),lar=l(),IF=a("li"),ybe=a("strong"),iar=o("rembert"),dar=o(" \u2014 "),LQ=a("a"),car=o("RemBertForTokenClassification"),far=o(" (RemBERT model)"),mar=l(),NF=a("li"),xbe=a("strong"),gar=o("roberta"),har=o(" \u2014 "),yQ=a("a"),par=o("RobertaForTokenClassification"),_ar=o(" (RoBERTa model)"),uar=l(),qF=a("li"),$be=a("strong"),bar=o("roformer"),Far=o(" \u2014 "),xQ=a("a"),Tar=o("RoFormerForTokenClassification"),Mar=o(" (RoFormer model)"),Ear=l(),jF=a("li"),kbe=a("strong"),Car=o("squeezebert"),war=o(" \u2014 "),$Q=a("a"),Aar=o("SqueezeBertForTokenClassification"),Lar=o(" (SqueezeBERT model)"),yar=l(),DF=a("li"),Sbe=a("strong"),xar=o("xlm"),$ar=o(" \u2014 "),kQ=a("a"),kar=o("XLMForTokenClassification"),Sar=o(" (XLM model)"),Rar=l(),GF=a("li"),Rbe=a("strong"),Par=o("xlm-roberta"),Bar=o(" \u2014 "),SQ=a("a"),Iar=o("XLMRobertaForTokenClassification"),Nar=o(" (XLM-RoBERTa model)"),qar=l(),OF=a("li"),Pbe=a("strong"),jar=o("xlm-roberta-xl"),Dar=o(" \u2014 "),RQ=a("a"),Gar=o("XLMRobertaXLForTokenClassification"),Oar=o(" (XLM-RoBERTa-XL model)"),Var=l(),VF=a("li"),Bbe=a("strong"),Xar=o("xlnet"),zar=o(" \u2014 "),PQ=a("a"),War=o("XLNetForTokenClassification"),Qar=o(" (XLNet model)"),Har=l(),XF=a("li"),Ibe=a("strong"),Uar=o("yoso"),Jar=o(" \u2014 "),BQ=a("a"),Yar=o("YosoForTokenClassification"),Kar=o(" (YOSO model)"),Zar=l(),zF=a("p"),enr=o("The model is set in evaluation mode by default using "),Nbe=a("code"),onr=o("model.eval()"),rnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qbe=a("code"),tnr=o("model.train()"),anr=l(),F(WF.$$.fragment),FQe=l(),Ed=a("h2"),QF=a("a"),jbe=a("span"),F(f9.$$.fragment),nnr=l(),Dbe=a("span"),snr=o("AutoModelForQuestionAnswering"),TQe=l(),Oo=a("div"),F(m9.$$.fragment),lnr=l(),Cd=a("p"),inr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),IQ=a("a"),dnr=o("from_pretrained()"),cnr=o(" class method or the "),NQ=a("a"),fnr=o("from_config()"),mnr=o(` class
method.`),gnr=l(),g9=a("p"),hnr=o("This class cannot be instantiated directly using "),Gbe=a("code"),pnr=o("__init__()"),_nr=o(" (throws an error)."),unr=l(),vt=a("div"),F(h9.$$.fragment),bnr=l(),Obe=a("p"),vnr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Fnr=l(),wd=a("p"),Tnr=o(`Note:
Loading a model from its configuration file does `),Vbe=a("strong"),Mnr=o("not"),Enr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qQ=a("a"),Cnr=o("from_pretrained()"),wnr=o(" to load the model weights."),Anr=l(),F(HF.$$.fragment),Lnr=l(),so=a("div"),F(p9.$$.fragment),ynr=l(),Xbe=a("p"),xnr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),$nr=l(),Ua=a("p"),knr=o("The model class to instantiate is selected based on the "),zbe=a("code"),Snr=o("model_type"),Rnr=o(` property of the config object (either
passed as an argument or loaded from `),Wbe=a("code"),Pnr=o("pretrained_model_name_or_path"),Bnr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qbe=a("code"),Inr=o("pretrained_model_name_or_path"),Nnr=o(":"),qnr=l(),V=a("ul"),UF=a("li"),Hbe=a("strong"),jnr=o("albert"),Dnr=o(" \u2014 "),jQ=a("a"),Gnr=o("AlbertForQuestionAnswering"),Onr=o(" (ALBERT model)"),Vnr=l(),JF=a("li"),Ube=a("strong"),Xnr=o("bart"),znr=o(" \u2014 "),DQ=a("a"),Wnr=o("BartForQuestionAnswering"),Qnr=o(" (BART model)"),Hnr=l(),YF=a("li"),Jbe=a("strong"),Unr=o("bert"),Jnr=o(" \u2014 "),GQ=a("a"),Ynr=o("BertForQuestionAnswering"),Knr=o(" (BERT model)"),Znr=l(),KF=a("li"),Ybe=a("strong"),esr=o("big_bird"),osr=o(" \u2014 "),OQ=a("a"),rsr=o("BigBirdForQuestionAnswering"),tsr=o(" (BigBird model)"),asr=l(),ZF=a("li"),Kbe=a("strong"),nsr=o("bigbird_pegasus"),ssr=o(" \u2014 "),VQ=a("a"),lsr=o("BigBirdPegasusForQuestionAnswering"),isr=o(" (BigBird-Pegasus model)"),dsr=l(),eT=a("li"),Zbe=a("strong"),csr=o("camembert"),fsr=o(" \u2014 "),XQ=a("a"),msr=o("CamembertForQuestionAnswering"),gsr=o(" (CamemBERT model)"),hsr=l(),oT=a("li"),eve=a("strong"),psr=o("canine"),_sr=o(" \u2014 "),zQ=a("a"),usr=o("CanineForQuestionAnswering"),bsr=o(" (CANINE model)"),vsr=l(),rT=a("li"),ove=a("strong"),Fsr=o("convbert"),Tsr=o(" \u2014 "),WQ=a("a"),Msr=o("ConvBertForQuestionAnswering"),Esr=o(" (ConvBERT model)"),Csr=l(),tT=a("li"),rve=a("strong"),wsr=o("data2vec-text"),Asr=o(" \u2014 "),QQ=a("a"),Lsr=o("Data2VecTextForQuestionAnswering"),ysr=o(" (Data2VecText model)"),xsr=l(),aT=a("li"),tve=a("strong"),$sr=o("deberta"),ksr=o(" \u2014 "),HQ=a("a"),Ssr=o("DebertaForQuestionAnswering"),Rsr=o(" (DeBERTa model)"),Psr=l(),nT=a("li"),ave=a("strong"),Bsr=o("deberta-v2"),Isr=o(" \u2014 "),UQ=a("a"),Nsr=o("DebertaV2ForQuestionAnswering"),qsr=o(" (DeBERTa-v2 model)"),jsr=l(),sT=a("li"),nve=a("strong"),Dsr=o("distilbert"),Gsr=o(" \u2014 "),JQ=a("a"),Osr=o("DistilBertForQuestionAnswering"),Vsr=o(" (DistilBERT model)"),Xsr=l(),lT=a("li"),sve=a("strong"),zsr=o("electra"),Wsr=o(" \u2014 "),YQ=a("a"),Qsr=o("ElectraForQuestionAnswering"),Hsr=o(" (ELECTRA model)"),Usr=l(),iT=a("li"),lve=a("strong"),Jsr=o("flaubert"),Ysr=o(" \u2014 "),KQ=a("a"),Ksr=o("FlaubertForQuestionAnsweringSimple"),Zsr=o(" (FlauBERT model)"),elr=l(),dT=a("li"),ive=a("strong"),olr=o("fnet"),rlr=o(" \u2014 "),ZQ=a("a"),tlr=o("FNetForQuestionAnswering"),alr=o(" (FNet model)"),nlr=l(),cT=a("li"),dve=a("strong"),slr=o("funnel"),llr=o(" \u2014 "),eH=a("a"),ilr=o("FunnelForQuestionAnswering"),dlr=o(" (Funnel Transformer model)"),clr=l(),fT=a("li"),cve=a("strong"),flr=o("gptj"),mlr=o(" \u2014 "),oH=a("a"),glr=o("GPTJForQuestionAnswering"),hlr=o(" (GPT-J model)"),plr=l(),mT=a("li"),fve=a("strong"),_lr=o("ibert"),ulr=o(" \u2014 "),rH=a("a"),blr=o("IBertForQuestionAnswering"),vlr=o(" (I-BERT model)"),Flr=l(),gT=a("li"),mve=a("strong"),Tlr=o("layoutlmv2"),Mlr=o(" \u2014 "),tH=a("a"),Elr=o("LayoutLMv2ForQuestionAnswering"),Clr=o(" (LayoutLMv2 model)"),wlr=l(),hT=a("li"),gve=a("strong"),Alr=o("layoutlmv3"),Llr=o(" \u2014 "),aH=a("a"),ylr=o("LayoutLMv3ForQuestionAnswering"),xlr=o(" (LayoutLMv3 model)"),$lr=l(),pT=a("li"),hve=a("strong"),klr=o("led"),Slr=o(" \u2014 "),nH=a("a"),Rlr=o("LEDForQuestionAnswering"),Plr=o(" (LED model)"),Blr=l(),_T=a("li"),pve=a("strong"),Ilr=o("longformer"),Nlr=o(" \u2014 "),sH=a("a"),qlr=o("LongformerForQuestionAnswering"),jlr=o(" (Longformer model)"),Dlr=l(),uT=a("li"),_ve=a("strong"),Glr=o("luke"),Olr=o(" \u2014 "),lH=a("a"),Vlr=o("LukeForQuestionAnswering"),Xlr=o(" (LUKE model)"),zlr=l(),bT=a("li"),uve=a("strong"),Wlr=o("lxmert"),Qlr=o(" \u2014 "),iH=a("a"),Hlr=o("LxmertForQuestionAnswering"),Ulr=o(" (LXMERT model)"),Jlr=l(),vT=a("li"),bve=a("strong"),Ylr=o("mbart"),Klr=o(" \u2014 "),dH=a("a"),Zlr=o("MBartForQuestionAnswering"),eir=o(" (mBART model)"),oir=l(),FT=a("li"),vve=a("strong"),rir=o("megatron-bert"),tir=o(" \u2014 "),cH=a("a"),air=o("MegatronBertForQuestionAnswering"),nir=o(" (Megatron-BERT model)"),sir=l(),TT=a("li"),Fve=a("strong"),lir=o("mobilebert"),iir=o(" \u2014 "),fH=a("a"),dir=o("MobileBertForQuestionAnswering"),cir=o(" (MobileBERT model)"),fir=l(),MT=a("li"),Tve=a("strong"),mir=o("mpnet"),gir=o(" \u2014 "),mH=a("a"),hir=o("MPNetForQuestionAnswering"),pir=o(" (MPNet model)"),_ir=l(),ET=a("li"),Mve=a("strong"),uir=o("mvp"),bir=o(" \u2014 "),gH=a("a"),vir=o("MvpForQuestionAnswering"),Fir=o(" (MVP model)"),Tir=l(),CT=a("li"),Eve=a("strong"),Mir=o("nezha"),Eir=o(" \u2014 "),hH=a("a"),Cir=o("NezhaForQuestionAnswering"),wir=o(" (Nezha model)"),Air=l(),wT=a("li"),Cve=a("strong"),Lir=o("nystromformer"),yir=o(" \u2014 "),pH=a("a"),xir=o("NystromformerForQuestionAnswering"),$ir=o(" (Nystr\xF6mformer model)"),kir=l(),AT=a("li"),wve=a("strong"),Sir=o("qdqbert"),Rir=o(" \u2014 "),_H=a("a"),Pir=o("QDQBertForQuestionAnswering"),Bir=o(" (QDQBert model)"),Iir=l(),LT=a("li"),Ave=a("strong"),Nir=o("reformer"),qir=o(" \u2014 "),uH=a("a"),jir=o("ReformerForQuestionAnswering"),Dir=o(" (Reformer model)"),Gir=l(),yT=a("li"),Lve=a("strong"),Oir=o("rembert"),Vir=o(" \u2014 "),bH=a("a"),Xir=o("RemBertForQuestionAnswering"),zir=o(" (RemBERT model)"),Wir=l(),xT=a("li"),yve=a("strong"),Qir=o("roberta"),Hir=o(" \u2014 "),vH=a("a"),Uir=o("RobertaForQuestionAnswering"),Jir=o(" (RoBERTa model)"),Yir=l(),$T=a("li"),xve=a("strong"),Kir=o("roformer"),Zir=o(" \u2014 "),FH=a("a"),edr=o("RoFormerForQuestionAnswering"),odr=o(" (RoFormer model)"),rdr=l(),kT=a("li"),$ve=a("strong"),tdr=o("splinter"),adr=o(" \u2014 "),TH=a("a"),ndr=o("SplinterForQuestionAnswering"),sdr=o(" (Splinter model)"),ldr=l(),ST=a("li"),kve=a("strong"),idr=o("squeezebert"),ddr=o(" \u2014 "),MH=a("a"),cdr=o("SqueezeBertForQuestionAnswering"),fdr=o(" (SqueezeBERT model)"),mdr=l(),RT=a("li"),Sve=a("strong"),gdr=o("xlm"),hdr=o(" \u2014 "),EH=a("a"),pdr=o("XLMForQuestionAnsweringSimple"),_dr=o(" (XLM model)"),udr=l(),PT=a("li"),Rve=a("strong"),bdr=o("xlm-roberta"),vdr=o(" \u2014 "),CH=a("a"),Fdr=o("XLMRobertaForQuestionAnswering"),Tdr=o(" (XLM-RoBERTa model)"),Mdr=l(),BT=a("li"),Pve=a("strong"),Edr=o("xlm-roberta-xl"),Cdr=o(" \u2014 "),wH=a("a"),wdr=o("XLMRobertaXLForQuestionAnswering"),Adr=o(" (XLM-RoBERTa-XL model)"),Ldr=l(),IT=a("li"),Bve=a("strong"),ydr=o("xlnet"),xdr=o(" \u2014 "),AH=a("a"),$dr=o("XLNetForQuestionAnsweringSimple"),kdr=o(" (XLNet model)"),Sdr=l(),NT=a("li"),Ive=a("strong"),Rdr=o("yoso"),Pdr=o(" \u2014 "),LH=a("a"),Bdr=o("YosoForQuestionAnswering"),Idr=o(" (YOSO model)"),Ndr=l(),qT=a("p"),qdr=o("The model is set in evaluation mode by default using "),Nve=a("code"),jdr=o("model.eval()"),Ddr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qve=a("code"),Gdr=o("model.train()"),Odr=l(),F(jT.$$.fragment),MQe=l(),Ad=a("h2"),DT=a("a"),jve=a("span"),F(_9.$$.fragment),Vdr=l(),Dve=a("span"),Xdr=o("AutoModelForTableQuestionAnswering"),EQe=l(),Vo=a("div"),F(u9.$$.fragment),zdr=l(),Ld=a("p"),Wdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),yH=a("a"),Qdr=o("from_pretrained()"),Hdr=o(" class method or the "),xH=a("a"),Udr=o("from_config()"),Jdr=o(` class
method.`),Ydr=l(),b9=a("p"),Kdr=o("This class cannot be instantiated directly using "),Gve=a("code"),Zdr=o("__init__()"),ecr=o(" (throws an error)."),ocr=l(),Ft=a("div"),F(v9.$$.fragment),rcr=l(),Ove=a("p"),tcr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),acr=l(),yd=a("p"),ncr=o(`Note:
Loading a model from its configuration file does `),Vve=a("strong"),scr=o("not"),lcr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=a("a"),icr=o("from_pretrained()"),dcr=o(" to load the model weights."),ccr=l(),F(GT.$$.fragment),fcr=l(),lo=a("div"),F(F9.$$.fragment),mcr=l(),Xve=a("p"),gcr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),hcr=l(),Ja=a("p"),pcr=o("The model class to instantiate is selected based on the "),zve=a("code"),_cr=o("model_type"),ucr=o(` property of the config object (either
passed as an argument or loaded from `),Wve=a("code"),bcr=o("pretrained_model_name_or_path"),vcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qve=a("code"),Fcr=o("pretrained_model_name_or_path"),Tcr=o(":"),Mcr=l(),Hve=a("ul"),OT=a("li"),Uve=a("strong"),Ecr=o("tapas"),Ccr=o(" \u2014 "),kH=a("a"),wcr=o("TapasForQuestionAnswering"),Acr=o(" (TAPAS model)"),Lcr=l(),VT=a("p"),ycr=o("The model is set in evaluation mode by default using "),Jve=a("code"),xcr=o("model.eval()"),$cr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yve=a("code"),kcr=o("model.train()"),Scr=l(),F(XT.$$.fragment),CQe=l(),xd=a("h2"),zT=a("a"),Kve=a("span"),F(T9.$$.fragment),Rcr=l(),Zve=a("span"),Pcr=o("AutoModelForImageClassification"),wQe=l(),Xo=a("div"),F(M9.$$.fragment),Bcr=l(),$d=a("p"),Icr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),SH=a("a"),Ncr=o("from_pretrained()"),qcr=o(" class method or the "),RH=a("a"),jcr=o("from_config()"),Dcr=o(` class
method.`),Gcr=l(),E9=a("p"),Ocr=o("This class cannot be instantiated directly using "),e0e=a("code"),Vcr=o("__init__()"),Xcr=o(" (throws an error)."),zcr=l(),Tt=a("div"),F(C9.$$.fragment),Wcr=l(),o0e=a("p"),Qcr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Hcr=l(),kd=a("p"),Ucr=o(`Note:
Loading a model from its configuration file does `),r0e=a("strong"),Jcr=o("not"),Ycr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),PH=a("a"),Kcr=o("from_pretrained()"),Zcr=o(" to load the model weights."),efr=l(),F(WT.$$.fragment),ofr=l(),io=a("div"),F(w9.$$.fragment),rfr=l(),t0e=a("p"),tfr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),afr=l(),Ya=a("p"),nfr=o("The model class to instantiate is selected based on the "),a0e=a("code"),sfr=o("model_type"),lfr=o(` property of the config object (either
passed as an argument or loaded from `),n0e=a("code"),ifr=o("pretrained_model_name_or_path"),dfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s0e=a("code"),cfr=o("pretrained_model_name_or_path"),ffr=o(":"),mfr=l(),be=a("ul"),QT=a("li"),l0e=a("strong"),gfr=o("beit"),hfr=o(" \u2014 "),BH=a("a"),pfr=o("BeitForImageClassification"),_fr=o(" (BEiT model)"),ufr=l(),HT=a("li"),i0e=a("strong"),bfr=o("convnext"),vfr=o(" \u2014 "),IH=a("a"),Ffr=o("ConvNextForImageClassification"),Tfr=o(" (ConvNeXT model)"),Mfr=l(),UT=a("li"),d0e=a("strong"),Efr=o("cvt"),Cfr=o(" \u2014 "),NH=a("a"),wfr=o("CvtForImageClassification"),Afr=o(" (CvT model)"),Lfr=l(),JT=a("li"),c0e=a("strong"),yfr=o("data2vec-vision"),xfr=o(" \u2014 "),qH=a("a"),$fr=o("Data2VecVisionForImageClassification"),kfr=o(" (Data2VecVision model)"),Sfr=l(),rl=a("li"),f0e=a("strong"),Rfr=o("deit"),Pfr=o(" \u2014 "),jH=a("a"),Bfr=o("DeiTForImageClassification"),Ifr=o(" or "),DH=a("a"),Nfr=o("DeiTForImageClassificationWithTeacher"),qfr=o(" (DeiT model)"),jfr=l(),YT=a("li"),m0e=a("strong"),Dfr=o("imagegpt"),Gfr=o(" \u2014 "),GH=a("a"),Ofr=o("ImageGPTForImageClassification"),Vfr=o(" (ImageGPT model)"),Xfr=l(),tl=a("li"),g0e=a("strong"),zfr=o("levit"),Wfr=o(" \u2014 "),OH=a("a"),Qfr=o("LevitForImageClassification"),Hfr=o(" or "),VH=a("a"),Ufr=o("LevitForImageClassificationWithTeacher"),Jfr=o(" (LeViT model)"),Yfr=l(),KT=a("li"),h0e=a("strong"),Kfr=o("mobilevit"),Zfr=o(" \u2014 "),XH=a("a"),emr=o("MobileViTForImageClassification"),omr=o(" (MobileViT model)"),rmr=l(),Mt=a("li"),p0e=a("strong"),tmr=o("perceiver"),amr=o(" \u2014 "),zH=a("a"),nmr=o("PerceiverForImageClassificationLearned"),smr=o(" or "),WH=a("a"),lmr=o("PerceiverForImageClassificationFourier"),imr=o(" or "),QH=a("a"),dmr=o("PerceiverForImageClassificationConvProcessing"),cmr=o(" (Perceiver model)"),fmr=l(),ZT=a("li"),_0e=a("strong"),mmr=o("poolformer"),gmr=o(" \u2014 "),HH=a("a"),hmr=o("PoolFormerForImageClassification"),pmr=o(" (PoolFormer model)"),_mr=l(),e8=a("li"),u0e=a("strong"),umr=o("regnet"),bmr=o(" \u2014 "),UH=a("a"),vmr=o("RegNetForImageClassification"),Fmr=o(" (RegNet model)"),Tmr=l(),o8=a("li"),b0e=a("strong"),Mmr=o("resnet"),Emr=o(" \u2014 "),JH=a("a"),Cmr=o("ResNetForImageClassification"),wmr=o(" (ResNet model)"),Amr=l(),r8=a("li"),v0e=a("strong"),Lmr=o("segformer"),ymr=o(" \u2014 "),YH=a("a"),xmr=o("SegformerForImageClassification"),$mr=o(" (SegFormer model)"),kmr=l(),t8=a("li"),F0e=a("strong"),Smr=o("swin"),Rmr=o(" \u2014 "),KH=a("a"),Pmr=o("SwinForImageClassification"),Bmr=o(" (Swin Transformer model)"),Imr=l(),a8=a("li"),T0e=a("strong"),Nmr=o("swinv2"),qmr=o(" \u2014 "),ZH=a("a"),jmr=o("Swinv2ForImageClassification"),Dmr=o(" (Swin Transformer V2 model)"),Gmr=l(),n8=a("li"),M0e=a("strong"),Omr=o("van"),Vmr=o(" \u2014 "),eU=a("a"),Xmr=o("VanForImageClassification"),zmr=o(" (VAN model)"),Wmr=l(),s8=a("li"),E0e=a("strong"),Qmr=o("vit"),Hmr=o(" \u2014 "),oU=a("a"),Umr=o("ViTForImageClassification"),Jmr=o(" (ViT model)"),Ymr=l(),l8=a("p"),Kmr=o("The model is set in evaluation mode by default using "),C0e=a("code"),Zmr=o("model.eval()"),egr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w0e=a("code"),ogr=o("model.train()"),rgr=l(),F(i8.$$.fragment),AQe=l(),Sd=a("h2"),d8=a("a"),A0e=a("span"),F(A9.$$.fragment),tgr=l(),L0e=a("span"),agr=o("AutoModelForVideoClassification"),LQe=l(),zo=a("div"),F(L9.$$.fragment),ngr=l(),Rd=a("p"),sgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),rU=a("a"),lgr=o("from_pretrained()"),igr=o(" class method or the "),tU=a("a"),dgr=o("from_config()"),cgr=o(` class
method.`),fgr=l(),y9=a("p"),mgr=o("This class cannot be instantiated directly using "),y0e=a("code"),ggr=o("__init__()"),hgr=o(" (throws an error)."),pgr=l(),Et=a("div"),F(x9.$$.fragment),_gr=l(),x0e=a("p"),ugr=o("Instantiates one of the model classes of the library (with a video classification head) from a configuration."),bgr=l(),Pd=a("p"),vgr=o(`Note:
Loading a model from its configuration file does `),$0e=a("strong"),Fgr=o("not"),Tgr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aU=a("a"),Mgr=o("from_pretrained()"),Egr=o(" to load the model weights."),Cgr=l(),F(c8.$$.fragment),wgr=l(),co=a("div"),F($9.$$.fragment),Agr=l(),k0e=a("p"),Lgr=o("Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),ygr=l(),Ka=a("p"),xgr=o("The model class to instantiate is selected based on the "),S0e=a("code"),$gr=o("model_type"),kgr=o(` property of the config object (either
passed as an argument or loaded from `),R0e=a("code"),Sgr=o("pretrained_model_name_or_path"),Rgr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P0e=a("code"),Pgr=o("pretrained_model_name_or_path"),Bgr=o(":"),Igr=l(),B0e=a("ul"),f8=a("li"),I0e=a("strong"),Ngr=o("videomae"),qgr=o(" \u2014 "),nU=a("a"),jgr=o("VideoMAEForVideoClassification"),Dgr=o(" (VideoMAE model)"),Ggr=l(),m8=a("p"),Ogr=o("The model is set in evaluation mode by default using "),N0e=a("code"),Vgr=o("model.eval()"),Xgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q0e=a("code"),zgr=o("model.train()"),Wgr=l(),F(g8.$$.fragment),yQe=l(),Bd=a("h2"),h8=a("a"),j0e=a("span"),F(k9.$$.fragment),Qgr=l(),D0e=a("span"),Hgr=o("AutoModelForVision2Seq"),xQe=l(),Wo=a("div"),F(S9.$$.fragment),Ugr=l(),Id=a("p"),Jgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),sU=a("a"),Ygr=o("from_pretrained()"),Kgr=o(" class method or the "),lU=a("a"),Zgr=o("from_config()"),ehr=o(` class
method.`),ohr=l(),R9=a("p"),rhr=o("This class cannot be instantiated directly using "),G0e=a("code"),thr=o("__init__()"),ahr=o(" (throws an error)."),nhr=l(),Ct=a("div"),F(P9.$$.fragment),shr=l(),O0e=a("p"),lhr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),ihr=l(),Nd=a("p"),dhr=o(`Note:
Loading a model from its configuration file does `),V0e=a("strong"),chr=o("not"),fhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iU=a("a"),mhr=o("from_pretrained()"),ghr=o(" to load the model weights."),hhr=l(),F(p8.$$.fragment),phr=l(),fo=a("div"),F(B9.$$.fragment),_hr=l(),X0e=a("p"),uhr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),bhr=l(),Za=a("p"),vhr=o("The model class to instantiate is selected based on the "),z0e=a("code"),Fhr=o("model_type"),Thr=o(` property of the config object (either
passed as an argument or loaded from `),W0e=a("code"),Mhr=o("pretrained_model_name_or_path"),Ehr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q0e=a("code"),Chr=o("pretrained_model_name_or_path"),whr=o(":"),Ahr=l(),H0e=a("ul"),_8=a("li"),U0e=a("strong"),Lhr=o("vision-encoder-decoder"),yhr=o(" \u2014 "),dU=a("a"),xhr=o("VisionEncoderDecoderModel"),$hr=o(" (Vision Encoder decoder model)"),khr=l(),u8=a("p"),Shr=o("The model is set in evaluation mode by default using "),J0e=a("code"),Rhr=o("model.eval()"),Phr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y0e=a("code"),Bhr=o("model.train()"),Ihr=l(),F(b8.$$.fragment),$Qe=l(),qd=a("h2"),v8=a("a"),K0e=a("span"),F(I9.$$.fragment),Nhr=l(),Z0e=a("span"),qhr=o("AutoModelForVisualQuestionAnswering"),kQe=l(),Qo=a("div"),F(N9.$$.fragment),jhr=l(),jd=a("p"),Dhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),cU=a("a"),Ghr=o("from_pretrained()"),Ohr=o(" class method or the "),fU=a("a"),Vhr=o("from_config()"),Xhr=o(` class
method.`),zhr=l(),q9=a("p"),Whr=o("This class cannot be instantiated directly using "),eFe=a("code"),Qhr=o("__init__()"),Hhr=o(" (throws an error)."),Uhr=l(),wt=a("div"),F(j9.$$.fragment),Jhr=l(),oFe=a("p"),Yhr=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Khr=l(),Dd=a("p"),Zhr=o(`Note:
Loading a model from its configuration file does `),rFe=a("strong"),epr=o("not"),opr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mU=a("a"),rpr=o("from_pretrained()"),tpr=o(" to load the model weights."),apr=l(),F(F8.$$.fragment),npr=l(),mo=a("div"),F(D9.$$.fragment),spr=l(),tFe=a("p"),lpr=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),ipr=l(),en=a("p"),dpr=o("The model class to instantiate is selected based on the "),aFe=a("code"),cpr=o("model_type"),fpr=o(` property of the config object (either
passed as an argument or loaded from `),nFe=a("code"),mpr=o("pretrained_model_name_or_path"),gpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=a("code"),hpr=o("pretrained_model_name_or_path"),ppr=o(":"),_pr=l(),lFe=a("ul"),T8=a("li"),iFe=a("strong"),upr=o("vilt"),bpr=o(" \u2014 "),gU=a("a"),vpr=o("ViltForQuestionAnswering"),Fpr=o(" (ViLT model)"),Tpr=l(),M8=a("p"),Mpr=o("The model is set in evaluation mode by default using "),dFe=a("code"),Epr=o("model.eval()"),Cpr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cFe=a("code"),wpr=o("model.train()"),Apr=l(),F(E8.$$.fragment),SQe=l(),Gd=a("h2"),C8=a("a"),fFe=a("span"),F(G9.$$.fragment),Lpr=l(),mFe=a("span"),ypr=o("AutoModelForAudioClassification"),RQe=l(),Ho=a("div"),F(O9.$$.fragment),xpr=l(),Od=a("p"),$pr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),hU=a("a"),kpr=o("from_pretrained()"),Spr=o(" class method or the "),pU=a("a"),Rpr=o("from_config()"),Ppr=o(` class
method.`),Bpr=l(),V9=a("p"),Ipr=o("This class cannot be instantiated directly using "),gFe=a("code"),Npr=o("__init__()"),qpr=o(" (throws an error)."),jpr=l(),At=a("div"),F(X9.$$.fragment),Dpr=l(),hFe=a("p"),Gpr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Opr=l(),Vd=a("p"),Vpr=o(`Note:
Loading a model from its configuration file does `),pFe=a("strong"),Xpr=o("not"),zpr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_U=a("a"),Wpr=o("from_pretrained()"),Qpr=o(" to load the model weights."),Hpr=l(),F(w8.$$.fragment),Upr=l(),go=a("div"),F(z9.$$.fragment),Jpr=l(),_Fe=a("p"),Ypr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Kpr=l(),on=a("p"),Zpr=o("The model class to instantiate is selected based on the "),uFe=a("code"),e_r=o("model_type"),o_r=o(` property of the config object (either
passed as an argument or loaded from `),bFe=a("code"),r_r=o("pretrained_model_name_or_path"),t_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vFe=a("code"),a_r=o("pretrained_model_name_or_path"),n_r=o(":"),s_r=l(),Be=a("ul"),A8=a("li"),FFe=a("strong"),l_r=o("data2vec-audio"),i_r=o(" \u2014 "),uU=a("a"),d_r=o("Data2VecAudioForSequenceClassification"),c_r=o(" (Data2VecAudio model)"),f_r=l(),L8=a("li"),TFe=a("strong"),m_r=o("hubert"),g_r=o(" \u2014 "),bU=a("a"),h_r=o("HubertForSequenceClassification"),p_r=o(" (Hubert model)"),__r=l(),y8=a("li"),MFe=a("strong"),u_r=o("sew"),b_r=o(" \u2014 "),vU=a("a"),v_r=o("SEWForSequenceClassification"),F_r=o(" (SEW model)"),T_r=l(),x8=a("li"),EFe=a("strong"),M_r=o("sew-d"),E_r=o(" \u2014 "),FU=a("a"),C_r=o("SEWDForSequenceClassification"),w_r=o(" (SEW-D model)"),A_r=l(),$8=a("li"),CFe=a("strong"),L_r=o("unispeech"),y_r=o(" \u2014 "),TU=a("a"),x_r=o("UniSpeechForSequenceClassification"),$_r=o(" (UniSpeech model)"),k_r=l(),k8=a("li"),wFe=a("strong"),S_r=o("unispeech-sat"),R_r=o(" \u2014 "),MU=a("a"),P_r=o("UniSpeechSatForSequenceClassification"),B_r=o(" (UniSpeechSat model)"),I_r=l(),S8=a("li"),AFe=a("strong"),N_r=o("wav2vec2"),q_r=o(" \u2014 "),EU=a("a"),j_r=o("Wav2Vec2ForSequenceClassification"),D_r=o(" (Wav2Vec2 model)"),G_r=l(),R8=a("li"),LFe=a("strong"),O_r=o("wav2vec2-conformer"),V_r=o(" \u2014 "),CU=a("a"),X_r=o("Wav2Vec2ConformerForSequenceClassification"),z_r=o(" (Wav2Vec2-Conformer model)"),W_r=l(),P8=a("li"),yFe=a("strong"),Q_r=o("wavlm"),H_r=o(" \u2014 "),wU=a("a"),U_r=o("WavLMForSequenceClassification"),J_r=o(" (WavLM model)"),Y_r=l(),B8=a("p"),K_r=o("The model is set in evaluation mode by default using "),xFe=a("code"),Z_r=o("model.eval()"),eur=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$Fe=a("code"),our=o("model.train()"),rur=l(),F(I8.$$.fragment),PQe=l(),Xd=a("h2"),N8=a("a"),kFe=a("span"),F(W9.$$.fragment),tur=l(),SFe=a("span"),aur=o("AutoModelForAudioFrameClassification"),BQe=l(),Uo=a("div"),F(Q9.$$.fragment),nur=l(),zd=a("p"),sur=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),AU=a("a"),lur=o("from_pretrained()"),iur=o(" class method or the "),LU=a("a"),dur=o("from_config()"),cur=o(` class
method.`),fur=l(),H9=a("p"),mur=o("This class cannot be instantiated directly using "),RFe=a("code"),gur=o("__init__()"),hur=o(" (throws an error)."),pur=l(),Lt=a("div"),F(U9.$$.fragment),_ur=l(),PFe=a("p"),uur=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),bur=l(),Wd=a("p"),vur=o(`Note:
Loading a model from its configuration file does `),BFe=a("strong"),Fur=o("not"),Tur=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yU=a("a"),Mur=o("from_pretrained()"),Eur=o(" to load the model weights."),Cur=l(),F(q8.$$.fragment),wur=l(),ho=a("div"),F(J9.$$.fragment),Aur=l(),IFe=a("p"),Lur=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),yur=l(),rn=a("p"),xur=o("The model class to instantiate is selected based on the "),NFe=a("code"),$ur=o("model_type"),kur=o(` property of the config object (either
passed as an argument or loaded from `),qFe=a("code"),Sur=o("pretrained_model_name_or_path"),Rur=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jFe=a("code"),Pur=o("pretrained_model_name_or_path"),Bur=o(":"),Iur=l(),at=a("ul"),j8=a("li"),DFe=a("strong"),Nur=o("data2vec-audio"),qur=o(" \u2014 "),xU=a("a"),jur=o("Data2VecAudioForAudioFrameClassification"),Dur=o(" (Data2VecAudio model)"),Gur=l(),D8=a("li"),GFe=a("strong"),Our=o("unispeech-sat"),Vur=o(" \u2014 "),$U=a("a"),Xur=o("UniSpeechSatForAudioFrameClassification"),zur=o(" (UniSpeechSat model)"),Wur=l(),G8=a("li"),OFe=a("strong"),Qur=o("wav2vec2"),Hur=o(" \u2014 "),kU=a("a"),Uur=o("Wav2Vec2ForAudioFrameClassification"),Jur=o(" (Wav2Vec2 model)"),Yur=l(),O8=a("li"),VFe=a("strong"),Kur=o("wav2vec2-conformer"),Zur=o(" \u2014 "),SU=a("a"),e2r=o("Wav2Vec2ConformerForAudioFrameClassification"),o2r=o(" (Wav2Vec2-Conformer model)"),r2r=l(),V8=a("li"),XFe=a("strong"),t2r=o("wavlm"),a2r=o(" \u2014 "),RU=a("a"),n2r=o("WavLMForAudioFrameClassification"),s2r=o(" (WavLM model)"),l2r=l(),X8=a("p"),i2r=o("The model is set in evaluation mode by default using "),zFe=a("code"),d2r=o("model.eval()"),c2r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),WFe=a("code"),f2r=o("model.train()"),m2r=l(),F(z8.$$.fragment),IQe=l(),Qd=a("h2"),W8=a("a"),QFe=a("span"),F(Y9.$$.fragment),g2r=l(),HFe=a("span"),h2r=o("AutoModelForCTC"),NQe=l(),Jo=a("div"),F(K9.$$.fragment),p2r=l(),Hd=a("p"),_2r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),PU=a("a"),u2r=o("from_pretrained()"),b2r=o(" class method or the "),BU=a("a"),v2r=o("from_config()"),F2r=o(` class
method.`),T2r=l(),Z9=a("p"),M2r=o("This class cannot be instantiated directly using "),UFe=a("code"),E2r=o("__init__()"),C2r=o(" (throws an error)."),w2r=l(),yt=a("div"),F(ex.$$.fragment),A2r=l(),JFe=a("p"),L2r=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),y2r=l(),Ud=a("p"),x2r=o(`Note:
Loading a model from its configuration file does `),YFe=a("strong"),$2r=o("not"),k2r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IU=a("a"),S2r=o("from_pretrained()"),R2r=o(" to load the model weights."),P2r=l(),F(Q8.$$.fragment),B2r=l(),po=a("div"),F(ox.$$.fragment),I2r=l(),KFe=a("p"),N2r=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),q2r=l(),tn=a("p"),j2r=o("The model class to instantiate is selected based on the "),ZFe=a("code"),D2r=o("model_type"),G2r=o(` property of the config object (either
passed as an argument or loaded from `),eTe=a("code"),O2r=o("pretrained_model_name_or_path"),V2r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oTe=a("code"),X2r=o("pretrained_model_name_or_path"),z2r=o(":"),W2r=l(),ye=a("ul"),H8=a("li"),rTe=a("strong"),Q2r=o("data2vec-audio"),H2r=o(" \u2014 "),NU=a("a"),U2r=o("Data2VecAudioForCTC"),J2r=o(" (Data2VecAudio model)"),Y2r=l(),U8=a("li"),tTe=a("strong"),K2r=o("hubert"),Z2r=o(" \u2014 "),qU=a("a"),e1r=o("HubertForCTC"),o1r=o(" (Hubert model)"),r1r=l(),J8=a("li"),aTe=a("strong"),t1r=o("mctct"),a1r=o(" \u2014 "),jU=a("a"),n1r=o("MCTCTForCTC"),s1r=o(" (M-CTC-T model)"),l1r=l(),Y8=a("li"),nTe=a("strong"),i1r=o("sew"),d1r=o(" \u2014 "),DU=a("a"),c1r=o("SEWForCTC"),f1r=o(" (SEW model)"),m1r=l(),K8=a("li"),sTe=a("strong"),g1r=o("sew-d"),h1r=o(" \u2014 "),GU=a("a"),p1r=o("SEWDForCTC"),_1r=o(" (SEW-D model)"),u1r=l(),Z8=a("li"),lTe=a("strong"),b1r=o("unispeech"),v1r=o(" \u2014 "),OU=a("a"),F1r=o("UniSpeechForCTC"),T1r=o(" (UniSpeech model)"),M1r=l(),eM=a("li"),iTe=a("strong"),E1r=o("unispeech-sat"),C1r=o(" \u2014 "),VU=a("a"),w1r=o("UniSpeechSatForCTC"),A1r=o(" (UniSpeechSat model)"),L1r=l(),oM=a("li"),dTe=a("strong"),y1r=o("wav2vec2"),x1r=o(" \u2014 "),XU=a("a"),$1r=o("Wav2Vec2ForCTC"),k1r=o(" (Wav2Vec2 model)"),S1r=l(),rM=a("li"),cTe=a("strong"),R1r=o("wav2vec2-conformer"),P1r=o(" \u2014 "),zU=a("a"),B1r=o("Wav2Vec2ConformerForCTC"),I1r=o(" (Wav2Vec2-Conformer model)"),N1r=l(),tM=a("li"),fTe=a("strong"),q1r=o("wavlm"),j1r=o(" \u2014 "),WU=a("a"),D1r=o("WavLMForCTC"),G1r=o(" (WavLM model)"),O1r=l(),aM=a("p"),V1r=o("The model is set in evaluation mode by default using "),mTe=a("code"),X1r=o("model.eval()"),z1r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gTe=a("code"),W1r=o("model.train()"),Q1r=l(),F(nM.$$.fragment),qQe=l(),Jd=a("h2"),sM=a("a"),hTe=a("span"),F(rx.$$.fragment),H1r=l(),pTe=a("span"),U1r=o("AutoModelForSpeechSeq2Seq"),jQe=l(),Yo=a("div"),F(tx.$$.fragment),J1r=l(),Yd=a("p"),Y1r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),QU=a("a"),K1r=o("from_pretrained()"),Z1r=o(" class method or the "),HU=a("a"),ebr=o("from_config()"),obr=o(` class
method.`),rbr=l(),ax=a("p"),tbr=o("This class cannot be instantiated directly using "),_Te=a("code"),abr=o("__init__()"),nbr=o(" (throws an error)."),sbr=l(),xt=a("div"),F(nx.$$.fragment),lbr=l(),uTe=a("p"),ibr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dbr=l(),Kd=a("p"),cbr=o(`Note:
Loading a model from its configuration file does `),bTe=a("strong"),fbr=o("not"),mbr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),UU=a("a"),gbr=o("from_pretrained()"),hbr=o(" to load the model weights."),pbr=l(),F(lM.$$.fragment),_br=l(),_o=a("div"),F(sx.$$.fragment),ubr=l(),vTe=a("p"),bbr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),vbr=l(),an=a("p"),Fbr=o("The model class to instantiate is selected based on the "),FTe=a("code"),Tbr=o("model_type"),Mbr=o(` property of the config object (either
passed as an argument or loaded from `),TTe=a("code"),Ebr=o("pretrained_model_name_or_path"),Cbr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=a("code"),wbr=o("pretrained_model_name_or_path"),Abr=o(":"),Lbr=l(),lx=a("ul"),iM=a("li"),ETe=a("strong"),ybr=o("speech-encoder-decoder"),xbr=o(" \u2014 "),JU=a("a"),$br=o("SpeechEncoderDecoderModel"),kbr=o(" (Speech Encoder decoder model)"),Sbr=l(),dM=a("li"),CTe=a("strong"),Rbr=o("speech_to_text"),Pbr=o(" \u2014 "),YU=a("a"),Bbr=o("Speech2TextForConditionalGeneration"),Ibr=o(" (Speech2Text model)"),Nbr=l(),cM=a("p"),qbr=o("The model is set in evaluation mode by default using "),wTe=a("code"),jbr=o("model.eval()"),Dbr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ATe=a("code"),Gbr=o("model.train()"),Obr=l(),F(fM.$$.fragment),DQe=l(),Zd=a("h2"),mM=a("a"),LTe=a("span"),F(ix.$$.fragment),Vbr=l(),yTe=a("span"),Xbr=o("AutoModelForAudioXVector"),GQe=l(),Ko=a("div"),F(dx.$$.fragment),zbr=l(),ec=a("p"),Wbr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),KU=a("a"),Qbr=o("from_pretrained()"),Hbr=o(" class method or the "),ZU=a("a"),Ubr=o("from_config()"),Jbr=o(` class
method.`),Ybr=l(),cx=a("p"),Kbr=o("This class cannot be instantiated directly using "),xTe=a("code"),Zbr=o("__init__()"),evr=o(" (throws an error)."),ovr=l(),$t=a("div"),F(fx.$$.fragment),rvr=l(),$Te=a("p"),tvr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),avr=l(),oc=a("p"),nvr=o(`Note:
Loading a model from its configuration file does `),kTe=a("strong"),svr=o("not"),lvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=a("a"),ivr=o("from_pretrained()"),dvr=o(" to load the model weights."),cvr=l(),F(gM.$$.fragment),fvr=l(),uo=a("div"),F(mx.$$.fragment),mvr=l(),STe=a("p"),gvr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),hvr=l(),nn=a("p"),pvr=o("The model class to instantiate is selected based on the "),RTe=a("code"),_vr=o("model_type"),uvr=o(` property of the config object (either
passed as an argument or loaded from `),PTe=a("code"),bvr=o("pretrained_model_name_or_path"),vvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BTe=a("code"),Fvr=o("pretrained_model_name_or_path"),Tvr=o(":"),Mvr=l(),nt=a("ul"),hM=a("li"),ITe=a("strong"),Evr=o("data2vec-audio"),Cvr=o(" \u2014 "),oJ=a("a"),wvr=o("Data2VecAudioForXVector"),Avr=o(" (Data2VecAudio model)"),Lvr=l(),pM=a("li"),NTe=a("strong"),yvr=o("unispeech-sat"),xvr=o(" \u2014 "),rJ=a("a"),$vr=o("UniSpeechSatForXVector"),kvr=o(" (UniSpeechSat model)"),Svr=l(),_M=a("li"),qTe=a("strong"),Rvr=o("wav2vec2"),Pvr=o(" \u2014 "),tJ=a("a"),Bvr=o("Wav2Vec2ForXVector"),Ivr=o(" (Wav2Vec2 model)"),Nvr=l(),uM=a("li"),jTe=a("strong"),qvr=o("wav2vec2-conformer"),jvr=o(" \u2014 "),aJ=a("a"),Dvr=o("Wav2Vec2ConformerForXVector"),Gvr=o(" (Wav2Vec2-Conformer model)"),Ovr=l(),bM=a("li"),DTe=a("strong"),Vvr=o("wavlm"),Xvr=o(" \u2014 "),nJ=a("a"),zvr=o("WavLMForXVector"),Wvr=o(" (WavLM model)"),Qvr=l(),vM=a("p"),Hvr=o("The model is set in evaluation mode by default using "),GTe=a("code"),Uvr=o("model.eval()"),Jvr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),OTe=a("code"),Yvr=o("model.train()"),Kvr=l(),F(FM.$$.fragment),OQe=l(),rc=a("h2"),TM=a("a"),VTe=a("span"),F(gx.$$.fragment),Zvr=l(),XTe=a("span"),e0r=o("AutoModelForMaskedImageModeling"),VQe=l(),Zo=a("div"),F(hx.$$.fragment),o0r=l(),tc=a("p"),r0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),sJ=a("a"),t0r=o("from_pretrained()"),a0r=o(" class method or the "),lJ=a("a"),n0r=o("from_config()"),s0r=o(` class
method.`),l0r=l(),px=a("p"),i0r=o("This class cannot be instantiated directly using "),zTe=a("code"),d0r=o("__init__()"),c0r=o(" (throws an error)."),f0r=l(),kt=a("div"),F(_x.$$.fragment),m0r=l(),WTe=a("p"),g0r=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),h0r=l(),ac=a("p"),p0r=o(`Note:
Loading a model from its configuration file does `),QTe=a("strong"),_0r=o("not"),u0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),iJ=a("a"),b0r=o("from_pretrained()"),v0r=o(" to load the model weights."),F0r=l(),F(MM.$$.fragment),T0r=l(),bo=a("div"),F(ux.$$.fragment),M0r=l(),HTe=a("p"),E0r=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),C0r=l(),sn=a("p"),w0r=o("The model class to instantiate is selected based on the "),UTe=a("code"),A0r=o("model_type"),L0r=o(` property of the config object (either
passed as an argument or loaded from `),JTe=a("code"),y0r=o("pretrained_model_name_or_path"),x0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YTe=a("code"),$0r=o("pretrained_model_name_or_path"),k0r=o(":"),S0r=l(),ln=a("ul"),EM=a("li"),KTe=a("strong"),R0r=o("deit"),P0r=o(" \u2014 "),dJ=a("a"),B0r=o("DeiTForMaskedImageModeling"),I0r=o(" (DeiT model)"),N0r=l(),CM=a("li"),ZTe=a("strong"),q0r=o("swin"),j0r=o(" \u2014 "),cJ=a("a"),D0r=o("SwinForMaskedImageModeling"),G0r=o(" (Swin Transformer model)"),O0r=l(),wM=a("li"),e8e=a("strong"),V0r=o("swinv2"),X0r=o(" \u2014 "),fJ=a("a"),z0r=o("Swinv2ForMaskedImageModeling"),W0r=o(" (Swin Transformer V2 model)"),Q0r=l(),AM=a("li"),o8e=a("strong"),H0r=o("vit"),U0r=o(" \u2014 "),mJ=a("a"),J0r=o("ViTForMaskedImageModeling"),Y0r=o(" (ViT model)"),K0r=l(),LM=a("p"),Z0r=o("The model is set in evaluation mode by default using "),r8e=a("code"),eFr=o("model.eval()"),oFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t8e=a("code"),rFr=o("model.train()"),tFr=l(),F(yM.$$.fragment),XQe=l(),nc=a("h2"),xM=a("a"),a8e=a("span"),F(bx.$$.fragment),aFr=l(),n8e=a("span"),nFr=o("AutoModelForObjectDetection"),zQe=l(),er=a("div"),F(vx.$$.fragment),sFr=l(),sc=a("p"),lFr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),gJ=a("a"),iFr=o("from_pretrained()"),dFr=o(" class method or the "),hJ=a("a"),cFr=o("from_config()"),fFr=o(` class
method.`),mFr=l(),Fx=a("p"),gFr=o("This class cannot be instantiated directly using "),s8e=a("code"),hFr=o("__init__()"),pFr=o(" (throws an error)."),_Fr=l(),St=a("div"),F(Tx.$$.fragment),uFr=l(),l8e=a("p"),bFr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),vFr=l(),lc=a("p"),FFr=o(`Note:
Loading a model from its configuration file does `),i8e=a("strong"),TFr=o("not"),MFr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pJ=a("a"),EFr=o("from_pretrained()"),CFr=o(" to load the model weights."),wFr=l(),F($M.$$.fragment),AFr=l(),vo=a("div"),F(Mx.$$.fragment),LFr=l(),d8e=a("p"),yFr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),xFr=l(),dn=a("p"),$Fr=o("The model class to instantiate is selected based on the "),c8e=a("code"),kFr=o("model_type"),SFr=o(` property of the config object (either
passed as an argument or loaded from `),f8e=a("code"),RFr=o("pretrained_model_name_or_path"),PFr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m8e=a("code"),BFr=o("pretrained_model_name_or_path"),IFr=o(":"),NFr=l(),Ex=a("ul"),kM=a("li"),g8e=a("strong"),qFr=o("detr"),jFr=o(" \u2014 "),_J=a("a"),DFr=o("DetrForObjectDetection"),GFr=o(" (DETR model)"),OFr=l(),SM=a("li"),h8e=a("strong"),VFr=o("yolos"),XFr=o(" \u2014 "),uJ=a("a"),zFr=o("YolosForObjectDetection"),WFr=o(" (YOLOS model)"),QFr=l(),RM=a("p"),HFr=o("The model is set in evaluation mode by default using "),p8e=a("code"),UFr=o("model.eval()"),JFr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_8e=a("code"),YFr=o("model.train()"),KFr=l(),F(PM.$$.fragment),WQe=l(),ic=a("h2"),BM=a("a"),u8e=a("span"),F(Cx.$$.fragment),ZFr=l(),b8e=a("span"),eTr=o("AutoModelForImageSegmentation"),QQe=l(),or=a("div"),F(wx.$$.fragment),oTr=l(),dc=a("p"),rTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),bJ=a("a"),tTr=o("from_pretrained()"),aTr=o(" class method or the "),vJ=a("a"),nTr=o("from_config()"),sTr=o(` class
method.`),lTr=l(),Ax=a("p"),iTr=o("This class cannot be instantiated directly using "),v8e=a("code"),dTr=o("__init__()"),cTr=o(" (throws an error)."),fTr=l(),Rt=a("div"),F(Lx.$$.fragment),mTr=l(),F8e=a("p"),gTr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),hTr=l(),cc=a("p"),pTr=o(`Note:
Loading a model from its configuration file does `),T8e=a("strong"),_Tr=o("not"),uTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),FJ=a("a"),bTr=o("from_pretrained()"),vTr=o(" to load the model weights."),FTr=l(),F(IM.$$.fragment),TTr=l(),Fo=a("div"),F(yx.$$.fragment),MTr=l(),M8e=a("p"),ETr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),CTr=l(),cn=a("p"),wTr=o("The model class to instantiate is selected based on the "),E8e=a("code"),ATr=o("model_type"),LTr=o(` property of the config object (either
passed as an argument or loaded from `),C8e=a("code"),yTr=o("pretrained_model_name_or_path"),xTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w8e=a("code"),$Tr=o("pretrained_model_name_or_path"),kTr=o(":"),STr=l(),A8e=a("ul"),NM=a("li"),L8e=a("strong"),RTr=o("detr"),PTr=o(" \u2014 "),TJ=a("a"),BTr=o("DetrForSegmentation"),ITr=o(" (DETR model)"),NTr=l(),qM=a("p"),qTr=o("The model is set in evaluation mode by default using "),y8e=a("code"),jTr=o("model.eval()"),DTr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x8e=a("code"),GTr=o("model.train()"),OTr=l(),F(jM.$$.fragment),HQe=l(),fc=a("h2"),DM=a("a"),$8e=a("span"),F(xx.$$.fragment),VTr=l(),k8e=a("span"),XTr=o("AutoModelForSemanticSegmentation"),UQe=l(),rr=a("div"),F($x.$$.fragment),zTr=l(),mc=a("p"),WTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),MJ=a("a"),QTr=o("from_pretrained()"),HTr=o(" class method or the "),EJ=a("a"),UTr=o("from_config()"),JTr=o(` class
method.`),YTr=l(),kx=a("p"),KTr=o("This class cannot be instantiated directly using "),S8e=a("code"),ZTr=o("__init__()"),e8r=o(" (throws an error)."),o8r=l(),Pt=a("div"),F(Sx.$$.fragment),r8r=l(),R8e=a("p"),t8r=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),a8r=l(),gc=a("p"),n8r=o(`Note:
Loading a model from its configuration file does `),P8e=a("strong"),s8r=o("not"),l8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CJ=a("a"),i8r=o("from_pretrained()"),d8r=o(" to load the model weights."),c8r=l(),F(GM.$$.fragment),f8r=l(),To=a("div"),F(Rx.$$.fragment),m8r=l(),B8e=a("p"),g8r=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),h8r=l(),fn=a("p"),p8r=o("The model class to instantiate is selected based on the "),I8e=a("code"),_8r=o("model_type"),u8r=o(` property of the config object (either
passed as an argument or loaded from `),N8e=a("code"),b8r=o("pretrained_model_name_or_path"),v8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q8e=a("code"),F8r=o("pretrained_model_name_or_path"),T8r=o(":"),M8r=l(),st=a("ul"),OM=a("li"),j8e=a("strong"),E8r=o("beit"),C8r=o(" \u2014 "),wJ=a("a"),w8r=o("BeitForSemanticSegmentation"),A8r=o(" (BEiT model)"),L8r=l(),VM=a("li"),D8e=a("strong"),y8r=o("data2vec-vision"),x8r=o(" \u2014 "),AJ=a("a"),$8r=o("Data2VecVisionForSemanticSegmentation"),k8r=o(" (Data2VecVision model)"),S8r=l(),XM=a("li"),G8e=a("strong"),R8r=o("dpt"),P8r=o(" \u2014 "),LJ=a("a"),B8r=o("DPTForSemanticSegmentation"),I8r=o(" (DPT model)"),N8r=l(),zM=a("li"),O8e=a("strong"),q8r=o("mobilevit"),j8r=o(" \u2014 "),yJ=a("a"),D8r=o("MobileViTForSemanticSegmentation"),G8r=o(" (MobileViT model)"),O8r=l(),WM=a("li"),V8e=a("strong"),V8r=o("segformer"),X8r=o(" \u2014 "),xJ=a("a"),z8r=o("SegformerForSemanticSegmentation"),W8r=o(" (SegFormer model)"),Q8r=l(),QM=a("p"),H8r=o("The model is set in evaluation mode by default using "),X8e=a("code"),U8r=o("model.eval()"),J8r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z8e=a("code"),Y8r=o("model.train()"),K8r=l(),F(HM.$$.fragment),JQe=l(),hc=a("h2"),UM=a("a"),W8e=a("span"),F(Px.$$.fragment),Z8r=l(),Q8e=a("span"),eMr=o("AutoModelForInstanceSegmentation"),YQe=l(),tr=a("div"),F(Bx.$$.fragment),oMr=l(),pc=a("p"),rMr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),$J=a("a"),tMr=o("from_pretrained()"),aMr=o(" class method or the "),kJ=a("a"),nMr=o("from_config()"),sMr=o(` class
method.`),lMr=l(),Ix=a("p"),iMr=o("This class cannot be instantiated directly using "),H8e=a("code"),dMr=o("__init__()"),cMr=o(" (throws an error)."),fMr=l(),Bt=a("div"),F(Nx.$$.fragment),mMr=l(),U8e=a("p"),gMr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),hMr=l(),_c=a("p"),pMr=o(`Note:
Loading a model from its configuration file does `),J8e=a("strong"),_Mr=o("not"),uMr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=a("a"),bMr=o("from_pretrained()"),vMr=o(" to load the model weights."),FMr=l(),F(JM.$$.fragment),TMr=l(),Mo=a("div"),F(qx.$$.fragment),MMr=l(),Y8e=a("p"),EMr=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),CMr=l(),mn=a("p"),wMr=o("The model class to instantiate is selected based on the "),K8e=a("code"),AMr=o("model_type"),LMr=o(` property of the config object (either
passed as an argument or loaded from `),Z8e=a("code"),yMr=o("pretrained_model_name_or_path"),xMr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eMe=a("code"),$Mr=o("pretrained_model_name_or_path"),kMr=o(":"),SMr=l(),oMe=a("ul"),YM=a("li"),rMe=a("strong"),RMr=o("maskformer"),PMr=o(" \u2014 "),RJ=a("a"),BMr=o("MaskFormerForInstanceSegmentation"),IMr=o(" (MaskFormer model)"),NMr=l(),KM=a("p"),qMr=o("The model is set in evaluation mode by default using "),tMe=a("code"),jMr=o("model.eval()"),DMr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aMe=a("code"),GMr=o("model.train()"),OMr=l(),F(ZM.$$.fragment),KQe=l(),uc=a("h2"),eE=a("a"),nMe=a("span"),F(jx.$$.fragment),VMr=l(),sMe=a("span"),XMr=o("TFAutoModel"),ZQe=l(),ar=a("div"),F(Dx.$$.fragment),zMr=l(),bc=a("p"),WMr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PJ=a("a"),QMr=o("from_pretrained()"),HMr=o(" class method or the "),BJ=a("a"),UMr=o("from_config()"),JMr=o(` class
method.`),YMr=l(),Gx=a("p"),KMr=o("This class cannot be instantiated directly using "),lMe=a("code"),ZMr=o("__init__()"),eEr=o(" (throws an error)."),oEr=l(),It=a("div"),F(Ox.$$.fragment),rEr=l(),iMe=a("p"),tEr=o("Instantiates one of the base model classes of the library from a configuration."),aEr=l(),vc=a("p"),nEr=o(`Note:
Loading a model from its configuration file does `),dMe=a("strong"),sEr=o("not"),lEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=a("a"),iEr=o("from_pretrained()"),dEr=o(" to load the model weights."),cEr=l(),F(oE.$$.fragment),fEr=l(),Sr=a("div"),F(Vx.$$.fragment),mEr=l(),cMe=a("p"),gEr=o("Instantiate one of the base model classes of the library from a pretrained model."),hEr=l(),gn=a("p"),pEr=o("The model class to instantiate is selected based on the "),fMe=a("code"),_Er=o("model_type"),uEr=o(` property of the config object (either
passed as an argument or loaded from `),mMe=a("code"),bEr=o("pretrained_model_name_or_path"),vEr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gMe=a("code"),FEr=o("pretrained_model_name_or_path"),TEr=o(":"),MEr=l(),q=a("ul"),rE=a("li"),hMe=a("strong"),EEr=o("albert"),CEr=o(" \u2014 "),NJ=a("a"),wEr=o("TFAlbertModel"),AEr=o(" (ALBERT model)"),LEr=l(),tE=a("li"),pMe=a("strong"),yEr=o("bart"),xEr=o(" \u2014 "),qJ=a("a"),$Er=o("TFBartModel"),kEr=o(" (BART model)"),SEr=l(),aE=a("li"),_Me=a("strong"),REr=o("bert"),PEr=o(" \u2014 "),jJ=a("a"),BEr=o("TFBertModel"),IEr=o(" (BERT model)"),NEr=l(),nE=a("li"),uMe=a("strong"),qEr=o("blenderbot"),jEr=o(" \u2014 "),DJ=a("a"),DEr=o("TFBlenderbotModel"),GEr=o(" (Blenderbot model)"),OEr=l(),sE=a("li"),bMe=a("strong"),VEr=o("blenderbot-small"),XEr=o(" \u2014 "),GJ=a("a"),zEr=o("TFBlenderbotSmallModel"),WEr=o(" (BlenderbotSmall model)"),QEr=l(),lE=a("li"),vMe=a("strong"),HEr=o("camembert"),UEr=o(" \u2014 "),OJ=a("a"),JEr=o("TFCamembertModel"),YEr=o(" (CamemBERT model)"),KEr=l(),iE=a("li"),FMe=a("strong"),ZEr=o("clip"),e4r=o(" \u2014 "),VJ=a("a"),o4r=o("TFCLIPModel"),r4r=o(" (CLIP model)"),t4r=l(),dE=a("li"),TMe=a("strong"),a4r=o("convbert"),n4r=o(" \u2014 "),XJ=a("a"),s4r=o("TFConvBertModel"),l4r=o(" (ConvBERT model)"),i4r=l(),cE=a("li"),MMe=a("strong"),d4r=o("convnext"),c4r=o(" \u2014 "),zJ=a("a"),f4r=o("TFConvNextModel"),m4r=o(" (ConvNeXT model)"),g4r=l(),fE=a("li"),EMe=a("strong"),h4r=o("ctrl"),p4r=o(" \u2014 "),WJ=a("a"),_4r=o("TFCTRLModel"),u4r=o(" (CTRL model)"),b4r=l(),mE=a("li"),CMe=a("strong"),v4r=o("data2vec-vision"),F4r=o(" \u2014 "),QJ=a("a"),T4r=o("TFData2VecVisionModel"),M4r=o(" (Data2VecVision model)"),E4r=l(),gE=a("li"),wMe=a("strong"),C4r=o("deberta"),w4r=o(" \u2014 "),HJ=a("a"),A4r=o("TFDebertaModel"),L4r=o(" (DeBERTa model)"),y4r=l(),hE=a("li"),AMe=a("strong"),x4r=o("deberta-v2"),$4r=o(" \u2014 "),UJ=a("a"),k4r=o("TFDebertaV2Model"),S4r=o(" (DeBERTa-v2 model)"),R4r=l(),pE=a("li"),LMe=a("strong"),P4r=o("deit"),B4r=o(" \u2014 "),JJ=a("a"),I4r=o("TFDeiTModel"),N4r=o(" (DeiT model)"),q4r=l(),_E=a("li"),yMe=a("strong"),j4r=o("distilbert"),D4r=o(" \u2014 "),YJ=a("a"),G4r=o("TFDistilBertModel"),O4r=o(" (DistilBERT model)"),V4r=l(),uE=a("li"),xMe=a("strong"),X4r=o("dpr"),z4r=o(" \u2014 "),KJ=a("a"),W4r=o("TFDPRQuestionEncoder"),Q4r=o(" (DPR model)"),H4r=l(),bE=a("li"),$Me=a("strong"),U4r=o("electra"),J4r=o(" \u2014 "),ZJ=a("a"),Y4r=o("TFElectraModel"),K4r=o(" (ELECTRA model)"),Z4r=l(),vE=a("li"),kMe=a("strong"),eCr=o("flaubert"),oCr=o(" \u2014 "),eY=a("a"),rCr=o("TFFlaubertModel"),tCr=o(" (FlauBERT model)"),aCr=l(),al=a("li"),SMe=a("strong"),nCr=o("funnel"),sCr=o(" \u2014 "),oY=a("a"),lCr=o("TFFunnelModel"),iCr=o(" or "),rY=a("a"),dCr=o("TFFunnelBaseModel"),cCr=o(" (Funnel Transformer model)"),fCr=l(),FE=a("li"),RMe=a("strong"),mCr=o("gpt2"),gCr=o(" \u2014 "),tY=a("a"),hCr=o("TFGPT2Model"),pCr=o(" (OpenAI GPT-2 model)"),_Cr=l(),TE=a("li"),PMe=a("strong"),uCr=o("gptj"),bCr=o(" \u2014 "),aY=a("a"),vCr=o("TFGPTJModel"),FCr=o(" (GPT-J model)"),TCr=l(),ME=a("li"),BMe=a("strong"),MCr=o("hubert"),ECr=o(" \u2014 "),nY=a("a"),CCr=o("TFHubertModel"),wCr=o(" (Hubert model)"),ACr=l(),EE=a("li"),IMe=a("strong"),LCr=o("layoutlm"),yCr=o(" \u2014 "),sY=a("a"),xCr=o("TFLayoutLMModel"),$Cr=o(" (LayoutLM model)"),kCr=l(),CE=a("li"),NMe=a("strong"),SCr=o("led"),RCr=o(" \u2014 "),lY=a("a"),PCr=o("TFLEDModel"),BCr=o(" (LED model)"),ICr=l(),wE=a("li"),qMe=a("strong"),NCr=o("longformer"),qCr=o(" \u2014 "),iY=a("a"),jCr=o("TFLongformerModel"),DCr=o(" (Longformer model)"),GCr=l(),AE=a("li"),jMe=a("strong"),OCr=o("lxmert"),VCr=o(" \u2014 "),dY=a("a"),XCr=o("TFLxmertModel"),zCr=o(" (LXMERT model)"),WCr=l(),LE=a("li"),DMe=a("strong"),QCr=o("marian"),HCr=o(" \u2014 "),cY=a("a"),UCr=o("TFMarianModel"),JCr=o(" (Marian model)"),YCr=l(),yE=a("li"),GMe=a("strong"),KCr=o("mbart"),ZCr=o(" \u2014 "),fY=a("a"),e5r=o("TFMBartModel"),o5r=o(" (mBART model)"),r5r=l(),xE=a("li"),OMe=a("strong"),t5r=o("mobilebert"),a5r=o(" \u2014 "),mY=a("a"),n5r=o("TFMobileBertModel"),s5r=o(" (MobileBERT model)"),l5r=l(),$E=a("li"),VMe=a("strong"),i5r=o("mpnet"),d5r=o(" \u2014 "),gY=a("a"),c5r=o("TFMPNetModel"),f5r=o(" (MPNet model)"),m5r=l(),kE=a("li"),XMe=a("strong"),g5r=o("mt5"),h5r=o(" \u2014 "),hY=a("a"),p5r=o("TFMT5Model"),_5r=o(" (MT5 model)"),u5r=l(),SE=a("li"),zMe=a("strong"),b5r=o("openai-gpt"),v5r=o(" \u2014 "),pY=a("a"),F5r=o("TFOpenAIGPTModel"),T5r=o(" (OpenAI GPT model)"),M5r=l(),RE=a("li"),WMe=a("strong"),E5r=o("opt"),C5r=o(" \u2014 "),_Y=a("a"),w5r=o("TFOPTModel"),A5r=o(" (OPT model)"),L5r=l(),PE=a("li"),QMe=a("strong"),y5r=o("pegasus"),x5r=o(" \u2014 "),uY=a("a"),$5r=o("TFPegasusModel"),k5r=o(" (Pegasus model)"),S5r=l(),BE=a("li"),HMe=a("strong"),R5r=o("regnet"),P5r=o(" \u2014 "),bY=a("a"),B5r=o("TFRegNetModel"),I5r=o(" (RegNet model)"),N5r=l(),IE=a("li"),UMe=a("strong"),q5r=o("rembert"),j5r=o(" \u2014 "),vY=a("a"),D5r=o("TFRemBertModel"),G5r=o(" (RemBERT model)"),O5r=l(),NE=a("li"),JMe=a("strong"),V5r=o("resnet"),X5r=o(" \u2014 "),FY=a("a"),z5r=o("TFResNetModel"),W5r=o(" (ResNet model)"),Q5r=l(),qE=a("li"),YMe=a("strong"),H5r=o("roberta"),U5r=o(" \u2014 "),TY=a("a"),J5r=o("TFRobertaModel"),Y5r=o(" (RoBERTa model)"),K5r=l(),jE=a("li"),KMe=a("strong"),Z5r=o("roformer"),e3r=o(" \u2014 "),MY=a("a"),o3r=o("TFRoFormerModel"),r3r=o(" (RoFormer model)"),t3r=l(),DE=a("li"),ZMe=a("strong"),a3r=o("segformer"),n3r=o(" \u2014 "),EY=a("a"),s3r=o("TFSegformerModel"),l3r=o(" (SegFormer model)"),i3r=l(),GE=a("li"),eEe=a("strong"),d3r=o("speech_to_text"),c3r=o(" \u2014 "),CY=a("a"),f3r=o("TFSpeech2TextModel"),m3r=o(" (Speech2Text model)"),g3r=l(),OE=a("li"),oEe=a("strong"),h3r=o("swin"),p3r=o(" \u2014 "),wY=a("a"),_3r=o("TFSwinModel"),u3r=o(" (Swin Transformer model)"),b3r=l(),VE=a("li"),rEe=a("strong"),v3r=o("t5"),F3r=o(" \u2014 "),AY=a("a"),T3r=o("TFT5Model"),M3r=o(" (T5 model)"),E3r=l(),XE=a("li"),tEe=a("strong"),C3r=o("tapas"),w3r=o(" \u2014 "),LY=a("a"),A3r=o("TFTapasModel"),L3r=o(" (TAPAS model)"),y3r=l(),zE=a("li"),aEe=a("strong"),x3r=o("transfo-xl"),$3r=o(" \u2014 "),yY=a("a"),k3r=o("TFTransfoXLModel"),S3r=o(" (Transformer-XL model)"),R3r=l(),WE=a("li"),nEe=a("strong"),P3r=o("vit"),B3r=o(" \u2014 "),xY=a("a"),I3r=o("TFViTModel"),N3r=o(" (ViT model)"),q3r=l(),QE=a("li"),sEe=a("strong"),j3r=o("vit_mae"),D3r=o(" \u2014 "),$Y=a("a"),G3r=o("TFViTMAEModel"),O3r=o(" (ViTMAE model)"),V3r=l(),HE=a("li"),lEe=a("strong"),X3r=o("wav2vec2"),z3r=o(" \u2014 "),kY=a("a"),W3r=o("TFWav2Vec2Model"),Q3r=o(" (Wav2Vec2 model)"),H3r=l(),UE=a("li"),iEe=a("strong"),U3r=o("xlm"),J3r=o(" \u2014 "),SY=a("a"),Y3r=o("TFXLMModel"),K3r=o(" (XLM model)"),Z3r=l(),JE=a("li"),dEe=a("strong"),ewr=o("xlm-roberta"),owr=o(" \u2014 "),RY=a("a"),rwr=o("TFXLMRobertaModel"),twr=o(" (XLM-RoBERTa model)"),awr=l(),YE=a("li"),cEe=a("strong"),nwr=o("xlnet"),swr=o(" \u2014 "),PY=a("a"),lwr=o("TFXLNetModel"),iwr=o(" (XLNet model)"),dwr=l(),F(KE.$$.fragment),eHe=l(),Fc=a("h2"),ZE=a("a"),fEe=a("span"),F(Xx.$$.fragment),cwr=l(),mEe=a("span"),fwr=o("TFAutoModelForPreTraining"),oHe=l(),nr=a("div"),F(zx.$$.fragment),mwr=l(),Tc=a("p"),gwr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),BY=a("a"),hwr=o("from_pretrained()"),pwr=o(" class method or the "),IY=a("a"),_wr=o("from_config()"),uwr=o(` class
method.`),bwr=l(),Wx=a("p"),vwr=o("This class cannot be instantiated directly using "),gEe=a("code"),Fwr=o("__init__()"),Twr=o(" (throws an error)."),Mwr=l(),Nt=a("div"),F(Qx.$$.fragment),Ewr=l(),hEe=a("p"),Cwr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),wwr=l(),Mc=a("p"),Awr=o(`Note:
Loading a model from its configuration file does `),pEe=a("strong"),Lwr=o("not"),ywr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NY=a("a"),xwr=o("from_pretrained()"),$wr=o(" to load the model weights."),kwr=l(),F(e4.$$.fragment),Swr=l(),Rr=a("div"),F(Hx.$$.fragment),Rwr=l(),_Ee=a("p"),Pwr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Bwr=l(),hn=a("p"),Iwr=o("The model class to instantiate is selected based on the "),uEe=a("code"),Nwr=o("model_type"),qwr=o(` property of the config object (either
passed as an argument or loaded from `),bEe=a("code"),jwr=o("pretrained_model_name_or_path"),Dwr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vEe=a("code"),Gwr=o("pretrained_model_name_or_path"),Owr=o(":"),Vwr=l(),se=a("ul"),o4=a("li"),FEe=a("strong"),Xwr=o("albert"),zwr=o(" \u2014 "),qY=a("a"),Wwr=o("TFAlbertForPreTraining"),Qwr=o(" (ALBERT model)"),Hwr=l(),r4=a("li"),TEe=a("strong"),Uwr=o("bart"),Jwr=o(" \u2014 "),jY=a("a"),Ywr=o("TFBartForConditionalGeneration"),Kwr=o(" (BART model)"),Zwr=l(),t4=a("li"),MEe=a("strong"),e6r=o("bert"),o6r=o(" \u2014 "),DY=a("a"),r6r=o("TFBertForPreTraining"),t6r=o(" (BERT model)"),a6r=l(),a4=a("li"),EEe=a("strong"),n6r=o("camembert"),s6r=o(" \u2014 "),GY=a("a"),l6r=o("TFCamembertForMaskedLM"),i6r=o(" (CamemBERT model)"),d6r=l(),n4=a("li"),CEe=a("strong"),c6r=o("ctrl"),f6r=o(" \u2014 "),OY=a("a"),m6r=o("TFCTRLLMHeadModel"),g6r=o(" (CTRL model)"),h6r=l(),s4=a("li"),wEe=a("strong"),p6r=o("distilbert"),_6r=o(" \u2014 "),VY=a("a"),u6r=o("TFDistilBertForMaskedLM"),b6r=o(" (DistilBERT model)"),v6r=l(),l4=a("li"),AEe=a("strong"),F6r=o("electra"),T6r=o(" \u2014 "),XY=a("a"),M6r=o("TFElectraForPreTraining"),E6r=o(" (ELECTRA model)"),C6r=l(),i4=a("li"),LEe=a("strong"),w6r=o("flaubert"),A6r=o(" \u2014 "),zY=a("a"),L6r=o("TFFlaubertWithLMHeadModel"),y6r=o(" (FlauBERT model)"),x6r=l(),d4=a("li"),yEe=a("strong"),$6r=o("funnel"),k6r=o(" \u2014 "),WY=a("a"),S6r=o("TFFunnelForPreTraining"),R6r=o(" (Funnel Transformer model)"),P6r=l(),c4=a("li"),xEe=a("strong"),B6r=o("gpt2"),I6r=o(" \u2014 "),QY=a("a"),N6r=o("TFGPT2LMHeadModel"),q6r=o(" (OpenAI GPT-2 model)"),j6r=l(),f4=a("li"),$Ee=a("strong"),D6r=o("layoutlm"),G6r=o(" \u2014 "),HY=a("a"),O6r=o("TFLayoutLMForMaskedLM"),V6r=o(" (LayoutLM model)"),X6r=l(),m4=a("li"),kEe=a("strong"),z6r=o("lxmert"),W6r=o(" \u2014 "),UY=a("a"),Q6r=o("TFLxmertForPreTraining"),H6r=o(" (LXMERT model)"),U6r=l(),g4=a("li"),SEe=a("strong"),J6r=o("mobilebert"),Y6r=o(" \u2014 "),JY=a("a"),K6r=o("TFMobileBertForPreTraining"),Z6r=o(" (MobileBERT model)"),eAr=l(),h4=a("li"),REe=a("strong"),oAr=o("mpnet"),rAr=o(" \u2014 "),YY=a("a"),tAr=o("TFMPNetForMaskedLM"),aAr=o(" (MPNet model)"),nAr=l(),p4=a("li"),PEe=a("strong"),sAr=o("openai-gpt"),lAr=o(" \u2014 "),KY=a("a"),iAr=o("TFOpenAIGPTLMHeadModel"),dAr=o(" (OpenAI GPT model)"),cAr=l(),_4=a("li"),BEe=a("strong"),fAr=o("roberta"),mAr=o(" \u2014 "),ZY=a("a"),gAr=o("TFRobertaForMaskedLM"),hAr=o(" (RoBERTa model)"),pAr=l(),u4=a("li"),IEe=a("strong"),_Ar=o("t5"),uAr=o(" \u2014 "),eK=a("a"),bAr=o("TFT5ForConditionalGeneration"),vAr=o(" (T5 model)"),FAr=l(),b4=a("li"),NEe=a("strong"),TAr=o("tapas"),MAr=o(" \u2014 "),oK=a("a"),EAr=o("TFTapasForMaskedLM"),CAr=o(" (TAPAS model)"),wAr=l(),v4=a("li"),qEe=a("strong"),AAr=o("transfo-xl"),LAr=o(" \u2014 "),rK=a("a"),yAr=o("TFTransfoXLLMHeadModel"),xAr=o(" (Transformer-XL model)"),$Ar=l(),F4=a("li"),jEe=a("strong"),kAr=o("vit_mae"),SAr=o(" \u2014 "),tK=a("a"),RAr=o("TFViTMAEForPreTraining"),PAr=o(" (ViTMAE model)"),BAr=l(),T4=a("li"),DEe=a("strong"),IAr=o("xlm"),NAr=o(" \u2014 "),aK=a("a"),qAr=o("TFXLMWithLMHeadModel"),jAr=o(" (XLM model)"),DAr=l(),M4=a("li"),GEe=a("strong"),GAr=o("xlm-roberta"),OAr=o(" \u2014 "),nK=a("a"),VAr=o("TFXLMRobertaForMaskedLM"),XAr=o(" (XLM-RoBERTa model)"),zAr=l(),E4=a("li"),OEe=a("strong"),WAr=o("xlnet"),QAr=o(" \u2014 "),sK=a("a"),HAr=o("TFXLNetLMHeadModel"),UAr=o(" (XLNet model)"),JAr=l(),F(C4.$$.fragment),rHe=l(),Ec=a("h2"),w4=a("a"),VEe=a("span"),F(Ux.$$.fragment),YAr=l(),XEe=a("span"),KAr=o("TFAutoModelForCausalLM"),tHe=l(),sr=a("div"),F(Jx.$$.fragment),ZAr=l(),Cc=a("p"),e7r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lK=a("a"),o7r=o("from_pretrained()"),r7r=o(" class method or the "),iK=a("a"),t7r=o("from_config()"),a7r=o(` class
method.`),n7r=l(),Yx=a("p"),s7r=o("This class cannot be instantiated directly using "),zEe=a("code"),l7r=o("__init__()"),i7r=o(" (throws an error)."),d7r=l(),qt=a("div"),F(Kx.$$.fragment),c7r=l(),WEe=a("p"),f7r=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),m7r=l(),wc=a("p"),g7r=o(`Note:
Loading a model from its configuration file does `),QEe=a("strong"),h7r=o("not"),p7r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),dK=a("a"),_7r=o("from_pretrained()"),u7r=o(" to load the model weights."),b7r=l(),F(A4.$$.fragment),v7r=l(),Pr=a("div"),F(Zx.$$.fragment),F7r=l(),HEe=a("p"),T7r=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),M7r=l(),pn=a("p"),E7r=o("The model class to instantiate is selected based on the "),UEe=a("code"),C7r=o("model_type"),w7r=o(` property of the config object (either
passed as an argument or loaded from `),JEe=a("code"),A7r=o("pretrained_model_name_or_path"),L7r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YEe=a("code"),y7r=o("pretrained_model_name_or_path"),x7r=o(":"),$7r=l(),Me=a("ul"),L4=a("li"),KEe=a("strong"),k7r=o("bert"),S7r=o(" \u2014 "),cK=a("a"),R7r=o("TFBertLMHeadModel"),P7r=o(" (BERT model)"),B7r=l(),y4=a("li"),ZEe=a("strong"),I7r=o("camembert"),N7r=o(" \u2014 "),fK=a("a"),q7r=o("TFCamembertForCausalLM"),j7r=o(" (CamemBERT model)"),D7r=l(),x4=a("li"),e4e=a("strong"),G7r=o("ctrl"),O7r=o(" \u2014 "),mK=a("a"),V7r=o("TFCTRLLMHeadModel"),X7r=o(" (CTRL model)"),z7r=l(),$4=a("li"),o4e=a("strong"),W7r=o("gpt2"),Q7r=o(" \u2014 "),gK=a("a"),H7r=o("TFGPT2LMHeadModel"),U7r=o(" (OpenAI GPT-2 model)"),J7r=l(),k4=a("li"),r4e=a("strong"),Y7r=o("gptj"),K7r=o(" \u2014 "),hK=a("a"),Z7r=o("TFGPTJForCausalLM"),eLr=o(" (GPT-J model)"),oLr=l(),S4=a("li"),t4e=a("strong"),rLr=o("openai-gpt"),tLr=o(" \u2014 "),pK=a("a"),aLr=o("TFOpenAIGPTLMHeadModel"),nLr=o(" (OpenAI GPT model)"),sLr=l(),R4=a("li"),a4e=a("strong"),lLr=o("opt"),iLr=o(" \u2014 "),_K=a("a"),dLr=o("TFOPTForCausalLM"),cLr=o(" (OPT model)"),fLr=l(),P4=a("li"),n4e=a("strong"),mLr=o("rembert"),gLr=o(" \u2014 "),uK=a("a"),hLr=o("TFRemBertForCausalLM"),pLr=o(" (RemBERT model)"),_Lr=l(),B4=a("li"),s4e=a("strong"),uLr=o("roberta"),bLr=o(" \u2014 "),bK=a("a"),vLr=o("TFRobertaForCausalLM"),FLr=o(" (RoBERTa model)"),TLr=l(),I4=a("li"),l4e=a("strong"),MLr=o("roformer"),ELr=o(" \u2014 "),vK=a("a"),CLr=o("TFRoFormerForCausalLM"),wLr=o(" (RoFormer model)"),ALr=l(),N4=a("li"),i4e=a("strong"),LLr=o("transfo-xl"),yLr=o(" \u2014 "),FK=a("a"),xLr=o("TFTransfoXLLMHeadModel"),$Lr=o(" (Transformer-XL model)"),kLr=l(),q4=a("li"),d4e=a("strong"),SLr=o("xlm"),RLr=o(" \u2014 "),TK=a("a"),PLr=o("TFXLMWithLMHeadModel"),BLr=o(" (XLM model)"),ILr=l(),j4=a("li"),c4e=a("strong"),NLr=o("xlnet"),qLr=o(" \u2014 "),MK=a("a"),jLr=o("TFXLNetLMHeadModel"),DLr=o(" (XLNet model)"),GLr=l(),F(D4.$$.fragment),aHe=l(),Ac=a("h2"),G4=a("a"),f4e=a("span"),F(e$.$$.fragment),OLr=l(),m4e=a("span"),VLr=o("TFAutoModelForImageClassification"),nHe=l(),lr=a("div"),F(o$.$$.fragment),XLr=l(),Lc=a("p"),zLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),EK=a("a"),WLr=o("from_pretrained()"),QLr=o(" class method or the "),CK=a("a"),HLr=o("from_config()"),ULr=o(` class
method.`),JLr=l(),r$=a("p"),YLr=o("This class cannot be instantiated directly using "),g4e=a("code"),KLr=o("__init__()"),ZLr=o(" (throws an error)."),eyr=l(),jt=a("div"),F(t$.$$.fragment),oyr=l(),h4e=a("p"),ryr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),tyr=l(),yc=a("p"),ayr=o(`Note:
Loading a model from its configuration file does `),p4e=a("strong"),nyr=o("not"),syr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=a("a"),lyr=o("from_pretrained()"),iyr=o(" to load the model weights."),dyr=l(),F(O4.$$.fragment),cyr=l(),Br=a("div"),F(a$.$$.fragment),fyr=l(),_4e=a("p"),myr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),gyr=l(),_n=a("p"),hyr=o("The model class to instantiate is selected based on the "),u4e=a("code"),pyr=o("model_type"),_yr=o(` property of the config object (either
passed as an argument or loaded from `),b4e=a("code"),uyr=o("pretrained_model_name_or_path"),byr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v4e=a("code"),vyr=o("pretrained_model_name_or_path"),Fyr=o(":"),Tyr=l(),Ve=a("ul"),V4=a("li"),F4e=a("strong"),Myr=o("convnext"),Eyr=o(" \u2014 "),AK=a("a"),Cyr=o("TFConvNextForImageClassification"),wyr=o(" (ConvNeXT model)"),Ayr=l(),X4=a("li"),T4e=a("strong"),Lyr=o("data2vec-vision"),yyr=o(" \u2014 "),LK=a("a"),xyr=o("TFData2VecVisionForImageClassification"),$yr=o(" (Data2VecVision model)"),kyr=l(),nl=a("li"),M4e=a("strong"),Syr=o("deit"),Ryr=o(" \u2014 "),yK=a("a"),Pyr=o("TFDeiTForImageClassification"),Byr=o(" or "),xK=a("a"),Iyr=o("TFDeiTForImageClassificationWithTeacher"),Nyr=o(" (DeiT model)"),qyr=l(),z4=a("li"),E4e=a("strong"),jyr=o("regnet"),Dyr=o(" \u2014 "),$K=a("a"),Gyr=o("TFRegNetForImageClassification"),Oyr=o(" (RegNet model)"),Vyr=l(),W4=a("li"),C4e=a("strong"),Xyr=o("resnet"),zyr=o(" \u2014 "),kK=a("a"),Wyr=o("TFResNetForImageClassification"),Qyr=o(" (ResNet model)"),Hyr=l(),Q4=a("li"),w4e=a("strong"),Uyr=o("segformer"),Jyr=o(" \u2014 "),SK=a("a"),Yyr=o("TFSegformerForImageClassification"),Kyr=o(" (SegFormer model)"),Zyr=l(),H4=a("li"),A4e=a("strong"),e9r=o("swin"),o9r=o(" \u2014 "),RK=a("a"),r9r=o("TFSwinForImageClassification"),t9r=o(" (Swin Transformer model)"),a9r=l(),U4=a("li"),L4e=a("strong"),n9r=o("vit"),s9r=o(" \u2014 "),PK=a("a"),l9r=o("TFViTForImageClassification"),i9r=o(" (ViT model)"),d9r=l(),F(J4.$$.fragment),sHe=l(),xc=a("h2"),Y4=a("a"),y4e=a("span"),F(n$.$$.fragment),c9r=l(),x4e=a("span"),f9r=o("TFAutoModelForMaskedLM"),lHe=l(),ir=a("div"),F(s$.$$.fragment),m9r=l(),$c=a("p"),g9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),BK=a("a"),h9r=o("from_pretrained()"),p9r=o(" class method or the "),IK=a("a"),_9r=o("from_config()"),u9r=o(` class
method.`),b9r=l(),l$=a("p"),v9r=o("This class cannot be instantiated directly using "),$4e=a("code"),F9r=o("__init__()"),T9r=o(" (throws an error)."),M9r=l(),Dt=a("div"),F(i$.$$.fragment),E9r=l(),k4e=a("p"),C9r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),w9r=l(),kc=a("p"),A9r=o(`Note:
Loading a model from its configuration file does `),S4e=a("strong"),L9r=o("not"),y9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),NK=a("a"),x9r=o("from_pretrained()"),$9r=o(" to load the model weights."),k9r=l(),F(K4.$$.fragment),S9r=l(),Ir=a("div"),F(d$.$$.fragment),R9r=l(),R4e=a("p"),P9r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),B9r=l(),un=a("p"),I9r=o("The model class to instantiate is selected based on the "),P4e=a("code"),N9r=o("model_type"),q9r=o(` property of the config object (either
passed as an argument or loaded from `),B4e=a("code"),j9r=o("pretrained_model_name_or_path"),D9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=a("code"),G9r=o("pretrained_model_name_or_path"),O9r=o(":"),V9r=l(),ie=a("ul"),Z4=a("li"),N4e=a("strong"),X9r=o("albert"),z9r=o(" \u2014 "),qK=a("a"),W9r=o("TFAlbertForMaskedLM"),Q9r=o(" (ALBERT model)"),H9r=l(),eC=a("li"),q4e=a("strong"),U9r=o("bert"),J9r=o(" \u2014 "),jK=a("a"),Y9r=o("TFBertForMaskedLM"),K9r=o(" (BERT model)"),Z9r=l(),oC=a("li"),j4e=a("strong"),exr=o("camembert"),oxr=o(" \u2014 "),DK=a("a"),rxr=o("TFCamembertForMaskedLM"),txr=o(" (CamemBERT model)"),axr=l(),rC=a("li"),D4e=a("strong"),nxr=o("convbert"),sxr=o(" \u2014 "),GK=a("a"),lxr=o("TFConvBertForMaskedLM"),ixr=o(" (ConvBERT model)"),dxr=l(),tC=a("li"),G4e=a("strong"),cxr=o("deberta"),fxr=o(" \u2014 "),OK=a("a"),mxr=o("TFDebertaForMaskedLM"),gxr=o(" (DeBERTa model)"),hxr=l(),aC=a("li"),O4e=a("strong"),pxr=o("deberta-v2"),_xr=o(" \u2014 "),VK=a("a"),uxr=o("TFDebertaV2ForMaskedLM"),bxr=o(" (DeBERTa-v2 model)"),vxr=l(),nC=a("li"),V4e=a("strong"),Fxr=o("distilbert"),Txr=o(" \u2014 "),XK=a("a"),Mxr=o("TFDistilBertForMaskedLM"),Exr=o(" (DistilBERT model)"),Cxr=l(),sC=a("li"),X4e=a("strong"),wxr=o("electra"),Axr=o(" \u2014 "),zK=a("a"),Lxr=o("TFElectraForMaskedLM"),yxr=o(" (ELECTRA model)"),xxr=l(),lC=a("li"),z4e=a("strong"),$xr=o("flaubert"),kxr=o(" \u2014 "),WK=a("a"),Sxr=o("TFFlaubertWithLMHeadModel"),Rxr=o(" (FlauBERT model)"),Pxr=l(),iC=a("li"),W4e=a("strong"),Bxr=o("funnel"),Ixr=o(" \u2014 "),QK=a("a"),Nxr=o("TFFunnelForMaskedLM"),qxr=o(" (Funnel Transformer model)"),jxr=l(),dC=a("li"),Q4e=a("strong"),Dxr=o("layoutlm"),Gxr=o(" \u2014 "),HK=a("a"),Oxr=o("TFLayoutLMForMaskedLM"),Vxr=o(" (LayoutLM model)"),Xxr=l(),cC=a("li"),H4e=a("strong"),zxr=o("longformer"),Wxr=o(" \u2014 "),UK=a("a"),Qxr=o("TFLongformerForMaskedLM"),Hxr=o(" (Longformer model)"),Uxr=l(),fC=a("li"),U4e=a("strong"),Jxr=o("mobilebert"),Yxr=o(" \u2014 "),JK=a("a"),Kxr=o("TFMobileBertForMaskedLM"),Zxr=o(" (MobileBERT model)"),e$r=l(),mC=a("li"),J4e=a("strong"),o$r=o("mpnet"),r$r=o(" \u2014 "),YK=a("a"),t$r=o("TFMPNetForMaskedLM"),a$r=o(" (MPNet model)"),n$r=l(),gC=a("li"),Y4e=a("strong"),s$r=o("rembert"),l$r=o(" \u2014 "),KK=a("a"),i$r=o("TFRemBertForMaskedLM"),d$r=o(" (RemBERT model)"),c$r=l(),hC=a("li"),K4e=a("strong"),f$r=o("roberta"),m$r=o(" \u2014 "),ZK=a("a"),g$r=o("TFRobertaForMaskedLM"),h$r=o(" (RoBERTa model)"),p$r=l(),pC=a("li"),Z4e=a("strong"),_$r=o("roformer"),u$r=o(" \u2014 "),eZ=a("a"),b$r=o("TFRoFormerForMaskedLM"),v$r=o(" (RoFormer model)"),F$r=l(),_C=a("li"),eCe=a("strong"),T$r=o("tapas"),M$r=o(" \u2014 "),oZ=a("a"),E$r=o("TFTapasForMaskedLM"),C$r=o(" (TAPAS model)"),w$r=l(),uC=a("li"),oCe=a("strong"),A$r=o("xlm"),L$r=o(" \u2014 "),rZ=a("a"),y$r=o("TFXLMWithLMHeadModel"),x$r=o(" (XLM model)"),$$r=l(),bC=a("li"),rCe=a("strong"),k$r=o("xlm-roberta"),S$r=o(" \u2014 "),tZ=a("a"),R$r=o("TFXLMRobertaForMaskedLM"),P$r=o(" (XLM-RoBERTa model)"),B$r=l(),F(vC.$$.fragment),iHe=l(),Sc=a("h2"),FC=a("a"),tCe=a("span"),F(c$.$$.fragment),I$r=l(),aCe=a("span"),N$r=o("TFAutoModelForSeq2SeqLM"),dHe=l(),dr=a("div"),F(f$.$$.fragment),q$r=l(),Rc=a("p"),j$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),aZ=a("a"),D$r=o("from_pretrained()"),G$r=o(" class method or the "),nZ=a("a"),O$r=o("from_config()"),V$r=o(` class
method.`),X$r=l(),m$=a("p"),z$r=o("This class cannot be instantiated directly using "),nCe=a("code"),W$r=o("__init__()"),Q$r=o(" (throws an error)."),H$r=l(),Gt=a("div"),F(g$.$$.fragment),U$r=l(),sCe=a("p"),J$r=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Y$r=l(),Pc=a("p"),K$r=o(`Note:
Loading a model from its configuration file does `),lCe=a("strong"),Z$r=o("not"),ekr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sZ=a("a"),okr=o("from_pretrained()"),rkr=o(" to load the model weights."),tkr=l(),F(TC.$$.fragment),akr=l(),Nr=a("div"),F(h$.$$.fragment),nkr=l(),iCe=a("p"),skr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),lkr=l(),bn=a("p"),ikr=o("The model class to instantiate is selected based on the "),dCe=a("code"),dkr=o("model_type"),ckr=o(` property of the config object (either
passed as an argument or loaded from `),cCe=a("code"),fkr=o("pretrained_model_name_or_path"),mkr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fCe=a("code"),gkr=o("pretrained_model_name_or_path"),hkr=o(":"),pkr=l(),xe=a("ul"),MC=a("li"),mCe=a("strong"),_kr=o("bart"),ukr=o(" \u2014 "),lZ=a("a"),bkr=o("TFBartForConditionalGeneration"),vkr=o(" (BART model)"),Fkr=l(),EC=a("li"),gCe=a("strong"),Tkr=o("blenderbot"),Mkr=o(" \u2014 "),iZ=a("a"),Ekr=o("TFBlenderbotForConditionalGeneration"),Ckr=o(" (Blenderbot model)"),wkr=l(),CC=a("li"),hCe=a("strong"),Akr=o("blenderbot-small"),Lkr=o(" \u2014 "),dZ=a("a"),ykr=o("TFBlenderbotSmallForConditionalGeneration"),xkr=o(" (BlenderbotSmall model)"),$kr=l(),wC=a("li"),pCe=a("strong"),kkr=o("encoder-decoder"),Skr=o(" \u2014 "),cZ=a("a"),Rkr=o("TFEncoderDecoderModel"),Pkr=o(" (Encoder decoder model)"),Bkr=l(),AC=a("li"),_Ce=a("strong"),Ikr=o("led"),Nkr=o(" \u2014 "),fZ=a("a"),qkr=o("TFLEDForConditionalGeneration"),jkr=o(" (LED model)"),Dkr=l(),LC=a("li"),uCe=a("strong"),Gkr=o("marian"),Okr=o(" \u2014 "),mZ=a("a"),Vkr=o("TFMarianMTModel"),Xkr=o(" (Marian model)"),zkr=l(),yC=a("li"),bCe=a("strong"),Wkr=o("mbart"),Qkr=o(" \u2014 "),gZ=a("a"),Hkr=o("TFMBartForConditionalGeneration"),Ukr=o(" (mBART model)"),Jkr=l(),xC=a("li"),vCe=a("strong"),Ykr=o("mt5"),Kkr=o(" \u2014 "),hZ=a("a"),Zkr=o("TFMT5ForConditionalGeneration"),eSr=o(" (MT5 model)"),oSr=l(),$C=a("li"),FCe=a("strong"),rSr=o("pegasus"),tSr=o(" \u2014 "),pZ=a("a"),aSr=o("TFPegasusForConditionalGeneration"),nSr=o(" (Pegasus model)"),sSr=l(),kC=a("li"),TCe=a("strong"),lSr=o("t5"),iSr=o(" \u2014 "),_Z=a("a"),dSr=o("TFT5ForConditionalGeneration"),cSr=o(" (T5 model)"),fSr=l(),F(SC.$$.fragment),cHe=l(),Bc=a("h2"),RC=a("a"),MCe=a("span"),F(p$.$$.fragment),mSr=l(),ECe=a("span"),gSr=o("TFAutoModelForSequenceClassification"),fHe=l(),cr=a("div"),F(_$.$$.fragment),hSr=l(),Ic=a("p"),pSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uZ=a("a"),_Sr=o("from_pretrained()"),uSr=o(" class method or the "),bZ=a("a"),bSr=o("from_config()"),vSr=o(` class
method.`),FSr=l(),u$=a("p"),TSr=o("This class cannot be instantiated directly using "),CCe=a("code"),MSr=o("__init__()"),ESr=o(" (throws an error)."),CSr=l(),Ot=a("div"),F(b$.$$.fragment),wSr=l(),wCe=a("p"),ASr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),LSr=l(),Nc=a("p"),ySr=o(`Note:
Loading a model from its configuration file does `),ACe=a("strong"),xSr=o("not"),$Sr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vZ=a("a"),kSr=o("from_pretrained()"),SSr=o(" to load the model weights."),RSr=l(),F(PC.$$.fragment),PSr=l(),qr=a("div"),F(v$.$$.fragment),BSr=l(),LCe=a("p"),ISr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),NSr=l(),vn=a("p"),qSr=o("The model class to instantiate is selected based on the "),yCe=a("code"),jSr=o("model_type"),DSr=o(` property of the config object (either
passed as an argument or loaded from `),xCe=a("code"),GSr=o("pretrained_model_name_or_path"),OSr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ce=a("code"),VSr=o("pretrained_model_name_or_path"),XSr=o(":"),zSr=l(),ae=a("ul"),BC=a("li"),kCe=a("strong"),WSr=o("albert"),QSr=o(" \u2014 "),FZ=a("a"),HSr=o("TFAlbertForSequenceClassification"),USr=o(" (ALBERT model)"),JSr=l(),IC=a("li"),SCe=a("strong"),YSr=o("bert"),KSr=o(" \u2014 "),TZ=a("a"),ZSr=o("TFBertForSequenceClassification"),eRr=o(" (BERT model)"),oRr=l(),NC=a("li"),RCe=a("strong"),rRr=o("camembert"),tRr=o(" \u2014 "),MZ=a("a"),aRr=o("TFCamembertForSequenceClassification"),nRr=o(" (CamemBERT model)"),sRr=l(),qC=a("li"),PCe=a("strong"),lRr=o("convbert"),iRr=o(" \u2014 "),EZ=a("a"),dRr=o("TFConvBertForSequenceClassification"),cRr=o(" (ConvBERT model)"),fRr=l(),jC=a("li"),BCe=a("strong"),mRr=o("ctrl"),gRr=o(" \u2014 "),CZ=a("a"),hRr=o("TFCTRLForSequenceClassification"),pRr=o(" (CTRL model)"),_Rr=l(),DC=a("li"),ICe=a("strong"),uRr=o("deberta"),bRr=o(" \u2014 "),wZ=a("a"),vRr=o("TFDebertaForSequenceClassification"),FRr=o(" (DeBERTa model)"),TRr=l(),GC=a("li"),NCe=a("strong"),MRr=o("deberta-v2"),ERr=o(" \u2014 "),AZ=a("a"),CRr=o("TFDebertaV2ForSequenceClassification"),wRr=o(" (DeBERTa-v2 model)"),ARr=l(),OC=a("li"),qCe=a("strong"),LRr=o("distilbert"),yRr=o(" \u2014 "),LZ=a("a"),xRr=o("TFDistilBertForSequenceClassification"),$Rr=o(" (DistilBERT model)"),kRr=l(),VC=a("li"),jCe=a("strong"),SRr=o("electra"),RRr=o(" \u2014 "),yZ=a("a"),PRr=o("TFElectraForSequenceClassification"),BRr=o(" (ELECTRA model)"),IRr=l(),XC=a("li"),DCe=a("strong"),NRr=o("flaubert"),qRr=o(" \u2014 "),xZ=a("a"),jRr=o("TFFlaubertForSequenceClassification"),DRr=o(" (FlauBERT model)"),GRr=l(),zC=a("li"),GCe=a("strong"),ORr=o("funnel"),VRr=o(" \u2014 "),$Z=a("a"),XRr=o("TFFunnelForSequenceClassification"),zRr=o(" (Funnel Transformer model)"),WRr=l(),WC=a("li"),OCe=a("strong"),QRr=o("gpt2"),HRr=o(" \u2014 "),kZ=a("a"),URr=o("TFGPT2ForSequenceClassification"),JRr=o(" (OpenAI GPT-2 model)"),YRr=l(),QC=a("li"),VCe=a("strong"),KRr=o("gptj"),ZRr=o(" \u2014 "),SZ=a("a"),ePr=o("TFGPTJForSequenceClassification"),oPr=o(" (GPT-J model)"),rPr=l(),HC=a("li"),XCe=a("strong"),tPr=o("layoutlm"),aPr=o(" \u2014 "),RZ=a("a"),nPr=o("TFLayoutLMForSequenceClassification"),sPr=o(" (LayoutLM model)"),lPr=l(),UC=a("li"),zCe=a("strong"),iPr=o("longformer"),dPr=o(" \u2014 "),PZ=a("a"),cPr=o("TFLongformerForSequenceClassification"),fPr=o(" (Longformer model)"),mPr=l(),JC=a("li"),WCe=a("strong"),gPr=o("mobilebert"),hPr=o(" \u2014 "),BZ=a("a"),pPr=o("TFMobileBertForSequenceClassification"),_Pr=o(" (MobileBERT model)"),uPr=l(),YC=a("li"),QCe=a("strong"),bPr=o("mpnet"),vPr=o(" \u2014 "),IZ=a("a"),FPr=o("TFMPNetForSequenceClassification"),TPr=o(" (MPNet model)"),MPr=l(),KC=a("li"),HCe=a("strong"),EPr=o("openai-gpt"),CPr=o(" \u2014 "),NZ=a("a"),wPr=o("TFOpenAIGPTForSequenceClassification"),APr=o(" (OpenAI GPT model)"),LPr=l(),ZC=a("li"),UCe=a("strong"),yPr=o("rembert"),xPr=o(" \u2014 "),qZ=a("a"),$Pr=o("TFRemBertForSequenceClassification"),kPr=o(" (RemBERT model)"),SPr=l(),e5=a("li"),JCe=a("strong"),RPr=o("roberta"),PPr=o(" \u2014 "),jZ=a("a"),BPr=o("TFRobertaForSequenceClassification"),IPr=o(" (RoBERTa model)"),NPr=l(),o5=a("li"),YCe=a("strong"),qPr=o("roformer"),jPr=o(" \u2014 "),DZ=a("a"),DPr=o("TFRoFormerForSequenceClassification"),GPr=o(" (RoFormer model)"),OPr=l(),r5=a("li"),KCe=a("strong"),VPr=o("tapas"),XPr=o(" \u2014 "),GZ=a("a"),zPr=o("TFTapasForSequenceClassification"),WPr=o(" (TAPAS model)"),QPr=l(),t5=a("li"),ZCe=a("strong"),HPr=o("transfo-xl"),UPr=o(" \u2014 "),OZ=a("a"),JPr=o("TFTransfoXLForSequenceClassification"),YPr=o(" (Transformer-XL model)"),KPr=l(),a5=a("li"),e5e=a("strong"),ZPr=o("xlm"),eBr=o(" \u2014 "),VZ=a("a"),oBr=o("TFXLMForSequenceClassification"),rBr=o(" (XLM model)"),tBr=l(),n5=a("li"),o5e=a("strong"),aBr=o("xlm-roberta"),nBr=o(" \u2014 "),XZ=a("a"),sBr=o("TFXLMRobertaForSequenceClassification"),lBr=o(" (XLM-RoBERTa model)"),iBr=l(),s5=a("li"),r5e=a("strong"),dBr=o("xlnet"),cBr=o(" \u2014 "),zZ=a("a"),fBr=o("TFXLNetForSequenceClassification"),mBr=o(" (XLNet model)"),gBr=l(),F(l5.$$.fragment),mHe=l(),qc=a("h2"),i5=a("a"),t5e=a("span"),F(F$.$$.fragment),hBr=l(),a5e=a("span"),pBr=o("TFAutoModelForMultipleChoice"),gHe=l(),fr=a("div"),F(T$.$$.fragment),_Br=l(),jc=a("p"),uBr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),WZ=a("a"),bBr=o("from_pretrained()"),vBr=o(" class method or the "),QZ=a("a"),FBr=o("from_config()"),TBr=o(` class
method.`),MBr=l(),M$=a("p"),EBr=o("This class cannot be instantiated directly using "),n5e=a("code"),CBr=o("__init__()"),wBr=o(" (throws an error)."),ABr=l(),Vt=a("div"),F(E$.$$.fragment),LBr=l(),s5e=a("p"),yBr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),xBr=l(),Dc=a("p"),$Br=o(`Note:
Loading a model from its configuration file does `),l5e=a("strong"),kBr=o("not"),SBr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),HZ=a("a"),RBr=o("from_pretrained()"),PBr=o(" to load the model weights."),BBr=l(),F(d5.$$.fragment),IBr=l(),jr=a("div"),F(C$.$$.fragment),NBr=l(),i5e=a("p"),qBr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),jBr=l(),Fn=a("p"),DBr=o("The model class to instantiate is selected based on the "),d5e=a("code"),GBr=o("model_type"),OBr=o(` property of the config object (either
passed as an argument or loaded from `),c5e=a("code"),VBr=o("pretrained_model_name_or_path"),XBr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f5e=a("code"),zBr=o("pretrained_model_name_or_path"),WBr=o(":"),QBr=l(),ve=a("ul"),c5=a("li"),m5e=a("strong"),HBr=o("albert"),UBr=o(" \u2014 "),UZ=a("a"),JBr=o("TFAlbertForMultipleChoice"),YBr=o(" (ALBERT model)"),KBr=l(),f5=a("li"),g5e=a("strong"),ZBr=o("bert"),eIr=o(" \u2014 "),JZ=a("a"),oIr=o("TFBertForMultipleChoice"),rIr=o(" (BERT model)"),tIr=l(),m5=a("li"),h5e=a("strong"),aIr=o("camembert"),nIr=o(" \u2014 "),YZ=a("a"),sIr=o("TFCamembertForMultipleChoice"),lIr=o(" (CamemBERT model)"),iIr=l(),g5=a("li"),p5e=a("strong"),dIr=o("convbert"),cIr=o(" \u2014 "),KZ=a("a"),fIr=o("TFConvBertForMultipleChoice"),mIr=o(" (ConvBERT model)"),gIr=l(),h5=a("li"),_5e=a("strong"),hIr=o("distilbert"),pIr=o(" \u2014 "),ZZ=a("a"),_Ir=o("TFDistilBertForMultipleChoice"),uIr=o(" (DistilBERT model)"),bIr=l(),p5=a("li"),u5e=a("strong"),vIr=o("electra"),FIr=o(" \u2014 "),eee=a("a"),TIr=o("TFElectraForMultipleChoice"),MIr=o(" (ELECTRA model)"),EIr=l(),_5=a("li"),b5e=a("strong"),CIr=o("flaubert"),wIr=o(" \u2014 "),oee=a("a"),AIr=o("TFFlaubertForMultipleChoice"),LIr=o(" (FlauBERT model)"),yIr=l(),u5=a("li"),v5e=a("strong"),xIr=o("funnel"),$Ir=o(" \u2014 "),ree=a("a"),kIr=o("TFFunnelForMultipleChoice"),SIr=o(" (Funnel Transformer model)"),RIr=l(),b5=a("li"),F5e=a("strong"),PIr=o("longformer"),BIr=o(" \u2014 "),tee=a("a"),IIr=o("TFLongformerForMultipleChoice"),NIr=o(" (Longformer model)"),qIr=l(),v5=a("li"),T5e=a("strong"),jIr=o("mobilebert"),DIr=o(" \u2014 "),aee=a("a"),GIr=o("TFMobileBertForMultipleChoice"),OIr=o(" (MobileBERT model)"),VIr=l(),F5=a("li"),M5e=a("strong"),XIr=o("mpnet"),zIr=o(" \u2014 "),nee=a("a"),WIr=o("TFMPNetForMultipleChoice"),QIr=o(" (MPNet model)"),HIr=l(),T5=a("li"),E5e=a("strong"),UIr=o("rembert"),JIr=o(" \u2014 "),see=a("a"),YIr=o("TFRemBertForMultipleChoice"),KIr=o(" (RemBERT model)"),ZIr=l(),M5=a("li"),C5e=a("strong"),eNr=o("roberta"),oNr=o(" \u2014 "),lee=a("a"),rNr=o("TFRobertaForMultipleChoice"),tNr=o(" (RoBERTa model)"),aNr=l(),E5=a("li"),w5e=a("strong"),nNr=o("roformer"),sNr=o(" \u2014 "),iee=a("a"),lNr=o("TFRoFormerForMultipleChoice"),iNr=o(" (RoFormer model)"),dNr=l(),C5=a("li"),A5e=a("strong"),cNr=o("xlm"),fNr=o(" \u2014 "),dee=a("a"),mNr=o("TFXLMForMultipleChoice"),gNr=o(" (XLM model)"),hNr=l(),w5=a("li"),L5e=a("strong"),pNr=o("xlm-roberta"),_Nr=o(" \u2014 "),cee=a("a"),uNr=o("TFXLMRobertaForMultipleChoice"),bNr=o(" (XLM-RoBERTa model)"),vNr=l(),A5=a("li"),y5e=a("strong"),FNr=o("xlnet"),TNr=o(" \u2014 "),fee=a("a"),MNr=o("TFXLNetForMultipleChoice"),ENr=o(" (XLNet model)"),CNr=l(),F(L5.$$.fragment),hHe=l(),Gc=a("h2"),y5=a("a"),x5e=a("span"),F(w$.$$.fragment),wNr=l(),$5e=a("span"),ANr=o("TFAutoModelForNextSentencePrediction"),pHe=l(),mr=a("div"),F(A$.$$.fragment),LNr=l(),Oc=a("p"),yNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),mee=a("a"),xNr=o("from_pretrained()"),$Nr=o(" class method or the "),gee=a("a"),kNr=o("from_config()"),SNr=o(` class
method.`),RNr=l(),L$=a("p"),PNr=o("This class cannot be instantiated directly using "),k5e=a("code"),BNr=o("__init__()"),INr=o(" (throws an error)."),NNr=l(),Xt=a("div"),F(y$.$$.fragment),qNr=l(),S5e=a("p"),jNr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),DNr=l(),Vc=a("p"),GNr=o(`Note:
Loading a model from its configuration file does `),R5e=a("strong"),ONr=o("not"),VNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hee=a("a"),XNr=o("from_pretrained()"),zNr=o(" to load the model weights."),WNr=l(),F(x5.$$.fragment),QNr=l(),Dr=a("div"),F(x$.$$.fragment),HNr=l(),P5e=a("p"),UNr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),JNr=l(),Tn=a("p"),YNr=o("The model class to instantiate is selected based on the "),B5e=a("code"),KNr=o("model_type"),ZNr=o(` property of the config object (either
passed as an argument or loaded from `),I5e=a("code"),eqr=o("pretrained_model_name_or_path"),oqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N5e=a("code"),rqr=o("pretrained_model_name_or_path"),tqr=o(":"),aqr=l(),$$=a("ul"),$5=a("li"),q5e=a("strong"),nqr=o("bert"),sqr=o(" \u2014 "),pee=a("a"),lqr=o("TFBertForNextSentencePrediction"),iqr=o(" (BERT model)"),dqr=l(),k5=a("li"),j5e=a("strong"),cqr=o("mobilebert"),fqr=o(" \u2014 "),_ee=a("a"),mqr=o("TFMobileBertForNextSentencePrediction"),gqr=o(" (MobileBERT model)"),hqr=l(),F(S5.$$.fragment),_He=l(),Xc=a("h2"),R5=a("a"),D5e=a("span"),F(k$.$$.fragment),pqr=l(),G5e=a("span"),_qr=o("TFAutoModelForTableQuestionAnswering"),uHe=l(),gr=a("div"),F(S$.$$.fragment),uqr=l(),zc=a("p"),bqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),uee=a("a"),vqr=o("from_pretrained()"),Fqr=o(" class method or the "),bee=a("a"),Tqr=o("from_config()"),Mqr=o(` class
method.`),Eqr=l(),R$=a("p"),Cqr=o("This class cannot be instantiated directly using "),O5e=a("code"),wqr=o("__init__()"),Aqr=o(" (throws an error)."),Lqr=l(),zt=a("div"),F(P$.$$.fragment),yqr=l(),V5e=a("p"),xqr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),$qr=l(),Wc=a("p"),kqr=o(`Note:
Loading a model from its configuration file does `),X5e=a("strong"),Sqr=o("not"),Rqr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vee=a("a"),Pqr=o("from_pretrained()"),Bqr=o(" to load the model weights."),Iqr=l(),F(P5.$$.fragment),Nqr=l(),Gr=a("div"),F(B$.$$.fragment),qqr=l(),z5e=a("p"),jqr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),Dqr=l(),Mn=a("p"),Gqr=o("The model class to instantiate is selected based on the "),W5e=a("code"),Oqr=o("model_type"),Vqr=o(` property of the config object (either
passed as an argument or loaded from `),Q5e=a("code"),Xqr=o("pretrained_model_name_or_path"),zqr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H5e=a("code"),Wqr=o("pretrained_model_name_or_path"),Qqr=o(":"),Hqr=l(),U5e=a("ul"),B5=a("li"),J5e=a("strong"),Uqr=o("tapas"),Jqr=o(" \u2014 "),Fee=a("a"),Yqr=o("TFTapasForQuestionAnswering"),Kqr=o(" (TAPAS model)"),Zqr=l(),F(I5.$$.fragment),bHe=l(),Qc=a("h2"),N5=a("a"),Y5e=a("span"),F(I$.$$.fragment),ejr=l(),K5e=a("span"),ojr=o("TFAutoModelForTokenClassification"),vHe=l(),hr=a("div"),F(N$.$$.fragment),rjr=l(),Hc=a("p"),tjr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Tee=a("a"),ajr=o("from_pretrained()"),njr=o(" class method or the "),Mee=a("a"),sjr=o("from_config()"),ljr=o(` class
method.`),ijr=l(),q$=a("p"),djr=o("This class cannot be instantiated directly using "),Z5e=a("code"),cjr=o("__init__()"),fjr=o(" (throws an error)."),mjr=l(),Wt=a("div"),F(j$.$$.fragment),gjr=l(),e3e=a("p"),hjr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),pjr=l(),Uc=a("p"),_jr=o(`Note:
Loading a model from its configuration file does `),o3e=a("strong"),ujr=o("not"),bjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=a("a"),vjr=o("from_pretrained()"),Fjr=o(" to load the model weights."),Tjr=l(),F(q5.$$.fragment),Mjr=l(),Or=a("div"),F(D$.$$.fragment),Ejr=l(),r3e=a("p"),Cjr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),wjr=l(),En=a("p"),Ajr=o("The model class to instantiate is selected based on the "),t3e=a("code"),Ljr=o("model_type"),yjr=o(` property of the config object (either
passed as an argument or loaded from `),a3e=a("code"),xjr=o("pretrained_model_name_or_path"),$jr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n3e=a("code"),kjr=o("pretrained_model_name_or_path"),Sjr=o(":"),Rjr=l(),de=a("ul"),j5=a("li"),s3e=a("strong"),Pjr=o("albert"),Bjr=o(" \u2014 "),Cee=a("a"),Ijr=o("TFAlbertForTokenClassification"),Njr=o(" (ALBERT model)"),qjr=l(),D5=a("li"),l3e=a("strong"),jjr=o("bert"),Djr=o(" \u2014 "),wee=a("a"),Gjr=o("TFBertForTokenClassification"),Ojr=o(" (BERT model)"),Vjr=l(),G5=a("li"),i3e=a("strong"),Xjr=o("camembert"),zjr=o(" \u2014 "),Aee=a("a"),Wjr=o("TFCamembertForTokenClassification"),Qjr=o(" (CamemBERT model)"),Hjr=l(),O5=a("li"),d3e=a("strong"),Ujr=o("convbert"),Jjr=o(" \u2014 "),Lee=a("a"),Yjr=o("TFConvBertForTokenClassification"),Kjr=o(" (ConvBERT model)"),Zjr=l(),V5=a("li"),c3e=a("strong"),eDr=o("deberta"),oDr=o(" \u2014 "),yee=a("a"),rDr=o("TFDebertaForTokenClassification"),tDr=o(" (DeBERTa model)"),aDr=l(),X5=a("li"),f3e=a("strong"),nDr=o("deberta-v2"),sDr=o(" \u2014 "),xee=a("a"),lDr=o("TFDebertaV2ForTokenClassification"),iDr=o(" (DeBERTa-v2 model)"),dDr=l(),z5=a("li"),m3e=a("strong"),cDr=o("distilbert"),fDr=o(" \u2014 "),$ee=a("a"),mDr=o("TFDistilBertForTokenClassification"),gDr=o(" (DistilBERT model)"),hDr=l(),W5=a("li"),g3e=a("strong"),pDr=o("electra"),_Dr=o(" \u2014 "),kee=a("a"),uDr=o("TFElectraForTokenClassification"),bDr=o(" (ELECTRA model)"),vDr=l(),Q5=a("li"),h3e=a("strong"),FDr=o("flaubert"),TDr=o(" \u2014 "),See=a("a"),MDr=o("TFFlaubertForTokenClassification"),EDr=o(" (FlauBERT model)"),CDr=l(),H5=a("li"),p3e=a("strong"),wDr=o("funnel"),ADr=o(" \u2014 "),Ree=a("a"),LDr=o("TFFunnelForTokenClassification"),yDr=o(" (Funnel Transformer model)"),xDr=l(),U5=a("li"),_3e=a("strong"),$Dr=o("layoutlm"),kDr=o(" \u2014 "),Pee=a("a"),SDr=o("TFLayoutLMForTokenClassification"),RDr=o(" (LayoutLM model)"),PDr=l(),J5=a("li"),u3e=a("strong"),BDr=o("longformer"),IDr=o(" \u2014 "),Bee=a("a"),NDr=o("TFLongformerForTokenClassification"),qDr=o(" (Longformer model)"),jDr=l(),Y5=a("li"),b3e=a("strong"),DDr=o("mobilebert"),GDr=o(" \u2014 "),Iee=a("a"),ODr=o("TFMobileBertForTokenClassification"),VDr=o(" (MobileBERT model)"),XDr=l(),K5=a("li"),v3e=a("strong"),zDr=o("mpnet"),WDr=o(" \u2014 "),Nee=a("a"),QDr=o("TFMPNetForTokenClassification"),HDr=o(" (MPNet model)"),UDr=l(),Z5=a("li"),F3e=a("strong"),JDr=o("rembert"),YDr=o(" \u2014 "),qee=a("a"),KDr=o("TFRemBertForTokenClassification"),ZDr=o(" (RemBERT model)"),eGr=l(),e3=a("li"),T3e=a("strong"),oGr=o("roberta"),rGr=o(" \u2014 "),jee=a("a"),tGr=o("TFRobertaForTokenClassification"),aGr=o(" (RoBERTa model)"),nGr=l(),o3=a("li"),M3e=a("strong"),sGr=o("roformer"),lGr=o(" \u2014 "),Dee=a("a"),iGr=o("TFRoFormerForTokenClassification"),dGr=o(" (RoFormer model)"),cGr=l(),r3=a("li"),E3e=a("strong"),fGr=o("xlm"),mGr=o(" \u2014 "),Gee=a("a"),gGr=o("TFXLMForTokenClassification"),hGr=o(" (XLM model)"),pGr=l(),t3=a("li"),C3e=a("strong"),_Gr=o("xlm-roberta"),uGr=o(" \u2014 "),Oee=a("a"),bGr=o("TFXLMRobertaForTokenClassification"),vGr=o(" (XLM-RoBERTa model)"),FGr=l(),a3=a("li"),w3e=a("strong"),TGr=o("xlnet"),MGr=o(" \u2014 "),Vee=a("a"),EGr=o("TFXLNetForTokenClassification"),CGr=o(" (XLNet model)"),wGr=l(),F(n3.$$.fragment),FHe=l(),Jc=a("h2"),s3=a("a"),A3e=a("span"),F(G$.$$.fragment),AGr=l(),L3e=a("span"),LGr=o("TFAutoModelForQuestionAnswering"),THe=l(),pr=a("div"),F(O$.$$.fragment),yGr=l(),Yc=a("p"),xGr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Xee=a("a"),$Gr=o("from_pretrained()"),kGr=o(" class method or the "),zee=a("a"),SGr=o("from_config()"),RGr=o(` class
method.`),PGr=l(),V$=a("p"),BGr=o("This class cannot be instantiated directly using "),y3e=a("code"),IGr=o("__init__()"),NGr=o(" (throws an error)."),qGr=l(),Qt=a("div"),F(X$.$$.fragment),jGr=l(),x3e=a("p"),DGr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),GGr=l(),Kc=a("p"),OGr=o(`Note:
Loading a model from its configuration file does `),$3e=a("strong"),VGr=o("not"),XGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Wee=a("a"),zGr=o("from_pretrained()"),WGr=o(" to load the model weights."),QGr=l(),F(l3.$$.fragment),HGr=l(),Vr=a("div"),F(z$.$$.fragment),UGr=l(),k3e=a("p"),JGr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),YGr=l(),Cn=a("p"),KGr=o("The model class to instantiate is selected based on the "),S3e=a("code"),ZGr=o("model_type"),eOr=o(` property of the config object (either
passed as an argument or loaded from `),R3e=a("code"),oOr=o("pretrained_model_name_or_path"),rOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P3e=a("code"),tOr=o("pretrained_model_name_or_path"),aOr=o(":"),nOr=l(),ce=a("ul"),i3=a("li"),B3e=a("strong"),sOr=o("albert"),lOr=o(" \u2014 "),Qee=a("a"),iOr=o("TFAlbertForQuestionAnswering"),dOr=o(" (ALBERT model)"),cOr=l(),d3=a("li"),I3e=a("strong"),fOr=o("bert"),mOr=o(" \u2014 "),Hee=a("a"),gOr=o("TFBertForQuestionAnswering"),hOr=o(" (BERT model)"),pOr=l(),c3=a("li"),N3e=a("strong"),_Or=o("camembert"),uOr=o(" \u2014 "),Uee=a("a"),bOr=o("TFCamembertForQuestionAnswering"),vOr=o(" (CamemBERT model)"),FOr=l(),f3=a("li"),q3e=a("strong"),TOr=o("convbert"),MOr=o(" \u2014 "),Jee=a("a"),EOr=o("TFConvBertForQuestionAnswering"),COr=o(" (ConvBERT model)"),wOr=l(),m3=a("li"),j3e=a("strong"),AOr=o("deberta"),LOr=o(" \u2014 "),Yee=a("a"),yOr=o("TFDebertaForQuestionAnswering"),xOr=o(" (DeBERTa model)"),$Or=l(),g3=a("li"),D3e=a("strong"),kOr=o("deberta-v2"),SOr=o(" \u2014 "),Kee=a("a"),ROr=o("TFDebertaV2ForQuestionAnswering"),POr=o(" (DeBERTa-v2 model)"),BOr=l(),h3=a("li"),G3e=a("strong"),IOr=o("distilbert"),NOr=o(" \u2014 "),Zee=a("a"),qOr=o("TFDistilBertForQuestionAnswering"),jOr=o(" (DistilBERT model)"),DOr=l(),p3=a("li"),O3e=a("strong"),GOr=o("electra"),OOr=o(" \u2014 "),eoe=a("a"),VOr=o("TFElectraForQuestionAnswering"),XOr=o(" (ELECTRA model)"),zOr=l(),_3=a("li"),V3e=a("strong"),WOr=o("flaubert"),QOr=o(" \u2014 "),ooe=a("a"),HOr=o("TFFlaubertForQuestionAnsweringSimple"),UOr=o(" (FlauBERT model)"),JOr=l(),u3=a("li"),X3e=a("strong"),YOr=o("funnel"),KOr=o(" \u2014 "),roe=a("a"),ZOr=o("TFFunnelForQuestionAnswering"),eVr=o(" (Funnel Transformer model)"),oVr=l(),b3=a("li"),z3e=a("strong"),rVr=o("gptj"),tVr=o(" \u2014 "),toe=a("a"),aVr=o("TFGPTJForQuestionAnswering"),nVr=o(" (GPT-J model)"),sVr=l(),v3=a("li"),W3e=a("strong"),lVr=o("longformer"),iVr=o(" \u2014 "),aoe=a("a"),dVr=o("TFLongformerForQuestionAnswering"),cVr=o(" (Longformer model)"),fVr=l(),F3=a("li"),Q3e=a("strong"),mVr=o("mobilebert"),gVr=o(" \u2014 "),noe=a("a"),hVr=o("TFMobileBertForQuestionAnswering"),pVr=o(" (MobileBERT model)"),_Vr=l(),T3=a("li"),H3e=a("strong"),uVr=o("mpnet"),bVr=o(" \u2014 "),soe=a("a"),vVr=o("TFMPNetForQuestionAnswering"),FVr=o(" (MPNet model)"),TVr=l(),M3=a("li"),U3e=a("strong"),MVr=o("rembert"),EVr=o(" \u2014 "),loe=a("a"),CVr=o("TFRemBertForQuestionAnswering"),wVr=o(" (RemBERT model)"),AVr=l(),E3=a("li"),J3e=a("strong"),LVr=o("roberta"),yVr=o(" \u2014 "),ioe=a("a"),xVr=o("TFRobertaForQuestionAnswering"),$Vr=o(" (RoBERTa model)"),kVr=l(),C3=a("li"),Y3e=a("strong"),SVr=o("roformer"),RVr=o(" \u2014 "),doe=a("a"),PVr=o("TFRoFormerForQuestionAnswering"),BVr=o(" (RoFormer model)"),IVr=l(),w3=a("li"),K3e=a("strong"),NVr=o("xlm"),qVr=o(" \u2014 "),coe=a("a"),jVr=o("TFXLMForQuestionAnsweringSimple"),DVr=o(" (XLM model)"),GVr=l(),A3=a("li"),Z3e=a("strong"),OVr=o("xlm-roberta"),VVr=o(" \u2014 "),foe=a("a"),XVr=o("TFXLMRobertaForQuestionAnswering"),zVr=o(" (XLM-RoBERTa model)"),WVr=l(),L3=a("li"),ewe=a("strong"),QVr=o("xlnet"),HVr=o(" \u2014 "),moe=a("a"),UVr=o("TFXLNetForQuestionAnsweringSimple"),JVr=o(" (XLNet model)"),YVr=l(),F(y3.$$.fragment),MHe=l(),Zc=a("h2"),x3=a("a"),owe=a("span"),F(W$.$$.fragment),KVr=l(),rwe=a("span"),ZVr=o("TFAutoModelForVision2Seq"),EHe=l(),_r=a("div"),F(Q$.$$.fragment),eXr=l(),ef=a("p"),oXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),goe=a("a"),rXr=o("from_pretrained()"),tXr=o(" class method or the "),hoe=a("a"),aXr=o("from_config()"),nXr=o(` class
method.`),sXr=l(),H$=a("p"),lXr=o("This class cannot be instantiated directly using "),twe=a("code"),iXr=o("__init__()"),dXr=o(" (throws an error)."),cXr=l(),Ht=a("div"),F(U$.$$.fragment),fXr=l(),awe=a("p"),mXr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),gXr=l(),of=a("p"),hXr=o(`Note:
Loading a model from its configuration file does `),nwe=a("strong"),pXr=o("not"),_Xr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=a("a"),uXr=o("from_pretrained()"),bXr=o(" to load the model weights."),vXr=l(),F($3.$$.fragment),FXr=l(),Xr=a("div"),F(J$.$$.fragment),TXr=l(),swe=a("p"),MXr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),EXr=l(),wn=a("p"),CXr=o("The model class to instantiate is selected based on the "),lwe=a("code"),wXr=o("model_type"),AXr=o(` property of the config object (either
passed as an argument or loaded from `),iwe=a("code"),LXr=o("pretrained_model_name_or_path"),yXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dwe=a("code"),xXr=o("pretrained_model_name_or_path"),$Xr=o(":"),kXr=l(),cwe=a("ul"),k3=a("li"),fwe=a("strong"),SXr=o("vision-encoder-decoder"),RXr=o(" \u2014 "),_oe=a("a"),PXr=o("TFVisionEncoderDecoderModel"),BXr=o(" (Vision Encoder decoder model)"),IXr=l(),F(S3.$$.fragment),CHe=l(),rf=a("h2"),R3=a("a"),mwe=a("span"),F(Y$.$$.fragment),NXr=l(),gwe=a("span"),qXr=o("TFAutoModelForSpeechSeq2Seq"),wHe=l(),ur=a("div"),F(K$.$$.fragment),jXr=l(),tf=a("p"),DXr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uoe=a("a"),GXr=o("from_pretrained()"),OXr=o(" class method or the "),boe=a("a"),VXr=o("from_config()"),XXr=o(` class
method.`),zXr=l(),Z$=a("p"),WXr=o("This class cannot be instantiated directly using "),hwe=a("code"),QXr=o("__init__()"),HXr=o(" (throws an error)."),UXr=l(),Ut=a("div"),F(ek.$$.fragment),JXr=l(),pwe=a("p"),YXr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),KXr=l(),af=a("p"),ZXr=o(`Note:
Loading a model from its configuration file does `),_we=a("strong"),ezr=o("not"),ozr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),voe=a("a"),rzr=o("from_pretrained()"),tzr=o(" to load the model weights."),azr=l(),F(P3.$$.fragment),nzr=l(),zr=a("div"),F(ok.$$.fragment),szr=l(),uwe=a("p"),lzr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),izr=l(),An=a("p"),dzr=o("The model class to instantiate is selected based on the "),bwe=a("code"),czr=o("model_type"),fzr=o(` property of the config object (either
passed as an argument or loaded from `),vwe=a("code"),mzr=o("pretrained_model_name_or_path"),gzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fwe=a("code"),hzr=o("pretrained_model_name_or_path"),pzr=o(":"),_zr=l(),Twe=a("ul"),B3=a("li"),Mwe=a("strong"),uzr=o("speech_to_text"),bzr=o(" \u2014 "),Foe=a("a"),vzr=o("TFSpeech2TextForConditionalGeneration"),Fzr=o(" (Speech2Text model)"),Tzr=l(),F(I3.$$.fragment),AHe=l(),nf=a("h2"),N3=a("a"),Ewe=a("span"),F(rk.$$.fragment),Mzr=l(),Cwe=a("span"),Ezr=o("FlaxAutoModel"),LHe=l(),br=a("div"),F(tk.$$.fragment),Czr=l(),sf=a("p"),wzr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Toe=a("a"),Azr=o("from_pretrained()"),Lzr=o(" class method or the "),Moe=a("a"),yzr=o("from_config()"),xzr=o(` class
method.`),$zr=l(),ak=a("p"),kzr=o("This class cannot be instantiated directly using "),wwe=a("code"),Szr=o("__init__()"),Rzr=o(" (throws an error)."),Pzr=l(),Jt=a("div"),F(nk.$$.fragment),Bzr=l(),Awe=a("p"),Izr=o("Instantiates one of the base model classes of the library from a configuration."),Nzr=l(),lf=a("p"),qzr=o(`Note:
Loading a model from its configuration file does `),Lwe=a("strong"),jzr=o("not"),Dzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Eoe=a("a"),Gzr=o("from_pretrained()"),Ozr=o(" to load the model weights."),Vzr=l(),F(q3.$$.fragment),Xzr=l(),Wr=a("div"),F(sk.$$.fragment),zzr=l(),ywe=a("p"),Wzr=o("Instantiate one of the base model classes of the library from a pretrained model."),Qzr=l(),Ln=a("p"),Hzr=o("The model class to instantiate is selected based on the "),xwe=a("code"),Uzr=o("model_type"),Jzr=o(` property of the config object (either
passed as an argument or loaded from `),$we=a("code"),Yzr=o("pretrained_model_name_or_path"),Kzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=a("code"),Zzr=o("pretrained_model_name_or_path"),eWr=o(":"),oWr=l(),oe=a("ul"),j3=a("li"),Swe=a("strong"),rWr=o("albert"),tWr=o(" \u2014 "),Coe=a("a"),aWr=o("FlaxAlbertModel"),nWr=o(" (ALBERT model)"),sWr=l(),D3=a("li"),Rwe=a("strong"),lWr=o("bart"),iWr=o(" \u2014 "),woe=a("a"),dWr=o("FlaxBartModel"),cWr=o(" (BART model)"),fWr=l(),G3=a("li"),Pwe=a("strong"),mWr=o("beit"),gWr=o(" \u2014 "),Aoe=a("a"),hWr=o("FlaxBeitModel"),pWr=o(" (BEiT model)"),_Wr=l(),O3=a("li"),Bwe=a("strong"),uWr=o("bert"),bWr=o(" \u2014 "),Loe=a("a"),vWr=o("FlaxBertModel"),FWr=o(" (BERT model)"),TWr=l(),V3=a("li"),Iwe=a("strong"),MWr=o("big_bird"),EWr=o(" \u2014 "),yoe=a("a"),CWr=o("FlaxBigBirdModel"),wWr=o(" (BigBird model)"),AWr=l(),X3=a("li"),Nwe=a("strong"),LWr=o("blenderbot"),yWr=o(" \u2014 "),xoe=a("a"),xWr=o("FlaxBlenderbotModel"),$Wr=o(" (Blenderbot model)"),kWr=l(),z3=a("li"),qwe=a("strong"),SWr=o("blenderbot-small"),RWr=o(" \u2014 "),$oe=a("a"),PWr=o("FlaxBlenderbotSmallModel"),BWr=o(" (BlenderbotSmall model)"),IWr=l(),W3=a("li"),jwe=a("strong"),NWr=o("bloom"),qWr=o(" \u2014 "),koe=a("a"),jWr=o("FlaxBloomModel"),DWr=o(" (BLOOM model)"),GWr=l(),Q3=a("li"),Dwe=a("strong"),OWr=o("clip"),VWr=o(" \u2014 "),Soe=a("a"),XWr=o("FlaxCLIPModel"),zWr=o(" (CLIP model)"),WWr=l(),H3=a("li"),Gwe=a("strong"),QWr=o("distilbert"),HWr=o(" \u2014 "),Roe=a("a"),UWr=o("FlaxDistilBertModel"),JWr=o(" (DistilBERT model)"),YWr=l(),U3=a("li"),Owe=a("strong"),KWr=o("electra"),ZWr=o(" \u2014 "),Poe=a("a"),eQr=o("FlaxElectraModel"),oQr=o(" (ELECTRA model)"),rQr=l(),J3=a("li"),Vwe=a("strong"),tQr=o("gpt2"),aQr=o(" \u2014 "),Boe=a("a"),nQr=o("FlaxGPT2Model"),sQr=o(" (OpenAI GPT-2 model)"),lQr=l(),Y3=a("li"),Xwe=a("strong"),iQr=o("gpt_neo"),dQr=o(" \u2014 "),Ioe=a("a"),cQr=o("FlaxGPTNeoModel"),fQr=o(" (GPT Neo model)"),mQr=l(),K3=a("li"),zwe=a("strong"),gQr=o("gptj"),hQr=o(" \u2014 "),Noe=a("a"),pQr=o("FlaxGPTJModel"),_Qr=o(" (GPT-J model)"),uQr=l(),Z3=a("li"),Wwe=a("strong"),bQr=o("longt5"),vQr=o(" \u2014 "),qoe=a("a"),FQr=o("FlaxLongT5Model"),TQr=o(" (LongT5 model)"),MQr=l(),ew=a("li"),Qwe=a("strong"),EQr=o("marian"),CQr=o(" \u2014 "),joe=a("a"),wQr=o("FlaxMarianModel"),AQr=o(" (Marian model)"),LQr=l(),ow=a("li"),Hwe=a("strong"),yQr=o("mbart"),xQr=o(" \u2014 "),Doe=a("a"),$Qr=o("FlaxMBartModel"),kQr=o(" (mBART model)"),SQr=l(),rw=a("li"),Uwe=a("strong"),RQr=o("mt5"),PQr=o(" \u2014 "),Goe=a("a"),BQr=o("FlaxMT5Model"),IQr=o(" (MT5 model)"),NQr=l(),tw=a("li"),Jwe=a("strong"),qQr=o("opt"),jQr=o(" \u2014 "),Ooe=a("a"),DQr=o("FlaxOPTModel"),GQr=o(" (OPT model)"),OQr=l(),aw=a("li"),Ywe=a("strong"),VQr=o("pegasus"),XQr=o(" \u2014 "),Voe=a("a"),zQr=o("FlaxPegasusModel"),WQr=o(" (Pegasus model)"),QQr=l(),nw=a("li"),Kwe=a("strong"),HQr=o("roberta"),UQr=o(" \u2014 "),Xoe=a("a"),JQr=o("FlaxRobertaModel"),YQr=o(" (RoBERTa model)"),KQr=l(),sw=a("li"),Zwe=a("strong"),ZQr=o("roformer"),eHr=o(" \u2014 "),zoe=a("a"),oHr=o("FlaxRoFormerModel"),rHr=o(" (RoFormer model)"),tHr=l(),lw=a("li"),e6e=a("strong"),aHr=o("t5"),nHr=o(" \u2014 "),Woe=a("a"),sHr=o("FlaxT5Model"),lHr=o(" (T5 model)"),iHr=l(),iw=a("li"),o6e=a("strong"),dHr=o("vision-text-dual-encoder"),cHr=o(" \u2014 "),Qoe=a("a"),fHr=o("FlaxVisionTextDualEncoderModel"),mHr=o(" (VisionTextDualEncoder model)"),gHr=l(),dw=a("li"),r6e=a("strong"),hHr=o("vit"),pHr=o(" \u2014 "),Hoe=a("a"),_Hr=o("FlaxViTModel"),uHr=o(" (ViT model)"),bHr=l(),cw=a("li"),t6e=a("strong"),vHr=o("wav2vec2"),FHr=o(" \u2014 "),Uoe=a("a"),THr=o("FlaxWav2Vec2Model"),MHr=o(" (Wav2Vec2 model)"),EHr=l(),fw=a("li"),a6e=a("strong"),CHr=o("xglm"),wHr=o(" \u2014 "),Joe=a("a"),AHr=o("FlaxXGLMModel"),LHr=o(" (XGLM model)"),yHr=l(),mw=a("li"),n6e=a("strong"),xHr=o("xlm-roberta"),$Hr=o(" \u2014 "),Yoe=a("a"),kHr=o("FlaxXLMRobertaModel"),SHr=o(" (XLM-RoBERTa model)"),RHr=l(),F(gw.$$.fragment),yHe=l(),df=a("h2"),hw=a("a"),s6e=a("span"),F(lk.$$.fragment),PHr=l(),l6e=a("span"),BHr=o("FlaxAutoModelForCausalLM"),xHe=l(),vr=a("div"),F(ik.$$.fragment),IHr=l(),cf=a("p"),NHr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Koe=a("a"),qHr=o("from_pretrained()"),jHr=o(" class method or the "),Zoe=a("a"),DHr=o("from_config()"),GHr=o(` class
method.`),OHr=l(),dk=a("p"),VHr=o("This class cannot be instantiated directly using "),i6e=a("code"),XHr=o("__init__()"),zHr=o(" (throws an error)."),WHr=l(),Yt=a("div"),F(ck.$$.fragment),QHr=l(),d6e=a("p"),HHr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),UHr=l(),ff=a("p"),JHr=o(`Note:
Loading a model from its configuration file does `),c6e=a("strong"),YHr=o("not"),KHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ere=a("a"),ZHr=o("from_pretrained()"),eUr=o(" to load the model weights."),oUr=l(),F(pw.$$.fragment),rUr=l(),Qr=a("div"),F(fk.$$.fragment),tUr=l(),f6e=a("p"),aUr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),nUr=l(),yn=a("p"),sUr=o("The model class to instantiate is selected based on the "),m6e=a("code"),lUr=o("model_type"),iUr=o(` property of the config object (either
passed as an argument or loaded from `),g6e=a("code"),dUr=o("pretrained_model_name_or_path"),cUr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h6e=a("code"),fUr=o("pretrained_model_name_or_path"),mUr=o(":"),gUr=l(),Ae=a("ul"),_w=a("li"),p6e=a("strong"),hUr=o("bart"),pUr=o(" \u2014 "),ore=a("a"),_Ur=o("FlaxBartForCausalLM"),uUr=o(" (BART model)"),bUr=l(),uw=a("li"),_6e=a("strong"),vUr=o("bert"),FUr=o(" \u2014 "),rre=a("a"),TUr=o("FlaxBertForCausalLM"),MUr=o(" (BERT model)"),EUr=l(),bw=a("li"),u6e=a("strong"),CUr=o("big_bird"),wUr=o(" \u2014 "),tre=a("a"),AUr=o("FlaxBigBirdForCausalLM"),LUr=o(" (BigBird model)"),yUr=l(),vw=a("li"),b6e=a("strong"),xUr=o("bloom"),$Ur=o(" \u2014 "),are=a("a"),kUr=o("FlaxBloomForCausalLM"),SUr=o(" (BLOOM model)"),RUr=l(),Fw=a("li"),v6e=a("strong"),PUr=o("electra"),BUr=o(" \u2014 "),nre=a("a"),IUr=o("FlaxElectraForCausalLM"),NUr=o(" (ELECTRA model)"),qUr=l(),Tw=a("li"),F6e=a("strong"),jUr=o("gpt2"),DUr=o(" \u2014 "),sre=a("a"),GUr=o("FlaxGPT2LMHeadModel"),OUr=o(" (OpenAI GPT-2 model)"),VUr=l(),Mw=a("li"),T6e=a("strong"),XUr=o("gpt_neo"),zUr=o(" \u2014 "),lre=a("a"),WUr=o("FlaxGPTNeoForCausalLM"),QUr=o(" (GPT Neo model)"),HUr=l(),Ew=a("li"),M6e=a("strong"),UUr=o("gptj"),JUr=o(" \u2014 "),ire=a("a"),YUr=o("FlaxGPTJForCausalLM"),KUr=o(" (GPT-J model)"),ZUr=l(),Cw=a("li"),E6e=a("strong"),eJr=o("opt"),oJr=o(" \u2014 "),dre=a("a"),rJr=o("FlaxOPTForCausalLM"),tJr=o(" (OPT model)"),aJr=l(),ww=a("li"),C6e=a("strong"),nJr=o("roberta"),sJr=o(" \u2014 "),cre=a("a"),lJr=o("FlaxRobertaForCausalLM"),iJr=o(" (RoBERTa model)"),dJr=l(),Aw=a("li"),w6e=a("strong"),cJr=o("xglm"),fJr=o(" \u2014 "),fre=a("a"),mJr=o("FlaxXGLMForCausalLM"),gJr=o(" (XGLM model)"),hJr=l(),F(Lw.$$.fragment),$He=l(),mf=a("h2"),yw=a("a"),A6e=a("span"),F(mk.$$.fragment),pJr=l(),L6e=a("span"),_Jr=o("FlaxAutoModelForPreTraining"),kHe=l(),Fr=a("div"),F(gk.$$.fragment),uJr=l(),gf=a("p"),bJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mre=a("a"),vJr=o("from_pretrained()"),FJr=o(" class method or the "),gre=a("a"),TJr=o("from_config()"),MJr=o(` class
method.`),EJr=l(),hk=a("p"),CJr=o("This class cannot be instantiated directly using "),y6e=a("code"),wJr=o("__init__()"),AJr=o(" (throws an error)."),LJr=l(),Kt=a("div"),F(pk.$$.fragment),yJr=l(),x6e=a("p"),xJr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),$Jr=l(),hf=a("p"),kJr=o(`Note:
Loading a model from its configuration file does `),$6e=a("strong"),SJr=o("not"),RJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),hre=a("a"),PJr=o("from_pretrained()"),BJr=o(" to load the model weights."),IJr=l(),F(xw.$$.fragment),NJr=l(),Hr=a("div"),F(_k.$$.fragment),qJr=l(),k6e=a("p"),jJr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),DJr=l(),xn=a("p"),GJr=o("The model class to instantiate is selected based on the "),S6e=a("code"),OJr=o("model_type"),VJr=o(` property of the config object (either
passed as an argument or loaded from `),R6e=a("code"),XJr=o("pretrained_model_name_or_path"),zJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P6e=a("code"),WJr=o("pretrained_model_name_or_path"),QJr=o(":"),HJr=l(),Ee=a("ul"),$w=a("li"),B6e=a("strong"),UJr=o("albert"),JJr=o(" \u2014 "),pre=a("a"),YJr=o("FlaxAlbertForPreTraining"),KJr=o(" (ALBERT model)"),ZJr=l(),kw=a("li"),I6e=a("strong"),eYr=o("bart"),oYr=o(" \u2014 "),_re=a("a"),rYr=o("FlaxBartForConditionalGeneration"),tYr=o(" (BART model)"),aYr=l(),Sw=a("li"),N6e=a("strong"),nYr=o("bert"),sYr=o(" \u2014 "),ure=a("a"),lYr=o("FlaxBertForPreTraining"),iYr=o(" (BERT model)"),dYr=l(),Rw=a("li"),q6e=a("strong"),cYr=o("big_bird"),fYr=o(" \u2014 "),bre=a("a"),mYr=o("FlaxBigBirdForPreTraining"),gYr=o(" (BigBird model)"),hYr=l(),Pw=a("li"),j6e=a("strong"),pYr=o("electra"),_Yr=o(" \u2014 "),vre=a("a"),uYr=o("FlaxElectraForPreTraining"),bYr=o(" (ELECTRA model)"),vYr=l(),Bw=a("li"),D6e=a("strong"),FYr=o("longt5"),TYr=o(" \u2014 "),Fre=a("a"),MYr=o("FlaxLongT5ForConditionalGeneration"),EYr=o(" (LongT5 model)"),CYr=l(),Iw=a("li"),G6e=a("strong"),wYr=o("mbart"),AYr=o(" \u2014 "),Tre=a("a"),LYr=o("FlaxMBartForConditionalGeneration"),yYr=o(" (mBART model)"),xYr=l(),Nw=a("li"),O6e=a("strong"),$Yr=o("mt5"),kYr=o(" \u2014 "),Mre=a("a"),SYr=o("FlaxMT5ForConditionalGeneration"),RYr=o(" (MT5 model)"),PYr=l(),qw=a("li"),V6e=a("strong"),BYr=o("roberta"),IYr=o(" \u2014 "),Ere=a("a"),NYr=o("FlaxRobertaForMaskedLM"),qYr=o(" (RoBERTa model)"),jYr=l(),jw=a("li"),X6e=a("strong"),DYr=o("roformer"),GYr=o(" \u2014 "),Cre=a("a"),OYr=o("FlaxRoFormerForMaskedLM"),VYr=o(" (RoFormer model)"),XYr=l(),Dw=a("li"),z6e=a("strong"),zYr=o("t5"),WYr=o(" \u2014 "),wre=a("a"),QYr=o("FlaxT5ForConditionalGeneration"),HYr=o(" (T5 model)"),UYr=l(),Gw=a("li"),W6e=a("strong"),JYr=o("wav2vec2"),YYr=o(" \u2014 "),Are=a("a"),KYr=o("FlaxWav2Vec2ForPreTraining"),ZYr=o(" (Wav2Vec2 model)"),eKr=l(),Ow=a("li"),Q6e=a("strong"),oKr=o("xlm-roberta"),rKr=o(" \u2014 "),Lre=a("a"),tKr=o("FlaxXLMRobertaForMaskedLM"),aKr=o(" (XLM-RoBERTa model)"),nKr=l(),F(Vw.$$.fragment),SHe=l(),pf=a("h2"),Xw=a("a"),H6e=a("span"),F(uk.$$.fragment),sKr=l(),U6e=a("span"),lKr=o("FlaxAutoModelForMaskedLM"),RHe=l(),Tr=a("div"),F(bk.$$.fragment),iKr=l(),_f=a("p"),dKr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),yre=a("a"),cKr=o("from_pretrained()"),fKr=o(" class method or the "),xre=a("a"),mKr=o("from_config()"),gKr=o(` class
method.`),hKr=l(),vk=a("p"),pKr=o("This class cannot be instantiated directly using "),J6e=a("code"),_Kr=o("__init__()"),uKr=o(" (throws an error)."),bKr=l(),Zt=a("div"),F(Fk.$$.fragment),vKr=l(),Y6e=a("p"),FKr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),TKr=l(),uf=a("p"),MKr=o(`Note:
Loading a model from its configuration file does `),K6e=a("strong"),EKr=o("not"),CKr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),$re=a("a"),wKr=o("from_pretrained()"),AKr=o(" to load the model weights."),LKr=l(),F(zw.$$.fragment),yKr=l(),Ur=a("div"),F(Tk.$$.fragment),xKr=l(),Z6e=a("p"),$Kr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),kKr=l(),$n=a("p"),SKr=o("The model class to instantiate is selected based on the "),eAe=a("code"),RKr=o("model_type"),PKr=o(` property of the config object (either
passed as an argument or loaded from `),oAe=a("code"),BKr=o("pretrained_model_name_or_path"),IKr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rAe=a("code"),NKr=o("pretrained_model_name_or_path"),qKr=o(":"),jKr=l(),$e=a("ul"),Ww=a("li"),tAe=a("strong"),DKr=o("albert"),GKr=o(" \u2014 "),kre=a("a"),OKr=o("FlaxAlbertForMaskedLM"),VKr=o(" (ALBERT model)"),XKr=l(),Qw=a("li"),aAe=a("strong"),zKr=o("bart"),WKr=o(" \u2014 "),Sre=a("a"),QKr=o("FlaxBartForConditionalGeneration"),HKr=o(" (BART model)"),UKr=l(),Hw=a("li"),nAe=a("strong"),JKr=o("bert"),YKr=o(" \u2014 "),Rre=a("a"),KKr=o("FlaxBertForMaskedLM"),ZKr=o(" (BERT model)"),eZr=l(),Uw=a("li"),sAe=a("strong"),oZr=o("big_bird"),rZr=o(" \u2014 "),Pre=a("a"),tZr=o("FlaxBigBirdForMaskedLM"),aZr=o(" (BigBird model)"),nZr=l(),Jw=a("li"),lAe=a("strong"),sZr=o("distilbert"),lZr=o(" \u2014 "),Bre=a("a"),iZr=o("FlaxDistilBertForMaskedLM"),dZr=o(" (DistilBERT model)"),cZr=l(),Yw=a("li"),iAe=a("strong"),fZr=o("electra"),mZr=o(" \u2014 "),Ire=a("a"),gZr=o("FlaxElectraForMaskedLM"),hZr=o(" (ELECTRA model)"),pZr=l(),Kw=a("li"),dAe=a("strong"),_Zr=o("mbart"),uZr=o(" \u2014 "),Nre=a("a"),bZr=o("FlaxMBartForConditionalGeneration"),vZr=o(" (mBART model)"),FZr=l(),Zw=a("li"),cAe=a("strong"),TZr=o("roberta"),MZr=o(" \u2014 "),qre=a("a"),EZr=o("FlaxRobertaForMaskedLM"),CZr=o(" (RoBERTa model)"),wZr=l(),e6=a("li"),fAe=a("strong"),AZr=o("roformer"),LZr=o(" \u2014 "),jre=a("a"),yZr=o("FlaxRoFormerForMaskedLM"),xZr=o(" (RoFormer model)"),$Zr=l(),o6=a("li"),mAe=a("strong"),kZr=o("xlm-roberta"),SZr=o(" \u2014 "),Dre=a("a"),RZr=o("FlaxXLMRobertaForMaskedLM"),PZr=o(" (XLM-RoBERTa model)"),BZr=l(),F(r6.$$.fragment),PHe=l(),bf=a("h2"),t6=a("a"),gAe=a("span"),F(Mk.$$.fragment),IZr=l(),hAe=a("span"),NZr=o("FlaxAutoModelForSeq2SeqLM"),BHe=l(),Mr=a("div"),F(Ek.$$.fragment),qZr=l(),vf=a("p"),jZr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Gre=a("a"),DZr=o("from_pretrained()"),GZr=o(" class method or the "),Ore=a("a"),OZr=o("from_config()"),VZr=o(` class
method.`),XZr=l(),Ck=a("p"),zZr=o("This class cannot be instantiated directly using "),pAe=a("code"),WZr=o("__init__()"),QZr=o(" (throws an error)."),HZr=l(),ea=a("div"),F(wk.$$.fragment),UZr=l(),_Ae=a("p"),JZr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),YZr=l(),Ff=a("p"),KZr=o(`Note:
Loading a model from its configuration file does `),uAe=a("strong"),ZZr=o("not"),eet=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Vre=a("a"),oet=o("from_pretrained()"),ret=o(" to load the model weights."),tet=l(),F(a6.$$.fragment),aet=l(),Jr=a("div"),F(Ak.$$.fragment),net=l(),bAe=a("p"),set=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),iet=l(),kn=a("p"),det=o("The model class to instantiate is selected based on the "),vAe=a("code"),cet=o("model_type"),fet=o(` property of the config object (either
passed as an argument or loaded from `),FAe=a("code"),met=o("pretrained_model_name_or_path"),get=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TAe=a("code"),het=o("pretrained_model_name_or_path"),pet=o(":"),_et=l(),ke=a("ul"),n6=a("li"),MAe=a("strong"),uet=o("bart"),bet=o(" \u2014 "),Xre=a("a"),vet=o("FlaxBartForConditionalGeneration"),Fet=o(" (BART model)"),Tet=l(),s6=a("li"),EAe=a("strong"),Met=o("blenderbot"),Eet=o(" \u2014 "),zre=a("a"),Cet=o("FlaxBlenderbotForConditionalGeneration"),wet=o(" (Blenderbot model)"),Aet=l(),l6=a("li"),CAe=a("strong"),Let=o("blenderbot-small"),yet=o(" \u2014 "),Wre=a("a"),xet=o("FlaxBlenderbotSmallForConditionalGeneration"),$et=o(" (BlenderbotSmall model)"),ket=l(),i6=a("li"),wAe=a("strong"),Set=o("encoder-decoder"),Ret=o(" \u2014 "),Qre=a("a"),Pet=o("FlaxEncoderDecoderModel"),Bet=o(" (Encoder decoder model)"),Iet=l(),d6=a("li"),AAe=a("strong"),Net=o("longt5"),qet=o(" \u2014 "),Hre=a("a"),jet=o("FlaxLongT5ForConditionalGeneration"),Det=o(" (LongT5 model)"),Get=l(),c6=a("li"),LAe=a("strong"),Oet=o("marian"),Vet=o(" \u2014 "),Ure=a("a"),Xet=o("FlaxMarianMTModel"),zet=o(" (Marian model)"),Wet=l(),f6=a("li"),yAe=a("strong"),Qet=o("mbart"),Het=o(" \u2014 "),Jre=a("a"),Uet=o("FlaxMBartForConditionalGeneration"),Jet=o(" (mBART model)"),Yet=l(),m6=a("li"),xAe=a("strong"),Ket=o("mt5"),Zet=o(" \u2014 "),Yre=a("a"),eot=o("FlaxMT5ForConditionalGeneration"),oot=o(" (MT5 model)"),rot=l(),g6=a("li"),$Ae=a("strong"),tot=o("pegasus"),aot=o(" \u2014 "),Kre=a("a"),not=o("FlaxPegasusForConditionalGeneration"),sot=o(" (Pegasus model)"),lot=l(),h6=a("li"),kAe=a("strong"),iot=o("t5"),dot=o(" \u2014 "),Zre=a("a"),cot=o("FlaxT5ForConditionalGeneration"),fot=o(" (T5 model)"),mot=l(),F(p6.$$.fragment),IHe=l(),Tf=a("h2"),_6=a("a"),SAe=a("span"),F(Lk.$$.fragment),got=l(),RAe=a("span"),hot=o("FlaxAutoModelForSequenceClassification"),NHe=l(),Er=a("div"),F(yk.$$.fragment),pot=l(),Mf=a("p"),_ot=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ete=a("a"),uot=o("from_pretrained()"),bot=o(" class method or the "),ote=a("a"),vot=o("from_config()"),Fot=o(` class
method.`),Tot=l(),xk=a("p"),Mot=o("This class cannot be instantiated directly using "),PAe=a("code"),Eot=o("__init__()"),Cot=o(" (throws an error)."),wot=l(),oa=a("div"),F($k.$$.fragment),Aot=l(),BAe=a("p"),Lot=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),yot=l(),Ef=a("p"),xot=o(`Note:
Loading a model from its configuration file does `),IAe=a("strong"),$ot=o("not"),kot=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),rte=a("a"),Sot=o("from_pretrained()"),Rot=o(" to load the model weights."),Pot=l(),F(u6.$$.fragment),Bot=l(),Yr=a("div"),F(kk.$$.fragment),Iot=l(),NAe=a("p"),Not=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),qot=l(),Sn=a("p"),jot=o("The model class to instantiate is selected based on the "),qAe=a("code"),Dot=o("model_type"),Got=o(` property of the config object (either
passed as an argument or loaded from `),jAe=a("code"),Oot=o("pretrained_model_name_or_path"),Vot=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DAe=a("code"),Xot=o("pretrained_model_name_or_path"),zot=o(":"),Wot=l(),Se=a("ul"),b6=a("li"),GAe=a("strong"),Qot=o("albert"),Hot=o(" \u2014 "),tte=a("a"),Uot=o("FlaxAlbertForSequenceClassification"),Jot=o(" (ALBERT model)"),Yot=l(),v6=a("li"),OAe=a("strong"),Kot=o("bart"),Zot=o(" \u2014 "),ate=a("a"),ert=o("FlaxBartForSequenceClassification"),ort=o(" (BART model)"),rrt=l(),F6=a("li"),VAe=a("strong"),trt=o("bert"),art=o(" \u2014 "),nte=a("a"),nrt=o("FlaxBertForSequenceClassification"),srt=o(" (BERT model)"),lrt=l(),T6=a("li"),XAe=a("strong"),irt=o("big_bird"),drt=o(" \u2014 "),ste=a("a"),crt=o("FlaxBigBirdForSequenceClassification"),frt=o(" (BigBird model)"),mrt=l(),M6=a("li"),zAe=a("strong"),grt=o("distilbert"),hrt=o(" \u2014 "),lte=a("a"),prt=o("FlaxDistilBertForSequenceClassification"),_rt=o(" (DistilBERT model)"),urt=l(),E6=a("li"),WAe=a("strong"),brt=o("electra"),vrt=o(" \u2014 "),ite=a("a"),Frt=o("FlaxElectraForSequenceClassification"),Trt=o(" (ELECTRA model)"),Mrt=l(),C6=a("li"),QAe=a("strong"),Ert=o("mbart"),Crt=o(" \u2014 "),dte=a("a"),wrt=o("FlaxMBartForSequenceClassification"),Art=o(" (mBART model)"),Lrt=l(),w6=a("li"),HAe=a("strong"),yrt=o("roberta"),xrt=o(" \u2014 "),cte=a("a"),$rt=o("FlaxRobertaForSequenceClassification"),krt=o(" (RoBERTa model)"),Srt=l(),A6=a("li"),UAe=a("strong"),Rrt=o("roformer"),Prt=o(" \u2014 "),fte=a("a"),Brt=o("FlaxRoFormerForSequenceClassification"),Irt=o(" (RoFormer model)"),Nrt=l(),L6=a("li"),JAe=a("strong"),qrt=o("xlm-roberta"),jrt=o(" \u2014 "),mte=a("a"),Drt=o("FlaxXLMRobertaForSequenceClassification"),Grt=o(" (XLM-RoBERTa model)"),Ort=l(),F(y6.$$.fragment),qHe=l(),Cf=a("h2"),x6=a("a"),YAe=a("span"),F(Sk.$$.fragment),Vrt=l(),KAe=a("span"),Xrt=o("FlaxAutoModelForQuestionAnswering"),jHe=l(),Cr=a("div"),F(Rk.$$.fragment),zrt=l(),wf=a("p"),Wrt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),gte=a("a"),Qrt=o("from_pretrained()"),Hrt=o(" class method or the "),hte=a("a"),Urt=o("from_config()"),Jrt=o(` class
method.`),Yrt=l(),Pk=a("p"),Krt=o("This class cannot be instantiated directly using "),ZAe=a("code"),Zrt=o("__init__()"),ett=o(" (throws an error)."),ott=l(),ra=a("div"),F(Bk.$$.fragment),rtt=l(),e7e=a("p"),ttt=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),att=l(),Af=a("p"),ntt=o(`Note:
Loading a model from its configuration file does `),o7e=a("strong"),stt=o("not"),ltt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),pte=a("a"),itt=o("from_pretrained()"),dtt=o(" to load the model weights."),ctt=l(),F($6.$$.fragment),ftt=l(),Kr=a("div"),F(Ik.$$.fragment),mtt=l(),r7e=a("p"),gtt=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),htt=l(),Rn=a("p"),ptt=o("The model class to instantiate is selected based on the "),t7e=a("code"),_tt=o("model_type"),utt=o(` property of the config object (either
passed as an argument or loaded from `),a7e=a("code"),btt=o("pretrained_model_name_or_path"),vtt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=a("code"),Ftt=o("pretrained_model_name_or_path"),Ttt=o(":"),Mtt=l(),Re=a("ul"),k6=a("li"),s7e=a("strong"),Ett=o("albert"),Ctt=o(" \u2014 "),_te=a("a"),wtt=o("FlaxAlbertForQuestionAnswering"),Att=o(" (ALBERT model)"),Ltt=l(),S6=a("li"),l7e=a("strong"),ytt=o("bart"),xtt=o(" \u2014 "),ute=a("a"),$tt=o("FlaxBartForQuestionAnswering"),ktt=o(" (BART model)"),Stt=l(),R6=a("li"),i7e=a("strong"),Rtt=o("bert"),Ptt=o(" \u2014 "),bte=a("a"),Btt=o("FlaxBertForQuestionAnswering"),Itt=o(" (BERT model)"),Ntt=l(),P6=a("li"),d7e=a("strong"),qtt=o("big_bird"),jtt=o(" \u2014 "),vte=a("a"),Dtt=o("FlaxBigBirdForQuestionAnswering"),Gtt=o(" (BigBird model)"),Ott=l(),B6=a("li"),c7e=a("strong"),Vtt=o("distilbert"),Xtt=o(" \u2014 "),Fte=a("a"),ztt=o("FlaxDistilBertForQuestionAnswering"),Wtt=o(" (DistilBERT model)"),Qtt=l(),I6=a("li"),f7e=a("strong"),Htt=o("electra"),Utt=o(" \u2014 "),Tte=a("a"),Jtt=o("FlaxElectraForQuestionAnswering"),Ytt=o(" (ELECTRA model)"),Ktt=l(),N6=a("li"),m7e=a("strong"),Ztt=o("mbart"),eat=o(" \u2014 "),Mte=a("a"),oat=o("FlaxMBartForQuestionAnswering"),rat=o(" (mBART model)"),tat=l(),q6=a("li"),g7e=a("strong"),aat=o("roberta"),nat=o(" \u2014 "),Ete=a("a"),sat=o("FlaxRobertaForQuestionAnswering"),lat=o(" (RoBERTa model)"),iat=l(),j6=a("li"),h7e=a("strong"),dat=o("roformer"),cat=o(" \u2014 "),Cte=a("a"),fat=o("FlaxRoFormerForQuestionAnswering"),mat=o(" (RoFormer model)"),gat=l(),D6=a("li"),p7e=a("strong"),hat=o("xlm-roberta"),pat=o(" \u2014 "),wte=a("a"),_at=o("FlaxXLMRobertaForQuestionAnswering"),uat=o(" (XLM-RoBERTa model)"),bat=l(),F(G6.$$.fragment),DHe=l(),Lf=a("h2"),O6=a("a"),_7e=a("span"),F(Nk.$$.fragment),vat=l(),u7e=a("span"),Fat=o("FlaxAutoModelForTokenClassification"),GHe=l(),wr=a("div"),F(qk.$$.fragment),Tat=l(),yf=a("p"),Mat=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Ate=a("a"),Eat=o("from_pretrained()"),Cat=o(" class method or the "),Lte=a("a"),wat=o("from_config()"),Aat=o(` class
method.`),Lat=l(),jk=a("p"),yat=o("This class cannot be instantiated directly using "),b7e=a("code"),xat=o("__init__()"),$at=o(" (throws an error)."),kat=l(),ta=a("div"),F(Dk.$$.fragment),Sat=l(),v7e=a("p"),Rat=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Pat=l(),xf=a("p"),Bat=o(`Note:
Loading a model from its configuration file does `),F7e=a("strong"),Iat=o("not"),Nat=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yte=a("a"),qat=o("from_pretrained()"),jat=o(" to load the model weights."),Dat=l(),F(V6.$$.fragment),Gat=l(),Zr=a("div"),F(Gk.$$.fragment),Oat=l(),T7e=a("p"),Vat=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),Xat=l(),Pn=a("p"),zat=o("The model class to instantiate is selected based on the "),M7e=a("code"),Wat=o("model_type"),Qat=o(` property of the config object (either
passed as an argument or loaded from `),E7e=a("code"),Hat=o("pretrained_model_name_or_path"),Uat=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=a("code"),Jat=o("pretrained_model_name_or_path"),Yat=o(":"),Kat=l(),Xe=a("ul"),X6=a("li"),w7e=a("strong"),Zat=o("albert"),ent=o(" \u2014 "),xte=a("a"),ont=o("FlaxAlbertForTokenClassification"),rnt=o(" (ALBERT model)"),tnt=l(),z6=a("li"),A7e=a("strong"),ant=o("bert"),nnt=o(" \u2014 "),$te=a("a"),snt=o("FlaxBertForTokenClassification"),lnt=o(" (BERT model)"),int=l(),W6=a("li"),L7e=a("strong"),dnt=o("big_bird"),cnt=o(" \u2014 "),kte=a("a"),fnt=o("FlaxBigBirdForTokenClassification"),mnt=o(" (BigBird model)"),gnt=l(),Q6=a("li"),y7e=a("strong"),hnt=o("distilbert"),pnt=o(" \u2014 "),Ste=a("a"),_nt=o("FlaxDistilBertForTokenClassification"),unt=o(" (DistilBERT model)"),bnt=l(),H6=a("li"),x7e=a("strong"),vnt=o("electra"),Fnt=o(" \u2014 "),Rte=a("a"),Tnt=o("FlaxElectraForTokenClassification"),Mnt=o(" (ELECTRA model)"),Ent=l(),U6=a("li"),$7e=a("strong"),Cnt=o("roberta"),wnt=o(" \u2014 "),Pte=a("a"),Ant=o("FlaxRobertaForTokenClassification"),Lnt=o(" (RoBERTa model)"),ynt=l(),J6=a("li"),k7e=a("strong"),xnt=o("roformer"),$nt=o(" \u2014 "),Bte=a("a"),knt=o("FlaxRoFormerForTokenClassification"),Snt=o(" (RoFormer model)"),Rnt=l(),Y6=a("li"),S7e=a("strong"),Pnt=o("xlm-roberta"),Bnt=o(" \u2014 "),Ite=a("a"),Int=o("FlaxXLMRobertaForTokenClassification"),Nnt=o(" (XLM-RoBERTa model)"),qnt=l(),F(K6.$$.fragment),OHe=l(),$f=a("h2"),Z6=a("a"),R7e=a("span"),F(Ok.$$.fragment),jnt=l(),P7e=a("span"),Dnt=o("FlaxAutoModelForMultipleChoice"),VHe=l(),Ar=a("div"),F(Vk.$$.fragment),Gnt=l(),kf=a("p"),Ont=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Nte=a("a"),Vnt=o("from_pretrained()"),Xnt=o(" class method or the "),qte=a("a"),znt=o("from_config()"),Wnt=o(` class
method.`),Qnt=l(),Xk=a("p"),Hnt=o("This class cannot be instantiated directly using "),B7e=a("code"),Unt=o("__init__()"),Jnt=o(" (throws an error)."),Ynt=l(),aa=a("div"),F(zk.$$.fragment),Knt=l(),I7e=a("p"),Znt=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),est=l(),Sf=a("p"),ost=o(`Note:
Loading a model from its configuration file does `),N7e=a("strong"),rst=o("not"),tst=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jte=a("a"),ast=o("from_pretrained()"),nst=o(" to load the model weights."),sst=l(),F(eA.$$.fragment),lst=l(),et=a("div"),F(Wk.$$.fragment),ist=l(),q7e=a("p"),dst=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),cst=l(),Bn=a("p"),fst=o("The model class to instantiate is selected based on the "),j7e=a("code"),mst=o("model_type"),gst=o(` property of the config object (either
passed as an argument or loaded from `),D7e=a("code"),hst=o("pretrained_model_name_or_path"),pst=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G7e=a("code"),_st=o("pretrained_model_name_or_path"),ust=o(":"),bst=l(),ze=a("ul"),oA=a("li"),O7e=a("strong"),vst=o("albert"),Fst=o(" \u2014 "),Dte=a("a"),Tst=o("FlaxAlbertForMultipleChoice"),Mst=o(" (ALBERT model)"),Est=l(),rA=a("li"),V7e=a("strong"),Cst=o("bert"),wst=o(" \u2014 "),Gte=a("a"),Ast=o("FlaxBertForMultipleChoice"),Lst=o(" (BERT model)"),yst=l(),tA=a("li"),X7e=a("strong"),xst=o("big_bird"),$st=o(" \u2014 "),Ote=a("a"),kst=o("FlaxBigBirdForMultipleChoice"),Sst=o(" (BigBird model)"),Rst=l(),aA=a("li"),z7e=a("strong"),Pst=o("distilbert"),Bst=o(" \u2014 "),Vte=a("a"),Ist=o("FlaxDistilBertForMultipleChoice"),Nst=o(" (DistilBERT model)"),qst=l(),nA=a("li"),W7e=a("strong"),jst=o("electra"),Dst=o(" \u2014 "),Xte=a("a"),Gst=o("FlaxElectraForMultipleChoice"),Ost=o(" (ELECTRA model)"),Vst=l(),sA=a("li"),Q7e=a("strong"),Xst=o("roberta"),zst=o(" \u2014 "),zte=a("a"),Wst=o("FlaxRobertaForMultipleChoice"),Qst=o(" (RoBERTa model)"),Hst=l(),lA=a("li"),H7e=a("strong"),Ust=o("roformer"),Jst=o(" \u2014 "),Wte=a("a"),Yst=o("FlaxRoFormerForMultipleChoice"),Kst=o(" (RoFormer model)"),Zst=l(),iA=a("li"),U7e=a("strong"),elt=o("xlm-roberta"),olt=o(" \u2014 "),Qte=a("a"),rlt=o("FlaxXLMRobertaForMultipleChoice"),tlt=o(" (XLM-RoBERTa model)"),alt=l(),F(dA.$$.fragment),XHe=l(),Rf=a("h2"),cA=a("a"),J7e=a("span"),F(Qk.$$.fragment),nlt=l(),Y7e=a("span"),slt=o("FlaxAutoModelForNextSentencePrediction"),zHe=l(),Lr=a("div"),F(Hk.$$.fragment),llt=l(),Pf=a("p"),ilt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Hte=a("a"),dlt=o("from_pretrained()"),clt=o(" class method or the "),Ute=a("a"),flt=o("from_config()"),mlt=o(` class
method.`),glt=l(),Uk=a("p"),hlt=o("This class cannot be instantiated directly using "),K7e=a("code"),plt=o("__init__()"),_lt=o(" (throws an error)."),ult=l(),na=a("div"),F(Jk.$$.fragment),blt=l(),Z7e=a("p"),vlt=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),Flt=l(),Bf=a("p"),Tlt=o(`Note:
Loading a model from its configuration file does `),eLe=a("strong"),Mlt=o("not"),Elt=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jte=a("a"),Clt=o("from_pretrained()"),wlt=o(" to load the model weights."),Alt=l(),F(fA.$$.fragment),Llt=l(),ot=a("div"),F(Yk.$$.fragment),ylt=l(),oLe=a("p"),xlt=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),$lt=l(),In=a("p"),klt=o("The model class to instantiate is selected based on the "),rLe=a("code"),Slt=o("model_type"),Rlt=o(` property of the config object (either
passed as an argument or loaded from `),tLe=a("code"),Plt=o("pretrained_model_name_or_path"),Blt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aLe=a("code"),Ilt=o("pretrained_model_name_or_path"),Nlt=o(":"),qlt=l(),nLe=a("ul"),mA=a("li"),sLe=a("strong"),jlt=o("bert"),Dlt=o(" \u2014 "),Yte=a("a"),Glt=o("FlaxBertForNextSentencePrediction"),Olt=o(" (BERT model)"),Vlt=l(),F(gA.$$.fragment),WHe=l(),If=a("h2"),hA=a("a"),lLe=a("span"),F(Kk.$$.fragment),Xlt=l(),iLe=a("span"),zlt=o("FlaxAutoModelForImageClassification"),QHe=l(),yr=a("div"),F(Zk.$$.fragment),Wlt=l(),Nf=a("p"),Qlt=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Kte=a("a"),Hlt=o("from_pretrained()"),Ult=o(" class method or the "),Zte=a("a"),Jlt=o("from_config()"),Ylt=o(` class
method.`),Klt=l(),eS=a("p"),Zlt=o("This class cannot be instantiated directly using "),dLe=a("code"),eit=o("__init__()"),oit=o(" (throws an error)."),rit=l(),sa=a("div"),F(oS.$$.fragment),tit=l(),cLe=a("p"),ait=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),nit=l(),qf=a("p"),sit=o(`Note:
Loading a model from its configuration file does `),fLe=a("strong"),lit=o("not"),iit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eae=a("a"),dit=o("from_pretrained()"),cit=o(" to load the model weights."),fit=l(),F(pA.$$.fragment),mit=l(),rt=a("div"),F(rS.$$.fragment),git=l(),mLe=a("p"),hit=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),pit=l(),Nn=a("p"),_it=o("The model class to instantiate is selected based on the "),gLe=a("code"),uit=o("model_type"),bit=o(` property of the config object (either
passed as an argument or loaded from `),hLe=a("code"),vit=o("pretrained_model_name_or_path"),Fit=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pLe=a("code"),Tit=o("pretrained_model_name_or_path"),Mit=o(":"),Eit=l(),tS=a("ul"),_A=a("li"),_Le=a("strong"),Cit=o("beit"),wit=o(" \u2014 "),oae=a("a"),Ait=o("FlaxBeitForImageClassification"),Lit=o(" (BEiT model)"),yit=l(),uA=a("li"),uLe=a("strong"),xit=o("vit"),$it=o(" \u2014 "),rae=a("a"),kit=o("FlaxViTForImageClassification"),Sit=o(" (ViT model)"),Rit=l(),F(bA.$$.fragment),HHe=l(),jf=a("h2"),vA=a("a"),bLe=a("span"),F(aS.$$.fragment),Pit=l(),vLe=a("span"),Bit=o("FlaxAutoModelForVision2Seq"),UHe=l(),xr=a("div"),F(nS.$$.fragment),Iit=l(),Df=a("p"),Nit=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),tae=a("a"),qit=o("from_pretrained()"),jit=o(" class method or the "),aae=a("a"),Dit=o("from_config()"),Git=o(` class
method.`),Oit=l(),sS=a("p"),Vit=o("This class cannot be instantiated directly using "),FLe=a("code"),Xit=o("__init__()"),zit=o(" (throws an error)."),Wit=l(),la=a("div"),F(lS.$$.fragment),Qit=l(),TLe=a("p"),Hit=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Uit=l(),Gf=a("p"),Jit=o(`Note:
Loading a model from its configuration file does `),MLe=a("strong"),Yit=o("not"),Kit=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nae=a("a"),Zit=o("from_pretrained()"),edt=o(" to load the model weights."),odt=l(),F(FA.$$.fragment),rdt=l(),tt=a("div"),F(iS.$$.fragment),tdt=l(),ELe=a("p"),adt=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),ndt=l(),qn=a("p"),sdt=o("The model class to instantiate is selected based on the "),CLe=a("code"),ldt=o("model_type"),idt=o(` property of the config object (either
passed as an argument or loaded from `),wLe=a("code"),ddt=o("pretrained_model_name_or_path"),cdt=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ALe=a("code"),fdt=o("pretrained_model_name_or_path"),mdt=o(":"),gdt=l(),LLe=a("ul"),TA=a("li"),yLe=a("strong"),hdt=o("vision-encoder-decoder"),pdt=o(" \u2014 "),sae=a("a"),_dt=o("FlaxVisionEncoderDecoderModel"),udt=o(" (Vision Encoder decoder model)"),bdt=l(),F(MA.$$.fragment),this.h()},l(f){const u=hea('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var dS=s(p);m=n(dS,"A",{id:!0,class:!0,href:!0});var xLe=s(m);_=n(xLe,"SPAN",{});var $Le=s(_);T(d.$$.fragment,$Le),$Le.forEach(t),xLe.forEach(t),h=i(dS),Ao=n(dS,"SPAN",{});var kLe=s(Ao);Ii=r(kLe,"Auto Classes"),kLe.forEach(t),dS.forEach(t),zf=i(f),dt=n(f,"P",{});var cS=s(dt);Ni=r(cS,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),qi=n(cS,"CODE",{});var SLe=s(qi);XL=r(SLe,"from_pretrained()"),SLe.forEach(t),Wf=r(cS,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),cS.forEach(t),Oe=i(f),Qe=n(f,"P",{});var jn=s(Qe);ji=r(jn,"Instantiating one of "),Dn=n(jn,"A",{href:!0});var RLe=s(Dn);zL=r(RLe,"AutoConfig"),RLe.forEach(t),Gn=r(jn,", "),On=n(jn,"A",{href:!0});var PLe=s(On);WL=r(PLe,"AutoModel"),PLe.forEach(t),Di=r(jn,`, and
`),Vn=n(jn,"A",{href:!0});var BLe=s(Vn);QL=r(BLe,"AutoTokenizer"),BLe.forEach(t),Gi=r(jn," will directly create a class of the relevant architecture. For instance"),jn.forEach(t),Qf=i(f),T(Ia.$$.fragment,f),He=i(f),Le=n(f,"P",{});var fS=s(Le);SR=r(fS,"will create a model that is an instance of "),Oi=n(fS,"A",{href:!0});var ILe=s(Oi);RR=r(ILe,"BertModel"),ILe.forEach(t),PR=r(fS,"."),fS.forEach(t),Lo=i(f),Na=n(f,"P",{});var mS=s(Na);BR=r(mS,"There is one class of "),Hf=n(mS,"CODE",{});var NLe=s(Hf);IR=r(NLe,"AutoModel"),NLe.forEach(t),iYe=r(mS," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),mS.forEach(t),VWe=i(f),Vi=n(f,"H2",{class:!0});var gS=s(Vi);Uf=n(gS,"A",{id:!0,class:!0,href:!0});var qLe=s(Uf);rse=n(qLe,"SPAN",{});var jLe=s(rse);T(HL.$$.fragment,jLe),jLe.forEach(t),qLe.forEach(t),dYe=i(gS),tse=n(gS,"SPAN",{});var DLe=s(tse);cYe=r(DLe,"Extending the Auto Classes"),DLe.forEach(t),gS.forEach(t),XWe=i(f),Xn=n(f,"P",{});var Of=s(Xn);fYe=r(Of,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),ase=n(Of,"CODE",{});var GLe=s(ase);mYe=r(GLe,"NewModel"),GLe.forEach(t),gYe=r(Of,", make sure you have a "),nse=n(Of,"CODE",{});var OLe=s(nse);hYe=r(OLe,"NewModelConfig"),OLe.forEach(t),pYe=r(Of,` then you can add those to the auto
classes like this:`),Of.forEach(t),zWe=i(f),T(UL.$$.fragment,f),WWe=i(f),NR=n(f,"P",{});var VLe=s(NR);_Ye=r(VLe,"You will then be able to use the auto classes like you would usually do!"),VLe.forEach(t),QWe=i(f),T(Jf.$$.fragment,f),HWe=i(f),Xi=n(f,"H2",{class:!0});var hS=s(Xi);Yf=n(hS,"A",{id:!0,class:!0,href:!0});var XLe=s(Yf);sse=n(XLe,"SPAN",{});var zLe=s(sse);T(JL.$$.fragment,zLe),zLe.forEach(t),XLe.forEach(t),uYe=i(hS),lse=n(hS,"SPAN",{});var WLe=s(lse);bYe=r(WLe,"AutoConfig"),WLe.forEach(t),hS.forEach(t),UWe=i(f),yo=n(f,"DIV",{class:!0});var lt=s(yo);T(YL.$$.fragment,lt),vYe=i(lt),KL=n(lt,"P",{});var pS=s(KL);FYe=r(pS,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),qR=n(pS,"A",{href:!0});var QLe=s(qR);TYe=r(QLe,"from_pretrained()"),QLe.forEach(t),MYe=r(pS," class method."),pS.forEach(t),EYe=i(lt),ZL=n(lt,"P",{});var _S=s(ZL);CYe=r(_S,"This class cannot be instantiated directly using "),ise=n(_S,"CODE",{});var HLe=s(ise);wYe=r(HLe,"__init__()"),HLe.forEach(t),AYe=r(_S," (throws an error)."),_S.forEach(t),LYe=i(lt),$r=n(lt,"DIV",{class:!0});var it=s($r);T(ey.$$.fragment,it),yYe=i(it),dse=n(it,"P",{});var ULe=s(dse);xYe=r(ULe,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),ULe.forEach(t),$Ye=i(it),zi=n(it,"P",{});var Vf=s(zi);kYe=r(Vf,"The configuration class to instantiate is selected based on the "),cse=n(Vf,"CODE",{});var JLe=s(cse);SYe=r(JLe,"model_type"),JLe.forEach(t),RYe=r(Vf,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),fse=n(Vf,"CODE",{});var YLe=s(fse);PYe=r(YLe,"pretrained_model_name_or_path"),YLe.forEach(t),BYe=r(Vf,":"),Vf.forEach(t),IYe=i(it),A=n(it,"UL",{});var L=s(A);Kf=n(L,"LI",{});var EA=s(Kf);mse=n(EA,"STRONG",{});var KLe=s(mse);NYe=r(KLe,"albert"),KLe.forEach(t),qYe=r(EA," \u2014 "),jR=n(EA,"A",{href:!0});var ZLe=s(jR);jYe=r(ZLe,"AlbertConfig"),ZLe.forEach(t),DYe=r(EA," (ALBERT model)"),EA.forEach(t),GYe=i(L),Zf=n(L,"LI",{});var CA=s(Zf);gse=n(CA,"STRONG",{});var eye=s(gse);OYe=r(eye,"bart"),eye.forEach(t),VYe=r(CA," \u2014 "),DR=n(CA,"A",{href:!0});var oye=s(DR);XYe=r(oye,"BartConfig"),oye.forEach(t),zYe=r(CA," (BART model)"),CA.forEach(t),WYe=i(L),em=n(L,"LI",{});var wA=s(em);hse=n(wA,"STRONG",{});var rye=s(hse);QYe=r(rye,"beit"),rye.forEach(t),HYe=r(wA," \u2014 "),GR=n(wA,"A",{href:!0});var tye=s(GR);UYe=r(tye,"BeitConfig"),tye.forEach(t),JYe=r(wA," (BEiT model)"),wA.forEach(t),YYe=i(L),om=n(L,"LI",{});var AA=s(om);pse=n(AA,"STRONG",{});var aye=s(pse);KYe=r(aye,"bert"),aye.forEach(t),ZYe=r(AA," \u2014 "),OR=n(AA,"A",{href:!0});var nye=s(OR);eKe=r(nye,"BertConfig"),nye.forEach(t),oKe=r(AA," (BERT model)"),AA.forEach(t),rKe=i(L),rm=n(L,"LI",{});var LA=s(rm);_se=n(LA,"STRONG",{});var sye=s(_se);tKe=r(sye,"bert-generation"),sye.forEach(t),aKe=r(LA," \u2014 "),VR=n(LA,"A",{href:!0});var lye=s(VR);nKe=r(lye,"BertGenerationConfig"),lye.forEach(t),sKe=r(LA," (Bert Generation model)"),LA.forEach(t),lKe=i(L),tm=n(L,"LI",{});var yA=s(tm);use=n(yA,"STRONG",{});var iye=s(use);iKe=r(iye,"big_bird"),iye.forEach(t),dKe=r(yA," \u2014 "),XR=n(yA,"A",{href:!0});var dye=s(XR);cKe=r(dye,"BigBirdConfig"),dye.forEach(t),fKe=r(yA," (BigBird model)"),yA.forEach(t),mKe=i(L),am=n(L,"LI",{});var xA=s(am);bse=n(xA,"STRONG",{});var cye=s(bse);gKe=r(cye,"bigbird_pegasus"),cye.forEach(t),hKe=r(xA," \u2014 "),zR=n(xA,"A",{href:!0});var fye=s(zR);pKe=r(fye,"BigBirdPegasusConfig"),fye.forEach(t),_Ke=r(xA," (BigBird-Pegasus model)"),xA.forEach(t),uKe=i(L),nm=n(L,"LI",{});var $A=s(nm);vse=n($A,"STRONG",{});var mye=s(vse);bKe=r(mye,"blenderbot"),mye.forEach(t),vKe=r($A," \u2014 "),WR=n($A,"A",{href:!0});var gye=s(WR);FKe=r(gye,"BlenderbotConfig"),gye.forEach(t),TKe=r($A," (Blenderbot model)"),$A.forEach(t),MKe=i(L),sm=n(L,"LI",{});var kA=s(sm);Fse=n(kA,"STRONG",{});var hye=s(Fse);EKe=r(hye,"blenderbot-small"),hye.forEach(t),CKe=r(kA," \u2014 "),QR=n(kA,"A",{href:!0});var pye=s(QR);wKe=r(pye,"BlenderbotSmallConfig"),pye.forEach(t),AKe=r(kA," (BlenderbotSmall model)"),kA.forEach(t),LKe=i(L),lm=n(L,"LI",{});var SA=s(lm);Tse=n(SA,"STRONG",{});var _ye=s(Tse);yKe=r(_ye,"bloom"),_ye.forEach(t),xKe=r(SA," \u2014 "),HR=n(SA,"A",{href:!0});var uye=s(HR);$Ke=r(uye,"BloomConfig"),uye.forEach(t),kKe=r(SA," (BLOOM model)"),SA.forEach(t),SKe=i(L),im=n(L,"LI",{});var RA=s(im);Mse=n(RA,"STRONG",{});var bye=s(Mse);RKe=r(bye,"camembert"),bye.forEach(t),PKe=r(RA," \u2014 "),UR=n(RA,"A",{href:!0});var vye=s(UR);BKe=r(vye,"CamembertConfig"),vye.forEach(t),IKe=r(RA," (CamemBERT model)"),RA.forEach(t),NKe=i(L),dm=n(L,"LI",{});var PA=s(dm);Ese=n(PA,"STRONG",{});var Fye=s(Ese);qKe=r(Fye,"canine"),Fye.forEach(t),jKe=r(PA," \u2014 "),JR=n(PA,"A",{href:!0});var Tye=s(JR);DKe=r(Tye,"CanineConfig"),Tye.forEach(t),GKe=r(PA," (CANINE model)"),PA.forEach(t),OKe=i(L),cm=n(L,"LI",{});var BA=s(cm);Cse=n(BA,"STRONG",{});var Mye=s(Cse);VKe=r(Mye,"clip"),Mye.forEach(t),XKe=r(BA," \u2014 "),YR=n(BA,"A",{href:!0});var Eye=s(YR);zKe=r(Eye,"CLIPConfig"),Eye.forEach(t),WKe=r(BA," (CLIP model)"),BA.forEach(t),QKe=i(L),fm=n(L,"LI",{});var IA=s(fm);wse=n(IA,"STRONG",{});var Cye=s(wse);HKe=r(Cye,"codegen"),Cye.forEach(t),UKe=r(IA," \u2014 "),KR=n(IA,"A",{href:!0});var wye=s(KR);JKe=r(wye,"CodeGenConfig"),wye.forEach(t),YKe=r(IA," (CodeGen model)"),IA.forEach(t),KKe=i(L),mm=n(L,"LI",{});var NA=s(mm);Ase=n(NA,"STRONG",{});var Aye=s(Ase);ZKe=r(Aye,"convbert"),Aye.forEach(t),eZe=r(NA," \u2014 "),ZR=n(NA,"A",{href:!0});var Lye=s(ZR);oZe=r(Lye,"ConvBertConfig"),Lye.forEach(t),rZe=r(NA," (ConvBERT model)"),NA.forEach(t),tZe=i(L),gm=n(L,"LI",{});var qA=s(gm);Lse=n(qA,"STRONG",{});var yye=s(Lse);aZe=r(yye,"convnext"),yye.forEach(t),nZe=r(qA," \u2014 "),eP=n(qA,"A",{href:!0});var xye=s(eP);sZe=r(xye,"ConvNextConfig"),xye.forEach(t),lZe=r(qA," (ConvNeXT model)"),qA.forEach(t),iZe=i(L),hm=n(L,"LI",{});var jA=s(hm);yse=n(jA,"STRONG",{});var $ye=s(yse);dZe=r($ye,"ctrl"),$ye.forEach(t),cZe=r(jA," \u2014 "),oP=n(jA,"A",{href:!0});var kye=s(oP);fZe=r(kye,"CTRLConfig"),kye.forEach(t),mZe=r(jA," (CTRL model)"),jA.forEach(t),gZe=i(L),pm=n(L,"LI",{});var DA=s(pm);xse=n(DA,"STRONG",{});var Sye=s(xse);hZe=r(Sye,"cvt"),Sye.forEach(t),pZe=r(DA," \u2014 "),rP=n(DA,"A",{href:!0});var Rye=s(rP);_Ze=r(Rye,"CvtConfig"),Rye.forEach(t),uZe=r(DA," (CvT model)"),DA.forEach(t),bZe=i(L),_m=n(L,"LI",{});var GA=s(_m);$se=n(GA,"STRONG",{});var Pye=s($se);vZe=r(Pye,"data2vec-audio"),Pye.forEach(t),FZe=r(GA," \u2014 "),tP=n(GA,"A",{href:!0});var Bye=s(tP);TZe=r(Bye,"Data2VecAudioConfig"),Bye.forEach(t),MZe=r(GA," (Data2VecAudio model)"),GA.forEach(t),EZe=i(L),um=n(L,"LI",{});var OA=s(um);kse=n(OA,"STRONG",{});var Iye=s(kse);CZe=r(Iye,"data2vec-text"),Iye.forEach(t),wZe=r(OA," \u2014 "),aP=n(OA,"A",{href:!0});var Nye=s(aP);AZe=r(Nye,"Data2VecTextConfig"),Nye.forEach(t),LZe=r(OA," (Data2VecText model)"),OA.forEach(t),yZe=i(L),bm=n(L,"LI",{});var VA=s(bm);Sse=n(VA,"STRONG",{});var qye=s(Sse);xZe=r(qye,"data2vec-vision"),qye.forEach(t),$Ze=r(VA," \u2014 "),nP=n(VA,"A",{href:!0});var jye=s(nP);kZe=r(jye,"Data2VecVisionConfig"),jye.forEach(t),SZe=r(VA," (Data2VecVision model)"),VA.forEach(t),RZe=i(L),vm=n(L,"LI",{});var XA=s(vm);Rse=n(XA,"STRONG",{});var Dye=s(Rse);PZe=r(Dye,"deberta"),Dye.forEach(t),BZe=r(XA," \u2014 "),sP=n(XA,"A",{href:!0});var Gye=s(sP);IZe=r(Gye,"DebertaConfig"),Gye.forEach(t),NZe=r(XA," (DeBERTa model)"),XA.forEach(t),qZe=i(L),Fm=n(L,"LI",{});var zA=s(Fm);Pse=n(zA,"STRONG",{});var Oye=s(Pse);jZe=r(Oye,"deberta-v2"),Oye.forEach(t),DZe=r(zA," \u2014 "),lP=n(zA,"A",{href:!0});var Vye=s(lP);GZe=r(Vye,"DebertaV2Config"),Vye.forEach(t),OZe=r(zA," (DeBERTa-v2 model)"),zA.forEach(t),VZe=i(L),Tm=n(L,"LI",{});var WA=s(Tm);Bse=n(WA,"STRONG",{});var Xye=s(Bse);XZe=r(Xye,"decision_transformer"),Xye.forEach(t),zZe=r(WA," \u2014 "),iP=n(WA,"A",{href:!0});var zye=s(iP);WZe=r(zye,"DecisionTransformerConfig"),zye.forEach(t),QZe=r(WA," (Decision Transformer model)"),WA.forEach(t),HZe=i(L),Mm=n(L,"LI",{});var Wye=s(Mm);Ise=n(Wye,"STRONG",{});var Fdt=s(Ise);UZe=r(Fdt,"deit"),Fdt.forEach(t),JZe=r(Wye," \u2014 "),dP=n(Wye,"A",{href:!0});var Tdt=s(dP);YZe=r(Tdt,"DeiTConfig"),Tdt.forEach(t),KZe=r(Wye," (DeiT model)"),Wye.forEach(t),ZZe=i(L),Em=n(L,"LI",{});var Qye=s(Em);Nse=n(Qye,"STRONG",{});var Mdt=s(Nse);eeo=r(Mdt,"detr"),Mdt.forEach(t),oeo=r(Qye," \u2014 "),cP=n(Qye,"A",{href:!0});var Edt=s(cP);reo=r(Edt,"DetrConfig"),Edt.forEach(t),teo=r(Qye," (DETR model)"),Qye.forEach(t),aeo=i(L),Cm=n(L,"LI",{});var Hye=s(Cm);qse=n(Hye,"STRONG",{});var Cdt=s(qse);neo=r(Cdt,"distilbert"),Cdt.forEach(t),seo=r(Hye," \u2014 "),fP=n(Hye,"A",{href:!0});var wdt=s(fP);leo=r(wdt,"DistilBertConfig"),wdt.forEach(t),ieo=r(Hye," (DistilBERT model)"),Hye.forEach(t),deo=i(L),wm=n(L,"LI",{});var Uye=s(wm);jse=n(Uye,"STRONG",{});var Adt=s(jse);ceo=r(Adt,"dpr"),Adt.forEach(t),feo=r(Uye," \u2014 "),mP=n(Uye,"A",{href:!0});var Ldt=s(mP);meo=r(Ldt,"DPRConfig"),Ldt.forEach(t),geo=r(Uye," (DPR model)"),Uye.forEach(t),heo=i(L),Am=n(L,"LI",{});var Jye=s(Am);Dse=n(Jye,"STRONG",{});var ydt=s(Dse);peo=r(ydt,"dpt"),ydt.forEach(t),_eo=r(Jye," \u2014 "),gP=n(Jye,"A",{href:!0});var xdt=s(gP);ueo=r(xdt,"DPTConfig"),xdt.forEach(t),beo=r(Jye," (DPT model)"),Jye.forEach(t),veo=i(L),Lm=n(L,"LI",{});var Yye=s(Lm);Gse=n(Yye,"STRONG",{});var $dt=s(Gse);Feo=r($dt,"electra"),$dt.forEach(t),Teo=r(Yye," \u2014 "),hP=n(Yye,"A",{href:!0});var kdt=s(hP);Meo=r(kdt,"ElectraConfig"),kdt.forEach(t),Eeo=r(Yye," (ELECTRA model)"),Yye.forEach(t),Ceo=i(L),ym=n(L,"LI",{});var Kye=s(ym);Ose=n(Kye,"STRONG",{});var Sdt=s(Ose);weo=r(Sdt,"encoder-decoder"),Sdt.forEach(t),Aeo=r(Kye," \u2014 "),pP=n(Kye,"A",{href:!0});var Rdt=s(pP);Leo=r(Rdt,"EncoderDecoderConfig"),Rdt.forEach(t),yeo=r(Kye," (Encoder decoder model)"),Kye.forEach(t),xeo=i(L),xm=n(L,"LI",{});var Zye=s(xm);Vse=n(Zye,"STRONG",{});var Pdt=s(Vse);$eo=r(Pdt,"flaubert"),Pdt.forEach(t),keo=r(Zye," \u2014 "),_P=n(Zye,"A",{href:!0});var Bdt=s(_P);Seo=r(Bdt,"FlaubertConfig"),Bdt.forEach(t),Reo=r(Zye," (FlauBERT model)"),Zye.forEach(t),Peo=i(L),$m=n(L,"LI",{});var e9e=s($m);Xse=n(e9e,"STRONG",{});var Idt=s(Xse);Beo=r(Idt,"flava"),Idt.forEach(t),Ieo=r(e9e," \u2014 "),uP=n(e9e,"A",{href:!0});var Ndt=s(uP);Neo=r(Ndt,"FlavaConfig"),Ndt.forEach(t),qeo=r(e9e," (FLAVA model)"),e9e.forEach(t),jeo=i(L),km=n(L,"LI",{});var o9e=s(km);zse=n(o9e,"STRONG",{});var qdt=s(zse);Deo=r(qdt,"fnet"),qdt.forEach(t),Geo=r(o9e," \u2014 "),bP=n(o9e,"A",{href:!0});var jdt=s(bP);Oeo=r(jdt,"FNetConfig"),jdt.forEach(t),Veo=r(o9e," (FNet model)"),o9e.forEach(t),Xeo=i(L),Sm=n(L,"LI",{});var r9e=s(Sm);Wse=n(r9e,"STRONG",{});var Ddt=s(Wse);zeo=r(Ddt,"fsmt"),Ddt.forEach(t),Weo=r(r9e," \u2014 "),vP=n(r9e,"A",{href:!0});var Gdt=s(vP);Qeo=r(Gdt,"FSMTConfig"),Gdt.forEach(t),Heo=r(r9e," (FairSeq Machine-Translation model)"),r9e.forEach(t),Ueo=i(L),Rm=n(L,"LI",{});var t9e=s(Rm);Qse=n(t9e,"STRONG",{});var Odt=s(Qse);Jeo=r(Odt,"funnel"),Odt.forEach(t),Yeo=r(t9e," \u2014 "),FP=n(t9e,"A",{href:!0});var Vdt=s(FP);Keo=r(Vdt,"FunnelConfig"),Vdt.forEach(t),Zeo=r(t9e," (Funnel Transformer model)"),t9e.forEach(t),eoo=i(L),Pm=n(L,"LI",{});var a9e=s(Pm);Hse=n(a9e,"STRONG",{});var Xdt=s(Hse);ooo=r(Xdt,"glpn"),Xdt.forEach(t),roo=r(a9e," \u2014 "),TP=n(a9e,"A",{href:!0});var zdt=s(TP);too=r(zdt,"GLPNConfig"),zdt.forEach(t),aoo=r(a9e," (GLPN model)"),a9e.forEach(t),noo=i(L),Bm=n(L,"LI",{});var n9e=s(Bm);Use=n(n9e,"STRONG",{});var Wdt=s(Use);soo=r(Wdt,"gpt2"),Wdt.forEach(t),loo=r(n9e," \u2014 "),MP=n(n9e,"A",{href:!0});var Qdt=s(MP);ioo=r(Qdt,"GPT2Config"),Qdt.forEach(t),doo=r(n9e," (OpenAI GPT-2 model)"),n9e.forEach(t),coo=i(L),Im=n(L,"LI",{});var s9e=s(Im);Jse=n(s9e,"STRONG",{});var Hdt=s(Jse);foo=r(Hdt,"gpt_neo"),Hdt.forEach(t),moo=r(s9e," \u2014 "),EP=n(s9e,"A",{href:!0});var Udt=s(EP);goo=r(Udt,"GPTNeoConfig"),Udt.forEach(t),hoo=r(s9e," (GPT Neo model)"),s9e.forEach(t),poo=i(L),Nm=n(L,"LI",{});var l9e=s(Nm);Yse=n(l9e,"STRONG",{});var Jdt=s(Yse);_oo=r(Jdt,"gpt_neox"),Jdt.forEach(t),uoo=r(l9e," \u2014 "),CP=n(l9e,"A",{href:!0});var Ydt=s(CP);boo=r(Ydt,"GPTNeoXConfig"),Ydt.forEach(t),voo=r(l9e," (GPT NeoX model)"),l9e.forEach(t),Foo=i(L),qm=n(L,"LI",{});var i9e=s(qm);Kse=n(i9e,"STRONG",{});var Kdt=s(Kse);Too=r(Kdt,"gptj"),Kdt.forEach(t),Moo=r(i9e," \u2014 "),wP=n(i9e,"A",{href:!0});var Zdt=s(wP);Eoo=r(Zdt,"GPTJConfig"),Zdt.forEach(t),Coo=r(i9e," (GPT-J model)"),i9e.forEach(t),woo=i(L),jm=n(L,"LI",{});var d9e=s(jm);Zse=n(d9e,"STRONG",{});var ect=s(Zse);Aoo=r(ect,"groupvit"),ect.forEach(t),Loo=r(d9e," \u2014 "),AP=n(d9e,"A",{href:!0});var oct=s(AP);yoo=r(oct,"GroupViTConfig"),oct.forEach(t),xoo=r(d9e," (GroupViT model)"),d9e.forEach(t),$oo=i(L),Dm=n(L,"LI",{});var c9e=s(Dm);ele=n(c9e,"STRONG",{});var rct=s(ele);koo=r(rct,"hubert"),rct.forEach(t),Soo=r(c9e," \u2014 "),LP=n(c9e,"A",{href:!0});var tct=s(LP);Roo=r(tct,"HubertConfig"),tct.forEach(t),Poo=r(c9e," (Hubert model)"),c9e.forEach(t),Boo=i(L),Gm=n(L,"LI",{});var f9e=s(Gm);ole=n(f9e,"STRONG",{});var act=s(ole);Ioo=r(act,"ibert"),act.forEach(t),Noo=r(f9e," \u2014 "),yP=n(f9e,"A",{href:!0});var nct=s(yP);qoo=r(nct,"IBertConfig"),nct.forEach(t),joo=r(f9e," (I-BERT model)"),f9e.forEach(t),Doo=i(L),Om=n(L,"LI",{});var m9e=s(Om);rle=n(m9e,"STRONG",{});var sct=s(rle);Goo=r(sct,"imagegpt"),sct.forEach(t),Ooo=r(m9e," \u2014 "),xP=n(m9e,"A",{href:!0});var lct=s(xP);Voo=r(lct,"ImageGPTConfig"),lct.forEach(t),Xoo=r(m9e," (ImageGPT model)"),m9e.forEach(t),zoo=i(L),Vm=n(L,"LI",{});var g9e=s(Vm);tle=n(g9e,"STRONG",{});var ict=s(tle);Woo=r(ict,"layoutlm"),ict.forEach(t),Qoo=r(g9e," \u2014 "),$P=n(g9e,"A",{href:!0});var dct=s($P);Hoo=r(dct,"LayoutLMConfig"),dct.forEach(t),Uoo=r(g9e," (LayoutLM model)"),g9e.forEach(t),Joo=i(L),Xm=n(L,"LI",{});var h9e=s(Xm);ale=n(h9e,"STRONG",{});var cct=s(ale);Yoo=r(cct,"layoutlmv2"),cct.forEach(t),Koo=r(h9e," \u2014 "),kP=n(h9e,"A",{href:!0});var fct=s(kP);Zoo=r(fct,"LayoutLMv2Config"),fct.forEach(t),ero=r(h9e," (LayoutLMv2 model)"),h9e.forEach(t),oro=i(L),zm=n(L,"LI",{});var p9e=s(zm);nle=n(p9e,"STRONG",{});var mct=s(nle);rro=r(mct,"layoutlmv3"),mct.forEach(t),tro=r(p9e," \u2014 "),SP=n(p9e,"A",{href:!0});var gct=s(SP);aro=r(gct,"LayoutLMv3Config"),gct.forEach(t),nro=r(p9e," (LayoutLMv3 model)"),p9e.forEach(t),sro=i(L),Wm=n(L,"LI",{});var _9e=s(Wm);sle=n(_9e,"STRONG",{});var hct=s(sle);lro=r(hct,"led"),hct.forEach(t),iro=r(_9e," \u2014 "),RP=n(_9e,"A",{href:!0});var pct=s(RP);dro=r(pct,"LEDConfig"),pct.forEach(t),cro=r(_9e," (LED model)"),_9e.forEach(t),fro=i(L),Qm=n(L,"LI",{});var u9e=s(Qm);lle=n(u9e,"STRONG",{});var _ct=s(lle);mro=r(_ct,"levit"),_ct.forEach(t),gro=r(u9e," \u2014 "),PP=n(u9e,"A",{href:!0});var uct=s(PP);hro=r(uct,"LevitConfig"),uct.forEach(t),pro=r(u9e," (LeViT model)"),u9e.forEach(t),_ro=i(L),Hm=n(L,"LI",{});var b9e=s(Hm);ile=n(b9e,"STRONG",{});var bct=s(ile);uro=r(bct,"longformer"),bct.forEach(t),bro=r(b9e," \u2014 "),BP=n(b9e,"A",{href:!0});var vct=s(BP);vro=r(vct,"LongformerConfig"),vct.forEach(t),Fro=r(b9e," (Longformer model)"),b9e.forEach(t),Tro=i(L),Um=n(L,"LI",{});var v9e=s(Um);dle=n(v9e,"STRONG",{});var Fct=s(dle);Mro=r(Fct,"longt5"),Fct.forEach(t),Ero=r(v9e," \u2014 "),IP=n(v9e,"A",{href:!0});var Tct=s(IP);Cro=r(Tct,"LongT5Config"),Tct.forEach(t),wro=r(v9e," (LongT5 model)"),v9e.forEach(t),Aro=i(L),Jm=n(L,"LI",{});var F9e=s(Jm);cle=n(F9e,"STRONG",{});var Mct=s(cle);Lro=r(Mct,"luke"),Mct.forEach(t),yro=r(F9e," \u2014 "),NP=n(F9e,"A",{href:!0});var Ect=s(NP);xro=r(Ect,"LukeConfig"),Ect.forEach(t),$ro=r(F9e," (LUKE model)"),F9e.forEach(t),kro=i(L),Ym=n(L,"LI",{});var T9e=s(Ym);fle=n(T9e,"STRONG",{});var Cct=s(fle);Sro=r(Cct,"lxmert"),Cct.forEach(t),Rro=r(T9e," \u2014 "),qP=n(T9e,"A",{href:!0});var wct=s(qP);Pro=r(wct,"LxmertConfig"),wct.forEach(t),Bro=r(T9e," (LXMERT model)"),T9e.forEach(t),Iro=i(L),Km=n(L,"LI",{});var M9e=s(Km);mle=n(M9e,"STRONG",{});var Act=s(mle);Nro=r(Act,"m2m_100"),Act.forEach(t),qro=r(M9e," \u2014 "),jP=n(M9e,"A",{href:!0});var Lct=s(jP);jro=r(Lct,"M2M100Config"),Lct.forEach(t),Dro=r(M9e," (M2M100 model)"),M9e.forEach(t),Gro=i(L),Zm=n(L,"LI",{});var E9e=s(Zm);gle=n(E9e,"STRONG",{});var yct=s(gle);Oro=r(yct,"marian"),yct.forEach(t),Vro=r(E9e," \u2014 "),DP=n(E9e,"A",{href:!0});var xct=s(DP);Xro=r(xct,"MarianConfig"),xct.forEach(t),zro=r(E9e," (Marian model)"),E9e.forEach(t),Wro=i(L),eg=n(L,"LI",{});var C9e=s(eg);hle=n(C9e,"STRONG",{});var $ct=s(hle);Qro=r($ct,"maskformer"),$ct.forEach(t),Hro=r(C9e," \u2014 "),GP=n(C9e,"A",{href:!0});var kct=s(GP);Uro=r(kct,"MaskFormerConfig"),kct.forEach(t),Jro=r(C9e," (MaskFormer model)"),C9e.forEach(t),Yro=i(L),og=n(L,"LI",{});var w9e=s(og);ple=n(w9e,"STRONG",{});var Sct=s(ple);Kro=r(Sct,"mbart"),Sct.forEach(t),Zro=r(w9e," \u2014 "),OP=n(w9e,"A",{href:!0});var Rct=s(OP);eto=r(Rct,"MBartConfig"),Rct.forEach(t),oto=r(w9e," (mBART model)"),w9e.forEach(t),rto=i(L),rg=n(L,"LI",{});var A9e=s(rg);_le=n(A9e,"STRONG",{});var Pct=s(_le);tto=r(Pct,"mctct"),Pct.forEach(t),ato=r(A9e," \u2014 "),VP=n(A9e,"A",{href:!0});var Bct=s(VP);nto=r(Bct,"MCTCTConfig"),Bct.forEach(t),sto=r(A9e," (M-CTC-T model)"),A9e.forEach(t),lto=i(L),tg=n(L,"LI",{});var L9e=s(tg);ule=n(L9e,"STRONG",{});var Ict=s(ule);ito=r(Ict,"megatron-bert"),Ict.forEach(t),dto=r(L9e," \u2014 "),XP=n(L9e,"A",{href:!0});var Nct=s(XP);cto=r(Nct,"MegatronBertConfig"),Nct.forEach(t),fto=r(L9e," (Megatron-BERT model)"),L9e.forEach(t),mto=i(L),ag=n(L,"LI",{});var y9e=s(ag);ble=n(y9e,"STRONG",{});var qct=s(ble);gto=r(qct,"mobilebert"),qct.forEach(t),hto=r(y9e," \u2014 "),zP=n(y9e,"A",{href:!0});var jct=s(zP);pto=r(jct,"MobileBertConfig"),jct.forEach(t),_to=r(y9e," (MobileBERT model)"),y9e.forEach(t),uto=i(L),ng=n(L,"LI",{});var x9e=s(ng);vle=n(x9e,"STRONG",{});var Dct=s(vle);bto=r(Dct,"mobilevit"),Dct.forEach(t),vto=r(x9e," \u2014 "),WP=n(x9e,"A",{href:!0});var Gct=s(WP);Fto=r(Gct,"MobileViTConfig"),Gct.forEach(t),Tto=r(x9e," (MobileViT model)"),x9e.forEach(t),Mto=i(L),sg=n(L,"LI",{});var $9e=s(sg);Fle=n($9e,"STRONG",{});var Oct=s(Fle);Eto=r(Oct,"mpnet"),Oct.forEach(t),Cto=r($9e," \u2014 "),QP=n($9e,"A",{href:!0});var Vct=s(QP);wto=r(Vct,"MPNetConfig"),Vct.forEach(t),Ato=r($9e," (MPNet model)"),$9e.forEach(t),Lto=i(L),lg=n(L,"LI",{});var k9e=s(lg);Tle=n(k9e,"STRONG",{});var Xct=s(Tle);yto=r(Xct,"mt5"),Xct.forEach(t),xto=r(k9e," \u2014 "),HP=n(k9e,"A",{href:!0});var zct=s(HP);$to=r(zct,"MT5Config"),zct.forEach(t),kto=r(k9e," (MT5 model)"),k9e.forEach(t),Sto=i(L),ig=n(L,"LI",{});var S9e=s(ig);Mle=n(S9e,"STRONG",{});var Wct=s(Mle);Rto=r(Wct,"mvp"),Wct.forEach(t),Pto=r(S9e," \u2014 "),UP=n(S9e,"A",{href:!0});var Qct=s(UP);Bto=r(Qct,"MvpConfig"),Qct.forEach(t),Ito=r(S9e," (MVP model)"),S9e.forEach(t),Nto=i(L),dg=n(L,"LI",{});var R9e=s(dg);Ele=n(R9e,"STRONG",{});var Hct=s(Ele);qto=r(Hct,"nezha"),Hct.forEach(t),jto=r(R9e," \u2014 "),JP=n(R9e,"A",{href:!0});var Uct=s(JP);Dto=r(Uct,"NezhaConfig"),Uct.forEach(t),Gto=r(R9e," (Nezha model)"),R9e.forEach(t),Oto=i(L),cg=n(L,"LI",{});var P9e=s(cg);Cle=n(P9e,"STRONG",{});var Jct=s(Cle);Vto=r(Jct,"nystromformer"),Jct.forEach(t),Xto=r(P9e," \u2014 "),YP=n(P9e,"A",{href:!0});var Yct=s(YP);zto=r(Yct,"NystromformerConfig"),Yct.forEach(t),Wto=r(P9e," (Nystr\xF6mformer model)"),P9e.forEach(t),Qto=i(L),fg=n(L,"LI",{});var B9e=s(fg);wle=n(B9e,"STRONG",{});var Kct=s(wle);Hto=r(Kct,"openai-gpt"),Kct.forEach(t),Uto=r(B9e," \u2014 "),KP=n(B9e,"A",{href:!0});var Zct=s(KP);Jto=r(Zct,"OpenAIGPTConfig"),Zct.forEach(t),Yto=r(B9e," (OpenAI GPT model)"),B9e.forEach(t),Kto=i(L),mg=n(L,"LI",{});var I9e=s(mg);Ale=n(I9e,"STRONG",{});var eft=s(Ale);Zto=r(eft,"opt"),eft.forEach(t),eao=r(I9e," \u2014 "),ZP=n(I9e,"A",{href:!0});var oft=s(ZP);oao=r(oft,"OPTConfig"),oft.forEach(t),rao=r(I9e," (OPT model)"),I9e.forEach(t),tao=i(L),gg=n(L,"LI",{});var N9e=s(gg);Lle=n(N9e,"STRONG",{});var rft=s(Lle);aao=r(rft,"owlvit"),rft.forEach(t),nao=r(N9e," \u2014 "),eB=n(N9e,"A",{href:!0});var tft=s(eB);sao=r(tft,"OwlViTConfig"),tft.forEach(t),lao=r(N9e," (OWL-ViT model)"),N9e.forEach(t),iao=i(L),hg=n(L,"LI",{});var q9e=s(hg);yle=n(q9e,"STRONG",{});var aft=s(yle);dao=r(aft,"pegasus"),aft.forEach(t),cao=r(q9e," \u2014 "),oB=n(q9e,"A",{href:!0});var nft=s(oB);fao=r(nft,"PegasusConfig"),nft.forEach(t),mao=r(q9e," (Pegasus model)"),q9e.forEach(t),gao=i(L),pg=n(L,"LI",{});var j9e=s(pg);xle=n(j9e,"STRONG",{});var sft=s(xle);hao=r(sft,"perceiver"),sft.forEach(t),pao=r(j9e," \u2014 "),rB=n(j9e,"A",{href:!0});var lft=s(rB);_ao=r(lft,"PerceiverConfig"),lft.forEach(t),uao=r(j9e," (Perceiver model)"),j9e.forEach(t),bao=i(L),_g=n(L,"LI",{});var D9e=s(_g);$le=n(D9e,"STRONG",{});var ift=s($le);vao=r(ift,"plbart"),ift.forEach(t),Fao=r(D9e," \u2014 "),tB=n(D9e,"A",{href:!0});var dft=s(tB);Tao=r(dft,"PLBartConfig"),dft.forEach(t),Mao=r(D9e," (PLBart model)"),D9e.forEach(t),Eao=i(L),ug=n(L,"LI",{});var G9e=s(ug);kle=n(G9e,"STRONG",{});var cft=s(kle);Cao=r(cft,"poolformer"),cft.forEach(t),wao=r(G9e," \u2014 "),aB=n(G9e,"A",{href:!0});var fft=s(aB);Aao=r(fft,"PoolFormerConfig"),fft.forEach(t),Lao=r(G9e," (PoolFormer model)"),G9e.forEach(t),yao=i(L),bg=n(L,"LI",{});var O9e=s(bg);Sle=n(O9e,"STRONG",{});var mft=s(Sle);xao=r(mft,"prophetnet"),mft.forEach(t),$ao=r(O9e," \u2014 "),nB=n(O9e,"A",{href:!0});var gft=s(nB);kao=r(gft,"ProphetNetConfig"),gft.forEach(t),Sao=r(O9e," (ProphetNet model)"),O9e.forEach(t),Rao=i(L),vg=n(L,"LI",{});var V9e=s(vg);Rle=n(V9e,"STRONG",{});var hft=s(Rle);Pao=r(hft,"qdqbert"),hft.forEach(t),Bao=r(V9e," \u2014 "),sB=n(V9e,"A",{href:!0});var pft=s(sB);Iao=r(pft,"QDQBertConfig"),pft.forEach(t),Nao=r(V9e," (QDQBert model)"),V9e.forEach(t),qao=i(L),Fg=n(L,"LI",{});var X9e=s(Fg);Ple=n(X9e,"STRONG",{});var _ft=s(Ple);jao=r(_ft,"rag"),_ft.forEach(t),Dao=r(X9e," \u2014 "),lB=n(X9e,"A",{href:!0});var uft=s(lB);Gao=r(uft,"RagConfig"),uft.forEach(t),Oao=r(X9e," (RAG model)"),X9e.forEach(t),Vao=i(L),Tg=n(L,"LI",{});var z9e=s(Tg);Ble=n(z9e,"STRONG",{});var bft=s(Ble);Xao=r(bft,"realm"),bft.forEach(t),zao=r(z9e," \u2014 "),iB=n(z9e,"A",{href:!0});var vft=s(iB);Wao=r(vft,"RealmConfig"),vft.forEach(t),Qao=r(z9e," (REALM model)"),z9e.forEach(t),Hao=i(L),Mg=n(L,"LI",{});var W9e=s(Mg);Ile=n(W9e,"STRONG",{});var Fft=s(Ile);Uao=r(Fft,"reformer"),Fft.forEach(t),Jao=r(W9e," \u2014 "),dB=n(W9e,"A",{href:!0});var Tft=s(dB);Yao=r(Tft,"ReformerConfig"),Tft.forEach(t),Kao=r(W9e," (Reformer model)"),W9e.forEach(t),Zao=i(L),Eg=n(L,"LI",{});var Q9e=s(Eg);Nle=n(Q9e,"STRONG",{});var Mft=s(Nle);eno=r(Mft,"regnet"),Mft.forEach(t),ono=r(Q9e," \u2014 "),cB=n(Q9e,"A",{href:!0});var Eft=s(cB);rno=r(Eft,"RegNetConfig"),Eft.forEach(t),tno=r(Q9e," (RegNet model)"),Q9e.forEach(t),ano=i(L),Cg=n(L,"LI",{});var H9e=s(Cg);qle=n(H9e,"STRONG",{});var Cft=s(qle);nno=r(Cft,"rembert"),Cft.forEach(t),sno=r(H9e," \u2014 "),fB=n(H9e,"A",{href:!0});var wft=s(fB);lno=r(wft,"RemBertConfig"),wft.forEach(t),ino=r(H9e," (RemBERT model)"),H9e.forEach(t),dno=i(L),wg=n(L,"LI",{});var U9e=s(wg);jle=n(U9e,"STRONG",{});var Aft=s(jle);cno=r(Aft,"resnet"),Aft.forEach(t),fno=r(U9e," \u2014 "),mB=n(U9e,"A",{href:!0});var Lft=s(mB);mno=r(Lft,"ResNetConfig"),Lft.forEach(t),gno=r(U9e," (ResNet model)"),U9e.forEach(t),hno=i(L),Ag=n(L,"LI",{});var J9e=s(Ag);Dle=n(J9e,"STRONG",{});var yft=s(Dle);pno=r(yft,"retribert"),yft.forEach(t),_no=r(J9e," \u2014 "),gB=n(J9e,"A",{href:!0});var xft=s(gB);uno=r(xft,"RetriBertConfig"),xft.forEach(t),bno=r(J9e," (RetriBERT model)"),J9e.forEach(t),vno=i(L),Lg=n(L,"LI",{});var Y9e=s(Lg);Gle=n(Y9e,"STRONG",{});var $ft=s(Gle);Fno=r($ft,"roberta"),$ft.forEach(t),Tno=r(Y9e," \u2014 "),hB=n(Y9e,"A",{href:!0});var kft=s(hB);Mno=r(kft,"RobertaConfig"),kft.forEach(t),Eno=r(Y9e," (RoBERTa model)"),Y9e.forEach(t),Cno=i(L),yg=n(L,"LI",{});var K9e=s(yg);Ole=n(K9e,"STRONG",{});var Sft=s(Ole);wno=r(Sft,"roformer"),Sft.forEach(t),Ano=r(K9e," \u2014 "),pB=n(K9e,"A",{href:!0});var Rft=s(pB);Lno=r(Rft,"RoFormerConfig"),Rft.forEach(t),yno=r(K9e," (RoFormer model)"),K9e.forEach(t),xno=i(L),xg=n(L,"LI",{});var Z9e=s(xg);Vle=n(Z9e,"STRONG",{});var Pft=s(Vle);$no=r(Pft,"segformer"),Pft.forEach(t),kno=r(Z9e," \u2014 "),_B=n(Z9e,"A",{href:!0});var Bft=s(_B);Sno=r(Bft,"SegformerConfig"),Bft.forEach(t),Rno=r(Z9e," (SegFormer model)"),Z9e.forEach(t),Pno=i(L),$g=n(L,"LI",{});var exe=s($g);Xle=n(exe,"STRONG",{});var Ift=s(Xle);Bno=r(Ift,"sew"),Ift.forEach(t),Ino=r(exe," \u2014 "),uB=n(exe,"A",{href:!0});var Nft=s(uB);Nno=r(Nft,"SEWConfig"),Nft.forEach(t),qno=r(exe," (SEW model)"),exe.forEach(t),jno=i(L),kg=n(L,"LI",{});var oxe=s(kg);zle=n(oxe,"STRONG",{});var qft=s(zle);Dno=r(qft,"sew-d"),qft.forEach(t),Gno=r(oxe," \u2014 "),bB=n(oxe,"A",{href:!0});var jft=s(bB);Ono=r(jft,"SEWDConfig"),jft.forEach(t),Vno=r(oxe," (SEW-D model)"),oxe.forEach(t),Xno=i(L),Sg=n(L,"LI",{});var rxe=s(Sg);Wle=n(rxe,"STRONG",{});var Dft=s(Wle);zno=r(Dft,"speech-encoder-decoder"),Dft.forEach(t),Wno=r(rxe," \u2014 "),vB=n(rxe,"A",{href:!0});var Gft=s(vB);Qno=r(Gft,"SpeechEncoderDecoderConfig"),Gft.forEach(t),Hno=r(rxe," (Speech Encoder decoder model)"),rxe.forEach(t),Uno=i(L),Rg=n(L,"LI",{});var txe=s(Rg);Qle=n(txe,"STRONG",{});var Oft=s(Qle);Jno=r(Oft,"speech_to_text"),Oft.forEach(t),Yno=r(txe," \u2014 "),FB=n(txe,"A",{href:!0});var Vft=s(FB);Kno=r(Vft,"Speech2TextConfig"),Vft.forEach(t),Zno=r(txe," (Speech2Text model)"),txe.forEach(t),eso=i(L),Pg=n(L,"LI",{});var axe=s(Pg);Hle=n(axe,"STRONG",{});var Xft=s(Hle);oso=r(Xft,"speech_to_text_2"),Xft.forEach(t),rso=r(axe," \u2014 "),TB=n(axe,"A",{href:!0});var zft=s(TB);tso=r(zft,"Speech2Text2Config"),zft.forEach(t),aso=r(axe," (Speech2Text2 model)"),axe.forEach(t),nso=i(L),Bg=n(L,"LI",{});var nxe=s(Bg);Ule=n(nxe,"STRONG",{});var Wft=s(Ule);sso=r(Wft,"splinter"),Wft.forEach(t),lso=r(nxe," \u2014 "),MB=n(nxe,"A",{href:!0});var Qft=s(MB);iso=r(Qft,"SplinterConfig"),Qft.forEach(t),dso=r(nxe," (Splinter model)"),nxe.forEach(t),cso=i(L),Ig=n(L,"LI",{});var sxe=s(Ig);Jle=n(sxe,"STRONG",{});var Hft=s(Jle);fso=r(Hft,"squeezebert"),Hft.forEach(t),mso=r(sxe," \u2014 "),EB=n(sxe,"A",{href:!0});var Uft=s(EB);gso=r(Uft,"SqueezeBertConfig"),Uft.forEach(t),hso=r(sxe," (SqueezeBERT model)"),sxe.forEach(t),pso=i(L),Ng=n(L,"LI",{});var lxe=s(Ng);Yle=n(lxe,"STRONG",{});var Jft=s(Yle);_so=r(Jft,"swin"),Jft.forEach(t),uso=r(lxe," \u2014 "),CB=n(lxe,"A",{href:!0});var Yft=s(CB);bso=r(Yft,"SwinConfig"),Yft.forEach(t),vso=r(lxe," (Swin Transformer model)"),lxe.forEach(t),Fso=i(L),qg=n(L,"LI",{});var ixe=s(qg);Kle=n(ixe,"STRONG",{});var Kft=s(Kle);Tso=r(Kft,"swinv2"),Kft.forEach(t),Mso=r(ixe," \u2014 "),wB=n(ixe,"A",{href:!0});var Zft=s(wB);Eso=r(Zft,"Swinv2Config"),Zft.forEach(t),Cso=r(ixe," (Swin Transformer V2 model)"),ixe.forEach(t),wso=i(L),jg=n(L,"LI",{});var dxe=s(jg);Zle=n(dxe,"STRONG",{});var emt=s(Zle);Aso=r(emt,"t5"),emt.forEach(t),Lso=r(dxe," \u2014 "),AB=n(dxe,"A",{href:!0});var omt=s(AB);yso=r(omt,"T5Config"),omt.forEach(t),xso=r(dxe," (T5 model)"),dxe.forEach(t),$so=i(L),Dg=n(L,"LI",{});var cxe=s(Dg);eie=n(cxe,"STRONG",{});var rmt=s(eie);kso=r(rmt,"tapas"),rmt.forEach(t),Sso=r(cxe," \u2014 "),LB=n(cxe,"A",{href:!0});var tmt=s(LB);Rso=r(tmt,"TapasConfig"),tmt.forEach(t),Pso=r(cxe," (TAPAS model)"),cxe.forEach(t),Bso=i(L),Gg=n(L,"LI",{});var fxe=s(Gg);oie=n(fxe,"STRONG",{});var amt=s(oie);Iso=r(amt,"trajectory_transformer"),amt.forEach(t),Nso=r(fxe," \u2014 "),yB=n(fxe,"A",{href:!0});var nmt=s(yB);qso=r(nmt,"TrajectoryTransformerConfig"),nmt.forEach(t),jso=r(fxe," (Trajectory Transformer model)"),fxe.forEach(t),Dso=i(L),Og=n(L,"LI",{});var mxe=s(Og);rie=n(mxe,"STRONG",{});var smt=s(rie);Gso=r(smt,"transfo-xl"),smt.forEach(t),Oso=r(mxe," \u2014 "),xB=n(mxe,"A",{href:!0});var lmt=s(xB);Vso=r(lmt,"TransfoXLConfig"),lmt.forEach(t),Xso=r(mxe," (Transformer-XL model)"),mxe.forEach(t),zso=i(L),Vg=n(L,"LI",{});var gxe=s(Vg);tie=n(gxe,"STRONG",{});var imt=s(tie);Wso=r(imt,"trocr"),imt.forEach(t),Qso=r(gxe," \u2014 "),$B=n(gxe,"A",{href:!0});var dmt=s($B);Hso=r(dmt,"TrOCRConfig"),dmt.forEach(t),Uso=r(gxe," (TrOCR model)"),gxe.forEach(t),Jso=i(L),Xg=n(L,"LI",{});var hxe=s(Xg);aie=n(hxe,"STRONG",{});var cmt=s(aie);Yso=r(cmt,"unispeech"),cmt.forEach(t),Kso=r(hxe," \u2014 "),kB=n(hxe,"A",{href:!0});var fmt=s(kB);Zso=r(fmt,"UniSpeechConfig"),fmt.forEach(t),elo=r(hxe," (UniSpeech model)"),hxe.forEach(t),olo=i(L),zg=n(L,"LI",{});var pxe=s(zg);nie=n(pxe,"STRONG",{});var mmt=s(nie);rlo=r(mmt,"unispeech-sat"),mmt.forEach(t),tlo=r(pxe," \u2014 "),SB=n(pxe,"A",{href:!0});var gmt=s(SB);alo=r(gmt,"UniSpeechSatConfig"),gmt.forEach(t),nlo=r(pxe," (UniSpeechSat model)"),pxe.forEach(t),slo=i(L),Wg=n(L,"LI",{});var _xe=s(Wg);sie=n(_xe,"STRONG",{});var hmt=s(sie);llo=r(hmt,"van"),hmt.forEach(t),ilo=r(_xe," \u2014 "),RB=n(_xe,"A",{href:!0});var pmt=s(RB);dlo=r(pmt,"VanConfig"),pmt.forEach(t),clo=r(_xe," (VAN model)"),_xe.forEach(t),flo=i(L),Qg=n(L,"LI",{});var uxe=s(Qg);lie=n(uxe,"STRONG",{});var _mt=s(lie);mlo=r(_mt,"videomae"),_mt.forEach(t),glo=r(uxe," \u2014 "),PB=n(uxe,"A",{href:!0});var umt=s(PB);hlo=r(umt,"VideoMAEConfig"),umt.forEach(t),plo=r(uxe," (VideoMAE model)"),uxe.forEach(t),_lo=i(L),Hg=n(L,"LI",{});var bxe=s(Hg);iie=n(bxe,"STRONG",{});var bmt=s(iie);ulo=r(bmt,"vilt"),bmt.forEach(t),blo=r(bxe," \u2014 "),BB=n(bxe,"A",{href:!0});var vmt=s(BB);vlo=r(vmt,"ViltConfig"),vmt.forEach(t),Flo=r(bxe," (ViLT model)"),bxe.forEach(t),Tlo=i(L),Ug=n(L,"LI",{});var vxe=s(Ug);die=n(vxe,"STRONG",{});var Fmt=s(die);Mlo=r(Fmt,"vision-encoder-decoder"),Fmt.forEach(t),Elo=r(vxe," \u2014 "),IB=n(vxe,"A",{href:!0});var Tmt=s(IB);Clo=r(Tmt,"VisionEncoderDecoderConfig"),Tmt.forEach(t),wlo=r(vxe," (Vision Encoder decoder model)"),vxe.forEach(t),Alo=i(L),Jg=n(L,"LI",{});var Fxe=s(Jg);cie=n(Fxe,"STRONG",{});var Mmt=s(cie);Llo=r(Mmt,"vision-text-dual-encoder"),Mmt.forEach(t),ylo=r(Fxe," \u2014 "),NB=n(Fxe,"A",{href:!0});var Emt=s(NB);xlo=r(Emt,"VisionTextDualEncoderConfig"),Emt.forEach(t),$lo=r(Fxe," (VisionTextDualEncoder model)"),Fxe.forEach(t),klo=i(L),Yg=n(L,"LI",{});var Txe=s(Yg);fie=n(Txe,"STRONG",{});var Cmt=s(fie);Slo=r(Cmt,"visual_bert"),Cmt.forEach(t),Rlo=r(Txe," \u2014 "),qB=n(Txe,"A",{href:!0});var wmt=s(qB);Plo=r(wmt,"VisualBertConfig"),wmt.forEach(t),Blo=r(Txe," (VisualBERT model)"),Txe.forEach(t),Ilo=i(L),Kg=n(L,"LI",{});var Mxe=s(Kg);mie=n(Mxe,"STRONG",{});var Amt=s(mie);Nlo=r(Amt,"vit"),Amt.forEach(t),qlo=r(Mxe," \u2014 "),jB=n(Mxe,"A",{href:!0});var Lmt=s(jB);jlo=r(Lmt,"ViTConfig"),Lmt.forEach(t),Dlo=r(Mxe," (ViT model)"),Mxe.forEach(t),Glo=i(L),Zg=n(L,"LI",{});var Exe=s(Zg);gie=n(Exe,"STRONG",{});var ymt=s(gie);Olo=r(ymt,"vit_mae"),ymt.forEach(t),Vlo=r(Exe," \u2014 "),DB=n(Exe,"A",{href:!0});var xmt=s(DB);Xlo=r(xmt,"ViTMAEConfig"),xmt.forEach(t),zlo=r(Exe," (ViTMAE model)"),Exe.forEach(t),Wlo=i(L),eh=n(L,"LI",{});var Cxe=s(eh);hie=n(Cxe,"STRONG",{});var $mt=s(hie);Qlo=r($mt,"wav2vec2"),$mt.forEach(t),Hlo=r(Cxe," \u2014 "),GB=n(Cxe,"A",{href:!0});var kmt=s(GB);Ulo=r(kmt,"Wav2Vec2Config"),kmt.forEach(t),Jlo=r(Cxe," (Wav2Vec2 model)"),Cxe.forEach(t),Ylo=i(L),oh=n(L,"LI",{});var wxe=s(oh);pie=n(wxe,"STRONG",{});var Smt=s(pie);Klo=r(Smt,"wav2vec2-conformer"),Smt.forEach(t),Zlo=r(wxe," \u2014 "),OB=n(wxe,"A",{href:!0});var Rmt=s(OB);eio=r(Rmt,"Wav2Vec2ConformerConfig"),Rmt.forEach(t),oio=r(wxe," (Wav2Vec2-Conformer model)"),wxe.forEach(t),rio=i(L),rh=n(L,"LI",{});var Axe=s(rh);_ie=n(Axe,"STRONG",{});var Pmt=s(_ie);tio=r(Pmt,"wavlm"),Pmt.forEach(t),aio=r(Axe," \u2014 "),VB=n(Axe,"A",{href:!0});var Bmt=s(VB);nio=r(Bmt,"WavLMConfig"),Bmt.forEach(t),sio=r(Axe," (WavLM model)"),Axe.forEach(t),lio=i(L),th=n(L,"LI",{});var Lxe=s(th);uie=n(Lxe,"STRONG",{});var Imt=s(uie);iio=r(Imt,"xglm"),Imt.forEach(t),dio=r(Lxe," \u2014 "),XB=n(Lxe,"A",{href:!0});var Nmt=s(XB);cio=r(Nmt,"XGLMConfig"),Nmt.forEach(t),fio=r(Lxe," (XGLM model)"),Lxe.forEach(t),mio=i(L),ah=n(L,"LI",{});var yxe=s(ah);bie=n(yxe,"STRONG",{});var qmt=s(bie);gio=r(qmt,"xlm"),qmt.forEach(t),hio=r(yxe," \u2014 "),zB=n(yxe,"A",{href:!0});var jmt=s(zB);pio=r(jmt,"XLMConfig"),jmt.forEach(t),_io=r(yxe," (XLM model)"),yxe.forEach(t),uio=i(L),nh=n(L,"LI",{});var xxe=s(nh);vie=n(xxe,"STRONG",{});var Dmt=s(vie);bio=r(Dmt,"xlm-prophetnet"),Dmt.forEach(t),vio=r(xxe," \u2014 "),WB=n(xxe,"A",{href:!0});var Gmt=s(WB);Fio=r(Gmt,"XLMProphetNetConfig"),Gmt.forEach(t),Tio=r(xxe," (XLM-ProphetNet model)"),xxe.forEach(t),Mio=i(L),sh=n(L,"LI",{});var $xe=s(sh);Fie=n($xe,"STRONG",{});var Omt=s(Fie);Eio=r(Omt,"xlm-roberta"),Omt.forEach(t),Cio=r($xe," \u2014 "),QB=n($xe,"A",{href:!0});var Vmt=s(QB);wio=r(Vmt,"XLMRobertaConfig"),Vmt.forEach(t),Aio=r($xe," (XLM-RoBERTa model)"),$xe.forEach(t),Lio=i(L),lh=n(L,"LI",{});var kxe=s(lh);Tie=n(kxe,"STRONG",{});var Xmt=s(Tie);yio=r(Xmt,"xlm-roberta-xl"),Xmt.forEach(t),xio=r(kxe," \u2014 "),HB=n(kxe,"A",{href:!0});var zmt=s(HB);$io=r(zmt,"XLMRobertaXLConfig"),zmt.forEach(t),kio=r(kxe," (XLM-RoBERTa-XL model)"),kxe.forEach(t),Sio=i(L),ih=n(L,"LI",{});var Sxe=s(ih);Mie=n(Sxe,"STRONG",{});var Wmt=s(Mie);Rio=r(Wmt,"xlnet"),Wmt.forEach(t),Pio=r(Sxe," \u2014 "),UB=n(Sxe,"A",{href:!0});var Qmt=s(UB);Bio=r(Qmt,"XLNetConfig"),Qmt.forEach(t),Iio=r(Sxe," (XLNet model)"),Sxe.forEach(t),Nio=i(L),dh=n(L,"LI",{});var Rxe=s(dh);Eie=n(Rxe,"STRONG",{});var Hmt=s(Eie);qio=r(Hmt,"yolos"),Hmt.forEach(t),jio=r(Rxe," \u2014 "),JB=n(Rxe,"A",{href:!0});var Umt=s(JB);Dio=r(Umt,"YolosConfig"),Umt.forEach(t),Gio=r(Rxe," (YOLOS model)"),Rxe.forEach(t),Oio=i(L),ch=n(L,"LI",{});var Pxe=s(ch);Cie=n(Pxe,"STRONG",{});var Jmt=s(Cie);Vio=r(Jmt,"yoso"),Jmt.forEach(t),Xio=r(Pxe," \u2014 "),YB=n(Pxe,"A",{href:!0});var Ymt=s(YB);zio=r(Ymt,"YosoConfig"),Ymt.forEach(t),Wio=r(Pxe," (YOSO model)"),Pxe.forEach(t),L.forEach(t),Qio=i(it),T(fh.$$.fragment,it),it.forEach(t),Hio=i(lt),mh=n(lt,"DIV",{class:!0});var YHe=s(mh);T(oy.$$.fragment,YHe),Uio=i(YHe),wie=n(YHe,"P",{});var Kmt=s(wie);Jio=r(Kmt,"Register a new configuration for this class."),Kmt.forEach(t),YHe.forEach(t),lt.forEach(t),JWe=i(f),Wi=n(f,"H2",{class:!0});var KHe=s(Wi);gh=n(KHe,"A",{id:!0,class:!0,href:!0});var Zmt=s(gh);Aie=n(Zmt,"SPAN",{});var egt=s(Aie);T(ry.$$.fragment,egt),egt.forEach(t),Zmt.forEach(t),Yio=i(KHe),Lie=n(KHe,"SPAN",{});var ogt=s(Lie);Kio=r(ogt,"AutoTokenizer"),ogt.forEach(t),KHe.forEach(t),YWe=i(f),xo=n(f,"DIV",{class:!0});var sl=s(xo);T(ty.$$.fragment,sl),Zio=i(sl),ay=n(sl,"P",{});var ZHe=s(ay);edo=r(ZHe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),KB=n(ZHe,"A",{href:!0});var rgt=s(KB);odo=r(rgt,"AutoTokenizer.from_pretrained()"),rgt.forEach(t),rdo=r(ZHe," class method."),ZHe.forEach(t),tdo=i(sl),ny=n(sl,"P",{});var eUe=s(ny);ado=r(eUe,"This class cannot be instantiated directly using "),yie=n(eUe,"CODE",{});var tgt=s(yie);ndo=r(tgt,"__init__()"),tgt.forEach(t),sdo=r(eUe," (throws an error)."),eUe.forEach(t),ldo=i(sl),kr=n(sl,"DIV",{class:!0});var ll=s(kr);T(sy.$$.fragment,ll),ido=i(ll),xie=n(ll,"P",{});var agt=s(xie);ddo=r(agt,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),agt.forEach(t),cdo=i(ll),qa=n(ll,"P",{});var QA=s(qa);fdo=r(QA,"The tokenizer class to instantiate is selected based on the "),$ie=n(QA,"CODE",{});var ngt=s($ie);mdo=r(ngt,"model_type"),ngt.forEach(t),gdo=r(QA,` property of the config object (either
passed as an argument or loaded from `),kie=n(QA,"CODE",{});var sgt=s(kie);hdo=r(sgt,"pretrained_model_name_or_path"),sgt.forEach(t),pdo=r(QA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sie=n(QA,"CODE",{});var lgt=s(Sie);_do=r(lgt,"pretrained_model_name_or_path"),lgt.forEach(t),udo=r(QA,":"),QA.forEach(t),bdo=i(ll),k=n(ll,"UL",{});var S=s(k);zn=n(S,"LI",{});var uS=s(zn);Rie=n(uS,"STRONG",{});var igt=s(Rie);vdo=r(igt,"albert"),igt.forEach(t),Fdo=r(uS," \u2014 "),ZB=n(uS,"A",{href:!0});var dgt=s(ZB);Tdo=r(dgt,"AlbertTokenizer"),dgt.forEach(t),Mdo=r(uS," or "),eI=n(uS,"A",{href:!0});var cgt=s(eI);Edo=r(cgt,"AlbertTokenizerFast"),cgt.forEach(t),Cdo=r(uS," (ALBERT model)"),uS.forEach(t),wdo=i(S),Wn=n(S,"LI",{});var bS=s(Wn);Pie=n(bS,"STRONG",{});var fgt=s(Pie);Ado=r(fgt,"bart"),fgt.forEach(t),Ldo=r(bS," \u2014 "),oI=n(bS,"A",{href:!0});var mgt=s(oI);ydo=r(mgt,"BartTokenizer"),mgt.forEach(t),xdo=r(bS," or "),rI=n(bS,"A",{href:!0});var ggt=s(rI);$do=r(ggt,"BartTokenizerFast"),ggt.forEach(t),kdo=r(bS," (BART model)"),bS.forEach(t),Sdo=i(S),Qn=n(S,"LI",{});var vS=s(Qn);Bie=n(vS,"STRONG",{});var hgt=s(Bie);Rdo=r(hgt,"barthez"),hgt.forEach(t),Pdo=r(vS," \u2014 "),tI=n(vS,"A",{href:!0});var pgt=s(tI);Bdo=r(pgt,"BarthezTokenizer"),pgt.forEach(t),Ido=r(vS," or "),aI=n(vS,"A",{href:!0});var _gt=s(aI);Ndo=r(_gt,"BarthezTokenizerFast"),_gt.forEach(t),qdo=r(vS," (BARThez model)"),vS.forEach(t),jdo=i(S),hh=n(S,"LI",{});var Bxe=s(hh);Iie=n(Bxe,"STRONG",{});var ugt=s(Iie);Ddo=r(ugt,"bartpho"),ugt.forEach(t),Gdo=r(Bxe," \u2014 "),nI=n(Bxe,"A",{href:!0});var bgt=s(nI);Odo=r(bgt,"BartphoTokenizer"),bgt.forEach(t),Vdo=r(Bxe," (BARTpho model)"),Bxe.forEach(t),Xdo=i(S),Hn=n(S,"LI",{});var FS=s(Hn);Nie=n(FS,"STRONG",{});var vgt=s(Nie);zdo=r(vgt,"bert"),vgt.forEach(t),Wdo=r(FS," \u2014 "),sI=n(FS,"A",{href:!0});var Fgt=s(sI);Qdo=r(Fgt,"BertTokenizer"),Fgt.forEach(t),Hdo=r(FS," or "),lI=n(FS,"A",{href:!0});var Tgt=s(lI);Udo=r(Tgt,"BertTokenizerFast"),Tgt.forEach(t),Jdo=r(FS," (BERT model)"),FS.forEach(t),Ydo=i(S),ph=n(S,"LI",{});var Ixe=s(ph);qie=n(Ixe,"STRONG",{});var Mgt=s(qie);Kdo=r(Mgt,"bert-generation"),Mgt.forEach(t),Zdo=r(Ixe," \u2014 "),iI=n(Ixe,"A",{href:!0});var Egt=s(iI);eco=r(Egt,"BertGenerationTokenizer"),Egt.forEach(t),oco=r(Ixe," (Bert Generation model)"),Ixe.forEach(t),rco=i(S),_h=n(S,"LI",{});var Nxe=s(_h);jie=n(Nxe,"STRONG",{});var Cgt=s(jie);tco=r(Cgt,"bert-japanese"),Cgt.forEach(t),aco=r(Nxe," \u2014 "),dI=n(Nxe,"A",{href:!0});var wgt=s(dI);nco=r(wgt,"BertJapaneseTokenizer"),wgt.forEach(t),sco=r(Nxe," (BertJapanese model)"),Nxe.forEach(t),lco=i(S),uh=n(S,"LI",{});var qxe=s(uh);Die=n(qxe,"STRONG",{});var Agt=s(Die);ico=r(Agt,"bertweet"),Agt.forEach(t),dco=r(qxe," \u2014 "),cI=n(qxe,"A",{href:!0});var Lgt=s(cI);cco=r(Lgt,"BertweetTokenizer"),Lgt.forEach(t),fco=r(qxe," (BERTweet model)"),qxe.forEach(t),mco=i(S),Un=n(S,"LI",{});var TS=s(Un);Gie=n(TS,"STRONG",{});var ygt=s(Gie);gco=r(ygt,"big_bird"),ygt.forEach(t),hco=r(TS," \u2014 "),fI=n(TS,"A",{href:!0});var xgt=s(fI);pco=r(xgt,"BigBirdTokenizer"),xgt.forEach(t),_co=r(TS," or "),mI=n(TS,"A",{href:!0});var $gt=s(mI);uco=r($gt,"BigBirdTokenizerFast"),$gt.forEach(t),bco=r(TS," (BigBird model)"),TS.forEach(t),vco=i(S),Jn=n(S,"LI",{});var MS=s(Jn);Oie=n(MS,"STRONG",{});var kgt=s(Oie);Fco=r(kgt,"bigbird_pegasus"),kgt.forEach(t),Tco=r(MS," \u2014 "),gI=n(MS,"A",{href:!0});var Sgt=s(gI);Mco=r(Sgt,"PegasusTokenizer"),Sgt.forEach(t),Eco=r(MS," or "),hI=n(MS,"A",{href:!0});var Rgt=s(hI);Cco=r(Rgt,"PegasusTokenizerFast"),Rgt.forEach(t),wco=r(MS," (BigBird-Pegasus model)"),MS.forEach(t),Aco=i(S),Yn=n(S,"LI",{});var ES=s(Yn);Vie=n(ES,"STRONG",{});var Pgt=s(Vie);Lco=r(Pgt,"blenderbot"),Pgt.forEach(t),yco=r(ES," \u2014 "),pI=n(ES,"A",{href:!0});var Bgt=s(pI);xco=r(Bgt,"BlenderbotTokenizer"),Bgt.forEach(t),$co=r(ES," or "),_I=n(ES,"A",{href:!0});var Igt=s(_I);kco=r(Igt,"BlenderbotTokenizerFast"),Igt.forEach(t),Sco=r(ES," (Blenderbot model)"),ES.forEach(t),Rco=i(S),bh=n(S,"LI",{});var jxe=s(bh);Xie=n(jxe,"STRONG",{});var Ngt=s(Xie);Pco=r(Ngt,"blenderbot-small"),Ngt.forEach(t),Bco=r(jxe," \u2014 "),uI=n(jxe,"A",{href:!0});var qgt=s(uI);Ico=r(qgt,"BlenderbotSmallTokenizer"),qgt.forEach(t),Nco=r(jxe," (BlenderbotSmall model)"),jxe.forEach(t),qco=i(S),vh=n(S,"LI",{});var Dxe=s(vh);zie=n(Dxe,"STRONG",{});var jgt=s(zie);jco=r(jgt,"bloom"),jgt.forEach(t),Dco=r(Dxe," \u2014 "),bI=n(Dxe,"A",{href:!0});var Dgt=s(bI);Gco=r(Dgt,"BloomTokenizerFast"),Dgt.forEach(t),Oco=r(Dxe," (BLOOM model)"),Dxe.forEach(t),Vco=i(S),Fh=n(S,"LI",{});var Gxe=s(Fh);Wie=n(Gxe,"STRONG",{});var Ggt=s(Wie);Xco=r(Ggt,"byt5"),Ggt.forEach(t),zco=r(Gxe," \u2014 "),vI=n(Gxe,"A",{href:!0});var Ogt=s(vI);Wco=r(Ogt,"ByT5Tokenizer"),Ogt.forEach(t),Qco=r(Gxe," (ByT5 model)"),Gxe.forEach(t),Hco=i(S),Kn=n(S,"LI",{});var CS=s(Kn);Qie=n(CS,"STRONG",{});var Vgt=s(Qie);Uco=r(Vgt,"camembert"),Vgt.forEach(t),Jco=r(CS," \u2014 "),FI=n(CS,"A",{href:!0});var Xgt=s(FI);Yco=r(Xgt,"CamembertTokenizer"),Xgt.forEach(t),Kco=r(CS," or "),TI=n(CS,"A",{href:!0});var zgt=s(TI);Zco=r(zgt,"CamembertTokenizerFast"),zgt.forEach(t),efo=r(CS," (CamemBERT model)"),CS.forEach(t),ofo=i(S),Th=n(S,"LI",{});var Oxe=s(Th);Hie=n(Oxe,"STRONG",{});var Wgt=s(Hie);rfo=r(Wgt,"canine"),Wgt.forEach(t),tfo=r(Oxe," \u2014 "),MI=n(Oxe,"A",{href:!0});var Qgt=s(MI);afo=r(Qgt,"CanineTokenizer"),Qgt.forEach(t),nfo=r(Oxe," (CANINE model)"),Oxe.forEach(t),sfo=i(S),Zn=n(S,"LI",{});var wS=s(Zn);Uie=n(wS,"STRONG",{});var Hgt=s(Uie);lfo=r(Hgt,"clip"),Hgt.forEach(t),ifo=r(wS," \u2014 "),EI=n(wS,"A",{href:!0});var Ugt=s(EI);dfo=r(Ugt,"CLIPTokenizer"),Ugt.forEach(t),cfo=r(wS," or "),CI=n(wS,"A",{href:!0});var Jgt=s(CI);ffo=r(Jgt,"CLIPTokenizerFast"),Jgt.forEach(t),mfo=r(wS," (CLIP model)"),wS.forEach(t),gfo=i(S),es=n(S,"LI",{});var AS=s(es);Jie=n(AS,"STRONG",{});var Ygt=s(Jie);hfo=r(Ygt,"codegen"),Ygt.forEach(t),pfo=r(AS," \u2014 "),wI=n(AS,"A",{href:!0});var Kgt=s(wI);_fo=r(Kgt,"CodeGenTokenizer"),Kgt.forEach(t),ufo=r(AS," or "),AI=n(AS,"A",{href:!0});var Zgt=s(AI);bfo=r(Zgt,"CodeGenTokenizerFast"),Zgt.forEach(t),vfo=r(AS," (CodeGen model)"),AS.forEach(t),Ffo=i(S),os=n(S,"LI",{});var LS=s(os);Yie=n(LS,"STRONG",{});var eht=s(Yie);Tfo=r(eht,"convbert"),eht.forEach(t),Mfo=r(LS," \u2014 "),LI=n(LS,"A",{href:!0});var oht=s(LI);Efo=r(oht,"ConvBertTokenizer"),oht.forEach(t),Cfo=r(LS," or "),yI=n(LS,"A",{href:!0});var rht=s(yI);wfo=r(rht,"ConvBertTokenizerFast"),rht.forEach(t),Afo=r(LS," (ConvBERT model)"),LS.forEach(t),Lfo=i(S),rs=n(S,"LI",{});var yS=s(rs);Kie=n(yS,"STRONG",{});var tht=s(Kie);yfo=r(tht,"cpm"),tht.forEach(t),xfo=r(yS," \u2014 "),xI=n(yS,"A",{href:!0});var aht=s(xI);$fo=r(aht,"CpmTokenizer"),aht.forEach(t),kfo=r(yS," or "),$I=n(yS,"A",{href:!0});var nht=s($I);Sfo=r(nht,"CpmTokenizerFast"),nht.forEach(t),Rfo=r(yS," (CPM model)"),yS.forEach(t),Pfo=i(S),Mh=n(S,"LI",{});var Vxe=s(Mh);Zie=n(Vxe,"STRONG",{});var sht=s(Zie);Bfo=r(sht,"ctrl"),sht.forEach(t),Ifo=r(Vxe," \u2014 "),kI=n(Vxe,"A",{href:!0});var lht=s(kI);Nfo=r(lht,"CTRLTokenizer"),lht.forEach(t),qfo=r(Vxe," (CTRL model)"),Vxe.forEach(t),jfo=i(S),ts=n(S,"LI",{});var xS=s(ts);ede=n(xS,"STRONG",{});var iht=s(ede);Dfo=r(iht,"data2vec-text"),iht.forEach(t),Gfo=r(xS," \u2014 "),SI=n(xS,"A",{href:!0});var dht=s(SI);Ofo=r(dht,"RobertaTokenizer"),dht.forEach(t),Vfo=r(xS," or "),RI=n(xS,"A",{href:!0});var cht=s(RI);Xfo=r(cht,"RobertaTokenizerFast"),cht.forEach(t),zfo=r(xS," (Data2VecText model)"),xS.forEach(t),Wfo=i(S),as=n(S,"LI",{});var $S=s(as);ode=n($S,"STRONG",{});var fht=s(ode);Qfo=r(fht,"deberta"),fht.forEach(t),Hfo=r($S," \u2014 "),PI=n($S,"A",{href:!0});var mht=s(PI);Ufo=r(mht,"DebertaTokenizer"),mht.forEach(t),Jfo=r($S," or "),BI=n($S,"A",{href:!0});var ght=s(BI);Yfo=r(ght,"DebertaTokenizerFast"),ght.forEach(t),Kfo=r($S," (DeBERTa model)"),$S.forEach(t),Zfo=i(S),ns=n(S,"LI",{});var kS=s(ns);rde=n(kS,"STRONG",{});var hht=s(rde);emo=r(hht,"deberta-v2"),hht.forEach(t),omo=r(kS," \u2014 "),II=n(kS,"A",{href:!0});var pht=s(II);rmo=r(pht,"DebertaV2Tokenizer"),pht.forEach(t),tmo=r(kS," or "),NI=n(kS,"A",{href:!0});var _ht=s(NI);amo=r(_ht,"DebertaV2TokenizerFast"),_ht.forEach(t),nmo=r(kS," (DeBERTa-v2 model)"),kS.forEach(t),smo=i(S),ss=n(S,"LI",{});var SS=s(ss);tde=n(SS,"STRONG",{});var uht=s(tde);lmo=r(uht,"distilbert"),uht.forEach(t),imo=r(SS," \u2014 "),qI=n(SS,"A",{href:!0});var bht=s(qI);dmo=r(bht,"DistilBertTokenizer"),bht.forEach(t),cmo=r(SS," or "),jI=n(SS,"A",{href:!0});var vht=s(jI);fmo=r(vht,"DistilBertTokenizerFast"),vht.forEach(t),mmo=r(SS," (DistilBERT model)"),SS.forEach(t),gmo=i(S),ls=n(S,"LI",{});var RS=s(ls);ade=n(RS,"STRONG",{});var Fht=s(ade);hmo=r(Fht,"dpr"),Fht.forEach(t),pmo=r(RS," \u2014 "),DI=n(RS,"A",{href:!0});var Tht=s(DI);_mo=r(Tht,"DPRQuestionEncoderTokenizer"),Tht.forEach(t),umo=r(RS," or "),GI=n(RS,"A",{href:!0});var Mht=s(GI);bmo=r(Mht,"DPRQuestionEncoderTokenizerFast"),Mht.forEach(t),vmo=r(RS," (DPR model)"),RS.forEach(t),Fmo=i(S),is=n(S,"LI",{});var PS=s(is);nde=n(PS,"STRONG",{});var Eht=s(nde);Tmo=r(Eht,"electra"),Eht.forEach(t),Mmo=r(PS," \u2014 "),OI=n(PS,"A",{href:!0});var Cht=s(OI);Emo=r(Cht,"ElectraTokenizer"),Cht.forEach(t),Cmo=r(PS," or "),VI=n(PS,"A",{href:!0});var wht=s(VI);wmo=r(wht,"ElectraTokenizerFast"),wht.forEach(t),Amo=r(PS," (ELECTRA model)"),PS.forEach(t),Lmo=i(S),Eh=n(S,"LI",{});var Xxe=s(Eh);sde=n(Xxe,"STRONG",{});var Aht=s(sde);ymo=r(Aht,"flaubert"),Aht.forEach(t),xmo=r(Xxe," \u2014 "),XI=n(Xxe,"A",{href:!0});var Lht=s(XI);$mo=r(Lht,"FlaubertTokenizer"),Lht.forEach(t),kmo=r(Xxe," (FlauBERT model)"),Xxe.forEach(t),Smo=i(S),ds=n(S,"LI",{});var BS=s(ds);lde=n(BS,"STRONG",{});var yht=s(lde);Rmo=r(yht,"fnet"),yht.forEach(t),Pmo=r(BS," \u2014 "),zI=n(BS,"A",{href:!0});var xht=s(zI);Bmo=r(xht,"FNetTokenizer"),xht.forEach(t),Imo=r(BS," or "),WI=n(BS,"A",{href:!0});var $ht=s(WI);Nmo=r($ht,"FNetTokenizerFast"),$ht.forEach(t),qmo=r(BS," (FNet model)"),BS.forEach(t),jmo=i(S),Ch=n(S,"LI",{});var zxe=s(Ch);ide=n(zxe,"STRONG",{});var kht=s(ide);Dmo=r(kht,"fsmt"),kht.forEach(t),Gmo=r(zxe," \u2014 "),QI=n(zxe,"A",{href:!0});var Sht=s(QI);Omo=r(Sht,"FSMTTokenizer"),Sht.forEach(t),Vmo=r(zxe," (FairSeq Machine-Translation model)"),zxe.forEach(t),Xmo=i(S),cs=n(S,"LI",{});var IS=s(cs);dde=n(IS,"STRONG",{});var Rht=s(dde);zmo=r(Rht,"funnel"),Rht.forEach(t),Wmo=r(IS," \u2014 "),HI=n(IS,"A",{href:!0});var Pht=s(HI);Qmo=r(Pht,"FunnelTokenizer"),Pht.forEach(t),Hmo=r(IS," or "),UI=n(IS,"A",{href:!0});var Bht=s(UI);Umo=r(Bht,"FunnelTokenizerFast"),Bht.forEach(t),Jmo=r(IS," (Funnel Transformer model)"),IS.forEach(t),Ymo=i(S),fs=n(S,"LI",{});var NS=s(fs);cde=n(NS,"STRONG",{});var Iht=s(cde);Kmo=r(Iht,"gpt2"),Iht.forEach(t),Zmo=r(NS," \u2014 "),JI=n(NS,"A",{href:!0});var Nht=s(JI);ego=r(Nht,"GPT2Tokenizer"),Nht.forEach(t),ogo=r(NS," or "),YI=n(NS,"A",{href:!0});var qht=s(YI);rgo=r(qht,"GPT2TokenizerFast"),qht.forEach(t),tgo=r(NS," (OpenAI GPT-2 model)"),NS.forEach(t),ago=i(S),ms=n(S,"LI",{});var qS=s(ms);fde=n(qS,"STRONG",{});var jht=s(fde);ngo=r(jht,"gpt_neo"),jht.forEach(t),sgo=r(qS," \u2014 "),KI=n(qS,"A",{href:!0});var Dht=s(KI);lgo=r(Dht,"GPT2Tokenizer"),Dht.forEach(t),igo=r(qS," or "),ZI=n(qS,"A",{href:!0});var Ght=s(ZI);dgo=r(Ght,"GPT2TokenizerFast"),Ght.forEach(t),cgo=r(qS," (GPT Neo model)"),qS.forEach(t),fgo=i(S),wh=n(S,"LI",{});var Wxe=s(wh);mde=n(Wxe,"STRONG",{});var Oht=s(mde);mgo=r(Oht,"gpt_neox"),Oht.forEach(t),ggo=r(Wxe," \u2014 "),eN=n(Wxe,"A",{href:!0});var Vht=s(eN);hgo=r(Vht,"GPTNeoXTokenizerFast"),Vht.forEach(t),pgo=r(Wxe," (GPT NeoX model)"),Wxe.forEach(t),_go=i(S),gs=n(S,"LI",{});var jS=s(gs);gde=n(jS,"STRONG",{});var Xht=s(gde);ugo=r(Xht,"gptj"),Xht.forEach(t),bgo=r(jS," \u2014 "),oN=n(jS,"A",{href:!0});var zht=s(oN);vgo=r(zht,"GPT2Tokenizer"),zht.forEach(t),Fgo=r(jS," or "),rN=n(jS,"A",{href:!0});var Wht=s(rN);Tgo=r(Wht,"GPT2TokenizerFast"),Wht.forEach(t),Mgo=r(jS," (GPT-J model)"),jS.forEach(t),Ego=i(S),hs=n(S,"LI",{});var DS=s(hs);hde=n(DS,"STRONG",{});var Qht=s(hde);Cgo=r(Qht,"groupvit"),Qht.forEach(t),wgo=r(DS," \u2014 "),tN=n(DS,"A",{href:!0});var Hht=s(tN);Ago=r(Hht,"CLIPTokenizer"),Hht.forEach(t),Lgo=r(DS," or "),aN=n(DS,"A",{href:!0});var Uht=s(aN);ygo=r(Uht,"CLIPTokenizerFast"),Uht.forEach(t),xgo=r(DS," (GroupViT model)"),DS.forEach(t),$go=i(S),ps=n(S,"LI",{});var GS=s(ps);pde=n(GS,"STRONG",{});var Jht=s(pde);kgo=r(Jht,"herbert"),Jht.forEach(t),Sgo=r(GS," \u2014 "),nN=n(GS,"A",{href:!0});var Yht=s(nN);Rgo=r(Yht,"HerbertTokenizer"),Yht.forEach(t),Pgo=r(GS," or "),sN=n(GS,"A",{href:!0});var Kht=s(sN);Bgo=r(Kht,"HerbertTokenizerFast"),Kht.forEach(t),Igo=r(GS," (HerBERT model)"),GS.forEach(t),Ngo=i(S),Ah=n(S,"LI",{});var Qxe=s(Ah);_de=n(Qxe,"STRONG",{});var Zht=s(_de);qgo=r(Zht,"hubert"),Zht.forEach(t),jgo=r(Qxe," \u2014 "),lN=n(Qxe,"A",{href:!0});var ept=s(lN);Dgo=r(ept,"Wav2Vec2CTCTokenizer"),ept.forEach(t),Ggo=r(Qxe," (Hubert model)"),Qxe.forEach(t),Ogo=i(S),_s=n(S,"LI",{});var OS=s(_s);ude=n(OS,"STRONG",{});var opt=s(ude);Vgo=r(opt,"ibert"),opt.forEach(t),Xgo=r(OS," \u2014 "),iN=n(OS,"A",{href:!0});var rpt=s(iN);zgo=r(rpt,"RobertaTokenizer"),rpt.forEach(t),Wgo=r(OS," or "),dN=n(OS,"A",{href:!0});var tpt=s(dN);Qgo=r(tpt,"RobertaTokenizerFast"),tpt.forEach(t),Hgo=r(OS," (I-BERT model)"),OS.forEach(t),Ugo=i(S),us=n(S,"LI",{});var VS=s(us);bde=n(VS,"STRONG",{});var apt=s(bde);Jgo=r(apt,"layoutlm"),apt.forEach(t),Ygo=r(VS," \u2014 "),cN=n(VS,"A",{href:!0});var npt=s(cN);Kgo=r(npt,"LayoutLMTokenizer"),npt.forEach(t),Zgo=r(VS," or "),fN=n(VS,"A",{href:!0});var spt=s(fN);eho=r(spt,"LayoutLMTokenizerFast"),spt.forEach(t),oho=r(VS," (LayoutLM model)"),VS.forEach(t),rho=i(S),bs=n(S,"LI",{});var XS=s(bs);vde=n(XS,"STRONG",{});var lpt=s(vde);tho=r(lpt,"layoutlmv2"),lpt.forEach(t),aho=r(XS," \u2014 "),mN=n(XS,"A",{href:!0});var ipt=s(mN);nho=r(ipt,"LayoutLMv2Tokenizer"),ipt.forEach(t),sho=r(XS," or "),gN=n(XS,"A",{href:!0});var dpt=s(gN);lho=r(dpt,"LayoutLMv2TokenizerFast"),dpt.forEach(t),iho=r(XS," (LayoutLMv2 model)"),XS.forEach(t),dho=i(S),vs=n(S,"LI",{});var zS=s(vs);Fde=n(zS,"STRONG",{});var cpt=s(Fde);cho=r(cpt,"layoutlmv3"),cpt.forEach(t),fho=r(zS," \u2014 "),hN=n(zS,"A",{href:!0});var fpt=s(hN);mho=r(fpt,"LayoutLMv3Tokenizer"),fpt.forEach(t),gho=r(zS," or "),pN=n(zS,"A",{href:!0});var mpt=s(pN);hho=r(mpt,"LayoutLMv3TokenizerFast"),mpt.forEach(t),pho=r(zS," (LayoutLMv3 model)"),zS.forEach(t),_ho=i(S),Fs=n(S,"LI",{});var WS=s(Fs);Tde=n(WS,"STRONG",{});var gpt=s(Tde);uho=r(gpt,"layoutxlm"),gpt.forEach(t),bho=r(WS," \u2014 "),_N=n(WS,"A",{href:!0});var hpt=s(_N);vho=r(hpt,"LayoutXLMTokenizer"),hpt.forEach(t),Fho=r(WS," or "),uN=n(WS,"A",{href:!0});var ppt=s(uN);Tho=r(ppt,"LayoutXLMTokenizerFast"),ppt.forEach(t),Mho=r(WS," (LayoutXLM model)"),WS.forEach(t),Eho=i(S),Ts=n(S,"LI",{});var QS=s(Ts);Mde=n(QS,"STRONG",{});var _pt=s(Mde);Cho=r(_pt,"led"),_pt.forEach(t),who=r(QS," \u2014 "),bN=n(QS,"A",{href:!0});var upt=s(bN);Aho=r(upt,"LEDTokenizer"),upt.forEach(t),Lho=r(QS," or "),vN=n(QS,"A",{href:!0});var bpt=s(vN);yho=r(bpt,"LEDTokenizerFast"),bpt.forEach(t),xho=r(QS," (LED model)"),QS.forEach(t),$ho=i(S),Ms=n(S,"LI",{});var HS=s(Ms);Ede=n(HS,"STRONG",{});var vpt=s(Ede);kho=r(vpt,"longformer"),vpt.forEach(t),Sho=r(HS," \u2014 "),FN=n(HS,"A",{href:!0});var Fpt=s(FN);Rho=r(Fpt,"LongformerTokenizer"),Fpt.forEach(t),Pho=r(HS," or "),TN=n(HS,"A",{href:!0});var Tpt=s(TN);Bho=r(Tpt,"LongformerTokenizerFast"),Tpt.forEach(t),Iho=r(HS," (Longformer model)"),HS.forEach(t),Nho=i(S),Es=n(S,"LI",{});var US=s(Es);Cde=n(US,"STRONG",{});var Mpt=s(Cde);qho=r(Mpt,"longt5"),Mpt.forEach(t),jho=r(US," \u2014 "),MN=n(US,"A",{href:!0});var Ept=s(MN);Dho=r(Ept,"T5Tokenizer"),Ept.forEach(t),Gho=r(US," or "),EN=n(US,"A",{href:!0});var Cpt=s(EN);Oho=r(Cpt,"T5TokenizerFast"),Cpt.forEach(t),Vho=r(US," (LongT5 model)"),US.forEach(t),Xho=i(S),Lh=n(S,"LI",{});var Hxe=s(Lh);wde=n(Hxe,"STRONG",{});var wpt=s(wde);zho=r(wpt,"luke"),wpt.forEach(t),Who=r(Hxe," \u2014 "),CN=n(Hxe,"A",{href:!0});var Apt=s(CN);Qho=r(Apt,"LukeTokenizer"),Apt.forEach(t),Hho=r(Hxe," (LUKE model)"),Hxe.forEach(t),Uho=i(S),Cs=n(S,"LI",{});var JS=s(Cs);Ade=n(JS,"STRONG",{});var Lpt=s(Ade);Jho=r(Lpt,"lxmert"),Lpt.forEach(t),Yho=r(JS," \u2014 "),wN=n(JS,"A",{href:!0});var ypt=s(wN);Kho=r(ypt,"LxmertTokenizer"),ypt.forEach(t),Zho=r(JS," or "),AN=n(JS,"A",{href:!0});var xpt=s(AN);epo=r(xpt,"LxmertTokenizerFast"),xpt.forEach(t),opo=r(JS," (LXMERT model)"),JS.forEach(t),rpo=i(S),yh=n(S,"LI",{});var Uxe=s(yh);Lde=n(Uxe,"STRONG",{});var $pt=s(Lde);tpo=r($pt,"m2m_100"),$pt.forEach(t),apo=r(Uxe," \u2014 "),LN=n(Uxe,"A",{href:!0});var kpt=s(LN);npo=r(kpt,"M2M100Tokenizer"),kpt.forEach(t),spo=r(Uxe," (M2M100 model)"),Uxe.forEach(t),lpo=i(S),xh=n(S,"LI",{});var Jxe=s(xh);yde=n(Jxe,"STRONG",{});var Spt=s(yde);ipo=r(Spt,"marian"),Spt.forEach(t),dpo=r(Jxe," \u2014 "),yN=n(Jxe,"A",{href:!0});var Rpt=s(yN);cpo=r(Rpt,"MarianTokenizer"),Rpt.forEach(t),fpo=r(Jxe," (Marian model)"),Jxe.forEach(t),mpo=i(S),ws=n(S,"LI",{});var YS=s(ws);xde=n(YS,"STRONG",{});var Ppt=s(xde);gpo=r(Ppt,"mbart"),Ppt.forEach(t),hpo=r(YS," \u2014 "),xN=n(YS,"A",{href:!0});var Bpt=s(xN);ppo=r(Bpt,"MBartTokenizer"),Bpt.forEach(t),_po=r(YS," or "),$N=n(YS,"A",{href:!0});var Ipt=s($N);upo=r(Ipt,"MBartTokenizerFast"),Ipt.forEach(t),bpo=r(YS," (mBART model)"),YS.forEach(t),vpo=i(S),As=n(S,"LI",{});var KS=s(As);$de=n(KS,"STRONG",{});var Npt=s($de);Fpo=r(Npt,"mbart50"),Npt.forEach(t),Tpo=r(KS," \u2014 "),kN=n(KS,"A",{href:!0});var qpt=s(kN);Mpo=r(qpt,"MBart50Tokenizer"),qpt.forEach(t),Epo=r(KS," or "),SN=n(KS,"A",{href:!0});var jpt=s(SN);Cpo=r(jpt,"MBart50TokenizerFast"),jpt.forEach(t),wpo=r(KS," (mBART-50 model)"),KS.forEach(t),Apo=i(S),Ls=n(S,"LI",{});var ZS=s(Ls);kde=n(ZS,"STRONG",{});var Dpt=s(kde);Lpo=r(Dpt,"megatron-bert"),Dpt.forEach(t),ypo=r(ZS," \u2014 "),RN=n(ZS,"A",{href:!0});var Gpt=s(RN);xpo=r(Gpt,"BertTokenizer"),Gpt.forEach(t),$po=r(ZS," or "),PN=n(ZS,"A",{href:!0});var Opt=s(PN);kpo=r(Opt,"BertTokenizerFast"),Opt.forEach(t),Spo=r(ZS," (Megatron-BERT model)"),ZS.forEach(t),Rpo=i(S),$h=n(S,"LI",{});var Yxe=s($h);Sde=n(Yxe,"STRONG",{});var Vpt=s(Sde);Ppo=r(Vpt,"mluke"),Vpt.forEach(t),Bpo=r(Yxe," \u2014 "),BN=n(Yxe,"A",{href:!0});var Xpt=s(BN);Ipo=r(Xpt,"MLukeTokenizer"),Xpt.forEach(t),Npo=r(Yxe," (mLUKE model)"),Yxe.forEach(t),qpo=i(S),ys=n(S,"LI",{});var eR=s(ys);Rde=n(eR,"STRONG",{});var zpt=s(Rde);jpo=r(zpt,"mobilebert"),zpt.forEach(t),Dpo=r(eR," \u2014 "),IN=n(eR,"A",{href:!0});var Wpt=s(IN);Gpo=r(Wpt,"MobileBertTokenizer"),Wpt.forEach(t),Opo=r(eR," or "),NN=n(eR,"A",{href:!0});var Qpt=s(NN);Vpo=r(Qpt,"MobileBertTokenizerFast"),Qpt.forEach(t),Xpo=r(eR," (MobileBERT model)"),eR.forEach(t),zpo=i(S),xs=n(S,"LI",{});var oR=s(xs);Pde=n(oR,"STRONG",{});var Hpt=s(Pde);Wpo=r(Hpt,"mpnet"),Hpt.forEach(t),Qpo=r(oR," \u2014 "),qN=n(oR,"A",{href:!0});var Upt=s(qN);Hpo=r(Upt,"MPNetTokenizer"),Upt.forEach(t),Upo=r(oR," or "),jN=n(oR,"A",{href:!0});var Jpt=s(jN);Jpo=r(Jpt,"MPNetTokenizerFast"),Jpt.forEach(t),Ypo=r(oR," (MPNet model)"),oR.forEach(t),Kpo=i(S),$s=n(S,"LI",{});var rR=s($s);Bde=n(rR,"STRONG",{});var Ypt=s(Bde);Zpo=r(Ypt,"mt5"),Ypt.forEach(t),e_o=r(rR," \u2014 "),DN=n(rR,"A",{href:!0});var Kpt=s(DN);o_o=r(Kpt,"MT5Tokenizer"),Kpt.forEach(t),r_o=r(rR," or "),GN=n(rR,"A",{href:!0});var Zpt=s(GN);t_o=r(Zpt,"MT5TokenizerFast"),Zpt.forEach(t),a_o=r(rR," (MT5 model)"),rR.forEach(t),n_o=i(S),ks=n(S,"LI",{});var tR=s(ks);Ide=n(tR,"STRONG",{});var e_t=s(Ide);s_o=r(e_t,"mvp"),e_t.forEach(t),l_o=r(tR," \u2014 "),ON=n(tR,"A",{href:!0});var o_t=s(ON);i_o=r(o_t,"MvpTokenizer"),o_t.forEach(t),d_o=r(tR," or "),VN=n(tR,"A",{href:!0});var r_t=s(VN);c_o=r(r_t,"MvpTokenizerFast"),r_t.forEach(t),f_o=r(tR," (MVP model)"),tR.forEach(t),m_o=i(S),Ss=n(S,"LI",{});var aR=s(Ss);Nde=n(aR,"STRONG",{});var t_t=s(Nde);g_o=r(t_t,"nezha"),t_t.forEach(t),h_o=r(aR," \u2014 "),XN=n(aR,"A",{href:!0});var a_t=s(XN);p_o=r(a_t,"BertTokenizer"),a_t.forEach(t),__o=r(aR," or "),zN=n(aR,"A",{href:!0});var n_t=s(zN);u_o=r(n_t,"BertTokenizerFast"),n_t.forEach(t),b_o=r(aR," (Nezha model)"),aR.forEach(t),v_o=i(S),Rs=n(S,"LI",{});var nR=s(Rs);qde=n(nR,"STRONG",{});var s_t=s(qde);F_o=r(s_t,"nllb"),s_t.forEach(t),T_o=r(nR," \u2014 "),WN=n(nR,"A",{href:!0});var l_t=s(WN);M_o=r(l_t,"NllbTokenizer"),l_t.forEach(t),E_o=r(nR," or "),QN=n(nR,"A",{href:!0});var i_t=s(QN);C_o=r(i_t,"NllbTokenizerFast"),i_t.forEach(t),w_o=r(nR," (NLLB model)"),nR.forEach(t),A_o=i(S),Ps=n(S,"LI",{});var sR=s(Ps);jde=n(sR,"STRONG",{});var d_t=s(jde);L_o=r(d_t,"nystromformer"),d_t.forEach(t),y_o=r(sR," \u2014 "),HN=n(sR,"A",{href:!0});var c_t=s(HN);x_o=r(c_t,"AlbertTokenizer"),c_t.forEach(t),$_o=r(sR," or "),UN=n(sR,"A",{href:!0});var f_t=s(UN);k_o=r(f_t,"AlbertTokenizerFast"),f_t.forEach(t),S_o=r(sR," (Nystr\xF6mformer model)"),sR.forEach(t),R_o=i(S),Bs=n(S,"LI",{});var lR=s(Bs);Dde=n(lR,"STRONG",{});var m_t=s(Dde);P_o=r(m_t,"openai-gpt"),m_t.forEach(t),B_o=r(lR," \u2014 "),JN=n(lR,"A",{href:!0});var g_t=s(JN);I_o=r(g_t,"OpenAIGPTTokenizer"),g_t.forEach(t),N_o=r(lR," or "),YN=n(lR,"A",{href:!0});var h_t=s(YN);q_o=r(h_t,"OpenAIGPTTokenizerFast"),h_t.forEach(t),j_o=r(lR," (OpenAI GPT model)"),lR.forEach(t),D_o=i(S),kh=n(S,"LI",{});var Kxe=s(kh);Gde=n(Kxe,"STRONG",{});var p_t=s(Gde);G_o=r(p_t,"opt"),p_t.forEach(t),O_o=r(Kxe," \u2014 "),KN=n(Kxe,"A",{href:!0});var __t=s(KN);V_o=r(__t,"GPT2Tokenizer"),__t.forEach(t),X_o=r(Kxe," (OPT model)"),Kxe.forEach(t),z_o=i(S),Is=n(S,"LI",{});var iR=s(Is);Ode=n(iR,"STRONG",{});var u_t=s(Ode);W_o=r(u_t,"owlvit"),u_t.forEach(t),Q_o=r(iR," \u2014 "),ZN=n(iR,"A",{href:!0});var b_t=s(ZN);H_o=r(b_t,"CLIPTokenizer"),b_t.forEach(t),U_o=r(iR," or "),eq=n(iR,"A",{href:!0});var v_t=s(eq);J_o=r(v_t,"CLIPTokenizerFast"),v_t.forEach(t),Y_o=r(iR," (OWL-ViT model)"),iR.forEach(t),K_o=i(S),Ns=n(S,"LI",{});var dR=s(Ns);Vde=n(dR,"STRONG",{});var F_t=s(Vde);Z_o=r(F_t,"pegasus"),F_t.forEach(t),euo=r(dR," \u2014 "),oq=n(dR,"A",{href:!0});var T_t=s(oq);ouo=r(T_t,"PegasusTokenizer"),T_t.forEach(t),ruo=r(dR," or "),rq=n(dR,"A",{href:!0});var M_t=s(rq);tuo=r(M_t,"PegasusTokenizerFast"),M_t.forEach(t),auo=r(dR," (Pegasus model)"),dR.forEach(t),nuo=i(S),Sh=n(S,"LI",{});var Zxe=s(Sh);Xde=n(Zxe,"STRONG",{});var E_t=s(Xde);suo=r(E_t,"perceiver"),E_t.forEach(t),luo=r(Zxe," \u2014 "),tq=n(Zxe,"A",{href:!0});var C_t=s(tq);iuo=r(C_t,"PerceiverTokenizer"),C_t.forEach(t),duo=r(Zxe," (Perceiver model)"),Zxe.forEach(t),cuo=i(S),Rh=n(S,"LI",{});var e$e=s(Rh);zde=n(e$e,"STRONG",{});var w_t=s(zde);fuo=r(w_t,"phobert"),w_t.forEach(t),muo=r(e$e," \u2014 "),aq=n(e$e,"A",{href:!0});var A_t=s(aq);guo=r(A_t,"PhobertTokenizer"),A_t.forEach(t),huo=r(e$e," (PhoBERT model)"),e$e.forEach(t),puo=i(S),Ph=n(S,"LI",{});var o$e=s(Ph);Wde=n(o$e,"STRONG",{});var L_t=s(Wde);_uo=r(L_t,"plbart"),L_t.forEach(t),uuo=r(o$e," \u2014 "),nq=n(o$e,"A",{href:!0});var y_t=s(nq);buo=r(y_t,"PLBartTokenizer"),y_t.forEach(t),vuo=r(o$e," (PLBart model)"),o$e.forEach(t),Fuo=i(S),Bh=n(S,"LI",{});var r$e=s(Bh);Qde=n(r$e,"STRONG",{});var x_t=s(Qde);Tuo=r(x_t,"prophetnet"),x_t.forEach(t),Muo=r(r$e," \u2014 "),sq=n(r$e,"A",{href:!0});var $_t=s(sq);Euo=r($_t,"ProphetNetTokenizer"),$_t.forEach(t),Cuo=r(r$e," (ProphetNet model)"),r$e.forEach(t),wuo=i(S),qs=n(S,"LI",{});var cR=s(qs);Hde=n(cR,"STRONG",{});var k_t=s(Hde);Auo=r(k_t,"qdqbert"),k_t.forEach(t),Luo=r(cR," \u2014 "),lq=n(cR,"A",{href:!0});var S_t=s(lq);yuo=r(S_t,"BertTokenizer"),S_t.forEach(t),xuo=r(cR," or "),iq=n(cR,"A",{href:!0});var R_t=s(iq);$uo=r(R_t,"BertTokenizerFast"),R_t.forEach(t),kuo=r(cR," (QDQBert model)"),cR.forEach(t),Suo=i(S),Ih=n(S,"LI",{});var t$e=s(Ih);Ude=n(t$e,"STRONG",{});var P_t=s(Ude);Ruo=r(P_t,"rag"),P_t.forEach(t),Puo=r(t$e," \u2014 "),dq=n(t$e,"A",{href:!0});var B_t=s(dq);Buo=r(B_t,"RagTokenizer"),B_t.forEach(t),Iuo=r(t$e," (RAG model)"),t$e.forEach(t),Nuo=i(S),js=n(S,"LI",{});var fR=s(js);Jde=n(fR,"STRONG",{});var I_t=s(Jde);quo=r(I_t,"realm"),I_t.forEach(t),juo=r(fR," \u2014 "),cq=n(fR,"A",{href:!0});var N_t=s(cq);Duo=r(N_t,"RealmTokenizer"),N_t.forEach(t),Guo=r(fR," or "),fq=n(fR,"A",{href:!0});var q_t=s(fq);Ouo=r(q_t,"RealmTokenizerFast"),q_t.forEach(t),Vuo=r(fR," (REALM model)"),fR.forEach(t),Xuo=i(S),Ds=n(S,"LI",{});var mR=s(Ds);Yde=n(mR,"STRONG",{});var j_t=s(Yde);zuo=r(j_t,"reformer"),j_t.forEach(t),Wuo=r(mR," \u2014 "),mq=n(mR,"A",{href:!0});var D_t=s(mq);Quo=r(D_t,"ReformerTokenizer"),D_t.forEach(t),Huo=r(mR," or "),gq=n(mR,"A",{href:!0});var G_t=s(gq);Uuo=r(G_t,"ReformerTokenizerFast"),G_t.forEach(t),Juo=r(mR," (Reformer model)"),mR.forEach(t),Yuo=i(S),Gs=n(S,"LI",{});var gR=s(Gs);Kde=n(gR,"STRONG",{});var O_t=s(Kde);Kuo=r(O_t,"rembert"),O_t.forEach(t),Zuo=r(gR," \u2014 "),hq=n(gR,"A",{href:!0});var V_t=s(hq);e2o=r(V_t,"RemBertTokenizer"),V_t.forEach(t),o2o=r(gR," or "),pq=n(gR,"A",{href:!0});var X_t=s(pq);r2o=r(X_t,"RemBertTokenizerFast"),X_t.forEach(t),t2o=r(gR," (RemBERT model)"),gR.forEach(t),a2o=i(S),Os=n(S,"LI",{});var hR=s(Os);Zde=n(hR,"STRONG",{});var z_t=s(Zde);n2o=r(z_t,"retribert"),z_t.forEach(t),s2o=r(hR," \u2014 "),_q=n(hR,"A",{href:!0});var W_t=s(_q);l2o=r(W_t,"RetriBertTokenizer"),W_t.forEach(t),i2o=r(hR," or "),uq=n(hR,"A",{href:!0});var Q_t=s(uq);d2o=r(Q_t,"RetriBertTokenizerFast"),Q_t.forEach(t),c2o=r(hR," (RetriBERT model)"),hR.forEach(t),f2o=i(S),Vs=n(S,"LI",{});var pR=s(Vs);ece=n(pR,"STRONG",{});var H_t=s(ece);m2o=r(H_t,"roberta"),H_t.forEach(t),g2o=r(pR," \u2014 "),bq=n(pR,"A",{href:!0});var U_t=s(bq);h2o=r(U_t,"RobertaTokenizer"),U_t.forEach(t),p2o=r(pR," or "),vq=n(pR,"A",{href:!0});var J_t=s(vq);_2o=r(J_t,"RobertaTokenizerFast"),J_t.forEach(t),u2o=r(pR," (RoBERTa model)"),pR.forEach(t),b2o=i(S),Xs=n(S,"LI",{});var _R=s(Xs);oce=n(_R,"STRONG",{});var Y_t=s(oce);v2o=r(Y_t,"roformer"),Y_t.forEach(t),F2o=r(_R," \u2014 "),Fq=n(_R,"A",{href:!0});var K_t=s(Fq);T2o=r(K_t,"RoFormerTokenizer"),K_t.forEach(t),M2o=r(_R," or "),Tq=n(_R,"A",{href:!0});var Z_t=s(Tq);E2o=r(Z_t,"RoFormerTokenizerFast"),Z_t.forEach(t),C2o=r(_R," (RoFormer model)"),_R.forEach(t),w2o=i(S),Nh=n(S,"LI",{});var a$e=s(Nh);rce=n(a$e,"STRONG",{});var eut=s(rce);A2o=r(eut,"speech_to_text"),eut.forEach(t),L2o=r(a$e," \u2014 "),Mq=n(a$e,"A",{href:!0});var out=s(Mq);y2o=r(out,"Speech2TextTokenizer"),out.forEach(t),x2o=r(a$e," (Speech2Text model)"),a$e.forEach(t),$2o=i(S),qh=n(S,"LI",{});var n$e=s(qh);tce=n(n$e,"STRONG",{});var rut=s(tce);k2o=r(rut,"speech_to_text_2"),rut.forEach(t),S2o=r(n$e," \u2014 "),Eq=n(n$e,"A",{href:!0});var tut=s(Eq);R2o=r(tut,"Speech2Text2Tokenizer"),tut.forEach(t),P2o=r(n$e," (Speech2Text2 model)"),n$e.forEach(t),B2o=i(S),zs=n(S,"LI",{});var uR=s(zs);ace=n(uR,"STRONG",{});var aut=s(ace);I2o=r(aut,"splinter"),aut.forEach(t),N2o=r(uR," \u2014 "),Cq=n(uR,"A",{href:!0});var nut=s(Cq);q2o=r(nut,"SplinterTokenizer"),nut.forEach(t),j2o=r(uR," or "),wq=n(uR,"A",{href:!0});var sut=s(wq);D2o=r(sut,"SplinterTokenizerFast"),sut.forEach(t),G2o=r(uR," (Splinter model)"),uR.forEach(t),O2o=i(S),Ws=n(S,"LI",{});var bR=s(Ws);nce=n(bR,"STRONG",{});var lut=s(nce);V2o=r(lut,"squeezebert"),lut.forEach(t),X2o=r(bR," \u2014 "),Aq=n(bR,"A",{href:!0});var iut=s(Aq);z2o=r(iut,"SqueezeBertTokenizer"),iut.forEach(t),W2o=r(bR," or "),Lq=n(bR,"A",{href:!0});var dut=s(Lq);Q2o=r(dut,"SqueezeBertTokenizerFast"),dut.forEach(t),H2o=r(bR," (SqueezeBERT model)"),bR.forEach(t),U2o=i(S),Qs=n(S,"LI",{});var vR=s(Qs);sce=n(vR,"STRONG",{});var cut=s(sce);J2o=r(cut,"t5"),cut.forEach(t),Y2o=r(vR," \u2014 "),yq=n(vR,"A",{href:!0});var fut=s(yq);K2o=r(fut,"T5Tokenizer"),fut.forEach(t),Z2o=r(vR," or "),xq=n(vR,"A",{href:!0});var mut=s(xq);e1o=r(mut,"T5TokenizerFast"),mut.forEach(t),o1o=r(vR," (T5 model)"),vR.forEach(t),r1o=i(S),jh=n(S,"LI",{});var s$e=s(jh);lce=n(s$e,"STRONG",{});var gut=s(lce);t1o=r(gut,"tapas"),gut.forEach(t),a1o=r(s$e," \u2014 "),$q=n(s$e,"A",{href:!0});var hut=s($q);n1o=r(hut,"TapasTokenizer"),hut.forEach(t),s1o=r(s$e," (TAPAS model)"),s$e.forEach(t),l1o=i(S),Dh=n(S,"LI",{});var l$e=s(Dh);ice=n(l$e,"STRONG",{});var put=s(ice);i1o=r(put,"tapex"),put.forEach(t),d1o=r(l$e," \u2014 "),kq=n(l$e,"A",{href:!0});var _ut=s(kq);c1o=r(_ut,"TapexTokenizer"),_ut.forEach(t),f1o=r(l$e," (TAPEX model)"),l$e.forEach(t),m1o=i(S),Gh=n(S,"LI",{});var i$e=s(Gh);dce=n(i$e,"STRONG",{});var uut=s(dce);g1o=r(uut,"transfo-xl"),uut.forEach(t),h1o=r(i$e," \u2014 "),Sq=n(i$e,"A",{href:!0});var but=s(Sq);p1o=r(but,"TransfoXLTokenizer"),but.forEach(t),_1o=r(i$e," (Transformer-XL model)"),i$e.forEach(t),u1o=i(S),Hs=n(S,"LI",{});var FR=s(Hs);cce=n(FR,"STRONG",{});var vut=s(cce);b1o=r(vut,"vilt"),vut.forEach(t),v1o=r(FR," \u2014 "),Rq=n(FR,"A",{href:!0});var Fut=s(Rq);F1o=r(Fut,"BertTokenizer"),Fut.forEach(t),T1o=r(FR," or "),Pq=n(FR,"A",{href:!0});var Tut=s(Pq);M1o=r(Tut,"BertTokenizerFast"),Tut.forEach(t),E1o=r(FR," (ViLT model)"),FR.forEach(t),C1o=i(S),Us=n(S,"LI",{});var TR=s(Us);fce=n(TR,"STRONG",{});var Mut=s(fce);w1o=r(Mut,"visual_bert"),Mut.forEach(t),A1o=r(TR," \u2014 "),Bq=n(TR,"A",{href:!0});var Eut=s(Bq);L1o=r(Eut,"BertTokenizer"),Eut.forEach(t),y1o=r(TR," or "),Iq=n(TR,"A",{href:!0});var Cut=s(Iq);x1o=r(Cut,"BertTokenizerFast"),Cut.forEach(t),$1o=r(TR," (VisualBERT model)"),TR.forEach(t),k1o=i(S),Oh=n(S,"LI",{});var d$e=s(Oh);mce=n(d$e,"STRONG",{});var wut=s(mce);S1o=r(wut,"wav2vec2"),wut.forEach(t),R1o=r(d$e," \u2014 "),Nq=n(d$e,"A",{href:!0});var Aut=s(Nq);P1o=r(Aut,"Wav2Vec2CTCTokenizer"),Aut.forEach(t),B1o=r(d$e," (Wav2Vec2 model)"),d$e.forEach(t),I1o=i(S),Vh=n(S,"LI",{});var c$e=s(Vh);gce=n(c$e,"STRONG",{});var Lut=s(gce);N1o=r(Lut,"wav2vec2-conformer"),Lut.forEach(t),q1o=r(c$e," \u2014 "),qq=n(c$e,"A",{href:!0});var yut=s(qq);j1o=r(yut,"Wav2Vec2CTCTokenizer"),yut.forEach(t),D1o=r(c$e," (Wav2Vec2-Conformer model)"),c$e.forEach(t),G1o=i(S),Xh=n(S,"LI",{});var f$e=s(Xh);hce=n(f$e,"STRONG",{});var xut=s(hce);O1o=r(xut,"wav2vec2_phoneme"),xut.forEach(t),V1o=r(f$e," \u2014 "),jq=n(f$e,"A",{href:!0});var $ut=s(jq);X1o=r($ut,"Wav2Vec2PhonemeCTCTokenizer"),$ut.forEach(t),z1o=r(f$e," (Wav2Vec2Phoneme model)"),f$e.forEach(t),W1o=i(S),Js=n(S,"LI",{});var MR=s(Js);pce=n(MR,"STRONG",{});var kut=s(pce);Q1o=r(kut,"xglm"),kut.forEach(t),H1o=r(MR," \u2014 "),Dq=n(MR,"A",{href:!0});var Sut=s(Dq);U1o=r(Sut,"XGLMTokenizer"),Sut.forEach(t),J1o=r(MR," or "),Gq=n(MR,"A",{href:!0});var Rut=s(Gq);Y1o=r(Rut,"XGLMTokenizerFast"),Rut.forEach(t),K1o=r(MR," (XGLM model)"),MR.forEach(t),Z1o=i(S),zh=n(S,"LI",{});var m$e=s(zh);_ce=n(m$e,"STRONG",{});var Put=s(_ce);ebo=r(Put,"xlm"),Put.forEach(t),obo=r(m$e," \u2014 "),Oq=n(m$e,"A",{href:!0});var But=s(Oq);rbo=r(But,"XLMTokenizer"),But.forEach(t),tbo=r(m$e," (XLM model)"),m$e.forEach(t),abo=i(S),Wh=n(S,"LI",{});var g$e=s(Wh);uce=n(g$e,"STRONG",{});var Iut=s(uce);nbo=r(Iut,"xlm-prophetnet"),Iut.forEach(t),sbo=r(g$e," \u2014 "),Vq=n(g$e,"A",{href:!0});var Nut=s(Vq);lbo=r(Nut,"XLMProphetNetTokenizer"),Nut.forEach(t),ibo=r(g$e," (XLM-ProphetNet model)"),g$e.forEach(t),dbo=i(S),Ys=n(S,"LI",{});var ER=s(Ys);bce=n(ER,"STRONG",{});var qut=s(bce);cbo=r(qut,"xlm-roberta"),qut.forEach(t),fbo=r(ER," \u2014 "),Xq=n(ER,"A",{href:!0});var jut=s(Xq);mbo=r(jut,"XLMRobertaTokenizer"),jut.forEach(t),gbo=r(ER," or "),zq=n(ER,"A",{href:!0});var Dut=s(zq);hbo=r(Dut,"XLMRobertaTokenizerFast"),Dut.forEach(t),pbo=r(ER," (XLM-RoBERTa model)"),ER.forEach(t),_bo=i(S),Ks=n(S,"LI",{});var CR=s(Ks);vce=n(CR,"STRONG",{});var Gut=s(vce);ubo=r(Gut,"xlm-roberta-xl"),Gut.forEach(t),bbo=r(CR," \u2014 "),Wq=n(CR,"A",{href:!0});var Out=s(Wq);vbo=r(Out,"RobertaTokenizer"),Out.forEach(t),Fbo=r(CR," or "),Qq=n(CR,"A",{href:!0});var Vut=s(Qq);Tbo=r(Vut,"RobertaTokenizerFast"),Vut.forEach(t),Mbo=r(CR," (XLM-RoBERTa-XL model)"),CR.forEach(t),Ebo=i(S),Zs=n(S,"LI",{});var wR=s(Zs);Fce=n(wR,"STRONG",{});var Xut=s(Fce);Cbo=r(Xut,"xlnet"),Xut.forEach(t),wbo=r(wR," \u2014 "),Hq=n(wR,"A",{href:!0});var zut=s(Hq);Abo=r(zut,"XLNetTokenizer"),zut.forEach(t),Lbo=r(wR," or "),Uq=n(wR,"A",{href:!0});var Wut=s(Uq);ybo=r(Wut,"XLNetTokenizerFast"),Wut.forEach(t),xbo=r(wR," (XLNet model)"),wR.forEach(t),$bo=i(S),el=n(S,"LI",{});var AR=s(el);Tce=n(AR,"STRONG",{});var Qut=s(Tce);kbo=r(Qut,"yoso"),Qut.forEach(t),Sbo=r(AR," \u2014 "),Jq=n(AR,"A",{href:!0});var Hut=s(Jq);Rbo=r(Hut,"AlbertTokenizer"),Hut.forEach(t),Pbo=r(AR," or "),Yq=n(AR,"A",{href:!0});var Uut=s(Yq);Bbo=r(Uut,"AlbertTokenizerFast"),Uut.forEach(t),Ibo=r(AR," (YOSO model)"),AR.forEach(t),S.forEach(t),Nbo=i(ll),T(Qh.$$.fragment,ll),ll.forEach(t),qbo=i(sl),Hh=n(sl,"DIV",{class:!0});var oUe=s(Hh);T(ly.$$.fragment,oUe),jbo=i(oUe),Mce=n(oUe,"P",{});var Jut=s(Mce);Dbo=r(Jut,"Register a new tokenizer in this mapping."),Jut.forEach(t),oUe.forEach(t),sl.forEach(t),KWe=i(f),Qi=n(f,"H2",{class:!0});var rUe=s(Qi);Uh=n(rUe,"A",{id:!0,class:!0,href:!0});var Yut=s(Uh);Ece=n(Yut,"SPAN",{});var Kut=s(Ece);T(iy.$$.fragment,Kut),Kut.forEach(t),Yut.forEach(t),Gbo=i(rUe),Cce=n(rUe,"SPAN",{});var Zut=s(Cce);Obo=r(Zut,"AutoFeatureExtractor"),Zut.forEach(t),rUe.forEach(t),ZWe=i(f),$o=n(f,"DIV",{class:!0});var il=s($o);T(dy.$$.fragment,il),Vbo=i(il),cy=n(il,"P",{});var tUe=s(cy);Xbo=r(tUe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),Kq=n(tUe,"A",{href:!0});var e2t=s(Kq);zbo=r(e2t,"AutoFeatureExtractor.from_pretrained()"),e2t.forEach(t),Wbo=r(tUe," class method."),tUe.forEach(t),Qbo=i(il),fy=n(il,"P",{});var aUe=s(fy);Hbo=r(aUe,"This class cannot be instantiated directly using "),wce=n(aUe,"CODE",{});var o2t=s(wce);Ubo=r(o2t,"__init__()"),o2t.forEach(t),Jbo=r(aUe," (throws an error)."),aUe.forEach(t),Ybo=i(il),Ue=n(il,"DIV",{class:!0});var ia=s(Ue);T(my.$$.fragment,ia),Kbo=i(ia),Ace=n(ia,"P",{});var r2t=s(Ace);Zbo=r(r2t,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),r2t.forEach(t),evo=i(ia),ja=n(ia,"P",{});var HA=s(ja);ovo=r(HA,"The feature extractor class to instantiate is selected based on the "),Lce=n(HA,"CODE",{});var t2t=s(Lce);rvo=r(t2t,"model_type"),t2t.forEach(t),tvo=r(HA,` property of the config object
(either passed as an argument or loaded from `),yce=n(HA,"CODE",{});var a2t=s(yce);avo=r(a2t,"pretrained_model_name_or_path"),a2t.forEach(t),nvo=r(HA,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),xce=n(HA,"CODE",{});var n2t=s(xce);svo=r(n2t,"pretrained_model_name_or_path"),n2t.forEach(t),lvo=r(HA,":"),HA.forEach(t),ivo=i(ia),H=n(ia,"UL",{});var Y=s(H);Jh=n(Y,"LI",{});var h$e=s(Jh);$ce=n(h$e,"STRONG",{});var s2t=s($ce);dvo=r(s2t,"beit"),s2t.forEach(t),cvo=r(h$e," \u2014 "),Zq=n(h$e,"A",{href:!0});var l2t=s(Zq);fvo=r(l2t,"BeitFeatureExtractor"),l2t.forEach(t),mvo=r(h$e," (BEiT model)"),h$e.forEach(t),gvo=i(Y),Yh=n(Y,"LI",{});var p$e=s(Yh);kce=n(p$e,"STRONG",{});var i2t=s(kce);hvo=r(i2t,"clip"),i2t.forEach(t),pvo=r(p$e," \u2014 "),ej=n(p$e,"A",{href:!0});var d2t=s(ej);_vo=r(d2t,"CLIPFeatureExtractor"),d2t.forEach(t),uvo=r(p$e," (CLIP model)"),p$e.forEach(t),bvo=i(Y),Kh=n(Y,"LI",{});var _$e=s(Kh);Sce=n(_$e,"STRONG",{});var c2t=s(Sce);vvo=r(c2t,"convnext"),c2t.forEach(t),Fvo=r(_$e," \u2014 "),oj=n(_$e,"A",{href:!0});var f2t=s(oj);Tvo=r(f2t,"ConvNextFeatureExtractor"),f2t.forEach(t),Mvo=r(_$e," (ConvNeXT model)"),_$e.forEach(t),Evo=i(Y),Zh=n(Y,"LI",{});var u$e=s(Zh);Rce=n(u$e,"STRONG",{});var m2t=s(Rce);Cvo=r(m2t,"cvt"),m2t.forEach(t),wvo=r(u$e," \u2014 "),rj=n(u$e,"A",{href:!0});var g2t=s(rj);Avo=r(g2t,"ConvNextFeatureExtractor"),g2t.forEach(t),Lvo=r(u$e," (CvT model)"),u$e.forEach(t),yvo=i(Y),ep=n(Y,"LI",{});var b$e=s(ep);Pce=n(b$e,"STRONG",{});var h2t=s(Pce);xvo=r(h2t,"data2vec-audio"),h2t.forEach(t),$vo=r(b$e," \u2014 "),tj=n(b$e,"A",{href:!0});var p2t=s(tj);kvo=r(p2t,"Wav2Vec2FeatureExtractor"),p2t.forEach(t),Svo=r(b$e," (Data2VecAudio model)"),b$e.forEach(t),Rvo=i(Y),op=n(Y,"LI",{});var v$e=s(op);Bce=n(v$e,"STRONG",{});var _2t=s(Bce);Pvo=r(_2t,"data2vec-vision"),_2t.forEach(t),Bvo=r(v$e," \u2014 "),aj=n(v$e,"A",{href:!0});var u2t=s(aj);Ivo=r(u2t,"BeitFeatureExtractor"),u2t.forEach(t),Nvo=r(v$e," (Data2VecVision model)"),v$e.forEach(t),qvo=i(Y),rp=n(Y,"LI",{});var F$e=s(rp);Ice=n(F$e,"STRONG",{});var b2t=s(Ice);jvo=r(b2t,"deit"),b2t.forEach(t),Dvo=r(F$e," \u2014 "),nj=n(F$e,"A",{href:!0});var v2t=s(nj);Gvo=r(v2t,"DeiTFeatureExtractor"),v2t.forEach(t),Ovo=r(F$e," (DeiT model)"),F$e.forEach(t),Vvo=i(Y),tp=n(Y,"LI",{});var T$e=s(tp);Nce=n(T$e,"STRONG",{});var F2t=s(Nce);Xvo=r(F2t,"detr"),F2t.forEach(t),zvo=r(T$e," \u2014 "),sj=n(T$e,"A",{href:!0});var T2t=s(sj);Wvo=r(T2t,"DetrFeatureExtractor"),T2t.forEach(t),Qvo=r(T$e," (DETR model)"),T$e.forEach(t),Hvo=i(Y),ap=n(Y,"LI",{});var M$e=s(ap);qce=n(M$e,"STRONG",{});var M2t=s(qce);Uvo=r(M2t,"dpt"),M2t.forEach(t),Jvo=r(M$e," \u2014 "),lj=n(M$e,"A",{href:!0});var E2t=s(lj);Yvo=r(E2t,"DPTFeatureExtractor"),E2t.forEach(t),Kvo=r(M$e," (DPT model)"),M$e.forEach(t),Zvo=i(Y),np=n(Y,"LI",{});var E$e=s(np);jce=n(E$e,"STRONG",{});var C2t=s(jce);e0o=r(C2t,"flava"),C2t.forEach(t),o0o=r(E$e," \u2014 "),ij=n(E$e,"A",{href:!0});var w2t=s(ij);r0o=r(w2t,"FlavaFeatureExtractor"),w2t.forEach(t),t0o=r(E$e," (FLAVA model)"),E$e.forEach(t),a0o=i(Y),sp=n(Y,"LI",{});var C$e=s(sp);Dce=n(C$e,"STRONG",{});var A2t=s(Dce);n0o=r(A2t,"glpn"),A2t.forEach(t),s0o=r(C$e," \u2014 "),dj=n(C$e,"A",{href:!0});var L2t=s(dj);l0o=r(L2t,"GLPNFeatureExtractor"),L2t.forEach(t),i0o=r(C$e," (GLPN model)"),C$e.forEach(t),d0o=i(Y),lp=n(Y,"LI",{});var w$e=s(lp);Gce=n(w$e,"STRONG",{});var y2t=s(Gce);c0o=r(y2t,"groupvit"),y2t.forEach(t),f0o=r(w$e," \u2014 "),cj=n(w$e,"A",{href:!0});var x2t=s(cj);m0o=r(x2t,"CLIPFeatureExtractor"),x2t.forEach(t),g0o=r(w$e," (GroupViT model)"),w$e.forEach(t),h0o=i(Y),ip=n(Y,"LI",{});var A$e=s(ip);Oce=n(A$e,"STRONG",{});var $2t=s(Oce);p0o=r($2t,"hubert"),$2t.forEach(t),_0o=r(A$e," \u2014 "),fj=n(A$e,"A",{href:!0});var k2t=s(fj);u0o=r(k2t,"Wav2Vec2FeatureExtractor"),k2t.forEach(t),b0o=r(A$e," (Hubert model)"),A$e.forEach(t),v0o=i(Y),dp=n(Y,"LI",{});var L$e=s(dp);Vce=n(L$e,"STRONG",{});var S2t=s(Vce);F0o=r(S2t,"imagegpt"),S2t.forEach(t),T0o=r(L$e," \u2014 "),mj=n(L$e,"A",{href:!0});var R2t=s(mj);M0o=r(R2t,"ImageGPTFeatureExtractor"),R2t.forEach(t),E0o=r(L$e," (ImageGPT model)"),L$e.forEach(t),C0o=i(Y),cp=n(Y,"LI",{});var y$e=s(cp);Xce=n(y$e,"STRONG",{});var P2t=s(Xce);w0o=r(P2t,"layoutlmv2"),P2t.forEach(t),A0o=r(y$e," \u2014 "),gj=n(y$e,"A",{href:!0});var B2t=s(gj);L0o=r(B2t,"LayoutLMv2FeatureExtractor"),B2t.forEach(t),y0o=r(y$e," (LayoutLMv2 model)"),y$e.forEach(t),x0o=i(Y),fp=n(Y,"LI",{});var x$e=s(fp);zce=n(x$e,"STRONG",{});var I2t=s(zce);$0o=r(I2t,"layoutlmv3"),I2t.forEach(t),k0o=r(x$e," \u2014 "),hj=n(x$e,"A",{href:!0});var N2t=s(hj);S0o=r(N2t,"LayoutLMv3FeatureExtractor"),N2t.forEach(t),R0o=r(x$e," (LayoutLMv3 model)"),x$e.forEach(t),P0o=i(Y),mp=n(Y,"LI",{});var $$e=s(mp);Wce=n($$e,"STRONG",{});var q2t=s(Wce);B0o=r(q2t,"levit"),q2t.forEach(t),I0o=r($$e," \u2014 "),pj=n($$e,"A",{href:!0});var j2t=s(pj);N0o=r(j2t,"LevitFeatureExtractor"),j2t.forEach(t),q0o=r($$e," (LeViT model)"),$$e.forEach(t),j0o=i(Y),gp=n(Y,"LI",{});var k$e=s(gp);Qce=n(k$e,"STRONG",{});var D2t=s(Qce);D0o=r(D2t,"maskformer"),D2t.forEach(t),G0o=r(k$e," \u2014 "),_j=n(k$e,"A",{href:!0});var G2t=s(_j);O0o=r(G2t,"MaskFormerFeatureExtractor"),G2t.forEach(t),V0o=r(k$e," (MaskFormer model)"),k$e.forEach(t),X0o=i(Y),hp=n(Y,"LI",{});var S$e=s(hp);Hce=n(S$e,"STRONG",{});var O2t=s(Hce);z0o=r(O2t,"mctct"),O2t.forEach(t),W0o=r(S$e," \u2014 "),uj=n(S$e,"A",{href:!0});var V2t=s(uj);Q0o=r(V2t,"MCTCTFeatureExtractor"),V2t.forEach(t),H0o=r(S$e," (M-CTC-T model)"),S$e.forEach(t),U0o=i(Y),pp=n(Y,"LI",{});var R$e=s(pp);Uce=n(R$e,"STRONG",{});var X2t=s(Uce);J0o=r(X2t,"mobilevit"),X2t.forEach(t),Y0o=r(R$e," \u2014 "),bj=n(R$e,"A",{href:!0});var z2t=s(bj);K0o=r(z2t,"MobileViTFeatureExtractor"),z2t.forEach(t),Z0o=r(R$e," (MobileViT model)"),R$e.forEach(t),eFo=i(Y),_p=n(Y,"LI",{});var P$e=s(_p);Jce=n(P$e,"STRONG",{});var W2t=s(Jce);oFo=r(W2t,"owlvit"),W2t.forEach(t),rFo=r(P$e," \u2014 "),vj=n(P$e,"A",{href:!0});var Q2t=s(vj);tFo=r(Q2t,"OwlViTFeatureExtractor"),Q2t.forEach(t),aFo=r(P$e," (OWL-ViT model)"),P$e.forEach(t),nFo=i(Y),up=n(Y,"LI",{});var B$e=s(up);Yce=n(B$e,"STRONG",{});var H2t=s(Yce);sFo=r(H2t,"perceiver"),H2t.forEach(t),lFo=r(B$e," \u2014 "),Fj=n(B$e,"A",{href:!0});var U2t=s(Fj);iFo=r(U2t,"PerceiverFeatureExtractor"),U2t.forEach(t),dFo=r(B$e," (Perceiver model)"),B$e.forEach(t),cFo=i(Y),bp=n(Y,"LI",{});var I$e=s(bp);Kce=n(I$e,"STRONG",{});var J2t=s(Kce);fFo=r(J2t,"poolformer"),J2t.forEach(t),mFo=r(I$e," \u2014 "),Tj=n(I$e,"A",{href:!0});var Y2t=s(Tj);gFo=r(Y2t,"PoolFormerFeatureExtractor"),Y2t.forEach(t),hFo=r(I$e," (PoolFormer model)"),I$e.forEach(t),pFo=i(Y),vp=n(Y,"LI",{});var N$e=s(vp);Zce=n(N$e,"STRONG",{});var K2t=s(Zce);_Fo=r(K2t,"regnet"),K2t.forEach(t),uFo=r(N$e," \u2014 "),Mj=n(N$e,"A",{href:!0});var Z2t=s(Mj);bFo=r(Z2t,"ConvNextFeatureExtractor"),Z2t.forEach(t),vFo=r(N$e," (RegNet model)"),N$e.forEach(t),FFo=i(Y),Fp=n(Y,"LI",{});var q$e=s(Fp);efe=n(q$e,"STRONG",{});var e1t=s(efe);TFo=r(e1t,"resnet"),e1t.forEach(t),MFo=r(q$e," \u2014 "),Ej=n(q$e,"A",{href:!0});var o1t=s(Ej);EFo=r(o1t,"ConvNextFeatureExtractor"),o1t.forEach(t),CFo=r(q$e," (ResNet model)"),q$e.forEach(t),wFo=i(Y),Tp=n(Y,"LI",{});var j$e=s(Tp);ofe=n(j$e,"STRONG",{});var r1t=s(ofe);AFo=r(r1t,"segformer"),r1t.forEach(t),LFo=r(j$e," \u2014 "),Cj=n(j$e,"A",{href:!0});var t1t=s(Cj);yFo=r(t1t,"SegformerFeatureExtractor"),t1t.forEach(t),xFo=r(j$e," (SegFormer model)"),j$e.forEach(t),$Fo=i(Y),Mp=n(Y,"LI",{});var D$e=s(Mp);rfe=n(D$e,"STRONG",{});var a1t=s(rfe);kFo=r(a1t,"speech_to_text"),a1t.forEach(t),SFo=r(D$e," \u2014 "),wj=n(D$e,"A",{href:!0});var n1t=s(wj);RFo=r(n1t,"Speech2TextFeatureExtractor"),n1t.forEach(t),PFo=r(D$e," (Speech2Text model)"),D$e.forEach(t),BFo=i(Y),Ep=n(Y,"LI",{});var G$e=s(Ep);tfe=n(G$e,"STRONG",{});var s1t=s(tfe);IFo=r(s1t,"swin"),s1t.forEach(t),NFo=r(G$e," \u2014 "),Aj=n(G$e,"A",{href:!0});var l1t=s(Aj);qFo=r(l1t,"ViTFeatureExtractor"),l1t.forEach(t),jFo=r(G$e," (Swin Transformer model)"),G$e.forEach(t),DFo=i(Y),Cp=n(Y,"LI",{});var O$e=s(Cp);afe=n(O$e,"STRONG",{});var i1t=s(afe);GFo=r(i1t,"swinv2"),i1t.forEach(t),OFo=r(O$e," \u2014 "),Lj=n(O$e,"A",{href:!0});var d1t=s(Lj);VFo=r(d1t,"ViTFeatureExtractor"),d1t.forEach(t),XFo=r(O$e," (Swin Transformer V2 model)"),O$e.forEach(t),zFo=i(Y),wp=n(Y,"LI",{});var V$e=s(wp);nfe=n(V$e,"STRONG",{});var c1t=s(nfe);WFo=r(c1t,"van"),c1t.forEach(t),QFo=r(V$e," \u2014 "),yj=n(V$e,"A",{href:!0});var f1t=s(yj);HFo=r(f1t,"ConvNextFeatureExtractor"),f1t.forEach(t),UFo=r(V$e," (VAN model)"),V$e.forEach(t),JFo=i(Y),Ap=n(Y,"LI",{});var X$e=s(Ap);sfe=n(X$e,"STRONG",{});var m1t=s(sfe);YFo=r(m1t,"videomae"),m1t.forEach(t),KFo=r(X$e," \u2014 "),xj=n(X$e,"A",{href:!0});var g1t=s(xj);ZFo=r(g1t,"ViTFeatureExtractor"),g1t.forEach(t),eTo=r(X$e," (VideoMAE model)"),X$e.forEach(t),oTo=i(Y),Lp=n(Y,"LI",{});var z$e=s(Lp);lfe=n(z$e,"STRONG",{});var h1t=s(lfe);rTo=r(h1t,"vilt"),h1t.forEach(t),tTo=r(z$e," \u2014 "),$j=n(z$e,"A",{href:!0});var p1t=s($j);aTo=r(p1t,"ViltFeatureExtractor"),p1t.forEach(t),nTo=r(z$e," (ViLT model)"),z$e.forEach(t),sTo=i(Y),yp=n(Y,"LI",{});var W$e=s(yp);ife=n(W$e,"STRONG",{});var _1t=s(ife);lTo=r(_1t,"vit"),_1t.forEach(t),iTo=r(W$e," \u2014 "),kj=n(W$e,"A",{href:!0});var u1t=s(kj);dTo=r(u1t,"ViTFeatureExtractor"),u1t.forEach(t),cTo=r(W$e," (ViT model)"),W$e.forEach(t),fTo=i(Y),xp=n(Y,"LI",{});var Q$e=s(xp);dfe=n(Q$e,"STRONG",{});var b1t=s(dfe);mTo=r(b1t,"vit_mae"),b1t.forEach(t),gTo=r(Q$e," \u2014 "),Sj=n(Q$e,"A",{href:!0});var v1t=s(Sj);hTo=r(v1t,"ViTFeatureExtractor"),v1t.forEach(t),pTo=r(Q$e," (ViTMAE model)"),Q$e.forEach(t),_To=i(Y),$p=n(Y,"LI",{});var H$e=s($p);cfe=n(H$e,"STRONG",{});var F1t=s(cfe);uTo=r(F1t,"wav2vec2"),F1t.forEach(t),bTo=r(H$e," \u2014 "),Rj=n(H$e,"A",{href:!0});var T1t=s(Rj);vTo=r(T1t,"Wav2Vec2FeatureExtractor"),T1t.forEach(t),FTo=r(H$e," (Wav2Vec2 model)"),H$e.forEach(t),TTo=i(Y),kp=n(Y,"LI",{});var U$e=s(kp);ffe=n(U$e,"STRONG",{});var M1t=s(ffe);MTo=r(M1t,"wav2vec2-conformer"),M1t.forEach(t),ETo=r(U$e," \u2014 "),Pj=n(U$e,"A",{href:!0});var E1t=s(Pj);CTo=r(E1t,"Wav2Vec2FeatureExtractor"),E1t.forEach(t),wTo=r(U$e," (Wav2Vec2-Conformer model)"),U$e.forEach(t),ATo=i(Y),Sp=n(Y,"LI",{});var J$e=s(Sp);mfe=n(J$e,"STRONG",{});var C1t=s(mfe);LTo=r(C1t,"yolos"),C1t.forEach(t),yTo=r(J$e," \u2014 "),Bj=n(J$e,"A",{href:!0});var w1t=s(Bj);xTo=r(w1t,"YolosFeatureExtractor"),w1t.forEach(t),$To=r(J$e," (YOLOS model)"),J$e.forEach(t),Y.forEach(t),kTo=i(ia),T(Rp.$$.fragment,ia),STo=i(ia),T(Pp.$$.fragment,ia),ia.forEach(t),RTo=i(il),Bp=n(il,"DIV",{class:!0});var nUe=s(Bp);T(gy.$$.fragment,nUe),PTo=i(nUe),gfe=n(nUe,"P",{});var A1t=s(gfe);BTo=r(A1t,"Register a new feature extractor for this class."),A1t.forEach(t),nUe.forEach(t),il.forEach(t),eQe=i(f),Hi=n(f,"H2",{class:!0});var sUe=s(Hi);Ip=n(sUe,"A",{id:!0,class:!0,href:!0});var L1t=s(Ip);hfe=n(L1t,"SPAN",{});var y1t=s(hfe);T(hy.$$.fragment,y1t),y1t.forEach(t),L1t.forEach(t),ITo=i(sUe),pfe=n(sUe,"SPAN",{});var x1t=s(pfe);NTo=r(x1t,"AutoProcessor"),x1t.forEach(t),sUe.forEach(t),oQe=i(f),ko=n(f,"DIV",{class:!0});var dl=s(ko);T(py.$$.fragment,dl),qTo=i(dl),_y=n(dl,"P",{});var lUe=s(_y);jTo=r(lUe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),Ij=n(lUe,"A",{href:!0});var $1t=s(Ij);DTo=r($1t,"AutoProcessor.from_pretrained()"),$1t.forEach(t),GTo=r(lUe," class method."),lUe.forEach(t),OTo=i(dl),uy=n(dl,"P",{});var iUe=s(uy);VTo=r(iUe,"This class cannot be instantiated directly using "),_fe=n(iUe,"CODE",{});var k1t=s(_fe);XTo=r(k1t,"__init__()"),k1t.forEach(t),zTo=r(iUe," (throws an error)."),iUe.forEach(t),WTo=i(dl),Je=n(dl,"DIV",{class:!0});var da=s(Je);T(by.$$.fragment,da),QTo=i(da),ufe=n(da,"P",{});var S1t=s(ufe);HTo=r(S1t,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),S1t.forEach(t),UTo=i(da),Ui=n(da,"P",{});var lae=s(Ui);JTo=r(lae,"The processor class to instantiate is selected based on the "),bfe=n(lae,"CODE",{});var R1t=s(bfe);YTo=r(R1t,"model_type"),R1t.forEach(t),KTo=r(lae,` property of the config object (either
passed as an argument or loaded from `),vfe=n(lae,"CODE",{});var P1t=s(vfe);ZTo=r(P1t,"pretrained_model_name_or_path"),P1t.forEach(t),e8o=r(lae," if possible):"),lae.forEach(t),o8o=i(da),fe=n(da,"UL",{});var _e=s(fe);Np=n(_e,"LI",{});var Y$e=s(Np);Ffe=n(Y$e,"STRONG",{});var B1t=s(Ffe);r8o=r(B1t,"clip"),B1t.forEach(t),t8o=r(Y$e," \u2014 "),Nj=n(Y$e,"A",{href:!0});var I1t=s(Nj);a8o=r(I1t,"CLIPProcessor"),I1t.forEach(t),n8o=r(Y$e," (CLIP model)"),Y$e.forEach(t),s8o=i(_e),qp=n(_e,"LI",{});var K$e=s(qp);Tfe=n(K$e,"STRONG",{});var N1t=s(Tfe);l8o=r(N1t,"flava"),N1t.forEach(t),i8o=r(K$e," \u2014 "),qj=n(K$e,"A",{href:!0});var q1t=s(qj);d8o=r(q1t,"FlavaProcessor"),q1t.forEach(t),c8o=r(K$e," (FLAVA model)"),K$e.forEach(t),f8o=i(_e),jp=n(_e,"LI",{});var Z$e=s(jp);Mfe=n(Z$e,"STRONG",{});var j1t=s(Mfe);m8o=r(j1t,"groupvit"),j1t.forEach(t),g8o=r(Z$e," \u2014 "),jj=n(Z$e,"A",{href:!0});var D1t=s(jj);h8o=r(D1t,"CLIPProcessor"),D1t.forEach(t),p8o=r(Z$e," (GroupViT model)"),Z$e.forEach(t),_8o=i(_e),Dp=n(_e,"LI",{});var eke=s(Dp);Efe=n(eke,"STRONG",{});var G1t=s(Efe);u8o=r(G1t,"layoutlmv2"),G1t.forEach(t),b8o=r(eke," \u2014 "),Dj=n(eke,"A",{href:!0});var O1t=s(Dj);v8o=r(O1t,"LayoutLMv2Processor"),O1t.forEach(t),F8o=r(eke," (LayoutLMv2 model)"),eke.forEach(t),T8o=i(_e),Gp=n(_e,"LI",{});var oke=s(Gp);Cfe=n(oke,"STRONG",{});var V1t=s(Cfe);M8o=r(V1t,"layoutlmv3"),V1t.forEach(t),E8o=r(oke," \u2014 "),Gj=n(oke,"A",{href:!0});var X1t=s(Gj);C8o=r(X1t,"LayoutLMv3Processor"),X1t.forEach(t),w8o=r(oke," (LayoutLMv3 model)"),oke.forEach(t),A8o=i(_e),Op=n(_e,"LI",{});var rke=s(Op);wfe=n(rke,"STRONG",{});var z1t=s(wfe);L8o=r(z1t,"layoutxlm"),z1t.forEach(t),y8o=r(rke," \u2014 "),Oj=n(rke,"A",{href:!0});var W1t=s(Oj);x8o=r(W1t,"LayoutXLMProcessor"),W1t.forEach(t),$8o=r(rke," (LayoutXLM model)"),rke.forEach(t),k8o=i(_e),Vp=n(_e,"LI",{});var tke=s(Vp);Afe=n(tke,"STRONG",{});var Q1t=s(Afe);S8o=r(Q1t,"owlvit"),Q1t.forEach(t),R8o=r(tke," \u2014 "),Vj=n(tke,"A",{href:!0});var H1t=s(Vj);P8o=r(H1t,"OwlViTProcessor"),H1t.forEach(t),B8o=r(tke," (OWL-ViT model)"),tke.forEach(t),I8o=i(_e),Xp=n(_e,"LI",{});var ake=s(Xp);Lfe=n(ake,"STRONG",{});var U1t=s(Lfe);N8o=r(U1t,"sew"),U1t.forEach(t),q8o=r(ake," \u2014 "),Xj=n(ake,"A",{href:!0});var J1t=s(Xj);j8o=r(J1t,"Wav2Vec2Processor"),J1t.forEach(t),D8o=r(ake," (SEW model)"),ake.forEach(t),G8o=i(_e),zp=n(_e,"LI",{});var nke=s(zp);yfe=n(nke,"STRONG",{});var Y1t=s(yfe);O8o=r(Y1t,"sew-d"),Y1t.forEach(t),V8o=r(nke," \u2014 "),zj=n(nke,"A",{href:!0});var K1t=s(zj);X8o=r(K1t,"Wav2Vec2Processor"),K1t.forEach(t),z8o=r(nke," (SEW-D model)"),nke.forEach(t),W8o=i(_e),Wp=n(_e,"LI",{});var ske=s(Wp);xfe=n(ske,"STRONG",{});var Z1t=s(xfe);Q8o=r(Z1t,"speech_to_text"),Z1t.forEach(t),H8o=r(ske," \u2014 "),Wj=n(ske,"A",{href:!0});var ebt=s(Wj);U8o=r(ebt,"Speech2TextProcessor"),ebt.forEach(t),J8o=r(ske," (Speech2Text model)"),ske.forEach(t),Y8o=i(_e),Qp=n(_e,"LI",{});var lke=s(Qp);$fe=n(lke,"STRONG",{});var obt=s($fe);K8o=r(obt,"speech_to_text_2"),obt.forEach(t),Z8o=r(lke," \u2014 "),Qj=n(lke,"A",{href:!0});var rbt=s(Qj);eMo=r(rbt,"Speech2Text2Processor"),rbt.forEach(t),oMo=r(lke," (Speech2Text2 model)"),lke.forEach(t),rMo=i(_e),Hp=n(_e,"LI",{});var ike=s(Hp);kfe=n(ike,"STRONG",{});var tbt=s(kfe);tMo=r(tbt,"trocr"),tbt.forEach(t),aMo=r(ike," \u2014 "),Hj=n(ike,"A",{href:!0});var abt=s(Hj);nMo=r(abt,"TrOCRProcessor"),abt.forEach(t),sMo=r(ike," (TrOCR model)"),ike.forEach(t),lMo=i(_e),Up=n(_e,"LI",{});var dke=s(Up);Sfe=n(dke,"STRONG",{});var nbt=s(Sfe);iMo=r(nbt,"unispeech"),nbt.forEach(t),dMo=r(dke," \u2014 "),Uj=n(dke,"A",{href:!0});var sbt=s(Uj);cMo=r(sbt,"Wav2Vec2Processor"),sbt.forEach(t),fMo=r(dke," (UniSpeech model)"),dke.forEach(t),mMo=i(_e),Jp=n(_e,"LI",{});var cke=s(Jp);Rfe=n(cke,"STRONG",{});var lbt=s(Rfe);gMo=r(lbt,"unispeech-sat"),lbt.forEach(t),hMo=r(cke," \u2014 "),Jj=n(cke,"A",{href:!0});var ibt=s(Jj);pMo=r(ibt,"Wav2Vec2Processor"),ibt.forEach(t),_Mo=r(cke," (UniSpeechSat model)"),cke.forEach(t),uMo=i(_e),Yp=n(_e,"LI",{});var fke=s(Yp);Pfe=n(fke,"STRONG",{});var dbt=s(Pfe);bMo=r(dbt,"vilt"),dbt.forEach(t),vMo=r(fke," \u2014 "),Yj=n(fke,"A",{href:!0});var cbt=s(Yj);FMo=r(cbt,"ViltProcessor"),cbt.forEach(t),TMo=r(fke," (ViLT model)"),fke.forEach(t),MMo=i(_e),Kp=n(_e,"LI",{});var mke=s(Kp);Bfe=n(mke,"STRONG",{});var fbt=s(Bfe);EMo=r(fbt,"vision-text-dual-encoder"),fbt.forEach(t),CMo=r(mke," \u2014 "),Kj=n(mke,"A",{href:!0});var mbt=s(Kj);wMo=r(mbt,"VisionTextDualEncoderProcessor"),mbt.forEach(t),AMo=r(mke," (VisionTextDualEncoder model)"),mke.forEach(t),LMo=i(_e),Zp=n(_e,"LI",{});var gke=s(Zp);Ife=n(gke,"STRONG",{});var gbt=s(Ife);yMo=r(gbt,"wav2vec2"),gbt.forEach(t),xMo=r(gke," \u2014 "),Zj=n(gke,"A",{href:!0});var hbt=s(Zj);$Mo=r(hbt,"Wav2Vec2Processor"),hbt.forEach(t),kMo=r(gke," (Wav2Vec2 model)"),gke.forEach(t),SMo=i(_e),e_=n(_e,"LI",{});var hke=s(e_);Nfe=n(hke,"STRONG",{});var pbt=s(Nfe);RMo=r(pbt,"wav2vec2-conformer"),pbt.forEach(t),PMo=r(hke," \u2014 "),eD=n(hke,"A",{href:!0});var _bt=s(eD);BMo=r(_bt,"Wav2Vec2Processor"),_bt.forEach(t),IMo=r(hke," (Wav2Vec2-Conformer model)"),hke.forEach(t),NMo=i(_e),o_=n(_e,"LI",{});var pke=s(o_);qfe=n(pke,"STRONG",{});var ubt=s(qfe);qMo=r(ubt,"wavlm"),ubt.forEach(t),jMo=r(pke," \u2014 "),oD=n(pke,"A",{href:!0});var bbt=s(oD);DMo=r(bbt,"Wav2Vec2Processor"),bbt.forEach(t),GMo=r(pke," (WavLM model)"),pke.forEach(t),_e.forEach(t),OMo=i(da),T(r_.$$.fragment,da),VMo=i(da),T(t_.$$.fragment,da),da.forEach(t),XMo=i(dl),a_=n(dl,"DIV",{class:!0});var dUe=s(a_);T(vy.$$.fragment,dUe),zMo=i(dUe),jfe=n(dUe,"P",{});var vbt=s(jfe);WMo=r(vbt,"Register a new processor for this class."),vbt.forEach(t),dUe.forEach(t),dl.forEach(t),rQe=i(f),Ji=n(f,"H2",{class:!0});var cUe=s(Ji);n_=n(cUe,"A",{id:!0,class:!0,href:!0});var Fbt=s(n_);Dfe=n(Fbt,"SPAN",{});var Tbt=s(Dfe);T(Fy.$$.fragment,Tbt),Tbt.forEach(t),Fbt.forEach(t),QMo=i(cUe),Gfe=n(cUe,"SPAN",{});var Mbt=s(Gfe);HMo=r(Mbt,"AutoModel"),Mbt.forEach(t),cUe.forEach(t),tQe=i(f),So=n(f,"DIV",{class:!0});var cl=s(So);T(Ty.$$.fragment,cl),UMo=i(cl),Yi=n(cl,"P",{});var iae=s(Yi);JMo=r(iae,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rD=n(iae,"A",{href:!0});var Ebt=s(rD);YMo=r(Ebt,"from_pretrained()"),Ebt.forEach(t),KMo=r(iae," class method or the "),tD=n(iae,"A",{href:!0});var Cbt=s(tD);ZMo=r(Cbt,"from_config()"),Cbt.forEach(t),eEo=r(iae,` class
method.`),iae.forEach(t),oEo=i(cl),My=n(cl,"P",{});var fUe=s(My);rEo=r(fUe,"This class cannot be instantiated directly using "),Ofe=n(fUe,"CODE",{});var wbt=s(Ofe);tEo=r(wbt,"__init__()"),wbt.forEach(t),aEo=r(fUe," (throws an error)."),fUe.forEach(t),nEo=i(cl),ct=n(cl,"DIV",{class:!0});var UA=s(ct);T(Ey.$$.fragment,UA),sEo=i(UA),Vfe=n(UA,"P",{});var Abt=s(Vfe);lEo=r(Abt,"Instantiates one of the base model classes of the library from a configuration."),Abt.forEach(t),iEo=i(UA),Ki=n(UA,"P",{});var dae=s(Ki);dEo=r(dae,`Note:
Loading a model from its configuration file does `),Xfe=n(dae,"STRONG",{});var Lbt=s(Xfe);cEo=r(Lbt,"not"),Lbt.forEach(t),fEo=r(dae,` load the model weights. It only affects the
model\u2019s configuration. Use `),aD=n(dae,"A",{href:!0});var ybt=s(aD);mEo=r(ybt,"from_pretrained()"),ybt.forEach(t),gEo=r(dae," to load the model weights."),dae.forEach(t),hEo=i(UA),T(s_.$$.fragment,UA),UA.forEach(t),pEo=i(cl),Ye=n(cl,"DIV",{class:!0});var ca=s(Ye);T(Cy.$$.fragment,ca),_Eo=i(ca),zfe=n(ca,"P",{});var xbt=s(zfe);uEo=r(xbt,"Instantiate one of the base model classes of the library from a pretrained model."),xbt.forEach(t),bEo=i(ca),Da=n(ca,"P",{});var JA=s(Da);vEo=r(JA,"The model class to instantiate is selected based on the "),Wfe=n(JA,"CODE",{});var $bt=s(Wfe);FEo=r($bt,"model_type"),$bt.forEach(t),TEo=r(JA,` property of the config object (either
passed as an argument or loaded from `),Qfe=n(JA,"CODE",{});var kbt=s(Qfe);MEo=r(kbt,"pretrained_model_name_or_path"),kbt.forEach(t),EEo=r(JA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Hfe=n(JA,"CODE",{});var Sbt=s(Hfe);CEo=r(Sbt,"pretrained_model_name_or_path"),Sbt.forEach(t),wEo=r(JA,":"),JA.forEach(t),AEo=i(ca),y=n(ca,"UL",{});var x=s(y);l_=n(x,"LI",{});var _ke=s(l_);Ufe=n(_ke,"STRONG",{});var Rbt=s(Ufe);LEo=r(Rbt,"albert"),Rbt.forEach(t),yEo=r(_ke," \u2014 "),nD=n(_ke,"A",{href:!0});var Pbt=s(nD);xEo=r(Pbt,"AlbertModel"),Pbt.forEach(t),$Eo=r(_ke," (ALBERT model)"),_ke.forEach(t),kEo=i(x),i_=n(x,"LI",{});var uke=s(i_);Jfe=n(uke,"STRONG",{});var Bbt=s(Jfe);SEo=r(Bbt,"bart"),Bbt.forEach(t),REo=r(uke," \u2014 "),sD=n(uke,"A",{href:!0});var Ibt=s(sD);PEo=r(Ibt,"BartModel"),Ibt.forEach(t),BEo=r(uke," (BART model)"),uke.forEach(t),IEo=i(x),d_=n(x,"LI",{});var bke=s(d_);Yfe=n(bke,"STRONG",{});var Nbt=s(Yfe);NEo=r(Nbt,"beit"),Nbt.forEach(t),qEo=r(bke," \u2014 "),lD=n(bke,"A",{href:!0});var qbt=s(lD);jEo=r(qbt,"BeitModel"),qbt.forEach(t),DEo=r(bke," (BEiT model)"),bke.forEach(t),GEo=i(x),c_=n(x,"LI",{});var vke=s(c_);Kfe=n(vke,"STRONG",{});var jbt=s(Kfe);OEo=r(jbt,"bert"),jbt.forEach(t),VEo=r(vke," \u2014 "),iD=n(vke,"A",{href:!0});var Dbt=s(iD);XEo=r(Dbt,"BertModel"),Dbt.forEach(t),zEo=r(vke," (BERT model)"),vke.forEach(t),WEo=i(x),f_=n(x,"LI",{});var Fke=s(f_);Zfe=n(Fke,"STRONG",{});var Gbt=s(Zfe);QEo=r(Gbt,"bert-generation"),Gbt.forEach(t),HEo=r(Fke," \u2014 "),dD=n(Fke,"A",{href:!0});var Obt=s(dD);UEo=r(Obt,"BertGenerationEncoder"),Obt.forEach(t),JEo=r(Fke," (Bert Generation model)"),Fke.forEach(t),YEo=i(x),m_=n(x,"LI",{});var Tke=s(m_);eme=n(Tke,"STRONG",{});var Vbt=s(eme);KEo=r(Vbt,"big_bird"),Vbt.forEach(t),ZEo=r(Tke," \u2014 "),cD=n(Tke,"A",{href:!0});var Xbt=s(cD);e4o=r(Xbt,"BigBirdModel"),Xbt.forEach(t),o4o=r(Tke," (BigBird model)"),Tke.forEach(t),r4o=i(x),g_=n(x,"LI",{});var Mke=s(g_);ome=n(Mke,"STRONG",{});var zbt=s(ome);t4o=r(zbt,"bigbird_pegasus"),zbt.forEach(t),a4o=r(Mke," \u2014 "),fD=n(Mke,"A",{href:!0});var Wbt=s(fD);n4o=r(Wbt,"BigBirdPegasusModel"),Wbt.forEach(t),s4o=r(Mke," (BigBird-Pegasus model)"),Mke.forEach(t),l4o=i(x),h_=n(x,"LI",{});var Eke=s(h_);rme=n(Eke,"STRONG",{});var Qbt=s(rme);i4o=r(Qbt,"blenderbot"),Qbt.forEach(t),d4o=r(Eke," \u2014 "),mD=n(Eke,"A",{href:!0});var Hbt=s(mD);c4o=r(Hbt,"BlenderbotModel"),Hbt.forEach(t),f4o=r(Eke," (Blenderbot model)"),Eke.forEach(t),m4o=i(x),p_=n(x,"LI",{});var Cke=s(p_);tme=n(Cke,"STRONG",{});var Ubt=s(tme);g4o=r(Ubt,"blenderbot-small"),Ubt.forEach(t),h4o=r(Cke," \u2014 "),gD=n(Cke,"A",{href:!0});var Jbt=s(gD);p4o=r(Jbt,"BlenderbotSmallModel"),Jbt.forEach(t),_4o=r(Cke," (BlenderbotSmall model)"),Cke.forEach(t),u4o=i(x),__=n(x,"LI",{});var wke=s(__);ame=n(wke,"STRONG",{});var Ybt=s(ame);b4o=r(Ybt,"bloom"),Ybt.forEach(t),v4o=r(wke," \u2014 "),hD=n(wke,"A",{href:!0});var Kbt=s(hD);F4o=r(Kbt,"BloomModel"),Kbt.forEach(t),T4o=r(wke," (BLOOM model)"),wke.forEach(t),M4o=i(x),u_=n(x,"LI",{});var Ake=s(u_);nme=n(Ake,"STRONG",{});var Zbt=s(nme);E4o=r(Zbt,"camembert"),Zbt.forEach(t),C4o=r(Ake," \u2014 "),pD=n(Ake,"A",{href:!0});var evt=s(pD);w4o=r(evt,"CamembertModel"),evt.forEach(t),A4o=r(Ake," (CamemBERT model)"),Ake.forEach(t),L4o=i(x),b_=n(x,"LI",{});var Lke=s(b_);sme=n(Lke,"STRONG",{});var ovt=s(sme);y4o=r(ovt,"canine"),ovt.forEach(t),x4o=r(Lke," \u2014 "),_D=n(Lke,"A",{href:!0});var rvt=s(_D);$4o=r(rvt,"CanineModel"),rvt.forEach(t),k4o=r(Lke," (CANINE model)"),Lke.forEach(t),S4o=i(x),v_=n(x,"LI",{});var yke=s(v_);lme=n(yke,"STRONG",{});var tvt=s(lme);R4o=r(tvt,"clip"),tvt.forEach(t),P4o=r(yke," \u2014 "),uD=n(yke,"A",{href:!0});var avt=s(uD);B4o=r(avt,"CLIPModel"),avt.forEach(t),I4o=r(yke," (CLIP model)"),yke.forEach(t),N4o=i(x),F_=n(x,"LI",{});var xke=s(F_);ime=n(xke,"STRONG",{});var nvt=s(ime);q4o=r(nvt,"codegen"),nvt.forEach(t),j4o=r(xke," \u2014 "),bD=n(xke,"A",{href:!0});var svt=s(bD);D4o=r(svt,"CodeGenModel"),svt.forEach(t),G4o=r(xke," (CodeGen model)"),xke.forEach(t),O4o=i(x),T_=n(x,"LI",{});var $ke=s(T_);dme=n($ke,"STRONG",{});var lvt=s(dme);V4o=r(lvt,"convbert"),lvt.forEach(t),X4o=r($ke," \u2014 "),vD=n($ke,"A",{href:!0});var ivt=s(vD);z4o=r(ivt,"ConvBertModel"),ivt.forEach(t),W4o=r($ke," (ConvBERT model)"),$ke.forEach(t),Q4o=i(x),M_=n(x,"LI",{});var kke=s(M_);cme=n(kke,"STRONG",{});var dvt=s(cme);H4o=r(dvt,"convnext"),dvt.forEach(t),U4o=r(kke," \u2014 "),FD=n(kke,"A",{href:!0});var cvt=s(FD);J4o=r(cvt,"ConvNextModel"),cvt.forEach(t),Y4o=r(kke," (ConvNeXT model)"),kke.forEach(t),K4o=i(x),E_=n(x,"LI",{});var Ske=s(E_);fme=n(Ske,"STRONG",{});var fvt=s(fme);Z4o=r(fvt,"ctrl"),fvt.forEach(t),eCo=r(Ske," \u2014 "),TD=n(Ske,"A",{href:!0});var mvt=s(TD);oCo=r(mvt,"CTRLModel"),mvt.forEach(t),rCo=r(Ske," (CTRL model)"),Ske.forEach(t),tCo=i(x),C_=n(x,"LI",{});var Rke=s(C_);mme=n(Rke,"STRONG",{});var gvt=s(mme);aCo=r(gvt,"cvt"),gvt.forEach(t),nCo=r(Rke," \u2014 "),MD=n(Rke,"A",{href:!0});var hvt=s(MD);sCo=r(hvt,"CvtModel"),hvt.forEach(t),lCo=r(Rke," (CvT model)"),Rke.forEach(t),iCo=i(x),w_=n(x,"LI",{});var Pke=s(w_);gme=n(Pke,"STRONG",{});var pvt=s(gme);dCo=r(pvt,"data2vec-audio"),pvt.forEach(t),cCo=r(Pke," \u2014 "),ED=n(Pke,"A",{href:!0});var _vt=s(ED);fCo=r(_vt,"Data2VecAudioModel"),_vt.forEach(t),mCo=r(Pke," (Data2VecAudio model)"),Pke.forEach(t),gCo=i(x),A_=n(x,"LI",{});var Bke=s(A_);hme=n(Bke,"STRONG",{});var uvt=s(hme);hCo=r(uvt,"data2vec-text"),uvt.forEach(t),pCo=r(Bke," \u2014 "),CD=n(Bke,"A",{href:!0});var bvt=s(CD);_Co=r(bvt,"Data2VecTextModel"),bvt.forEach(t),uCo=r(Bke," (Data2VecText model)"),Bke.forEach(t),bCo=i(x),L_=n(x,"LI",{});var Ike=s(L_);pme=n(Ike,"STRONG",{});var vvt=s(pme);vCo=r(vvt,"data2vec-vision"),vvt.forEach(t),FCo=r(Ike," \u2014 "),wD=n(Ike,"A",{href:!0});var Fvt=s(wD);TCo=r(Fvt,"Data2VecVisionModel"),Fvt.forEach(t),MCo=r(Ike," (Data2VecVision model)"),Ike.forEach(t),ECo=i(x),y_=n(x,"LI",{});var Nke=s(y_);_me=n(Nke,"STRONG",{});var Tvt=s(_me);CCo=r(Tvt,"deberta"),Tvt.forEach(t),wCo=r(Nke," \u2014 "),AD=n(Nke,"A",{href:!0});var Mvt=s(AD);ACo=r(Mvt,"DebertaModel"),Mvt.forEach(t),LCo=r(Nke," (DeBERTa model)"),Nke.forEach(t),yCo=i(x),x_=n(x,"LI",{});var qke=s(x_);ume=n(qke,"STRONG",{});var Evt=s(ume);xCo=r(Evt,"deberta-v2"),Evt.forEach(t),$Co=r(qke," \u2014 "),LD=n(qke,"A",{href:!0});var Cvt=s(LD);kCo=r(Cvt,"DebertaV2Model"),Cvt.forEach(t),SCo=r(qke," (DeBERTa-v2 model)"),qke.forEach(t),RCo=i(x),$_=n(x,"LI",{});var jke=s($_);bme=n(jke,"STRONG",{});var wvt=s(bme);PCo=r(wvt,"decision_transformer"),wvt.forEach(t),BCo=r(jke," \u2014 "),yD=n(jke,"A",{href:!0});var Avt=s(yD);ICo=r(Avt,"DecisionTransformerModel"),Avt.forEach(t),NCo=r(jke," (Decision Transformer model)"),jke.forEach(t),qCo=i(x),k_=n(x,"LI",{});var Dke=s(k_);vme=n(Dke,"STRONG",{});var Lvt=s(vme);jCo=r(Lvt,"deit"),Lvt.forEach(t),DCo=r(Dke," \u2014 "),xD=n(Dke,"A",{href:!0});var yvt=s(xD);GCo=r(yvt,"DeiTModel"),yvt.forEach(t),OCo=r(Dke," (DeiT model)"),Dke.forEach(t),VCo=i(x),S_=n(x,"LI",{});var Gke=s(S_);Fme=n(Gke,"STRONG",{});var xvt=s(Fme);XCo=r(xvt,"detr"),xvt.forEach(t),zCo=r(Gke," \u2014 "),$D=n(Gke,"A",{href:!0});var $vt=s($D);WCo=r($vt,"DetrModel"),$vt.forEach(t),QCo=r(Gke," (DETR model)"),Gke.forEach(t),HCo=i(x),R_=n(x,"LI",{});var Oke=s(R_);Tme=n(Oke,"STRONG",{});var kvt=s(Tme);UCo=r(kvt,"distilbert"),kvt.forEach(t),JCo=r(Oke," \u2014 "),kD=n(Oke,"A",{href:!0});var Svt=s(kD);YCo=r(Svt,"DistilBertModel"),Svt.forEach(t),KCo=r(Oke," (DistilBERT model)"),Oke.forEach(t),ZCo=i(x),P_=n(x,"LI",{});var Vke=s(P_);Mme=n(Vke,"STRONG",{});var Rvt=s(Mme);e5o=r(Rvt,"dpr"),Rvt.forEach(t),o5o=r(Vke," \u2014 "),SD=n(Vke,"A",{href:!0});var Pvt=s(SD);r5o=r(Pvt,"DPRQuestionEncoder"),Pvt.forEach(t),t5o=r(Vke," (DPR model)"),Vke.forEach(t),a5o=i(x),B_=n(x,"LI",{});var Xke=s(B_);Eme=n(Xke,"STRONG",{});var Bvt=s(Eme);n5o=r(Bvt,"dpt"),Bvt.forEach(t),s5o=r(Xke," \u2014 "),RD=n(Xke,"A",{href:!0});var Ivt=s(RD);l5o=r(Ivt,"DPTModel"),Ivt.forEach(t),i5o=r(Xke," (DPT model)"),Xke.forEach(t),d5o=i(x),I_=n(x,"LI",{});var zke=s(I_);Cme=n(zke,"STRONG",{});var Nvt=s(Cme);c5o=r(Nvt,"electra"),Nvt.forEach(t),f5o=r(zke," \u2014 "),PD=n(zke,"A",{href:!0});var qvt=s(PD);m5o=r(qvt,"ElectraModel"),qvt.forEach(t),g5o=r(zke," (ELECTRA model)"),zke.forEach(t),h5o=i(x),N_=n(x,"LI",{});var Wke=s(N_);wme=n(Wke,"STRONG",{});var jvt=s(wme);p5o=r(jvt,"flaubert"),jvt.forEach(t),_5o=r(Wke," \u2014 "),BD=n(Wke,"A",{href:!0});var Dvt=s(BD);u5o=r(Dvt,"FlaubertModel"),Dvt.forEach(t),b5o=r(Wke," (FlauBERT model)"),Wke.forEach(t),v5o=i(x),q_=n(x,"LI",{});var Qke=s(q_);Ame=n(Qke,"STRONG",{});var Gvt=s(Ame);F5o=r(Gvt,"flava"),Gvt.forEach(t),T5o=r(Qke," \u2014 "),ID=n(Qke,"A",{href:!0});var Ovt=s(ID);M5o=r(Ovt,"FlavaModel"),Ovt.forEach(t),E5o=r(Qke," (FLAVA model)"),Qke.forEach(t),C5o=i(x),j_=n(x,"LI",{});var Hke=s(j_);Lme=n(Hke,"STRONG",{});var Vvt=s(Lme);w5o=r(Vvt,"fnet"),Vvt.forEach(t),A5o=r(Hke," \u2014 "),ND=n(Hke,"A",{href:!0});var Xvt=s(ND);L5o=r(Xvt,"FNetModel"),Xvt.forEach(t),y5o=r(Hke," (FNet model)"),Hke.forEach(t),x5o=i(x),D_=n(x,"LI",{});var Uke=s(D_);yme=n(Uke,"STRONG",{});var zvt=s(yme);$5o=r(zvt,"fsmt"),zvt.forEach(t),k5o=r(Uke," \u2014 "),qD=n(Uke,"A",{href:!0});var Wvt=s(qD);S5o=r(Wvt,"FSMTModel"),Wvt.forEach(t),R5o=r(Uke," (FairSeq Machine-Translation model)"),Uke.forEach(t),P5o=i(x),ol=n(x,"LI",{});var LR=s(ol);xme=n(LR,"STRONG",{});var Qvt=s(xme);B5o=r(Qvt,"funnel"),Qvt.forEach(t),I5o=r(LR," \u2014 "),jD=n(LR,"A",{href:!0});var Hvt=s(jD);N5o=r(Hvt,"FunnelModel"),Hvt.forEach(t),q5o=r(LR," or "),DD=n(LR,"A",{href:!0});var Uvt=s(DD);j5o=r(Uvt,"FunnelBaseModel"),Uvt.forEach(t),D5o=r(LR," (Funnel Transformer model)"),LR.forEach(t),G5o=i(x),G_=n(x,"LI",{});var Jke=s(G_);$me=n(Jke,"STRONG",{});var Jvt=s($me);O5o=r(Jvt,"glpn"),Jvt.forEach(t),V5o=r(Jke," \u2014 "),GD=n(Jke,"A",{href:!0});var Yvt=s(GD);X5o=r(Yvt,"GLPNModel"),Yvt.forEach(t),z5o=r(Jke," (GLPN model)"),Jke.forEach(t),W5o=i(x),O_=n(x,"LI",{});var Yke=s(O_);kme=n(Yke,"STRONG",{});var Kvt=s(kme);Q5o=r(Kvt,"gpt2"),Kvt.forEach(t),H5o=r(Yke," \u2014 "),OD=n(Yke,"A",{href:!0});var Zvt=s(OD);U5o=r(Zvt,"GPT2Model"),Zvt.forEach(t),J5o=r(Yke," (OpenAI GPT-2 model)"),Yke.forEach(t),Y5o=i(x),V_=n(x,"LI",{});var Kke=s(V_);Sme=n(Kke,"STRONG",{});var e0t=s(Sme);K5o=r(e0t,"gpt_neo"),e0t.forEach(t),Z5o=r(Kke," \u2014 "),VD=n(Kke,"A",{href:!0});var o0t=s(VD);e3o=r(o0t,"GPTNeoModel"),o0t.forEach(t),o3o=r(Kke," (GPT Neo model)"),Kke.forEach(t),r3o=i(x),X_=n(x,"LI",{});var Zke=s(X_);Rme=n(Zke,"STRONG",{});var r0t=s(Rme);t3o=r(r0t,"gpt_neox"),r0t.forEach(t),a3o=r(Zke," \u2014 "),XD=n(Zke,"A",{href:!0});var t0t=s(XD);n3o=r(t0t,"GPTNeoXModel"),t0t.forEach(t),s3o=r(Zke," (GPT NeoX model)"),Zke.forEach(t),l3o=i(x),z_=n(x,"LI",{});var eSe=s(z_);Pme=n(eSe,"STRONG",{});var a0t=s(Pme);i3o=r(a0t,"gptj"),a0t.forEach(t),d3o=r(eSe," \u2014 "),zD=n(eSe,"A",{href:!0});var n0t=s(zD);c3o=r(n0t,"GPTJModel"),n0t.forEach(t),f3o=r(eSe," (GPT-J model)"),eSe.forEach(t),m3o=i(x),W_=n(x,"LI",{});var oSe=s(W_);Bme=n(oSe,"STRONG",{});var s0t=s(Bme);g3o=r(s0t,"groupvit"),s0t.forEach(t),h3o=r(oSe," \u2014 "),WD=n(oSe,"A",{href:!0});var l0t=s(WD);p3o=r(l0t,"GroupViTModel"),l0t.forEach(t),_3o=r(oSe," (GroupViT model)"),oSe.forEach(t),u3o=i(x),Q_=n(x,"LI",{});var rSe=s(Q_);Ime=n(rSe,"STRONG",{});var i0t=s(Ime);b3o=r(i0t,"hubert"),i0t.forEach(t),v3o=r(rSe," \u2014 "),QD=n(rSe,"A",{href:!0});var d0t=s(QD);F3o=r(d0t,"HubertModel"),d0t.forEach(t),T3o=r(rSe," (Hubert model)"),rSe.forEach(t),M3o=i(x),H_=n(x,"LI",{});var tSe=s(H_);Nme=n(tSe,"STRONG",{});var c0t=s(Nme);E3o=r(c0t,"ibert"),c0t.forEach(t),C3o=r(tSe," \u2014 "),HD=n(tSe,"A",{href:!0});var f0t=s(HD);w3o=r(f0t,"IBertModel"),f0t.forEach(t),A3o=r(tSe," (I-BERT model)"),tSe.forEach(t),L3o=i(x),U_=n(x,"LI",{});var aSe=s(U_);qme=n(aSe,"STRONG",{});var m0t=s(qme);y3o=r(m0t,"imagegpt"),m0t.forEach(t),x3o=r(aSe," \u2014 "),UD=n(aSe,"A",{href:!0});var g0t=s(UD);$3o=r(g0t,"ImageGPTModel"),g0t.forEach(t),k3o=r(aSe," (ImageGPT model)"),aSe.forEach(t),S3o=i(x),J_=n(x,"LI",{});var nSe=s(J_);jme=n(nSe,"STRONG",{});var h0t=s(jme);R3o=r(h0t,"layoutlm"),h0t.forEach(t),P3o=r(nSe," \u2014 "),JD=n(nSe,"A",{href:!0});var p0t=s(JD);B3o=r(p0t,"LayoutLMModel"),p0t.forEach(t),I3o=r(nSe," (LayoutLM model)"),nSe.forEach(t),N3o=i(x),Y_=n(x,"LI",{});var sSe=s(Y_);Dme=n(sSe,"STRONG",{});var _0t=s(Dme);q3o=r(_0t,"layoutlmv2"),_0t.forEach(t),j3o=r(sSe," \u2014 "),YD=n(sSe,"A",{href:!0});var u0t=s(YD);D3o=r(u0t,"LayoutLMv2Model"),u0t.forEach(t),G3o=r(sSe," (LayoutLMv2 model)"),sSe.forEach(t),O3o=i(x),K_=n(x,"LI",{});var lSe=s(K_);Gme=n(lSe,"STRONG",{});var b0t=s(Gme);V3o=r(b0t,"layoutlmv3"),b0t.forEach(t),X3o=r(lSe," \u2014 "),KD=n(lSe,"A",{href:!0});var v0t=s(KD);z3o=r(v0t,"LayoutLMv3Model"),v0t.forEach(t),W3o=r(lSe," (LayoutLMv3 model)"),lSe.forEach(t),Q3o=i(x),Z_=n(x,"LI",{});var iSe=s(Z_);Ome=n(iSe,"STRONG",{});var F0t=s(Ome);H3o=r(F0t,"led"),F0t.forEach(t),U3o=r(iSe," \u2014 "),ZD=n(iSe,"A",{href:!0});var T0t=s(ZD);J3o=r(T0t,"LEDModel"),T0t.forEach(t),Y3o=r(iSe," (LED model)"),iSe.forEach(t),K3o=i(x),eu=n(x,"LI",{});var dSe=s(eu);Vme=n(dSe,"STRONG",{});var M0t=s(Vme);Z3o=r(M0t,"levit"),M0t.forEach(t),ewo=r(dSe," \u2014 "),eG=n(dSe,"A",{href:!0});var E0t=s(eG);owo=r(E0t,"LevitModel"),E0t.forEach(t),rwo=r(dSe," (LeViT model)"),dSe.forEach(t),two=i(x),ou=n(x,"LI",{});var cSe=s(ou);Xme=n(cSe,"STRONG",{});var C0t=s(Xme);awo=r(C0t,"longformer"),C0t.forEach(t),nwo=r(cSe," \u2014 "),oG=n(cSe,"A",{href:!0});var w0t=s(oG);swo=r(w0t,"LongformerModel"),w0t.forEach(t),lwo=r(cSe," (Longformer model)"),cSe.forEach(t),iwo=i(x),ru=n(x,"LI",{});var fSe=s(ru);zme=n(fSe,"STRONG",{});var A0t=s(zme);dwo=r(A0t,"longt5"),A0t.forEach(t),cwo=r(fSe," \u2014 "),rG=n(fSe,"A",{href:!0});var L0t=s(rG);fwo=r(L0t,"LongT5Model"),L0t.forEach(t),mwo=r(fSe," (LongT5 model)"),fSe.forEach(t),gwo=i(x),tu=n(x,"LI",{});var mSe=s(tu);Wme=n(mSe,"STRONG",{});var y0t=s(Wme);hwo=r(y0t,"luke"),y0t.forEach(t),pwo=r(mSe," \u2014 "),tG=n(mSe,"A",{href:!0});var x0t=s(tG);_wo=r(x0t,"LukeModel"),x0t.forEach(t),uwo=r(mSe," (LUKE model)"),mSe.forEach(t),bwo=i(x),au=n(x,"LI",{});var gSe=s(au);Qme=n(gSe,"STRONG",{});var $0t=s(Qme);vwo=r($0t,"lxmert"),$0t.forEach(t),Fwo=r(gSe," \u2014 "),aG=n(gSe,"A",{href:!0});var k0t=s(aG);Two=r(k0t,"LxmertModel"),k0t.forEach(t),Mwo=r(gSe," (LXMERT model)"),gSe.forEach(t),Ewo=i(x),nu=n(x,"LI",{});var hSe=s(nu);Hme=n(hSe,"STRONG",{});var S0t=s(Hme);Cwo=r(S0t,"m2m_100"),S0t.forEach(t),wwo=r(hSe," \u2014 "),nG=n(hSe,"A",{href:!0});var R0t=s(nG);Awo=r(R0t,"M2M100Model"),R0t.forEach(t),Lwo=r(hSe," (M2M100 model)"),hSe.forEach(t),ywo=i(x),su=n(x,"LI",{});var pSe=s(su);Ume=n(pSe,"STRONG",{});var P0t=s(Ume);xwo=r(P0t,"marian"),P0t.forEach(t),$wo=r(pSe," \u2014 "),sG=n(pSe,"A",{href:!0});var B0t=s(sG);kwo=r(B0t,"MarianModel"),B0t.forEach(t),Swo=r(pSe," (Marian model)"),pSe.forEach(t),Rwo=i(x),lu=n(x,"LI",{});var _Se=s(lu);Jme=n(_Se,"STRONG",{});var I0t=s(Jme);Pwo=r(I0t,"maskformer"),I0t.forEach(t),Bwo=r(_Se," \u2014 "),lG=n(_Se,"A",{href:!0});var N0t=s(lG);Iwo=r(N0t,"MaskFormerModel"),N0t.forEach(t),Nwo=r(_Se," (MaskFormer model)"),_Se.forEach(t),qwo=i(x),iu=n(x,"LI",{});var uSe=s(iu);Yme=n(uSe,"STRONG",{});var q0t=s(Yme);jwo=r(q0t,"mbart"),q0t.forEach(t),Dwo=r(uSe," \u2014 "),iG=n(uSe,"A",{href:!0});var j0t=s(iG);Gwo=r(j0t,"MBartModel"),j0t.forEach(t),Owo=r(uSe," (mBART model)"),uSe.forEach(t),Vwo=i(x),du=n(x,"LI",{});var bSe=s(du);Kme=n(bSe,"STRONG",{});var D0t=s(Kme);Xwo=r(D0t,"mctct"),D0t.forEach(t),zwo=r(bSe," \u2014 "),dG=n(bSe,"A",{href:!0});var G0t=s(dG);Wwo=r(G0t,"MCTCTModel"),G0t.forEach(t),Qwo=r(bSe," (M-CTC-T model)"),bSe.forEach(t),Hwo=i(x),cu=n(x,"LI",{});var vSe=s(cu);Zme=n(vSe,"STRONG",{});var O0t=s(Zme);Uwo=r(O0t,"megatron-bert"),O0t.forEach(t),Jwo=r(vSe," \u2014 "),cG=n(vSe,"A",{href:!0});var V0t=s(cG);Ywo=r(V0t,"MegatronBertModel"),V0t.forEach(t),Kwo=r(vSe," (Megatron-BERT model)"),vSe.forEach(t),Zwo=i(x),fu=n(x,"LI",{});var FSe=s(fu);ege=n(FSe,"STRONG",{});var X0t=s(ege);e6o=r(X0t,"mobilebert"),X0t.forEach(t),o6o=r(FSe," \u2014 "),fG=n(FSe,"A",{href:!0});var z0t=s(fG);r6o=r(z0t,"MobileBertModel"),z0t.forEach(t),t6o=r(FSe," (MobileBERT model)"),FSe.forEach(t),a6o=i(x),mu=n(x,"LI",{});var TSe=s(mu);oge=n(TSe,"STRONG",{});var W0t=s(oge);n6o=r(W0t,"mobilevit"),W0t.forEach(t),s6o=r(TSe," \u2014 "),mG=n(TSe,"A",{href:!0});var Q0t=s(mG);l6o=r(Q0t,"MobileViTModel"),Q0t.forEach(t),i6o=r(TSe," (MobileViT model)"),TSe.forEach(t),d6o=i(x),gu=n(x,"LI",{});var MSe=s(gu);rge=n(MSe,"STRONG",{});var H0t=s(rge);c6o=r(H0t,"mpnet"),H0t.forEach(t),f6o=r(MSe," \u2014 "),gG=n(MSe,"A",{href:!0});var U0t=s(gG);m6o=r(U0t,"MPNetModel"),U0t.forEach(t),g6o=r(MSe," (MPNet model)"),MSe.forEach(t),h6o=i(x),hu=n(x,"LI",{});var ESe=s(hu);tge=n(ESe,"STRONG",{});var J0t=s(tge);p6o=r(J0t,"mt5"),J0t.forEach(t),_6o=r(ESe," \u2014 "),hG=n(ESe,"A",{href:!0});var Y0t=s(hG);u6o=r(Y0t,"MT5Model"),Y0t.forEach(t),b6o=r(ESe," (MT5 model)"),ESe.forEach(t),v6o=i(x),pu=n(x,"LI",{});var CSe=s(pu);age=n(CSe,"STRONG",{});var K0t=s(age);F6o=r(K0t,"mvp"),K0t.forEach(t),T6o=r(CSe," \u2014 "),pG=n(CSe,"A",{href:!0});var Z0t=s(pG);M6o=r(Z0t,"MvpModel"),Z0t.forEach(t),E6o=r(CSe," (MVP model)"),CSe.forEach(t),C6o=i(x),_u=n(x,"LI",{});var wSe=s(_u);nge=n(wSe,"STRONG",{});var eFt=s(nge);w6o=r(eFt,"nezha"),eFt.forEach(t),A6o=r(wSe," \u2014 "),_G=n(wSe,"A",{href:!0});var oFt=s(_G);L6o=r(oFt,"NezhaModel"),oFt.forEach(t),y6o=r(wSe," (Nezha model)"),wSe.forEach(t),x6o=i(x),uu=n(x,"LI",{});var ASe=s(uu);sge=n(ASe,"STRONG",{});var rFt=s(sge);$6o=r(rFt,"nllb"),rFt.forEach(t),k6o=r(ASe," \u2014 "),uG=n(ASe,"A",{href:!0});var tFt=s(uG);S6o=r(tFt,"M2M100Model"),tFt.forEach(t),R6o=r(ASe," (NLLB model)"),ASe.forEach(t),P6o=i(x),bu=n(x,"LI",{});var LSe=s(bu);lge=n(LSe,"STRONG",{});var aFt=s(lge);B6o=r(aFt,"nystromformer"),aFt.forEach(t),I6o=r(LSe," \u2014 "),bG=n(LSe,"A",{href:!0});var nFt=s(bG);N6o=r(nFt,"NystromformerModel"),nFt.forEach(t),q6o=r(LSe," (Nystr\xF6mformer model)"),LSe.forEach(t),j6o=i(x),vu=n(x,"LI",{});var ySe=s(vu);ige=n(ySe,"STRONG",{});var sFt=s(ige);D6o=r(sFt,"openai-gpt"),sFt.forEach(t),G6o=r(ySe," \u2014 "),vG=n(ySe,"A",{href:!0});var lFt=s(vG);O6o=r(lFt,"OpenAIGPTModel"),lFt.forEach(t),V6o=r(ySe," (OpenAI GPT model)"),ySe.forEach(t),X6o=i(x),Fu=n(x,"LI",{});var xSe=s(Fu);dge=n(xSe,"STRONG",{});var iFt=s(dge);z6o=r(iFt,"opt"),iFt.forEach(t),W6o=r(xSe," \u2014 "),FG=n(xSe,"A",{href:!0});var dFt=s(FG);Q6o=r(dFt,"OPTModel"),dFt.forEach(t),H6o=r(xSe," (OPT model)"),xSe.forEach(t),U6o=i(x),Tu=n(x,"LI",{});var $Se=s(Tu);cge=n($Se,"STRONG",{});var cFt=s(cge);J6o=r(cFt,"owlvit"),cFt.forEach(t),Y6o=r($Se," \u2014 "),TG=n($Se,"A",{href:!0});var fFt=s(TG);K6o=r(fFt,"OwlViTModel"),fFt.forEach(t),Z6o=r($Se," (OWL-ViT model)"),$Se.forEach(t),eAo=i(x),Mu=n(x,"LI",{});var kSe=s(Mu);fge=n(kSe,"STRONG",{});var mFt=s(fge);oAo=r(mFt,"pegasus"),mFt.forEach(t),rAo=r(kSe," \u2014 "),MG=n(kSe,"A",{href:!0});var gFt=s(MG);tAo=r(gFt,"PegasusModel"),gFt.forEach(t),aAo=r(kSe," (Pegasus model)"),kSe.forEach(t),nAo=i(x),Eu=n(x,"LI",{});var SSe=s(Eu);mge=n(SSe,"STRONG",{});var hFt=s(mge);sAo=r(hFt,"perceiver"),hFt.forEach(t),lAo=r(SSe," \u2014 "),EG=n(SSe,"A",{href:!0});var pFt=s(EG);iAo=r(pFt,"PerceiverModel"),pFt.forEach(t),dAo=r(SSe," (Perceiver model)"),SSe.forEach(t),cAo=i(x),Cu=n(x,"LI",{});var RSe=s(Cu);gge=n(RSe,"STRONG",{});var _Ft=s(gge);fAo=r(_Ft,"plbart"),_Ft.forEach(t),mAo=r(RSe," \u2014 "),CG=n(RSe,"A",{href:!0});var uFt=s(CG);gAo=r(uFt,"PLBartModel"),uFt.forEach(t),hAo=r(RSe," (PLBart model)"),RSe.forEach(t),pAo=i(x),wu=n(x,"LI",{});var PSe=s(wu);hge=n(PSe,"STRONG",{});var bFt=s(hge);_Ao=r(bFt,"poolformer"),bFt.forEach(t),uAo=r(PSe," \u2014 "),wG=n(PSe,"A",{href:!0});var vFt=s(wG);bAo=r(vFt,"PoolFormerModel"),vFt.forEach(t),vAo=r(PSe," (PoolFormer model)"),PSe.forEach(t),FAo=i(x),Au=n(x,"LI",{});var BSe=s(Au);pge=n(BSe,"STRONG",{});var FFt=s(pge);TAo=r(FFt,"prophetnet"),FFt.forEach(t),MAo=r(BSe," \u2014 "),AG=n(BSe,"A",{href:!0});var TFt=s(AG);EAo=r(TFt,"ProphetNetModel"),TFt.forEach(t),CAo=r(BSe," (ProphetNet model)"),BSe.forEach(t),wAo=i(x),Lu=n(x,"LI",{});var ISe=s(Lu);_ge=n(ISe,"STRONG",{});var MFt=s(_ge);AAo=r(MFt,"qdqbert"),MFt.forEach(t),LAo=r(ISe," \u2014 "),LG=n(ISe,"A",{href:!0});var EFt=s(LG);yAo=r(EFt,"QDQBertModel"),EFt.forEach(t),xAo=r(ISe," (QDQBert model)"),ISe.forEach(t),$Ao=i(x),yu=n(x,"LI",{});var NSe=s(yu);uge=n(NSe,"STRONG",{});var CFt=s(uge);kAo=r(CFt,"reformer"),CFt.forEach(t),SAo=r(NSe," \u2014 "),yG=n(NSe,"A",{href:!0});var wFt=s(yG);RAo=r(wFt,"ReformerModel"),wFt.forEach(t),PAo=r(NSe," (Reformer model)"),NSe.forEach(t),BAo=i(x),xu=n(x,"LI",{});var qSe=s(xu);bge=n(qSe,"STRONG",{});var AFt=s(bge);IAo=r(AFt,"regnet"),AFt.forEach(t),NAo=r(qSe," \u2014 "),xG=n(qSe,"A",{href:!0});var LFt=s(xG);qAo=r(LFt,"RegNetModel"),LFt.forEach(t),jAo=r(qSe," (RegNet model)"),qSe.forEach(t),DAo=i(x),$u=n(x,"LI",{});var jSe=s($u);vge=n(jSe,"STRONG",{});var yFt=s(vge);GAo=r(yFt,"rembert"),yFt.forEach(t),OAo=r(jSe," \u2014 "),$G=n(jSe,"A",{href:!0});var xFt=s($G);VAo=r(xFt,"RemBertModel"),xFt.forEach(t),XAo=r(jSe," (RemBERT model)"),jSe.forEach(t),zAo=i(x),ku=n(x,"LI",{});var DSe=s(ku);Fge=n(DSe,"STRONG",{});var $Ft=s(Fge);WAo=r($Ft,"resnet"),$Ft.forEach(t),QAo=r(DSe," \u2014 "),kG=n(DSe,"A",{href:!0});var kFt=s(kG);HAo=r(kFt,"ResNetModel"),kFt.forEach(t),UAo=r(DSe," (ResNet model)"),DSe.forEach(t),JAo=i(x),Su=n(x,"LI",{});var GSe=s(Su);Tge=n(GSe,"STRONG",{});var SFt=s(Tge);YAo=r(SFt,"retribert"),SFt.forEach(t),KAo=r(GSe," \u2014 "),SG=n(GSe,"A",{href:!0});var RFt=s(SG);ZAo=r(RFt,"RetriBertModel"),RFt.forEach(t),e7o=r(GSe," (RetriBERT model)"),GSe.forEach(t),o7o=i(x),Ru=n(x,"LI",{});var OSe=s(Ru);Mge=n(OSe,"STRONG",{});var PFt=s(Mge);r7o=r(PFt,"roberta"),PFt.forEach(t),t7o=r(OSe," \u2014 "),RG=n(OSe,"A",{href:!0});var BFt=s(RG);a7o=r(BFt,"RobertaModel"),BFt.forEach(t),n7o=r(OSe," (RoBERTa model)"),OSe.forEach(t),s7o=i(x),Pu=n(x,"LI",{});var VSe=s(Pu);Ege=n(VSe,"STRONG",{});var IFt=s(Ege);l7o=r(IFt,"roformer"),IFt.forEach(t),i7o=r(VSe," \u2014 "),PG=n(VSe,"A",{href:!0});var NFt=s(PG);d7o=r(NFt,"RoFormerModel"),NFt.forEach(t),c7o=r(VSe," (RoFormer model)"),VSe.forEach(t),f7o=i(x),Bu=n(x,"LI",{});var XSe=s(Bu);Cge=n(XSe,"STRONG",{});var qFt=s(Cge);m7o=r(qFt,"segformer"),qFt.forEach(t),g7o=r(XSe," \u2014 "),BG=n(XSe,"A",{href:!0});var jFt=s(BG);h7o=r(jFt,"SegformerModel"),jFt.forEach(t),p7o=r(XSe," (SegFormer model)"),XSe.forEach(t),_7o=i(x),Iu=n(x,"LI",{});var zSe=s(Iu);wge=n(zSe,"STRONG",{});var DFt=s(wge);u7o=r(DFt,"sew"),DFt.forEach(t),b7o=r(zSe," \u2014 "),IG=n(zSe,"A",{href:!0});var GFt=s(IG);v7o=r(GFt,"SEWModel"),GFt.forEach(t),F7o=r(zSe," (SEW model)"),zSe.forEach(t),T7o=i(x),Nu=n(x,"LI",{});var WSe=s(Nu);Age=n(WSe,"STRONG",{});var OFt=s(Age);M7o=r(OFt,"sew-d"),OFt.forEach(t),E7o=r(WSe," \u2014 "),NG=n(WSe,"A",{href:!0});var VFt=s(NG);C7o=r(VFt,"SEWDModel"),VFt.forEach(t),w7o=r(WSe," (SEW-D model)"),WSe.forEach(t),A7o=i(x),qu=n(x,"LI",{});var QSe=s(qu);Lge=n(QSe,"STRONG",{});var XFt=s(Lge);L7o=r(XFt,"speech_to_text"),XFt.forEach(t),y7o=r(QSe," \u2014 "),qG=n(QSe,"A",{href:!0});var zFt=s(qG);x7o=r(zFt,"Speech2TextModel"),zFt.forEach(t),$7o=r(QSe," (Speech2Text model)"),QSe.forEach(t),k7o=i(x),ju=n(x,"LI",{});var HSe=s(ju);yge=n(HSe,"STRONG",{});var WFt=s(yge);S7o=r(WFt,"splinter"),WFt.forEach(t),R7o=r(HSe," \u2014 "),jG=n(HSe,"A",{href:!0});var QFt=s(jG);P7o=r(QFt,"SplinterModel"),QFt.forEach(t),B7o=r(HSe," (Splinter model)"),HSe.forEach(t),I7o=i(x),Du=n(x,"LI",{});var USe=s(Du);xge=n(USe,"STRONG",{});var HFt=s(xge);N7o=r(HFt,"squeezebert"),HFt.forEach(t),q7o=r(USe," \u2014 "),DG=n(USe,"A",{href:!0});var UFt=s(DG);j7o=r(UFt,"SqueezeBertModel"),UFt.forEach(t),D7o=r(USe," (SqueezeBERT model)"),USe.forEach(t),G7o=i(x),Gu=n(x,"LI",{});var JSe=s(Gu);$ge=n(JSe,"STRONG",{});var JFt=s($ge);O7o=r(JFt,"swin"),JFt.forEach(t),V7o=r(JSe," \u2014 "),GG=n(JSe,"A",{href:!0});var YFt=s(GG);X7o=r(YFt,"SwinModel"),YFt.forEach(t),z7o=r(JSe," (Swin Transformer model)"),JSe.forEach(t),W7o=i(x),Ou=n(x,"LI",{});var YSe=s(Ou);kge=n(YSe,"STRONG",{});var KFt=s(kge);Q7o=r(KFt,"swinv2"),KFt.forEach(t),H7o=r(YSe," \u2014 "),OG=n(YSe,"A",{href:!0});var ZFt=s(OG);U7o=r(ZFt,"Swinv2Model"),ZFt.forEach(t),J7o=r(YSe," (Swin Transformer V2 model)"),YSe.forEach(t),Y7o=i(x),Vu=n(x,"LI",{});var KSe=s(Vu);Sge=n(KSe,"STRONG",{});var eTt=s(Sge);K7o=r(eTt,"t5"),eTt.forEach(t),Z7o=r(KSe," \u2014 "),VG=n(KSe,"A",{href:!0});var oTt=s(VG);eLo=r(oTt,"T5Model"),oTt.forEach(t),oLo=r(KSe," (T5 model)"),KSe.forEach(t),rLo=i(x),Xu=n(x,"LI",{});var ZSe=s(Xu);Rge=n(ZSe,"STRONG",{});var rTt=s(Rge);tLo=r(rTt,"tapas"),rTt.forEach(t),aLo=r(ZSe," \u2014 "),XG=n(ZSe,"A",{href:!0});var tTt=s(XG);nLo=r(tTt,"TapasModel"),tTt.forEach(t),sLo=r(ZSe," (TAPAS model)"),ZSe.forEach(t),lLo=i(x),zu=n(x,"LI",{});var eRe=s(zu);Pge=n(eRe,"STRONG",{});var aTt=s(Pge);iLo=r(aTt,"trajectory_transformer"),aTt.forEach(t),dLo=r(eRe," \u2014 "),zG=n(eRe,"A",{href:!0});var nTt=s(zG);cLo=r(nTt,"TrajectoryTransformerModel"),nTt.forEach(t),fLo=r(eRe," (Trajectory Transformer model)"),eRe.forEach(t),mLo=i(x),Wu=n(x,"LI",{});var oRe=s(Wu);Bge=n(oRe,"STRONG",{});var sTt=s(Bge);gLo=r(sTt,"transfo-xl"),sTt.forEach(t),hLo=r(oRe," \u2014 "),WG=n(oRe,"A",{href:!0});var lTt=s(WG);pLo=r(lTt,"TransfoXLModel"),lTt.forEach(t),_Lo=r(oRe," (Transformer-XL model)"),oRe.forEach(t),uLo=i(x),Qu=n(x,"LI",{});var rRe=s(Qu);Ige=n(rRe,"STRONG",{});var iTt=s(Ige);bLo=r(iTt,"unispeech"),iTt.forEach(t),vLo=r(rRe," \u2014 "),QG=n(rRe,"A",{href:!0});var dTt=s(QG);FLo=r(dTt,"UniSpeechModel"),dTt.forEach(t),TLo=r(rRe," (UniSpeech model)"),rRe.forEach(t),MLo=i(x),Hu=n(x,"LI",{});var tRe=s(Hu);Nge=n(tRe,"STRONG",{});var cTt=s(Nge);ELo=r(cTt,"unispeech-sat"),cTt.forEach(t),CLo=r(tRe," \u2014 "),HG=n(tRe,"A",{href:!0});var fTt=s(HG);wLo=r(fTt,"UniSpeechSatModel"),fTt.forEach(t),ALo=r(tRe," (UniSpeechSat model)"),tRe.forEach(t),LLo=i(x),Uu=n(x,"LI",{});var aRe=s(Uu);qge=n(aRe,"STRONG",{});var mTt=s(qge);yLo=r(mTt,"van"),mTt.forEach(t),xLo=r(aRe," \u2014 "),UG=n(aRe,"A",{href:!0});var gTt=s(UG);$Lo=r(gTt,"VanModel"),gTt.forEach(t),kLo=r(aRe," (VAN model)"),aRe.forEach(t),SLo=i(x),Ju=n(x,"LI",{});var nRe=s(Ju);jge=n(nRe,"STRONG",{});var hTt=s(jge);RLo=r(hTt,"videomae"),hTt.forEach(t),PLo=r(nRe," \u2014 "),JG=n(nRe,"A",{href:!0});var pTt=s(JG);BLo=r(pTt,"VideoMAEModel"),pTt.forEach(t),ILo=r(nRe," (VideoMAE model)"),nRe.forEach(t),NLo=i(x),Yu=n(x,"LI",{});var sRe=s(Yu);Dge=n(sRe,"STRONG",{});var _Tt=s(Dge);qLo=r(_Tt,"vilt"),_Tt.forEach(t),jLo=r(sRe," \u2014 "),YG=n(sRe,"A",{href:!0});var uTt=s(YG);DLo=r(uTt,"ViltModel"),uTt.forEach(t),GLo=r(sRe," (ViLT model)"),sRe.forEach(t),OLo=i(x),Ku=n(x,"LI",{});var lRe=s(Ku);Gge=n(lRe,"STRONG",{});var bTt=s(Gge);VLo=r(bTt,"vision-text-dual-encoder"),bTt.forEach(t),XLo=r(lRe," \u2014 "),KG=n(lRe,"A",{href:!0});var vTt=s(KG);zLo=r(vTt,"VisionTextDualEncoderModel"),vTt.forEach(t),WLo=r(lRe," (VisionTextDualEncoder model)"),lRe.forEach(t),QLo=i(x),Zu=n(x,"LI",{});var iRe=s(Zu);Oge=n(iRe,"STRONG",{});var FTt=s(Oge);HLo=r(FTt,"visual_bert"),FTt.forEach(t),ULo=r(iRe," \u2014 "),ZG=n(iRe,"A",{href:!0});var TTt=s(ZG);JLo=r(TTt,"VisualBertModel"),TTt.forEach(t),YLo=r(iRe," (VisualBERT model)"),iRe.forEach(t),KLo=i(x),e2=n(x,"LI",{});var dRe=s(e2);Vge=n(dRe,"STRONG",{});var MTt=s(Vge);ZLo=r(MTt,"vit"),MTt.forEach(t),eyo=r(dRe," \u2014 "),eO=n(dRe,"A",{href:!0});var ETt=s(eO);oyo=r(ETt,"ViTModel"),ETt.forEach(t),ryo=r(dRe," (ViT model)"),dRe.forEach(t),tyo=i(x),o2=n(x,"LI",{});var cRe=s(o2);Xge=n(cRe,"STRONG",{});var CTt=s(Xge);ayo=r(CTt,"vit_mae"),CTt.forEach(t),nyo=r(cRe," \u2014 "),oO=n(cRe,"A",{href:!0});var wTt=s(oO);syo=r(wTt,"ViTMAEModel"),wTt.forEach(t),lyo=r(cRe," (ViTMAE model)"),cRe.forEach(t),iyo=i(x),r2=n(x,"LI",{});var fRe=s(r2);zge=n(fRe,"STRONG",{});var ATt=s(zge);dyo=r(ATt,"wav2vec2"),ATt.forEach(t),cyo=r(fRe," \u2014 "),rO=n(fRe,"A",{href:!0});var LTt=s(rO);fyo=r(LTt,"Wav2Vec2Model"),LTt.forEach(t),myo=r(fRe," (Wav2Vec2 model)"),fRe.forEach(t),gyo=i(x),t2=n(x,"LI",{});var mRe=s(t2);Wge=n(mRe,"STRONG",{});var yTt=s(Wge);hyo=r(yTt,"wav2vec2-conformer"),yTt.forEach(t),pyo=r(mRe," \u2014 "),tO=n(mRe,"A",{href:!0});var xTt=s(tO);_yo=r(xTt,"Wav2Vec2ConformerModel"),xTt.forEach(t),uyo=r(mRe," (Wav2Vec2-Conformer model)"),mRe.forEach(t),byo=i(x),a2=n(x,"LI",{});var gRe=s(a2);Qge=n(gRe,"STRONG",{});var $Tt=s(Qge);vyo=r($Tt,"wavlm"),$Tt.forEach(t),Fyo=r(gRe," \u2014 "),aO=n(gRe,"A",{href:!0});var kTt=s(aO);Tyo=r(kTt,"WavLMModel"),kTt.forEach(t),Myo=r(gRe," (WavLM model)"),gRe.forEach(t),Eyo=i(x),n2=n(x,"LI",{});var hRe=s(n2);Hge=n(hRe,"STRONG",{});var STt=s(Hge);Cyo=r(STt,"xglm"),STt.forEach(t),wyo=r(hRe," \u2014 "),nO=n(hRe,"A",{href:!0});var RTt=s(nO);Ayo=r(RTt,"XGLMModel"),RTt.forEach(t),Lyo=r(hRe," (XGLM model)"),hRe.forEach(t),yyo=i(x),s2=n(x,"LI",{});var pRe=s(s2);Uge=n(pRe,"STRONG",{});var PTt=s(Uge);xyo=r(PTt,"xlm"),PTt.forEach(t),$yo=r(pRe," \u2014 "),sO=n(pRe,"A",{href:!0});var BTt=s(sO);kyo=r(BTt,"XLMModel"),BTt.forEach(t),Syo=r(pRe," (XLM model)"),pRe.forEach(t),Ryo=i(x),l2=n(x,"LI",{});var _Re=s(l2);Jge=n(_Re,"STRONG",{});var ITt=s(Jge);Pyo=r(ITt,"xlm-prophetnet"),ITt.forEach(t),Byo=r(_Re," \u2014 "),lO=n(_Re,"A",{href:!0});var NTt=s(lO);Iyo=r(NTt,"XLMProphetNetModel"),NTt.forEach(t),Nyo=r(_Re," (XLM-ProphetNet model)"),_Re.forEach(t),qyo=i(x),i2=n(x,"LI",{});var uRe=s(i2);Yge=n(uRe,"STRONG",{});var qTt=s(Yge);jyo=r(qTt,"xlm-roberta"),qTt.forEach(t),Dyo=r(uRe," \u2014 "),iO=n(uRe,"A",{href:!0});var jTt=s(iO);Gyo=r(jTt,"XLMRobertaModel"),jTt.forEach(t),Oyo=r(uRe," (XLM-RoBERTa model)"),uRe.forEach(t),Vyo=i(x),d2=n(x,"LI",{});var bRe=s(d2);Kge=n(bRe,"STRONG",{});var DTt=s(Kge);Xyo=r(DTt,"xlm-roberta-xl"),DTt.forEach(t),zyo=r(bRe," \u2014 "),dO=n(bRe,"A",{href:!0});var GTt=s(dO);Wyo=r(GTt,"XLMRobertaXLModel"),GTt.forEach(t),Qyo=r(bRe," (XLM-RoBERTa-XL model)"),bRe.forEach(t),Hyo=i(x),c2=n(x,"LI",{});var vRe=s(c2);Zge=n(vRe,"STRONG",{});var OTt=s(Zge);Uyo=r(OTt,"xlnet"),OTt.forEach(t),Jyo=r(vRe," \u2014 "),cO=n(vRe,"A",{href:!0});var VTt=s(cO);Yyo=r(VTt,"XLNetModel"),VTt.forEach(t),Kyo=r(vRe," (XLNet model)"),vRe.forEach(t),Zyo=i(x),f2=n(x,"LI",{});var FRe=s(f2);ehe=n(FRe,"STRONG",{});var XTt=s(ehe);e9o=r(XTt,"yolos"),XTt.forEach(t),o9o=r(FRe," \u2014 "),fO=n(FRe,"A",{href:!0});var zTt=s(fO);r9o=r(zTt,"YolosModel"),zTt.forEach(t),t9o=r(FRe," (YOLOS model)"),FRe.forEach(t),a9o=i(x),m2=n(x,"LI",{});var TRe=s(m2);ohe=n(TRe,"STRONG",{});var WTt=s(ohe);n9o=r(WTt,"yoso"),WTt.forEach(t),s9o=r(TRe," \u2014 "),mO=n(TRe,"A",{href:!0});var QTt=s(mO);l9o=r(QTt,"YosoModel"),QTt.forEach(t),i9o=r(TRe," (YOSO model)"),TRe.forEach(t),x.forEach(t),d9o=i(ca),g2=n(ca,"P",{});var MRe=s(g2);c9o=r(MRe,"The model is set in evaluation mode by default using "),rhe=n(MRe,"CODE",{});var HTt=s(rhe);f9o=r(HTt,"model.eval()"),HTt.forEach(t),m9o=r(MRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),the=n(MRe,"CODE",{});var UTt=s(the);g9o=r(UTt,"model.train()"),UTt.forEach(t),MRe.forEach(t),h9o=i(ca),T(h2.$$.fragment,ca),ca.forEach(t),cl.forEach(t),aQe=i(f),Zi=n(f,"H2",{class:!0});var mUe=s(Zi);p2=n(mUe,"A",{id:!0,class:!0,href:!0});var JTt=s(p2);ahe=n(JTt,"SPAN",{});var YTt=s(ahe);T(wy.$$.fragment,YTt),YTt.forEach(t),JTt.forEach(t),p9o=i(mUe),nhe=n(mUe,"SPAN",{});var KTt=s(nhe);_9o=r(KTt,"AutoModelForPreTraining"),KTt.forEach(t),mUe.forEach(t),nQe=i(f),Ro=n(f,"DIV",{class:!0});var fl=s(Ro);T(Ay.$$.fragment,fl),u9o=i(fl),ed=n(fl,"P",{});var cae=s(ed);b9o=r(cae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),gO=n(cae,"A",{href:!0});var ZTt=s(gO);v9o=r(ZTt,"from_pretrained()"),ZTt.forEach(t),F9o=r(cae," class method or the "),hO=n(cae,"A",{href:!0});var e8t=s(hO);T9o=r(e8t,"from_config()"),e8t.forEach(t),M9o=r(cae,` class
method.`),cae.forEach(t),E9o=i(fl),Ly=n(fl,"P",{});var gUe=s(Ly);C9o=r(gUe,"This class cannot be instantiated directly using "),she=n(gUe,"CODE",{});var o8t=s(she);w9o=r(o8t,"__init__()"),o8t.forEach(t),A9o=r(gUe," (throws an error)."),gUe.forEach(t),L9o=i(fl),ft=n(fl,"DIV",{class:!0});var YA=s(ft);T(yy.$$.fragment,YA),y9o=i(YA),lhe=n(YA,"P",{});var r8t=s(lhe);x9o=r(r8t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),r8t.forEach(t),$9o=i(YA),od=n(YA,"P",{});var fae=s(od);k9o=r(fae,`Note:
Loading a model from its configuration file does `),ihe=n(fae,"STRONG",{});var t8t=s(ihe);S9o=r(t8t,"not"),t8t.forEach(t),R9o=r(fae,` load the model weights. It only affects the
model\u2019s configuration. Use `),pO=n(fae,"A",{href:!0});var a8t=s(pO);P9o=r(a8t,"from_pretrained()"),a8t.forEach(t),B9o=r(fae," to load the model weights."),fae.forEach(t),I9o=i(YA),T(_2.$$.fragment,YA),YA.forEach(t),N9o=i(fl),Ke=n(fl,"DIV",{class:!0});var fa=s(Ke);T(xy.$$.fragment,fa),q9o=i(fa),dhe=n(fa,"P",{});var n8t=s(dhe);j9o=r(n8t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),n8t.forEach(t),D9o=i(fa),Ga=n(fa,"P",{});var KA=s(Ga);G9o=r(KA,"The model class to instantiate is selected based on the "),che=n(KA,"CODE",{});var s8t=s(che);O9o=r(s8t,"model_type"),s8t.forEach(t),V9o=r(KA,` property of the config object (either
passed as an argument or loaded from `),fhe=n(KA,"CODE",{});var l8t=s(fhe);X9o=r(l8t,"pretrained_model_name_or_path"),l8t.forEach(t),z9o=r(KA,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),mhe=n(KA,"CODE",{});var i8t=s(mhe);W9o=r(i8t,"pretrained_model_name_or_path"),i8t.forEach(t),Q9o=r(KA,":"),KA.forEach(t),H9o=i(fa),G=n(fa,"UL",{});var O=s(G);u2=n(O,"LI",{});var ERe=s(u2);ghe=n(ERe,"STRONG",{});var d8t=s(ghe);U9o=r(d8t,"albert"),d8t.forEach(t),J9o=r(ERe," \u2014 "),_O=n(ERe,"A",{href:!0});var c8t=s(_O);Y9o=r(c8t,"AlbertForPreTraining"),c8t.forEach(t),K9o=r(ERe," (ALBERT model)"),ERe.forEach(t),Z9o=i(O),b2=n(O,"LI",{});var CRe=s(b2);hhe=n(CRe,"STRONG",{});var f8t=s(hhe);exo=r(f8t,"bart"),f8t.forEach(t),oxo=r(CRe," \u2014 "),uO=n(CRe,"A",{href:!0});var m8t=s(uO);rxo=r(m8t,"BartForConditionalGeneration"),m8t.forEach(t),txo=r(CRe," (BART model)"),CRe.forEach(t),axo=i(O),v2=n(O,"LI",{});var wRe=s(v2);phe=n(wRe,"STRONG",{});var g8t=s(phe);nxo=r(g8t,"bert"),g8t.forEach(t),sxo=r(wRe," \u2014 "),bO=n(wRe,"A",{href:!0});var h8t=s(bO);lxo=r(h8t,"BertForPreTraining"),h8t.forEach(t),ixo=r(wRe," (BERT model)"),wRe.forEach(t),dxo=i(O),F2=n(O,"LI",{});var ARe=s(F2);_he=n(ARe,"STRONG",{});var p8t=s(_he);cxo=r(p8t,"big_bird"),p8t.forEach(t),fxo=r(ARe," \u2014 "),vO=n(ARe,"A",{href:!0});var _8t=s(vO);mxo=r(_8t,"BigBirdForPreTraining"),_8t.forEach(t),gxo=r(ARe," (BigBird model)"),ARe.forEach(t),hxo=i(O),T2=n(O,"LI",{});var LRe=s(T2);uhe=n(LRe,"STRONG",{});var u8t=s(uhe);pxo=r(u8t,"bloom"),u8t.forEach(t),_xo=r(LRe," \u2014 "),FO=n(LRe,"A",{href:!0});var b8t=s(FO);uxo=r(b8t,"BloomForCausalLM"),b8t.forEach(t),bxo=r(LRe," (BLOOM model)"),LRe.forEach(t),vxo=i(O),M2=n(O,"LI",{});var yRe=s(M2);bhe=n(yRe,"STRONG",{});var v8t=s(bhe);Fxo=r(v8t,"camembert"),v8t.forEach(t),Txo=r(yRe," \u2014 "),TO=n(yRe,"A",{href:!0});var F8t=s(TO);Mxo=r(F8t,"CamembertForMaskedLM"),F8t.forEach(t),Exo=r(yRe," (CamemBERT model)"),yRe.forEach(t),Cxo=i(O),E2=n(O,"LI",{});var xRe=s(E2);vhe=n(xRe,"STRONG",{});var T8t=s(vhe);wxo=r(T8t,"ctrl"),T8t.forEach(t),Axo=r(xRe," \u2014 "),MO=n(xRe,"A",{href:!0});var M8t=s(MO);Lxo=r(M8t,"CTRLLMHeadModel"),M8t.forEach(t),yxo=r(xRe," (CTRL model)"),xRe.forEach(t),xxo=i(O),C2=n(O,"LI",{});var $Re=s(C2);Fhe=n($Re,"STRONG",{});var E8t=s(Fhe);$xo=r(E8t,"data2vec-text"),E8t.forEach(t),kxo=r($Re," \u2014 "),EO=n($Re,"A",{href:!0});var C8t=s(EO);Sxo=r(C8t,"Data2VecTextForMaskedLM"),C8t.forEach(t),Rxo=r($Re," (Data2VecText model)"),$Re.forEach(t),Pxo=i(O),w2=n(O,"LI",{});var kRe=s(w2);The=n(kRe,"STRONG",{});var w8t=s(The);Bxo=r(w8t,"deberta"),w8t.forEach(t),Ixo=r(kRe," \u2014 "),CO=n(kRe,"A",{href:!0});var A8t=s(CO);Nxo=r(A8t,"DebertaForMaskedLM"),A8t.forEach(t),qxo=r(kRe," (DeBERTa model)"),kRe.forEach(t),jxo=i(O),A2=n(O,"LI",{});var SRe=s(A2);Mhe=n(SRe,"STRONG",{});var L8t=s(Mhe);Dxo=r(L8t,"deberta-v2"),L8t.forEach(t),Gxo=r(SRe," \u2014 "),wO=n(SRe,"A",{href:!0});var y8t=s(wO);Oxo=r(y8t,"DebertaV2ForMaskedLM"),y8t.forEach(t),Vxo=r(SRe," (DeBERTa-v2 model)"),SRe.forEach(t),Xxo=i(O),L2=n(O,"LI",{});var RRe=s(L2);Ehe=n(RRe,"STRONG",{});var x8t=s(Ehe);zxo=r(x8t,"distilbert"),x8t.forEach(t),Wxo=r(RRe," \u2014 "),AO=n(RRe,"A",{href:!0});var $8t=s(AO);Qxo=r($8t,"DistilBertForMaskedLM"),$8t.forEach(t),Hxo=r(RRe," (DistilBERT model)"),RRe.forEach(t),Uxo=i(O),y2=n(O,"LI",{});var PRe=s(y2);Che=n(PRe,"STRONG",{});var k8t=s(Che);Jxo=r(k8t,"electra"),k8t.forEach(t),Yxo=r(PRe," \u2014 "),LO=n(PRe,"A",{href:!0});var S8t=s(LO);Kxo=r(S8t,"ElectraForPreTraining"),S8t.forEach(t),Zxo=r(PRe," (ELECTRA model)"),PRe.forEach(t),e$o=i(O),x2=n(O,"LI",{});var BRe=s(x2);whe=n(BRe,"STRONG",{});var R8t=s(whe);o$o=r(R8t,"flaubert"),R8t.forEach(t),r$o=r(BRe," \u2014 "),yO=n(BRe,"A",{href:!0});var P8t=s(yO);t$o=r(P8t,"FlaubertWithLMHeadModel"),P8t.forEach(t),a$o=r(BRe," (FlauBERT model)"),BRe.forEach(t),n$o=i(O),$2=n(O,"LI",{});var IRe=s($2);Ahe=n(IRe,"STRONG",{});var B8t=s(Ahe);s$o=r(B8t,"flava"),B8t.forEach(t),l$o=r(IRe," \u2014 "),xO=n(IRe,"A",{href:!0});var I8t=s(xO);i$o=r(I8t,"FlavaForPreTraining"),I8t.forEach(t),d$o=r(IRe," (FLAVA model)"),IRe.forEach(t),c$o=i(O),k2=n(O,"LI",{});var NRe=s(k2);Lhe=n(NRe,"STRONG",{});var N8t=s(Lhe);f$o=r(N8t,"fnet"),N8t.forEach(t),m$o=r(NRe," \u2014 "),$O=n(NRe,"A",{href:!0});var q8t=s($O);g$o=r(q8t,"FNetForPreTraining"),q8t.forEach(t),h$o=r(NRe," (FNet model)"),NRe.forEach(t),p$o=i(O),S2=n(O,"LI",{});var qRe=s(S2);yhe=n(qRe,"STRONG",{});var j8t=s(yhe);_$o=r(j8t,"fsmt"),j8t.forEach(t),u$o=r(qRe," \u2014 "),kO=n(qRe,"A",{href:!0});var D8t=s(kO);b$o=r(D8t,"FSMTForConditionalGeneration"),D8t.forEach(t),v$o=r(qRe," (FairSeq Machine-Translation model)"),qRe.forEach(t),F$o=i(O),R2=n(O,"LI",{});var jRe=s(R2);xhe=n(jRe,"STRONG",{});var G8t=s(xhe);T$o=r(G8t,"funnel"),G8t.forEach(t),M$o=r(jRe," \u2014 "),SO=n(jRe,"A",{href:!0});var O8t=s(SO);E$o=r(O8t,"FunnelForPreTraining"),O8t.forEach(t),C$o=r(jRe," (Funnel Transformer model)"),jRe.forEach(t),w$o=i(O),P2=n(O,"LI",{});var DRe=s(P2);$he=n(DRe,"STRONG",{});var V8t=s($he);A$o=r(V8t,"gpt2"),V8t.forEach(t),L$o=r(DRe," \u2014 "),RO=n(DRe,"A",{href:!0});var X8t=s(RO);y$o=r(X8t,"GPT2LMHeadModel"),X8t.forEach(t),x$o=r(DRe," (OpenAI GPT-2 model)"),DRe.forEach(t),$$o=i(O),B2=n(O,"LI",{});var GRe=s(B2);khe=n(GRe,"STRONG",{});var z8t=s(khe);k$o=r(z8t,"ibert"),z8t.forEach(t),S$o=r(GRe," \u2014 "),PO=n(GRe,"A",{href:!0});var W8t=s(PO);R$o=r(W8t,"IBertForMaskedLM"),W8t.forEach(t),P$o=r(GRe," (I-BERT model)"),GRe.forEach(t),B$o=i(O),I2=n(O,"LI",{});var ORe=s(I2);She=n(ORe,"STRONG",{});var Q8t=s(She);I$o=r(Q8t,"layoutlm"),Q8t.forEach(t),N$o=r(ORe," \u2014 "),BO=n(ORe,"A",{href:!0});var H8t=s(BO);q$o=r(H8t,"LayoutLMForMaskedLM"),H8t.forEach(t),j$o=r(ORe," (LayoutLM model)"),ORe.forEach(t),D$o=i(O),N2=n(O,"LI",{});var VRe=s(N2);Rhe=n(VRe,"STRONG",{});var U8t=s(Rhe);G$o=r(U8t,"longformer"),U8t.forEach(t),O$o=r(VRe," \u2014 "),IO=n(VRe,"A",{href:!0});var J8t=s(IO);V$o=r(J8t,"LongformerForMaskedLM"),J8t.forEach(t),X$o=r(VRe," (Longformer model)"),VRe.forEach(t),z$o=i(O),q2=n(O,"LI",{});var XRe=s(q2);Phe=n(XRe,"STRONG",{});var Y8t=s(Phe);W$o=r(Y8t,"luke"),Y8t.forEach(t),Q$o=r(XRe," \u2014 "),NO=n(XRe,"A",{href:!0});var K8t=s(NO);H$o=r(K8t,"LukeForMaskedLM"),K8t.forEach(t),U$o=r(XRe," (LUKE model)"),XRe.forEach(t),J$o=i(O),j2=n(O,"LI",{});var zRe=s(j2);Bhe=n(zRe,"STRONG",{});var Z8t=s(Bhe);Y$o=r(Z8t,"lxmert"),Z8t.forEach(t),K$o=r(zRe," \u2014 "),qO=n(zRe,"A",{href:!0});var eMt=s(qO);Z$o=r(eMt,"LxmertForPreTraining"),eMt.forEach(t),eko=r(zRe," (LXMERT model)"),zRe.forEach(t),oko=i(O),D2=n(O,"LI",{});var WRe=s(D2);Ihe=n(WRe,"STRONG",{});var oMt=s(Ihe);rko=r(oMt,"megatron-bert"),oMt.forEach(t),tko=r(WRe," \u2014 "),jO=n(WRe,"A",{href:!0});var rMt=s(jO);ako=r(rMt,"MegatronBertForPreTraining"),rMt.forEach(t),nko=r(WRe," (Megatron-BERT model)"),WRe.forEach(t),sko=i(O),G2=n(O,"LI",{});var QRe=s(G2);Nhe=n(QRe,"STRONG",{});var tMt=s(Nhe);lko=r(tMt,"mobilebert"),tMt.forEach(t),iko=r(QRe," \u2014 "),DO=n(QRe,"A",{href:!0});var aMt=s(DO);dko=r(aMt,"MobileBertForPreTraining"),aMt.forEach(t),cko=r(QRe," (MobileBERT model)"),QRe.forEach(t),fko=i(O),O2=n(O,"LI",{});var HRe=s(O2);qhe=n(HRe,"STRONG",{});var nMt=s(qhe);mko=r(nMt,"mpnet"),nMt.forEach(t),gko=r(HRe," \u2014 "),GO=n(HRe,"A",{href:!0});var sMt=s(GO);hko=r(sMt,"MPNetForMaskedLM"),sMt.forEach(t),pko=r(HRe," (MPNet model)"),HRe.forEach(t),_ko=i(O),V2=n(O,"LI",{});var URe=s(V2);jhe=n(URe,"STRONG",{});var lMt=s(jhe);uko=r(lMt,"mvp"),lMt.forEach(t),bko=r(URe," \u2014 "),OO=n(URe,"A",{href:!0});var iMt=s(OO);vko=r(iMt,"MvpForConditionalGeneration"),iMt.forEach(t),Fko=r(URe," (MVP model)"),URe.forEach(t),Tko=i(O),X2=n(O,"LI",{});var JRe=s(X2);Dhe=n(JRe,"STRONG",{});var dMt=s(Dhe);Mko=r(dMt,"nezha"),dMt.forEach(t),Eko=r(JRe," \u2014 "),VO=n(JRe,"A",{href:!0});var cMt=s(VO);Cko=r(cMt,"NezhaForPreTraining"),cMt.forEach(t),wko=r(JRe," (Nezha model)"),JRe.forEach(t),Ako=i(O),z2=n(O,"LI",{});var YRe=s(z2);Ghe=n(YRe,"STRONG",{});var fMt=s(Ghe);Lko=r(fMt,"openai-gpt"),fMt.forEach(t),yko=r(YRe," \u2014 "),XO=n(YRe,"A",{href:!0});var mMt=s(XO);xko=r(mMt,"OpenAIGPTLMHeadModel"),mMt.forEach(t),$ko=r(YRe," (OpenAI GPT model)"),YRe.forEach(t),kko=i(O),W2=n(O,"LI",{});var KRe=s(W2);Ohe=n(KRe,"STRONG",{});var gMt=s(Ohe);Sko=r(gMt,"retribert"),gMt.forEach(t),Rko=r(KRe," \u2014 "),zO=n(KRe,"A",{href:!0});var hMt=s(zO);Pko=r(hMt,"RetriBertModel"),hMt.forEach(t),Bko=r(KRe," (RetriBERT model)"),KRe.forEach(t),Iko=i(O),Q2=n(O,"LI",{});var ZRe=s(Q2);Vhe=n(ZRe,"STRONG",{});var pMt=s(Vhe);Nko=r(pMt,"roberta"),pMt.forEach(t),qko=r(ZRe," \u2014 "),WO=n(ZRe,"A",{href:!0});var _Mt=s(WO);jko=r(_Mt,"RobertaForMaskedLM"),_Mt.forEach(t),Dko=r(ZRe," (RoBERTa model)"),ZRe.forEach(t),Gko=i(O),H2=n(O,"LI",{});var ePe=s(H2);Xhe=n(ePe,"STRONG",{});var uMt=s(Xhe);Oko=r(uMt,"splinter"),uMt.forEach(t),Vko=r(ePe," \u2014 "),QO=n(ePe,"A",{href:!0});var bMt=s(QO);Xko=r(bMt,"SplinterForPreTraining"),bMt.forEach(t),zko=r(ePe," (Splinter model)"),ePe.forEach(t),Wko=i(O),U2=n(O,"LI",{});var oPe=s(U2);zhe=n(oPe,"STRONG",{});var vMt=s(zhe);Qko=r(vMt,"squeezebert"),vMt.forEach(t),Hko=r(oPe," \u2014 "),HO=n(oPe,"A",{href:!0});var FMt=s(HO);Uko=r(FMt,"SqueezeBertForMaskedLM"),FMt.forEach(t),Jko=r(oPe," (SqueezeBERT model)"),oPe.forEach(t),Yko=i(O),J2=n(O,"LI",{});var rPe=s(J2);Whe=n(rPe,"STRONG",{});var TMt=s(Whe);Kko=r(TMt,"t5"),TMt.forEach(t),Zko=r(rPe," \u2014 "),UO=n(rPe,"A",{href:!0});var MMt=s(UO);eSo=r(MMt,"T5ForConditionalGeneration"),MMt.forEach(t),oSo=r(rPe," (T5 model)"),rPe.forEach(t),rSo=i(O),Y2=n(O,"LI",{});var tPe=s(Y2);Qhe=n(tPe,"STRONG",{});var EMt=s(Qhe);tSo=r(EMt,"tapas"),EMt.forEach(t),aSo=r(tPe," \u2014 "),JO=n(tPe,"A",{href:!0});var CMt=s(JO);nSo=r(CMt,"TapasForMaskedLM"),CMt.forEach(t),sSo=r(tPe," (TAPAS model)"),tPe.forEach(t),lSo=i(O),K2=n(O,"LI",{});var aPe=s(K2);Hhe=n(aPe,"STRONG",{});var wMt=s(Hhe);iSo=r(wMt,"transfo-xl"),wMt.forEach(t),dSo=r(aPe," \u2014 "),YO=n(aPe,"A",{href:!0});var AMt=s(YO);cSo=r(AMt,"TransfoXLLMHeadModel"),AMt.forEach(t),fSo=r(aPe," (Transformer-XL model)"),aPe.forEach(t),mSo=i(O),Z2=n(O,"LI",{});var nPe=s(Z2);Uhe=n(nPe,"STRONG",{});var LMt=s(Uhe);gSo=r(LMt,"unispeech"),LMt.forEach(t),hSo=r(nPe," \u2014 "),KO=n(nPe,"A",{href:!0});var yMt=s(KO);pSo=r(yMt,"UniSpeechForPreTraining"),yMt.forEach(t),_So=r(nPe," (UniSpeech model)"),nPe.forEach(t),uSo=i(O),e1=n(O,"LI",{});var sPe=s(e1);Jhe=n(sPe,"STRONG",{});var xMt=s(Jhe);bSo=r(xMt,"unispeech-sat"),xMt.forEach(t),vSo=r(sPe," \u2014 "),ZO=n(sPe,"A",{href:!0});var $Mt=s(ZO);FSo=r($Mt,"UniSpeechSatForPreTraining"),$Mt.forEach(t),TSo=r(sPe," (UniSpeechSat model)"),sPe.forEach(t),MSo=i(O),o1=n(O,"LI",{});var lPe=s(o1);Yhe=n(lPe,"STRONG",{});var kMt=s(Yhe);ESo=r(kMt,"videomae"),kMt.forEach(t),CSo=r(lPe," \u2014 "),eV=n(lPe,"A",{href:!0});var SMt=s(eV);wSo=r(SMt,"VideoMAEForPreTraining"),SMt.forEach(t),ASo=r(lPe," (VideoMAE model)"),lPe.forEach(t),LSo=i(O),r1=n(O,"LI",{});var iPe=s(r1);Khe=n(iPe,"STRONG",{});var RMt=s(Khe);ySo=r(RMt,"visual_bert"),RMt.forEach(t),xSo=r(iPe," \u2014 "),oV=n(iPe,"A",{href:!0});var PMt=s(oV);$So=r(PMt,"VisualBertForPreTraining"),PMt.forEach(t),kSo=r(iPe," (VisualBERT model)"),iPe.forEach(t),SSo=i(O),t1=n(O,"LI",{});var dPe=s(t1);Zhe=n(dPe,"STRONG",{});var BMt=s(Zhe);RSo=r(BMt,"vit_mae"),BMt.forEach(t),PSo=r(dPe," \u2014 "),rV=n(dPe,"A",{href:!0});var IMt=s(rV);BSo=r(IMt,"ViTMAEForPreTraining"),IMt.forEach(t),ISo=r(dPe," (ViTMAE model)"),dPe.forEach(t),NSo=i(O),a1=n(O,"LI",{});var cPe=s(a1);epe=n(cPe,"STRONG",{});var NMt=s(epe);qSo=r(NMt,"wav2vec2"),NMt.forEach(t),jSo=r(cPe," \u2014 "),tV=n(cPe,"A",{href:!0});var qMt=s(tV);DSo=r(qMt,"Wav2Vec2ForPreTraining"),qMt.forEach(t),GSo=r(cPe," (Wav2Vec2 model)"),cPe.forEach(t),OSo=i(O),n1=n(O,"LI",{});var fPe=s(n1);ope=n(fPe,"STRONG",{});var jMt=s(ope);VSo=r(jMt,"wav2vec2-conformer"),jMt.forEach(t),XSo=r(fPe," \u2014 "),aV=n(fPe,"A",{href:!0});var DMt=s(aV);zSo=r(DMt,"Wav2Vec2ConformerForPreTraining"),DMt.forEach(t),WSo=r(fPe," (Wav2Vec2-Conformer model)"),fPe.forEach(t),QSo=i(O),s1=n(O,"LI",{});var mPe=s(s1);rpe=n(mPe,"STRONG",{});var GMt=s(rpe);HSo=r(GMt,"xlm"),GMt.forEach(t),USo=r(mPe," \u2014 "),nV=n(mPe,"A",{href:!0});var OMt=s(nV);JSo=r(OMt,"XLMWithLMHeadModel"),OMt.forEach(t),YSo=r(mPe," (XLM model)"),mPe.forEach(t),KSo=i(O),l1=n(O,"LI",{});var gPe=s(l1);tpe=n(gPe,"STRONG",{});var VMt=s(tpe);ZSo=r(VMt,"xlm-roberta"),VMt.forEach(t),eRo=r(gPe," \u2014 "),sV=n(gPe,"A",{href:!0});var XMt=s(sV);oRo=r(XMt,"XLMRobertaForMaskedLM"),XMt.forEach(t),rRo=r(gPe," (XLM-RoBERTa model)"),gPe.forEach(t),tRo=i(O),i1=n(O,"LI",{});var hPe=s(i1);ape=n(hPe,"STRONG",{});var zMt=s(ape);aRo=r(zMt,"xlm-roberta-xl"),zMt.forEach(t),nRo=r(hPe," \u2014 "),lV=n(hPe,"A",{href:!0});var WMt=s(lV);sRo=r(WMt,"XLMRobertaXLForMaskedLM"),WMt.forEach(t),lRo=r(hPe," (XLM-RoBERTa-XL model)"),hPe.forEach(t),iRo=i(O),d1=n(O,"LI",{});var pPe=s(d1);npe=n(pPe,"STRONG",{});var QMt=s(npe);dRo=r(QMt,"xlnet"),QMt.forEach(t),cRo=r(pPe," \u2014 "),iV=n(pPe,"A",{href:!0});var HMt=s(iV);fRo=r(HMt,"XLNetLMHeadModel"),HMt.forEach(t),mRo=r(pPe," (XLNet model)"),pPe.forEach(t),O.forEach(t),gRo=i(fa),c1=n(fa,"P",{});var _Pe=s(c1);hRo=r(_Pe,"The model is set in evaluation mode by default using "),spe=n(_Pe,"CODE",{});var UMt=s(spe);pRo=r(UMt,"model.eval()"),UMt.forEach(t),_Ro=r(_Pe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),lpe=n(_Pe,"CODE",{});var JMt=s(lpe);uRo=r(JMt,"model.train()"),JMt.forEach(t),_Pe.forEach(t),bRo=i(fa),T(f1.$$.fragment,fa),fa.forEach(t),fl.forEach(t),sQe=i(f),rd=n(f,"H2",{class:!0});var hUe=s(rd);m1=n(hUe,"A",{id:!0,class:!0,href:!0});var YMt=s(m1);ipe=n(YMt,"SPAN",{});var KMt=s(ipe);T($y.$$.fragment,KMt),KMt.forEach(t),YMt.forEach(t),vRo=i(hUe),dpe=n(hUe,"SPAN",{});var ZMt=s(dpe);FRo=r(ZMt,"AutoModelForCausalLM"),ZMt.forEach(t),hUe.forEach(t),lQe=i(f),Po=n(f,"DIV",{class:!0});var ml=s(Po);T(ky.$$.fragment,ml),TRo=i(ml),td=n(ml,"P",{});var mae=s(td);MRo=r(mae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),dV=n(mae,"A",{href:!0});var eEt=s(dV);ERo=r(eEt,"from_pretrained()"),eEt.forEach(t),CRo=r(mae," class method or the "),cV=n(mae,"A",{href:!0});var oEt=s(cV);wRo=r(oEt,"from_config()"),oEt.forEach(t),ARo=r(mae,` class
method.`),mae.forEach(t),LRo=i(ml),Sy=n(ml,"P",{});var pUe=s(Sy);yRo=r(pUe,"This class cannot be instantiated directly using "),cpe=n(pUe,"CODE",{});var rEt=s(cpe);xRo=r(rEt,"__init__()"),rEt.forEach(t),$Ro=r(pUe," (throws an error)."),pUe.forEach(t),kRo=i(ml),mt=n(ml,"DIV",{class:!0});var ZA=s(mt);T(Ry.$$.fragment,ZA),SRo=i(ZA),fpe=n(ZA,"P",{});var tEt=s(fpe);RRo=r(tEt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),tEt.forEach(t),PRo=i(ZA),ad=n(ZA,"P",{});var gae=s(ad);BRo=r(gae,`Note:
Loading a model from its configuration file does `),mpe=n(gae,"STRONG",{});var aEt=s(mpe);IRo=r(aEt,"not"),aEt.forEach(t),NRo=r(gae,` load the model weights. It only affects the
model\u2019s configuration. Use `),fV=n(gae,"A",{href:!0});var nEt=s(fV);qRo=r(nEt,"from_pretrained()"),nEt.forEach(t),jRo=r(gae," to load the model weights."),gae.forEach(t),DRo=i(ZA),T(g1.$$.fragment,ZA),ZA.forEach(t),GRo=i(ml),Ze=n(ml,"DIV",{class:!0});var ma=s(Ze);T(Py.$$.fragment,ma),ORo=i(ma),gpe=n(ma,"P",{});var sEt=s(gpe);VRo=r(sEt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),sEt.forEach(t),XRo=i(ma),Oa=n(ma,"P",{});var e7=s(Oa);zRo=r(e7,"The model class to instantiate is selected based on the "),hpe=n(e7,"CODE",{});var lEt=s(hpe);WRo=r(lEt,"model_type"),lEt.forEach(t),QRo=r(e7,` property of the config object (either
passed as an argument or loaded from `),ppe=n(e7,"CODE",{});var iEt=s(ppe);HRo=r(iEt,"pretrained_model_name_or_path"),iEt.forEach(t),URo=r(e7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_pe=n(e7,"CODE",{});var dEt=s(_pe);JRo=r(dEt,"pretrained_model_name_or_path"),dEt.forEach(t),YRo=r(e7,":"),e7.forEach(t),KRo=i(ma),z=n(ma,"UL",{});var W=s(z);h1=n(W,"LI",{});var uPe=s(h1);upe=n(uPe,"STRONG",{});var cEt=s(upe);ZRo=r(cEt,"bart"),cEt.forEach(t),ePo=r(uPe," \u2014 "),mV=n(uPe,"A",{href:!0});var fEt=s(mV);oPo=r(fEt,"BartForCausalLM"),fEt.forEach(t),rPo=r(uPe," (BART model)"),uPe.forEach(t),tPo=i(W),p1=n(W,"LI",{});var bPe=s(p1);bpe=n(bPe,"STRONG",{});var mEt=s(bpe);aPo=r(mEt,"bert"),mEt.forEach(t),nPo=r(bPe," \u2014 "),gV=n(bPe,"A",{href:!0});var gEt=s(gV);sPo=r(gEt,"BertLMHeadModel"),gEt.forEach(t),lPo=r(bPe," (BERT model)"),bPe.forEach(t),iPo=i(W),_1=n(W,"LI",{});var vPe=s(_1);vpe=n(vPe,"STRONG",{});var hEt=s(vpe);dPo=r(hEt,"bert-generation"),hEt.forEach(t),cPo=r(vPe," \u2014 "),hV=n(vPe,"A",{href:!0});var pEt=s(hV);fPo=r(pEt,"BertGenerationDecoder"),pEt.forEach(t),mPo=r(vPe," (Bert Generation model)"),vPe.forEach(t),gPo=i(W),u1=n(W,"LI",{});var FPe=s(u1);Fpe=n(FPe,"STRONG",{});var _Et=s(Fpe);hPo=r(_Et,"big_bird"),_Et.forEach(t),pPo=r(FPe," \u2014 "),pV=n(FPe,"A",{href:!0});var uEt=s(pV);_Po=r(uEt,"BigBirdForCausalLM"),uEt.forEach(t),uPo=r(FPe," (BigBird model)"),FPe.forEach(t),bPo=i(W),b1=n(W,"LI",{});var TPe=s(b1);Tpe=n(TPe,"STRONG",{});var bEt=s(Tpe);vPo=r(bEt,"bigbird_pegasus"),bEt.forEach(t),FPo=r(TPe," \u2014 "),_V=n(TPe,"A",{href:!0});var vEt=s(_V);TPo=r(vEt,"BigBirdPegasusForCausalLM"),vEt.forEach(t),MPo=r(TPe," (BigBird-Pegasus model)"),TPe.forEach(t),EPo=i(W),v1=n(W,"LI",{});var MPe=s(v1);Mpe=n(MPe,"STRONG",{});var FEt=s(Mpe);CPo=r(FEt,"blenderbot"),FEt.forEach(t),wPo=r(MPe," \u2014 "),uV=n(MPe,"A",{href:!0});var TEt=s(uV);APo=r(TEt,"BlenderbotForCausalLM"),TEt.forEach(t),LPo=r(MPe," (Blenderbot model)"),MPe.forEach(t),yPo=i(W),F1=n(W,"LI",{});var EPe=s(F1);Epe=n(EPe,"STRONG",{});var MEt=s(Epe);xPo=r(MEt,"blenderbot-small"),MEt.forEach(t),$Po=r(EPe," \u2014 "),bV=n(EPe,"A",{href:!0});var EEt=s(bV);kPo=r(EEt,"BlenderbotSmallForCausalLM"),EEt.forEach(t),SPo=r(EPe," (BlenderbotSmall model)"),EPe.forEach(t),RPo=i(W),T1=n(W,"LI",{});var CPe=s(T1);Cpe=n(CPe,"STRONG",{});var CEt=s(Cpe);PPo=r(CEt,"bloom"),CEt.forEach(t),BPo=r(CPe," \u2014 "),vV=n(CPe,"A",{href:!0});var wEt=s(vV);IPo=r(wEt,"BloomForCausalLM"),wEt.forEach(t),NPo=r(CPe," (BLOOM model)"),CPe.forEach(t),qPo=i(W),M1=n(W,"LI",{});var wPe=s(M1);wpe=n(wPe,"STRONG",{});var AEt=s(wpe);jPo=r(AEt,"camembert"),AEt.forEach(t),DPo=r(wPe," \u2014 "),FV=n(wPe,"A",{href:!0});var LEt=s(FV);GPo=r(LEt,"CamembertForCausalLM"),LEt.forEach(t),OPo=r(wPe," (CamemBERT model)"),wPe.forEach(t),VPo=i(W),E1=n(W,"LI",{});var APe=s(E1);Ape=n(APe,"STRONG",{});var yEt=s(Ape);XPo=r(yEt,"codegen"),yEt.forEach(t),zPo=r(APe," \u2014 "),TV=n(APe,"A",{href:!0});var xEt=s(TV);WPo=r(xEt,"CodeGenForCausalLM"),xEt.forEach(t),QPo=r(APe," (CodeGen model)"),APe.forEach(t),HPo=i(W),C1=n(W,"LI",{});var LPe=s(C1);Lpe=n(LPe,"STRONG",{});var $Et=s(Lpe);UPo=r($Et,"ctrl"),$Et.forEach(t),JPo=r(LPe," \u2014 "),MV=n(LPe,"A",{href:!0});var kEt=s(MV);YPo=r(kEt,"CTRLLMHeadModel"),kEt.forEach(t),KPo=r(LPe," (CTRL model)"),LPe.forEach(t),ZPo=i(W),w1=n(W,"LI",{});var yPe=s(w1);ype=n(yPe,"STRONG",{});var SEt=s(ype);eBo=r(SEt,"data2vec-text"),SEt.forEach(t),oBo=r(yPe," \u2014 "),EV=n(yPe,"A",{href:!0});var REt=s(EV);rBo=r(REt,"Data2VecTextForCausalLM"),REt.forEach(t),tBo=r(yPe," (Data2VecText model)"),yPe.forEach(t),aBo=i(W),A1=n(W,"LI",{});var xPe=s(A1);xpe=n(xPe,"STRONG",{});var PEt=s(xpe);nBo=r(PEt,"electra"),PEt.forEach(t),sBo=r(xPe," \u2014 "),CV=n(xPe,"A",{href:!0});var BEt=s(CV);lBo=r(BEt,"ElectraForCausalLM"),BEt.forEach(t),iBo=r(xPe," (ELECTRA model)"),xPe.forEach(t),dBo=i(W),L1=n(W,"LI",{});var $Pe=s(L1);$pe=n($Pe,"STRONG",{});var IEt=s($pe);cBo=r(IEt,"gpt2"),IEt.forEach(t),fBo=r($Pe," \u2014 "),wV=n($Pe,"A",{href:!0});var NEt=s(wV);mBo=r(NEt,"GPT2LMHeadModel"),NEt.forEach(t),gBo=r($Pe," (OpenAI GPT-2 model)"),$Pe.forEach(t),hBo=i(W),y1=n(W,"LI",{});var kPe=s(y1);kpe=n(kPe,"STRONG",{});var qEt=s(kpe);pBo=r(qEt,"gpt_neo"),qEt.forEach(t),_Bo=r(kPe," \u2014 "),AV=n(kPe,"A",{href:!0});var jEt=s(AV);uBo=r(jEt,"GPTNeoForCausalLM"),jEt.forEach(t),bBo=r(kPe," (GPT Neo model)"),kPe.forEach(t),vBo=i(W),x1=n(W,"LI",{});var SPe=s(x1);Spe=n(SPe,"STRONG",{});var DEt=s(Spe);FBo=r(DEt,"gpt_neox"),DEt.forEach(t),TBo=r(SPe," \u2014 "),LV=n(SPe,"A",{href:!0});var GEt=s(LV);MBo=r(GEt,"GPTNeoXForCausalLM"),GEt.forEach(t),EBo=r(SPe," (GPT NeoX model)"),SPe.forEach(t),CBo=i(W),$1=n(W,"LI",{});var RPe=s($1);Rpe=n(RPe,"STRONG",{});var OEt=s(Rpe);wBo=r(OEt,"gptj"),OEt.forEach(t),ABo=r(RPe," \u2014 "),yV=n(RPe,"A",{href:!0});var VEt=s(yV);LBo=r(VEt,"GPTJForCausalLM"),VEt.forEach(t),yBo=r(RPe," (GPT-J model)"),RPe.forEach(t),xBo=i(W),k1=n(W,"LI",{});var PPe=s(k1);Ppe=n(PPe,"STRONG",{});var XEt=s(Ppe);$Bo=r(XEt,"marian"),XEt.forEach(t),kBo=r(PPe," \u2014 "),xV=n(PPe,"A",{href:!0});var zEt=s(xV);SBo=r(zEt,"MarianForCausalLM"),zEt.forEach(t),RBo=r(PPe," (Marian model)"),PPe.forEach(t),PBo=i(W),S1=n(W,"LI",{});var BPe=s(S1);Bpe=n(BPe,"STRONG",{});var WEt=s(Bpe);BBo=r(WEt,"mbart"),WEt.forEach(t),IBo=r(BPe," \u2014 "),$V=n(BPe,"A",{href:!0});var QEt=s($V);NBo=r(QEt,"MBartForCausalLM"),QEt.forEach(t),qBo=r(BPe," (mBART model)"),BPe.forEach(t),jBo=i(W),R1=n(W,"LI",{});var IPe=s(R1);Ipe=n(IPe,"STRONG",{});var HEt=s(Ipe);DBo=r(HEt,"megatron-bert"),HEt.forEach(t),GBo=r(IPe," \u2014 "),kV=n(IPe,"A",{href:!0});var UEt=s(kV);OBo=r(UEt,"MegatronBertForCausalLM"),UEt.forEach(t),VBo=r(IPe," (Megatron-BERT model)"),IPe.forEach(t),XBo=i(W),P1=n(W,"LI",{});var NPe=s(P1);Npe=n(NPe,"STRONG",{});var JEt=s(Npe);zBo=r(JEt,"mvp"),JEt.forEach(t),WBo=r(NPe," \u2014 "),SV=n(NPe,"A",{href:!0});var YEt=s(SV);QBo=r(YEt,"MvpForCausalLM"),YEt.forEach(t),HBo=r(NPe," (MVP model)"),NPe.forEach(t),UBo=i(W),B1=n(W,"LI",{});var qPe=s(B1);qpe=n(qPe,"STRONG",{});var KEt=s(qpe);JBo=r(KEt,"openai-gpt"),KEt.forEach(t),YBo=r(qPe," \u2014 "),RV=n(qPe,"A",{href:!0});var ZEt=s(RV);KBo=r(ZEt,"OpenAIGPTLMHeadModel"),ZEt.forEach(t),ZBo=r(qPe," (OpenAI GPT model)"),qPe.forEach(t),eIo=i(W),I1=n(W,"LI",{});var jPe=s(I1);jpe=n(jPe,"STRONG",{});var e4t=s(jpe);oIo=r(e4t,"opt"),e4t.forEach(t),rIo=r(jPe," \u2014 "),PV=n(jPe,"A",{href:!0});var o4t=s(PV);tIo=r(o4t,"OPTForCausalLM"),o4t.forEach(t),aIo=r(jPe," (OPT model)"),jPe.forEach(t),nIo=i(W),N1=n(W,"LI",{});var DPe=s(N1);Dpe=n(DPe,"STRONG",{});var r4t=s(Dpe);sIo=r(r4t,"pegasus"),r4t.forEach(t),lIo=r(DPe," \u2014 "),BV=n(DPe,"A",{href:!0});var t4t=s(BV);iIo=r(t4t,"PegasusForCausalLM"),t4t.forEach(t),dIo=r(DPe," (Pegasus model)"),DPe.forEach(t),cIo=i(W),q1=n(W,"LI",{});var GPe=s(q1);Gpe=n(GPe,"STRONG",{});var a4t=s(Gpe);fIo=r(a4t,"plbart"),a4t.forEach(t),mIo=r(GPe," \u2014 "),IV=n(GPe,"A",{href:!0});var n4t=s(IV);gIo=r(n4t,"PLBartForCausalLM"),n4t.forEach(t),hIo=r(GPe," (PLBart model)"),GPe.forEach(t),pIo=i(W),j1=n(W,"LI",{});var OPe=s(j1);Ope=n(OPe,"STRONG",{});var s4t=s(Ope);_Io=r(s4t,"prophetnet"),s4t.forEach(t),uIo=r(OPe," \u2014 "),NV=n(OPe,"A",{href:!0});var l4t=s(NV);bIo=r(l4t,"ProphetNetForCausalLM"),l4t.forEach(t),vIo=r(OPe," (ProphetNet model)"),OPe.forEach(t),FIo=i(W),D1=n(W,"LI",{});var VPe=s(D1);Vpe=n(VPe,"STRONG",{});var i4t=s(Vpe);TIo=r(i4t,"qdqbert"),i4t.forEach(t),MIo=r(VPe," \u2014 "),qV=n(VPe,"A",{href:!0});var d4t=s(qV);EIo=r(d4t,"QDQBertLMHeadModel"),d4t.forEach(t),CIo=r(VPe," (QDQBert model)"),VPe.forEach(t),wIo=i(W),G1=n(W,"LI",{});var XPe=s(G1);Xpe=n(XPe,"STRONG",{});var c4t=s(Xpe);AIo=r(c4t,"reformer"),c4t.forEach(t),LIo=r(XPe," \u2014 "),jV=n(XPe,"A",{href:!0});var f4t=s(jV);yIo=r(f4t,"ReformerModelWithLMHead"),f4t.forEach(t),xIo=r(XPe," (Reformer model)"),XPe.forEach(t),$Io=i(W),O1=n(W,"LI",{});var zPe=s(O1);zpe=n(zPe,"STRONG",{});var m4t=s(zpe);kIo=r(m4t,"rembert"),m4t.forEach(t),SIo=r(zPe," \u2014 "),DV=n(zPe,"A",{href:!0});var g4t=s(DV);RIo=r(g4t,"RemBertForCausalLM"),g4t.forEach(t),PIo=r(zPe," (RemBERT model)"),zPe.forEach(t),BIo=i(W),V1=n(W,"LI",{});var WPe=s(V1);Wpe=n(WPe,"STRONG",{});var h4t=s(Wpe);IIo=r(h4t,"roberta"),h4t.forEach(t),NIo=r(WPe," \u2014 "),GV=n(WPe,"A",{href:!0});var p4t=s(GV);qIo=r(p4t,"RobertaForCausalLM"),p4t.forEach(t),jIo=r(WPe," (RoBERTa model)"),WPe.forEach(t),DIo=i(W),X1=n(W,"LI",{});var QPe=s(X1);Qpe=n(QPe,"STRONG",{});var _4t=s(Qpe);GIo=r(_4t,"roformer"),_4t.forEach(t),OIo=r(QPe," \u2014 "),OV=n(QPe,"A",{href:!0});var u4t=s(OV);VIo=r(u4t,"RoFormerForCausalLM"),u4t.forEach(t),XIo=r(QPe," (RoFormer model)"),QPe.forEach(t),zIo=i(W),z1=n(W,"LI",{});var HPe=s(z1);Hpe=n(HPe,"STRONG",{});var b4t=s(Hpe);WIo=r(b4t,"speech_to_text_2"),b4t.forEach(t),QIo=r(HPe," \u2014 "),VV=n(HPe,"A",{href:!0});var v4t=s(VV);HIo=r(v4t,"Speech2Text2ForCausalLM"),v4t.forEach(t),UIo=r(HPe," (Speech2Text2 model)"),HPe.forEach(t),JIo=i(W),W1=n(W,"LI",{});var UPe=s(W1);Upe=n(UPe,"STRONG",{});var F4t=s(Upe);YIo=r(F4t,"transfo-xl"),F4t.forEach(t),KIo=r(UPe," \u2014 "),XV=n(UPe,"A",{href:!0});var T4t=s(XV);ZIo=r(T4t,"TransfoXLLMHeadModel"),T4t.forEach(t),eNo=r(UPe," (Transformer-XL model)"),UPe.forEach(t),oNo=i(W),Q1=n(W,"LI",{});var JPe=s(Q1);Jpe=n(JPe,"STRONG",{});var M4t=s(Jpe);rNo=r(M4t,"trocr"),M4t.forEach(t),tNo=r(JPe," \u2014 "),zV=n(JPe,"A",{href:!0});var E4t=s(zV);aNo=r(E4t,"TrOCRForCausalLM"),E4t.forEach(t),nNo=r(JPe," (TrOCR model)"),JPe.forEach(t),sNo=i(W),H1=n(W,"LI",{});var YPe=s(H1);Ype=n(YPe,"STRONG",{});var C4t=s(Ype);lNo=r(C4t,"xglm"),C4t.forEach(t),iNo=r(YPe," \u2014 "),WV=n(YPe,"A",{href:!0});var w4t=s(WV);dNo=r(w4t,"XGLMForCausalLM"),w4t.forEach(t),cNo=r(YPe," (XGLM model)"),YPe.forEach(t),fNo=i(W),U1=n(W,"LI",{});var KPe=s(U1);Kpe=n(KPe,"STRONG",{});var A4t=s(Kpe);mNo=r(A4t,"xlm"),A4t.forEach(t),gNo=r(KPe," \u2014 "),QV=n(KPe,"A",{href:!0});var L4t=s(QV);hNo=r(L4t,"XLMWithLMHeadModel"),L4t.forEach(t),pNo=r(KPe," (XLM model)"),KPe.forEach(t),_No=i(W),J1=n(W,"LI",{});var ZPe=s(J1);Zpe=n(ZPe,"STRONG",{});var y4t=s(Zpe);uNo=r(y4t,"xlm-prophetnet"),y4t.forEach(t),bNo=r(ZPe," \u2014 "),HV=n(ZPe,"A",{href:!0});var x4t=s(HV);vNo=r(x4t,"XLMProphetNetForCausalLM"),x4t.forEach(t),FNo=r(ZPe," (XLM-ProphetNet model)"),ZPe.forEach(t),TNo=i(W),Y1=n(W,"LI",{});var eBe=s(Y1);e_e=n(eBe,"STRONG",{});var $4t=s(e_e);MNo=r($4t,"xlm-roberta"),$4t.forEach(t),ENo=r(eBe," \u2014 "),UV=n(eBe,"A",{href:!0});var k4t=s(UV);CNo=r(k4t,"XLMRobertaForCausalLM"),k4t.forEach(t),wNo=r(eBe," (XLM-RoBERTa model)"),eBe.forEach(t),ANo=i(W),K1=n(W,"LI",{});var oBe=s(K1);o_e=n(oBe,"STRONG",{});var S4t=s(o_e);LNo=r(S4t,"xlm-roberta-xl"),S4t.forEach(t),yNo=r(oBe," \u2014 "),JV=n(oBe,"A",{href:!0});var R4t=s(JV);xNo=r(R4t,"XLMRobertaXLForCausalLM"),R4t.forEach(t),$No=r(oBe," (XLM-RoBERTa-XL model)"),oBe.forEach(t),kNo=i(W),Z1=n(W,"LI",{});var rBe=s(Z1);r_e=n(rBe,"STRONG",{});var P4t=s(r_e);SNo=r(P4t,"xlnet"),P4t.forEach(t),RNo=r(rBe," \u2014 "),YV=n(rBe,"A",{href:!0});var B4t=s(YV);PNo=r(B4t,"XLNetLMHeadModel"),B4t.forEach(t),BNo=r(rBe," (XLNet model)"),rBe.forEach(t),W.forEach(t),INo=i(ma),eb=n(ma,"P",{});var tBe=s(eb);NNo=r(tBe,"The model is set in evaluation mode by default using "),t_e=n(tBe,"CODE",{});var I4t=s(t_e);qNo=r(I4t,"model.eval()"),I4t.forEach(t),jNo=r(tBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),a_e=n(tBe,"CODE",{});var N4t=s(a_e);DNo=r(N4t,"model.train()"),N4t.forEach(t),tBe.forEach(t),GNo=i(ma),T(ob.$$.fragment,ma),ma.forEach(t),ml.forEach(t),iQe=i(f),nd=n(f,"H2",{class:!0});var _Ue=s(nd);rb=n(_Ue,"A",{id:!0,class:!0,href:!0});var q4t=s(rb);n_e=n(q4t,"SPAN",{});var j4t=s(n_e);T(By.$$.fragment,j4t),j4t.forEach(t),q4t.forEach(t),ONo=i(_Ue),s_e=n(_Ue,"SPAN",{});var D4t=s(s_e);VNo=r(D4t,"AutoModelForMaskedLM"),D4t.forEach(t),_Ue.forEach(t),dQe=i(f),Bo=n(f,"DIV",{class:!0});var gl=s(Bo);T(Iy.$$.fragment,gl),XNo=i(gl),sd=n(gl,"P",{});var hae=s(sd);zNo=r(hae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),KV=n(hae,"A",{href:!0});var G4t=s(KV);WNo=r(G4t,"from_pretrained()"),G4t.forEach(t),QNo=r(hae," class method or the "),ZV=n(hae,"A",{href:!0});var O4t=s(ZV);HNo=r(O4t,"from_config()"),O4t.forEach(t),UNo=r(hae,` class
method.`),hae.forEach(t),JNo=i(gl),Ny=n(gl,"P",{});var uUe=s(Ny);YNo=r(uUe,"This class cannot be instantiated directly using "),l_e=n(uUe,"CODE",{});var V4t=s(l_e);KNo=r(V4t,"__init__()"),V4t.forEach(t),ZNo=r(uUe," (throws an error)."),uUe.forEach(t),eqo=i(gl),gt=n(gl,"DIV",{class:!0});var o7=s(gt);T(qy.$$.fragment,o7),oqo=i(o7),i_e=n(o7,"P",{});var X4t=s(i_e);rqo=r(X4t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),X4t.forEach(t),tqo=i(o7),ld=n(o7,"P",{});var pae=s(ld);aqo=r(pae,`Note:
Loading a model from its configuration file does `),d_e=n(pae,"STRONG",{});var z4t=s(d_e);nqo=r(z4t,"not"),z4t.forEach(t),sqo=r(pae,` load the model weights. It only affects the
model\u2019s configuration. Use `),eX=n(pae,"A",{href:!0});var W4t=s(eX);lqo=r(W4t,"from_pretrained()"),W4t.forEach(t),iqo=r(pae," to load the model weights."),pae.forEach(t),dqo=i(o7),T(tb.$$.fragment,o7),o7.forEach(t),cqo=i(gl),eo=n(gl,"DIV",{class:!0});var ga=s(eo);T(jy.$$.fragment,ga),fqo=i(ga),c_e=n(ga,"P",{});var Q4t=s(c_e);mqo=r(Q4t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Q4t.forEach(t),gqo=i(ga),Va=n(ga,"P",{});var r7=s(Va);hqo=r(r7,"The model class to instantiate is selected based on the "),f_e=n(r7,"CODE",{});var H4t=s(f_e);pqo=r(H4t,"model_type"),H4t.forEach(t),_qo=r(r7,` property of the config object (either
passed as an argument or loaded from `),m_e=n(r7,"CODE",{});var U4t=s(m_e);uqo=r(U4t,"pretrained_model_name_or_path"),U4t.forEach(t),bqo=r(r7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),g_e=n(r7,"CODE",{});var J4t=s(g_e);vqo=r(J4t,"pretrained_model_name_or_path"),J4t.forEach(t),Fqo=r(r7,":"),r7.forEach(t),Tqo=i(ga),Q=n(ga,"UL",{});var J=s(Q);ab=n(J,"LI",{});var aBe=s(ab);h_e=n(aBe,"STRONG",{});var Y4t=s(h_e);Mqo=r(Y4t,"albert"),Y4t.forEach(t),Eqo=r(aBe," \u2014 "),oX=n(aBe,"A",{href:!0});var K4t=s(oX);Cqo=r(K4t,"AlbertForMaskedLM"),K4t.forEach(t),wqo=r(aBe," (ALBERT model)"),aBe.forEach(t),Aqo=i(J),nb=n(J,"LI",{});var nBe=s(nb);p_e=n(nBe,"STRONG",{});var Z4t=s(p_e);Lqo=r(Z4t,"bart"),Z4t.forEach(t),yqo=r(nBe," \u2014 "),rX=n(nBe,"A",{href:!0});var eCt=s(rX);xqo=r(eCt,"BartForConditionalGeneration"),eCt.forEach(t),$qo=r(nBe," (BART model)"),nBe.forEach(t),kqo=i(J),sb=n(J,"LI",{});var sBe=s(sb);__e=n(sBe,"STRONG",{});var oCt=s(__e);Sqo=r(oCt,"bert"),oCt.forEach(t),Rqo=r(sBe," \u2014 "),tX=n(sBe,"A",{href:!0});var rCt=s(tX);Pqo=r(rCt,"BertForMaskedLM"),rCt.forEach(t),Bqo=r(sBe," (BERT model)"),sBe.forEach(t),Iqo=i(J),lb=n(J,"LI",{});var lBe=s(lb);u_e=n(lBe,"STRONG",{});var tCt=s(u_e);Nqo=r(tCt,"big_bird"),tCt.forEach(t),qqo=r(lBe," \u2014 "),aX=n(lBe,"A",{href:!0});var aCt=s(aX);jqo=r(aCt,"BigBirdForMaskedLM"),aCt.forEach(t),Dqo=r(lBe," (BigBird model)"),lBe.forEach(t),Gqo=i(J),ib=n(J,"LI",{});var iBe=s(ib);b_e=n(iBe,"STRONG",{});var nCt=s(b_e);Oqo=r(nCt,"camembert"),nCt.forEach(t),Vqo=r(iBe," \u2014 "),nX=n(iBe,"A",{href:!0});var sCt=s(nX);Xqo=r(sCt,"CamembertForMaskedLM"),sCt.forEach(t),zqo=r(iBe," (CamemBERT model)"),iBe.forEach(t),Wqo=i(J),db=n(J,"LI",{});var dBe=s(db);v_e=n(dBe,"STRONG",{});var lCt=s(v_e);Qqo=r(lCt,"convbert"),lCt.forEach(t),Hqo=r(dBe," \u2014 "),sX=n(dBe,"A",{href:!0});var iCt=s(sX);Uqo=r(iCt,"ConvBertForMaskedLM"),iCt.forEach(t),Jqo=r(dBe," (ConvBERT model)"),dBe.forEach(t),Yqo=i(J),cb=n(J,"LI",{});var cBe=s(cb);F_e=n(cBe,"STRONG",{});var dCt=s(F_e);Kqo=r(dCt,"data2vec-text"),dCt.forEach(t),Zqo=r(cBe," \u2014 "),lX=n(cBe,"A",{href:!0});var cCt=s(lX);ejo=r(cCt,"Data2VecTextForMaskedLM"),cCt.forEach(t),ojo=r(cBe," (Data2VecText model)"),cBe.forEach(t),rjo=i(J),fb=n(J,"LI",{});var fBe=s(fb);T_e=n(fBe,"STRONG",{});var fCt=s(T_e);tjo=r(fCt,"deberta"),fCt.forEach(t),ajo=r(fBe," \u2014 "),iX=n(fBe,"A",{href:!0});var mCt=s(iX);njo=r(mCt,"DebertaForMaskedLM"),mCt.forEach(t),sjo=r(fBe," (DeBERTa model)"),fBe.forEach(t),ljo=i(J),mb=n(J,"LI",{});var mBe=s(mb);M_e=n(mBe,"STRONG",{});var gCt=s(M_e);ijo=r(gCt,"deberta-v2"),gCt.forEach(t),djo=r(mBe," \u2014 "),dX=n(mBe,"A",{href:!0});var hCt=s(dX);cjo=r(hCt,"DebertaV2ForMaskedLM"),hCt.forEach(t),fjo=r(mBe," (DeBERTa-v2 model)"),mBe.forEach(t),mjo=i(J),gb=n(J,"LI",{});var gBe=s(gb);E_e=n(gBe,"STRONG",{});var pCt=s(E_e);gjo=r(pCt,"distilbert"),pCt.forEach(t),hjo=r(gBe," \u2014 "),cX=n(gBe,"A",{href:!0});var _Ct=s(cX);pjo=r(_Ct,"DistilBertForMaskedLM"),_Ct.forEach(t),_jo=r(gBe," (DistilBERT model)"),gBe.forEach(t),ujo=i(J),hb=n(J,"LI",{});var hBe=s(hb);C_e=n(hBe,"STRONG",{});var uCt=s(C_e);bjo=r(uCt,"electra"),uCt.forEach(t),vjo=r(hBe," \u2014 "),fX=n(hBe,"A",{href:!0});var bCt=s(fX);Fjo=r(bCt,"ElectraForMaskedLM"),bCt.forEach(t),Tjo=r(hBe," (ELECTRA model)"),hBe.forEach(t),Mjo=i(J),pb=n(J,"LI",{});var pBe=s(pb);w_e=n(pBe,"STRONG",{});var vCt=s(w_e);Ejo=r(vCt,"flaubert"),vCt.forEach(t),Cjo=r(pBe," \u2014 "),mX=n(pBe,"A",{href:!0});var FCt=s(mX);wjo=r(FCt,"FlaubertWithLMHeadModel"),FCt.forEach(t),Ajo=r(pBe," (FlauBERT model)"),pBe.forEach(t),Ljo=i(J),_b=n(J,"LI",{});var _Be=s(_b);A_e=n(_Be,"STRONG",{});var TCt=s(A_e);yjo=r(TCt,"fnet"),TCt.forEach(t),xjo=r(_Be," \u2014 "),gX=n(_Be,"A",{href:!0});var MCt=s(gX);$jo=r(MCt,"FNetForMaskedLM"),MCt.forEach(t),kjo=r(_Be," (FNet model)"),_Be.forEach(t),Sjo=i(J),ub=n(J,"LI",{});var uBe=s(ub);L_e=n(uBe,"STRONG",{});var ECt=s(L_e);Rjo=r(ECt,"funnel"),ECt.forEach(t),Pjo=r(uBe," \u2014 "),hX=n(uBe,"A",{href:!0});var CCt=s(hX);Bjo=r(CCt,"FunnelForMaskedLM"),CCt.forEach(t),Ijo=r(uBe," (Funnel Transformer model)"),uBe.forEach(t),Njo=i(J),bb=n(J,"LI",{});var bBe=s(bb);y_e=n(bBe,"STRONG",{});var wCt=s(y_e);qjo=r(wCt,"ibert"),wCt.forEach(t),jjo=r(bBe," \u2014 "),pX=n(bBe,"A",{href:!0});var ACt=s(pX);Djo=r(ACt,"IBertForMaskedLM"),ACt.forEach(t),Gjo=r(bBe," (I-BERT model)"),bBe.forEach(t),Ojo=i(J),vb=n(J,"LI",{});var vBe=s(vb);x_e=n(vBe,"STRONG",{});var LCt=s(x_e);Vjo=r(LCt,"layoutlm"),LCt.forEach(t),Xjo=r(vBe," \u2014 "),_X=n(vBe,"A",{href:!0});var yCt=s(_X);zjo=r(yCt,"LayoutLMForMaskedLM"),yCt.forEach(t),Wjo=r(vBe," (LayoutLM model)"),vBe.forEach(t),Qjo=i(J),Fb=n(J,"LI",{});var FBe=s(Fb);$_e=n(FBe,"STRONG",{});var xCt=s($_e);Hjo=r(xCt,"longformer"),xCt.forEach(t),Ujo=r(FBe," \u2014 "),uX=n(FBe,"A",{href:!0});var $Ct=s(uX);Jjo=r($Ct,"LongformerForMaskedLM"),$Ct.forEach(t),Yjo=r(FBe," (Longformer model)"),FBe.forEach(t),Kjo=i(J),Tb=n(J,"LI",{});var TBe=s(Tb);k_e=n(TBe,"STRONG",{});var kCt=s(k_e);Zjo=r(kCt,"luke"),kCt.forEach(t),eDo=r(TBe," \u2014 "),bX=n(TBe,"A",{href:!0});var SCt=s(bX);oDo=r(SCt,"LukeForMaskedLM"),SCt.forEach(t),rDo=r(TBe," (LUKE model)"),TBe.forEach(t),tDo=i(J),Mb=n(J,"LI",{});var MBe=s(Mb);S_e=n(MBe,"STRONG",{});var RCt=s(S_e);aDo=r(RCt,"mbart"),RCt.forEach(t),nDo=r(MBe," \u2014 "),vX=n(MBe,"A",{href:!0});var PCt=s(vX);sDo=r(PCt,"MBartForConditionalGeneration"),PCt.forEach(t),lDo=r(MBe," (mBART model)"),MBe.forEach(t),iDo=i(J),Eb=n(J,"LI",{});var EBe=s(Eb);R_e=n(EBe,"STRONG",{});var BCt=s(R_e);dDo=r(BCt,"megatron-bert"),BCt.forEach(t),cDo=r(EBe," \u2014 "),FX=n(EBe,"A",{href:!0});var ICt=s(FX);fDo=r(ICt,"MegatronBertForMaskedLM"),ICt.forEach(t),mDo=r(EBe," (Megatron-BERT model)"),EBe.forEach(t),gDo=i(J),Cb=n(J,"LI",{});var CBe=s(Cb);P_e=n(CBe,"STRONG",{});var NCt=s(P_e);hDo=r(NCt,"mobilebert"),NCt.forEach(t),pDo=r(CBe," \u2014 "),TX=n(CBe,"A",{href:!0});var qCt=s(TX);_Do=r(qCt,"MobileBertForMaskedLM"),qCt.forEach(t),uDo=r(CBe," (MobileBERT model)"),CBe.forEach(t),bDo=i(J),wb=n(J,"LI",{});var wBe=s(wb);B_e=n(wBe,"STRONG",{});var jCt=s(B_e);vDo=r(jCt,"mpnet"),jCt.forEach(t),FDo=r(wBe," \u2014 "),MX=n(wBe,"A",{href:!0});var DCt=s(MX);TDo=r(DCt,"MPNetForMaskedLM"),DCt.forEach(t),MDo=r(wBe," (MPNet model)"),wBe.forEach(t),EDo=i(J),Ab=n(J,"LI",{});var ABe=s(Ab);I_e=n(ABe,"STRONG",{});var GCt=s(I_e);CDo=r(GCt,"mvp"),GCt.forEach(t),wDo=r(ABe," \u2014 "),EX=n(ABe,"A",{href:!0});var OCt=s(EX);ADo=r(OCt,"MvpForConditionalGeneration"),OCt.forEach(t),LDo=r(ABe," (MVP model)"),ABe.forEach(t),yDo=i(J),Lb=n(J,"LI",{});var LBe=s(Lb);N_e=n(LBe,"STRONG",{});var VCt=s(N_e);xDo=r(VCt,"nezha"),VCt.forEach(t),$Do=r(LBe," \u2014 "),CX=n(LBe,"A",{href:!0});var XCt=s(CX);kDo=r(XCt,"NezhaForMaskedLM"),XCt.forEach(t),SDo=r(LBe," (Nezha model)"),LBe.forEach(t),RDo=i(J),yb=n(J,"LI",{});var yBe=s(yb);q_e=n(yBe,"STRONG",{});var zCt=s(q_e);PDo=r(zCt,"nystromformer"),zCt.forEach(t),BDo=r(yBe," \u2014 "),wX=n(yBe,"A",{href:!0});var WCt=s(wX);IDo=r(WCt,"NystromformerForMaskedLM"),WCt.forEach(t),NDo=r(yBe," (Nystr\xF6mformer model)"),yBe.forEach(t),qDo=i(J),xb=n(J,"LI",{});var xBe=s(xb);j_e=n(xBe,"STRONG",{});var QCt=s(j_e);jDo=r(QCt,"perceiver"),QCt.forEach(t),DDo=r(xBe," \u2014 "),AX=n(xBe,"A",{href:!0});var HCt=s(AX);GDo=r(HCt,"PerceiverForMaskedLM"),HCt.forEach(t),ODo=r(xBe," (Perceiver model)"),xBe.forEach(t),VDo=i(J),$b=n(J,"LI",{});var $Be=s($b);D_e=n($Be,"STRONG",{});var UCt=s(D_e);XDo=r(UCt,"qdqbert"),UCt.forEach(t),zDo=r($Be," \u2014 "),LX=n($Be,"A",{href:!0});var JCt=s(LX);WDo=r(JCt,"QDQBertForMaskedLM"),JCt.forEach(t),QDo=r($Be," (QDQBert model)"),$Be.forEach(t),HDo=i(J),kb=n(J,"LI",{});var kBe=s(kb);G_e=n(kBe,"STRONG",{});var YCt=s(G_e);UDo=r(YCt,"reformer"),YCt.forEach(t),JDo=r(kBe," \u2014 "),yX=n(kBe,"A",{href:!0});var KCt=s(yX);YDo=r(KCt,"ReformerForMaskedLM"),KCt.forEach(t),KDo=r(kBe," (Reformer model)"),kBe.forEach(t),ZDo=i(J),Sb=n(J,"LI",{});var SBe=s(Sb);O_e=n(SBe,"STRONG",{});var ZCt=s(O_e);eGo=r(ZCt,"rembert"),ZCt.forEach(t),oGo=r(SBe," \u2014 "),xX=n(SBe,"A",{href:!0});var e5t=s(xX);rGo=r(e5t,"RemBertForMaskedLM"),e5t.forEach(t),tGo=r(SBe," (RemBERT model)"),SBe.forEach(t),aGo=i(J),Rb=n(J,"LI",{});var RBe=s(Rb);V_e=n(RBe,"STRONG",{});var o5t=s(V_e);nGo=r(o5t,"roberta"),o5t.forEach(t),sGo=r(RBe," \u2014 "),$X=n(RBe,"A",{href:!0});var r5t=s($X);lGo=r(r5t,"RobertaForMaskedLM"),r5t.forEach(t),iGo=r(RBe," (RoBERTa model)"),RBe.forEach(t),dGo=i(J),Pb=n(J,"LI",{});var PBe=s(Pb);X_e=n(PBe,"STRONG",{});var t5t=s(X_e);cGo=r(t5t,"roformer"),t5t.forEach(t),fGo=r(PBe," \u2014 "),kX=n(PBe,"A",{href:!0});var a5t=s(kX);mGo=r(a5t,"RoFormerForMaskedLM"),a5t.forEach(t),gGo=r(PBe," (RoFormer model)"),PBe.forEach(t),hGo=i(J),Bb=n(J,"LI",{});var BBe=s(Bb);z_e=n(BBe,"STRONG",{});var n5t=s(z_e);pGo=r(n5t,"squeezebert"),n5t.forEach(t),_Go=r(BBe," \u2014 "),SX=n(BBe,"A",{href:!0});var s5t=s(SX);uGo=r(s5t,"SqueezeBertForMaskedLM"),s5t.forEach(t),bGo=r(BBe," (SqueezeBERT model)"),BBe.forEach(t),vGo=i(J),Ib=n(J,"LI",{});var IBe=s(Ib);W_e=n(IBe,"STRONG",{});var l5t=s(W_e);FGo=r(l5t,"tapas"),l5t.forEach(t),TGo=r(IBe," \u2014 "),RX=n(IBe,"A",{href:!0});var i5t=s(RX);MGo=r(i5t,"TapasForMaskedLM"),i5t.forEach(t),EGo=r(IBe," (TAPAS model)"),IBe.forEach(t),CGo=i(J),Nb=n(J,"LI",{});var NBe=s(Nb);Q_e=n(NBe,"STRONG",{});var d5t=s(Q_e);wGo=r(d5t,"wav2vec2"),d5t.forEach(t),AGo=r(NBe," \u2014 "),H_e=n(NBe,"CODE",{});var c5t=s(H_e);LGo=r(c5t,"Wav2Vec2ForMaskedLM"),c5t.forEach(t),yGo=r(NBe," (Wav2Vec2 model)"),NBe.forEach(t),xGo=i(J),qb=n(J,"LI",{});var qBe=s(qb);U_e=n(qBe,"STRONG",{});var f5t=s(U_e);$Go=r(f5t,"xlm"),f5t.forEach(t),kGo=r(qBe," \u2014 "),PX=n(qBe,"A",{href:!0});var m5t=s(PX);SGo=r(m5t,"XLMWithLMHeadModel"),m5t.forEach(t),RGo=r(qBe," (XLM model)"),qBe.forEach(t),PGo=i(J),jb=n(J,"LI",{});var jBe=s(jb);J_e=n(jBe,"STRONG",{});var g5t=s(J_e);BGo=r(g5t,"xlm-roberta"),g5t.forEach(t),IGo=r(jBe," \u2014 "),BX=n(jBe,"A",{href:!0});var h5t=s(BX);NGo=r(h5t,"XLMRobertaForMaskedLM"),h5t.forEach(t),qGo=r(jBe," (XLM-RoBERTa model)"),jBe.forEach(t),jGo=i(J),Db=n(J,"LI",{});var DBe=s(Db);Y_e=n(DBe,"STRONG",{});var p5t=s(Y_e);DGo=r(p5t,"xlm-roberta-xl"),p5t.forEach(t),GGo=r(DBe," \u2014 "),IX=n(DBe,"A",{href:!0});var _5t=s(IX);OGo=r(_5t,"XLMRobertaXLForMaskedLM"),_5t.forEach(t),VGo=r(DBe," (XLM-RoBERTa-XL model)"),DBe.forEach(t),XGo=i(J),Gb=n(J,"LI",{});var GBe=s(Gb);K_e=n(GBe,"STRONG",{});var u5t=s(K_e);zGo=r(u5t,"yoso"),u5t.forEach(t),WGo=r(GBe," \u2014 "),NX=n(GBe,"A",{href:!0});var b5t=s(NX);QGo=r(b5t,"YosoForMaskedLM"),b5t.forEach(t),HGo=r(GBe," (YOSO model)"),GBe.forEach(t),J.forEach(t),UGo=i(ga),Ob=n(ga,"P",{});var OBe=s(Ob);JGo=r(OBe,"The model is set in evaluation mode by default using "),Z_e=n(OBe,"CODE",{});var v5t=s(Z_e);YGo=r(v5t,"model.eval()"),v5t.forEach(t),KGo=r(OBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),eue=n(OBe,"CODE",{});var F5t=s(eue);ZGo=r(F5t,"model.train()"),F5t.forEach(t),OBe.forEach(t),eOo=i(ga),T(Vb.$$.fragment,ga),ga.forEach(t),gl.forEach(t),cQe=i(f),id=n(f,"H2",{class:!0});var bUe=s(id);Xb=n(bUe,"A",{id:!0,class:!0,href:!0});var T5t=s(Xb);oue=n(T5t,"SPAN",{});var M5t=s(oue);T(Dy.$$.fragment,M5t),M5t.forEach(t),T5t.forEach(t),oOo=i(bUe),rue=n(bUe,"SPAN",{});var E5t=s(rue);rOo=r(E5t,"AutoModelForSeq2SeqLM"),E5t.forEach(t),bUe.forEach(t),fQe=i(f),Io=n(f,"DIV",{class:!0});var hl=s(Io);T(Gy.$$.fragment,hl),tOo=i(hl),dd=n(hl,"P",{});var _ae=s(dd);aOo=r(_ae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),qX=n(_ae,"A",{href:!0});var C5t=s(qX);nOo=r(C5t,"from_pretrained()"),C5t.forEach(t),sOo=r(_ae," class method or the "),jX=n(_ae,"A",{href:!0});var w5t=s(jX);lOo=r(w5t,"from_config()"),w5t.forEach(t),iOo=r(_ae,` class
method.`),_ae.forEach(t),dOo=i(hl),Oy=n(hl,"P",{});var vUe=s(Oy);cOo=r(vUe,"This class cannot be instantiated directly using "),tue=n(vUe,"CODE",{});var A5t=s(tue);fOo=r(A5t,"__init__()"),A5t.forEach(t),mOo=r(vUe," (throws an error)."),vUe.forEach(t),gOo=i(hl),ht=n(hl,"DIV",{class:!0});var t7=s(ht);T(Vy.$$.fragment,t7),hOo=i(t7),aue=n(t7,"P",{});var L5t=s(aue);pOo=r(L5t,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),L5t.forEach(t),_Oo=i(t7),cd=n(t7,"P",{});var uae=s(cd);uOo=r(uae,`Note:
Loading a model from its configuration file does `),nue=n(uae,"STRONG",{});var y5t=s(nue);bOo=r(y5t,"not"),y5t.forEach(t),vOo=r(uae,` load the model weights. It only affects the
model\u2019s configuration. Use `),DX=n(uae,"A",{href:!0});var x5t=s(DX);FOo=r(x5t,"from_pretrained()"),x5t.forEach(t),TOo=r(uae," to load the model weights."),uae.forEach(t),MOo=i(t7),T(zb.$$.fragment,t7),t7.forEach(t),EOo=i(hl),oo=n(hl,"DIV",{class:!0});var ha=s(oo);T(Xy.$$.fragment,ha),COo=i(ha),sue=n(ha,"P",{});var $5t=s(sue);wOo=r($5t,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$5t.forEach(t),AOo=i(ha),Xa=n(ha,"P",{});var a7=s(Xa);LOo=r(a7,"The model class to instantiate is selected based on the "),lue=n(a7,"CODE",{});var k5t=s(lue);yOo=r(k5t,"model_type"),k5t.forEach(t),xOo=r(a7,` property of the config object (either
passed as an argument or loaded from `),iue=n(a7,"CODE",{});var S5t=s(iue);$Oo=r(S5t,"pretrained_model_name_or_path"),S5t.forEach(t),kOo=r(a7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),due=n(a7,"CODE",{});var R5t=s(due);SOo=r(R5t,"pretrained_model_name_or_path"),R5t.forEach(t),ROo=r(a7,":"),a7.forEach(t),POo=i(ha),me=n(ha,"UL",{});var ue=s(me);Wb=n(ue,"LI",{});var VBe=s(Wb);cue=n(VBe,"STRONG",{});var P5t=s(cue);BOo=r(P5t,"bart"),P5t.forEach(t),IOo=r(VBe," \u2014 "),GX=n(VBe,"A",{href:!0});var B5t=s(GX);NOo=r(B5t,"BartForConditionalGeneration"),B5t.forEach(t),qOo=r(VBe," (BART model)"),VBe.forEach(t),jOo=i(ue),Qb=n(ue,"LI",{});var XBe=s(Qb);fue=n(XBe,"STRONG",{});var I5t=s(fue);DOo=r(I5t,"bigbird_pegasus"),I5t.forEach(t),GOo=r(XBe," \u2014 "),OX=n(XBe,"A",{href:!0});var N5t=s(OX);OOo=r(N5t,"BigBirdPegasusForConditionalGeneration"),N5t.forEach(t),VOo=r(XBe," (BigBird-Pegasus model)"),XBe.forEach(t),XOo=i(ue),Hb=n(ue,"LI",{});var zBe=s(Hb);mue=n(zBe,"STRONG",{});var q5t=s(mue);zOo=r(q5t,"blenderbot"),q5t.forEach(t),WOo=r(zBe," \u2014 "),VX=n(zBe,"A",{href:!0});var j5t=s(VX);QOo=r(j5t,"BlenderbotForConditionalGeneration"),j5t.forEach(t),HOo=r(zBe," (Blenderbot model)"),zBe.forEach(t),UOo=i(ue),Ub=n(ue,"LI",{});var WBe=s(Ub);gue=n(WBe,"STRONG",{});var D5t=s(gue);JOo=r(D5t,"blenderbot-small"),D5t.forEach(t),YOo=r(WBe," \u2014 "),XX=n(WBe,"A",{href:!0});var G5t=s(XX);KOo=r(G5t,"BlenderbotSmallForConditionalGeneration"),G5t.forEach(t),ZOo=r(WBe," (BlenderbotSmall model)"),WBe.forEach(t),eVo=i(ue),Jb=n(ue,"LI",{});var QBe=s(Jb);hue=n(QBe,"STRONG",{});var O5t=s(hue);oVo=r(O5t,"encoder-decoder"),O5t.forEach(t),rVo=r(QBe," \u2014 "),zX=n(QBe,"A",{href:!0});var V5t=s(zX);tVo=r(V5t,"EncoderDecoderModel"),V5t.forEach(t),aVo=r(QBe," (Encoder decoder model)"),QBe.forEach(t),nVo=i(ue),Yb=n(ue,"LI",{});var HBe=s(Yb);pue=n(HBe,"STRONG",{});var X5t=s(pue);sVo=r(X5t,"fsmt"),X5t.forEach(t),lVo=r(HBe," \u2014 "),WX=n(HBe,"A",{href:!0});var z5t=s(WX);iVo=r(z5t,"FSMTForConditionalGeneration"),z5t.forEach(t),dVo=r(HBe," (FairSeq Machine-Translation model)"),HBe.forEach(t),cVo=i(ue),Kb=n(ue,"LI",{});var UBe=s(Kb);_ue=n(UBe,"STRONG",{});var W5t=s(_ue);fVo=r(W5t,"led"),W5t.forEach(t),mVo=r(UBe," \u2014 "),QX=n(UBe,"A",{href:!0});var Q5t=s(QX);gVo=r(Q5t,"LEDForConditionalGeneration"),Q5t.forEach(t),hVo=r(UBe," (LED model)"),UBe.forEach(t),pVo=i(ue),Zb=n(ue,"LI",{});var JBe=s(Zb);uue=n(JBe,"STRONG",{});var H5t=s(uue);_Vo=r(H5t,"longt5"),H5t.forEach(t),uVo=r(JBe," \u2014 "),HX=n(JBe,"A",{href:!0});var U5t=s(HX);bVo=r(U5t,"LongT5ForConditionalGeneration"),U5t.forEach(t),vVo=r(JBe," (LongT5 model)"),JBe.forEach(t),FVo=i(ue),ev=n(ue,"LI",{});var YBe=s(ev);bue=n(YBe,"STRONG",{});var J5t=s(bue);TVo=r(J5t,"m2m_100"),J5t.forEach(t),MVo=r(YBe," \u2014 "),UX=n(YBe,"A",{href:!0});var Y5t=s(UX);EVo=r(Y5t,"M2M100ForConditionalGeneration"),Y5t.forEach(t),CVo=r(YBe," (M2M100 model)"),YBe.forEach(t),wVo=i(ue),ov=n(ue,"LI",{});var KBe=s(ov);vue=n(KBe,"STRONG",{});var K5t=s(vue);AVo=r(K5t,"marian"),K5t.forEach(t),LVo=r(KBe," \u2014 "),JX=n(KBe,"A",{href:!0});var Z5t=s(JX);yVo=r(Z5t,"MarianMTModel"),Z5t.forEach(t),xVo=r(KBe," (Marian model)"),KBe.forEach(t),$Vo=i(ue),rv=n(ue,"LI",{});var ZBe=s(rv);Fue=n(ZBe,"STRONG",{});var e3t=s(Fue);kVo=r(e3t,"mbart"),e3t.forEach(t),SVo=r(ZBe," \u2014 "),YX=n(ZBe,"A",{href:!0});var o3t=s(YX);RVo=r(o3t,"MBartForConditionalGeneration"),o3t.forEach(t),PVo=r(ZBe," (mBART model)"),ZBe.forEach(t),BVo=i(ue),tv=n(ue,"LI",{});var eIe=s(tv);Tue=n(eIe,"STRONG",{});var r3t=s(Tue);IVo=r(r3t,"mt5"),r3t.forEach(t),NVo=r(eIe," \u2014 "),KX=n(eIe,"A",{href:!0});var t3t=s(KX);qVo=r(t3t,"MT5ForConditionalGeneration"),t3t.forEach(t),jVo=r(eIe," (MT5 model)"),eIe.forEach(t),DVo=i(ue),av=n(ue,"LI",{});var oIe=s(av);Mue=n(oIe,"STRONG",{});var a3t=s(Mue);GVo=r(a3t,"mvp"),a3t.forEach(t),OVo=r(oIe," \u2014 "),ZX=n(oIe,"A",{href:!0});var n3t=s(ZX);VVo=r(n3t,"MvpForConditionalGeneration"),n3t.forEach(t),XVo=r(oIe," (MVP model)"),oIe.forEach(t),zVo=i(ue),nv=n(ue,"LI",{});var rIe=s(nv);Eue=n(rIe,"STRONG",{});var s3t=s(Eue);WVo=r(s3t,"nllb"),s3t.forEach(t),QVo=r(rIe," \u2014 "),ez=n(rIe,"A",{href:!0});var l3t=s(ez);HVo=r(l3t,"M2M100ForConditionalGeneration"),l3t.forEach(t),UVo=r(rIe," (NLLB model)"),rIe.forEach(t),JVo=i(ue),sv=n(ue,"LI",{});var tIe=s(sv);Cue=n(tIe,"STRONG",{});var i3t=s(Cue);YVo=r(i3t,"pegasus"),i3t.forEach(t),KVo=r(tIe," \u2014 "),oz=n(tIe,"A",{href:!0});var d3t=s(oz);ZVo=r(d3t,"PegasusForConditionalGeneration"),d3t.forEach(t),eXo=r(tIe," (Pegasus model)"),tIe.forEach(t),oXo=i(ue),lv=n(ue,"LI",{});var aIe=s(lv);wue=n(aIe,"STRONG",{});var c3t=s(wue);rXo=r(c3t,"plbart"),c3t.forEach(t),tXo=r(aIe," \u2014 "),rz=n(aIe,"A",{href:!0});var f3t=s(rz);aXo=r(f3t,"PLBartForConditionalGeneration"),f3t.forEach(t),nXo=r(aIe," (PLBart model)"),aIe.forEach(t),sXo=i(ue),iv=n(ue,"LI",{});var nIe=s(iv);Aue=n(nIe,"STRONG",{});var m3t=s(Aue);lXo=r(m3t,"prophetnet"),m3t.forEach(t),iXo=r(nIe," \u2014 "),tz=n(nIe,"A",{href:!0});var g3t=s(tz);dXo=r(g3t,"ProphetNetForConditionalGeneration"),g3t.forEach(t),cXo=r(nIe," (ProphetNet model)"),nIe.forEach(t),fXo=i(ue),dv=n(ue,"LI",{});var sIe=s(dv);Lue=n(sIe,"STRONG",{});var h3t=s(Lue);mXo=r(h3t,"t5"),h3t.forEach(t),gXo=r(sIe," \u2014 "),az=n(sIe,"A",{href:!0});var p3t=s(az);hXo=r(p3t,"T5ForConditionalGeneration"),p3t.forEach(t),pXo=r(sIe," (T5 model)"),sIe.forEach(t),_Xo=i(ue),cv=n(ue,"LI",{});var lIe=s(cv);yue=n(lIe,"STRONG",{});var _3t=s(yue);uXo=r(_3t,"xlm-prophetnet"),_3t.forEach(t),bXo=r(lIe," \u2014 "),nz=n(lIe,"A",{href:!0});var u3t=s(nz);vXo=r(u3t,"XLMProphetNetForConditionalGeneration"),u3t.forEach(t),FXo=r(lIe," (XLM-ProphetNet model)"),lIe.forEach(t),ue.forEach(t),TXo=i(ha),fv=n(ha,"P",{});var iIe=s(fv);MXo=r(iIe,"The model is set in evaluation mode by default using "),xue=n(iIe,"CODE",{});var b3t=s(xue);EXo=r(b3t,"model.eval()"),b3t.forEach(t),CXo=r(iIe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$ue=n(iIe,"CODE",{});var v3t=s($ue);wXo=r(v3t,"model.train()"),v3t.forEach(t),iIe.forEach(t),AXo=i(ha),T(mv.$$.fragment,ha),ha.forEach(t),hl.forEach(t),mQe=i(f),fd=n(f,"H2",{class:!0});var FUe=s(fd);gv=n(FUe,"A",{id:!0,class:!0,href:!0});var F3t=s(gv);kue=n(F3t,"SPAN",{});var T3t=s(kue);T(zy.$$.fragment,T3t),T3t.forEach(t),F3t.forEach(t),LXo=i(FUe),Sue=n(FUe,"SPAN",{});var M3t=s(Sue);yXo=r(M3t,"AutoModelForSequenceClassification"),M3t.forEach(t),FUe.forEach(t),gQe=i(f),No=n(f,"DIV",{class:!0});var pl=s(No);T(Wy.$$.fragment,pl),xXo=i(pl),md=n(pl,"P",{});var bae=s(md);$Xo=r(bae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),sz=n(bae,"A",{href:!0});var E3t=s(sz);kXo=r(E3t,"from_pretrained()"),E3t.forEach(t),SXo=r(bae," class method or the "),lz=n(bae,"A",{href:!0});var C3t=s(lz);RXo=r(C3t,"from_config()"),C3t.forEach(t),PXo=r(bae,` class
method.`),bae.forEach(t),BXo=i(pl),Qy=n(pl,"P",{});var TUe=s(Qy);IXo=r(TUe,"This class cannot be instantiated directly using "),Rue=n(TUe,"CODE",{});var w3t=s(Rue);NXo=r(w3t,"__init__()"),w3t.forEach(t),qXo=r(TUe," (throws an error)."),TUe.forEach(t),jXo=i(pl),pt=n(pl,"DIV",{class:!0});var n7=s(pt);T(Hy.$$.fragment,n7),DXo=i(n7),Pue=n(n7,"P",{});var A3t=s(Pue);GXo=r(A3t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),A3t.forEach(t),OXo=i(n7),gd=n(n7,"P",{});var vae=s(gd);VXo=r(vae,`Note:
Loading a model from its configuration file does `),Bue=n(vae,"STRONG",{});var L3t=s(Bue);XXo=r(L3t,"not"),L3t.forEach(t),zXo=r(vae,` load the model weights. It only affects the
model\u2019s configuration. Use `),iz=n(vae,"A",{href:!0});var y3t=s(iz);WXo=r(y3t,"from_pretrained()"),y3t.forEach(t),QXo=r(vae," to load the model weights."),vae.forEach(t),HXo=i(n7),T(hv.$$.fragment,n7),n7.forEach(t),UXo=i(pl),ro=n(pl,"DIV",{class:!0});var pa=s(ro);T(Uy.$$.fragment,pa),JXo=i(pa),Iue=n(pa,"P",{});var x3t=s(Iue);YXo=r(x3t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),x3t.forEach(t),KXo=i(pa),za=n(pa,"P",{});var s7=s(za);ZXo=r(s7,"The model class to instantiate is selected based on the "),Nue=n(s7,"CODE",{});var $3t=s(Nue);ezo=r($3t,"model_type"),$3t.forEach(t),ozo=r(s7,` property of the config object (either
passed as an argument or loaded from `),que=n(s7,"CODE",{});var k3t=s(que);rzo=r(k3t,"pretrained_model_name_or_path"),k3t.forEach(t),tzo=r(s7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jue=n(s7,"CODE",{});var S3t=s(jue);azo=r(S3t,"pretrained_model_name_or_path"),S3t.forEach(t),nzo=r(s7,":"),s7.forEach(t),szo=i(pa),B=n(pa,"UL",{});var j=s(B);pv=n(j,"LI",{});var dIe=s(pv);Due=n(dIe,"STRONG",{});var R3t=s(Due);lzo=r(R3t,"albert"),R3t.forEach(t),izo=r(dIe," \u2014 "),dz=n(dIe,"A",{href:!0});var P3t=s(dz);dzo=r(P3t,"AlbertForSequenceClassification"),P3t.forEach(t),czo=r(dIe," (ALBERT model)"),dIe.forEach(t),fzo=i(j),_v=n(j,"LI",{});var cIe=s(_v);Gue=n(cIe,"STRONG",{});var B3t=s(Gue);mzo=r(B3t,"bart"),B3t.forEach(t),gzo=r(cIe," \u2014 "),cz=n(cIe,"A",{href:!0});var I3t=s(cz);hzo=r(I3t,"BartForSequenceClassification"),I3t.forEach(t),pzo=r(cIe," (BART model)"),cIe.forEach(t),_zo=i(j),uv=n(j,"LI",{});var fIe=s(uv);Oue=n(fIe,"STRONG",{});var N3t=s(Oue);uzo=r(N3t,"bert"),N3t.forEach(t),bzo=r(fIe," \u2014 "),fz=n(fIe,"A",{href:!0});var q3t=s(fz);vzo=r(q3t,"BertForSequenceClassification"),q3t.forEach(t),Fzo=r(fIe," (BERT model)"),fIe.forEach(t),Tzo=i(j),bv=n(j,"LI",{});var mIe=s(bv);Vue=n(mIe,"STRONG",{});var j3t=s(Vue);Mzo=r(j3t,"big_bird"),j3t.forEach(t),Ezo=r(mIe," \u2014 "),mz=n(mIe,"A",{href:!0});var D3t=s(mz);Czo=r(D3t,"BigBirdForSequenceClassification"),D3t.forEach(t),wzo=r(mIe," (BigBird model)"),mIe.forEach(t),Azo=i(j),vv=n(j,"LI",{});var gIe=s(vv);Xue=n(gIe,"STRONG",{});var G3t=s(Xue);Lzo=r(G3t,"bigbird_pegasus"),G3t.forEach(t),yzo=r(gIe," \u2014 "),gz=n(gIe,"A",{href:!0});var O3t=s(gz);xzo=r(O3t,"BigBirdPegasusForSequenceClassification"),O3t.forEach(t),$zo=r(gIe," (BigBird-Pegasus model)"),gIe.forEach(t),kzo=i(j),Fv=n(j,"LI",{});var hIe=s(Fv);zue=n(hIe,"STRONG",{});var V3t=s(zue);Szo=r(V3t,"bloom"),V3t.forEach(t),Rzo=r(hIe," \u2014 "),hz=n(hIe,"A",{href:!0});var X3t=s(hz);Pzo=r(X3t,"BloomForSequenceClassification"),X3t.forEach(t),Bzo=r(hIe," (BLOOM model)"),hIe.forEach(t),Izo=i(j),Tv=n(j,"LI",{});var pIe=s(Tv);Wue=n(pIe,"STRONG",{});var z3t=s(Wue);Nzo=r(z3t,"camembert"),z3t.forEach(t),qzo=r(pIe," \u2014 "),pz=n(pIe,"A",{href:!0});var W3t=s(pz);jzo=r(W3t,"CamembertForSequenceClassification"),W3t.forEach(t),Dzo=r(pIe," (CamemBERT model)"),pIe.forEach(t),Gzo=i(j),Mv=n(j,"LI",{});var _Ie=s(Mv);Que=n(_Ie,"STRONG",{});var Q3t=s(Que);Ozo=r(Q3t,"canine"),Q3t.forEach(t),Vzo=r(_Ie," \u2014 "),_z=n(_Ie,"A",{href:!0});var H3t=s(_z);Xzo=r(H3t,"CanineForSequenceClassification"),H3t.forEach(t),zzo=r(_Ie," (CANINE model)"),_Ie.forEach(t),Wzo=i(j),Ev=n(j,"LI",{});var uIe=s(Ev);Hue=n(uIe,"STRONG",{});var U3t=s(Hue);Qzo=r(U3t,"convbert"),U3t.forEach(t),Hzo=r(uIe," \u2014 "),uz=n(uIe,"A",{href:!0});var J3t=s(uz);Uzo=r(J3t,"ConvBertForSequenceClassification"),J3t.forEach(t),Jzo=r(uIe," (ConvBERT model)"),uIe.forEach(t),Yzo=i(j),Cv=n(j,"LI",{});var bIe=s(Cv);Uue=n(bIe,"STRONG",{});var Y3t=s(Uue);Kzo=r(Y3t,"ctrl"),Y3t.forEach(t),Zzo=r(bIe," \u2014 "),bz=n(bIe,"A",{href:!0});var K3t=s(bz);eWo=r(K3t,"CTRLForSequenceClassification"),K3t.forEach(t),oWo=r(bIe," (CTRL model)"),bIe.forEach(t),rWo=i(j),wv=n(j,"LI",{});var vIe=s(wv);Jue=n(vIe,"STRONG",{});var Z3t=s(Jue);tWo=r(Z3t,"data2vec-text"),Z3t.forEach(t),aWo=r(vIe," \u2014 "),vz=n(vIe,"A",{href:!0});var ewt=s(vz);nWo=r(ewt,"Data2VecTextForSequenceClassification"),ewt.forEach(t),sWo=r(vIe," (Data2VecText model)"),vIe.forEach(t),lWo=i(j),Av=n(j,"LI",{});var FIe=s(Av);Yue=n(FIe,"STRONG",{});var owt=s(Yue);iWo=r(owt,"deberta"),owt.forEach(t),dWo=r(FIe," \u2014 "),Fz=n(FIe,"A",{href:!0});var rwt=s(Fz);cWo=r(rwt,"DebertaForSequenceClassification"),rwt.forEach(t),fWo=r(FIe," (DeBERTa model)"),FIe.forEach(t),mWo=i(j),Lv=n(j,"LI",{});var TIe=s(Lv);Kue=n(TIe,"STRONG",{});var twt=s(Kue);gWo=r(twt,"deberta-v2"),twt.forEach(t),hWo=r(TIe," \u2014 "),Tz=n(TIe,"A",{href:!0});var awt=s(Tz);pWo=r(awt,"DebertaV2ForSequenceClassification"),awt.forEach(t),_Wo=r(TIe," (DeBERTa-v2 model)"),TIe.forEach(t),uWo=i(j),yv=n(j,"LI",{});var MIe=s(yv);Zue=n(MIe,"STRONG",{});var nwt=s(Zue);bWo=r(nwt,"distilbert"),nwt.forEach(t),vWo=r(MIe," \u2014 "),Mz=n(MIe,"A",{href:!0});var swt=s(Mz);FWo=r(swt,"DistilBertForSequenceClassification"),swt.forEach(t),TWo=r(MIe," (DistilBERT model)"),MIe.forEach(t),MWo=i(j),xv=n(j,"LI",{});var EIe=s(xv);e2e=n(EIe,"STRONG",{});var lwt=s(e2e);EWo=r(lwt,"electra"),lwt.forEach(t),CWo=r(EIe," \u2014 "),Ez=n(EIe,"A",{href:!0});var iwt=s(Ez);wWo=r(iwt,"ElectraForSequenceClassification"),iwt.forEach(t),AWo=r(EIe," (ELECTRA model)"),EIe.forEach(t),LWo=i(j),$v=n(j,"LI",{});var CIe=s($v);o2e=n(CIe,"STRONG",{});var dwt=s(o2e);yWo=r(dwt,"flaubert"),dwt.forEach(t),xWo=r(CIe," \u2014 "),Cz=n(CIe,"A",{href:!0});var cwt=s(Cz);$Wo=r(cwt,"FlaubertForSequenceClassification"),cwt.forEach(t),kWo=r(CIe," (FlauBERT model)"),CIe.forEach(t),SWo=i(j),kv=n(j,"LI",{});var wIe=s(kv);r2e=n(wIe,"STRONG",{});var fwt=s(r2e);RWo=r(fwt,"fnet"),fwt.forEach(t),PWo=r(wIe," \u2014 "),wz=n(wIe,"A",{href:!0});var mwt=s(wz);BWo=r(mwt,"FNetForSequenceClassification"),mwt.forEach(t),IWo=r(wIe," (FNet model)"),wIe.forEach(t),NWo=i(j),Sv=n(j,"LI",{});var AIe=s(Sv);t2e=n(AIe,"STRONG",{});var gwt=s(t2e);qWo=r(gwt,"funnel"),gwt.forEach(t),jWo=r(AIe," \u2014 "),Az=n(AIe,"A",{href:!0});var hwt=s(Az);DWo=r(hwt,"FunnelForSequenceClassification"),hwt.forEach(t),GWo=r(AIe," (Funnel Transformer model)"),AIe.forEach(t),OWo=i(j),Rv=n(j,"LI",{});var LIe=s(Rv);a2e=n(LIe,"STRONG",{});var pwt=s(a2e);VWo=r(pwt,"gpt2"),pwt.forEach(t),XWo=r(LIe," \u2014 "),Lz=n(LIe,"A",{href:!0});var _wt=s(Lz);zWo=r(_wt,"GPT2ForSequenceClassification"),_wt.forEach(t),WWo=r(LIe," (OpenAI GPT-2 model)"),LIe.forEach(t),QWo=i(j),Pv=n(j,"LI",{});var yIe=s(Pv);n2e=n(yIe,"STRONG",{});var uwt=s(n2e);HWo=r(uwt,"gpt_neo"),uwt.forEach(t),UWo=r(yIe," \u2014 "),yz=n(yIe,"A",{href:!0});var bwt=s(yz);JWo=r(bwt,"GPTNeoForSequenceClassification"),bwt.forEach(t),YWo=r(yIe," (GPT Neo model)"),yIe.forEach(t),KWo=i(j),Bv=n(j,"LI",{});var xIe=s(Bv);s2e=n(xIe,"STRONG",{});var vwt=s(s2e);ZWo=r(vwt,"gptj"),vwt.forEach(t),eQo=r(xIe," \u2014 "),xz=n(xIe,"A",{href:!0});var Fwt=s(xz);oQo=r(Fwt,"GPTJForSequenceClassification"),Fwt.forEach(t),rQo=r(xIe," (GPT-J model)"),xIe.forEach(t),tQo=i(j),Iv=n(j,"LI",{});var $Ie=s(Iv);l2e=n($Ie,"STRONG",{});var Twt=s(l2e);aQo=r(Twt,"ibert"),Twt.forEach(t),nQo=r($Ie," \u2014 "),$z=n($Ie,"A",{href:!0});var Mwt=s($z);sQo=r(Mwt,"IBertForSequenceClassification"),Mwt.forEach(t),lQo=r($Ie," (I-BERT model)"),$Ie.forEach(t),iQo=i(j),Nv=n(j,"LI",{});var kIe=s(Nv);i2e=n(kIe,"STRONG",{});var Ewt=s(i2e);dQo=r(Ewt,"layoutlm"),Ewt.forEach(t),cQo=r(kIe," \u2014 "),kz=n(kIe,"A",{href:!0});var Cwt=s(kz);fQo=r(Cwt,"LayoutLMForSequenceClassification"),Cwt.forEach(t),mQo=r(kIe," (LayoutLM model)"),kIe.forEach(t),gQo=i(j),qv=n(j,"LI",{});var SIe=s(qv);d2e=n(SIe,"STRONG",{});var wwt=s(d2e);hQo=r(wwt,"layoutlmv2"),wwt.forEach(t),pQo=r(SIe," \u2014 "),Sz=n(SIe,"A",{href:!0});var Awt=s(Sz);_Qo=r(Awt,"LayoutLMv2ForSequenceClassification"),Awt.forEach(t),uQo=r(SIe," (LayoutLMv2 model)"),SIe.forEach(t),bQo=i(j),jv=n(j,"LI",{});var RIe=s(jv);c2e=n(RIe,"STRONG",{});var Lwt=s(c2e);vQo=r(Lwt,"layoutlmv3"),Lwt.forEach(t),FQo=r(RIe," \u2014 "),Rz=n(RIe,"A",{href:!0});var ywt=s(Rz);TQo=r(ywt,"LayoutLMv3ForSequenceClassification"),ywt.forEach(t),MQo=r(RIe," (LayoutLMv3 model)"),RIe.forEach(t),EQo=i(j),Dv=n(j,"LI",{});var PIe=s(Dv);f2e=n(PIe,"STRONG",{});var xwt=s(f2e);CQo=r(xwt,"led"),xwt.forEach(t),wQo=r(PIe," \u2014 "),Pz=n(PIe,"A",{href:!0});var $wt=s(Pz);AQo=r($wt,"LEDForSequenceClassification"),$wt.forEach(t),LQo=r(PIe," (LED model)"),PIe.forEach(t),yQo=i(j),Gv=n(j,"LI",{});var BIe=s(Gv);m2e=n(BIe,"STRONG",{});var kwt=s(m2e);xQo=r(kwt,"longformer"),kwt.forEach(t),$Qo=r(BIe," \u2014 "),Bz=n(BIe,"A",{href:!0});var Swt=s(Bz);kQo=r(Swt,"LongformerForSequenceClassification"),Swt.forEach(t),SQo=r(BIe," (Longformer model)"),BIe.forEach(t),RQo=i(j),Ov=n(j,"LI",{});var IIe=s(Ov);g2e=n(IIe,"STRONG",{});var Rwt=s(g2e);PQo=r(Rwt,"luke"),Rwt.forEach(t),BQo=r(IIe," \u2014 "),Iz=n(IIe,"A",{href:!0});var Pwt=s(Iz);IQo=r(Pwt,"LukeForSequenceClassification"),Pwt.forEach(t),NQo=r(IIe," (LUKE model)"),IIe.forEach(t),qQo=i(j),Vv=n(j,"LI",{});var NIe=s(Vv);h2e=n(NIe,"STRONG",{});var Bwt=s(h2e);jQo=r(Bwt,"mbart"),Bwt.forEach(t),DQo=r(NIe," \u2014 "),Nz=n(NIe,"A",{href:!0});var Iwt=s(Nz);GQo=r(Iwt,"MBartForSequenceClassification"),Iwt.forEach(t),OQo=r(NIe," (mBART model)"),NIe.forEach(t),VQo=i(j),Xv=n(j,"LI",{});var qIe=s(Xv);p2e=n(qIe,"STRONG",{});var Nwt=s(p2e);XQo=r(Nwt,"megatron-bert"),Nwt.forEach(t),zQo=r(qIe," \u2014 "),qz=n(qIe,"A",{href:!0});var qwt=s(qz);WQo=r(qwt,"MegatronBertForSequenceClassification"),qwt.forEach(t),QQo=r(qIe," (Megatron-BERT model)"),qIe.forEach(t),HQo=i(j),zv=n(j,"LI",{});var jIe=s(zv);_2e=n(jIe,"STRONG",{});var jwt=s(_2e);UQo=r(jwt,"mobilebert"),jwt.forEach(t),JQo=r(jIe," \u2014 "),jz=n(jIe,"A",{href:!0});var Dwt=s(jz);YQo=r(Dwt,"MobileBertForSequenceClassification"),Dwt.forEach(t),KQo=r(jIe," (MobileBERT model)"),jIe.forEach(t),ZQo=i(j),Wv=n(j,"LI",{});var DIe=s(Wv);u2e=n(DIe,"STRONG",{});var Gwt=s(u2e);eHo=r(Gwt,"mpnet"),Gwt.forEach(t),oHo=r(DIe," \u2014 "),Dz=n(DIe,"A",{href:!0});var Owt=s(Dz);rHo=r(Owt,"MPNetForSequenceClassification"),Owt.forEach(t),tHo=r(DIe," (MPNet model)"),DIe.forEach(t),aHo=i(j),Qv=n(j,"LI",{});var GIe=s(Qv);b2e=n(GIe,"STRONG",{});var Vwt=s(b2e);nHo=r(Vwt,"mvp"),Vwt.forEach(t),sHo=r(GIe," \u2014 "),Gz=n(GIe,"A",{href:!0});var Xwt=s(Gz);lHo=r(Xwt,"MvpForSequenceClassification"),Xwt.forEach(t),iHo=r(GIe," (MVP model)"),GIe.forEach(t),dHo=i(j),Hv=n(j,"LI",{});var OIe=s(Hv);v2e=n(OIe,"STRONG",{});var zwt=s(v2e);cHo=r(zwt,"nezha"),zwt.forEach(t),fHo=r(OIe," \u2014 "),Oz=n(OIe,"A",{href:!0});var Wwt=s(Oz);mHo=r(Wwt,"NezhaForSequenceClassification"),Wwt.forEach(t),gHo=r(OIe," (Nezha model)"),OIe.forEach(t),hHo=i(j),Uv=n(j,"LI",{});var VIe=s(Uv);F2e=n(VIe,"STRONG",{});var Qwt=s(F2e);pHo=r(Qwt,"nystromformer"),Qwt.forEach(t),_Ho=r(VIe," \u2014 "),Vz=n(VIe,"A",{href:!0});var Hwt=s(Vz);uHo=r(Hwt,"NystromformerForSequenceClassification"),Hwt.forEach(t),bHo=r(VIe," (Nystr\xF6mformer model)"),VIe.forEach(t),vHo=i(j),Jv=n(j,"LI",{});var XIe=s(Jv);T2e=n(XIe,"STRONG",{});var Uwt=s(T2e);FHo=r(Uwt,"openai-gpt"),Uwt.forEach(t),THo=r(XIe," \u2014 "),Xz=n(XIe,"A",{href:!0});var Jwt=s(Xz);MHo=r(Jwt,"OpenAIGPTForSequenceClassification"),Jwt.forEach(t),EHo=r(XIe," (OpenAI GPT model)"),XIe.forEach(t),CHo=i(j),Yv=n(j,"LI",{});var zIe=s(Yv);M2e=n(zIe,"STRONG",{});var Ywt=s(M2e);wHo=r(Ywt,"opt"),Ywt.forEach(t),AHo=r(zIe," \u2014 "),zz=n(zIe,"A",{href:!0});var Kwt=s(zz);LHo=r(Kwt,"OPTForSequenceClassification"),Kwt.forEach(t),yHo=r(zIe," (OPT model)"),zIe.forEach(t),xHo=i(j),Kv=n(j,"LI",{});var WIe=s(Kv);E2e=n(WIe,"STRONG",{});var Zwt=s(E2e);$Ho=r(Zwt,"perceiver"),Zwt.forEach(t),kHo=r(WIe," \u2014 "),Wz=n(WIe,"A",{href:!0});var e6t=s(Wz);SHo=r(e6t,"PerceiverForSequenceClassification"),e6t.forEach(t),RHo=r(WIe," (Perceiver model)"),WIe.forEach(t),PHo=i(j),Zv=n(j,"LI",{});var QIe=s(Zv);C2e=n(QIe,"STRONG",{});var o6t=s(C2e);BHo=r(o6t,"plbart"),o6t.forEach(t),IHo=r(QIe," \u2014 "),Qz=n(QIe,"A",{href:!0});var r6t=s(Qz);NHo=r(r6t,"PLBartForSequenceClassification"),r6t.forEach(t),qHo=r(QIe," (PLBart model)"),QIe.forEach(t),jHo=i(j),e0=n(j,"LI",{});var HIe=s(e0);w2e=n(HIe,"STRONG",{});var t6t=s(w2e);DHo=r(t6t,"qdqbert"),t6t.forEach(t),GHo=r(HIe," \u2014 "),Hz=n(HIe,"A",{href:!0});var a6t=s(Hz);OHo=r(a6t,"QDQBertForSequenceClassification"),a6t.forEach(t),VHo=r(HIe," (QDQBert model)"),HIe.forEach(t),XHo=i(j),o0=n(j,"LI",{});var UIe=s(o0);A2e=n(UIe,"STRONG",{});var n6t=s(A2e);zHo=r(n6t,"reformer"),n6t.forEach(t),WHo=r(UIe," \u2014 "),Uz=n(UIe,"A",{href:!0});var s6t=s(Uz);QHo=r(s6t,"ReformerForSequenceClassification"),s6t.forEach(t),HHo=r(UIe," (Reformer model)"),UIe.forEach(t),UHo=i(j),r0=n(j,"LI",{});var JIe=s(r0);L2e=n(JIe,"STRONG",{});var l6t=s(L2e);JHo=r(l6t,"rembert"),l6t.forEach(t),YHo=r(JIe," \u2014 "),Jz=n(JIe,"A",{href:!0});var i6t=s(Jz);KHo=r(i6t,"RemBertForSequenceClassification"),i6t.forEach(t),ZHo=r(JIe," (RemBERT model)"),JIe.forEach(t),eUo=i(j),t0=n(j,"LI",{});var YIe=s(t0);y2e=n(YIe,"STRONG",{});var d6t=s(y2e);oUo=r(d6t,"roberta"),d6t.forEach(t),rUo=r(YIe," \u2014 "),Yz=n(YIe,"A",{href:!0});var c6t=s(Yz);tUo=r(c6t,"RobertaForSequenceClassification"),c6t.forEach(t),aUo=r(YIe," (RoBERTa model)"),YIe.forEach(t),nUo=i(j),a0=n(j,"LI",{});var KIe=s(a0);x2e=n(KIe,"STRONG",{});var f6t=s(x2e);sUo=r(f6t,"roformer"),f6t.forEach(t),lUo=r(KIe," \u2014 "),Kz=n(KIe,"A",{href:!0});var m6t=s(Kz);iUo=r(m6t,"RoFormerForSequenceClassification"),m6t.forEach(t),dUo=r(KIe," (RoFormer model)"),KIe.forEach(t),cUo=i(j),n0=n(j,"LI",{});var ZIe=s(n0);$2e=n(ZIe,"STRONG",{});var g6t=s($2e);fUo=r(g6t,"squeezebert"),g6t.forEach(t),mUo=r(ZIe," \u2014 "),Zz=n(ZIe,"A",{href:!0});var h6t=s(Zz);gUo=r(h6t,"SqueezeBertForSequenceClassification"),h6t.forEach(t),hUo=r(ZIe," (SqueezeBERT model)"),ZIe.forEach(t),pUo=i(j),s0=n(j,"LI",{});var eNe=s(s0);k2e=n(eNe,"STRONG",{});var p6t=s(k2e);_Uo=r(p6t,"tapas"),p6t.forEach(t),uUo=r(eNe," \u2014 "),eW=n(eNe,"A",{href:!0});var _6t=s(eW);bUo=r(_6t,"TapasForSequenceClassification"),_6t.forEach(t),vUo=r(eNe," (TAPAS model)"),eNe.forEach(t),FUo=i(j),l0=n(j,"LI",{});var oNe=s(l0);S2e=n(oNe,"STRONG",{});var u6t=s(S2e);TUo=r(u6t,"transfo-xl"),u6t.forEach(t),MUo=r(oNe," \u2014 "),oW=n(oNe,"A",{href:!0});var b6t=s(oW);EUo=r(b6t,"TransfoXLForSequenceClassification"),b6t.forEach(t),CUo=r(oNe," (Transformer-XL model)"),oNe.forEach(t),wUo=i(j),i0=n(j,"LI",{});var rNe=s(i0);R2e=n(rNe,"STRONG",{});var v6t=s(R2e);AUo=r(v6t,"xlm"),v6t.forEach(t),LUo=r(rNe," \u2014 "),rW=n(rNe,"A",{href:!0});var F6t=s(rW);yUo=r(F6t,"XLMForSequenceClassification"),F6t.forEach(t),xUo=r(rNe," (XLM model)"),rNe.forEach(t),$Uo=i(j),d0=n(j,"LI",{});var tNe=s(d0);P2e=n(tNe,"STRONG",{});var T6t=s(P2e);kUo=r(T6t,"xlm-roberta"),T6t.forEach(t),SUo=r(tNe," \u2014 "),tW=n(tNe,"A",{href:!0});var M6t=s(tW);RUo=r(M6t,"XLMRobertaForSequenceClassification"),M6t.forEach(t),PUo=r(tNe," (XLM-RoBERTa model)"),tNe.forEach(t),BUo=i(j),c0=n(j,"LI",{});var aNe=s(c0);B2e=n(aNe,"STRONG",{});var E6t=s(B2e);IUo=r(E6t,"xlm-roberta-xl"),E6t.forEach(t),NUo=r(aNe," \u2014 "),aW=n(aNe,"A",{href:!0});var C6t=s(aW);qUo=r(C6t,"XLMRobertaXLForSequenceClassification"),C6t.forEach(t),jUo=r(aNe," (XLM-RoBERTa-XL model)"),aNe.forEach(t),DUo=i(j),f0=n(j,"LI",{});var nNe=s(f0);I2e=n(nNe,"STRONG",{});var w6t=s(I2e);GUo=r(w6t,"xlnet"),w6t.forEach(t),OUo=r(nNe," \u2014 "),nW=n(nNe,"A",{href:!0});var A6t=s(nW);VUo=r(A6t,"XLNetForSequenceClassification"),A6t.forEach(t),XUo=r(nNe," (XLNet model)"),nNe.forEach(t),zUo=i(j),m0=n(j,"LI",{});var sNe=s(m0);N2e=n(sNe,"STRONG",{});var L6t=s(N2e);WUo=r(L6t,"yoso"),L6t.forEach(t),QUo=r(sNe," \u2014 "),sW=n(sNe,"A",{href:!0});var y6t=s(sW);HUo=r(y6t,"YosoForSequenceClassification"),y6t.forEach(t),UUo=r(sNe," (YOSO model)"),sNe.forEach(t),j.forEach(t),JUo=i(pa),g0=n(pa,"P",{});var lNe=s(g0);YUo=r(lNe,"The model is set in evaluation mode by default using "),q2e=n(lNe,"CODE",{});var x6t=s(q2e);KUo=r(x6t,"model.eval()"),x6t.forEach(t),ZUo=r(lNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),j2e=n(lNe,"CODE",{});var $6t=s(j2e);eJo=r($6t,"model.train()"),$6t.forEach(t),lNe.forEach(t),oJo=i(pa),T(h0.$$.fragment,pa),pa.forEach(t),pl.forEach(t),hQe=i(f),hd=n(f,"H2",{class:!0});var MUe=s(hd);p0=n(MUe,"A",{id:!0,class:!0,href:!0});var k6t=s(p0);D2e=n(k6t,"SPAN",{});var S6t=s(D2e);T(Jy.$$.fragment,S6t),S6t.forEach(t),k6t.forEach(t),rJo=i(MUe),G2e=n(MUe,"SPAN",{});var R6t=s(G2e);tJo=r(R6t,"AutoModelForMultipleChoice"),R6t.forEach(t),MUe.forEach(t),pQe=i(f),qo=n(f,"DIV",{class:!0});var _l=s(qo);T(Yy.$$.fragment,_l),aJo=i(_l),pd=n(_l,"P",{});var Fae=s(pd);nJo=r(Fae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),lW=n(Fae,"A",{href:!0});var P6t=s(lW);sJo=r(P6t,"from_pretrained()"),P6t.forEach(t),lJo=r(Fae," class method or the "),iW=n(Fae,"A",{href:!0});var B6t=s(iW);iJo=r(B6t,"from_config()"),B6t.forEach(t),dJo=r(Fae,` class
method.`),Fae.forEach(t),cJo=i(_l),Ky=n(_l,"P",{});var EUe=s(Ky);fJo=r(EUe,"This class cannot be instantiated directly using "),O2e=n(EUe,"CODE",{});var I6t=s(O2e);mJo=r(I6t,"__init__()"),I6t.forEach(t),gJo=r(EUe," (throws an error)."),EUe.forEach(t),hJo=i(_l),_t=n(_l,"DIV",{class:!0});var l7=s(_t);T(Zy.$$.fragment,l7),pJo=i(l7),V2e=n(l7,"P",{});var N6t=s(V2e);_Jo=r(N6t,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),N6t.forEach(t),uJo=i(l7),_d=n(l7,"P",{});var Tae=s(_d);bJo=r(Tae,`Note:
Loading a model from its configuration file does `),X2e=n(Tae,"STRONG",{});var q6t=s(X2e);vJo=r(q6t,"not"),q6t.forEach(t),FJo=r(Tae,` load the model weights. It only affects the
model\u2019s configuration. Use `),dW=n(Tae,"A",{href:!0});var j6t=s(dW);TJo=r(j6t,"from_pretrained()"),j6t.forEach(t),MJo=r(Tae," to load the model weights."),Tae.forEach(t),EJo=i(l7),T(_0.$$.fragment,l7),l7.forEach(t),CJo=i(_l),to=n(_l,"DIV",{class:!0});var _a=s(to);T(e9.$$.fragment,_a),wJo=i(_a),z2e=n(_a,"P",{});var D6t=s(z2e);AJo=r(D6t,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),D6t.forEach(t),LJo=i(_a),Wa=n(_a,"P",{});var i7=s(Wa);yJo=r(i7,"The model class to instantiate is selected based on the "),W2e=n(i7,"CODE",{});var G6t=s(W2e);xJo=r(G6t,"model_type"),G6t.forEach(t),$Jo=r(i7,` property of the config object (either
passed as an argument or loaded from `),Q2e=n(i7,"CODE",{});var O6t=s(Q2e);kJo=r(O6t,"pretrained_model_name_or_path"),O6t.forEach(t),SJo=r(i7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H2e=n(i7,"CODE",{});var V6t=s(H2e);RJo=r(V6t,"pretrained_model_name_or_path"),V6t.forEach(t),PJo=r(i7,":"),i7.forEach(t),BJo=i(_a),Z=n(_a,"UL",{});var ee=s(Z);u0=n(ee,"LI",{});var iNe=s(u0);U2e=n(iNe,"STRONG",{});var X6t=s(U2e);IJo=r(X6t,"albert"),X6t.forEach(t),NJo=r(iNe," \u2014 "),cW=n(iNe,"A",{href:!0});var z6t=s(cW);qJo=r(z6t,"AlbertForMultipleChoice"),z6t.forEach(t),jJo=r(iNe," (ALBERT model)"),iNe.forEach(t),DJo=i(ee),b0=n(ee,"LI",{});var dNe=s(b0);J2e=n(dNe,"STRONG",{});var W6t=s(J2e);GJo=r(W6t,"bert"),W6t.forEach(t),OJo=r(dNe," \u2014 "),fW=n(dNe,"A",{href:!0});var Q6t=s(fW);VJo=r(Q6t,"BertForMultipleChoice"),Q6t.forEach(t),XJo=r(dNe," (BERT model)"),dNe.forEach(t),zJo=i(ee),v0=n(ee,"LI",{});var cNe=s(v0);Y2e=n(cNe,"STRONG",{});var H6t=s(Y2e);WJo=r(H6t,"big_bird"),H6t.forEach(t),QJo=r(cNe," \u2014 "),mW=n(cNe,"A",{href:!0});var U6t=s(mW);HJo=r(U6t,"BigBirdForMultipleChoice"),U6t.forEach(t),UJo=r(cNe," (BigBird model)"),cNe.forEach(t),JJo=i(ee),F0=n(ee,"LI",{});var fNe=s(F0);K2e=n(fNe,"STRONG",{});var J6t=s(K2e);YJo=r(J6t,"camembert"),J6t.forEach(t),KJo=r(fNe," \u2014 "),gW=n(fNe,"A",{href:!0});var Y6t=s(gW);ZJo=r(Y6t,"CamembertForMultipleChoice"),Y6t.forEach(t),eYo=r(fNe," (CamemBERT model)"),fNe.forEach(t),oYo=i(ee),T0=n(ee,"LI",{});var mNe=s(T0);Z2e=n(mNe,"STRONG",{});var K6t=s(Z2e);rYo=r(K6t,"canine"),K6t.forEach(t),tYo=r(mNe," \u2014 "),hW=n(mNe,"A",{href:!0});var Z6t=s(hW);aYo=r(Z6t,"CanineForMultipleChoice"),Z6t.forEach(t),nYo=r(mNe," (CANINE model)"),mNe.forEach(t),sYo=i(ee),M0=n(ee,"LI",{});var gNe=s(M0);e1e=n(gNe,"STRONG",{});var eAt=s(e1e);lYo=r(eAt,"convbert"),eAt.forEach(t),iYo=r(gNe," \u2014 "),pW=n(gNe,"A",{href:!0});var oAt=s(pW);dYo=r(oAt,"ConvBertForMultipleChoice"),oAt.forEach(t),cYo=r(gNe," (ConvBERT model)"),gNe.forEach(t),fYo=i(ee),E0=n(ee,"LI",{});var hNe=s(E0);o1e=n(hNe,"STRONG",{});var rAt=s(o1e);mYo=r(rAt,"data2vec-text"),rAt.forEach(t),gYo=r(hNe," \u2014 "),_W=n(hNe,"A",{href:!0});var tAt=s(_W);hYo=r(tAt,"Data2VecTextForMultipleChoice"),tAt.forEach(t),pYo=r(hNe," (Data2VecText model)"),hNe.forEach(t),_Yo=i(ee),C0=n(ee,"LI",{});var pNe=s(C0);r1e=n(pNe,"STRONG",{});var aAt=s(r1e);uYo=r(aAt,"deberta-v2"),aAt.forEach(t),bYo=r(pNe," \u2014 "),uW=n(pNe,"A",{href:!0});var nAt=s(uW);vYo=r(nAt,"DebertaV2ForMultipleChoice"),nAt.forEach(t),FYo=r(pNe," (DeBERTa-v2 model)"),pNe.forEach(t),TYo=i(ee),w0=n(ee,"LI",{});var _Ne=s(w0);t1e=n(_Ne,"STRONG",{});var sAt=s(t1e);MYo=r(sAt,"distilbert"),sAt.forEach(t),EYo=r(_Ne," \u2014 "),bW=n(_Ne,"A",{href:!0});var lAt=s(bW);CYo=r(lAt,"DistilBertForMultipleChoice"),lAt.forEach(t),wYo=r(_Ne," (DistilBERT model)"),_Ne.forEach(t),AYo=i(ee),A0=n(ee,"LI",{});var uNe=s(A0);a1e=n(uNe,"STRONG",{});var iAt=s(a1e);LYo=r(iAt,"electra"),iAt.forEach(t),yYo=r(uNe," \u2014 "),vW=n(uNe,"A",{href:!0});var dAt=s(vW);xYo=r(dAt,"ElectraForMultipleChoice"),dAt.forEach(t),$Yo=r(uNe," (ELECTRA model)"),uNe.forEach(t),kYo=i(ee),L0=n(ee,"LI",{});var bNe=s(L0);n1e=n(bNe,"STRONG",{});var cAt=s(n1e);SYo=r(cAt,"flaubert"),cAt.forEach(t),RYo=r(bNe," \u2014 "),FW=n(bNe,"A",{href:!0});var fAt=s(FW);PYo=r(fAt,"FlaubertForMultipleChoice"),fAt.forEach(t),BYo=r(bNe," (FlauBERT model)"),bNe.forEach(t),IYo=i(ee),y0=n(ee,"LI",{});var vNe=s(y0);s1e=n(vNe,"STRONG",{});var mAt=s(s1e);NYo=r(mAt,"fnet"),mAt.forEach(t),qYo=r(vNe," \u2014 "),TW=n(vNe,"A",{href:!0});var gAt=s(TW);jYo=r(gAt,"FNetForMultipleChoice"),gAt.forEach(t),DYo=r(vNe," (FNet model)"),vNe.forEach(t),GYo=i(ee),x0=n(ee,"LI",{});var FNe=s(x0);l1e=n(FNe,"STRONG",{});var hAt=s(l1e);OYo=r(hAt,"funnel"),hAt.forEach(t),VYo=r(FNe," \u2014 "),MW=n(FNe,"A",{href:!0});var pAt=s(MW);XYo=r(pAt,"FunnelForMultipleChoice"),pAt.forEach(t),zYo=r(FNe," (Funnel Transformer model)"),FNe.forEach(t),WYo=i(ee),$0=n(ee,"LI",{});var TNe=s($0);i1e=n(TNe,"STRONG",{});var _At=s(i1e);QYo=r(_At,"ibert"),_At.forEach(t),HYo=r(TNe," \u2014 "),EW=n(TNe,"A",{href:!0});var uAt=s(EW);UYo=r(uAt,"IBertForMultipleChoice"),uAt.forEach(t),JYo=r(TNe," (I-BERT model)"),TNe.forEach(t),YYo=i(ee),k0=n(ee,"LI",{});var MNe=s(k0);d1e=n(MNe,"STRONG",{});var bAt=s(d1e);KYo=r(bAt,"longformer"),bAt.forEach(t),ZYo=r(MNe," \u2014 "),CW=n(MNe,"A",{href:!0});var vAt=s(CW);eKo=r(vAt,"LongformerForMultipleChoice"),vAt.forEach(t),oKo=r(MNe," (Longformer model)"),MNe.forEach(t),rKo=i(ee),S0=n(ee,"LI",{});var ENe=s(S0);c1e=n(ENe,"STRONG",{});var FAt=s(c1e);tKo=r(FAt,"luke"),FAt.forEach(t),aKo=r(ENe," \u2014 "),wW=n(ENe,"A",{href:!0});var TAt=s(wW);nKo=r(TAt,"LukeForMultipleChoice"),TAt.forEach(t),sKo=r(ENe," (LUKE model)"),ENe.forEach(t),lKo=i(ee),R0=n(ee,"LI",{});var CNe=s(R0);f1e=n(CNe,"STRONG",{});var MAt=s(f1e);iKo=r(MAt,"megatron-bert"),MAt.forEach(t),dKo=r(CNe," \u2014 "),AW=n(CNe,"A",{href:!0});var EAt=s(AW);cKo=r(EAt,"MegatronBertForMultipleChoice"),EAt.forEach(t),fKo=r(CNe," (Megatron-BERT model)"),CNe.forEach(t),mKo=i(ee),P0=n(ee,"LI",{});var wNe=s(P0);m1e=n(wNe,"STRONG",{});var CAt=s(m1e);gKo=r(CAt,"mobilebert"),CAt.forEach(t),hKo=r(wNe," \u2014 "),LW=n(wNe,"A",{href:!0});var wAt=s(LW);pKo=r(wAt,"MobileBertForMultipleChoice"),wAt.forEach(t),_Ko=r(wNe," (MobileBERT model)"),wNe.forEach(t),uKo=i(ee),B0=n(ee,"LI",{});var ANe=s(B0);g1e=n(ANe,"STRONG",{});var AAt=s(g1e);bKo=r(AAt,"mpnet"),AAt.forEach(t),vKo=r(ANe," \u2014 "),yW=n(ANe,"A",{href:!0});var LAt=s(yW);FKo=r(LAt,"MPNetForMultipleChoice"),LAt.forEach(t),TKo=r(ANe," (MPNet model)"),ANe.forEach(t),MKo=i(ee),I0=n(ee,"LI",{});var LNe=s(I0);h1e=n(LNe,"STRONG",{});var yAt=s(h1e);EKo=r(yAt,"nezha"),yAt.forEach(t),CKo=r(LNe," \u2014 "),xW=n(LNe,"A",{href:!0});var xAt=s(xW);wKo=r(xAt,"NezhaForMultipleChoice"),xAt.forEach(t),AKo=r(LNe," (Nezha model)"),LNe.forEach(t),LKo=i(ee),N0=n(ee,"LI",{});var yNe=s(N0);p1e=n(yNe,"STRONG",{});var $At=s(p1e);yKo=r($At,"nystromformer"),$At.forEach(t),xKo=r(yNe," \u2014 "),$W=n(yNe,"A",{href:!0});var kAt=s($W);$Ko=r(kAt,"NystromformerForMultipleChoice"),kAt.forEach(t),kKo=r(yNe," (Nystr\xF6mformer model)"),yNe.forEach(t),SKo=i(ee),q0=n(ee,"LI",{});var xNe=s(q0);_1e=n(xNe,"STRONG",{});var SAt=s(_1e);RKo=r(SAt,"qdqbert"),SAt.forEach(t),PKo=r(xNe," \u2014 "),kW=n(xNe,"A",{href:!0});var RAt=s(kW);BKo=r(RAt,"QDQBertForMultipleChoice"),RAt.forEach(t),IKo=r(xNe," (QDQBert model)"),xNe.forEach(t),NKo=i(ee),j0=n(ee,"LI",{});var $Ne=s(j0);u1e=n($Ne,"STRONG",{});var PAt=s(u1e);qKo=r(PAt,"rembert"),PAt.forEach(t),jKo=r($Ne," \u2014 "),SW=n($Ne,"A",{href:!0});var BAt=s(SW);DKo=r(BAt,"RemBertForMultipleChoice"),BAt.forEach(t),GKo=r($Ne," (RemBERT model)"),$Ne.forEach(t),OKo=i(ee),D0=n(ee,"LI",{});var kNe=s(D0);b1e=n(kNe,"STRONG",{});var IAt=s(b1e);VKo=r(IAt,"roberta"),IAt.forEach(t),XKo=r(kNe," \u2014 "),RW=n(kNe,"A",{href:!0});var NAt=s(RW);zKo=r(NAt,"RobertaForMultipleChoice"),NAt.forEach(t),WKo=r(kNe," (RoBERTa model)"),kNe.forEach(t),QKo=i(ee),G0=n(ee,"LI",{});var SNe=s(G0);v1e=n(SNe,"STRONG",{});var qAt=s(v1e);HKo=r(qAt,"roformer"),qAt.forEach(t),UKo=r(SNe," \u2014 "),PW=n(SNe,"A",{href:!0});var jAt=s(PW);JKo=r(jAt,"RoFormerForMultipleChoice"),jAt.forEach(t),YKo=r(SNe," (RoFormer model)"),SNe.forEach(t),KKo=i(ee),O0=n(ee,"LI",{});var RNe=s(O0);F1e=n(RNe,"STRONG",{});var DAt=s(F1e);ZKo=r(DAt,"squeezebert"),DAt.forEach(t),eZo=r(RNe," \u2014 "),BW=n(RNe,"A",{href:!0});var GAt=s(BW);oZo=r(GAt,"SqueezeBertForMultipleChoice"),GAt.forEach(t),rZo=r(RNe," (SqueezeBERT model)"),RNe.forEach(t),tZo=i(ee),V0=n(ee,"LI",{});var PNe=s(V0);T1e=n(PNe,"STRONG",{});var OAt=s(T1e);aZo=r(OAt,"xlm"),OAt.forEach(t),nZo=r(PNe," \u2014 "),IW=n(PNe,"A",{href:!0});var VAt=s(IW);sZo=r(VAt,"XLMForMultipleChoice"),VAt.forEach(t),lZo=r(PNe," (XLM model)"),PNe.forEach(t),iZo=i(ee),X0=n(ee,"LI",{});var BNe=s(X0);M1e=n(BNe,"STRONG",{});var XAt=s(M1e);dZo=r(XAt,"xlm-roberta"),XAt.forEach(t),cZo=r(BNe," \u2014 "),NW=n(BNe,"A",{href:!0});var zAt=s(NW);fZo=r(zAt,"XLMRobertaForMultipleChoice"),zAt.forEach(t),mZo=r(BNe," (XLM-RoBERTa model)"),BNe.forEach(t),gZo=i(ee),z0=n(ee,"LI",{});var INe=s(z0);E1e=n(INe,"STRONG",{});var WAt=s(E1e);hZo=r(WAt,"xlm-roberta-xl"),WAt.forEach(t),pZo=r(INe," \u2014 "),qW=n(INe,"A",{href:!0});var QAt=s(qW);_Zo=r(QAt,"XLMRobertaXLForMultipleChoice"),QAt.forEach(t),uZo=r(INe," (XLM-RoBERTa-XL model)"),INe.forEach(t),bZo=i(ee),W0=n(ee,"LI",{});var NNe=s(W0);C1e=n(NNe,"STRONG",{});var HAt=s(C1e);vZo=r(HAt,"xlnet"),HAt.forEach(t),FZo=r(NNe," \u2014 "),jW=n(NNe,"A",{href:!0});var UAt=s(jW);TZo=r(UAt,"XLNetForMultipleChoice"),UAt.forEach(t),MZo=r(NNe," (XLNet model)"),NNe.forEach(t),EZo=i(ee),Q0=n(ee,"LI",{});var qNe=s(Q0);w1e=n(qNe,"STRONG",{});var JAt=s(w1e);CZo=r(JAt,"yoso"),JAt.forEach(t),wZo=r(qNe," \u2014 "),DW=n(qNe,"A",{href:!0});var YAt=s(DW);AZo=r(YAt,"YosoForMultipleChoice"),YAt.forEach(t),LZo=r(qNe," (YOSO model)"),qNe.forEach(t),ee.forEach(t),yZo=i(_a),H0=n(_a,"P",{});var jNe=s(H0);xZo=r(jNe,"The model is set in evaluation mode by default using "),A1e=n(jNe,"CODE",{});var KAt=s(A1e);$Zo=r(KAt,"model.eval()"),KAt.forEach(t),kZo=r(jNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),L1e=n(jNe,"CODE",{});var ZAt=s(L1e);SZo=r(ZAt,"model.train()"),ZAt.forEach(t),jNe.forEach(t),RZo=i(_a),T(U0.$$.fragment,_a),_a.forEach(t),_l.forEach(t),_Qe=i(f),ud=n(f,"H2",{class:!0});var CUe=s(ud);J0=n(CUe,"A",{id:!0,class:!0,href:!0});var e7t=s(J0);y1e=n(e7t,"SPAN",{});var o7t=s(y1e);T(o9.$$.fragment,o7t),o7t.forEach(t),e7t.forEach(t),PZo=i(CUe),x1e=n(CUe,"SPAN",{});var r7t=s(x1e);BZo=r(r7t,"AutoModelForNextSentencePrediction"),r7t.forEach(t),CUe.forEach(t),uQe=i(f),jo=n(f,"DIV",{class:!0});var ul=s(jo);T(r9.$$.fragment,ul),IZo=i(ul),bd=n(ul,"P",{});var Mae=s(bd);NZo=r(Mae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),GW=n(Mae,"A",{href:!0});var t7t=s(GW);qZo=r(t7t,"from_pretrained()"),t7t.forEach(t),jZo=r(Mae," class method or the "),OW=n(Mae,"A",{href:!0});var a7t=s(OW);DZo=r(a7t,"from_config()"),a7t.forEach(t),GZo=r(Mae,` class
method.`),Mae.forEach(t),OZo=i(ul),t9=n(ul,"P",{});var wUe=s(t9);VZo=r(wUe,"This class cannot be instantiated directly using "),$1e=n(wUe,"CODE",{});var n7t=s($1e);XZo=r(n7t,"__init__()"),n7t.forEach(t),zZo=r(wUe," (throws an error)."),wUe.forEach(t),WZo=i(ul),ut=n(ul,"DIV",{class:!0});var d7=s(ut);T(a9.$$.fragment,d7),QZo=i(d7),k1e=n(d7,"P",{});var s7t=s(k1e);HZo=r(s7t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),s7t.forEach(t),UZo=i(d7),vd=n(d7,"P",{});var Eae=s(vd);JZo=r(Eae,`Note:
Loading a model from its configuration file does `),S1e=n(Eae,"STRONG",{});var l7t=s(S1e);YZo=r(l7t,"not"),l7t.forEach(t),KZo=r(Eae,` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=n(Eae,"A",{href:!0});var i7t=s(VW);ZZo=r(i7t,"from_pretrained()"),i7t.forEach(t),eer=r(Eae," to load the model weights."),Eae.forEach(t),oer=i(d7),T(Y0.$$.fragment,d7),d7.forEach(t),rer=i(ul),ao=n(ul,"DIV",{class:!0});var ua=s(ao);T(n9.$$.fragment,ua),ter=i(ua),R1e=n(ua,"P",{});var d7t=s(R1e);aer=r(d7t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),d7t.forEach(t),ner=i(ua),Qa=n(ua,"P",{});var c7=s(Qa);ser=r(c7,"The model class to instantiate is selected based on the "),P1e=n(c7,"CODE",{});var c7t=s(P1e);ler=r(c7t,"model_type"),c7t.forEach(t),ier=r(c7,` property of the config object (either
passed as an argument or loaded from `),B1e=n(c7,"CODE",{});var f7t=s(B1e);der=r(f7t,"pretrained_model_name_or_path"),f7t.forEach(t),cer=r(c7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I1e=n(c7,"CODE",{});var m7t=s(I1e);fer=r(m7t,"pretrained_model_name_or_path"),m7t.forEach(t),mer=r(c7,":"),c7.forEach(t),ger=i(ua),Do=n(ua,"UL",{});var ba=s(Do);K0=n(ba,"LI",{});var DNe=s(K0);N1e=n(DNe,"STRONG",{});var g7t=s(N1e);her=r(g7t,"bert"),g7t.forEach(t),per=r(DNe," \u2014 "),XW=n(DNe,"A",{href:!0});var h7t=s(XW);_er=r(h7t,"BertForNextSentencePrediction"),h7t.forEach(t),uer=r(DNe," (BERT model)"),DNe.forEach(t),ber=i(ba),Z0=n(ba,"LI",{});var GNe=s(Z0);q1e=n(GNe,"STRONG",{});var p7t=s(q1e);ver=r(p7t,"fnet"),p7t.forEach(t),Fer=r(GNe," \u2014 "),zW=n(GNe,"A",{href:!0});var _7t=s(zW);Ter=r(_7t,"FNetForNextSentencePrediction"),_7t.forEach(t),Mer=r(GNe," (FNet model)"),GNe.forEach(t),Eer=i(ba),eF=n(ba,"LI",{});var ONe=s(eF);j1e=n(ONe,"STRONG",{});var u7t=s(j1e);Cer=r(u7t,"megatron-bert"),u7t.forEach(t),wer=r(ONe," \u2014 "),WW=n(ONe,"A",{href:!0});var b7t=s(WW);Aer=r(b7t,"MegatronBertForNextSentencePrediction"),b7t.forEach(t),Ler=r(ONe," (Megatron-BERT model)"),ONe.forEach(t),yer=i(ba),oF=n(ba,"LI",{});var VNe=s(oF);D1e=n(VNe,"STRONG",{});var v7t=s(D1e);xer=r(v7t,"mobilebert"),v7t.forEach(t),$er=r(VNe," \u2014 "),QW=n(VNe,"A",{href:!0});var F7t=s(QW);ker=r(F7t,"MobileBertForNextSentencePrediction"),F7t.forEach(t),Ser=r(VNe," (MobileBERT model)"),VNe.forEach(t),Rer=i(ba),rF=n(ba,"LI",{});var XNe=s(rF);G1e=n(XNe,"STRONG",{});var T7t=s(G1e);Per=r(T7t,"nezha"),T7t.forEach(t),Ber=r(XNe," \u2014 "),HW=n(XNe,"A",{href:!0});var M7t=s(HW);Ier=r(M7t,"NezhaForNextSentencePrediction"),M7t.forEach(t),Ner=r(XNe," (Nezha model)"),XNe.forEach(t),qer=i(ba),tF=n(ba,"LI",{});var zNe=s(tF);O1e=n(zNe,"STRONG",{});var E7t=s(O1e);jer=r(E7t,"qdqbert"),E7t.forEach(t),Der=r(zNe," \u2014 "),UW=n(zNe,"A",{href:!0});var C7t=s(UW);Ger=r(C7t,"QDQBertForNextSentencePrediction"),C7t.forEach(t),Oer=r(zNe," (QDQBert model)"),zNe.forEach(t),ba.forEach(t),Ver=i(ua),aF=n(ua,"P",{});var WNe=s(aF);Xer=r(WNe,"The model is set in evaluation mode by default using "),V1e=n(WNe,"CODE",{});var w7t=s(V1e);zer=r(w7t,"model.eval()"),w7t.forEach(t),Wer=r(WNe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),X1e=n(WNe,"CODE",{});var A7t=s(X1e);Qer=r(A7t,"model.train()"),A7t.forEach(t),WNe.forEach(t),Her=i(ua),T(nF.$$.fragment,ua),ua.forEach(t),ul.forEach(t),bQe=i(f),Fd=n(f,"H2",{class:!0});var AUe=s(Fd);sF=n(AUe,"A",{id:!0,class:!0,href:!0});var L7t=s(sF);z1e=n(L7t,"SPAN",{});var y7t=s(z1e);T(s9.$$.fragment,y7t),y7t.forEach(t),L7t.forEach(t),Uer=i(AUe),W1e=n(AUe,"SPAN",{});var x7t=s(W1e);Jer=r(x7t,"AutoModelForTokenClassification"),x7t.forEach(t),AUe.forEach(t),vQe=i(f),Go=n(f,"DIV",{class:!0});var bl=s(Go);T(l9.$$.fragment,bl),Yer=i(bl),Td=n(bl,"P",{});var Cae=s(Td);Ker=r(Cae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),JW=n(Cae,"A",{href:!0});var $7t=s(JW);Zer=r($7t,"from_pretrained()"),$7t.forEach(t),eor=r(Cae," class method or the "),YW=n(Cae,"A",{href:!0});var k7t=s(YW);oor=r(k7t,"from_config()"),k7t.forEach(t),ror=r(Cae,` class
method.`),Cae.forEach(t),tor=i(bl),i9=n(bl,"P",{});var LUe=s(i9);aor=r(LUe,"This class cannot be instantiated directly using "),Q1e=n(LUe,"CODE",{});var S7t=s(Q1e);nor=r(S7t,"__init__()"),S7t.forEach(t),sor=r(LUe," (throws an error)."),LUe.forEach(t),lor=i(bl),bt=n(bl,"DIV",{class:!0});var f7=s(bt);T(d9.$$.fragment,f7),ior=i(f7),H1e=n(f7,"P",{});var R7t=s(H1e);dor=r(R7t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),R7t.forEach(t),cor=i(f7),Md=n(f7,"P",{});var wae=s(Md);mor=r(wae,`Note:
Loading a model from its configuration file does `),U1e=n(wae,"STRONG",{});var P7t=s(U1e);gor=r(P7t,"not"),P7t.forEach(t),hor=r(wae,` load the model weights. It only affects the
model\u2019s configuration. Use `),KW=n(wae,"A",{href:!0});var B7t=s(KW);por=r(B7t,"from_pretrained()"),B7t.forEach(t),_or=r(wae," to load the model weights."),wae.forEach(t),uor=i(f7),T(lF.$$.fragment,f7),f7.forEach(t),bor=i(bl),no=n(bl,"DIV",{class:!0});var va=s(no);T(c9.$$.fragment,va),vor=i(va),J1e=n(va,"P",{});var I7t=s(J1e);For=r(I7t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),I7t.forEach(t),Tor=i(va),Ha=n(va,"P",{});var m7=s(Ha);Mor=r(m7,"The model class to instantiate is selected based on the "),Y1e=n(m7,"CODE",{});var N7t=s(Y1e);Eor=r(N7t,"model_type"),N7t.forEach(t),Cor=r(m7,` property of the config object (either
passed as an argument or loaded from `),K1e=n(m7,"CODE",{});var q7t=s(K1e);wor=r(q7t,"pretrained_model_name_or_path"),q7t.forEach(t),Aor=r(m7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z1e=n(m7,"CODE",{});var j7t=s(Z1e);Lor=r(j7t,"pretrained_model_name_or_path"),j7t.forEach(t),yor=r(m7,":"),m7.forEach(t),xor=i(va),U=n(va,"UL",{});var K=s(U);iF=n(K,"LI",{});var QNe=s(iF);ebe=n(QNe,"STRONG",{});var D7t=s(ebe);$or=r(D7t,"albert"),D7t.forEach(t),kor=r(QNe," \u2014 "),ZW=n(QNe,"A",{href:!0});var G7t=s(ZW);Sor=r(G7t,"AlbertForTokenClassification"),G7t.forEach(t),Ror=r(QNe," (ALBERT model)"),QNe.forEach(t),Por=i(K),dF=n(K,"LI",{});var HNe=s(dF);obe=n(HNe,"STRONG",{});var O7t=s(obe);Bor=r(O7t,"bert"),O7t.forEach(t),Ior=r(HNe," \u2014 "),eQ=n(HNe,"A",{href:!0});var V7t=s(eQ);Nor=r(V7t,"BertForTokenClassification"),V7t.forEach(t),qor=r(HNe," (BERT model)"),HNe.forEach(t),jor=i(K),cF=n(K,"LI",{});var UNe=s(cF);rbe=n(UNe,"STRONG",{});var X7t=s(rbe);Dor=r(X7t,"big_bird"),X7t.forEach(t),Gor=r(UNe," \u2014 "),oQ=n(UNe,"A",{href:!0});var z7t=s(oQ);Oor=r(z7t,"BigBirdForTokenClassification"),z7t.forEach(t),Vor=r(UNe," (BigBird model)"),UNe.forEach(t),Xor=i(K),fF=n(K,"LI",{});var JNe=s(fF);tbe=n(JNe,"STRONG",{});var W7t=s(tbe);zor=r(W7t,"bloom"),W7t.forEach(t),Wor=r(JNe," \u2014 "),rQ=n(JNe,"A",{href:!0});var Q7t=s(rQ);Qor=r(Q7t,"BloomForTokenClassification"),Q7t.forEach(t),Hor=r(JNe," (BLOOM model)"),JNe.forEach(t),Uor=i(K),mF=n(K,"LI",{});var YNe=s(mF);abe=n(YNe,"STRONG",{});var H7t=s(abe);Jor=r(H7t,"camembert"),H7t.forEach(t),Yor=r(YNe," \u2014 "),tQ=n(YNe,"A",{href:!0});var U7t=s(tQ);Kor=r(U7t,"CamembertForTokenClassification"),U7t.forEach(t),Zor=r(YNe," (CamemBERT model)"),YNe.forEach(t),err=i(K),gF=n(K,"LI",{});var KNe=s(gF);nbe=n(KNe,"STRONG",{});var J7t=s(nbe);orr=r(J7t,"canine"),J7t.forEach(t),rrr=r(KNe," \u2014 "),aQ=n(KNe,"A",{href:!0});var Y7t=s(aQ);trr=r(Y7t,"CanineForTokenClassification"),Y7t.forEach(t),arr=r(KNe," (CANINE model)"),KNe.forEach(t),nrr=i(K),hF=n(K,"LI",{});var ZNe=s(hF);sbe=n(ZNe,"STRONG",{});var K7t=s(sbe);srr=r(K7t,"convbert"),K7t.forEach(t),lrr=r(ZNe," \u2014 "),nQ=n(ZNe,"A",{href:!0});var Z7t=s(nQ);irr=r(Z7t,"ConvBertForTokenClassification"),Z7t.forEach(t),drr=r(ZNe," (ConvBERT model)"),ZNe.forEach(t),crr=i(K),pF=n(K,"LI",{});var eqe=s(pF);lbe=n(eqe,"STRONG",{});var eLt=s(lbe);frr=r(eLt,"data2vec-text"),eLt.forEach(t),mrr=r(eqe," \u2014 "),sQ=n(eqe,"A",{href:!0});var oLt=s(sQ);grr=r(oLt,"Data2VecTextForTokenClassification"),oLt.forEach(t),hrr=r(eqe," (Data2VecText model)"),eqe.forEach(t),prr=i(K),_F=n(K,"LI",{});var oqe=s(_F);ibe=n(oqe,"STRONG",{});var rLt=s(ibe);_rr=r(rLt,"deberta"),rLt.forEach(t),urr=r(oqe," \u2014 "),lQ=n(oqe,"A",{href:!0});var tLt=s(lQ);brr=r(tLt,"DebertaForTokenClassification"),tLt.forEach(t),vrr=r(oqe," (DeBERTa model)"),oqe.forEach(t),Frr=i(K),uF=n(K,"LI",{});var rqe=s(uF);dbe=n(rqe,"STRONG",{});var aLt=s(dbe);Trr=r(aLt,"deberta-v2"),aLt.forEach(t),Mrr=r(rqe," \u2014 "),iQ=n(rqe,"A",{href:!0});var nLt=s(iQ);Err=r(nLt,"DebertaV2ForTokenClassification"),nLt.forEach(t),Crr=r(rqe," (DeBERTa-v2 model)"),rqe.forEach(t),wrr=i(K),bF=n(K,"LI",{});var tqe=s(bF);cbe=n(tqe,"STRONG",{});var sLt=s(cbe);Arr=r(sLt,"distilbert"),sLt.forEach(t),Lrr=r(tqe," \u2014 "),dQ=n(tqe,"A",{href:!0});var lLt=s(dQ);yrr=r(lLt,"DistilBertForTokenClassification"),lLt.forEach(t),xrr=r(tqe," (DistilBERT model)"),tqe.forEach(t),$rr=i(K),vF=n(K,"LI",{});var aqe=s(vF);fbe=n(aqe,"STRONG",{});var iLt=s(fbe);krr=r(iLt,"electra"),iLt.forEach(t),Srr=r(aqe," \u2014 "),cQ=n(aqe,"A",{href:!0});var dLt=s(cQ);Rrr=r(dLt,"ElectraForTokenClassification"),dLt.forEach(t),Prr=r(aqe," (ELECTRA model)"),aqe.forEach(t),Brr=i(K),FF=n(K,"LI",{});var nqe=s(FF);mbe=n(nqe,"STRONG",{});var cLt=s(mbe);Irr=r(cLt,"flaubert"),cLt.forEach(t),Nrr=r(nqe," \u2014 "),fQ=n(nqe,"A",{href:!0});var fLt=s(fQ);qrr=r(fLt,"FlaubertForTokenClassification"),fLt.forEach(t),jrr=r(nqe," (FlauBERT model)"),nqe.forEach(t),Drr=i(K),TF=n(K,"LI",{});var sqe=s(TF);gbe=n(sqe,"STRONG",{});var mLt=s(gbe);Grr=r(mLt,"fnet"),mLt.forEach(t),Orr=r(sqe," \u2014 "),mQ=n(sqe,"A",{href:!0});var gLt=s(mQ);Vrr=r(gLt,"FNetForTokenClassification"),gLt.forEach(t),Xrr=r(sqe," (FNet model)"),sqe.forEach(t),zrr=i(K),MF=n(K,"LI",{});var lqe=s(MF);hbe=n(lqe,"STRONG",{});var hLt=s(hbe);Wrr=r(hLt,"funnel"),hLt.forEach(t),Qrr=r(lqe," \u2014 "),gQ=n(lqe,"A",{href:!0});var pLt=s(gQ);Hrr=r(pLt,"FunnelForTokenClassification"),pLt.forEach(t),Urr=r(lqe," (Funnel Transformer model)"),lqe.forEach(t),Jrr=i(K),EF=n(K,"LI",{});var iqe=s(EF);pbe=n(iqe,"STRONG",{});var _Lt=s(pbe);Yrr=r(_Lt,"gpt2"),_Lt.forEach(t),Krr=r(iqe," \u2014 "),hQ=n(iqe,"A",{href:!0});var uLt=s(hQ);Zrr=r(uLt,"GPT2ForTokenClassification"),uLt.forEach(t),etr=r(iqe," (OpenAI GPT-2 model)"),iqe.forEach(t),otr=i(K),CF=n(K,"LI",{});var dqe=s(CF);_be=n(dqe,"STRONG",{});var bLt=s(_be);rtr=r(bLt,"ibert"),bLt.forEach(t),ttr=r(dqe," \u2014 "),pQ=n(dqe,"A",{href:!0});var vLt=s(pQ);atr=r(vLt,"IBertForTokenClassification"),vLt.forEach(t),ntr=r(dqe," (I-BERT model)"),dqe.forEach(t),str=i(K),wF=n(K,"LI",{});var cqe=s(wF);ube=n(cqe,"STRONG",{});var FLt=s(ube);ltr=r(FLt,"layoutlm"),FLt.forEach(t),itr=r(cqe," \u2014 "),_Q=n(cqe,"A",{href:!0});var TLt=s(_Q);dtr=r(TLt,"LayoutLMForTokenClassification"),TLt.forEach(t),ctr=r(cqe," (LayoutLM model)"),cqe.forEach(t),ftr=i(K),AF=n(K,"LI",{});var fqe=s(AF);bbe=n(fqe,"STRONG",{});var MLt=s(bbe);mtr=r(MLt,"layoutlmv2"),MLt.forEach(t),gtr=r(fqe," \u2014 "),uQ=n(fqe,"A",{href:!0});var ELt=s(uQ);htr=r(ELt,"LayoutLMv2ForTokenClassification"),ELt.forEach(t),ptr=r(fqe," (LayoutLMv2 model)"),fqe.forEach(t),_tr=i(K),LF=n(K,"LI",{});var mqe=s(LF);vbe=n(mqe,"STRONG",{});var CLt=s(vbe);utr=r(CLt,"layoutlmv3"),CLt.forEach(t),btr=r(mqe," \u2014 "),bQ=n(mqe,"A",{href:!0});var wLt=s(bQ);vtr=r(wLt,"LayoutLMv3ForTokenClassification"),wLt.forEach(t),Ftr=r(mqe," (LayoutLMv3 model)"),mqe.forEach(t),Ttr=i(K),yF=n(K,"LI",{});var gqe=s(yF);Fbe=n(gqe,"STRONG",{});var ALt=s(Fbe);Mtr=r(ALt,"longformer"),ALt.forEach(t),Etr=r(gqe," \u2014 "),vQ=n(gqe,"A",{href:!0});var LLt=s(vQ);Ctr=r(LLt,"LongformerForTokenClassification"),LLt.forEach(t),wtr=r(gqe," (Longformer model)"),gqe.forEach(t),Atr=i(K),xF=n(K,"LI",{});var hqe=s(xF);Tbe=n(hqe,"STRONG",{});var yLt=s(Tbe);Ltr=r(yLt,"luke"),yLt.forEach(t),ytr=r(hqe," \u2014 "),FQ=n(hqe,"A",{href:!0});var xLt=s(FQ);xtr=r(xLt,"LukeForTokenClassification"),xLt.forEach(t),$tr=r(hqe," (LUKE model)"),hqe.forEach(t),ktr=i(K),$F=n(K,"LI",{});var pqe=s($F);Mbe=n(pqe,"STRONG",{});var $Lt=s(Mbe);Str=r($Lt,"megatron-bert"),$Lt.forEach(t),Rtr=r(pqe," \u2014 "),TQ=n(pqe,"A",{href:!0});var kLt=s(TQ);Ptr=r(kLt,"MegatronBertForTokenClassification"),kLt.forEach(t),Btr=r(pqe," (Megatron-BERT model)"),pqe.forEach(t),Itr=i(K),kF=n(K,"LI",{});var _qe=s(kF);Ebe=n(_qe,"STRONG",{});var SLt=s(Ebe);Ntr=r(SLt,"mobilebert"),SLt.forEach(t),qtr=r(_qe," \u2014 "),MQ=n(_qe,"A",{href:!0});var RLt=s(MQ);jtr=r(RLt,"MobileBertForTokenClassification"),RLt.forEach(t),Dtr=r(_qe," (MobileBERT model)"),_qe.forEach(t),Gtr=i(K),SF=n(K,"LI",{});var uqe=s(SF);Cbe=n(uqe,"STRONG",{});var PLt=s(Cbe);Otr=r(PLt,"mpnet"),PLt.forEach(t),Vtr=r(uqe," \u2014 "),EQ=n(uqe,"A",{href:!0});var BLt=s(EQ);Xtr=r(BLt,"MPNetForTokenClassification"),BLt.forEach(t),ztr=r(uqe," (MPNet model)"),uqe.forEach(t),Wtr=i(K),RF=n(K,"LI",{});var bqe=s(RF);wbe=n(bqe,"STRONG",{});var ILt=s(wbe);Qtr=r(ILt,"nezha"),ILt.forEach(t),Htr=r(bqe," \u2014 "),CQ=n(bqe,"A",{href:!0});var NLt=s(CQ);Utr=r(NLt,"NezhaForTokenClassification"),NLt.forEach(t),Jtr=r(bqe," (Nezha model)"),bqe.forEach(t),Ytr=i(K),PF=n(K,"LI",{});var vqe=s(PF);Abe=n(vqe,"STRONG",{});var qLt=s(Abe);Ktr=r(qLt,"nystromformer"),qLt.forEach(t),Ztr=r(vqe," \u2014 "),wQ=n(vqe,"A",{href:!0});var jLt=s(wQ);ear=r(jLt,"NystromformerForTokenClassification"),jLt.forEach(t),oar=r(vqe," (Nystr\xF6mformer model)"),vqe.forEach(t),rar=i(K),BF=n(K,"LI",{});var Fqe=s(BF);Lbe=n(Fqe,"STRONG",{});var DLt=s(Lbe);tar=r(DLt,"qdqbert"),DLt.forEach(t),aar=r(Fqe," \u2014 "),AQ=n(Fqe,"A",{href:!0});var GLt=s(AQ);nar=r(GLt,"QDQBertForTokenClassification"),GLt.forEach(t),sar=r(Fqe," (QDQBert model)"),Fqe.forEach(t),lar=i(K),IF=n(K,"LI",{});var Tqe=s(IF);ybe=n(Tqe,"STRONG",{});var OLt=s(ybe);iar=r(OLt,"rembert"),OLt.forEach(t),dar=r(Tqe," \u2014 "),LQ=n(Tqe,"A",{href:!0});var VLt=s(LQ);car=r(VLt,"RemBertForTokenClassification"),VLt.forEach(t),far=r(Tqe," (RemBERT model)"),Tqe.forEach(t),mar=i(K),NF=n(K,"LI",{});var Mqe=s(NF);xbe=n(Mqe,"STRONG",{});var XLt=s(xbe);gar=r(XLt,"roberta"),XLt.forEach(t),har=r(Mqe," \u2014 "),yQ=n(Mqe,"A",{href:!0});var zLt=s(yQ);par=r(zLt,"RobertaForTokenClassification"),zLt.forEach(t),_ar=r(Mqe," (RoBERTa model)"),Mqe.forEach(t),uar=i(K),qF=n(K,"LI",{});var Eqe=s(qF);$be=n(Eqe,"STRONG",{});var WLt=s($be);bar=r(WLt,"roformer"),WLt.forEach(t),Far=r(Eqe," \u2014 "),xQ=n(Eqe,"A",{href:!0});var QLt=s(xQ);Tar=r(QLt,"RoFormerForTokenClassification"),QLt.forEach(t),Mar=r(Eqe," (RoFormer model)"),Eqe.forEach(t),Ear=i(K),jF=n(K,"LI",{});var Cqe=s(jF);kbe=n(Cqe,"STRONG",{});var HLt=s(kbe);Car=r(HLt,"squeezebert"),HLt.forEach(t),war=r(Cqe," \u2014 "),$Q=n(Cqe,"A",{href:!0});var ULt=s($Q);Aar=r(ULt,"SqueezeBertForTokenClassification"),ULt.forEach(t),Lar=r(Cqe," (SqueezeBERT model)"),Cqe.forEach(t),yar=i(K),DF=n(K,"LI",{});var wqe=s(DF);Sbe=n(wqe,"STRONG",{});var JLt=s(Sbe);xar=r(JLt,"xlm"),JLt.forEach(t),$ar=r(wqe," \u2014 "),kQ=n(wqe,"A",{href:!0});var YLt=s(kQ);kar=r(YLt,"XLMForTokenClassification"),YLt.forEach(t),Sar=r(wqe," (XLM model)"),wqe.forEach(t),Rar=i(K),GF=n(K,"LI",{});var Aqe=s(GF);Rbe=n(Aqe,"STRONG",{});var KLt=s(Rbe);Par=r(KLt,"xlm-roberta"),KLt.forEach(t),Bar=r(Aqe," \u2014 "),SQ=n(Aqe,"A",{href:!0});var ZLt=s(SQ);Iar=r(ZLt,"XLMRobertaForTokenClassification"),ZLt.forEach(t),Nar=r(Aqe," (XLM-RoBERTa model)"),Aqe.forEach(t),qar=i(K),OF=n(K,"LI",{});var Lqe=s(OF);Pbe=n(Lqe,"STRONG",{});var eyt=s(Pbe);jar=r(eyt,"xlm-roberta-xl"),eyt.forEach(t),Dar=r(Lqe," \u2014 "),RQ=n(Lqe,"A",{href:!0});var oyt=s(RQ);Gar=r(oyt,"XLMRobertaXLForTokenClassification"),oyt.forEach(t),Oar=r(Lqe," (XLM-RoBERTa-XL model)"),Lqe.forEach(t),Var=i(K),VF=n(K,"LI",{});var yqe=s(VF);Bbe=n(yqe,"STRONG",{});var ryt=s(Bbe);Xar=r(ryt,"xlnet"),ryt.forEach(t),zar=r(yqe," \u2014 "),PQ=n(yqe,"A",{href:!0});var tyt=s(PQ);War=r(tyt,"XLNetForTokenClassification"),tyt.forEach(t),Qar=r(yqe," (XLNet model)"),yqe.forEach(t),Har=i(K),XF=n(K,"LI",{});var xqe=s(XF);Ibe=n(xqe,"STRONG",{});var ayt=s(Ibe);Uar=r(ayt,"yoso"),ayt.forEach(t),Jar=r(xqe," \u2014 "),BQ=n(xqe,"A",{href:!0});var nyt=s(BQ);Yar=r(nyt,"YosoForTokenClassification"),nyt.forEach(t),Kar=r(xqe," (YOSO model)"),xqe.forEach(t),K.forEach(t),Zar=i(va),zF=n(va,"P",{});var $qe=s(zF);enr=r($qe,"The model is set in evaluation mode by default using "),Nbe=n($qe,"CODE",{});var syt=s(Nbe);onr=r(syt,"model.eval()"),syt.forEach(t),rnr=r($qe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qbe=n($qe,"CODE",{});var lyt=s(qbe);tnr=r(lyt,"model.train()"),lyt.forEach(t),$qe.forEach(t),anr=i(va),T(WF.$$.fragment,va),va.forEach(t),bl.forEach(t),FQe=i(f),Ed=n(f,"H2",{class:!0});var yUe=s(Ed);QF=n(yUe,"A",{id:!0,class:!0,href:!0});var iyt=s(QF);jbe=n(iyt,"SPAN",{});var dyt=s(jbe);T(f9.$$.fragment,dyt),dyt.forEach(t),iyt.forEach(t),nnr=i(yUe),Dbe=n(yUe,"SPAN",{});var cyt=s(Dbe);snr=r(cyt,"AutoModelForQuestionAnswering"),cyt.forEach(t),yUe.forEach(t),TQe=i(f),Oo=n(f,"DIV",{class:!0});var vl=s(Oo);T(m9.$$.fragment,vl),lnr=i(vl),Cd=n(vl,"P",{});var Aae=s(Cd);inr=r(Aae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),IQ=n(Aae,"A",{href:!0});var fyt=s(IQ);dnr=r(fyt,"from_pretrained()"),fyt.forEach(t),cnr=r(Aae," class method or the "),NQ=n(Aae,"A",{href:!0});var myt=s(NQ);fnr=r(myt,"from_config()"),myt.forEach(t),mnr=r(Aae,` class
method.`),Aae.forEach(t),gnr=i(vl),g9=n(vl,"P",{});var xUe=s(g9);hnr=r(xUe,"This class cannot be instantiated directly using "),Gbe=n(xUe,"CODE",{});var gyt=s(Gbe);pnr=r(gyt,"__init__()"),gyt.forEach(t),_nr=r(xUe," (throws an error)."),xUe.forEach(t),unr=i(vl),vt=n(vl,"DIV",{class:!0});var g7=s(vt);T(h9.$$.fragment,g7),bnr=i(g7),Obe=n(g7,"P",{});var hyt=s(Obe);vnr=r(hyt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),hyt.forEach(t),Fnr=i(g7),wd=n(g7,"P",{});var Lae=s(wd);Tnr=r(Lae,`Note:
Loading a model from its configuration file does `),Vbe=n(Lae,"STRONG",{});var pyt=s(Vbe);Mnr=r(pyt,"not"),pyt.forEach(t),Enr=r(Lae,` load the model weights. It only affects the
model\u2019s configuration. Use `),qQ=n(Lae,"A",{href:!0});var _yt=s(qQ);Cnr=r(_yt,"from_pretrained()"),_yt.forEach(t),wnr=r(Lae," to load the model weights."),Lae.forEach(t),Anr=i(g7),T(HF.$$.fragment,g7),g7.forEach(t),Lnr=i(vl),so=n(vl,"DIV",{class:!0});var Fa=s(so);T(p9.$$.fragment,Fa),ynr=i(Fa),Xbe=n(Fa,"P",{});var uyt=s(Xbe);xnr=r(uyt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),uyt.forEach(t),$nr=i(Fa),Ua=n(Fa,"P",{});var h7=s(Ua);knr=r(h7,"The model class to instantiate is selected based on the "),zbe=n(h7,"CODE",{});var byt=s(zbe);Snr=r(byt,"model_type"),byt.forEach(t),Rnr=r(h7,` property of the config object (either
passed as an argument or loaded from `),Wbe=n(h7,"CODE",{});var vyt=s(Wbe);Pnr=r(vyt,"pretrained_model_name_or_path"),vyt.forEach(t),Bnr=r(h7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qbe=n(h7,"CODE",{});var Fyt=s(Qbe);Inr=r(Fyt,"pretrained_model_name_or_path"),Fyt.forEach(t),Nnr=r(h7,":"),h7.forEach(t),qnr=i(Fa),V=n(Fa,"UL",{});var X=s(V);UF=n(X,"LI",{});var kqe=s(UF);Hbe=n(kqe,"STRONG",{});var Tyt=s(Hbe);jnr=r(Tyt,"albert"),Tyt.forEach(t),Dnr=r(kqe," \u2014 "),jQ=n(kqe,"A",{href:!0});var Myt=s(jQ);Gnr=r(Myt,"AlbertForQuestionAnswering"),Myt.forEach(t),Onr=r(kqe," (ALBERT model)"),kqe.forEach(t),Vnr=i(X),JF=n(X,"LI",{});var Sqe=s(JF);Ube=n(Sqe,"STRONG",{});var Eyt=s(Ube);Xnr=r(Eyt,"bart"),Eyt.forEach(t),znr=r(Sqe," \u2014 "),DQ=n(Sqe,"A",{href:!0});var Cyt=s(DQ);Wnr=r(Cyt,"BartForQuestionAnswering"),Cyt.forEach(t),Qnr=r(Sqe," (BART model)"),Sqe.forEach(t),Hnr=i(X),YF=n(X,"LI",{});var Rqe=s(YF);Jbe=n(Rqe,"STRONG",{});var wyt=s(Jbe);Unr=r(wyt,"bert"),wyt.forEach(t),Jnr=r(Rqe," \u2014 "),GQ=n(Rqe,"A",{href:!0});var Ayt=s(GQ);Ynr=r(Ayt,"BertForQuestionAnswering"),Ayt.forEach(t),Knr=r(Rqe," (BERT model)"),Rqe.forEach(t),Znr=i(X),KF=n(X,"LI",{});var Pqe=s(KF);Ybe=n(Pqe,"STRONG",{});var Lyt=s(Ybe);esr=r(Lyt,"big_bird"),Lyt.forEach(t),osr=r(Pqe," \u2014 "),OQ=n(Pqe,"A",{href:!0});var yyt=s(OQ);rsr=r(yyt,"BigBirdForQuestionAnswering"),yyt.forEach(t),tsr=r(Pqe," (BigBird model)"),Pqe.forEach(t),asr=i(X),ZF=n(X,"LI",{});var Bqe=s(ZF);Kbe=n(Bqe,"STRONG",{});var xyt=s(Kbe);nsr=r(xyt,"bigbird_pegasus"),xyt.forEach(t),ssr=r(Bqe," \u2014 "),VQ=n(Bqe,"A",{href:!0});var $yt=s(VQ);lsr=r($yt,"BigBirdPegasusForQuestionAnswering"),$yt.forEach(t),isr=r(Bqe," (BigBird-Pegasus model)"),Bqe.forEach(t),dsr=i(X),eT=n(X,"LI",{});var Iqe=s(eT);Zbe=n(Iqe,"STRONG",{});var kyt=s(Zbe);csr=r(kyt,"camembert"),kyt.forEach(t),fsr=r(Iqe," \u2014 "),XQ=n(Iqe,"A",{href:!0});var Syt=s(XQ);msr=r(Syt,"CamembertForQuestionAnswering"),Syt.forEach(t),gsr=r(Iqe," (CamemBERT model)"),Iqe.forEach(t),hsr=i(X),oT=n(X,"LI",{});var Nqe=s(oT);eve=n(Nqe,"STRONG",{});var Ryt=s(eve);psr=r(Ryt,"canine"),Ryt.forEach(t),_sr=r(Nqe," \u2014 "),zQ=n(Nqe,"A",{href:!0});var Pyt=s(zQ);usr=r(Pyt,"CanineForQuestionAnswering"),Pyt.forEach(t),bsr=r(Nqe," (CANINE model)"),Nqe.forEach(t),vsr=i(X),rT=n(X,"LI",{});var qqe=s(rT);ove=n(qqe,"STRONG",{});var Byt=s(ove);Fsr=r(Byt,"convbert"),Byt.forEach(t),Tsr=r(qqe," \u2014 "),WQ=n(qqe,"A",{href:!0});var Iyt=s(WQ);Msr=r(Iyt,"ConvBertForQuestionAnswering"),Iyt.forEach(t),Esr=r(qqe," (ConvBERT model)"),qqe.forEach(t),Csr=i(X),tT=n(X,"LI",{});var jqe=s(tT);rve=n(jqe,"STRONG",{});var Nyt=s(rve);wsr=r(Nyt,"data2vec-text"),Nyt.forEach(t),Asr=r(jqe," \u2014 "),QQ=n(jqe,"A",{href:!0});var qyt=s(QQ);Lsr=r(qyt,"Data2VecTextForQuestionAnswering"),qyt.forEach(t),ysr=r(jqe," (Data2VecText model)"),jqe.forEach(t),xsr=i(X),aT=n(X,"LI",{});var Dqe=s(aT);tve=n(Dqe,"STRONG",{});var jyt=s(tve);$sr=r(jyt,"deberta"),jyt.forEach(t),ksr=r(Dqe," \u2014 "),HQ=n(Dqe,"A",{href:!0});var Dyt=s(HQ);Ssr=r(Dyt,"DebertaForQuestionAnswering"),Dyt.forEach(t),Rsr=r(Dqe," (DeBERTa model)"),Dqe.forEach(t),Psr=i(X),nT=n(X,"LI",{});var Gqe=s(nT);ave=n(Gqe,"STRONG",{});var Gyt=s(ave);Bsr=r(Gyt,"deberta-v2"),Gyt.forEach(t),Isr=r(Gqe," \u2014 "),UQ=n(Gqe,"A",{href:!0});var Oyt=s(UQ);Nsr=r(Oyt,"DebertaV2ForQuestionAnswering"),Oyt.forEach(t),qsr=r(Gqe," (DeBERTa-v2 model)"),Gqe.forEach(t),jsr=i(X),sT=n(X,"LI",{});var Oqe=s(sT);nve=n(Oqe,"STRONG",{});var Vyt=s(nve);Dsr=r(Vyt,"distilbert"),Vyt.forEach(t),Gsr=r(Oqe," \u2014 "),JQ=n(Oqe,"A",{href:!0});var Xyt=s(JQ);Osr=r(Xyt,"DistilBertForQuestionAnswering"),Xyt.forEach(t),Vsr=r(Oqe," (DistilBERT model)"),Oqe.forEach(t),Xsr=i(X),lT=n(X,"LI",{});var Vqe=s(lT);sve=n(Vqe,"STRONG",{});var zyt=s(sve);zsr=r(zyt,"electra"),zyt.forEach(t),Wsr=r(Vqe," \u2014 "),YQ=n(Vqe,"A",{href:!0});var Wyt=s(YQ);Qsr=r(Wyt,"ElectraForQuestionAnswering"),Wyt.forEach(t),Hsr=r(Vqe," (ELECTRA model)"),Vqe.forEach(t),Usr=i(X),iT=n(X,"LI",{});var Xqe=s(iT);lve=n(Xqe,"STRONG",{});var Qyt=s(lve);Jsr=r(Qyt,"flaubert"),Qyt.forEach(t),Ysr=r(Xqe," \u2014 "),KQ=n(Xqe,"A",{href:!0});var Hyt=s(KQ);Ksr=r(Hyt,"FlaubertForQuestionAnsweringSimple"),Hyt.forEach(t),Zsr=r(Xqe," (FlauBERT model)"),Xqe.forEach(t),elr=i(X),dT=n(X,"LI",{});var zqe=s(dT);ive=n(zqe,"STRONG",{});var Uyt=s(ive);olr=r(Uyt,"fnet"),Uyt.forEach(t),rlr=r(zqe," \u2014 "),ZQ=n(zqe,"A",{href:!0});var Jyt=s(ZQ);tlr=r(Jyt,"FNetForQuestionAnswering"),Jyt.forEach(t),alr=r(zqe," (FNet model)"),zqe.forEach(t),nlr=i(X),cT=n(X,"LI",{});var Wqe=s(cT);dve=n(Wqe,"STRONG",{});var Yyt=s(dve);slr=r(Yyt,"funnel"),Yyt.forEach(t),llr=r(Wqe," \u2014 "),eH=n(Wqe,"A",{href:!0});var Kyt=s(eH);ilr=r(Kyt,"FunnelForQuestionAnswering"),Kyt.forEach(t),dlr=r(Wqe," (Funnel Transformer model)"),Wqe.forEach(t),clr=i(X),fT=n(X,"LI",{});var Qqe=s(fT);cve=n(Qqe,"STRONG",{});var Zyt=s(cve);flr=r(Zyt,"gptj"),Zyt.forEach(t),mlr=r(Qqe," \u2014 "),oH=n(Qqe,"A",{href:!0});var e9t=s(oH);glr=r(e9t,"GPTJForQuestionAnswering"),e9t.forEach(t),hlr=r(Qqe," (GPT-J model)"),Qqe.forEach(t),plr=i(X),mT=n(X,"LI",{});var Hqe=s(mT);fve=n(Hqe,"STRONG",{});var o9t=s(fve);_lr=r(o9t,"ibert"),o9t.forEach(t),ulr=r(Hqe," \u2014 "),rH=n(Hqe,"A",{href:!0});var r9t=s(rH);blr=r(r9t,"IBertForQuestionAnswering"),r9t.forEach(t),vlr=r(Hqe," (I-BERT model)"),Hqe.forEach(t),Flr=i(X),gT=n(X,"LI",{});var Uqe=s(gT);mve=n(Uqe,"STRONG",{});var t9t=s(mve);Tlr=r(t9t,"layoutlmv2"),t9t.forEach(t),Mlr=r(Uqe," \u2014 "),tH=n(Uqe,"A",{href:!0});var a9t=s(tH);Elr=r(a9t,"LayoutLMv2ForQuestionAnswering"),a9t.forEach(t),Clr=r(Uqe," (LayoutLMv2 model)"),Uqe.forEach(t),wlr=i(X),hT=n(X,"LI",{});var Jqe=s(hT);gve=n(Jqe,"STRONG",{});var n9t=s(gve);Alr=r(n9t,"layoutlmv3"),n9t.forEach(t),Llr=r(Jqe," \u2014 "),aH=n(Jqe,"A",{href:!0});var s9t=s(aH);ylr=r(s9t,"LayoutLMv3ForQuestionAnswering"),s9t.forEach(t),xlr=r(Jqe," (LayoutLMv3 model)"),Jqe.forEach(t),$lr=i(X),pT=n(X,"LI",{});var Yqe=s(pT);hve=n(Yqe,"STRONG",{});var l9t=s(hve);klr=r(l9t,"led"),l9t.forEach(t),Slr=r(Yqe," \u2014 "),nH=n(Yqe,"A",{href:!0});var i9t=s(nH);Rlr=r(i9t,"LEDForQuestionAnswering"),i9t.forEach(t),Plr=r(Yqe," (LED model)"),Yqe.forEach(t),Blr=i(X),_T=n(X,"LI",{});var Kqe=s(_T);pve=n(Kqe,"STRONG",{});var d9t=s(pve);Ilr=r(d9t,"longformer"),d9t.forEach(t),Nlr=r(Kqe," \u2014 "),sH=n(Kqe,"A",{href:!0});var c9t=s(sH);qlr=r(c9t,"LongformerForQuestionAnswering"),c9t.forEach(t),jlr=r(Kqe," (Longformer model)"),Kqe.forEach(t),Dlr=i(X),uT=n(X,"LI",{});var Zqe=s(uT);_ve=n(Zqe,"STRONG",{});var f9t=s(_ve);Glr=r(f9t,"luke"),f9t.forEach(t),Olr=r(Zqe," \u2014 "),lH=n(Zqe,"A",{href:!0});var m9t=s(lH);Vlr=r(m9t,"LukeForQuestionAnswering"),m9t.forEach(t),Xlr=r(Zqe," (LUKE model)"),Zqe.forEach(t),zlr=i(X),bT=n(X,"LI",{});var eje=s(bT);uve=n(eje,"STRONG",{});var g9t=s(uve);Wlr=r(g9t,"lxmert"),g9t.forEach(t),Qlr=r(eje," \u2014 "),iH=n(eje,"A",{href:!0});var h9t=s(iH);Hlr=r(h9t,"LxmertForQuestionAnswering"),h9t.forEach(t),Ulr=r(eje," (LXMERT model)"),eje.forEach(t),Jlr=i(X),vT=n(X,"LI",{});var oje=s(vT);bve=n(oje,"STRONG",{});var p9t=s(bve);Ylr=r(p9t,"mbart"),p9t.forEach(t),Klr=r(oje," \u2014 "),dH=n(oje,"A",{href:!0});var _9t=s(dH);Zlr=r(_9t,"MBartForQuestionAnswering"),_9t.forEach(t),eir=r(oje," (mBART model)"),oje.forEach(t),oir=i(X),FT=n(X,"LI",{});var rje=s(FT);vve=n(rje,"STRONG",{});var u9t=s(vve);rir=r(u9t,"megatron-bert"),u9t.forEach(t),tir=r(rje," \u2014 "),cH=n(rje,"A",{href:!0});var b9t=s(cH);air=r(b9t,"MegatronBertForQuestionAnswering"),b9t.forEach(t),nir=r(rje," (Megatron-BERT model)"),rje.forEach(t),sir=i(X),TT=n(X,"LI",{});var tje=s(TT);Fve=n(tje,"STRONG",{});var v9t=s(Fve);lir=r(v9t,"mobilebert"),v9t.forEach(t),iir=r(tje," \u2014 "),fH=n(tje,"A",{href:!0});var F9t=s(fH);dir=r(F9t,"MobileBertForQuestionAnswering"),F9t.forEach(t),cir=r(tje," (MobileBERT model)"),tje.forEach(t),fir=i(X),MT=n(X,"LI",{});var aje=s(MT);Tve=n(aje,"STRONG",{});var T9t=s(Tve);mir=r(T9t,"mpnet"),T9t.forEach(t),gir=r(aje," \u2014 "),mH=n(aje,"A",{href:!0});var M9t=s(mH);hir=r(M9t,"MPNetForQuestionAnswering"),M9t.forEach(t),pir=r(aje," (MPNet model)"),aje.forEach(t),_ir=i(X),ET=n(X,"LI",{});var nje=s(ET);Mve=n(nje,"STRONG",{});var E9t=s(Mve);uir=r(E9t,"mvp"),E9t.forEach(t),bir=r(nje," \u2014 "),gH=n(nje,"A",{href:!0});var C9t=s(gH);vir=r(C9t,"MvpForQuestionAnswering"),C9t.forEach(t),Fir=r(nje," (MVP model)"),nje.forEach(t),Tir=i(X),CT=n(X,"LI",{});var sje=s(CT);Eve=n(sje,"STRONG",{});var w9t=s(Eve);Mir=r(w9t,"nezha"),w9t.forEach(t),Eir=r(sje," \u2014 "),hH=n(sje,"A",{href:!0});var A9t=s(hH);Cir=r(A9t,"NezhaForQuestionAnswering"),A9t.forEach(t),wir=r(sje," (Nezha model)"),sje.forEach(t),Air=i(X),wT=n(X,"LI",{});var lje=s(wT);Cve=n(lje,"STRONG",{});var L9t=s(Cve);Lir=r(L9t,"nystromformer"),L9t.forEach(t),yir=r(lje," \u2014 "),pH=n(lje,"A",{href:!0});var y9t=s(pH);xir=r(y9t,"NystromformerForQuestionAnswering"),y9t.forEach(t),$ir=r(lje," (Nystr\xF6mformer model)"),lje.forEach(t),kir=i(X),AT=n(X,"LI",{});var ije=s(AT);wve=n(ije,"STRONG",{});var x9t=s(wve);Sir=r(x9t,"qdqbert"),x9t.forEach(t),Rir=r(ije," \u2014 "),_H=n(ije,"A",{href:!0});var $9t=s(_H);Pir=r($9t,"QDQBertForQuestionAnswering"),$9t.forEach(t),Bir=r(ije," (QDQBert model)"),ije.forEach(t),Iir=i(X),LT=n(X,"LI",{});var dje=s(LT);Ave=n(dje,"STRONG",{});var k9t=s(Ave);Nir=r(k9t,"reformer"),k9t.forEach(t),qir=r(dje," \u2014 "),uH=n(dje,"A",{href:!0});var S9t=s(uH);jir=r(S9t,"ReformerForQuestionAnswering"),S9t.forEach(t),Dir=r(dje," (Reformer model)"),dje.forEach(t),Gir=i(X),yT=n(X,"LI",{});var cje=s(yT);Lve=n(cje,"STRONG",{});var R9t=s(Lve);Oir=r(R9t,"rembert"),R9t.forEach(t),Vir=r(cje," \u2014 "),bH=n(cje,"A",{href:!0});var P9t=s(bH);Xir=r(P9t,"RemBertForQuestionAnswering"),P9t.forEach(t),zir=r(cje," (RemBERT model)"),cje.forEach(t),Wir=i(X),xT=n(X,"LI",{});var fje=s(xT);yve=n(fje,"STRONG",{});var B9t=s(yve);Qir=r(B9t,"roberta"),B9t.forEach(t),Hir=r(fje," \u2014 "),vH=n(fje,"A",{href:!0});var I9t=s(vH);Uir=r(I9t,"RobertaForQuestionAnswering"),I9t.forEach(t),Jir=r(fje," (RoBERTa model)"),fje.forEach(t),Yir=i(X),$T=n(X,"LI",{});var mje=s($T);xve=n(mje,"STRONG",{});var N9t=s(xve);Kir=r(N9t,"roformer"),N9t.forEach(t),Zir=r(mje," \u2014 "),FH=n(mje,"A",{href:!0});var q9t=s(FH);edr=r(q9t,"RoFormerForQuestionAnswering"),q9t.forEach(t),odr=r(mje," (RoFormer model)"),mje.forEach(t),rdr=i(X),kT=n(X,"LI",{});var gje=s(kT);$ve=n(gje,"STRONG",{});var j9t=s($ve);tdr=r(j9t,"splinter"),j9t.forEach(t),adr=r(gje," \u2014 "),TH=n(gje,"A",{href:!0});var D9t=s(TH);ndr=r(D9t,"SplinterForQuestionAnswering"),D9t.forEach(t),sdr=r(gje," (Splinter model)"),gje.forEach(t),ldr=i(X),ST=n(X,"LI",{});var hje=s(ST);kve=n(hje,"STRONG",{});var G9t=s(kve);idr=r(G9t,"squeezebert"),G9t.forEach(t),ddr=r(hje," \u2014 "),MH=n(hje,"A",{href:!0});var O9t=s(MH);cdr=r(O9t,"SqueezeBertForQuestionAnswering"),O9t.forEach(t),fdr=r(hje," (SqueezeBERT model)"),hje.forEach(t),mdr=i(X),RT=n(X,"LI",{});var pje=s(RT);Sve=n(pje,"STRONG",{});var V9t=s(Sve);gdr=r(V9t,"xlm"),V9t.forEach(t),hdr=r(pje," \u2014 "),EH=n(pje,"A",{href:!0});var X9t=s(EH);pdr=r(X9t,"XLMForQuestionAnsweringSimple"),X9t.forEach(t),_dr=r(pje," (XLM model)"),pje.forEach(t),udr=i(X),PT=n(X,"LI",{});var _je=s(PT);Rve=n(_je,"STRONG",{});var z9t=s(Rve);bdr=r(z9t,"xlm-roberta"),z9t.forEach(t),vdr=r(_je," \u2014 "),CH=n(_je,"A",{href:!0});var W9t=s(CH);Fdr=r(W9t,"XLMRobertaForQuestionAnswering"),W9t.forEach(t),Tdr=r(_je," (XLM-RoBERTa model)"),_je.forEach(t),Mdr=i(X),BT=n(X,"LI",{});var uje=s(BT);Pve=n(uje,"STRONG",{});var Q9t=s(Pve);Edr=r(Q9t,"xlm-roberta-xl"),Q9t.forEach(t),Cdr=r(uje," \u2014 "),wH=n(uje,"A",{href:!0});var H9t=s(wH);wdr=r(H9t,"XLMRobertaXLForQuestionAnswering"),H9t.forEach(t),Adr=r(uje," (XLM-RoBERTa-XL model)"),uje.forEach(t),Ldr=i(X),IT=n(X,"LI",{});var bje=s(IT);Bve=n(bje,"STRONG",{});var U9t=s(Bve);ydr=r(U9t,"xlnet"),U9t.forEach(t),xdr=r(bje," \u2014 "),AH=n(bje,"A",{href:!0});var J9t=s(AH);$dr=r(J9t,"XLNetForQuestionAnsweringSimple"),J9t.forEach(t),kdr=r(bje," (XLNet model)"),bje.forEach(t),Sdr=i(X),NT=n(X,"LI",{});var vje=s(NT);Ive=n(vje,"STRONG",{});var Y9t=s(Ive);Rdr=r(Y9t,"yoso"),Y9t.forEach(t),Pdr=r(vje," \u2014 "),LH=n(vje,"A",{href:!0});var K9t=s(LH);Bdr=r(K9t,"YosoForQuestionAnswering"),K9t.forEach(t),Idr=r(vje," (YOSO model)"),vje.forEach(t),X.forEach(t),Ndr=i(Fa),qT=n(Fa,"P",{});var Fje=s(qT);qdr=r(Fje,"The model is set in evaluation mode by default using "),Nve=n(Fje,"CODE",{});var Z9t=s(Nve);jdr=r(Z9t,"model.eval()"),Z9t.forEach(t),Ddr=r(Fje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),qve=n(Fje,"CODE",{});var ext=s(qve);Gdr=r(ext,"model.train()"),ext.forEach(t),Fje.forEach(t),Odr=i(Fa),T(jT.$$.fragment,Fa),Fa.forEach(t),vl.forEach(t),MQe=i(f),Ad=n(f,"H2",{class:!0});var $Ue=s(Ad);DT=n($Ue,"A",{id:!0,class:!0,href:!0});var oxt=s(DT);jve=n(oxt,"SPAN",{});var rxt=s(jve);T(_9.$$.fragment,rxt),rxt.forEach(t),oxt.forEach(t),Vdr=i($Ue),Dve=n($Ue,"SPAN",{});var txt=s(Dve);Xdr=r(txt,"AutoModelForTableQuestionAnswering"),txt.forEach(t),$Ue.forEach(t),EQe=i(f),Vo=n(f,"DIV",{class:!0});var Fl=s(Vo);T(u9.$$.fragment,Fl),zdr=i(Fl),Ld=n(Fl,"P",{});var yae=s(Ld);Wdr=r(yae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),yH=n(yae,"A",{href:!0});var axt=s(yH);Qdr=r(axt,"from_pretrained()"),axt.forEach(t),Hdr=r(yae," class method or the "),xH=n(yae,"A",{href:!0});var nxt=s(xH);Udr=r(nxt,"from_config()"),nxt.forEach(t),Jdr=r(yae,` class
method.`),yae.forEach(t),Ydr=i(Fl),b9=n(Fl,"P",{});var kUe=s(b9);Kdr=r(kUe,"This class cannot be instantiated directly using "),Gve=n(kUe,"CODE",{});var sxt=s(Gve);Zdr=r(sxt,"__init__()"),sxt.forEach(t),ecr=r(kUe," (throws an error)."),kUe.forEach(t),ocr=i(Fl),Ft=n(Fl,"DIV",{class:!0});var p7=s(Ft);T(v9.$$.fragment,p7),rcr=i(p7),Ove=n(p7,"P",{});var lxt=s(Ove);tcr=r(lxt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),lxt.forEach(t),acr=i(p7),yd=n(p7,"P",{});var xae=s(yd);ncr=r(xae,`Note:
Loading a model from its configuration file does `),Vve=n(xae,"STRONG",{});var ixt=s(Vve);scr=r(ixt,"not"),ixt.forEach(t),lcr=r(xae,` load the model weights. It only affects the
model\u2019s configuration. Use `),$H=n(xae,"A",{href:!0});var dxt=s($H);icr=r(dxt,"from_pretrained()"),dxt.forEach(t),dcr=r(xae," to load the model weights."),xae.forEach(t),ccr=i(p7),T(GT.$$.fragment,p7),p7.forEach(t),fcr=i(Fl),lo=n(Fl,"DIV",{class:!0});var Ta=s(lo);T(F9.$$.fragment,Ta),mcr=i(Ta),Xve=n(Ta,"P",{});var cxt=s(Xve);gcr=r(cxt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),cxt.forEach(t),hcr=i(Ta),Ja=n(Ta,"P",{});var _7=s(Ja);pcr=r(_7,"The model class to instantiate is selected based on the "),zve=n(_7,"CODE",{});var fxt=s(zve);_cr=r(fxt,"model_type"),fxt.forEach(t),ucr=r(_7,` property of the config object (either
passed as an argument or loaded from `),Wve=n(_7,"CODE",{});var mxt=s(Wve);bcr=r(mxt,"pretrained_model_name_or_path"),mxt.forEach(t),vcr=r(_7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qve=n(_7,"CODE",{});var gxt=s(Qve);Fcr=r(gxt,"pretrained_model_name_or_path"),gxt.forEach(t),Tcr=r(_7,":"),_7.forEach(t),Mcr=i(Ta),Hve=n(Ta,"UL",{});var hxt=s(Hve);OT=n(hxt,"LI",{});var Tje=s(OT);Uve=n(Tje,"STRONG",{});var pxt=s(Uve);Ecr=r(pxt,"tapas"),pxt.forEach(t),Ccr=r(Tje," \u2014 "),kH=n(Tje,"A",{href:!0});var _xt=s(kH);wcr=r(_xt,"TapasForQuestionAnswering"),_xt.forEach(t),Acr=r(Tje," (TAPAS model)"),Tje.forEach(t),hxt.forEach(t),Lcr=i(Ta),VT=n(Ta,"P",{});var Mje=s(VT);ycr=r(Mje,"The model is set in evaluation mode by default using "),Jve=n(Mje,"CODE",{});var uxt=s(Jve);xcr=r(uxt,"model.eval()"),uxt.forEach(t),$cr=r(Mje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yve=n(Mje,"CODE",{});var bxt=s(Yve);kcr=r(bxt,"model.train()"),bxt.forEach(t),Mje.forEach(t),Scr=i(Ta),T(XT.$$.fragment,Ta),Ta.forEach(t),Fl.forEach(t),CQe=i(f),xd=n(f,"H2",{class:!0});var SUe=s(xd);zT=n(SUe,"A",{id:!0,class:!0,href:!0});var vxt=s(zT);Kve=n(vxt,"SPAN",{});var Fxt=s(Kve);T(T9.$$.fragment,Fxt),Fxt.forEach(t),vxt.forEach(t),Rcr=i(SUe),Zve=n(SUe,"SPAN",{});var Txt=s(Zve);Pcr=r(Txt,"AutoModelForImageClassification"),Txt.forEach(t),SUe.forEach(t),wQe=i(f),Xo=n(f,"DIV",{class:!0});var Tl=s(Xo);T(M9.$$.fragment,Tl),Bcr=i(Tl),$d=n(Tl,"P",{});var $ae=s($d);Icr=r($ae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),SH=n($ae,"A",{href:!0});var Mxt=s(SH);Ncr=r(Mxt,"from_pretrained()"),Mxt.forEach(t),qcr=r($ae," class method or the "),RH=n($ae,"A",{href:!0});var Ext=s(RH);jcr=r(Ext,"from_config()"),Ext.forEach(t),Dcr=r($ae,` class
method.`),$ae.forEach(t),Gcr=i(Tl),E9=n(Tl,"P",{});var RUe=s(E9);Ocr=r(RUe,"This class cannot be instantiated directly using "),e0e=n(RUe,"CODE",{});var Cxt=s(e0e);Vcr=r(Cxt,"__init__()"),Cxt.forEach(t),Xcr=r(RUe," (throws an error)."),RUe.forEach(t),zcr=i(Tl),Tt=n(Tl,"DIV",{class:!0});var u7=s(Tt);T(C9.$$.fragment,u7),Wcr=i(u7),o0e=n(u7,"P",{});var wxt=s(o0e);Qcr=r(wxt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),wxt.forEach(t),Hcr=i(u7),kd=n(u7,"P",{});var kae=s(kd);Ucr=r(kae,`Note:
Loading a model from its configuration file does `),r0e=n(kae,"STRONG",{});var Axt=s(r0e);Jcr=r(Axt,"not"),Axt.forEach(t),Ycr=r(kae,` load the model weights. It only affects the
model\u2019s configuration. Use `),PH=n(kae,"A",{href:!0});var Lxt=s(PH);Kcr=r(Lxt,"from_pretrained()"),Lxt.forEach(t),Zcr=r(kae," to load the model weights."),kae.forEach(t),efr=i(u7),T(WT.$$.fragment,u7),u7.forEach(t),ofr=i(Tl),io=n(Tl,"DIV",{class:!0});var Ma=s(io);T(w9.$$.fragment,Ma),rfr=i(Ma),t0e=n(Ma,"P",{});var yxt=s(t0e);tfr=r(yxt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),yxt.forEach(t),afr=i(Ma),Ya=n(Ma,"P",{});var b7=s(Ya);nfr=r(b7,"The model class to instantiate is selected based on the "),a0e=n(b7,"CODE",{});var xxt=s(a0e);sfr=r(xxt,"model_type"),xxt.forEach(t),lfr=r(b7,` property of the config object (either
passed as an argument or loaded from `),n0e=n(b7,"CODE",{});var $xt=s(n0e);ifr=r($xt,"pretrained_model_name_or_path"),$xt.forEach(t),dfr=r(b7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),s0e=n(b7,"CODE",{});var kxt=s(s0e);cfr=r(kxt,"pretrained_model_name_or_path"),kxt.forEach(t),ffr=r(b7,":"),b7.forEach(t),mfr=i(Ma),be=n(Ma,"UL",{});var Fe=s(be);QT=n(Fe,"LI",{});var Eje=s(QT);l0e=n(Eje,"STRONG",{});var Sxt=s(l0e);gfr=r(Sxt,"beit"),Sxt.forEach(t),hfr=r(Eje," \u2014 "),BH=n(Eje,"A",{href:!0});var Rxt=s(BH);pfr=r(Rxt,"BeitForImageClassification"),Rxt.forEach(t),_fr=r(Eje," (BEiT model)"),Eje.forEach(t),ufr=i(Fe),HT=n(Fe,"LI",{});var Cje=s(HT);i0e=n(Cje,"STRONG",{});var Pxt=s(i0e);bfr=r(Pxt,"convnext"),Pxt.forEach(t),vfr=r(Cje," \u2014 "),IH=n(Cje,"A",{href:!0});var Bxt=s(IH);Ffr=r(Bxt,"ConvNextForImageClassification"),Bxt.forEach(t),Tfr=r(Cje," (ConvNeXT model)"),Cje.forEach(t),Mfr=i(Fe),UT=n(Fe,"LI",{});var wje=s(UT);d0e=n(wje,"STRONG",{});var Ixt=s(d0e);Efr=r(Ixt,"cvt"),Ixt.forEach(t),Cfr=r(wje," \u2014 "),NH=n(wje,"A",{href:!0});var Nxt=s(NH);wfr=r(Nxt,"CvtForImageClassification"),Nxt.forEach(t),Afr=r(wje," (CvT model)"),wje.forEach(t),Lfr=i(Fe),JT=n(Fe,"LI",{});var Aje=s(JT);c0e=n(Aje,"STRONG",{});var qxt=s(c0e);yfr=r(qxt,"data2vec-vision"),qxt.forEach(t),xfr=r(Aje," \u2014 "),qH=n(Aje,"A",{href:!0});var jxt=s(qH);$fr=r(jxt,"Data2VecVisionForImageClassification"),jxt.forEach(t),kfr=r(Aje," (Data2VecVision model)"),Aje.forEach(t),Sfr=i(Fe),rl=n(Fe,"LI",{});var yR=s(rl);f0e=n(yR,"STRONG",{});var Dxt=s(f0e);Rfr=r(Dxt,"deit"),Dxt.forEach(t),Pfr=r(yR," \u2014 "),jH=n(yR,"A",{href:!0});var Gxt=s(jH);Bfr=r(Gxt,"DeiTForImageClassification"),Gxt.forEach(t),Ifr=r(yR," or "),DH=n(yR,"A",{href:!0});var Oxt=s(DH);Nfr=r(Oxt,"DeiTForImageClassificationWithTeacher"),Oxt.forEach(t),qfr=r(yR," (DeiT model)"),yR.forEach(t),jfr=i(Fe),YT=n(Fe,"LI",{});var Lje=s(YT);m0e=n(Lje,"STRONG",{});var Vxt=s(m0e);Dfr=r(Vxt,"imagegpt"),Vxt.forEach(t),Gfr=r(Lje," \u2014 "),GH=n(Lje,"A",{href:!0});var Xxt=s(GH);Ofr=r(Xxt,"ImageGPTForImageClassification"),Xxt.forEach(t),Vfr=r(Lje," (ImageGPT model)"),Lje.forEach(t),Xfr=i(Fe),tl=n(Fe,"LI",{});var xR=s(tl);g0e=n(xR,"STRONG",{});var zxt=s(g0e);zfr=r(zxt,"levit"),zxt.forEach(t),Wfr=r(xR," \u2014 "),OH=n(xR,"A",{href:!0});var Wxt=s(OH);Qfr=r(Wxt,"LevitForImageClassification"),Wxt.forEach(t),Hfr=r(xR," or "),VH=n(xR,"A",{href:!0});var Qxt=s(VH);Ufr=r(Qxt,"LevitForImageClassificationWithTeacher"),Qxt.forEach(t),Jfr=r(xR," (LeViT model)"),xR.forEach(t),Yfr=i(Fe),KT=n(Fe,"LI",{});var yje=s(KT);h0e=n(yje,"STRONG",{});var Hxt=s(h0e);Kfr=r(Hxt,"mobilevit"),Hxt.forEach(t),Zfr=r(yje," \u2014 "),XH=n(yje,"A",{href:!0});var Uxt=s(XH);emr=r(Uxt,"MobileViTForImageClassification"),Uxt.forEach(t),omr=r(yje," (MobileViT model)"),yje.forEach(t),rmr=i(Fe),Mt=n(Fe,"LI",{});var Xf=s(Mt);p0e=n(Xf,"STRONG",{});var Jxt=s(p0e);tmr=r(Jxt,"perceiver"),Jxt.forEach(t),amr=r(Xf," \u2014 "),zH=n(Xf,"A",{href:!0});var Yxt=s(zH);nmr=r(Yxt,"PerceiverForImageClassificationLearned"),Yxt.forEach(t),smr=r(Xf," or "),WH=n(Xf,"A",{href:!0});var Kxt=s(WH);lmr=r(Kxt,"PerceiverForImageClassificationFourier"),Kxt.forEach(t),imr=r(Xf," or "),QH=n(Xf,"A",{href:!0});var Zxt=s(QH);dmr=r(Zxt,"PerceiverForImageClassificationConvProcessing"),Zxt.forEach(t),cmr=r(Xf," (Perceiver model)"),Xf.forEach(t),fmr=i(Fe),ZT=n(Fe,"LI",{});var xje=s(ZT);_0e=n(xje,"STRONG",{});var e$t=s(_0e);mmr=r(e$t,"poolformer"),e$t.forEach(t),gmr=r(xje," \u2014 "),HH=n(xje,"A",{href:!0});var o$t=s(HH);hmr=r(o$t,"PoolFormerForImageClassification"),o$t.forEach(t),pmr=r(xje," (PoolFormer model)"),xje.forEach(t),_mr=i(Fe),e8=n(Fe,"LI",{});var $je=s(e8);u0e=n($je,"STRONG",{});var r$t=s(u0e);umr=r(r$t,"regnet"),r$t.forEach(t),bmr=r($je," \u2014 "),UH=n($je,"A",{href:!0});var t$t=s(UH);vmr=r(t$t,"RegNetForImageClassification"),t$t.forEach(t),Fmr=r($je," (RegNet model)"),$je.forEach(t),Tmr=i(Fe),o8=n(Fe,"LI",{});var kje=s(o8);b0e=n(kje,"STRONG",{});var a$t=s(b0e);Mmr=r(a$t,"resnet"),a$t.forEach(t),Emr=r(kje," \u2014 "),JH=n(kje,"A",{href:!0});var n$t=s(JH);Cmr=r(n$t,"ResNetForImageClassification"),n$t.forEach(t),wmr=r(kje," (ResNet model)"),kje.forEach(t),Amr=i(Fe),r8=n(Fe,"LI",{});var Sje=s(r8);v0e=n(Sje,"STRONG",{});var s$t=s(v0e);Lmr=r(s$t,"segformer"),s$t.forEach(t),ymr=r(Sje," \u2014 "),YH=n(Sje,"A",{href:!0});var l$t=s(YH);xmr=r(l$t,"SegformerForImageClassification"),l$t.forEach(t),$mr=r(Sje," (SegFormer model)"),Sje.forEach(t),kmr=i(Fe),t8=n(Fe,"LI",{});var Rje=s(t8);F0e=n(Rje,"STRONG",{});var i$t=s(F0e);Smr=r(i$t,"swin"),i$t.forEach(t),Rmr=r(Rje," \u2014 "),KH=n(Rje,"A",{href:!0});var d$t=s(KH);Pmr=r(d$t,"SwinForImageClassification"),d$t.forEach(t),Bmr=r(Rje," (Swin Transformer model)"),Rje.forEach(t),Imr=i(Fe),a8=n(Fe,"LI",{});var Pje=s(a8);T0e=n(Pje,"STRONG",{});var c$t=s(T0e);Nmr=r(c$t,"swinv2"),c$t.forEach(t),qmr=r(Pje," \u2014 "),ZH=n(Pje,"A",{href:!0});var f$t=s(ZH);jmr=r(f$t,"Swinv2ForImageClassification"),f$t.forEach(t),Dmr=r(Pje," (Swin Transformer V2 model)"),Pje.forEach(t),Gmr=i(Fe),n8=n(Fe,"LI",{});var Bje=s(n8);M0e=n(Bje,"STRONG",{});var m$t=s(M0e);Omr=r(m$t,"van"),m$t.forEach(t),Vmr=r(Bje," \u2014 "),eU=n(Bje,"A",{href:!0});var g$t=s(eU);Xmr=r(g$t,"VanForImageClassification"),g$t.forEach(t),zmr=r(Bje," (VAN model)"),Bje.forEach(t),Wmr=i(Fe),s8=n(Fe,"LI",{});var Ije=s(s8);E0e=n(Ije,"STRONG",{});var h$t=s(E0e);Qmr=r(h$t,"vit"),h$t.forEach(t),Hmr=r(Ije," \u2014 "),oU=n(Ije,"A",{href:!0});var p$t=s(oU);Umr=r(p$t,"ViTForImageClassification"),p$t.forEach(t),Jmr=r(Ije," (ViT model)"),Ije.forEach(t),Fe.forEach(t),Ymr=i(Ma),l8=n(Ma,"P",{});var Nje=s(l8);Kmr=r(Nje,"The model is set in evaluation mode by default using "),C0e=n(Nje,"CODE",{});var _$t=s(C0e);Zmr=r(_$t,"model.eval()"),_$t.forEach(t),egr=r(Nje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),w0e=n(Nje,"CODE",{});var u$t=s(w0e);ogr=r(u$t,"model.train()"),u$t.forEach(t),Nje.forEach(t),rgr=i(Ma),T(i8.$$.fragment,Ma),Ma.forEach(t),Tl.forEach(t),AQe=i(f),Sd=n(f,"H2",{class:!0});var PUe=s(Sd);d8=n(PUe,"A",{id:!0,class:!0,href:!0});var b$t=s(d8);A0e=n(b$t,"SPAN",{});var v$t=s(A0e);T(A9.$$.fragment,v$t),v$t.forEach(t),b$t.forEach(t),tgr=i(PUe),L0e=n(PUe,"SPAN",{});var F$t=s(L0e);agr=r(F$t,"AutoModelForVideoClassification"),F$t.forEach(t),PUe.forEach(t),LQe=i(f),zo=n(f,"DIV",{class:!0});var Ml=s(zo);T(L9.$$.fragment,Ml),ngr=i(Ml),Rd=n(Ml,"P",{});var Sae=s(Rd);sgr=r(Sae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a video classification head) when created
with the `),rU=n(Sae,"A",{href:!0});var T$t=s(rU);lgr=r(T$t,"from_pretrained()"),T$t.forEach(t),igr=r(Sae," class method or the "),tU=n(Sae,"A",{href:!0});var M$t=s(tU);dgr=r(M$t,"from_config()"),M$t.forEach(t),cgr=r(Sae,` class
method.`),Sae.forEach(t),fgr=i(Ml),y9=n(Ml,"P",{});var BUe=s(y9);mgr=r(BUe,"This class cannot be instantiated directly using "),y0e=n(BUe,"CODE",{});var E$t=s(y0e);ggr=r(E$t,"__init__()"),E$t.forEach(t),hgr=r(BUe," (throws an error)."),BUe.forEach(t),pgr=i(Ml),Et=n(Ml,"DIV",{class:!0});var v7=s(Et);T(x9.$$.fragment,v7),_gr=i(v7),x0e=n(v7,"P",{});var C$t=s(x0e);ugr=r(C$t,"Instantiates one of the model classes of the library (with a video classification head) from a configuration."),C$t.forEach(t),bgr=i(v7),Pd=n(v7,"P",{});var Rae=s(Pd);vgr=r(Rae,`Note:
Loading a model from its configuration file does `),$0e=n(Rae,"STRONG",{});var w$t=s($0e);Fgr=r(w$t,"not"),w$t.forEach(t),Tgr=r(Rae,` load the model weights. It only affects the
model\u2019s configuration. Use `),aU=n(Rae,"A",{href:!0});var A$t=s(aU);Mgr=r(A$t,"from_pretrained()"),A$t.forEach(t),Egr=r(Rae," to load the model weights."),Rae.forEach(t),Cgr=i(v7),T(c8.$$.fragment,v7),v7.forEach(t),wgr=i(Ml),co=n(Ml,"DIV",{class:!0});var Ea=s(co);T($9.$$.fragment,Ea),Agr=i(Ea),k0e=n(Ea,"P",{});var L$t=s(k0e);Lgr=r(L$t,"Instantiate one of the model classes of the library (with a video classification head) from a pretrained model."),L$t.forEach(t),ygr=i(Ea),Ka=n(Ea,"P",{});var F7=s(Ka);xgr=r(F7,"The model class to instantiate is selected based on the "),S0e=n(F7,"CODE",{});var y$t=s(S0e);$gr=r(y$t,"model_type"),y$t.forEach(t),kgr=r(F7,` property of the config object (either
passed as an argument or loaded from `),R0e=n(F7,"CODE",{});var x$t=s(R0e);Sgr=r(x$t,"pretrained_model_name_or_path"),x$t.forEach(t),Rgr=r(F7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P0e=n(F7,"CODE",{});var $$t=s(P0e);Pgr=r($$t,"pretrained_model_name_or_path"),$$t.forEach(t),Bgr=r(F7,":"),F7.forEach(t),Igr=i(Ea),B0e=n(Ea,"UL",{});var k$t=s(B0e);f8=n(k$t,"LI",{});var qje=s(f8);I0e=n(qje,"STRONG",{});var S$t=s(I0e);Ngr=r(S$t,"videomae"),S$t.forEach(t),qgr=r(qje," \u2014 "),nU=n(qje,"A",{href:!0});var R$t=s(nU);jgr=r(R$t,"VideoMAEForVideoClassification"),R$t.forEach(t),Dgr=r(qje," (VideoMAE model)"),qje.forEach(t),k$t.forEach(t),Ggr=i(Ea),m8=n(Ea,"P",{});var jje=s(m8);Ogr=r(jje,"The model is set in evaluation mode by default using "),N0e=n(jje,"CODE",{});var P$t=s(N0e);Vgr=r(P$t,"model.eval()"),P$t.forEach(t),Xgr=r(jje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q0e=n(jje,"CODE",{});var B$t=s(q0e);zgr=r(B$t,"model.train()"),B$t.forEach(t),jje.forEach(t),Wgr=i(Ea),T(g8.$$.fragment,Ea),Ea.forEach(t),Ml.forEach(t),yQe=i(f),Bd=n(f,"H2",{class:!0});var IUe=s(Bd);h8=n(IUe,"A",{id:!0,class:!0,href:!0});var I$t=s(h8);j0e=n(I$t,"SPAN",{});var N$t=s(j0e);T(k9.$$.fragment,N$t),N$t.forEach(t),I$t.forEach(t),Qgr=i(IUe),D0e=n(IUe,"SPAN",{});var q$t=s(D0e);Hgr=r(q$t,"AutoModelForVision2Seq"),q$t.forEach(t),IUe.forEach(t),xQe=i(f),Wo=n(f,"DIV",{class:!0});var El=s(Wo);T(S9.$$.fragment,El),Ugr=i(El),Id=n(El,"P",{});var Pae=s(Id);Jgr=r(Pae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),sU=n(Pae,"A",{href:!0});var j$t=s(sU);Ygr=r(j$t,"from_pretrained()"),j$t.forEach(t),Kgr=r(Pae," class method or the "),lU=n(Pae,"A",{href:!0});var D$t=s(lU);Zgr=r(D$t,"from_config()"),D$t.forEach(t),ehr=r(Pae,` class
method.`),Pae.forEach(t),ohr=i(El),R9=n(El,"P",{});var NUe=s(R9);rhr=r(NUe,"This class cannot be instantiated directly using "),G0e=n(NUe,"CODE",{});var G$t=s(G0e);thr=r(G$t,"__init__()"),G$t.forEach(t),ahr=r(NUe," (throws an error)."),NUe.forEach(t),nhr=i(El),Ct=n(El,"DIV",{class:!0});var T7=s(Ct);T(P9.$$.fragment,T7),shr=i(T7),O0e=n(T7,"P",{});var O$t=s(O0e);lhr=r(O$t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),O$t.forEach(t),ihr=i(T7),Nd=n(T7,"P",{});var Bae=s(Nd);dhr=r(Bae,`Note:
Loading a model from its configuration file does `),V0e=n(Bae,"STRONG",{});var V$t=s(V0e);chr=r(V$t,"not"),V$t.forEach(t),fhr=r(Bae,` load the model weights. It only affects the
model\u2019s configuration. Use `),iU=n(Bae,"A",{href:!0});var X$t=s(iU);mhr=r(X$t,"from_pretrained()"),X$t.forEach(t),ghr=r(Bae," to load the model weights."),Bae.forEach(t),hhr=i(T7),T(p8.$$.fragment,T7),T7.forEach(t),phr=i(El),fo=n(El,"DIV",{class:!0});var Ca=s(fo);T(B9.$$.fragment,Ca),_hr=i(Ca),X0e=n(Ca,"P",{});var z$t=s(X0e);uhr=r(z$t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),z$t.forEach(t),bhr=i(Ca),Za=n(Ca,"P",{});var M7=s(Za);vhr=r(M7,"The model class to instantiate is selected based on the "),z0e=n(M7,"CODE",{});var W$t=s(z0e);Fhr=r(W$t,"model_type"),W$t.forEach(t),Thr=r(M7,` property of the config object (either
passed as an argument or loaded from `),W0e=n(M7,"CODE",{});var Q$t=s(W0e);Mhr=r(Q$t,"pretrained_model_name_or_path"),Q$t.forEach(t),Ehr=r(M7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q0e=n(M7,"CODE",{});var H$t=s(Q0e);Chr=r(H$t,"pretrained_model_name_or_path"),H$t.forEach(t),whr=r(M7,":"),M7.forEach(t),Ahr=i(Ca),H0e=n(Ca,"UL",{});var U$t=s(H0e);_8=n(U$t,"LI",{});var Dje=s(_8);U0e=n(Dje,"STRONG",{});var J$t=s(U0e);Lhr=r(J$t,"vision-encoder-decoder"),J$t.forEach(t),yhr=r(Dje," \u2014 "),dU=n(Dje,"A",{href:!0});var Y$t=s(dU);xhr=r(Y$t,"VisionEncoderDecoderModel"),Y$t.forEach(t),$hr=r(Dje," (Vision Encoder decoder model)"),Dje.forEach(t),U$t.forEach(t),khr=i(Ca),u8=n(Ca,"P",{});var Gje=s(u8);Shr=r(Gje,"The model is set in evaluation mode by default using "),J0e=n(Gje,"CODE",{});var K$t=s(J0e);Rhr=r(K$t,"model.eval()"),K$t.forEach(t),Phr=r(Gje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Y0e=n(Gje,"CODE",{});var Z$t=s(Y0e);Bhr=r(Z$t,"model.train()"),Z$t.forEach(t),Gje.forEach(t),Ihr=i(Ca),T(b8.$$.fragment,Ca),Ca.forEach(t),El.forEach(t),$Qe=i(f),qd=n(f,"H2",{class:!0});var qUe=s(qd);v8=n(qUe,"A",{id:!0,class:!0,href:!0});var ekt=s(v8);K0e=n(ekt,"SPAN",{});var okt=s(K0e);T(I9.$$.fragment,okt),okt.forEach(t),ekt.forEach(t),Nhr=i(qUe),Z0e=n(qUe,"SPAN",{});var rkt=s(Z0e);qhr=r(rkt,"AutoModelForVisualQuestionAnswering"),rkt.forEach(t),qUe.forEach(t),kQe=i(f),Qo=n(f,"DIV",{class:!0});var Cl=s(Qo);T(N9.$$.fragment,Cl),jhr=i(Cl),jd=n(Cl,"P",{});var Iae=s(jd);Dhr=r(Iae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),cU=n(Iae,"A",{href:!0});var tkt=s(cU);Ghr=r(tkt,"from_pretrained()"),tkt.forEach(t),Ohr=r(Iae," class method or the "),fU=n(Iae,"A",{href:!0});var akt=s(fU);Vhr=r(akt,"from_config()"),akt.forEach(t),Xhr=r(Iae,` class
method.`),Iae.forEach(t),zhr=i(Cl),q9=n(Cl,"P",{});var jUe=s(q9);Whr=r(jUe,"This class cannot be instantiated directly using "),eFe=n(jUe,"CODE",{});var nkt=s(eFe);Qhr=r(nkt,"__init__()"),nkt.forEach(t),Hhr=r(jUe," (throws an error)."),jUe.forEach(t),Uhr=i(Cl),wt=n(Cl,"DIV",{class:!0});var E7=s(wt);T(j9.$$.fragment,E7),Jhr=i(E7),oFe=n(E7,"P",{});var skt=s(oFe);Yhr=r(skt,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),skt.forEach(t),Khr=i(E7),Dd=n(E7,"P",{});var Nae=s(Dd);Zhr=r(Nae,`Note:
Loading a model from its configuration file does `),rFe=n(Nae,"STRONG",{});var lkt=s(rFe);epr=r(lkt,"not"),lkt.forEach(t),opr=r(Nae,` load the model weights. It only affects the
model\u2019s configuration. Use `),mU=n(Nae,"A",{href:!0});var ikt=s(mU);rpr=r(ikt,"from_pretrained()"),ikt.forEach(t),tpr=r(Nae," to load the model weights."),Nae.forEach(t),apr=i(E7),T(F8.$$.fragment,E7),E7.forEach(t),npr=i(Cl),mo=n(Cl,"DIV",{class:!0});var wa=s(mo);T(D9.$$.fragment,wa),spr=i(wa),tFe=n(wa,"P",{});var dkt=s(tFe);lpr=r(dkt,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),dkt.forEach(t),ipr=i(wa),en=n(wa,"P",{});var C7=s(en);dpr=r(C7,"The model class to instantiate is selected based on the "),aFe=n(C7,"CODE",{});var ckt=s(aFe);cpr=r(ckt,"model_type"),ckt.forEach(t),fpr=r(C7,` property of the config object (either
passed as an argument or loaded from `),nFe=n(C7,"CODE",{});var fkt=s(nFe);mpr=r(fkt,"pretrained_model_name_or_path"),fkt.forEach(t),gpr=r(C7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=n(C7,"CODE",{});var mkt=s(sFe);hpr=r(mkt,"pretrained_model_name_or_path"),mkt.forEach(t),ppr=r(C7,":"),C7.forEach(t),_pr=i(wa),lFe=n(wa,"UL",{});var gkt=s(lFe);T8=n(gkt,"LI",{});var Oje=s(T8);iFe=n(Oje,"STRONG",{});var hkt=s(iFe);upr=r(hkt,"vilt"),hkt.forEach(t),bpr=r(Oje," \u2014 "),gU=n(Oje,"A",{href:!0});var pkt=s(gU);vpr=r(pkt,"ViltForQuestionAnswering"),pkt.forEach(t),Fpr=r(Oje," (ViLT model)"),Oje.forEach(t),gkt.forEach(t),Tpr=i(wa),M8=n(wa,"P",{});var Vje=s(M8);Mpr=r(Vje,"The model is set in evaluation mode by default using "),dFe=n(Vje,"CODE",{});var _kt=s(dFe);Epr=r(_kt,"model.eval()"),_kt.forEach(t),Cpr=r(Vje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cFe=n(Vje,"CODE",{});var ukt=s(cFe);wpr=r(ukt,"model.train()"),ukt.forEach(t),Vje.forEach(t),Apr=i(wa),T(E8.$$.fragment,wa),wa.forEach(t),Cl.forEach(t),SQe=i(f),Gd=n(f,"H2",{class:!0});var DUe=s(Gd);C8=n(DUe,"A",{id:!0,class:!0,href:!0});var bkt=s(C8);fFe=n(bkt,"SPAN",{});var vkt=s(fFe);T(G9.$$.fragment,vkt),vkt.forEach(t),bkt.forEach(t),Lpr=i(DUe),mFe=n(DUe,"SPAN",{});var Fkt=s(mFe);ypr=r(Fkt,"AutoModelForAudioClassification"),Fkt.forEach(t),DUe.forEach(t),RQe=i(f),Ho=n(f,"DIV",{class:!0});var wl=s(Ho);T(O9.$$.fragment,wl),xpr=i(wl),Od=n(wl,"P",{});var qae=s(Od);$pr=r(qae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),hU=n(qae,"A",{href:!0});var Tkt=s(hU);kpr=r(Tkt,"from_pretrained()"),Tkt.forEach(t),Spr=r(qae," class method or the "),pU=n(qae,"A",{href:!0});var Mkt=s(pU);Rpr=r(Mkt,"from_config()"),Mkt.forEach(t),Ppr=r(qae,` class
method.`),qae.forEach(t),Bpr=i(wl),V9=n(wl,"P",{});var GUe=s(V9);Ipr=r(GUe,"This class cannot be instantiated directly using "),gFe=n(GUe,"CODE",{});var Ekt=s(gFe);Npr=r(Ekt,"__init__()"),Ekt.forEach(t),qpr=r(GUe," (throws an error)."),GUe.forEach(t),jpr=i(wl),At=n(wl,"DIV",{class:!0});var w7=s(At);T(X9.$$.fragment,w7),Dpr=i(w7),hFe=n(w7,"P",{});var Ckt=s(hFe);Gpr=r(Ckt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),Ckt.forEach(t),Opr=i(w7),Vd=n(w7,"P",{});var jae=s(Vd);Vpr=r(jae,`Note:
Loading a model from its configuration file does `),pFe=n(jae,"STRONG",{});var wkt=s(pFe);Xpr=r(wkt,"not"),wkt.forEach(t),zpr=r(jae,` load the model weights. It only affects the
model\u2019s configuration. Use `),_U=n(jae,"A",{href:!0});var Akt=s(_U);Wpr=r(Akt,"from_pretrained()"),Akt.forEach(t),Qpr=r(jae," to load the model weights."),jae.forEach(t),Hpr=i(w7),T(w8.$$.fragment,w7),w7.forEach(t),Upr=i(wl),go=n(wl,"DIV",{class:!0});var Aa=s(go);T(z9.$$.fragment,Aa),Jpr=i(Aa),_Fe=n(Aa,"P",{});var Lkt=s(_Fe);Ypr=r(Lkt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Lkt.forEach(t),Kpr=i(Aa),on=n(Aa,"P",{});var A7=s(on);Zpr=r(A7,"The model class to instantiate is selected based on the "),uFe=n(A7,"CODE",{});var ykt=s(uFe);e_r=r(ykt,"model_type"),ykt.forEach(t),o_r=r(A7,` property of the config object (either
passed as an argument or loaded from `),bFe=n(A7,"CODE",{});var xkt=s(bFe);r_r=r(xkt,"pretrained_model_name_or_path"),xkt.forEach(t),t_r=r(A7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vFe=n(A7,"CODE",{});var $kt=s(vFe);a_r=r($kt,"pretrained_model_name_or_path"),$kt.forEach(t),n_r=r(A7,":"),A7.forEach(t),s_r=i(Aa),Be=n(Aa,"UL",{});var We=s(Be);A8=n(We,"LI",{});var Xje=s(A8);FFe=n(Xje,"STRONG",{});var kkt=s(FFe);l_r=r(kkt,"data2vec-audio"),kkt.forEach(t),i_r=r(Xje," \u2014 "),uU=n(Xje,"A",{href:!0});var Skt=s(uU);d_r=r(Skt,"Data2VecAudioForSequenceClassification"),Skt.forEach(t),c_r=r(Xje," (Data2VecAudio model)"),Xje.forEach(t),f_r=i(We),L8=n(We,"LI",{});var zje=s(L8);TFe=n(zje,"STRONG",{});var Rkt=s(TFe);m_r=r(Rkt,"hubert"),Rkt.forEach(t),g_r=r(zje," \u2014 "),bU=n(zje,"A",{href:!0});var Pkt=s(bU);h_r=r(Pkt,"HubertForSequenceClassification"),Pkt.forEach(t),p_r=r(zje," (Hubert model)"),zje.forEach(t),__r=i(We),y8=n(We,"LI",{});var Wje=s(y8);MFe=n(Wje,"STRONG",{});var Bkt=s(MFe);u_r=r(Bkt,"sew"),Bkt.forEach(t),b_r=r(Wje," \u2014 "),vU=n(Wje,"A",{href:!0});var Ikt=s(vU);v_r=r(Ikt,"SEWForSequenceClassification"),Ikt.forEach(t),F_r=r(Wje," (SEW model)"),Wje.forEach(t),T_r=i(We),x8=n(We,"LI",{});var Qje=s(x8);EFe=n(Qje,"STRONG",{});var Nkt=s(EFe);M_r=r(Nkt,"sew-d"),Nkt.forEach(t),E_r=r(Qje," \u2014 "),FU=n(Qje,"A",{href:!0});var qkt=s(FU);C_r=r(qkt,"SEWDForSequenceClassification"),qkt.forEach(t),w_r=r(Qje," (SEW-D model)"),Qje.forEach(t),A_r=i(We),$8=n(We,"LI",{});var Hje=s($8);CFe=n(Hje,"STRONG",{});var jkt=s(CFe);L_r=r(jkt,"unispeech"),jkt.forEach(t),y_r=r(Hje," \u2014 "),TU=n(Hje,"A",{href:!0});var Dkt=s(TU);x_r=r(Dkt,"UniSpeechForSequenceClassification"),Dkt.forEach(t),$_r=r(Hje," (UniSpeech model)"),Hje.forEach(t),k_r=i(We),k8=n(We,"LI",{});var Uje=s(k8);wFe=n(Uje,"STRONG",{});var Gkt=s(wFe);S_r=r(Gkt,"unispeech-sat"),Gkt.forEach(t),R_r=r(Uje," \u2014 "),MU=n(Uje,"A",{href:!0});var Okt=s(MU);P_r=r(Okt,"UniSpeechSatForSequenceClassification"),Okt.forEach(t),B_r=r(Uje," (UniSpeechSat model)"),Uje.forEach(t),I_r=i(We),S8=n(We,"LI",{});var Jje=s(S8);AFe=n(Jje,"STRONG",{});var Vkt=s(AFe);N_r=r(Vkt,"wav2vec2"),Vkt.forEach(t),q_r=r(Jje," \u2014 "),EU=n(Jje,"A",{href:!0});var Xkt=s(EU);j_r=r(Xkt,"Wav2Vec2ForSequenceClassification"),Xkt.forEach(t),D_r=r(Jje," (Wav2Vec2 model)"),Jje.forEach(t),G_r=i(We),R8=n(We,"LI",{});var Yje=s(R8);LFe=n(Yje,"STRONG",{});var zkt=s(LFe);O_r=r(zkt,"wav2vec2-conformer"),zkt.forEach(t),V_r=r(Yje," \u2014 "),CU=n(Yje,"A",{href:!0});var Wkt=s(CU);X_r=r(Wkt,"Wav2Vec2ConformerForSequenceClassification"),Wkt.forEach(t),z_r=r(Yje," (Wav2Vec2-Conformer model)"),Yje.forEach(t),W_r=i(We),P8=n(We,"LI",{});var Kje=s(P8);yFe=n(Kje,"STRONG",{});var Qkt=s(yFe);Q_r=r(Qkt,"wavlm"),Qkt.forEach(t),H_r=r(Kje," \u2014 "),wU=n(Kje,"A",{href:!0});var Hkt=s(wU);U_r=r(Hkt,"WavLMForSequenceClassification"),Hkt.forEach(t),J_r=r(Kje," (WavLM model)"),Kje.forEach(t),We.forEach(t),Y_r=i(Aa),B8=n(Aa,"P",{});var Zje=s(B8);K_r=r(Zje,"The model is set in evaluation mode by default using "),xFe=n(Zje,"CODE",{});var Ukt=s(xFe);Z_r=r(Ukt,"model.eval()"),Ukt.forEach(t),eur=r(Zje,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),$Fe=n(Zje,"CODE",{});var Jkt=s($Fe);our=r(Jkt,"model.train()"),Jkt.forEach(t),Zje.forEach(t),rur=i(Aa),T(I8.$$.fragment,Aa),Aa.forEach(t),wl.forEach(t),PQe=i(f),Xd=n(f,"H2",{class:!0});var OUe=s(Xd);N8=n(OUe,"A",{id:!0,class:!0,href:!0});var Ykt=s(N8);kFe=n(Ykt,"SPAN",{});var Kkt=s(kFe);T(W9.$$.fragment,Kkt),Kkt.forEach(t),Ykt.forEach(t),tur=i(OUe),SFe=n(OUe,"SPAN",{});var Zkt=s(SFe);aur=r(Zkt,"AutoModelForAudioFrameClassification"),Zkt.forEach(t),OUe.forEach(t),BQe=i(f),Uo=n(f,"DIV",{class:!0});var Al=s(Uo);T(Q9.$$.fragment,Al),nur=i(Al),zd=n(Al,"P",{});var Dae=s(zd);sur=r(Dae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),AU=n(Dae,"A",{href:!0});var eSt=s(AU);lur=r(eSt,"from_pretrained()"),eSt.forEach(t),iur=r(Dae," class method or the "),LU=n(Dae,"A",{href:!0});var oSt=s(LU);dur=r(oSt,"from_config()"),oSt.forEach(t),cur=r(Dae,` class
method.`),Dae.forEach(t),fur=i(Al),H9=n(Al,"P",{});var VUe=s(H9);mur=r(VUe,"This class cannot be instantiated directly using "),RFe=n(VUe,"CODE",{});var rSt=s(RFe);gur=r(rSt,"__init__()"),rSt.forEach(t),hur=r(VUe," (throws an error)."),VUe.forEach(t),pur=i(Al),Lt=n(Al,"DIV",{class:!0});var L7=s(Lt);T(U9.$$.fragment,L7),_ur=i(L7),PFe=n(L7,"P",{});var tSt=s(PFe);uur=r(tSt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),tSt.forEach(t),bur=i(L7),Wd=n(L7,"P",{});var Gae=s(Wd);vur=r(Gae,`Note:
Loading a model from its configuration file does `),BFe=n(Gae,"STRONG",{});var aSt=s(BFe);Fur=r(aSt,"not"),aSt.forEach(t),Tur=r(Gae,` load the model weights. It only affects the
model\u2019s configuration. Use `),yU=n(Gae,"A",{href:!0});var nSt=s(yU);Mur=r(nSt,"from_pretrained()"),nSt.forEach(t),Eur=r(Gae," to load the model weights."),Gae.forEach(t),Cur=i(L7),T(q8.$$.fragment,L7),L7.forEach(t),wur=i(Al),ho=n(Al,"DIV",{class:!0});var La=s(ho);T(J9.$$.fragment,La),Aur=i(La),IFe=n(La,"P",{});var sSt=s(IFe);Lur=r(sSt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),sSt.forEach(t),yur=i(La),rn=n(La,"P",{});var y7=s(rn);xur=r(y7,"The model class to instantiate is selected based on the "),NFe=n(y7,"CODE",{});var lSt=s(NFe);$ur=r(lSt,"model_type"),lSt.forEach(t),kur=r(y7,` property of the config object (either
passed as an argument or loaded from `),qFe=n(y7,"CODE",{});var iSt=s(qFe);Sur=r(iSt,"pretrained_model_name_or_path"),iSt.forEach(t),Rur=r(y7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),jFe=n(y7,"CODE",{});var dSt=s(jFe);Pur=r(dSt,"pretrained_model_name_or_path"),dSt.forEach(t),Bur=r(y7,":"),y7.forEach(t),Iur=i(La),at=n(La,"UL",{});var Ll=s(at);j8=n(Ll,"LI",{});var eDe=s(j8);DFe=n(eDe,"STRONG",{});var cSt=s(DFe);Nur=r(cSt,"data2vec-audio"),cSt.forEach(t),qur=r(eDe," \u2014 "),xU=n(eDe,"A",{href:!0});var fSt=s(xU);jur=r(fSt,"Data2VecAudioForAudioFrameClassification"),fSt.forEach(t),Dur=r(eDe," (Data2VecAudio model)"),eDe.forEach(t),Gur=i(Ll),D8=n(Ll,"LI",{});var oDe=s(D8);GFe=n(oDe,"STRONG",{});var mSt=s(GFe);Our=r(mSt,"unispeech-sat"),mSt.forEach(t),Vur=r(oDe," \u2014 "),$U=n(oDe,"A",{href:!0});var gSt=s($U);Xur=r(gSt,"UniSpeechSatForAudioFrameClassification"),gSt.forEach(t),zur=r(oDe," (UniSpeechSat model)"),oDe.forEach(t),Wur=i(Ll),G8=n(Ll,"LI",{});var rDe=s(G8);OFe=n(rDe,"STRONG",{});var hSt=s(OFe);Qur=r(hSt,"wav2vec2"),hSt.forEach(t),Hur=r(rDe," \u2014 "),kU=n(rDe,"A",{href:!0});var pSt=s(kU);Uur=r(pSt,"Wav2Vec2ForAudioFrameClassification"),pSt.forEach(t),Jur=r(rDe," (Wav2Vec2 model)"),rDe.forEach(t),Yur=i(Ll),O8=n(Ll,"LI",{});var tDe=s(O8);VFe=n(tDe,"STRONG",{});var _St=s(VFe);Kur=r(_St,"wav2vec2-conformer"),_St.forEach(t),Zur=r(tDe," \u2014 "),SU=n(tDe,"A",{href:!0});var uSt=s(SU);e2r=r(uSt,"Wav2Vec2ConformerForAudioFrameClassification"),uSt.forEach(t),o2r=r(tDe," (Wav2Vec2-Conformer model)"),tDe.forEach(t),r2r=i(Ll),V8=n(Ll,"LI",{});var aDe=s(V8);XFe=n(aDe,"STRONG",{});var bSt=s(XFe);t2r=r(bSt,"wavlm"),bSt.forEach(t),a2r=r(aDe," \u2014 "),RU=n(aDe,"A",{href:!0});var vSt=s(RU);n2r=r(vSt,"WavLMForAudioFrameClassification"),vSt.forEach(t),s2r=r(aDe," (WavLM model)"),aDe.forEach(t),Ll.forEach(t),l2r=i(La),X8=n(La,"P",{});var nDe=s(X8);i2r=r(nDe,"The model is set in evaluation mode by default using "),zFe=n(nDe,"CODE",{});var FSt=s(zFe);d2r=r(FSt,"model.eval()"),FSt.forEach(t),c2r=r(nDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),WFe=n(nDe,"CODE",{});var TSt=s(WFe);f2r=r(TSt,"model.train()"),TSt.forEach(t),nDe.forEach(t),m2r=i(La),T(z8.$$.fragment,La),La.forEach(t),Al.forEach(t),IQe=i(f),Qd=n(f,"H2",{class:!0});var XUe=s(Qd);W8=n(XUe,"A",{id:!0,class:!0,href:!0});var MSt=s(W8);QFe=n(MSt,"SPAN",{});var ESt=s(QFe);T(Y9.$$.fragment,ESt),ESt.forEach(t),MSt.forEach(t),g2r=i(XUe),HFe=n(XUe,"SPAN",{});var CSt=s(HFe);h2r=r(CSt,"AutoModelForCTC"),CSt.forEach(t),XUe.forEach(t),NQe=i(f),Jo=n(f,"DIV",{class:!0});var yl=s(Jo);T(K9.$$.fragment,yl),p2r=i(yl),Hd=n(yl,"P",{});var Oae=s(Hd);_2r=r(Oae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),PU=n(Oae,"A",{href:!0});var wSt=s(PU);u2r=r(wSt,"from_pretrained()"),wSt.forEach(t),b2r=r(Oae," class method or the "),BU=n(Oae,"A",{href:!0});var ASt=s(BU);v2r=r(ASt,"from_config()"),ASt.forEach(t),F2r=r(Oae,` class
method.`),Oae.forEach(t),T2r=i(yl),Z9=n(yl,"P",{});var zUe=s(Z9);M2r=r(zUe,"This class cannot be instantiated directly using "),UFe=n(zUe,"CODE",{});var LSt=s(UFe);E2r=r(LSt,"__init__()"),LSt.forEach(t),C2r=r(zUe," (throws an error)."),zUe.forEach(t),w2r=i(yl),yt=n(yl,"DIV",{class:!0});var x7=s(yt);T(ex.$$.fragment,x7),A2r=i(x7),JFe=n(x7,"P",{});var ySt=s(JFe);L2r=r(ySt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),ySt.forEach(t),y2r=i(x7),Ud=n(x7,"P",{});var Vae=s(Ud);x2r=r(Vae,`Note:
Loading a model from its configuration file does `),YFe=n(Vae,"STRONG",{});var xSt=s(YFe);$2r=r(xSt,"not"),xSt.forEach(t),k2r=r(Vae,` load the model weights. It only affects the
model\u2019s configuration. Use `),IU=n(Vae,"A",{href:!0});var $St=s(IU);S2r=r($St,"from_pretrained()"),$St.forEach(t),R2r=r(Vae," to load the model weights."),Vae.forEach(t),P2r=i(x7),T(Q8.$$.fragment,x7),x7.forEach(t),B2r=i(yl),po=n(yl,"DIV",{class:!0});var ya=s(po);T(ox.$$.fragment,ya),I2r=i(ya),KFe=n(ya,"P",{});var kSt=s(KFe);N2r=r(kSt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),kSt.forEach(t),q2r=i(ya),tn=n(ya,"P",{});var $7=s(tn);j2r=r($7,"The model class to instantiate is selected based on the "),ZFe=n($7,"CODE",{});var SSt=s(ZFe);D2r=r(SSt,"model_type"),SSt.forEach(t),G2r=r($7,` property of the config object (either
passed as an argument or loaded from `),eTe=n($7,"CODE",{});var RSt=s(eTe);O2r=r(RSt,"pretrained_model_name_or_path"),RSt.forEach(t),V2r=r($7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oTe=n($7,"CODE",{});var PSt=s(oTe);X2r=r(PSt,"pretrained_model_name_or_path"),PSt.forEach(t),z2r=r($7,":"),$7.forEach(t),W2r=i(ya),ye=n(ya,"UL",{});var Ie=s(ye);H8=n(Ie,"LI",{});var sDe=s(H8);rTe=n(sDe,"STRONG",{});var BSt=s(rTe);Q2r=r(BSt,"data2vec-audio"),BSt.forEach(t),H2r=r(sDe," \u2014 "),NU=n(sDe,"A",{href:!0});var ISt=s(NU);U2r=r(ISt,"Data2VecAudioForCTC"),ISt.forEach(t),J2r=r(sDe," (Data2VecAudio model)"),sDe.forEach(t),Y2r=i(Ie),U8=n(Ie,"LI",{});var lDe=s(U8);tTe=n(lDe,"STRONG",{});var NSt=s(tTe);K2r=r(NSt,"hubert"),NSt.forEach(t),Z2r=r(lDe," \u2014 "),qU=n(lDe,"A",{href:!0});var qSt=s(qU);e1r=r(qSt,"HubertForCTC"),qSt.forEach(t),o1r=r(lDe," (Hubert model)"),lDe.forEach(t),r1r=i(Ie),J8=n(Ie,"LI",{});var iDe=s(J8);aTe=n(iDe,"STRONG",{});var jSt=s(aTe);t1r=r(jSt,"mctct"),jSt.forEach(t),a1r=r(iDe," \u2014 "),jU=n(iDe,"A",{href:!0});var DSt=s(jU);n1r=r(DSt,"MCTCTForCTC"),DSt.forEach(t),s1r=r(iDe," (M-CTC-T model)"),iDe.forEach(t),l1r=i(Ie),Y8=n(Ie,"LI",{});var dDe=s(Y8);nTe=n(dDe,"STRONG",{});var GSt=s(nTe);i1r=r(GSt,"sew"),GSt.forEach(t),d1r=r(dDe," \u2014 "),DU=n(dDe,"A",{href:!0});var OSt=s(DU);c1r=r(OSt,"SEWForCTC"),OSt.forEach(t),f1r=r(dDe," (SEW model)"),dDe.forEach(t),m1r=i(Ie),K8=n(Ie,"LI",{});var cDe=s(K8);sTe=n(cDe,"STRONG",{});var VSt=s(sTe);g1r=r(VSt,"sew-d"),VSt.forEach(t),h1r=r(cDe," \u2014 "),GU=n(cDe,"A",{href:!0});var XSt=s(GU);p1r=r(XSt,"SEWDForCTC"),XSt.forEach(t),_1r=r(cDe," (SEW-D model)"),cDe.forEach(t),u1r=i(Ie),Z8=n(Ie,"LI",{});var fDe=s(Z8);lTe=n(fDe,"STRONG",{});var zSt=s(lTe);b1r=r(zSt,"unispeech"),zSt.forEach(t),v1r=r(fDe," \u2014 "),OU=n(fDe,"A",{href:!0});var WSt=s(OU);F1r=r(WSt,"UniSpeechForCTC"),WSt.forEach(t),T1r=r(fDe," (UniSpeech model)"),fDe.forEach(t),M1r=i(Ie),eM=n(Ie,"LI",{});var mDe=s(eM);iTe=n(mDe,"STRONG",{});var QSt=s(iTe);E1r=r(QSt,"unispeech-sat"),QSt.forEach(t),C1r=r(mDe," \u2014 "),VU=n(mDe,"A",{href:!0});var HSt=s(VU);w1r=r(HSt,"UniSpeechSatForCTC"),HSt.forEach(t),A1r=r(mDe," (UniSpeechSat model)"),mDe.forEach(t),L1r=i(Ie),oM=n(Ie,"LI",{});var gDe=s(oM);dTe=n(gDe,"STRONG",{});var USt=s(dTe);y1r=r(USt,"wav2vec2"),USt.forEach(t),x1r=r(gDe," \u2014 "),XU=n(gDe,"A",{href:!0});var JSt=s(XU);$1r=r(JSt,"Wav2Vec2ForCTC"),JSt.forEach(t),k1r=r(gDe," (Wav2Vec2 model)"),gDe.forEach(t),S1r=i(Ie),rM=n(Ie,"LI",{});var hDe=s(rM);cTe=n(hDe,"STRONG",{});var YSt=s(cTe);R1r=r(YSt,"wav2vec2-conformer"),YSt.forEach(t),P1r=r(hDe," \u2014 "),zU=n(hDe,"A",{href:!0});var KSt=s(zU);B1r=r(KSt,"Wav2Vec2ConformerForCTC"),KSt.forEach(t),I1r=r(hDe," (Wav2Vec2-Conformer model)"),hDe.forEach(t),N1r=i(Ie),tM=n(Ie,"LI",{});var pDe=s(tM);fTe=n(pDe,"STRONG",{});var ZSt=s(fTe);q1r=r(ZSt,"wavlm"),ZSt.forEach(t),j1r=r(pDe," \u2014 "),WU=n(pDe,"A",{href:!0});var eRt=s(WU);D1r=r(eRt,"WavLMForCTC"),eRt.forEach(t),G1r=r(pDe," (WavLM model)"),pDe.forEach(t),Ie.forEach(t),O1r=i(ya),aM=n(ya,"P",{});var _De=s(aM);V1r=r(_De,"The model is set in evaluation mode by default using "),mTe=n(_De,"CODE",{});var oRt=s(mTe);X1r=r(oRt,"model.eval()"),oRt.forEach(t),z1r=r(_De,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),gTe=n(_De,"CODE",{});var rRt=s(gTe);W1r=r(rRt,"model.train()"),rRt.forEach(t),_De.forEach(t),Q1r=i(ya),T(nM.$$.fragment,ya),ya.forEach(t),yl.forEach(t),qQe=i(f),Jd=n(f,"H2",{class:!0});var WUe=s(Jd);sM=n(WUe,"A",{id:!0,class:!0,href:!0});var tRt=s(sM);hTe=n(tRt,"SPAN",{});var aRt=s(hTe);T(rx.$$.fragment,aRt),aRt.forEach(t),tRt.forEach(t),H1r=i(WUe),pTe=n(WUe,"SPAN",{});var nRt=s(pTe);U1r=r(nRt,"AutoModelForSpeechSeq2Seq"),nRt.forEach(t),WUe.forEach(t),jQe=i(f),Yo=n(f,"DIV",{class:!0});var xl=s(Yo);T(tx.$$.fragment,xl),J1r=i(xl),Yd=n(xl,"P",{});var Xae=s(Yd);Y1r=r(Xae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),QU=n(Xae,"A",{href:!0});var sRt=s(QU);K1r=r(sRt,"from_pretrained()"),sRt.forEach(t),Z1r=r(Xae," class method or the "),HU=n(Xae,"A",{href:!0});var lRt=s(HU);ebr=r(lRt,"from_config()"),lRt.forEach(t),obr=r(Xae,` class
method.`),Xae.forEach(t),rbr=i(xl),ax=n(xl,"P",{});var QUe=s(ax);tbr=r(QUe,"This class cannot be instantiated directly using "),_Te=n(QUe,"CODE",{});var iRt=s(_Te);abr=r(iRt,"__init__()"),iRt.forEach(t),nbr=r(QUe," (throws an error)."),QUe.forEach(t),sbr=i(xl),xt=n(xl,"DIV",{class:!0});var k7=s(xt);T(nx.$$.fragment,k7),lbr=i(k7),uTe=n(k7,"P",{});var dRt=s(uTe);ibr=r(dRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dRt.forEach(t),dbr=i(k7),Kd=n(k7,"P",{});var zae=s(Kd);cbr=r(zae,`Note:
Loading a model from its configuration file does `),bTe=n(zae,"STRONG",{});var cRt=s(bTe);fbr=r(cRt,"not"),cRt.forEach(t),mbr=r(zae,` load the model weights. It only affects the
model\u2019s configuration. Use `),UU=n(zae,"A",{href:!0});var fRt=s(UU);gbr=r(fRt,"from_pretrained()"),fRt.forEach(t),hbr=r(zae," to load the model weights."),zae.forEach(t),pbr=i(k7),T(lM.$$.fragment,k7),k7.forEach(t),_br=i(xl),_o=n(xl,"DIV",{class:!0});var xa=s(_o);T(sx.$$.fragment,xa),ubr=i(xa),vTe=n(xa,"P",{});var mRt=s(vTe);bbr=r(mRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),mRt.forEach(t),vbr=i(xa),an=n(xa,"P",{});var S7=s(an);Fbr=r(S7,"The model class to instantiate is selected based on the "),FTe=n(S7,"CODE",{});var gRt=s(FTe);Tbr=r(gRt,"model_type"),gRt.forEach(t),Mbr=r(S7,` property of the config object (either
passed as an argument or loaded from `),TTe=n(S7,"CODE",{});var hRt=s(TTe);Ebr=r(hRt,"pretrained_model_name_or_path"),hRt.forEach(t),Cbr=r(S7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),MTe=n(S7,"CODE",{});var pRt=s(MTe);wbr=r(pRt,"pretrained_model_name_or_path"),pRt.forEach(t),Abr=r(S7,":"),S7.forEach(t),Lbr=i(xa),lx=n(xa,"UL",{});var HUe=s(lx);iM=n(HUe,"LI",{});var uDe=s(iM);ETe=n(uDe,"STRONG",{});var _Rt=s(ETe);ybr=r(_Rt,"speech-encoder-decoder"),_Rt.forEach(t),xbr=r(uDe," \u2014 "),JU=n(uDe,"A",{href:!0});var uRt=s(JU);$br=r(uRt,"SpeechEncoderDecoderModel"),uRt.forEach(t),kbr=r(uDe," (Speech Encoder decoder model)"),uDe.forEach(t),Sbr=i(HUe),dM=n(HUe,"LI",{});var bDe=s(dM);CTe=n(bDe,"STRONG",{});var bRt=s(CTe);Rbr=r(bRt,"speech_to_text"),bRt.forEach(t),Pbr=r(bDe," \u2014 "),YU=n(bDe,"A",{href:!0});var vRt=s(YU);Bbr=r(vRt,"Speech2TextForConditionalGeneration"),vRt.forEach(t),Ibr=r(bDe," (Speech2Text model)"),bDe.forEach(t),HUe.forEach(t),Nbr=i(xa),cM=n(xa,"P",{});var vDe=s(cM);qbr=r(vDe,"The model is set in evaluation mode by default using "),wTe=n(vDe,"CODE",{});var FRt=s(wTe);jbr=r(FRt,"model.eval()"),FRt.forEach(t),Dbr=r(vDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ATe=n(vDe,"CODE",{});var TRt=s(ATe);Gbr=r(TRt,"model.train()"),TRt.forEach(t),vDe.forEach(t),Obr=i(xa),T(fM.$$.fragment,xa),xa.forEach(t),xl.forEach(t),DQe=i(f),Zd=n(f,"H2",{class:!0});var UUe=s(Zd);mM=n(UUe,"A",{id:!0,class:!0,href:!0});var MRt=s(mM);LTe=n(MRt,"SPAN",{});var ERt=s(LTe);T(ix.$$.fragment,ERt),ERt.forEach(t),MRt.forEach(t),Vbr=i(UUe),yTe=n(UUe,"SPAN",{});var CRt=s(yTe);Xbr=r(CRt,"AutoModelForAudioXVector"),CRt.forEach(t),UUe.forEach(t),GQe=i(f),Ko=n(f,"DIV",{class:!0});var $l=s(Ko);T(dx.$$.fragment,$l),zbr=i($l),ec=n($l,"P",{});var Wae=s(ec);Wbr=r(Wae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),KU=n(Wae,"A",{href:!0});var wRt=s(KU);Qbr=r(wRt,"from_pretrained()"),wRt.forEach(t),Hbr=r(Wae," class method or the "),ZU=n(Wae,"A",{href:!0});var ARt=s(ZU);Ubr=r(ARt,"from_config()"),ARt.forEach(t),Jbr=r(Wae,` class
method.`),Wae.forEach(t),Ybr=i($l),cx=n($l,"P",{});var JUe=s(cx);Kbr=r(JUe,"This class cannot be instantiated directly using "),xTe=n(JUe,"CODE",{});var LRt=s(xTe);Zbr=r(LRt,"__init__()"),LRt.forEach(t),evr=r(JUe," (throws an error)."),JUe.forEach(t),ovr=i($l),$t=n($l,"DIV",{class:!0});var R7=s($t);T(fx.$$.fragment,R7),rvr=i(R7),$Te=n(R7,"P",{});var yRt=s($Te);tvr=r(yRt,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),yRt.forEach(t),avr=i(R7),oc=n(R7,"P",{});var Qae=s(oc);nvr=r(Qae,`Note:
Loading a model from its configuration file does `),kTe=n(Qae,"STRONG",{});var xRt=s(kTe);svr=r(xRt,"not"),xRt.forEach(t),lvr=r(Qae,` load the model weights. It only affects the
model\u2019s configuration. Use `),eJ=n(Qae,"A",{href:!0});var $Rt=s(eJ);ivr=r($Rt,"from_pretrained()"),$Rt.forEach(t),dvr=r(Qae," to load the model weights."),Qae.forEach(t),cvr=i(R7),T(gM.$$.fragment,R7),R7.forEach(t),fvr=i($l),uo=n($l,"DIV",{class:!0});var $a=s(uo);T(mx.$$.fragment,$a),mvr=i($a),STe=n($a,"P",{});var kRt=s(STe);gvr=r(kRt,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),kRt.forEach(t),hvr=i($a),nn=n($a,"P",{});var P7=s(nn);pvr=r(P7,"The model class to instantiate is selected based on the "),RTe=n(P7,"CODE",{});var SRt=s(RTe);_vr=r(SRt,"model_type"),SRt.forEach(t),uvr=r(P7,` property of the config object (either
passed as an argument or loaded from `),PTe=n(P7,"CODE",{});var RRt=s(PTe);bvr=r(RRt,"pretrained_model_name_or_path"),RRt.forEach(t),vvr=r(P7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),BTe=n(P7,"CODE",{});var PRt=s(BTe);Fvr=r(PRt,"pretrained_model_name_or_path"),PRt.forEach(t),Tvr=r(P7,":"),P7.forEach(t),Mvr=i($a),nt=n($a,"UL",{});var kl=s(nt);hM=n(kl,"LI",{});var FDe=s(hM);ITe=n(FDe,"STRONG",{});var BRt=s(ITe);Evr=r(BRt,"data2vec-audio"),BRt.forEach(t),Cvr=r(FDe," \u2014 "),oJ=n(FDe,"A",{href:!0});var IRt=s(oJ);wvr=r(IRt,"Data2VecAudioForXVector"),IRt.forEach(t),Avr=r(FDe," (Data2VecAudio model)"),FDe.forEach(t),Lvr=i(kl),pM=n(kl,"LI",{});var TDe=s(pM);NTe=n(TDe,"STRONG",{});var NRt=s(NTe);yvr=r(NRt,"unispeech-sat"),NRt.forEach(t),xvr=r(TDe," \u2014 "),rJ=n(TDe,"A",{href:!0});var qRt=s(rJ);$vr=r(qRt,"UniSpeechSatForXVector"),qRt.forEach(t),kvr=r(TDe," (UniSpeechSat model)"),TDe.forEach(t),Svr=i(kl),_M=n(kl,"LI",{});var MDe=s(_M);qTe=n(MDe,"STRONG",{});var jRt=s(qTe);Rvr=r(jRt,"wav2vec2"),jRt.forEach(t),Pvr=r(MDe," \u2014 "),tJ=n(MDe,"A",{href:!0});var DRt=s(tJ);Bvr=r(DRt,"Wav2Vec2ForXVector"),DRt.forEach(t),Ivr=r(MDe," (Wav2Vec2 model)"),MDe.forEach(t),Nvr=i(kl),uM=n(kl,"LI",{});var EDe=s(uM);jTe=n(EDe,"STRONG",{});var GRt=s(jTe);qvr=r(GRt,"wav2vec2-conformer"),GRt.forEach(t),jvr=r(EDe," \u2014 "),aJ=n(EDe,"A",{href:!0});var ORt=s(aJ);Dvr=r(ORt,"Wav2Vec2ConformerForXVector"),ORt.forEach(t),Gvr=r(EDe," (Wav2Vec2-Conformer model)"),EDe.forEach(t),Ovr=i(kl),bM=n(kl,"LI",{});var CDe=s(bM);DTe=n(CDe,"STRONG",{});var VRt=s(DTe);Vvr=r(VRt,"wavlm"),VRt.forEach(t),Xvr=r(CDe," \u2014 "),nJ=n(CDe,"A",{href:!0});var XRt=s(nJ);zvr=r(XRt,"WavLMForXVector"),XRt.forEach(t),Wvr=r(CDe," (WavLM model)"),CDe.forEach(t),kl.forEach(t),Qvr=i($a),vM=n($a,"P",{});var wDe=s(vM);Hvr=r(wDe,"The model is set in evaluation mode by default using "),GTe=n(wDe,"CODE",{});var zRt=s(GTe);Uvr=r(zRt,"model.eval()"),zRt.forEach(t),Jvr=r(wDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),OTe=n(wDe,"CODE",{});var WRt=s(OTe);Yvr=r(WRt,"model.train()"),WRt.forEach(t),wDe.forEach(t),Kvr=i($a),T(FM.$$.fragment,$a),$a.forEach(t),$l.forEach(t),OQe=i(f),rc=n(f,"H2",{class:!0});var YUe=s(rc);TM=n(YUe,"A",{id:!0,class:!0,href:!0});var QRt=s(TM);VTe=n(QRt,"SPAN",{});var HRt=s(VTe);T(gx.$$.fragment,HRt),HRt.forEach(t),QRt.forEach(t),Zvr=i(YUe),XTe=n(YUe,"SPAN",{});var URt=s(XTe);e0r=r(URt,"AutoModelForMaskedImageModeling"),URt.forEach(t),YUe.forEach(t),VQe=i(f),Zo=n(f,"DIV",{class:!0});var Sl=s(Zo);T(hx.$$.fragment,Sl),o0r=i(Sl),tc=n(Sl,"P",{});var Hae=s(tc);r0r=r(Hae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),sJ=n(Hae,"A",{href:!0});var JRt=s(sJ);t0r=r(JRt,"from_pretrained()"),JRt.forEach(t),a0r=r(Hae," class method or the "),lJ=n(Hae,"A",{href:!0});var YRt=s(lJ);n0r=r(YRt,"from_config()"),YRt.forEach(t),s0r=r(Hae,` class
method.`),Hae.forEach(t),l0r=i(Sl),px=n(Sl,"P",{});var KUe=s(px);i0r=r(KUe,"This class cannot be instantiated directly using "),zTe=n(KUe,"CODE",{});var KRt=s(zTe);d0r=r(KRt,"__init__()"),KRt.forEach(t),c0r=r(KUe," (throws an error)."),KUe.forEach(t),f0r=i(Sl),kt=n(Sl,"DIV",{class:!0});var B7=s(kt);T(_x.$$.fragment,B7),m0r=i(B7),WTe=n(B7,"P",{});var ZRt=s(WTe);g0r=r(ZRt,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),ZRt.forEach(t),h0r=i(B7),ac=n(B7,"P",{});var Uae=s(ac);p0r=r(Uae,`Note:
Loading a model from its configuration file does `),QTe=n(Uae,"STRONG",{});var ePt=s(QTe);_0r=r(ePt,"not"),ePt.forEach(t),u0r=r(Uae,` load the model weights. It only affects the
model\u2019s configuration. Use `),iJ=n(Uae,"A",{href:!0});var oPt=s(iJ);b0r=r(oPt,"from_pretrained()"),oPt.forEach(t),v0r=r(Uae," to load the model weights."),Uae.forEach(t),F0r=i(B7),T(MM.$$.fragment,B7),B7.forEach(t),T0r=i(Sl),bo=n(Sl,"DIV",{class:!0});var ka=s(bo);T(ux.$$.fragment,ka),M0r=i(ka),HTe=n(ka,"P",{});var rPt=s(HTe);E0r=r(rPt,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),rPt.forEach(t),C0r=i(ka),sn=n(ka,"P",{});var I7=s(sn);w0r=r(I7,"The model class to instantiate is selected based on the "),UTe=n(I7,"CODE",{});var tPt=s(UTe);A0r=r(tPt,"model_type"),tPt.forEach(t),L0r=r(I7,` property of the config object (either
passed as an argument or loaded from `),JTe=n(I7,"CODE",{});var aPt=s(JTe);y0r=r(aPt,"pretrained_model_name_or_path"),aPt.forEach(t),x0r=r(I7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YTe=n(I7,"CODE",{});var nPt=s(YTe);$0r=r(nPt,"pretrained_model_name_or_path"),nPt.forEach(t),k0r=r(I7,":"),I7.forEach(t),S0r=i(ka),ln=n(ka,"UL",{});var N7=s(ln);EM=n(N7,"LI",{});var ADe=s(EM);KTe=n(ADe,"STRONG",{});var sPt=s(KTe);R0r=r(sPt,"deit"),sPt.forEach(t),P0r=r(ADe," \u2014 "),dJ=n(ADe,"A",{href:!0});var lPt=s(dJ);B0r=r(lPt,"DeiTForMaskedImageModeling"),lPt.forEach(t),I0r=r(ADe," (DeiT model)"),ADe.forEach(t),N0r=i(N7),CM=n(N7,"LI",{});var LDe=s(CM);ZTe=n(LDe,"STRONG",{});var iPt=s(ZTe);q0r=r(iPt,"swin"),iPt.forEach(t),j0r=r(LDe," \u2014 "),cJ=n(LDe,"A",{href:!0});var dPt=s(cJ);D0r=r(dPt,"SwinForMaskedImageModeling"),dPt.forEach(t),G0r=r(LDe," (Swin Transformer model)"),LDe.forEach(t),O0r=i(N7),wM=n(N7,"LI",{});var yDe=s(wM);e8e=n(yDe,"STRONG",{});var cPt=s(e8e);V0r=r(cPt,"swinv2"),cPt.forEach(t),X0r=r(yDe," \u2014 "),fJ=n(yDe,"A",{href:!0});var fPt=s(fJ);z0r=r(fPt,"Swinv2ForMaskedImageModeling"),fPt.forEach(t),W0r=r(yDe," (Swin Transformer V2 model)"),yDe.forEach(t),Q0r=i(N7),AM=n(N7,"LI",{});var xDe=s(AM);o8e=n(xDe,"STRONG",{});var mPt=s(o8e);H0r=r(mPt,"vit"),mPt.forEach(t),U0r=r(xDe," \u2014 "),mJ=n(xDe,"A",{href:!0});var gPt=s(mJ);J0r=r(gPt,"ViTForMaskedImageModeling"),gPt.forEach(t),Y0r=r(xDe," (ViT model)"),xDe.forEach(t),N7.forEach(t),K0r=i(ka),LM=n(ka,"P",{});var $De=s(LM);Z0r=r($De,"The model is set in evaluation mode by default using "),r8e=n($De,"CODE",{});var hPt=s(r8e);eFr=r(hPt,"model.eval()"),hPt.forEach(t),oFr=r($De,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),t8e=n($De,"CODE",{});var pPt=s(t8e);rFr=r(pPt,"model.train()"),pPt.forEach(t),$De.forEach(t),tFr=i(ka),T(yM.$$.fragment,ka),ka.forEach(t),Sl.forEach(t),XQe=i(f),nc=n(f,"H2",{class:!0});var ZUe=s(nc);xM=n(ZUe,"A",{id:!0,class:!0,href:!0});var _Pt=s(xM);a8e=n(_Pt,"SPAN",{});var uPt=s(a8e);T(bx.$$.fragment,uPt),uPt.forEach(t),_Pt.forEach(t),aFr=i(ZUe),n8e=n(ZUe,"SPAN",{});var bPt=s(n8e);nFr=r(bPt,"AutoModelForObjectDetection"),bPt.forEach(t),ZUe.forEach(t),zQe=i(f),er=n(f,"DIV",{class:!0});var Rl=s(er);T(vx.$$.fragment,Rl),sFr=i(Rl),sc=n(Rl,"P",{});var Jae=s(sc);lFr=r(Jae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),gJ=n(Jae,"A",{href:!0});var vPt=s(gJ);iFr=r(vPt,"from_pretrained()"),vPt.forEach(t),dFr=r(Jae," class method or the "),hJ=n(Jae,"A",{href:!0});var FPt=s(hJ);cFr=r(FPt,"from_config()"),FPt.forEach(t),fFr=r(Jae,` class
method.`),Jae.forEach(t),mFr=i(Rl),Fx=n(Rl,"P",{});var eJe=s(Fx);gFr=r(eJe,"This class cannot be instantiated directly using "),s8e=n(eJe,"CODE",{});var TPt=s(s8e);hFr=r(TPt,"__init__()"),TPt.forEach(t),pFr=r(eJe," (throws an error)."),eJe.forEach(t),_Fr=i(Rl),St=n(Rl,"DIV",{class:!0});var q7=s(St);T(Tx.$$.fragment,q7),uFr=i(q7),l8e=n(q7,"P",{});var MPt=s(l8e);bFr=r(MPt,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),MPt.forEach(t),vFr=i(q7),lc=n(q7,"P",{});var Yae=s(lc);FFr=r(Yae,`Note:
Loading a model from its configuration file does `),i8e=n(Yae,"STRONG",{});var EPt=s(i8e);TFr=r(EPt,"not"),EPt.forEach(t),MFr=r(Yae,` load the model weights. It only affects the
model\u2019s configuration. Use `),pJ=n(Yae,"A",{href:!0});var CPt=s(pJ);EFr=r(CPt,"from_pretrained()"),CPt.forEach(t),CFr=r(Yae," to load the model weights."),Yae.forEach(t),wFr=i(q7),T($M.$$.fragment,q7),q7.forEach(t),AFr=i(Rl),vo=n(Rl,"DIV",{class:!0});var Sa=s(vo);T(Mx.$$.fragment,Sa),LFr=i(Sa),d8e=n(Sa,"P",{});var wPt=s(d8e);yFr=r(wPt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),wPt.forEach(t),xFr=i(Sa),dn=n(Sa,"P",{});var j7=s(dn);$Fr=r(j7,"The model class to instantiate is selected based on the "),c8e=n(j7,"CODE",{});var APt=s(c8e);kFr=r(APt,"model_type"),APt.forEach(t),SFr=r(j7,` property of the config object (either
passed as an argument or loaded from `),f8e=n(j7,"CODE",{});var LPt=s(f8e);RFr=r(LPt,"pretrained_model_name_or_path"),LPt.forEach(t),PFr=r(j7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),m8e=n(j7,"CODE",{});var yPt=s(m8e);BFr=r(yPt,"pretrained_model_name_or_path"),yPt.forEach(t),IFr=r(j7,":"),j7.forEach(t),NFr=i(Sa),Ex=n(Sa,"UL",{});var oJe=s(Ex);kM=n(oJe,"LI",{});var kDe=s(kM);g8e=n(kDe,"STRONG",{});var xPt=s(g8e);qFr=r(xPt,"detr"),xPt.forEach(t),jFr=r(kDe," \u2014 "),_J=n(kDe,"A",{href:!0});var $Pt=s(_J);DFr=r($Pt,"DetrForObjectDetection"),$Pt.forEach(t),GFr=r(kDe," (DETR model)"),kDe.forEach(t),OFr=i(oJe),SM=n(oJe,"LI",{});var SDe=s(SM);h8e=n(SDe,"STRONG",{});var kPt=s(h8e);VFr=r(kPt,"yolos"),kPt.forEach(t),XFr=r(SDe," \u2014 "),uJ=n(SDe,"A",{href:!0});var SPt=s(uJ);zFr=r(SPt,"YolosForObjectDetection"),SPt.forEach(t),WFr=r(SDe," (YOLOS model)"),SDe.forEach(t),oJe.forEach(t),QFr=i(Sa),RM=n(Sa,"P",{});var RDe=s(RM);HFr=r(RDe,"The model is set in evaluation mode by default using "),p8e=n(RDe,"CODE",{});var RPt=s(p8e);UFr=r(RPt,"model.eval()"),RPt.forEach(t),JFr=r(RDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),_8e=n(RDe,"CODE",{});var PPt=s(_8e);YFr=r(PPt,"model.train()"),PPt.forEach(t),RDe.forEach(t),KFr=i(Sa),T(PM.$$.fragment,Sa),Sa.forEach(t),Rl.forEach(t),WQe=i(f),ic=n(f,"H2",{class:!0});var rJe=s(ic);BM=n(rJe,"A",{id:!0,class:!0,href:!0});var BPt=s(BM);u8e=n(BPt,"SPAN",{});var IPt=s(u8e);T(Cx.$$.fragment,IPt),IPt.forEach(t),BPt.forEach(t),ZFr=i(rJe),b8e=n(rJe,"SPAN",{});var NPt=s(b8e);eTr=r(NPt,"AutoModelForImageSegmentation"),NPt.forEach(t),rJe.forEach(t),QQe=i(f),or=n(f,"DIV",{class:!0});var Pl=s(or);T(wx.$$.fragment,Pl),oTr=i(Pl),dc=n(Pl,"P",{});var Kae=s(dc);rTr=r(Kae,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),bJ=n(Kae,"A",{href:!0});var qPt=s(bJ);tTr=r(qPt,"from_pretrained()"),qPt.forEach(t),aTr=r(Kae," class method or the "),vJ=n(Kae,"A",{href:!0});var jPt=s(vJ);nTr=r(jPt,"from_config()"),jPt.forEach(t),sTr=r(Kae,` class
method.`),Kae.forEach(t),lTr=i(Pl),Ax=n(Pl,"P",{});var tJe=s(Ax);iTr=r(tJe,"This class cannot be instantiated directly using "),v8e=n(tJe,"CODE",{});var DPt=s(v8e);dTr=r(DPt,"__init__()"),DPt.forEach(t),cTr=r(tJe," (throws an error)."),tJe.forEach(t),fTr=i(Pl),Rt=n(Pl,"DIV",{class:!0});var D7=s(Rt);T(Lx.$$.fragment,D7),mTr=i(D7),F8e=n(D7,"P",{});var GPt=s(F8e);gTr=r(GPt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),GPt.forEach(t),hTr=i(D7),cc=n(D7,"P",{});var Zae=s(cc);pTr=r(Zae,`Note:
Loading a model from its configuration file does `),T8e=n(Zae,"STRONG",{});var OPt=s(T8e);_Tr=r(OPt,"not"),OPt.forEach(t),uTr=r(Zae,` load the model weights. It only affects the
model\u2019s configuration. Use `),FJ=n(Zae,"A",{href:!0});var VPt=s(FJ);bTr=r(VPt,"from_pretrained()"),VPt.forEach(t),vTr=r(Zae," to load the model weights."),Zae.forEach(t),FTr=i(D7),T(IM.$$.fragment,D7),D7.forEach(t),TTr=i(Pl),Fo=n(Pl,"DIV",{class:!0});var Ra=s(Fo);T(yx.$$.fragment,Ra),MTr=i(Ra),M8e=n(Ra,"P",{});var XPt=s(M8e);ETr=r(XPt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),XPt.forEach(t),CTr=i(Ra),cn=n(Ra,"P",{});var G7=s(cn);wTr=r(G7,"The model class to instantiate is selected based on the "),E8e=n(G7,"CODE",{});var zPt=s(E8e);ATr=r(zPt,"model_type"),zPt.forEach(t),LTr=r(G7,` property of the config object (either
passed as an argument or loaded from `),C8e=n(G7,"CODE",{});var WPt=s(C8e);yTr=r(WPt,"pretrained_model_name_or_path"),WPt.forEach(t),xTr=r(G7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w8e=n(G7,"CODE",{});var QPt=s(w8e);$Tr=r(QPt,"pretrained_model_name_or_path"),QPt.forEach(t),kTr=r(G7,":"),G7.forEach(t),STr=i(Ra),A8e=n(Ra,"UL",{});var HPt=s(A8e);NM=n(HPt,"LI",{});var PDe=s(NM);L8e=n(PDe,"STRONG",{});var UPt=s(L8e);RTr=r(UPt,"detr"),UPt.forEach(t),PTr=r(PDe," \u2014 "),TJ=n(PDe,"A",{href:!0});var JPt=s(TJ);BTr=r(JPt,"DetrForSegmentation"),JPt.forEach(t),ITr=r(PDe," (DETR model)"),PDe.forEach(t),HPt.forEach(t),NTr=i(Ra),qM=n(Ra,"P",{});var BDe=s(qM);qTr=r(BDe,"The model is set in evaluation mode by default using "),y8e=n(BDe,"CODE",{});var YPt=s(y8e);jTr=r(YPt,"model.eval()"),YPt.forEach(t),DTr=r(BDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),x8e=n(BDe,"CODE",{});var KPt=s(x8e);GTr=r(KPt,"model.train()"),KPt.forEach(t),BDe.forEach(t),OTr=i(Ra),T(jM.$$.fragment,Ra),Ra.forEach(t),Pl.forEach(t),HQe=i(f),fc=n(f,"H2",{class:!0});var aJe=s(fc);DM=n(aJe,"A",{id:!0,class:!0,href:!0});var ZPt=s(DM);$8e=n(ZPt,"SPAN",{});var eBt=s($8e);T(xx.$$.fragment,eBt),eBt.forEach(t),ZPt.forEach(t),VTr=i(aJe),k8e=n(aJe,"SPAN",{});var oBt=s(k8e);XTr=r(oBt,"AutoModelForSemanticSegmentation"),oBt.forEach(t),aJe.forEach(t),UQe=i(f),rr=n(f,"DIV",{class:!0});var Bl=s(rr);T($x.$$.fragment,Bl),zTr=i(Bl),mc=n(Bl,"P",{});var ene=s(mc);WTr=r(ene,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),MJ=n(ene,"A",{href:!0});var rBt=s(MJ);QTr=r(rBt,"from_pretrained()"),rBt.forEach(t),HTr=r(ene," class method or the "),EJ=n(ene,"A",{href:!0});var tBt=s(EJ);UTr=r(tBt,"from_config()"),tBt.forEach(t),JTr=r(ene,` class
method.`),ene.forEach(t),YTr=i(Bl),kx=n(Bl,"P",{});var nJe=s(kx);KTr=r(nJe,"This class cannot be instantiated directly using "),S8e=n(nJe,"CODE",{});var aBt=s(S8e);ZTr=r(aBt,"__init__()"),aBt.forEach(t),e8r=r(nJe," (throws an error)."),nJe.forEach(t),o8r=i(Bl),Pt=n(Bl,"DIV",{class:!0});var O7=s(Pt);T(Sx.$$.fragment,O7),r8r=i(O7),R8e=n(O7,"P",{});var nBt=s(R8e);t8r=r(nBt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),nBt.forEach(t),a8r=i(O7),gc=n(O7,"P",{});var one=s(gc);n8r=r(one,`Note:
Loading a model from its configuration file does `),P8e=n(one,"STRONG",{});var sBt=s(P8e);s8r=r(sBt,"not"),sBt.forEach(t),l8r=r(one,` load the model weights. It only affects the
model\u2019s configuration. Use `),CJ=n(one,"A",{href:!0});var lBt=s(CJ);i8r=r(lBt,"from_pretrained()"),lBt.forEach(t),d8r=r(one," to load the model weights."),one.forEach(t),c8r=i(O7),T(GM.$$.fragment,O7),O7.forEach(t),f8r=i(Bl),To=n(Bl,"DIV",{class:!0});var Pa=s(To);T(Rx.$$.fragment,Pa),m8r=i(Pa),B8e=n(Pa,"P",{});var iBt=s(B8e);g8r=r(iBt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),iBt.forEach(t),h8r=i(Pa),fn=n(Pa,"P",{});var V7=s(fn);p8r=r(V7,"The model class to instantiate is selected based on the "),I8e=n(V7,"CODE",{});var dBt=s(I8e);_8r=r(dBt,"model_type"),dBt.forEach(t),u8r=r(V7,` property of the config object (either
passed as an argument or loaded from `),N8e=n(V7,"CODE",{});var cBt=s(N8e);b8r=r(cBt,"pretrained_model_name_or_path"),cBt.forEach(t),v8r=r(V7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),q8e=n(V7,"CODE",{});var fBt=s(q8e);F8r=r(fBt,"pretrained_model_name_or_path"),fBt.forEach(t),T8r=r(V7,":"),V7.forEach(t),M8r=i(Pa),st=n(Pa,"UL",{});var Il=s(st);OM=n(Il,"LI",{});var IDe=s(OM);j8e=n(IDe,"STRONG",{});var mBt=s(j8e);E8r=r(mBt,"beit"),mBt.forEach(t),C8r=r(IDe," \u2014 "),wJ=n(IDe,"A",{href:!0});var gBt=s(wJ);w8r=r(gBt,"BeitForSemanticSegmentation"),gBt.forEach(t),A8r=r(IDe," (BEiT model)"),IDe.forEach(t),L8r=i(Il),VM=n(Il,"LI",{});var NDe=s(VM);D8e=n(NDe,"STRONG",{});var hBt=s(D8e);y8r=r(hBt,"data2vec-vision"),hBt.forEach(t),x8r=r(NDe," \u2014 "),AJ=n(NDe,"A",{href:!0});var pBt=s(AJ);$8r=r(pBt,"Data2VecVisionForSemanticSegmentation"),pBt.forEach(t),k8r=r(NDe," (Data2VecVision model)"),NDe.forEach(t),S8r=i(Il),XM=n(Il,"LI",{});var qDe=s(XM);G8e=n(qDe,"STRONG",{});var _Bt=s(G8e);R8r=r(_Bt,"dpt"),_Bt.forEach(t),P8r=r(qDe," \u2014 "),LJ=n(qDe,"A",{href:!0});var uBt=s(LJ);B8r=r(uBt,"DPTForSemanticSegmentation"),uBt.forEach(t),I8r=r(qDe," (DPT model)"),qDe.forEach(t),N8r=i(Il),zM=n(Il,"LI",{});var jDe=s(zM);O8e=n(jDe,"STRONG",{});var bBt=s(O8e);q8r=r(bBt,"mobilevit"),bBt.forEach(t),j8r=r(jDe," \u2014 "),yJ=n(jDe,"A",{href:!0});var vBt=s(yJ);D8r=r(vBt,"MobileViTForSemanticSegmentation"),vBt.forEach(t),G8r=r(jDe," (MobileViT model)"),jDe.forEach(t),O8r=i(Il),WM=n(Il,"LI",{});var DDe=s(WM);V8e=n(DDe,"STRONG",{});var FBt=s(V8e);V8r=r(FBt,"segformer"),FBt.forEach(t),X8r=r(DDe," \u2014 "),xJ=n(DDe,"A",{href:!0});var TBt=s(xJ);z8r=r(TBt,"SegformerForSemanticSegmentation"),TBt.forEach(t),W8r=r(DDe," (SegFormer model)"),DDe.forEach(t),Il.forEach(t),Q8r=i(Pa),QM=n(Pa,"P",{});var GDe=s(QM);H8r=r(GDe,"The model is set in evaluation mode by default using "),X8e=n(GDe,"CODE",{});var MBt=s(X8e);U8r=r(MBt,"model.eval()"),MBt.forEach(t),J8r=r(GDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),z8e=n(GDe,"CODE",{});var EBt=s(z8e);Y8r=r(EBt,"model.train()"),EBt.forEach(t),GDe.forEach(t),K8r=i(Pa),T(HM.$$.fragment,Pa),Pa.forEach(t),Bl.forEach(t),JQe=i(f),hc=n(f,"H2",{class:!0});var sJe=s(hc);UM=n(sJe,"A",{id:!0,class:!0,href:!0});var CBt=s(UM);W8e=n(CBt,"SPAN",{});var wBt=s(W8e);T(Px.$$.fragment,wBt),wBt.forEach(t),CBt.forEach(t),Z8r=i(sJe),Q8e=n(sJe,"SPAN",{});var ABt=s(Q8e);eMr=r(ABt,"AutoModelForInstanceSegmentation"),ABt.forEach(t),sJe.forEach(t),YQe=i(f),tr=n(f,"DIV",{class:!0});var Nl=s(tr);T(Bx.$$.fragment,Nl),oMr=i(Nl),pc=n(Nl,"P",{});var rne=s(pc);rMr=r(rne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),$J=n(rne,"A",{href:!0});var LBt=s($J);tMr=r(LBt,"from_pretrained()"),LBt.forEach(t),aMr=r(rne," class method or the "),kJ=n(rne,"A",{href:!0});var yBt=s(kJ);nMr=r(yBt,"from_config()"),yBt.forEach(t),sMr=r(rne,` class
method.`),rne.forEach(t),lMr=i(Nl),Ix=n(Nl,"P",{});var lJe=s(Ix);iMr=r(lJe,"This class cannot be instantiated directly using "),H8e=n(lJe,"CODE",{});var xBt=s(H8e);dMr=r(xBt,"__init__()"),xBt.forEach(t),cMr=r(lJe," (throws an error)."),lJe.forEach(t),fMr=i(Nl),Bt=n(Nl,"DIV",{class:!0});var X7=s(Bt);T(Nx.$$.fragment,X7),mMr=i(X7),U8e=n(X7,"P",{});var $Bt=s(U8e);gMr=r($Bt,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),$Bt.forEach(t),hMr=i(X7),_c=n(X7,"P",{});var tne=s(_c);pMr=r(tne,`Note:
Loading a model from its configuration file does `),J8e=n(tne,"STRONG",{});var kBt=s(J8e);_Mr=r(kBt,"not"),kBt.forEach(t),uMr=r(tne,` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=n(tne,"A",{href:!0});var SBt=s(SJ);bMr=r(SBt,"from_pretrained()"),SBt.forEach(t),vMr=r(tne," to load the model weights."),tne.forEach(t),FMr=i(X7),T(JM.$$.fragment,X7),X7.forEach(t),TMr=i(Nl),Mo=n(Nl,"DIV",{class:!0});var Ba=s(Mo);T(qx.$$.fragment,Ba),MMr=i(Ba),Y8e=n(Ba,"P",{});var RBt=s(Y8e);EMr=r(RBt,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),RBt.forEach(t),CMr=i(Ba),mn=n(Ba,"P",{});var z7=s(mn);wMr=r(z7,"The model class to instantiate is selected based on the "),K8e=n(z7,"CODE",{});var PBt=s(K8e);AMr=r(PBt,"model_type"),PBt.forEach(t),LMr=r(z7,` property of the config object (either
passed as an argument or loaded from `),Z8e=n(z7,"CODE",{});var BBt=s(Z8e);yMr=r(BBt,"pretrained_model_name_or_path"),BBt.forEach(t),xMr=r(z7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),eMe=n(z7,"CODE",{});var IBt=s(eMe);$Mr=r(IBt,"pretrained_model_name_or_path"),IBt.forEach(t),kMr=r(z7,":"),z7.forEach(t),SMr=i(Ba),oMe=n(Ba,"UL",{});var NBt=s(oMe);YM=n(NBt,"LI",{});var ODe=s(YM);rMe=n(ODe,"STRONG",{});var qBt=s(rMe);RMr=r(qBt,"maskformer"),qBt.forEach(t),PMr=r(ODe," \u2014 "),RJ=n(ODe,"A",{href:!0});var jBt=s(RJ);BMr=r(jBt,"MaskFormerForInstanceSegmentation"),jBt.forEach(t),IMr=r(ODe," (MaskFormer model)"),ODe.forEach(t),NBt.forEach(t),NMr=i(Ba),KM=n(Ba,"P",{});var VDe=s(KM);qMr=r(VDe,"The model is set in evaluation mode by default using "),tMe=n(VDe,"CODE",{});var DBt=s(tMe);jMr=r(DBt,"model.eval()"),DBt.forEach(t),DMr=r(VDe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),aMe=n(VDe,"CODE",{});var GBt=s(aMe);GMr=r(GBt,"model.train()"),GBt.forEach(t),VDe.forEach(t),OMr=i(Ba),T(ZM.$$.fragment,Ba),Ba.forEach(t),Nl.forEach(t),KQe=i(f),uc=n(f,"H2",{class:!0});var iJe=s(uc);eE=n(iJe,"A",{id:!0,class:!0,href:!0});var OBt=s(eE);nMe=n(OBt,"SPAN",{});var VBt=s(nMe);T(jx.$$.fragment,VBt),VBt.forEach(t),OBt.forEach(t),VMr=i(iJe),sMe=n(iJe,"SPAN",{});var XBt=s(sMe);XMr=r(XBt,"TFAutoModel"),XBt.forEach(t),iJe.forEach(t),ZQe=i(f),ar=n(f,"DIV",{class:!0});var ql=s(ar);T(Dx.$$.fragment,ql),zMr=i(ql),bc=n(ql,"P",{});var ane=s(bc);WMr=r(ane,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PJ=n(ane,"A",{href:!0});var zBt=s(PJ);QMr=r(zBt,"from_pretrained()"),zBt.forEach(t),HMr=r(ane," class method or the "),BJ=n(ane,"A",{href:!0});var WBt=s(BJ);UMr=r(WBt,"from_config()"),WBt.forEach(t),JMr=r(ane,` class
method.`),ane.forEach(t),YMr=i(ql),Gx=n(ql,"P",{});var dJe=s(Gx);KMr=r(dJe,"This class cannot be instantiated directly using "),lMe=n(dJe,"CODE",{});var QBt=s(lMe);ZMr=r(QBt,"__init__()"),QBt.forEach(t),eEr=r(dJe," (throws an error)."),dJe.forEach(t),oEr=i(ql),It=n(ql,"DIV",{class:!0});var W7=s(It);T(Ox.$$.fragment,W7),rEr=i(W7),iMe=n(W7,"P",{});var HBt=s(iMe);tEr=r(HBt,"Instantiates one of the base model classes of the library from a configuration."),HBt.forEach(t),aEr=i(W7),vc=n(W7,"P",{});var nne=s(vc);nEr=r(nne,`Note:
Loading a model from its configuration file does `),dMe=n(nne,"STRONG",{});var UBt=s(dMe);sEr=r(UBt,"not"),UBt.forEach(t),lEr=r(nne,` load the model weights. It only affects the
model\u2019s configuration. Use `),IJ=n(nne,"A",{href:!0});var JBt=s(IJ);iEr=r(JBt,"from_pretrained()"),JBt.forEach(t),dEr=r(nne," to load the model weights."),nne.forEach(t),cEr=i(W7),T(oE.$$.fragment,W7),W7.forEach(t),fEr=i(ql),Sr=n(ql,"DIV",{class:!0});var jl=s(Sr);T(Vx.$$.fragment,jl),mEr=i(jl),cMe=n(jl,"P",{});var YBt=s(cMe);gEr=r(YBt,"Instantiate one of the base model classes of the library from a pretrained model."),YBt.forEach(t),hEr=i(jl),gn=n(jl,"P",{});var Q7=s(gn);pEr=r(Q7,"The model class to instantiate is selected based on the "),fMe=n(Q7,"CODE",{});var KBt=s(fMe);_Er=r(KBt,"model_type"),KBt.forEach(t),uEr=r(Q7,` property of the config object (either
passed as an argument or loaded from `),mMe=n(Q7,"CODE",{});var ZBt=s(mMe);bEr=r(ZBt,"pretrained_model_name_or_path"),ZBt.forEach(t),vEr=r(Q7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),gMe=n(Q7,"CODE",{});var eIt=s(gMe);FEr=r(eIt,"pretrained_model_name_or_path"),eIt.forEach(t),TEr=r(Q7,":"),Q7.forEach(t),MEr=i(jl),q=n(jl,"UL",{});var D=s(q);rE=n(D,"LI",{});var XDe=s(rE);hMe=n(XDe,"STRONG",{});var oIt=s(hMe);EEr=r(oIt,"albert"),oIt.forEach(t),CEr=r(XDe," \u2014 "),NJ=n(XDe,"A",{href:!0});var rIt=s(NJ);wEr=r(rIt,"TFAlbertModel"),rIt.forEach(t),AEr=r(XDe," (ALBERT model)"),XDe.forEach(t),LEr=i(D),tE=n(D,"LI",{});var zDe=s(tE);pMe=n(zDe,"STRONG",{});var tIt=s(pMe);yEr=r(tIt,"bart"),tIt.forEach(t),xEr=r(zDe," \u2014 "),qJ=n(zDe,"A",{href:!0});var aIt=s(qJ);$Er=r(aIt,"TFBartModel"),aIt.forEach(t),kEr=r(zDe," (BART model)"),zDe.forEach(t),SEr=i(D),aE=n(D,"LI",{});var WDe=s(aE);_Me=n(WDe,"STRONG",{});var nIt=s(_Me);REr=r(nIt,"bert"),nIt.forEach(t),PEr=r(WDe," \u2014 "),jJ=n(WDe,"A",{href:!0});var sIt=s(jJ);BEr=r(sIt,"TFBertModel"),sIt.forEach(t),IEr=r(WDe," (BERT model)"),WDe.forEach(t),NEr=i(D),nE=n(D,"LI",{});var QDe=s(nE);uMe=n(QDe,"STRONG",{});var lIt=s(uMe);qEr=r(lIt,"blenderbot"),lIt.forEach(t),jEr=r(QDe," \u2014 "),DJ=n(QDe,"A",{href:!0});var iIt=s(DJ);DEr=r(iIt,"TFBlenderbotModel"),iIt.forEach(t),GEr=r(QDe," (Blenderbot model)"),QDe.forEach(t),OEr=i(D),sE=n(D,"LI",{});var HDe=s(sE);bMe=n(HDe,"STRONG",{});var dIt=s(bMe);VEr=r(dIt,"blenderbot-small"),dIt.forEach(t),XEr=r(HDe," \u2014 "),GJ=n(HDe,"A",{href:!0});var cIt=s(GJ);zEr=r(cIt,"TFBlenderbotSmallModel"),cIt.forEach(t),WEr=r(HDe," (BlenderbotSmall model)"),HDe.forEach(t),QEr=i(D),lE=n(D,"LI",{});var UDe=s(lE);vMe=n(UDe,"STRONG",{});var fIt=s(vMe);HEr=r(fIt,"camembert"),fIt.forEach(t),UEr=r(UDe," \u2014 "),OJ=n(UDe,"A",{href:!0});var mIt=s(OJ);JEr=r(mIt,"TFCamembertModel"),mIt.forEach(t),YEr=r(UDe," (CamemBERT model)"),UDe.forEach(t),KEr=i(D),iE=n(D,"LI",{});var JDe=s(iE);FMe=n(JDe,"STRONG",{});var gIt=s(FMe);ZEr=r(gIt,"clip"),gIt.forEach(t),e4r=r(JDe," \u2014 "),VJ=n(JDe,"A",{href:!0});var hIt=s(VJ);o4r=r(hIt,"TFCLIPModel"),hIt.forEach(t),r4r=r(JDe," (CLIP model)"),JDe.forEach(t),t4r=i(D),dE=n(D,"LI",{});var YDe=s(dE);TMe=n(YDe,"STRONG",{});var pIt=s(TMe);a4r=r(pIt,"convbert"),pIt.forEach(t),n4r=r(YDe," \u2014 "),XJ=n(YDe,"A",{href:!0});var _It=s(XJ);s4r=r(_It,"TFConvBertModel"),_It.forEach(t),l4r=r(YDe," (ConvBERT model)"),YDe.forEach(t),i4r=i(D),cE=n(D,"LI",{});var KDe=s(cE);MMe=n(KDe,"STRONG",{});var uIt=s(MMe);d4r=r(uIt,"convnext"),uIt.forEach(t),c4r=r(KDe," \u2014 "),zJ=n(KDe,"A",{href:!0});var bIt=s(zJ);f4r=r(bIt,"TFConvNextModel"),bIt.forEach(t),m4r=r(KDe," (ConvNeXT model)"),KDe.forEach(t),g4r=i(D),fE=n(D,"LI",{});var ZDe=s(fE);EMe=n(ZDe,"STRONG",{});var vIt=s(EMe);h4r=r(vIt,"ctrl"),vIt.forEach(t),p4r=r(ZDe," \u2014 "),WJ=n(ZDe,"A",{href:!0});var FIt=s(WJ);_4r=r(FIt,"TFCTRLModel"),FIt.forEach(t),u4r=r(ZDe," (CTRL model)"),ZDe.forEach(t),b4r=i(D),mE=n(D,"LI",{});var eGe=s(mE);CMe=n(eGe,"STRONG",{});var TIt=s(CMe);v4r=r(TIt,"data2vec-vision"),TIt.forEach(t),F4r=r(eGe," \u2014 "),QJ=n(eGe,"A",{href:!0});var MIt=s(QJ);T4r=r(MIt,"TFData2VecVisionModel"),MIt.forEach(t),M4r=r(eGe," (Data2VecVision model)"),eGe.forEach(t),E4r=i(D),gE=n(D,"LI",{});var oGe=s(gE);wMe=n(oGe,"STRONG",{});var EIt=s(wMe);C4r=r(EIt,"deberta"),EIt.forEach(t),w4r=r(oGe," \u2014 "),HJ=n(oGe,"A",{href:!0});var CIt=s(HJ);A4r=r(CIt,"TFDebertaModel"),CIt.forEach(t),L4r=r(oGe," (DeBERTa model)"),oGe.forEach(t),y4r=i(D),hE=n(D,"LI",{});var rGe=s(hE);AMe=n(rGe,"STRONG",{});var wIt=s(AMe);x4r=r(wIt,"deberta-v2"),wIt.forEach(t),$4r=r(rGe," \u2014 "),UJ=n(rGe,"A",{href:!0});var AIt=s(UJ);k4r=r(AIt,"TFDebertaV2Model"),AIt.forEach(t),S4r=r(rGe," (DeBERTa-v2 model)"),rGe.forEach(t),R4r=i(D),pE=n(D,"LI",{});var tGe=s(pE);LMe=n(tGe,"STRONG",{});var LIt=s(LMe);P4r=r(LIt,"deit"),LIt.forEach(t),B4r=r(tGe," \u2014 "),JJ=n(tGe,"A",{href:!0});var yIt=s(JJ);I4r=r(yIt,"TFDeiTModel"),yIt.forEach(t),N4r=r(tGe," (DeiT model)"),tGe.forEach(t),q4r=i(D),_E=n(D,"LI",{});var aGe=s(_E);yMe=n(aGe,"STRONG",{});var xIt=s(yMe);j4r=r(xIt,"distilbert"),xIt.forEach(t),D4r=r(aGe," \u2014 "),YJ=n(aGe,"A",{href:!0});var $It=s(YJ);G4r=r($It,"TFDistilBertModel"),$It.forEach(t),O4r=r(aGe," (DistilBERT model)"),aGe.forEach(t),V4r=i(D),uE=n(D,"LI",{});var nGe=s(uE);xMe=n(nGe,"STRONG",{});var kIt=s(xMe);X4r=r(kIt,"dpr"),kIt.forEach(t),z4r=r(nGe," \u2014 "),KJ=n(nGe,"A",{href:!0});var SIt=s(KJ);W4r=r(SIt,"TFDPRQuestionEncoder"),SIt.forEach(t),Q4r=r(nGe," (DPR model)"),nGe.forEach(t),H4r=i(D),bE=n(D,"LI",{});var sGe=s(bE);$Me=n(sGe,"STRONG",{});var RIt=s($Me);U4r=r(RIt,"electra"),RIt.forEach(t),J4r=r(sGe," \u2014 "),ZJ=n(sGe,"A",{href:!0});var PIt=s(ZJ);Y4r=r(PIt,"TFElectraModel"),PIt.forEach(t),K4r=r(sGe," (ELECTRA model)"),sGe.forEach(t),Z4r=i(D),vE=n(D,"LI",{});var lGe=s(vE);kMe=n(lGe,"STRONG",{});var BIt=s(kMe);eCr=r(BIt,"flaubert"),BIt.forEach(t),oCr=r(lGe," \u2014 "),eY=n(lGe,"A",{href:!0});var IIt=s(eY);rCr=r(IIt,"TFFlaubertModel"),IIt.forEach(t),tCr=r(lGe," (FlauBERT model)"),lGe.forEach(t),aCr=i(D),al=n(D,"LI",{});var $R=s(al);SMe=n($R,"STRONG",{});var NIt=s(SMe);nCr=r(NIt,"funnel"),NIt.forEach(t),sCr=r($R," \u2014 "),oY=n($R,"A",{href:!0});var qIt=s(oY);lCr=r(qIt,"TFFunnelModel"),qIt.forEach(t),iCr=r($R," or "),rY=n($R,"A",{href:!0});var jIt=s(rY);dCr=r(jIt,"TFFunnelBaseModel"),jIt.forEach(t),cCr=r($R," (Funnel Transformer model)"),$R.forEach(t),fCr=i(D),FE=n(D,"LI",{});var iGe=s(FE);RMe=n(iGe,"STRONG",{});var DIt=s(RMe);mCr=r(DIt,"gpt2"),DIt.forEach(t),gCr=r(iGe," \u2014 "),tY=n(iGe,"A",{href:!0});var GIt=s(tY);hCr=r(GIt,"TFGPT2Model"),GIt.forEach(t),pCr=r(iGe," (OpenAI GPT-2 model)"),iGe.forEach(t),_Cr=i(D),TE=n(D,"LI",{});var dGe=s(TE);PMe=n(dGe,"STRONG",{});var OIt=s(PMe);uCr=r(OIt,"gptj"),OIt.forEach(t),bCr=r(dGe," \u2014 "),aY=n(dGe,"A",{href:!0});var VIt=s(aY);vCr=r(VIt,"TFGPTJModel"),VIt.forEach(t),FCr=r(dGe," (GPT-J model)"),dGe.forEach(t),TCr=i(D),ME=n(D,"LI",{});var cGe=s(ME);BMe=n(cGe,"STRONG",{});var XIt=s(BMe);MCr=r(XIt,"hubert"),XIt.forEach(t),ECr=r(cGe," \u2014 "),nY=n(cGe,"A",{href:!0});var zIt=s(nY);CCr=r(zIt,"TFHubertModel"),zIt.forEach(t),wCr=r(cGe," (Hubert model)"),cGe.forEach(t),ACr=i(D),EE=n(D,"LI",{});var fGe=s(EE);IMe=n(fGe,"STRONG",{});var WIt=s(IMe);LCr=r(WIt,"layoutlm"),WIt.forEach(t),yCr=r(fGe," \u2014 "),sY=n(fGe,"A",{href:!0});var QIt=s(sY);xCr=r(QIt,"TFLayoutLMModel"),QIt.forEach(t),$Cr=r(fGe," (LayoutLM model)"),fGe.forEach(t),kCr=i(D),CE=n(D,"LI",{});var mGe=s(CE);NMe=n(mGe,"STRONG",{});var HIt=s(NMe);SCr=r(HIt,"led"),HIt.forEach(t),RCr=r(mGe," \u2014 "),lY=n(mGe,"A",{href:!0});var UIt=s(lY);PCr=r(UIt,"TFLEDModel"),UIt.forEach(t),BCr=r(mGe," (LED model)"),mGe.forEach(t),ICr=i(D),wE=n(D,"LI",{});var gGe=s(wE);qMe=n(gGe,"STRONG",{});var JIt=s(qMe);NCr=r(JIt,"longformer"),JIt.forEach(t),qCr=r(gGe," \u2014 "),iY=n(gGe,"A",{href:!0});var YIt=s(iY);jCr=r(YIt,"TFLongformerModel"),YIt.forEach(t),DCr=r(gGe," (Longformer model)"),gGe.forEach(t),GCr=i(D),AE=n(D,"LI",{});var hGe=s(AE);jMe=n(hGe,"STRONG",{});var KIt=s(jMe);OCr=r(KIt,"lxmert"),KIt.forEach(t),VCr=r(hGe," \u2014 "),dY=n(hGe,"A",{href:!0});var ZIt=s(dY);XCr=r(ZIt,"TFLxmertModel"),ZIt.forEach(t),zCr=r(hGe," (LXMERT model)"),hGe.forEach(t),WCr=i(D),LE=n(D,"LI",{});var pGe=s(LE);DMe=n(pGe,"STRONG",{});var eNt=s(DMe);QCr=r(eNt,"marian"),eNt.forEach(t),HCr=r(pGe," \u2014 "),cY=n(pGe,"A",{href:!0});var oNt=s(cY);UCr=r(oNt,"TFMarianModel"),oNt.forEach(t),JCr=r(pGe," (Marian model)"),pGe.forEach(t),YCr=i(D),yE=n(D,"LI",{});var _Ge=s(yE);GMe=n(_Ge,"STRONG",{});var rNt=s(GMe);KCr=r(rNt,"mbart"),rNt.forEach(t),ZCr=r(_Ge," \u2014 "),fY=n(_Ge,"A",{href:!0});var tNt=s(fY);e5r=r(tNt,"TFMBartModel"),tNt.forEach(t),o5r=r(_Ge," (mBART model)"),_Ge.forEach(t),r5r=i(D),xE=n(D,"LI",{});var uGe=s(xE);OMe=n(uGe,"STRONG",{});var aNt=s(OMe);t5r=r(aNt,"mobilebert"),aNt.forEach(t),a5r=r(uGe," \u2014 "),mY=n(uGe,"A",{href:!0});var nNt=s(mY);n5r=r(nNt,"TFMobileBertModel"),nNt.forEach(t),s5r=r(uGe," (MobileBERT model)"),uGe.forEach(t),l5r=i(D),$E=n(D,"LI",{});var bGe=s($E);VMe=n(bGe,"STRONG",{});var sNt=s(VMe);i5r=r(sNt,"mpnet"),sNt.forEach(t),d5r=r(bGe," \u2014 "),gY=n(bGe,"A",{href:!0});var lNt=s(gY);c5r=r(lNt,"TFMPNetModel"),lNt.forEach(t),f5r=r(bGe," (MPNet model)"),bGe.forEach(t),m5r=i(D),kE=n(D,"LI",{});var vGe=s(kE);XMe=n(vGe,"STRONG",{});var iNt=s(XMe);g5r=r(iNt,"mt5"),iNt.forEach(t),h5r=r(vGe," \u2014 "),hY=n(vGe,"A",{href:!0});var dNt=s(hY);p5r=r(dNt,"TFMT5Model"),dNt.forEach(t),_5r=r(vGe," (MT5 model)"),vGe.forEach(t),u5r=i(D),SE=n(D,"LI",{});var FGe=s(SE);zMe=n(FGe,"STRONG",{});var cNt=s(zMe);b5r=r(cNt,"openai-gpt"),cNt.forEach(t),v5r=r(FGe," \u2014 "),pY=n(FGe,"A",{href:!0});var fNt=s(pY);F5r=r(fNt,"TFOpenAIGPTModel"),fNt.forEach(t),T5r=r(FGe," (OpenAI GPT model)"),FGe.forEach(t),M5r=i(D),RE=n(D,"LI",{});var TGe=s(RE);WMe=n(TGe,"STRONG",{});var mNt=s(WMe);E5r=r(mNt,"opt"),mNt.forEach(t),C5r=r(TGe," \u2014 "),_Y=n(TGe,"A",{href:!0});var gNt=s(_Y);w5r=r(gNt,"TFOPTModel"),gNt.forEach(t),A5r=r(TGe," (OPT model)"),TGe.forEach(t),L5r=i(D),PE=n(D,"LI",{});var MGe=s(PE);QMe=n(MGe,"STRONG",{});var hNt=s(QMe);y5r=r(hNt,"pegasus"),hNt.forEach(t),x5r=r(MGe," \u2014 "),uY=n(MGe,"A",{href:!0});var pNt=s(uY);$5r=r(pNt,"TFPegasusModel"),pNt.forEach(t),k5r=r(MGe," (Pegasus model)"),MGe.forEach(t),S5r=i(D),BE=n(D,"LI",{});var EGe=s(BE);HMe=n(EGe,"STRONG",{});var _Nt=s(HMe);R5r=r(_Nt,"regnet"),_Nt.forEach(t),P5r=r(EGe," \u2014 "),bY=n(EGe,"A",{href:!0});var uNt=s(bY);B5r=r(uNt,"TFRegNetModel"),uNt.forEach(t),I5r=r(EGe," (RegNet model)"),EGe.forEach(t),N5r=i(D),IE=n(D,"LI",{});var CGe=s(IE);UMe=n(CGe,"STRONG",{});var bNt=s(UMe);q5r=r(bNt,"rembert"),bNt.forEach(t),j5r=r(CGe," \u2014 "),vY=n(CGe,"A",{href:!0});var vNt=s(vY);D5r=r(vNt,"TFRemBertModel"),vNt.forEach(t),G5r=r(CGe," (RemBERT model)"),CGe.forEach(t),O5r=i(D),NE=n(D,"LI",{});var wGe=s(NE);JMe=n(wGe,"STRONG",{});var FNt=s(JMe);V5r=r(FNt,"resnet"),FNt.forEach(t),X5r=r(wGe," \u2014 "),FY=n(wGe,"A",{href:!0});var TNt=s(FY);z5r=r(TNt,"TFResNetModel"),TNt.forEach(t),W5r=r(wGe," (ResNet model)"),wGe.forEach(t),Q5r=i(D),qE=n(D,"LI",{});var AGe=s(qE);YMe=n(AGe,"STRONG",{});var MNt=s(YMe);H5r=r(MNt,"roberta"),MNt.forEach(t),U5r=r(AGe," \u2014 "),TY=n(AGe,"A",{href:!0});var ENt=s(TY);J5r=r(ENt,"TFRobertaModel"),ENt.forEach(t),Y5r=r(AGe," (RoBERTa model)"),AGe.forEach(t),K5r=i(D),jE=n(D,"LI",{});var LGe=s(jE);KMe=n(LGe,"STRONG",{});var CNt=s(KMe);Z5r=r(CNt,"roformer"),CNt.forEach(t),e3r=r(LGe," \u2014 "),MY=n(LGe,"A",{href:!0});var wNt=s(MY);o3r=r(wNt,"TFRoFormerModel"),wNt.forEach(t),r3r=r(LGe," (RoFormer model)"),LGe.forEach(t),t3r=i(D),DE=n(D,"LI",{});var yGe=s(DE);ZMe=n(yGe,"STRONG",{});var ANt=s(ZMe);a3r=r(ANt,"segformer"),ANt.forEach(t),n3r=r(yGe," \u2014 "),EY=n(yGe,"A",{href:!0});var LNt=s(EY);s3r=r(LNt,"TFSegformerModel"),LNt.forEach(t),l3r=r(yGe," (SegFormer model)"),yGe.forEach(t),i3r=i(D),GE=n(D,"LI",{});var xGe=s(GE);eEe=n(xGe,"STRONG",{});var yNt=s(eEe);d3r=r(yNt,"speech_to_text"),yNt.forEach(t),c3r=r(xGe," \u2014 "),CY=n(xGe,"A",{href:!0});var xNt=s(CY);f3r=r(xNt,"TFSpeech2TextModel"),xNt.forEach(t),m3r=r(xGe," (Speech2Text model)"),xGe.forEach(t),g3r=i(D),OE=n(D,"LI",{});var $Ge=s(OE);oEe=n($Ge,"STRONG",{});var $Nt=s(oEe);h3r=r($Nt,"swin"),$Nt.forEach(t),p3r=r($Ge," \u2014 "),wY=n($Ge,"A",{href:!0});var kNt=s(wY);_3r=r(kNt,"TFSwinModel"),kNt.forEach(t),u3r=r($Ge," (Swin Transformer model)"),$Ge.forEach(t),b3r=i(D),VE=n(D,"LI",{});var kGe=s(VE);rEe=n(kGe,"STRONG",{});var SNt=s(rEe);v3r=r(SNt,"t5"),SNt.forEach(t),F3r=r(kGe," \u2014 "),AY=n(kGe,"A",{href:!0});var RNt=s(AY);T3r=r(RNt,"TFT5Model"),RNt.forEach(t),M3r=r(kGe," (T5 model)"),kGe.forEach(t),E3r=i(D),XE=n(D,"LI",{});var SGe=s(XE);tEe=n(SGe,"STRONG",{});var PNt=s(tEe);C3r=r(PNt,"tapas"),PNt.forEach(t),w3r=r(SGe," \u2014 "),LY=n(SGe,"A",{href:!0});var BNt=s(LY);A3r=r(BNt,"TFTapasModel"),BNt.forEach(t),L3r=r(SGe," (TAPAS model)"),SGe.forEach(t),y3r=i(D),zE=n(D,"LI",{});var RGe=s(zE);aEe=n(RGe,"STRONG",{});var INt=s(aEe);x3r=r(INt,"transfo-xl"),INt.forEach(t),$3r=r(RGe," \u2014 "),yY=n(RGe,"A",{href:!0});var NNt=s(yY);k3r=r(NNt,"TFTransfoXLModel"),NNt.forEach(t),S3r=r(RGe," (Transformer-XL model)"),RGe.forEach(t),R3r=i(D),WE=n(D,"LI",{});var PGe=s(WE);nEe=n(PGe,"STRONG",{});var qNt=s(nEe);P3r=r(qNt,"vit"),qNt.forEach(t),B3r=r(PGe," \u2014 "),xY=n(PGe,"A",{href:!0});var jNt=s(xY);I3r=r(jNt,"TFViTModel"),jNt.forEach(t),N3r=r(PGe," (ViT model)"),PGe.forEach(t),q3r=i(D),QE=n(D,"LI",{});var BGe=s(QE);sEe=n(BGe,"STRONG",{});var DNt=s(sEe);j3r=r(DNt,"vit_mae"),DNt.forEach(t),D3r=r(BGe," \u2014 "),$Y=n(BGe,"A",{href:!0});var GNt=s($Y);G3r=r(GNt,"TFViTMAEModel"),GNt.forEach(t),O3r=r(BGe," (ViTMAE model)"),BGe.forEach(t),V3r=i(D),HE=n(D,"LI",{});var IGe=s(HE);lEe=n(IGe,"STRONG",{});var ONt=s(lEe);X3r=r(ONt,"wav2vec2"),ONt.forEach(t),z3r=r(IGe," \u2014 "),kY=n(IGe,"A",{href:!0});var VNt=s(kY);W3r=r(VNt,"TFWav2Vec2Model"),VNt.forEach(t),Q3r=r(IGe," (Wav2Vec2 model)"),IGe.forEach(t),H3r=i(D),UE=n(D,"LI",{});var NGe=s(UE);iEe=n(NGe,"STRONG",{});var XNt=s(iEe);U3r=r(XNt,"xlm"),XNt.forEach(t),J3r=r(NGe," \u2014 "),SY=n(NGe,"A",{href:!0});var zNt=s(SY);Y3r=r(zNt,"TFXLMModel"),zNt.forEach(t),K3r=r(NGe," (XLM model)"),NGe.forEach(t),Z3r=i(D),JE=n(D,"LI",{});var qGe=s(JE);dEe=n(qGe,"STRONG",{});var WNt=s(dEe);ewr=r(WNt,"xlm-roberta"),WNt.forEach(t),owr=r(qGe," \u2014 "),RY=n(qGe,"A",{href:!0});var QNt=s(RY);rwr=r(QNt,"TFXLMRobertaModel"),QNt.forEach(t),twr=r(qGe," (XLM-RoBERTa model)"),qGe.forEach(t),awr=i(D),YE=n(D,"LI",{});var jGe=s(YE);cEe=n(jGe,"STRONG",{});var HNt=s(cEe);nwr=r(HNt,"xlnet"),HNt.forEach(t),swr=r(jGe," \u2014 "),PY=n(jGe,"A",{href:!0});var UNt=s(PY);lwr=r(UNt,"TFXLNetModel"),UNt.forEach(t),iwr=r(jGe," (XLNet model)"),jGe.forEach(t),D.forEach(t),dwr=i(jl),T(KE.$$.fragment,jl),jl.forEach(t),ql.forEach(t),eHe=i(f),Fc=n(f,"H2",{class:!0});var cJe=s(Fc);ZE=n(cJe,"A",{id:!0,class:!0,href:!0});var JNt=s(ZE);fEe=n(JNt,"SPAN",{});var YNt=s(fEe);T(Xx.$$.fragment,YNt),YNt.forEach(t),JNt.forEach(t),cwr=i(cJe),mEe=n(cJe,"SPAN",{});var KNt=s(mEe);fwr=r(KNt,"TFAutoModelForPreTraining"),KNt.forEach(t),cJe.forEach(t),oHe=i(f),nr=n(f,"DIV",{class:!0});var Dl=s(nr);T(zx.$$.fragment,Dl),mwr=i(Dl),Tc=n(Dl,"P",{});var sne=s(Tc);gwr=r(sne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),BY=n(sne,"A",{href:!0});var ZNt=s(BY);hwr=r(ZNt,"from_pretrained()"),ZNt.forEach(t),pwr=r(sne," class method or the "),IY=n(sne,"A",{href:!0});var eqt=s(IY);_wr=r(eqt,"from_config()"),eqt.forEach(t),uwr=r(sne,` class
method.`),sne.forEach(t),bwr=i(Dl),Wx=n(Dl,"P",{});var fJe=s(Wx);vwr=r(fJe,"This class cannot be instantiated directly using "),gEe=n(fJe,"CODE",{});var oqt=s(gEe);Fwr=r(oqt,"__init__()"),oqt.forEach(t),Twr=r(fJe," (throws an error)."),fJe.forEach(t),Mwr=i(Dl),Nt=n(Dl,"DIV",{class:!0});var H7=s(Nt);T(Qx.$$.fragment,H7),Ewr=i(H7),hEe=n(H7,"P",{});var rqt=s(hEe);Cwr=r(rqt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),rqt.forEach(t),wwr=i(H7),Mc=n(H7,"P",{});var lne=s(Mc);Awr=r(lne,`Note:
Loading a model from its configuration file does `),pEe=n(lne,"STRONG",{});var tqt=s(pEe);Lwr=r(tqt,"not"),tqt.forEach(t),ywr=r(lne,` load the model weights. It only affects the
model\u2019s configuration. Use `),NY=n(lne,"A",{href:!0});var aqt=s(NY);xwr=r(aqt,"from_pretrained()"),aqt.forEach(t),$wr=r(lne," to load the model weights."),lne.forEach(t),kwr=i(H7),T(e4.$$.fragment,H7),H7.forEach(t),Swr=i(Dl),Rr=n(Dl,"DIV",{class:!0});var Gl=s(Rr);T(Hx.$$.fragment,Gl),Rwr=i(Gl),_Ee=n(Gl,"P",{});var nqt=s(_Ee);Pwr=r(nqt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),nqt.forEach(t),Bwr=i(Gl),hn=n(Gl,"P",{});var U7=s(hn);Iwr=r(U7,"The model class to instantiate is selected based on the "),uEe=n(U7,"CODE",{});var sqt=s(uEe);Nwr=r(sqt,"model_type"),sqt.forEach(t),qwr=r(U7,` property of the config object (either
passed as an argument or loaded from `),bEe=n(U7,"CODE",{});var lqt=s(bEe);jwr=r(lqt,"pretrained_model_name_or_path"),lqt.forEach(t),Dwr=r(U7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vEe=n(U7,"CODE",{});var iqt=s(vEe);Gwr=r(iqt,"pretrained_model_name_or_path"),iqt.forEach(t),Owr=r(U7,":"),U7.forEach(t),Vwr=i(Gl),se=n(Gl,"UL",{});var le=s(se);o4=n(le,"LI",{});var DGe=s(o4);FEe=n(DGe,"STRONG",{});var dqt=s(FEe);Xwr=r(dqt,"albert"),dqt.forEach(t),zwr=r(DGe," \u2014 "),qY=n(DGe,"A",{href:!0});var cqt=s(qY);Wwr=r(cqt,"TFAlbertForPreTraining"),cqt.forEach(t),Qwr=r(DGe," (ALBERT model)"),DGe.forEach(t),Hwr=i(le),r4=n(le,"LI",{});var GGe=s(r4);TEe=n(GGe,"STRONG",{});var fqt=s(TEe);Uwr=r(fqt,"bart"),fqt.forEach(t),Jwr=r(GGe," \u2014 "),jY=n(GGe,"A",{href:!0});var mqt=s(jY);Ywr=r(mqt,"TFBartForConditionalGeneration"),mqt.forEach(t),Kwr=r(GGe," (BART model)"),GGe.forEach(t),Zwr=i(le),t4=n(le,"LI",{});var OGe=s(t4);MEe=n(OGe,"STRONG",{});var gqt=s(MEe);e6r=r(gqt,"bert"),gqt.forEach(t),o6r=r(OGe," \u2014 "),DY=n(OGe,"A",{href:!0});var hqt=s(DY);r6r=r(hqt,"TFBertForPreTraining"),hqt.forEach(t),t6r=r(OGe," (BERT model)"),OGe.forEach(t),a6r=i(le),a4=n(le,"LI",{});var VGe=s(a4);EEe=n(VGe,"STRONG",{});var pqt=s(EEe);n6r=r(pqt,"camembert"),pqt.forEach(t),s6r=r(VGe," \u2014 "),GY=n(VGe,"A",{href:!0});var _qt=s(GY);l6r=r(_qt,"TFCamembertForMaskedLM"),_qt.forEach(t),i6r=r(VGe," (CamemBERT model)"),VGe.forEach(t),d6r=i(le),n4=n(le,"LI",{});var XGe=s(n4);CEe=n(XGe,"STRONG",{});var uqt=s(CEe);c6r=r(uqt,"ctrl"),uqt.forEach(t),f6r=r(XGe," \u2014 "),OY=n(XGe,"A",{href:!0});var bqt=s(OY);m6r=r(bqt,"TFCTRLLMHeadModel"),bqt.forEach(t),g6r=r(XGe," (CTRL model)"),XGe.forEach(t),h6r=i(le),s4=n(le,"LI",{});var zGe=s(s4);wEe=n(zGe,"STRONG",{});var vqt=s(wEe);p6r=r(vqt,"distilbert"),vqt.forEach(t),_6r=r(zGe," \u2014 "),VY=n(zGe,"A",{href:!0});var Fqt=s(VY);u6r=r(Fqt,"TFDistilBertForMaskedLM"),Fqt.forEach(t),b6r=r(zGe," (DistilBERT model)"),zGe.forEach(t),v6r=i(le),l4=n(le,"LI",{});var WGe=s(l4);AEe=n(WGe,"STRONG",{});var Tqt=s(AEe);F6r=r(Tqt,"electra"),Tqt.forEach(t),T6r=r(WGe," \u2014 "),XY=n(WGe,"A",{href:!0});var Mqt=s(XY);M6r=r(Mqt,"TFElectraForPreTraining"),Mqt.forEach(t),E6r=r(WGe," (ELECTRA model)"),WGe.forEach(t),C6r=i(le),i4=n(le,"LI",{});var QGe=s(i4);LEe=n(QGe,"STRONG",{});var Eqt=s(LEe);w6r=r(Eqt,"flaubert"),Eqt.forEach(t),A6r=r(QGe," \u2014 "),zY=n(QGe,"A",{href:!0});var Cqt=s(zY);L6r=r(Cqt,"TFFlaubertWithLMHeadModel"),Cqt.forEach(t),y6r=r(QGe," (FlauBERT model)"),QGe.forEach(t),x6r=i(le),d4=n(le,"LI",{});var HGe=s(d4);yEe=n(HGe,"STRONG",{});var wqt=s(yEe);$6r=r(wqt,"funnel"),wqt.forEach(t),k6r=r(HGe," \u2014 "),WY=n(HGe,"A",{href:!0});var Aqt=s(WY);S6r=r(Aqt,"TFFunnelForPreTraining"),Aqt.forEach(t),R6r=r(HGe," (Funnel Transformer model)"),HGe.forEach(t),P6r=i(le),c4=n(le,"LI",{});var UGe=s(c4);xEe=n(UGe,"STRONG",{});var Lqt=s(xEe);B6r=r(Lqt,"gpt2"),Lqt.forEach(t),I6r=r(UGe," \u2014 "),QY=n(UGe,"A",{href:!0});var yqt=s(QY);N6r=r(yqt,"TFGPT2LMHeadModel"),yqt.forEach(t),q6r=r(UGe," (OpenAI GPT-2 model)"),UGe.forEach(t),j6r=i(le),f4=n(le,"LI",{});var JGe=s(f4);$Ee=n(JGe,"STRONG",{});var xqt=s($Ee);D6r=r(xqt,"layoutlm"),xqt.forEach(t),G6r=r(JGe," \u2014 "),HY=n(JGe,"A",{href:!0});var $qt=s(HY);O6r=r($qt,"TFLayoutLMForMaskedLM"),$qt.forEach(t),V6r=r(JGe," (LayoutLM model)"),JGe.forEach(t),X6r=i(le),m4=n(le,"LI",{});var YGe=s(m4);kEe=n(YGe,"STRONG",{});var kqt=s(kEe);z6r=r(kqt,"lxmert"),kqt.forEach(t),W6r=r(YGe," \u2014 "),UY=n(YGe,"A",{href:!0});var Sqt=s(UY);Q6r=r(Sqt,"TFLxmertForPreTraining"),Sqt.forEach(t),H6r=r(YGe," (LXMERT model)"),YGe.forEach(t),U6r=i(le),g4=n(le,"LI",{});var KGe=s(g4);SEe=n(KGe,"STRONG",{});var Rqt=s(SEe);J6r=r(Rqt,"mobilebert"),Rqt.forEach(t),Y6r=r(KGe," \u2014 "),JY=n(KGe,"A",{href:!0});var Pqt=s(JY);K6r=r(Pqt,"TFMobileBertForPreTraining"),Pqt.forEach(t),Z6r=r(KGe," (MobileBERT model)"),KGe.forEach(t),eAr=i(le),h4=n(le,"LI",{});var ZGe=s(h4);REe=n(ZGe,"STRONG",{});var Bqt=s(REe);oAr=r(Bqt,"mpnet"),Bqt.forEach(t),rAr=r(ZGe," \u2014 "),YY=n(ZGe,"A",{href:!0});var Iqt=s(YY);tAr=r(Iqt,"TFMPNetForMaskedLM"),Iqt.forEach(t),aAr=r(ZGe," (MPNet model)"),ZGe.forEach(t),nAr=i(le),p4=n(le,"LI",{});var eOe=s(p4);PEe=n(eOe,"STRONG",{});var Nqt=s(PEe);sAr=r(Nqt,"openai-gpt"),Nqt.forEach(t),lAr=r(eOe," \u2014 "),KY=n(eOe,"A",{href:!0});var qqt=s(KY);iAr=r(qqt,"TFOpenAIGPTLMHeadModel"),qqt.forEach(t),dAr=r(eOe," (OpenAI GPT model)"),eOe.forEach(t),cAr=i(le),_4=n(le,"LI",{});var oOe=s(_4);BEe=n(oOe,"STRONG",{});var jqt=s(BEe);fAr=r(jqt,"roberta"),jqt.forEach(t),mAr=r(oOe," \u2014 "),ZY=n(oOe,"A",{href:!0});var Dqt=s(ZY);gAr=r(Dqt,"TFRobertaForMaskedLM"),Dqt.forEach(t),hAr=r(oOe," (RoBERTa model)"),oOe.forEach(t),pAr=i(le),u4=n(le,"LI",{});var rOe=s(u4);IEe=n(rOe,"STRONG",{});var Gqt=s(IEe);_Ar=r(Gqt,"t5"),Gqt.forEach(t),uAr=r(rOe," \u2014 "),eK=n(rOe,"A",{href:!0});var Oqt=s(eK);bAr=r(Oqt,"TFT5ForConditionalGeneration"),Oqt.forEach(t),vAr=r(rOe," (T5 model)"),rOe.forEach(t),FAr=i(le),b4=n(le,"LI",{});var tOe=s(b4);NEe=n(tOe,"STRONG",{});var Vqt=s(NEe);TAr=r(Vqt,"tapas"),Vqt.forEach(t),MAr=r(tOe," \u2014 "),oK=n(tOe,"A",{href:!0});var Xqt=s(oK);EAr=r(Xqt,"TFTapasForMaskedLM"),Xqt.forEach(t),CAr=r(tOe," (TAPAS model)"),tOe.forEach(t),wAr=i(le),v4=n(le,"LI",{});var aOe=s(v4);qEe=n(aOe,"STRONG",{});var zqt=s(qEe);AAr=r(zqt,"transfo-xl"),zqt.forEach(t),LAr=r(aOe," \u2014 "),rK=n(aOe,"A",{href:!0});var Wqt=s(rK);yAr=r(Wqt,"TFTransfoXLLMHeadModel"),Wqt.forEach(t),xAr=r(aOe," (Transformer-XL model)"),aOe.forEach(t),$Ar=i(le),F4=n(le,"LI",{});var nOe=s(F4);jEe=n(nOe,"STRONG",{});var Qqt=s(jEe);kAr=r(Qqt,"vit_mae"),Qqt.forEach(t),SAr=r(nOe," \u2014 "),tK=n(nOe,"A",{href:!0});var Hqt=s(tK);RAr=r(Hqt,"TFViTMAEForPreTraining"),Hqt.forEach(t),PAr=r(nOe," (ViTMAE model)"),nOe.forEach(t),BAr=i(le),T4=n(le,"LI",{});var sOe=s(T4);DEe=n(sOe,"STRONG",{});var Uqt=s(DEe);IAr=r(Uqt,"xlm"),Uqt.forEach(t),NAr=r(sOe," \u2014 "),aK=n(sOe,"A",{href:!0});var Jqt=s(aK);qAr=r(Jqt,"TFXLMWithLMHeadModel"),Jqt.forEach(t),jAr=r(sOe," (XLM model)"),sOe.forEach(t),DAr=i(le),M4=n(le,"LI",{});var lOe=s(M4);GEe=n(lOe,"STRONG",{});var Yqt=s(GEe);GAr=r(Yqt,"xlm-roberta"),Yqt.forEach(t),OAr=r(lOe," \u2014 "),nK=n(lOe,"A",{href:!0});var Kqt=s(nK);VAr=r(Kqt,"TFXLMRobertaForMaskedLM"),Kqt.forEach(t),XAr=r(lOe," (XLM-RoBERTa model)"),lOe.forEach(t),zAr=i(le),E4=n(le,"LI",{});var iOe=s(E4);OEe=n(iOe,"STRONG",{});var Zqt=s(OEe);WAr=r(Zqt,"xlnet"),Zqt.forEach(t),QAr=r(iOe," \u2014 "),sK=n(iOe,"A",{href:!0});var ejt=s(sK);HAr=r(ejt,"TFXLNetLMHeadModel"),ejt.forEach(t),UAr=r(iOe," (XLNet model)"),iOe.forEach(t),le.forEach(t),JAr=i(Gl),T(C4.$$.fragment,Gl),Gl.forEach(t),Dl.forEach(t),rHe=i(f),Ec=n(f,"H2",{class:!0});var mJe=s(Ec);w4=n(mJe,"A",{id:!0,class:!0,href:!0});var ojt=s(w4);VEe=n(ojt,"SPAN",{});var rjt=s(VEe);T(Ux.$$.fragment,rjt),rjt.forEach(t),ojt.forEach(t),YAr=i(mJe),XEe=n(mJe,"SPAN",{});var tjt=s(XEe);KAr=r(tjt,"TFAutoModelForCausalLM"),tjt.forEach(t),mJe.forEach(t),tHe=i(f),sr=n(f,"DIV",{class:!0});var Ol=s(sr);T(Jx.$$.fragment,Ol),ZAr=i(Ol),Cc=n(Ol,"P",{});var ine=s(Cc);e7r=r(ine,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),lK=n(ine,"A",{href:!0});var ajt=s(lK);o7r=r(ajt,"from_pretrained()"),ajt.forEach(t),r7r=r(ine," class method or the "),iK=n(ine,"A",{href:!0});var njt=s(iK);t7r=r(njt,"from_config()"),njt.forEach(t),a7r=r(ine,` class
method.`),ine.forEach(t),n7r=i(Ol),Yx=n(Ol,"P",{});var gJe=s(Yx);s7r=r(gJe,"This class cannot be instantiated directly using "),zEe=n(gJe,"CODE",{});var sjt=s(zEe);l7r=r(sjt,"__init__()"),sjt.forEach(t),i7r=r(gJe," (throws an error)."),gJe.forEach(t),d7r=i(Ol),qt=n(Ol,"DIV",{class:!0});var J7=s(qt);T(Kx.$$.fragment,J7),c7r=i(J7),WEe=n(J7,"P",{});var ljt=s(WEe);f7r=r(ljt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ljt.forEach(t),m7r=i(J7),wc=n(J7,"P",{});var dne=s(wc);g7r=r(dne,`Note:
Loading a model from its configuration file does `),QEe=n(dne,"STRONG",{});var ijt=s(QEe);h7r=r(ijt,"not"),ijt.forEach(t),p7r=r(dne,` load the model weights. It only affects the
model\u2019s configuration. Use `),dK=n(dne,"A",{href:!0});var djt=s(dK);_7r=r(djt,"from_pretrained()"),djt.forEach(t),u7r=r(dne," to load the model weights."),dne.forEach(t),b7r=i(J7),T(A4.$$.fragment,J7),J7.forEach(t),v7r=i(Ol),Pr=n(Ol,"DIV",{class:!0});var Vl=s(Pr);T(Zx.$$.fragment,Vl),F7r=i(Vl),HEe=n(Vl,"P",{});var cjt=s(HEe);T7r=r(cjt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),cjt.forEach(t),M7r=i(Vl),pn=n(Vl,"P",{});var Y7=s(pn);E7r=r(Y7,"The model class to instantiate is selected based on the "),UEe=n(Y7,"CODE",{});var fjt=s(UEe);C7r=r(fjt,"model_type"),fjt.forEach(t),w7r=r(Y7,` property of the config object (either
passed as an argument or loaded from `),JEe=n(Y7,"CODE",{});var mjt=s(JEe);A7r=r(mjt,"pretrained_model_name_or_path"),mjt.forEach(t),L7r=r(Y7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),YEe=n(Y7,"CODE",{});var gjt=s(YEe);y7r=r(gjt,"pretrained_model_name_or_path"),gjt.forEach(t),x7r=r(Y7,":"),Y7.forEach(t),$7r=i(Vl),Me=n(Vl,"UL",{});var Ce=s(Me);L4=n(Ce,"LI",{});var dOe=s(L4);KEe=n(dOe,"STRONG",{});var hjt=s(KEe);k7r=r(hjt,"bert"),hjt.forEach(t),S7r=r(dOe," \u2014 "),cK=n(dOe,"A",{href:!0});var pjt=s(cK);R7r=r(pjt,"TFBertLMHeadModel"),pjt.forEach(t),P7r=r(dOe," (BERT model)"),dOe.forEach(t),B7r=i(Ce),y4=n(Ce,"LI",{});var cOe=s(y4);ZEe=n(cOe,"STRONG",{});var _jt=s(ZEe);I7r=r(_jt,"camembert"),_jt.forEach(t),N7r=r(cOe," \u2014 "),fK=n(cOe,"A",{href:!0});var ujt=s(fK);q7r=r(ujt,"TFCamembertForCausalLM"),ujt.forEach(t),j7r=r(cOe," (CamemBERT model)"),cOe.forEach(t),D7r=i(Ce),x4=n(Ce,"LI",{});var fOe=s(x4);e4e=n(fOe,"STRONG",{});var bjt=s(e4e);G7r=r(bjt,"ctrl"),bjt.forEach(t),O7r=r(fOe," \u2014 "),mK=n(fOe,"A",{href:!0});var vjt=s(mK);V7r=r(vjt,"TFCTRLLMHeadModel"),vjt.forEach(t),X7r=r(fOe," (CTRL model)"),fOe.forEach(t),z7r=i(Ce),$4=n(Ce,"LI",{});var mOe=s($4);o4e=n(mOe,"STRONG",{});var Fjt=s(o4e);W7r=r(Fjt,"gpt2"),Fjt.forEach(t),Q7r=r(mOe," \u2014 "),gK=n(mOe,"A",{href:!0});var Tjt=s(gK);H7r=r(Tjt,"TFGPT2LMHeadModel"),Tjt.forEach(t),U7r=r(mOe," (OpenAI GPT-2 model)"),mOe.forEach(t),J7r=i(Ce),k4=n(Ce,"LI",{});var gOe=s(k4);r4e=n(gOe,"STRONG",{});var Mjt=s(r4e);Y7r=r(Mjt,"gptj"),Mjt.forEach(t),K7r=r(gOe," \u2014 "),hK=n(gOe,"A",{href:!0});var Ejt=s(hK);Z7r=r(Ejt,"TFGPTJForCausalLM"),Ejt.forEach(t),eLr=r(gOe," (GPT-J model)"),gOe.forEach(t),oLr=i(Ce),S4=n(Ce,"LI",{});var hOe=s(S4);t4e=n(hOe,"STRONG",{});var Cjt=s(t4e);rLr=r(Cjt,"openai-gpt"),Cjt.forEach(t),tLr=r(hOe," \u2014 "),pK=n(hOe,"A",{href:!0});var wjt=s(pK);aLr=r(wjt,"TFOpenAIGPTLMHeadModel"),wjt.forEach(t),nLr=r(hOe," (OpenAI GPT model)"),hOe.forEach(t),sLr=i(Ce),R4=n(Ce,"LI",{});var pOe=s(R4);a4e=n(pOe,"STRONG",{});var Ajt=s(a4e);lLr=r(Ajt,"opt"),Ajt.forEach(t),iLr=r(pOe," \u2014 "),_K=n(pOe,"A",{href:!0});var Ljt=s(_K);dLr=r(Ljt,"TFOPTForCausalLM"),Ljt.forEach(t),cLr=r(pOe," (OPT model)"),pOe.forEach(t),fLr=i(Ce),P4=n(Ce,"LI",{});var _Oe=s(P4);n4e=n(_Oe,"STRONG",{});var yjt=s(n4e);mLr=r(yjt,"rembert"),yjt.forEach(t),gLr=r(_Oe," \u2014 "),uK=n(_Oe,"A",{href:!0});var xjt=s(uK);hLr=r(xjt,"TFRemBertForCausalLM"),xjt.forEach(t),pLr=r(_Oe," (RemBERT model)"),_Oe.forEach(t),_Lr=i(Ce),B4=n(Ce,"LI",{});var uOe=s(B4);s4e=n(uOe,"STRONG",{});var $jt=s(s4e);uLr=r($jt,"roberta"),$jt.forEach(t),bLr=r(uOe," \u2014 "),bK=n(uOe,"A",{href:!0});var kjt=s(bK);vLr=r(kjt,"TFRobertaForCausalLM"),kjt.forEach(t),FLr=r(uOe," (RoBERTa model)"),uOe.forEach(t),TLr=i(Ce),I4=n(Ce,"LI",{});var bOe=s(I4);l4e=n(bOe,"STRONG",{});var Sjt=s(l4e);MLr=r(Sjt,"roformer"),Sjt.forEach(t),ELr=r(bOe," \u2014 "),vK=n(bOe,"A",{href:!0});var Rjt=s(vK);CLr=r(Rjt,"TFRoFormerForCausalLM"),Rjt.forEach(t),wLr=r(bOe," (RoFormer model)"),bOe.forEach(t),ALr=i(Ce),N4=n(Ce,"LI",{});var vOe=s(N4);i4e=n(vOe,"STRONG",{});var Pjt=s(i4e);LLr=r(Pjt,"transfo-xl"),Pjt.forEach(t),yLr=r(vOe," \u2014 "),FK=n(vOe,"A",{href:!0});var Bjt=s(FK);xLr=r(Bjt,"TFTransfoXLLMHeadModel"),Bjt.forEach(t),$Lr=r(vOe," (Transformer-XL model)"),vOe.forEach(t),kLr=i(Ce),q4=n(Ce,"LI",{});var FOe=s(q4);d4e=n(FOe,"STRONG",{});var Ijt=s(d4e);SLr=r(Ijt,"xlm"),Ijt.forEach(t),RLr=r(FOe," \u2014 "),TK=n(FOe,"A",{href:!0});var Njt=s(TK);PLr=r(Njt,"TFXLMWithLMHeadModel"),Njt.forEach(t),BLr=r(FOe," (XLM model)"),FOe.forEach(t),ILr=i(Ce),j4=n(Ce,"LI",{});var TOe=s(j4);c4e=n(TOe,"STRONG",{});var qjt=s(c4e);NLr=r(qjt,"xlnet"),qjt.forEach(t),qLr=r(TOe," \u2014 "),MK=n(TOe,"A",{href:!0});var jjt=s(MK);jLr=r(jjt,"TFXLNetLMHeadModel"),jjt.forEach(t),DLr=r(TOe," (XLNet model)"),TOe.forEach(t),Ce.forEach(t),GLr=i(Vl),T(D4.$$.fragment,Vl),Vl.forEach(t),Ol.forEach(t),aHe=i(f),Ac=n(f,"H2",{class:!0});var hJe=s(Ac);G4=n(hJe,"A",{id:!0,class:!0,href:!0});var Djt=s(G4);f4e=n(Djt,"SPAN",{});var Gjt=s(f4e);T(e$.$$.fragment,Gjt),Gjt.forEach(t),Djt.forEach(t),OLr=i(hJe),m4e=n(hJe,"SPAN",{});var Ojt=s(m4e);VLr=r(Ojt,"TFAutoModelForImageClassification"),Ojt.forEach(t),hJe.forEach(t),nHe=i(f),lr=n(f,"DIV",{class:!0});var Xl=s(lr);T(o$.$$.fragment,Xl),XLr=i(Xl),Lc=n(Xl,"P",{});var cne=s(Lc);zLr=r(cne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),EK=n(cne,"A",{href:!0});var Vjt=s(EK);WLr=r(Vjt,"from_pretrained()"),Vjt.forEach(t),QLr=r(cne," class method or the "),CK=n(cne,"A",{href:!0});var Xjt=s(CK);HLr=r(Xjt,"from_config()"),Xjt.forEach(t),ULr=r(cne,` class
method.`),cne.forEach(t),JLr=i(Xl),r$=n(Xl,"P",{});var pJe=s(r$);YLr=r(pJe,"This class cannot be instantiated directly using "),g4e=n(pJe,"CODE",{});var zjt=s(g4e);KLr=r(zjt,"__init__()"),zjt.forEach(t),ZLr=r(pJe," (throws an error)."),pJe.forEach(t),eyr=i(Xl),jt=n(Xl,"DIV",{class:!0});var K7=s(jt);T(t$.$$.fragment,K7),oyr=i(K7),h4e=n(K7,"P",{});var Wjt=s(h4e);ryr=r(Wjt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Wjt.forEach(t),tyr=i(K7),yc=n(K7,"P",{});var fne=s(yc);ayr=r(fne,`Note:
Loading a model from its configuration file does `),p4e=n(fne,"STRONG",{});var Qjt=s(p4e);nyr=r(Qjt,"not"),Qjt.forEach(t),syr=r(fne,` load the model weights. It only affects the
model\u2019s configuration. Use `),wK=n(fne,"A",{href:!0});var Hjt=s(wK);lyr=r(Hjt,"from_pretrained()"),Hjt.forEach(t),iyr=r(fne," to load the model weights."),fne.forEach(t),dyr=i(K7),T(O4.$$.fragment,K7),K7.forEach(t),cyr=i(Xl),Br=n(Xl,"DIV",{class:!0});var zl=s(Br);T(a$.$$.fragment,zl),fyr=i(zl),_4e=n(zl,"P",{});var Ujt=s(_4e);myr=r(Ujt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ujt.forEach(t),gyr=i(zl),_n=n(zl,"P",{});var Z7=s(_n);hyr=r(Z7,"The model class to instantiate is selected based on the "),u4e=n(Z7,"CODE",{});var Jjt=s(u4e);pyr=r(Jjt,"model_type"),Jjt.forEach(t),_yr=r(Z7,` property of the config object (either
passed as an argument or loaded from `),b4e=n(Z7,"CODE",{});var Yjt=s(b4e);uyr=r(Yjt,"pretrained_model_name_or_path"),Yjt.forEach(t),byr=r(Z7,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),v4e=n(Z7,"CODE",{});var Kjt=s(v4e);vyr=r(Kjt,"pretrained_model_name_or_path"),Kjt.forEach(t),Fyr=r(Z7,":"),Z7.forEach(t),Tyr=i(zl),Ve=n(zl,"UL",{});var Eo=s(Ve);V4=n(Eo,"LI",{});var MOe=s(V4);F4e=n(MOe,"STRONG",{});var Zjt=s(F4e);Myr=r(Zjt,"convnext"),Zjt.forEach(t),Eyr=r(MOe," \u2014 "),AK=n(MOe,"A",{href:!0});var eDt=s(AK);Cyr=r(eDt,"TFConvNextForImageClassification"),eDt.forEach(t),wyr=r(MOe," (ConvNeXT model)"),MOe.forEach(t),Ayr=i(Eo),X4=n(Eo,"LI",{});var EOe=s(X4);T4e=n(EOe,"STRONG",{});var oDt=s(T4e);Lyr=r(oDt,"data2vec-vision"),oDt.forEach(t),yyr=r(EOe," \u2014 "),LK=n(EOe,"A",{href:!0});var rDt=s(LK);xyr=r(rDt,"TFData2VecVisionForImageClassification"),rDt.forEach(t),$yr=r(EOe," (Data2VecVision model)"),EOe.forEach(t),kyr=i(Eo),nl=n(Eo,"LI",{});var kR=s(nl);M4e=n(kR,"STRONG",{});var tDt=s(M4e);Syr=r(tDt,"deit"),tDt.forEach(t),Ryr=r(kR," \u2014 "),yK=n(kR,"A",{href:!0});var aDt=s(yK);Pyr=r(aDt,"TFDeiTForImageClassification"),aDt.forEach(t),Byr=r(kR," or "),xK=n(kR,"A",{href:!0});var nDt=s(xK);Iyr=r(nDt,"TFDeiTForImageClassificationWithTeacher"),nDt.forEach(t),Nyr=r(kR," (DeiT model)"),kR.forEach(t),qyr=i(Eo),z4=n(Eo,"LI",{});var COe=s(z4);E4e=n(COe,"STRONG",{});var sDt=s(E4e);jyr=r(sDt,"regnet"),sDt.forEach(t),Dyr=r(COe," \u2014 "),$K=n(COe,"A",{href:!0});var lDt=s($K);Gyr=r(lDt,"TFRegNetForImageClassification"),lDt.forEach(t),Oyr=r(COe," (RegNet model)"),COe.forEach(t),Vyr=i(Eo),W4=n(Eo,"LI",{});var wOe=s(W4);C4e=n(wOe,"STRONG",{});var iDt=s(C4e);Xyr=r(iDt,"resnet"),iDt.forEach(t),zyr=r(wOe," \u2014 "),kK=n(wOe,"A",{href:!0});var dDt=s(kK);Wyr=r(dDt,"TFResNetForImageClassification"),dDt.forEach(t),Qyr=r(wOe," (ResNet model)"),wOe.forEach(t),Hyr=i(Eo),Q4=n(Eo,"LI",{});var AOe=s(Q4);w4e=n(AOe,"STRONG",{});var cDt=s(w4e);Uyr=r(cDt,"segformer"),cDt.forEach(t),Jyr=r(AOe," \u2014 "),SK=n(AOe,"A",{href:!0});var fDt=s(SK);Yyr=r(fDt,"TFSegformerForImageClassification"),fDt.forEach(t),Kyr=r(AOe," (SegFormer model)"),AOe.forEach(t),Zyr=i(Eo),H4=n(Eo,"LI",{});var LOe=s(H4);A4e=n(LOe,"STRONG",{});var mDt=s(A4e);e9r=r(mDt,"swin"),mDt.forEach(t),o9r=r(LOe," \u2014 "),RK=n(LOe,"A",{href:!0});var gDt=s(RK);r9r=r(gDt,"TFSwinForImageClassification"),gDt.forEach(t),t9r=r(LOe," (Swin Transformer model)"),LOe.forEach(t),a9r=i(Eo),U4=n(Eo,"LI",{});var yOe=s(U4);L4e=n(yOe,"STRONG",{});var hDt=s(L4e);n9r=r(hDt,"vit"),hDt.forEach(t),s9r=r(yOe," \u2014 "),PK=n(yOe,"A",{href:!0});var pDt=s(PK);l9r=r(pDt,"TFViTForImageClassification"),pDt.forEach(t),i9r=r(yOe," (ViT model)"),yOe.forEach(t),Eo.forEach(t),d9r=i(zl),T(J4.$$.fragment,zl),zl.forEach(t),Xl.forEach(t),sHe=i(f),xc=n(f,"H2",{class:!0});var _Je=s(xc);Y4=n(_Je,"A",{id:!0,class:!0,href:!0});var _Dt=s(Y4);y4e=n(_Dt,"SPAN",{});var uDt=s(y4e);T(n$.$$.fragment,uDt),uDt.forEach(t),_Dt.forEach(t),c9r=i(_Je),x4e=n(_Je,"SPAN",{});var bDt=s(x4e);f9r=r(bDt,"TFAutoModelForMaskedLM"),bDt.forEach(t),_Je.forEach(t),lHe=i(f),ir=n(f,"DIV",{class:!0});var Wl=s(ir);T(s$.$$.fragment,Wl),m9r=i(Wl),$c=n(Wl,"P",{});var mne=s($c);g9r=r(mne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),BK=n(mne,"A",{href:!0});var vDt=s(BK);h9r=r(vDt,"from_pretrained()"),vDt.forEach(t),p9r=r(mne," class method or the "),IK=n(mne,"A",{href:!0});var FDt=s(IK);_9r=r(FDt,"from_config()"),FDt.forEach(t),u9r=r(mne,` class
method.`),mne.forEach(t),b9r=i(Wl),l$=n(Wl,"P",{});var uJe=s(l$);v9r=r(uJe,"This class cannot be instantiated directly using "),$4e=n(uJe,"CODE",{});var TDt=s($4e);F9r=r(TDt,"__init__()"),TDt.forEach(t),T9r=r(uJe," (throws an error)."),uJe.forEach(t),M9r=i(Wl),Dt=n(Wl,"DIV",{class:!0});var eL=s(Dt);T(i$.$$.fragment,eL),E9r=i(eL),k4e=n(eL,"P",{});var MDt=s(k4e);C9r=r(MDt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),MDt.forEach(t),w9r=i(eL),kc=n(eL,"P",{});var gne=s(kc);A9r=r(gne,`Note:
Loading a model from its configuration file does `),S4e=n(gne,"STRONG",{});var EDt=s(S4e);L9r=r(EDt,"not"),EDt.forEach(t),y9r=r(gne,` load the model weights. It only affects the
model\u2019s configuration. Use `),NK=n(gne,"A",{href:!0});var CDt=s(NK);x9r=r(CDt,"from_pretrained()"),CDt.forEach(t),$9r=r(gne," to load the model weights."),gne.forEach(t),k9r=i(eL),T(K4.$$.fragment,eL),eL.forEach(t),S9r=i(Wl),Ir=n(Wl,"DIV",{class:!0});var Ql=s(Ir);T(d$.$$.fragment,Ql),R9r=i(Ql),R4e=n(Ql,"P",{});var wDt=s(R4e);P9r=r(wDt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),wDt.forEach(t),B9r=i(Ql),un=n(Ql,"P",{});var oL=s(un);I9r=r(oL,"The model class to instantiate is selected based on the "),P4e=n(oL,"CODE",{});var ADt=s(P4e);N9r=r(ADt,"model_type"),ADt.forEach(t),q9r=r(oL,` property of the config object (either
passed as an argument or loaded from `),B4e=n(oL,"CODE",{});var LDt=s(B4e);j9r=r(LDt,"pretrained_model_name_or_path"),LDt.forEach(t),D9r=r(oL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=n(oL,"CODE",{});var yDt=s(I4e);G9r=r(yDt,"pretrained_model_name_or_path"),yDt.forEach(t),O9r=r(oL,":"),oL.forEach(t),V9r=i(Ql),ie=n(Ql,"UL",{});var ge=s(ie);Z4=n(ge,"LI",{});var xOe=s(Z4);N4e=n(xOe,"STRONG",{});var xDt=s(N4e);X9r=r(xDt,"albert"),xDt.forEach(t),z9r=r(xOe," \u2014 "),qK=n(xOe,"A",{href:!0});var $Dt=s(qK);W9r=r($Dt,"TFAlbertForMaskedLM"),$Dt.forEach(t),Q9r=r(xOe," (ALBERT model)"),xOe.forEach(t),H9r=i(ge),eC=n(ge,"LI",{});var $Oe=s(eC);q4e=n($Oe,"STRONG",{});var kDt=s(q4e);U9r=r(kDt,"bert"),kDt.forEach(t),J9r=r($Oe," \u2014 "),jK=n($Oe,"A",{href:!0});var SDt=s(jK);Y9r=r(SDt,"TFBertForMaskedLM"),SDt.forEach(t),K9r=r($Oe," (BERT model)"),$Oe.forEach(t),Z9r=i(ge),oC=n(ge,"LI",{});var kOe=s(oC);j4e=n(kOe,"STRONG",{});var RDt=s(j4e);exr=r(RDt,"camembert"),RDt.forEach(t),oxr=r(kOe," \u2014 "),DK=n(kOe,"A",{href:!0});var PDt=s(DK);rxr=r(PDt,"TFCamembertForMaskedLM"),PDt.forEach(t),txr=r(kOe," (CamemBERT model)"),kOe.forEach(t),axr=i(ge),rC=n(ge,"LI",{});var SOe=s(rC);D4e=n(SOe,"STRONG",{});var BDt=s(D4e);nxr=r(BDt,"convbert"),BDt.forEach(t),sxr=r(SOe," \u2014 "),GK=n(SOe,"A",{href:!0});var IDt=s(GK);lxr=r(IDt,"TFConvBertForMaskedLM"),IDt.forEach(t),ixr=r(SOe," (ConvBERT model)"),SOe.forEach(t),dxr=i(ge),tC=n(ge,"LI",{});var ROe=s(tC);G4e=n(ROe,"STRONG",{});var NDt=s(G4e);cxr=r(NDt,"deberta"),NDt.forEach(t),fxr=r(ROe," \u2014 "),OK=n(ROe,"A",{href:!0});var qDt=s(OK);mxr=r(qDt,"TFDebertaForMaskedLM"),qDt.forEach(t),gxr=r(ROe," (DeBERTa model)"),ROe.forEach(t),hxr=i(ge),aC=n(ge,"LI",{});var POe=s(aC);O4e=n(POe,"STRONG",{});var jDt=s(O4e);pxr=r(jDt,"deberta-v2"),jDt.forEach(t),_xr=r(POe," \u2014 "),VK=n(POe,"A",{href:!0});var DDt=s(VK);uxr=r(DDt,"TFDebertaV2ForMaskedLM"),DDt.forEach(t),bxr=r(POe," (DeBERTa-v2 model)"),POe.forEach(t),vxr=i(ge),nC=n(ge,"LI",{});var BOe=s(nC);V4e=n(BOe,"STRONG",{});var GDt=s(V4e);Fxr=r(GDt,"distilbert"),GDt.forEach(t),Txr=r(BOe," \u2014 "),XK=n(BOe,"A",{href:!0});var ODt=s(XK);Mxr=r(ODt,"TFDistilBertForMaskedLM"),ODt.forEach(t),Exr=r(BOe," (DistilBERT model)"),BOe.forEach(t),Cxr=i(ge),sC=n(ge,"LI",{});var IOe=s(sC);X4e=n(IOe,"STRONG",{});var VDt=s(X4e);wxr=r(VDt,"electra"),VDt.forEach(t),Axr=r(IOe," \u2014 "),zK=n(IOe,"A",{href:!0});var XDt=s(zK);Lxr=r(XDt,"TFElectraForMaskedLM"),XDt.forEach(t),yxr=r(IOe," (ELECTRA model)"),IOe.forEach(t),xxr=i(ge),lC=n(ge,"LI",{});var NOe=s(lC);z4e=n(NOe,"STRONG",{});var zDt=s(z4e);$xr=r(zDt,"flaubert"),zDt.forEach(t),kxr=r(NOe," \u2014 "),WK=n(NOe,"A",{href:!0});var WDt=s(WK);Sxr=r(WDt,"TFFlaubertWithLMHeadModel"),WDt.forEach(t),Rxr=r(NOe," (FlauBERT model)"),NOe.forEach(t),Pxr=i(ge),iC=n(ge,"LI",{});var qOe=s(iC);W4e=n(qOe,"STRONG",{});var QDt=s(W4e);Bxr=r(QDt,"funnel"),QDt.forEach(t),Ixr=r(qOe," \u2014 "),QK=n(qOe,"A",{href:!0});var HDt=s(QK);Nxr=r(HDt,"TFFunnelForMaskedLM"),HDt.forEach(t),qxr=r(qOe," (Funnel Transformer model)"),qOe.forEach(t),jxr=i(ge),dC=n(ge,"LI",{});var jOe=s(dC);Q4e=n(jOe,"STRONG",{});var UDt=s(Q4e);Dxr=r(UDt,"layoutlm"),UDt.forEach(t),Gxr=r(jOe," \u2014 "),HK=n(jOe,"A",{href:!0});var JDt=s(HK);Oxr=r(JDt,"TFLayoutLMForMaskedLM"),JDt.forEach(t),Vxr=r(jOe," (LayoutLM model)"),jOe.forEach(t),Xxr=i(ge),cC=n(ge,"LI",{});var DOe=s(cC);H4e=n(DOe,"STRONG",{});var YDt=s(H4e);zxr=r(YDt,"longformer"),YDt.forEach(t),Wxr=r(DOe," \u2014 "),UK=n(DOe,"A",{href:!0});var KDt=s(UK);Qxr=r(KDt,"TFLongformerForMaskedLM"),KDt.forEach(t),Hxr=r(DOe," (Longformer model)"),DOe.forEach(t),Uxr=i(ge),fC=n(ge,"LI",{});var GOe=s(fC);U4e=n(GOe,"STRONG",{});var ZDt=s(U4e);Jxr=r(ZDt,"mobilebert"),ZDt.forEach(t),Yxr=r(GOe," \u2014 "),JK=n(GOe,"A",{href:!0});var eGt=s(JK);Kxr=r(eGt,"TFMobileBertForMaskedLM"),eGt.forEach(t),Zxr=r(GOe," (MobileBERT model)"),GOe.forEach(t),e$r=i(ge),mC=n(ge,"LI",{});var OOe=s(mC);J4e=n(OOe,"STRONG",{});var oGt=s(J4e);o$r=r(oGt,"mpnet"),oGt.forEach(t),r$r=r(OOe," \u2014 "),YK=n(OOe,"A",{href:!0});var rGt=s(YK);t$r=r(rGt,"TFMPNetForMaskedLM"),rGt.forEach(t),a$r=r(OOe," (MPNet model)"),OOe.forEach(t),n$r=i(ge),gC=n(ge,"LI",{});var VOe=s(gC);Y4e=n(VOe,"STRONG",{});var tGt=s(Y4e);s$r=r(tGt,"rembert"),tGt.forEach(t),l$r=r(VOe," \u2014 "),KK=n(VOe,"A",{href:!0});var aGt=s(KK);i$r=r(aGt,"TFRemBertForMaskedLM"),aGt.forEach(t),d$r=r(VOe," (RemBERT model)"),VOe.forEach(t),c$r=i(ge),hC=n(ge,"LI",{});var XOe=s(hC);K4e=n(XOe,"STRONG",{});var nGt=s(K4e);f$r=r(nGt,"roberta"),nGt.forEach(t),m$r=r(XOe," \u2014 "),ZK=n(XOe,"A",{href:!0});var sGt=s(ZK);g$r=r(sGt,"TFRobertaForMaskedLM"),sGt.forEach(t),h$r=r(XOe," (RoBERTa model)"),XOe.forEach(t),p$r=i(ge),pC=n(ge,"LI",{});var zOe=s(pC);Z4e=n(zOe,"STRONG",{});var lGt=s(Z4e);_$r=r(lGt,"roformer"),lGt.forEach(t),u$r=r(zOe," \u2014 "),eZ=n(zOe,"A",{href:!0});var iGt=s(eZ);b$r=r(iGt,"TFRoFormerForMaskedLM"),iGt.forEach(t),v$r=r(zOe," (RoFormer model)"),zOe.forEach(t),F$r=i(ge),_C=n(ge,"LI",{});var WOe=s(_C);eCe=n(WOe,"STRONG",{});var dGt=s(eCe);T$r=r(dGt,"tapas"),dGt.forEach(t),M$r=r(WOe," \u2014 "),oZ=n(WOe,"A",{href:!0});var cGt=s(oZ);E$r=r(cGt,"TFTapasForMaskedLM"),cGt.forEach(t),C$r=r(WOe," (TAPAS model)"),WOe.forEach(t),w$r=i(ge),uC=n(ge,"LI",{});var QOe=s(uC);oCe=n(QOe,"STRONG",{});var fGt=s(oCe);A$r=r(fGt,"xlm"),fGt.forEach(t),L$r=r(QOe," \u2014 "),rZ=n(QOe,"A",{href:!0});var mGt=s(rZ);y$r=r(mGt,"TFXLMWithLMHeadModel"),mGt.forEach(t),x$r=r(QOe," (XLM model)"),QOe.forEach(t),$$r=i(ge),bC=n(ge,"LI",{});var HOe=s(bC);rCe=n(HOe,"STRONG",{});var gGt=s(rCe);k$r=r(gGt,"xlm-roberta"),gGt.forEach(t),S$r=r(HOe," \u2014 "),tZ=n(HOe,"A",{href:!0});var hGt=s(tZ);R$r=r(hGt,"TFXLMRobertaForMaskedLM"),hGt.forEach(t),P$r=r(HOe," (XLM-RoBERTa model)"),HOe.forEach(t),ge.forEach(t),B$r=i(Ql),T(vC.$$.fragment,Ql),Ql.forEach(t),Wl.forEach(t),iHe=i(f),Sc=n(f,"H2",{class:!0});var bJe=s(Sc);FC=n(bJe,"A",{id:!0,class:!0,href:!0});var pGt=s(FC);tCe=n(pGt,"SPAN",{});var _Gt=s(tCe);T(c$.$$.fragment,_Gt),_Gt.forEach(t),pGt.forEach(t),I$r=i(bJe),aCe=n(bJe,"SPAN",{});var uGt=s(aCe);N$r=r(uGt,"TFAutoModelForSeq2SeqLM"),uGt.forEach(t),bJe.forEach(t),dHe=i(f),dr=n(f,"DIV",{class:!0});var Hl=s(dr);T(f$.$$.fragment,Hl),q$r=i(Hl),Rc=n(Hl,"P",{});var hne=s(Rc);j$r=r(hne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),aZ=n(hne,"A",{href:!0});var bGt=s(aZ);D$r=r(bGt,"from_pretrained()"),bGt.forEach(t),G$r=r(hne," class method or the "),nZ=n(hne,"A",{href:!0});var vGt=s(nZ);O$r=r(vGt,"from_config()"),vGt.forEach(t),V$r=r(hne,` class
method.`),hne.forEach(t),X$r=i(Hl),m$=n(Hl,"P",{});var vJe=s(m$);z$r=r(vJe,"This class cannot be instantiated directly using "),nCe=n(vJe,"CODE",{});var FGt=s(nCe);W$r=r(FGt,"__init__()"),FGt.forEach(t),Q$r=r(vJe," (throws an error)."),vJe.forEach(t),H$r=i(Hl),Gt=n(Hl,"DIV",{class:!0});var rL=s(Gt);T(g$.$$.fragment,rL),U$r=i(rL),sCe=n(rL,"P",{});var TGt=s(sCe);J$r=r(TGt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),TGt.forEach(t),Y$r=i(rL),Pc=n(rL,"P",{});var pne=s(Pc);K$r=r(pne,`Note:
Loading a model from its configuration file does `),lCe=n(pne,"STRONG",{});var MGt=s(lCe);Z$r=r(MGt,"not"),MGt.forEach(t),ekr=r(pne,` load the model weights. It only affects the
model\u2019s configuration. Use `),sZ=n(pne,"A",{href:!0});var EGt=s(sZ);okr=r(EGt,"from_pretrained()"),EGt.forEach(t),rkr=r(pne," to load the model weights."),pne.forEach(t),tkr=i(rL),T(TC.$$.fragment,rL),rL.forEach(t),akr=i(Hl),Nr=n(Hl,"DIV",{class:!0});var Ul=s(Nr);T(h$.$$.fragment,Ul),nkr=i(Ul),iCe=n(Ul,"P",{});var CGt=s(iCe);skr=r(CGt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),CGt.forEach(t),lkr=i(Ul),bn=n(Ul,"P",{});var tL=s(bn);ikr=r(tL,"The model class to instantiate is selected based on the "),dCe=n(tL,"CODE",{});var wGt=s(dCe);dkr=r(wGt,"model_type"),wGt.forEach(t),ckr=r(tL,` property of the config object (either
passed as an argument or loaded from `),cCe=n(tL,"CODE",{});var AGt=s(cCe);fkr=r(AGt,"pretrained_model_name_or_path"),AGt.forEach(t),mkr=r(tL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fCe=n(tL,"CODE",{});var LGt=s(fCe);gkr=r(LGt,"pretrained_model_name_or_path"),LGt.forEach(t),hkr=r(tL,":"),tL.forEach(t),pkr=i(Ul),xe=n(Ul,"UL",{});var Ne=s(xe);MC=n(Ne,"LI",{});var UOe=s(MC);mCe=n(UOe,"STRONG",{});var yGt=s(mCe);_kr=r(yGt,"bart"),yGt.forEach(t),ukr=r(UOe," \u2014 "),lZ=n(UOe,"A",{href:!0});var xGt=s(lZ);bkr=r(xGt,"TFBartForConditionalGeneration"),xGt.forEach(t),vkr=r(UOe," (BART model)"),UOe.forEach(t),Fkr=i(Ne),EC=n(Ne,"LI",{});var JOe=s(EC);gCe=n(JOe,"STRONG",{});var $Gt=s(gCe);Tkr=r($Gt,"blenderbot"),$Gt.forEach(t),Mkr=r(JOe," \u2014 "),iZ=n(JOe,"A",{href:!0});var kGt=s(iZ);Ekr=r(kGt,"TFBlenderbotForConditionalGeneration"),kGt.forEach(t),Ckr=r(JOe," (Blenderbot model)"),JOe.forEach(t),wkr=i(Ne),CC=n(Ne,"LI",{});var YOe=s(CC);hCe=n(YOe,"STRONG",{});var SGt=s(hCe);Akr=r(SGt,"blenderbot-small"),SGt.forEach(t),Lkr=r(YOe," \u2014 "),dZ=n(YOe,"A",{href:!0});var RGt=s(dZ);ykr=r(RGt,"TFBlenderbotSmallForConditionalGeneration"),RGt.forEach(t),xkr=r(YOe," (BlenderbotSmall model)"),YOe.forEach(t),$kr=i(Ne),wC=n(Ne,"LI",{});var KOe=s(wC);pCe=n(KOe,"STRONG",{});var PGt=s(pCe);kkr=r(PGt,"encoder-decoder"),PGt.forEach(t),Skr=r(KOe," \u2014 "),cZ=n(KOe,"A",{href:!0});var BGt=s(cZ);Rkr=r(BGt,"TFEncoderDecoderModel"),BGt.forEach(t),Pkr=r(KOe," (Encoder decoder model)"),KOe.forEach(t),Bkr=i(Ne),AC=n(Ne,"LI",{});var ZOe=s(AC);_Ce=n(ZOe,"STRONG",{});var IGt=s(_Ce);Ikr=r(IGt,"led"),IGt.forEach(t),Nkr=r(ZOe," \u2014 "),fZ=n(ZOe,"A",{href:!0});var NGt=s(fZ);qkr=r(NGt,"TFLEDForConditionalGeneration"),NGt.forEach(t),jkr=r(ZOe," (LED model)"),ZOe.forEach(t),Dkr=i(Ne),LC=n(Ne,"LI",{});var eVe=s(LC);uCe=n(eVe,"STRONG",{});var qGt=s(uCe);Gkr=r(qGt,"marian"),qGt.forEach(t),Okr=r(eVe," \u2014 "),mZ=n(eVe,"A",{href:!0});var jGt=s(mZ);Vkr=r(jGt,"TFMarianMTModel"),jGt.forEach(t),Xkr=r(eVe," (Marian model)"),eVe.forEach(t),zkr=i(Ne),yC=n(Ne,"LI",{});var oVe=s(yC);bCe=n(oVe,"STRONG",{});var DGt=s(bCe);Wkr=r(DGt,"mbart"),DGt.forEach(t),Qkr=r(oVe," \u2014 "),gZ=n(oVe,"A",{href:!0});var GGt=s(gZ);Hkr=r(GGt,"TFMBartForConditionalGeneration"),GGt.forEach(t),Ukr=r(oVe," (mBART model)"),oVe.forEach(t),Jkr=i(Ne),xC=n(Ne,"LI",{});var rVe=s(xC);vCe=n(rVe,"STRONG",{});var OGt=s(vCe);Ykr=r(OGt,"mt5"),OGt.forEach(t),Kkr=r(rVe," \u2014 "),hZ=n(rVe,"A",{href:!0});var VGt=s(hZ);Zkr=r(VGt,"TFMT5ForConditionalGeneration"),VGt.forEach(t),eSr=r(rVe," (MT5 model)"),rVe.forEach(t),oSr=i(Ne),$C=n(Ne,"LI",{});var tVe=s($C);FCe=n(tVe,"STRONG",{});var XGt=s(FCe);rSr=r(XGt,"pegasus"),XGt.forEach(t),tSr=r(tVe," \u2014 "),pZ=n(tVe,"A",{href:!0});var zGt=s(pZ);aSr=r(zGt,"TFPegasusForConditionalGeneration"),zGt.forEach(t),nSr=r(tVe," (Pegasus model)"),tVe.forEach(t),sSr=i(Ne),kC=n(Ne,"LI",{});var aVe=s(kC);TCe=n(aVe,"STRONG",{});var WGt=s(TCe);lSr=r(WGt,"t5"),WGt.forEach(t),iSr=r(aVe," \u2014 "),_Z=n(aVe,"A",{href:!0});var QGt=s(_Z);dSr=r(QGt,"TFT5ForConditionalGeneration"),QGt.forEach(t),cSr=r(aVe," (T5 model)"),aVe.forEach(t),Ne.forEach(t),fSr=i(Ul),T(SC.$$.fragment,Ul),Ul.forEach(t),Hl.forEach(t),cHe=i(f),Bc=n(f,"H2",{class:!0});var FJe=s(Bc);RC=n(FJe,"A",{id:!0,class:!0,href:!0});var HGt=s(RC);MCe=n(HGt,"SPAN",{});var UGt=s(MCe);T(p$.$$.fragment,UGt),UGt.forEach(t),HGt.forEach(t),mSr=i(FJe),ECe=n(FJe,"SPAN",{});var JGt=s(ECe);gSr=r(JGt,"TFAutoModelForSequenceClassification"),JGt.forEach(t),FJe.forEach(t),fHe=i(f),cr=n(f,"DIV",{class:!0});var Jl=s(cr);T(_$.$$.fragment,Jl),hSr=i(Jl),Ic=n(Jl,"P",{});var _ne=s(Ic);pSr=r(_ne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),uZ=n(_ne,"A",{href:!0});var YGt=s(uZ);_Sr=r(YGt,"from_pretrained()"),YGt.forEach(t),uSr=r(_ne," class method or the "),bZ=n(_ne,"A",{href:!0});var KGt=s(bZ);bSr=r(KGt,"from_config()"),KGt.forEach(t),vSr=r(_ne,` class
method.`),_ne.forEach(t),FSr=i(Jl),u$=n(Jl,"P",{});var TJe=s(u$);TSr=r(TJe,"This class cannot be instantiated directly using "),CCe=n(TJe,"CODE",{});var ZGt=s(CCe);MSr=r(ZGt,"__init__()"),ZGt.forEach(t),ESr=r(TJe," (throws an error)."),TJe.forEach(t),CSr=i(Jl),Ot=n(Jl,"DIV",{class:!0});var aL=s(Ot);T(b$.$$.fragment,aL),wSr=i(aL),wCe=n(aL,"P",{});var eOt=s(wCe);ASr=r(eOt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),eOt.forEach(t),LSr=i(aL),Nc=n(aL,"P",{});var une=s(Nc);ySr=r(une,`Note:
Loading a model from its configuration file does `),ACe=n(une,"STRONG",{});var oOt=s(ACe);xSr=r(oOt,"not"),oOt.forEach(t),$Sr=r(une,` load the model weights. It only affects the
model\u2019s configuration. Use `),vZ=n(une,"A",{href:!0});var rOt=s(vZ);kSr=r(rOt,"from_pretrained()"),rOt.forEach(t),SSr=r(une," to load the model weights."),une.forEach(t),RSr=i(aL),T(PC.$$.fragment,aL),aL.forEach(t),PSr=i(Jl),qr=n(Jl,"DIV",{class:!0});var Yl=s(qr);T(v$.$$.fragment,Yl),BSr=i(Yl),LCe=n(Yl,"P",{});var tOt=s(LCe);ISr=r(tOt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),tOt.forEach(t),NSr=i(Yl),vn=n(Yl,"P",{});var nL=s(vn);qSr=r(nL,"The model class to instantiate is selected based on the "),yCe=n(nL,"CODE",{});var aOt=s(yCe);jSr=r(aOt,"model_type"),aOt.forEach(t),DSr=r(nL,` property of the config object (either
passed as an argument or loaded from `),xCe=n(nL,"CODE",{});var nOt=s(xCe);GSr=r(nOt,"pretrained_model_name_or_path"),nOt.forEach(t),OSr=r(nL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ce=n(nL,"CODE",{});var sOt=s($Ce);VSr=r(sOt,"pretrained_model_name_or_path"),sOt.forEach(t),XSr=r(nL,":"),nL.forEach(t),zSr=i(Yl),ae=n(Yl,"UL",{});var ne=s(ae);BC=n(ne,"LI",{});var nVe=s(BC);kCe=n(nVe,"STRONG",{});var lOt=s(kCe);WSr=r(lOt,"albert"),lOt.forEach(t),QSr=r(nVe," \u2014 "),FZ=n(nVe,"A",{href:!0});var iOt=s(FZ);HSr=r(iOt,"TFAlbertForSequenceClassification"),iOt.forEach(t),USr=r(nVe," (ALBERT model)"),nVe.forEach(t),JSr=i(ne),IC=n(ne,"LI",{});var sVe=s(IC);SCe=n(sVe,"STRONG",{});var dOt=s(SCe);YSr=r(dOt,"bert"),dOt.forEach(t),KSr=r(sVe," \u2014 "),TZ=n(sVe,"A",{href:!0});var cOt=s(TZ);ZSr=r(cOt,"TFBertForSequenceClassification"),cOt.forEach(t),eRr=r(sVe," (BERT model)"),sVe.forEach(t),oRr=i(ne),NC=n(ne,"LI",{});var lVe=s(NC);RCe=n(lVe,"STRONG",{});var fOt=s(RCe);rRr=r(fOt,"camembert"),fOt.forEach(t),tRr=r(lVe," \u2014 "),MZ=n(lVe,"A",{href:!0});var mOt=s(MZ);aRr=r(mOt,"TFCamembertForSequenceClassification"),mOt.forEach(t),nRr=r(lVe," (CamemBERT model)"),lVe.forEach(t),sRr=i(ne),qC=n(ne,"LI",{});var iVe=s(qC);PCe=n(iVe,"STRONG",{});var gOt=s(PCe);lRr=r(gOt,"convbert"),gOt.forEach(t),iRr=r(iVe," \u2014 "),EZ=n(iVe,"A",{href:!0});var hOt=s(EZ);dRr=r(hOt,"TFConvBertForSequenceClassification"),hOt.forEach(t),cRr=r(iVe," (ConvBERT model)"),iVe.forEach(t),fRr=i(ne),jC=n(ne,"LI",{});var dVe=s(jC);BCe=n(dVe,"STRONG",{});var pOt=s(BCe);mRr=r(pOt,"ctrl"),pOt.forEach(t),gRr=r(dVe," \u2014 "),CZ=n(dVe,"A",{href:!0});var _Ot=s(CZ);hRr=r(_Ot,"TFCTRLForSequenceClassification"),_Ot.forEach(t),pRr=r(dVe," (CTRL model)"),dVe.forEach(t),_Rr=i(ne),DC=n(ne,"LI",{});var cVe=s(DC);ICe=n(cVe,"STRONG",{});var uOt=s(ICe);uRr=r(uOt,"deberta"),uOt.forEach(t),bRr=r(cVe," \u2014 "),wZ=n(cVe,"A",{href:!0});var bOt=s(wZ);vRr=r(bOt,"TFDebertaForSequenceClassification"),bOt.forEach(t),FRr=r(cVe," (DeBERTa model)"),cVe.forEach(t),TRr=i(ne),GC=n(ne,"LI",{});var fVe=s(GC);NCe=n(fVe,"STRONG",{});var vOt=s(NCe);MRr=r(vOt,"deberta-v2"),vOt.forEach(t),ERr=r(fVe," \u2014 "),AZ=n(fVe,"A",{href:!0});var FOt=s(AZ);CRr=r(FOt,"TFDebertaV2ForSequenceClassification"),FOt.forEach(t),wRr=r(fVe," (DeBERTa-v2 model)"),fVe.forEach(t),ARr=i(ne),OC=n(ne,"LI",{});var mVe=s(OC);qCe=n(mVe,"STRONG",{});var TOt=s(qCe);LRr=r(TOt,"distilbert"),TOt.forEach(t),yRr=r(mVe," \u2014 "),LZ=n(mVe,"A",{href:!0});var MOt=s(LZ);xRr=r(MOt,"TFDistilBertForSequenceClassification"),MOt.forEach(t),$Rr=r(mVe," (DistilBERT model)"),mVe.forEach(t),kRr=i(ne),VC=n(ne,"LI",{});var gVe=s(VC);jCe=n(gVe,"STRONG",{});var EOt=s(jCe);SRr=r(EOt,"electra"),EOt.forEach(t),RRr=r(gVe," \u2014 "),yZ=n(gVe,"A",{href:!0});var COt=s(yZ);PRr=r(COt,"TFElectraForSequenceClassification"),COt.forEach(t),BRr=r(gVe," (ELECTRA model)"),gVe.forEach(t),IRr=i(ne),XC=n(ne,"LI",{});var hVe=s(XC);DCe=n(hVe,"STRONG",{});var wOt=s(DCe);NRr=r(wOt,"flaubert"),wOt.forEach(t),qRr=r(hVe," \u2014 "),xZ=n(hVe,"A",{href:!0});var AOt=s(xZ);jRr=r(AOt,"TFFlaubertForSequenceClassification"),AOt.forEach(t),DRr=r(hVe," (FlauBERT model)"),hVe.forEach(t),GRr=i(ne),zC=n(ne,"LI",{});var pVe=s(zC);GCe=n(pVe,"STRONG",{});var LOt=s(GCe);ORr=r(LOt,"funnel"),LOt.forEach(t),VRr=r(pVe," \u2014 "),$Z=n(pVe,"A",{href:!0});var yOt=s($Z);XRr=r(yOt,"TFFunnelForSequenceClassification"),yOt.forEach(t),zRr=r(pVe," (Funnel Transformer model)"),pVe.forEach(t),WRr=i(ne),WC=n(ne,"LI",{});var _Ve=s(WC);OCe=n(_Ve,"STRONG",{});var xOt=s(OCe);QRr=r(xOt,"gpt2"),xOt.forEach(t),HRr=r(_Ve," \u2014 "),kZ=n(_Ve,"A",{href:!0});var $Ot=s(kZ);URr=r($Ot,"TFGPT2ForSequenceClassification"),$Ot.forEach(t),JRr=r(_Ve," (OpenAI GPT-2 model)"),_Ve.forEach(t),YRr=i(ne),QC=n(ne,"LI",{});var uVe=s(QC);VCe=n(uVe,"STRONG",{});var kOt=s(VCe);KRr=r(kOt,"gptj"),kOt.forEach(t),ZRr=r(uVe," \u2014 "),SZ=n(uVe,"A",{href:!0});var SOt=s(SZ);ePr=r(SOt,"TFGPTJForSequenceClassification"),SOt.forEach(t),oPr=r(uVe," (GPT-J model)"),uVe.forEach(t),rPr=i(ne),HC=n(ne,"LI",{});var bVe=s(HC);XCe=n(bVe,"STRONG",{});var ROt=s(XCe);tPr=r(ROt,"layoutlm"),ROt.forEach(t),aPr=r(bVe," \u2014 "),RZ=n(bVe,"A",{href:!0});var POt=s(RZ);nPr=r(POt,"TFLayoutLMForSequenceClassification"),POt.forEach(t),sPr=r(bVe," (LayoutLM model)"),bVe.forEach(t),lPr=i(ne),UC=n(ne,"LI",{});var vVe=s(UC);zCe=n(vVe,"STRONG",{});var BOt=s(zCe);iPr=r(BOt,"longformer"),BOt.forEach(t),dPr=r(vVe," \u2014 "),PZ=n(vVe,"A",{href:!0});var IOt=s(PZ);cPr=r(IOt,"TFLongformerForSequenceClassification"),IOt.forEach(t),fPr=r(vVe," (Longformer model)"),vVe.forEach(t),mPr=i(ne),JC=n(ne,"LI",{});var FVe=s(JC);WCe=n(FVe,"STRONG",{});var NOt=s(WCe);gPr=r(NOt,"mobilebert"),NOt.forEach(t),hPr=r(FVe," \u2014 "),BZ=n(FVe,"A",{href:!0});var qOt=s(BZ);pPr=r(qOt,"TFMobileBertForSequenceClassification"),qOt.forEach(t),_Pr=r(FVe," (MobileBERT model)"),FVe.forEach(t),uPr=i(ne),YC=n(ne,"LI",{});var TVe=s(YC);QCe=n(TVe,"STRONG",{});var jOt=s(QCe);bPr=r(jOt,"mpnet"),jOt.forEach(t),vPr=r(TVe," \u2014 "),IZ=n(TVe,"A",{href:!0});var DOt=s(IZ);FPr=r(DOt,"TFMPNetForSequenceClassification"),DOt.forEach(t),TPr=r(TVe," (MPNet model)"),TVe.forEach(t),MPr=i(ne),KC=n(ne,"LI",{});var MVe=s(KC);HCe=n(MVe,"STRONG",{});var GOt=s(HCe);EPr=r(GOt,"openai-gpt"),GOt.forEach(t),CPr=r(MVe," \u2014 "),NZ=n(MVe,"A",{href:!0});var OOt=s(NZ);wPr=r(OOt,"TFOpenAIGPTForSequenceClassification"),OOt.forEach(t),APr=r(MVe," (OpenAI GPT model)"),MVe.forEach(t),LPr=i(ne),ZC=n(ne,"LI",{});var EVe=s(ZC);UCe=n(EVe,"STRONG",{});var VOt=s(UCe);yPr=r(VOt,"rembert"),VOt.forEach(t),xPr=r(EVe," \u2014 "),qZ=n(EVe,"A",{href:!0});var XOt=s(qZ);$Pr=r(XOt,"TFRemBertForSequenceClassification"),XOt.forEach(t),kPr=r(EVe," (RemBERT model)"),EVe.forEach(t),SPr=i(ne),e5=n(ne,"LI",{});var CVe=s(e5);JCe=n(CVe,"STRONG",{});var zOt=s(JCe);RPr=r(zOt,"roberta"),zOt.forEach(t),PPr=r(CVe," \u2014 "),jZ=n(CVe,"A",{href:!0});var WOt=s(jZ);BPr=r(WOt,"TFRobertaForSequenceClassification"),WOt.forEach(t),IPr=r(CVe," (RoBERTa model)"),CVe.forEach(t),NPr=i(ne),o5=n(ne,"LI",{});var wVe=s(o5);YCe=n(wVe,"STRONG",{});var QOt=s(YCe);qPr=r(QOt,"roformer"),QOt.forEach(t),jPr=r(wVe," \u2014 "),DZ=n(wVe,"A",{href:!0});var HOt=s(DZ);DPr=r(HOt,"TFRoFormerForSequenceClassification"),HOt.forEach(t),GPr=r(wVe," (RoFormer model)"),wVe.forEach(t),OPr=i(ne),r5=n(ne,"LI",{});var AVe=s(r5);KCe=n(AVe,"STRONG",{});var UOt=s(KCe);VPr=r(UOt,"tapas"),UOt.forEach(t),XPr=r(AVe," \u2014 "),GZ=n(AVe,"A",{href:!0});var JOt=s(GZ);zPr=r(JOt,"TFTapasForSequenceClassification"),JOt.forEach(t),WPr=r(AVe," (TAPAS model)"),AVe.forEach(t),QPr=i(ne),t5=n(ne,"LI",{});var LVe=s(t5);ZCe=n(LVe,"STRONG",{});var YOt=s(ZCe);HPr=r(YOt,"transfo-xl"),YOt.forEach(t),UPr=r(LVe," \u2014 "),OZ=n(LVe,"A",{href:!0});var KOt=s(OZ);JPr=r(KOt,"TFTransfoXLForSequenceClassification"),KOt.forEach(t),YPr=r(LVe," (Transformer-XL model)"),LVe.forEach(t),KPr=i(ne),a5=n(ne,"LI",{});var yVe=s(a5);e5e=n(yVe,"STRONG",{});var ZOt=s(e5e);ZPr=r(ZOt,"xlm"),ZOt.forEach(t),eBr=r(yVe," \u2014 "),VZ=n(yVe,"A",{href:!0});var eVt=s(VZ);oBr=r(eVt,"TFXLMForSequenceClassification"),eVt.forEach(t),rBr=r(yVe," (XLM model)"),yVe.forEach(t),tBr=i(ne),n5=n(ne,"LI",{});var xVe=s(n5);o5e=n(xVe,"STRONG",{});var oVt=s(o5e);aBr=r(oVt,"xlm-roberta"),oVt.forEach(t),nBr=r(xVe," \u2014 "),XZ=n(xVe,"A",{href:!0});var rVt=s(XZ);sBr=r(rVt,"TFXLMRobertaForSequenceClassification"),rVt.forEach(t),lBr=r(xVe," (XLM-RoBERTa model)"),xVe.forEach(t),iBr=i(ne),s5=n(ne,"LI",{});var $Ve=s(s5);r5e=n($Ve,"STRONG",{});var tVt=s(r5e);dBr=r(tVt,"xlnet"),tVt.forEach(t),cBr=r($Ve," \u2014 "),zZ=n($Ve,"A",{href:!0});var aVt=s(zZ);fBr=r(aVt,"TFXLNetForSequenceClassification"),aVt.forEach(t),mBr=r($Ve," (XLNet model)"),$Ve.forEach(t),ne.forEach(t),gBr=i(Yl),T(l5.$$.fragment,Yl),Yl.forEach(t),Jl.forEach(t),mHe=i(f),qc=n(f,"H2",{class:!0});var MJe=s(qc);i5=n(MJe,"A",{id:!0,class:!0,href:!0});var nVt=s(i5);t5e=n(nVt,"SPAN",{});var sVt=s(t5e);T(F$.$$.fragment,sVt),sVt.forEach(t),nVt.forEach(t),hBr=i(MJe),a5e=n(MJe,"SPAN",{});var lVt=s(a5e);pBr=r(lVt,"TFAutoModelForMultipleChoice"),lVt.forEach(t),MJe.forEach(t),gHe=i(f),fr=n(f,"DIV",{class:!0});var Kl=s(fr);T(T$.$$.fragment,Kl),_Br=i(Kl),jc=n(Kl,"P",{});var bne=s(jc);uBr=r(bne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),WZ=n(bne,"A",{href:!0});var iVt=s(WZ);bBr=r(iVt,"from_pretrained()"),iVt.forEach(t),vBr=r(bne," class method or the "),QZ=n(bne,"A",{href:!0});var dVt=s(QZ);FBr=r(dVt,"from_config()"),dVt.forEach(t),TBr=r(bne,` class
method.`),bne.forEach(t),MBr=i(Kl),M$=n(Kl,"P",{});var EJe=s(M$);EBr=r(EJe,"This class cannot be instantiated directly using "),n5e=n(EJe,"CODE",{});var cVt=s(n5e);CBr=r(cVt,"__init__()"),cVt.forEach(t),wBr=r(EJe," (throws an error)."),EJe.forEach(t),ABr=i(Kl),Vt=n(Kl,"DIV",{class:!0});var sL=s(Vt);T(E$.$$.fragment,sL),LBr=i(sL),s5e=n(sL,"P",{});var fVt=s(s5e);yBr=r(fVt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),fVt.forEach(t),xBr=i(sL),Dc=n(sL,"P",{});var vne=s(Dc);$Br=r(vne,`Note:
Loading a model from its configuration file does `),l5e=n(vne,"STRONG",{});var mVt=s(l5e);kBr=r(mVt,"not"),mVt.forEach(t),SBr=r(vne,` load the model weights. It only affects the
model\u2019s configuration. Use `),HZ=n(vne,"A",{href:!0});var gVt=s(HZ);RBr=r(gVt,"from_pretrained()"),gVt.forEach(t),PBr=r(vne," to load the model weights."),vne.forEach(t),BBr=i(sL),T(d5.$$.fragment,sL),sL.forEach(t),IBr=i(Kl),jr=n(Kl,"DIV",{class:!0});var Zl=s(jr);T(C$.$$.fragment,Zl),NBr=i(Zl),i5e=n(Zl,"P",{});var hVt=s(i5e);qBr=r(hVt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),hVt.forEach(t),jBr=i(Zl),Fn=n(Zl,"P",{});var lL=s(Fn);DBr=r(lL,"The model class to instantiate is selected based on the "),d5e=n(lL,"CODE",{});var pVt=s(d5e);GBr=r(pVt,"model_type"),pVt.forEach(t),OBr=r(lL,` property of the config object (either
passed as an argument or loaded from `),c5e=n(lL,"CODE",{});var _Vt=s(c5e);VBr=r(_Vt,"pretrained_model_name_or_path"),_Vt.forEach(t),XBr=r(lL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f5e=n(lL,"CODE",{});var uVt=s(f5e);zBr=r(uVt,"pretrained_model_name_or_path"),uVt.forEach(t),WBr=r(lL,":"),lL.forEach(t),QBr=i(Zl),ve=n(Zl,"UL",{});var Te=s(ve);c5=n(Te,"LI",{});var kVe=s(c5);m5e=n(kVe,"STRONG",{});var bVt=s(m5e);HBr=r(bVt,"albert"),bVt.forEach(t),UBr=r(kVe," \u2014 "),UZ=n(kVe,"A",{href:!0});var vVt=s(UZ);JBr=r(vVt,"TFAlbertForMultipleChoice"),vVt.forEach(t),YBr=r(kVe," (ALBERT model)"),kVe.forEach(t),KBr=i(Te),f5=n(Te,"LI",{});var SVe=s(f5);g5e=n(SVe,"STRONG",{});var FVt=s(g5e);ZBr=r(FVt,"bert"),FVt.forEach(t),eIr=r(SVe," \u2014 "),JZ=n(SVe,"A",{href:!0});var TVt=s(JZ);oIr=r(TVt,"TFBertForMultipleChoice"),TVt.forEach(t),rIr=r(SVe," (BERT model)"),SVe.forEach(t),tIr=i(Te),m5=n(Te,"LI",{});var RVe=s(m5);h5e=n(RVe,"STRONG",{});var MVt=s(h5e);aIr=r(MVt,"camembert"),MVt.forEach(t),nIr=r(RVe," \u2014 "),YZ=n(RVe,"A",{href:!0});var EVt=s(YZ);sIr=r(EVt,"TFCamembertForMultipleChoice"),EVt.forEach(t),lIr=r(RVe," (CamemBERT model)"),RVe.forEach(t),iIr=i(Te),g5=n(Te,"LI",{});var PVe=s(g5);p5e=n(PVe,"STRONG",{});var CVt=s(p5e);dIr=r(CVt,"convbert"),CVt.forEach(t),cIr=r(PVe," \u2014 "),KZ=n(PVe,"A",{href:!0});var wVt=s(KZ);fIr=r(wVt,"TFConvBertForMultipleChoice"),wVt.forEach(t),mIr=r(PVe," (ConvBERT model)"),PVe.forEach(t),gIr=i(Te),h5=n(Te,"LI",{});var BVe=s(h5);_5e=n(BVe,"STRONG",{});var AVt=s(_5e);hIr=r(AVt,"distilbert"),AVt.forEach(t),pIr=r(BVe," \u2014 "),ZZ=n(BVe,"A",{href:!0});var LVt=s(ZZ);_Ir=r(LVt,"TFDistilBertForMultipleChoice"),LVt.forEach(t),uIr=r(BVe," (DistilBERT model)"),BVe.forEach(t),bIr=i(Te),p5=n(Te,"LI",{});var IVe=s(p5);u5e=n(IVe,"STRONG",{});var yVt=s(u5e);vIr=r(yVt,"electra"),yVt.forEach(t),FIr=r(IVe," \u2014 "),eee=n(IVe,"A",{href:!0});var xVt=s(eee);TIr=r(xVt,"TFElectraForMultipleChoice"),xVt.forEach(t),MIr=r(IVe," (ELECTRA model)"),IVe.forEach(t),EIr=i(Te),_5=n(Te,"LI",{});var NVe=s(_5);b5e=n(NVe,"STRONG",{});var $Vt=s(b5e);CIr=r($Vt,"flaubert"),$Vt.forEach(t),wIr=r(NVe," \u2014 "),oee=n(NVe,"A",{href:!0});var kVt=s(oee);AIr=r(kVt,"TFFlaubertForMultipleChoice"),kVt.forEach(t),LIr=r(NVe," (FlauBERT model)"),NVe.forEach(t),yIr=i(Te),u5=n(Te,"LI",{});var qVe=s(u5);v5e=n(qVe,"STRONG",{});var SVt=s(v5e);xIr=r(SVt,"funnel"),SVt.forEach(t),$Ir=r(qVe," \u2014 "),ree=n(qVe,"A",{href:!0});var RVt=s(ree);kIr=r(RVt,"TFFunnelForMultipleChoice"),RVt.forEach(t),SIr=r(qVe," (Funnel Transformer model)"),qVe.forEach(t),RIr=i(Te),b5=n(Te,"LI",{});var jVe=s(b5);F5e=n(jVe,"STRONG",{});var PVt=s(F5e);PIr=r(PVt,"longformer"),PVt.forEach(t),BIr=r(jVe," \u2014 "),tee=n(jVe,"A",{href:!0});var BVt=s(tee);IIr=r(BVt,"TFLongformerForMultipleChoice"),BVt.forEach(t),NIr=r(jVe," (Longformer model)"),jVe.forEach(t),qIr=i(Te),v5=n(Te,"LI",{});var DVe=s(v5);T5e=n(DVe,"STRONG",{});var IVt=s(T5e);jIr=r(IVt,"mobilebert"),IVt.forEach(t),DIr=r(DVe," \u2014 "),aee=n(DVe,"A",{href:!0});var NVt=s(aee);GIr=r(NVt,"TFMobileBertForMultipleChoice"),NVt.forEach(t),OIr=r(DVe," (MobileBERT model)"),DVe.forEach(t),VIr=i(Te),F5=n(Te,"LI",{});var GVe=s(F5);M5e=n(GVe,"STRONG",{});var qVt=s(M5e);XIr=r(qVt,"mpnet"),qVt.forEach(t),zIr=r(GVe," \u2014 "),nee=n(GVe,"A",{href:!0});var jVt=s(nee);WIr=r(jVt,"TFMPNetForMultipleChoice"),jVt.forEach(t),QIr=r(GVe," (MPNet model)"),GVe.forEach(t),HIr=i(Te),T5=n(Te,"LI",{});var OVe=s(T5);E5e=n(OVe,"STRONG",{});var DVt=s(E5e);UIr=r(DVt,"rembert"),DVt.forEach(t),JIr=r(OVe," \u2014 "),see=n(OVe,"A",{href:!0});var GVt=s(see);YIr=r(GVt,"TFRemBertForMultipleChoice"),GVt.forEach(t),KIr=r(OVe," (RemBERT model)"),OVe.forEach(t),ZIr=i(Te),M5=n(Te,"LI",{});var VVe=s(M5);C5e=n(VVe,"STRONG",{});var OVt=s(C5e);eNr=r(OVt,"roberta"),OVt.forEach(t),oNr=r(VVe," \u2014 "),lee=n(VVe,"A",{href:!0});var VVt=s(lee);rNr=r(VVt,"TFRobertaForMultipleChoice"),VVt.forEach(t),tNr=r(VVe," (RoBERTa model)"),VVe.forEach(t),aNr=i(Te),E5=n(Te,"LI",{});var XVe=s(E5);w5e=n(XVe,"STRONG",{});var XVt=s(w5e);nNr=r(XVt,"roformer"),XVt.forEach(t),sNr=r(XVe," \u2014 "),iee=n(XVe,"A",{href:!0});var zVt=s(iee);lNr=r(zVt,"TFRoFormerForMultipleChoice"),zVt.forEach(t),iNr=r(XVe," (RoFormer model)"),XVe.forEach(t),dNr=i(Te),C5=n(Te,"LI",{});var zVe=s(C5);A5e=n(zVe,"STRONG",{});var WVt=s(A5e);cNr=r(WVt,"xlm"),WVt.forEach(t),fNr=r(zVe," \u2014 "),dee=n(zVe,"A",{href:!0});var QVt=s(dee);mNr=r(QVt,"TFXLMForMultipleChoice"),QVt.forEach(t),gNr=r(zVe," (XLM model)"),zVe.forEach(t),hNr=i(Te),w5=n(Te,"LI",{});var WVe=s(w5);L5e=n(WVe,"STRONG",{});var HVt=s(L5e);pNr=r(HVt,"xlm-roberta"),HVt.forEach(t),_Nr=r(WVe," \u2014 "),cee=n(WVe,"A",{href:!0});var UVt=s(cee);uNr=r(UVt,"TFXLMRobertaForMultipleChoice"),UVt.forEach(t),bNr=r(WVe," (XLM-RoBERTa model)"),WVe.forEach(t),vNr=i(Te),A5=n(Te,"LI",{});var QVe=s(A5);y5e=n(QVe,"STRONG",{});var JVt=s(y5e);FNr=r(JVt,"xlnet"),JVt.forEach(t),TNr=r(QVe," \u2014 "),fee=n(QVe,"A",{href:!0});var YVt=s(fee);MNr=r(YVt,"TFXLNetForMultipleChoice"),YVt.forEach(t),ENr=r(QVe," (XLNet model)"),QVe.forEach(t),Te.forEach(t),CNr=i(Zl),T(L5.$$.fragment,Zl),Zl.forEach(t),Kl.forEach(t),hHe=i(f),Gc=n(f,"H2",{class:!0});var CJe=s(Gc);y5=n(CJe,"A",{id:!0,class:!0,href:!0});var KVt=s(y5);x5e=n(KVt,"SPAN",{});var ZVt=s(x5e);T(w$.$$.fragment,ZVt),ZVt.forEach(t),KVt.forEach(t),wNr=i(CJe),$5e=n(CJe,"SPAN",{});var eXt=s($5e);ANr=r(eXt,"TFAutoModelForNextSentencePrediction"),eXt.forEach(t),CJe.forEach(t),pHe=i(f),mr=n(f,"DIV",{class:!0});var ei=s(mr);T(A$.$$.fragment,ei),LNr=i(ei),Oc=n(ei,"P",{});var Fne=s(Oc);yNr=r(Fne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),mee=n(Fne,"A",{href:!0});var oXt=s(mee);xNr=r(oXt,"from_pretrained()"),oXt.forEach(t),$Nr=r(Fne," class method or the "),gee=n(Fne,"A",{href:!0});var rXt=s(gee);kNr=r(rXt,"from_config()"),rXt.forEach(t),SNr=r(Fne,` class
method.`),Fne.forEach(t),RNr=i(ei),L$=n(ei,"P",{});var wJe=s(L$);PNr=r(wJe,"This class cannot be instantiated directly using "),k5e=n(wJe,"CODE",{});var tXt=s(k5e);BNr=r(tXt,"__init__()"),tXt.forEach(t),INr=r(wJe," (throws an error)."),wJe.forEach(t),NNr=i(ei),Xt=n(ei,"DIV",{class:!0});var iL=s(Xt);T(y$.$$.fragment,iL),qNr=i(iL),S5e=n(iL,"P",{});var aXt=s(S5e);jNr=r(aXt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),aXt.forEach(t),DNr=i(iL),Vc=n(iL,"P",{});var Tne=s(Vc);GNr=r(Tne,`Note:
Loading a model from its configuration file does `),R5e=n(Tne,"STRONG",{});var nXt=s(R5e);ONr=r(nXt,"not"),nXt.forEach(t),VNr=r(Tne,` load the model weights. It only affects the
model\u2019s configuration. Use `),hee=n(Tne,"A",{href:!0});var sXt=s(hee);XNr=r(sXt,"from_pretrained()"),sXt.forEach(t),zNr=r(Tne," to load the model weights."),Tne.forEach(t),WNr=i(iL),T(x5.$$.fragment,iL),iL.forEach(t),QNr=i(ei),Dr=n(ei,"DIV",{class:!0});var oi=s(Dr);T(x$.$$.fragment,oi),HNr=i(oi),P5e=n(oi,"P",{});var lXt=s(P5e);UNr=r(lXt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),lXt.forEach(t),JNr=i(oi),Tn=n(oi,"P",{});var dL=s(Tn);YNr=r(dL,"The model class to instantiate is selected based on the "),B5e=n(dL,"CODE",{});var iXt=s(B5e);KNr=r(iXt,"model_type"),iXt.forEach(t),ZNr=r(dL,` property of the config object (either
passed as an argument or loaded from `),I5e=n(dL,"CODE",{});var dXt=s(I5e);eqr=r(dXt,"pretrained_model_name_or_path"),dXt.forEach(t),oqr=r(dL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),N5e=n(dL,"CODE",{});var cXt=s(N5e);rqr=r(cXt,"pretrained_model_name_or_path"),cXt.forEach(t),tqr=r(dL,":"),dL.forEach(t),aqr=i(oi),$$=n(oi,"UL",{});var AJe=s($$);$5=n(AJe,"LI",{});var HVe=s($5);q5e=n(HVe,"STRONG",{});var fXt=s(q5e);nqr=r(fXt,"bert"),fXt.forEach(t),sqr=r(HVe," \u2014 "),pee=n(HVe,"A",{href:!0});var mXt=s(pee);lqr=r(mXt,"TFBertForNextSentencePrediction"),mXt.forEach(t),iqr=r(HVe," (BERT model)"),HVe.forEach(t),dqr=i(AJe),k5=n(AJe,"LI",{});var UVe=s(k5);j5e=n(UVe,"STRONG",{});var gXt=s(j5e);cqr=r(gXt,"mobilebert"),gXt.forEach(t),fqr=r(UVe," \u2014 "),_ee=n(UVe,"A",{href:!0});var hXt=s(_ee);mqr=r(hXt,"TFMobileBertForNextSentencePrediction"),hXt.forEach(t),gqr=r(UVe," (MobileBERT model)"),UVe.forEach(t),AJe.forEach(t),hqr=i(oi),T(S5.$$.fragment,oi),oi.forEach(t),ei.forEach(t),_He=i(f),Xc=n(f,"H2",{class:!0});var LJe=s(Xc);R5=n(LJe,"A",{id:!0,class:!0,href:!0});var pXt=s(R5);D5e=n(pXt,"SPAN",{});var _Xt=s(D5e);T(k$.$$.fragment,_Xt),_Xt.forEach(t),pXt.forEach(t),pqr=i(LJe),G5e=n(LJe,"SPAN",{});var uXt=s(G5e);_qr=r(uXt,"TFAutoModelForTableQuestionAnswering"),uXt.forEach(t),LJe.forEach(t),uHe=i(f),gr=n(f,"DIV",{class:!0});var ri=s(gr);T(S$.$$.fragment,ri),uqr=i(ri),zc=n(ri,"P",{});var Mne=s(zc);bqr=r(Mne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),uee=n(Mne,"A",{href:!0});var bXt=s(uee);vqr=r(bXt,"from_pretrained()"),bXt.forEach(t),Fqr=r(Mne," class method or the "),bee=n(Mne,"A",{href:!0});var vXt=s(bee);Tqr=r(vXt,"from_config()"),vXt.forEach(t),Mqr=r(Mne,` class
method.`),Mne.forEach(t),Eqr=i(ri),R$=n(ri,"P",{});var yJe=s(R$);Cqr=r(yJe,"This class cannot be instantiated directly using "),O5e=n(yJe,"CODE",{});var FXt=s(O5e);wqr=r(FXt,"__init__()"),FXt.forEach(t),Aqr=r(yJe," (throws an error)."),yJe.forEach(t),Lqr=i(ri),zt=n(ri,"DIV",{class:!0});var cL=s(zt);T(P$.$$.fragment,cL),yqr=i(cL),V5e=n(cL,"P",{});var TXt=s(V5e);xqr=r(TXt,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),TXt.forEach(t),$qr=i(cL),Wc=n(cL,"P",{});var Ene=s(Wc);kqr=r(Ene,`Note:
Loading a model from its configuration file does `),X5e=n(Ene,"STRONG",{});var MXt=s(X5e);Sqr=r(MXt,"not"),MXt.forEach(t),Rqr=r(Ene,` load the model weights. It only affects the
model\u2019s configuration. Use `),vee=n(Ene,"A",{href:!0});var EXt=s(vee);Pqr=r(EXt,"from_pretrained()"),EXt.forEach(t),Bqr=r(Ene," to load the model weights."),Ene.forEach(t),Iqr=i(cL),T(P5.$$.fragment,cL),cL.forEach(t),Nqr=i(ri),Gr=n(ri,"DIV",{class:!0});var ti=s(Gr);T(B$.$$.fragment,ti),qqr=i(ti),z5e=n(ti,"P",{});var CXt=s(z5e);jqr=r(CXt,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),CXt.forEach(t),Dqr=i(ti),Mn=n(ti,"P",{});var fL=s(Mn);Gqr=r(fL,"The model class to instantiate is selected based on the "),W5e=n(fL,"CODE",{});var wXt=s(W5e);Oqr=r(wXt,"model_type"),wXt.forEach(t),Vqr=r(fL,` property of the config object (either
passed as an argument or loaded from `),Q5e=n(fL,"CODE",{});var AXt=s(Q5e);Xqr=r(AXt,"pretrained_model_name_or_path"),AXt.forEach(t),zqr=r(fL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),H5e=n(fL,"CODE",{});var LXt=s(H5e);Wqr=r(LXt,"pretrained_model_name_or_path"),LXt.forEach(t),Qqr=r(fL,":"),fL.forEach(t),Hqr=i(ti),U5e=n(ti,"UL",{});var yXt=s(U5e);B5=n(yXt,"LI",{});var JVe=s(B5);J5e=n(JVe,"STRONG",{});var xXt=s(J5e);Uqr=r(xXt,"tapas"),xXt.forEach(t),Jqr=r(JVe," \u2014 "),Fee=n(JVe,"A",{href:!0});var $Xt=s(Fee);Yqr=r($Xt,"TFTapasForQuestionAnswering"),$Xt.forEach(t),Kqr=r(JVe," (TAPAS model)"),JVe.forEach(t),yXt.forEach(t),Zqr=i(ti),T(I5.$$.fragment,ti),ti.forEach(t),ri.forEach(t),bHe=i(f),Qc=n(f,"H2",{class:!0});var xJe=s(Qc);N5=n(xJe,"A",{id:!0,class:!0,href:!0});var kXt=s(N5);Y5e=n(kXt,"SPAN",{});var SXt=s(Y5e);T(I$.$$.fragment,SXt),SXt.forEach(t),kXt.forEach(t),ejr=i(xJe),K5e=n(xJe,"SPAN",{});var RXt=s(K5e);ojr=r(RXt,"TFAutoModelForTokenClassification"),RXt.forEach(t),xJe.forEach(t),vHe=i(f),hr=n(f,"DIV",{class:!0});var ai=s(hr);T(N$.$$.fragment,ai),rjr=i(ai),Hc=n(ai,"P",{});var Cne=s(Hc);tjr=r(Cne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Tee=n(Cne,"A",{href:!0});var PXt=s(Tee);ajr=r(PXt,"from_pretrained()"),PXt.forEach(t),njr=r(Cne," class method or the "),Mee=n(Cne,"A",{href:!0});var BXt=s(Mee);sjr=r(BXt,"from_config()"),BXt.forEach(t),ljr=r(Cne,` class
method.`),Cne.forEach(t),ijr=i(ai),q$=n(ai,"P",{});var $Je=s(q$);djr=r($Je,"This class cannot be instantiated directly using "),Z5e=n($Je,"CODE",{});var IXt=s(Z5e);cjr=r(IXt,"__init__()"),IXt.forEach(t),fjr=r($Je," (throws an error)."),$Je.forEach(t),mjr=i(ai),Wt=n(ai,"DIV",{class:!0});var mL=s(Wt);T(j$.$$.fragment,mL),gjr=i(mL),e3e=n(mL,"P",{});var NXt=s(e3e);hjr=r(NXt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),NXt.forEach(t),pjr=i(mL),Uc=n(mL,"P",{});var wne=s(Uc);_jr=r(wne,`Note:
Loading a model from its configuration file does `),o3e=n(wne,"STRONG",{});var qXt=s(o3e);ujr=r(qXt,"not"),qXt.forEach(t),bjr=r(wne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eee=n(wne,"A",{href:!0});var jXt=s(Eee);vjr=r(jXt,"from_pretrained()"),jXt.forEach(t),Fjr=r(wne," to load the model weights."),wne.forEach(t),Tjr=i(mL),T(q5.$$.fragment,mL),mL.forEach(t),Mjr=i(ai),Or=n(ai,"DIV",{class:!0});var ni=s(Or);T(D$.$$.fragment,ni),Ejr=i(ni),r3e=n(ni,"P",{});var DXt=s(r3e);Cjr=r(DXt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),DXt.forEach(t),wjr=i(ni),En=n(ni,"P",{});var gL=s(En);Ajr=r(gL,"The model class to instantiate is selected based on the "),t3e=n(gL,"CODE",{});var GXt=s(t3e);Ljr=r(GXt,"model_type"),GXt.forEach(t),yjr=r(gL,` property of the config object (either
passed as an argument or loaded from `),a3e=n(gL,"CODE",{});var OXt=s(a3e);xjr=r(OXt,"pretrained_model_name_or_path"),OXt.forEach(t),$jr=r(gL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n3e=n(gL,"CODE",{});var VXt=s(n3e);kjr=r(VXt,"pretrained_model_name_or_path"),VXt.forEach(t),Sjr=r(gL,":"),gL.forEach(t),Rjr=i(ni),de=n(ni,"UL",{});var he=s(de);j5=n(he,"LI",{});var YVe=s(j5);s3e=n(YVe,"STRONG",{});var XXt=s(s3e);Pjr=r(XXt,"albert"),XXt.forEach(t),Bjr=r(YVe," \u2014 "),Cee=n(YVe,"A",{href:!0});var zXt=s(Cee);Ijr=r(zXt,"TFAlbertForTokenClassification"),zXt.forEach(t),Njr=r(YVe," (ALBERT model)"),YVe.forEach(t),qjr=i(he),D5=n(he,"LI",{});var KVe=s(D5);l3e=n(KVe,"STRONG",{});var WXt=s(l3e);jjr=r(WXt,"bert"),WXt.forEach(t),Djr=r(KVe," \u2014 "),wee=n(KVe,"A",{href:!0});var QXt=s(wee);Gjr=r(QXt,"TFBertForTokenClassification"),QXt.forEach(t),Ojr=r(KVe," (BERT model)"),KVe.forEach(t),Vjr=i(he),G5=n(he,"LI",{});var ZVe=s(G5);i3e=n(ZVe,"STRONG",{});var HXt=s(i3e);Xjr=r(HXt,"camembert"),HXt.forEach(t),zjr=r(ZVe," \u2014 "),Aee=n(ZVe,"A",{href:!0});var UXt=s(Aee);Wjr=r(UXt,"TFCamembertForTokenClassification"),UXt.forEach(t),Qjr=r(ZVe," (CamemBERT model)"),ZVe.forEach(t),Hjr=i(he),O5=n(he,"LI",{});var eXe=s(O5);d3e=n(eXe,"STRONG",{});var JXt=s(d3e);Ujr=r(JXt,"convbert"),JXt.forEach(t),Jjr=r(eXe," \u2014 "),Lee=n(eXe,"A",{href:!0});var YXt=s(Lee);Yjr=r(YXt,"TFConvBertForTokenClassification"),YXt.forEach(t),Kjr=r(eXe," (ConvBERT model)"),eXe.forEach(t),Zjr=i(he),V5=n(he,"LI",{});var oXe=s(V5);c3e=n(oXe,"STRONG",{});var KXt=s(c3e);eDr=r(KXt,"deberta"),KXt.forEach(t),oDr=r(oXe," \u2014 "),yee=n(oXe,"A",{href:!0});var ZXt=s(yee);rDr=r(ZXt,"TFDebertaForTokenClassification"),ZXt.forEach(t),tDr=r(oXe," (DeBERTa model)"),oXe.forEach(t),aDr=i(he),X5=n(he,"LI",{});var rXe=s(X5);f3e=n(rXe,"STRONG",{});var ezt=s(f3e);nDr=r(ezt,"deberta-v2"),ezt.forEach(t),sDr=r(rXe," \u2014 "),xee=n(rXe,"A",{href:!0});var ozt=s(xee);lDr=r(ozt,"TFDebertaV2ForTokenClassification"),ozt.forEach(t),iDr=r(rXe," (DeBERTa-v2 model)"),rXe.forEach(t),dDr=i(he),z5=n(he,"LI",{});var tXe=s(z5);m3e=n(tXe,"STRONG",{});var rzt=s(m3e);cDr=r(rzt,"distilbert"),rzt.forEach(t),fDr=r(tXe," \u2014 "),$ee=n(tXe,"A",{href:!0});var tzt=s($ee);mDr=r(tzt,"TFDistilBertForTokenClassification"),tzt.forEach(t),gDr=r(tXe," (DistilBERT model)"),tXe.forEach(t),hDr=i(he),W5=n(he,"LI",{});var aXe=s(W5);g3e=n(aXe,"STRONG",{});var azt=s(g3e);pDr=r(azt,"electra"),azt.forEach(t),_Dr=r(aXe," \u2014 "),kee=n(aXe,"A",{href:!0});var nzt=s(kee);uDr=r(nzt,"TFElectraForTokenClassification"),nzt.forEach(t),bDr=r(aXe," (ELECTRA model)"),aXe.forEach(t),vDr=i(he),Q5=n(he,"LI",{});var nXe=s(Q5);h3e=n(nXe,"STRONG",{});var szt=s(h3e);FDr=r(szt,"flaubert"),szt.forEach(t),TDr=r(nXe," \u2014 "),See=n(nXe,"A",{href:!0});var lzt=s(See);MDr=r(lzt,"TFFlaubertForTokenClassification"),lzt.forEach(t),EDr=r(nXe," (FlauBERT model)"),nXe.forEach(t),CDr=i(he),H5=n(he,"LI",{});var sXe=s(H5);p3e=n(sXe,"STRONG",{});var izt=s(p3e);wDr=r(izt,"funnel"),izt.forEach(t),ADr=r(sXe," \u2014 "),Ree=n(sXe,"A",{href:!0});var dzt=s(Ree);LDr=r(dzt,"TFFunnelForTokenClassification"),dzt.forEach(t),yDr=r(sXe," (Funnel Transformer model)"),sXe.forEach(t),xDr=i(he),U5=n(he,"LI",{});var lXe=s(U5);_3e=n(lXe,"STRONG",{});var czt=s(_3e);$Dr=r(czt,"layoutlm"),czt.forEach(t),kDr=r(lXe," \u2014 "),Pee=n(lXe,"A",{href:!0});var fzt=s(Pee);SDr=r(fzt,"TFLayoutLMForTokenClassification"),fzt.forEach(t),RDr=r(lXe," (LayoutLM model)"),lXe.forEach(t),PDr=i(he),J5=n(he,"LI",{});var iXe=s(J5);u3e=n(iXe,"STRONG",{});var mzt=s(u3e);BDr=r(mzt,"longformer"),mzt.forEach(t),IDr=r(iXe," \u2014 "),Bee=n(iXe,"A",{href:!0});var gzt=s(Bee);NDr=r(gzt,"TFLongformerForTokenClassification"),gzt.forEach(t),qDr=r(iXe," (Longformer model)"),iXe.forEach(t),jDr=i(he),Y5=n(he,"LI",{});var dXe=s(Y5);b3e=n(dXe,"STRONG",{});var hzt=s(b3e);DDr=r(hzt,"mobilebert"),hzt.forEach(t),GDr=r(dXe," \u2014 "),Iee=n(dXe,"A",{href:!0});var pzt=s(Iee);ODr=r(pzt,"TFMobileBertForTokenClassification"),pzt.forEach(t),VDr=r(dXe," (MobileBERT model)"),dXe.forEach(t),XDr=i(he),K5=n(he,"LI",{});var cXe=s(K5);v3e=n(cXe,"STRONG",{});var _zt=s(v3e);zDr=r(_zt,"mpnet"),_zt.forEach(t),WDr=r(cXe," \u2014 "),Nee=n(cXe,"A",{href:!0});var uzt=s(Nee);QDr=r(uzt,"TFMPNetForTokenClassification"),uzt.forEach(t),HDr=r(cXe," (MPNet model)"),cXe.forEach(t),UDr=i(he),Z5=n(he,"LI",{});var fXe=s(Z5);F3e=n(fXe,"STRONG",{});var bzt=s(F3e);JDr=r(bzt,"rembert"),bzt.forEach(t),YDr=r(fXe," \u2014 "),qee=n(fXe,"A",{href:!0});var vzt=s(qee);KDr=r(vzt,"TFRemBertForTokenClassification"),vzt.forEach(t),ZDr=r(fXe," (RemBERT model)"),fXe.forEach(t),eGr=i(he),e3=n(he,"LI",{});var mXe=s(e3);T3e=n(mXe,"STRONG",{});var Fzt=s(T3e);oGr=r(Fzt,"roberta"),Fzt.forEach(t),rGr=r(mXe," \u2014 "),jee=n(mXe,"A",{href:!0});var Tzt=s(jee);tGr=r(Tzt,"TFRobertaForTokenClassification"),Tzt.forEach(t),aGr=r(mXe," (RoBERTa model)"),mXe.forEach(t),nGr=i(he),o3=n(he,"LI",{});var gXe=s(o3);M3e=n(gXe,"STRONG",{});var Mzt=s(M3e);sGr=r(Mzt,"roformer"),Mzt.forEach(t),lGr=r(gXe," \u2014 "),Dee=n(gXe,"A",{href:!0});var Ezt=s(Dee);iGr=r(Ezt,"TFRoFormerForTokenClassification"),Ezt.forEach(t),dGr=r(gXe," (RoFormer model)"),gXe.forEach(t),cGr=i(he),r3=n(he,"LI",{});var hXe=s(r3);E3e=n(hXe,"STRONG",{});var Czt=s(E3e);fGr=r(Czt,"xlm"),Czt.forEach(t),mGr=r(hXe," \u2014 "),Gee=n(hXe,"A",{href:!0});var wzt=s(Gee);gGr=r(wzt,"TFXLMForTokenClassification"),wzt.forEach(t),hGr=r(hXe," (XLM model)"),hXe.forEach(t),pGr=i(he),t3=n(he,"LI",{});var pXe=s(t3);C3e=n(pXe,"STRONG",{});var Azt=s(C3e);_Gr=r(Azt,"xlm-roberta"),Azt.forEach(t),uGr=r(pXe," \u2014 "),Oee=n(pXe,"A",{href:!0});var Lzt=s(Oee);bGr=r(Lzt,"TFXLMRobertaForTokenClassification"),Lzt.forEach(t),vGr=r(pXe," (XLM-RoBERTa model)"),pXe.forEach(t),FGr=i(he),a3=n(he,"LI",{});var _Xe=s(a3);w3e=n(_Xe,"STRONG",{});var yzt=s(w3e);TGr=r(yzt,"xlnet"),yzt.forEach(t),MGr=r(_Xe," \u2014 "),Vee=n(_Xe,"A",{href:!0});var xzt=s(Vee);EGr=r(xzt,"TFXLNetForTokenClassification"),xzt.forEach(t),CGr=r(_Xe," (XLNet model)"),_Xe.forEach(t),he.forEach(t),wGr=i(ni),T(n3.$$.fragment,ni),ni.forEach(t),ai.forEach(t),FHe=i(f),Jc=n(f,"H2",{class:!0});var kJe=s(Jc);s3=n(kJe,"A",{id:!0,class:!0,href:!0});var $zt=s(s3);A3e=n($zt,"SPAN",{});var kzt=s(A3e);T(G$.$$.fragment,kzt),kzt.forEach(t),$zt.forEach(t),AGr=i(kJe),L3e=n(kJe,"SPAN",{});var Szt=s(L3e);LGr=r(Szt,"TFAutoModelForQuestionAnswering"),Szt.forEach(t),kJe.forEach(t),THe=i(f),pr=n(f,"DIV",{class:!0});var si=s(pr);T(O$.$$.fragment,si),yGr=i(si),Yc=n(si,"P",{});var Ane=s(Yc);xGr=r(Ane,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Xee=n(Ane,"A",{href:!0});var Rzt=s(Xee);$Gr=r(Rzt,"from_pretrained()"),Rzt.forEach(t),kGr=r(Ane," class method or the "),zee=n(Ane,"A",{href:!0});var Pzt=s(zee);SGr=r(Pzt,"from_config()"),Pzt.forEach(t),RGr=r(Ane,` class
method.`),Ane.forEach(t),PGr=i(si),V$=n(si,"P",{});var SJe=s(V$);BGr=r(SJe,"This class cannot be instantiated directly using "),y3e=n(SJe,"CODE",{});var Bzt=s(y3e);IGr=r(Bzt,"__init__()"),Bzt.forEach(t),NGr=r(SJe," (throws an error)."),SJe.forEach(t),qGr=i(si),Qt=n(si,"DIV",{class:!0});var hL=s(Qt);T(X$.$$.fragment,hL),jGr=i(hL),x3e=n(hL,"P",{});var Izt=s(x3e);DGr=r(Izt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Izt.forEach(t),GGr=i(hL),Kc=n(hL,"P",{});var Lne=s(Kc);OGr=r(Lne,`Note:
Loading a model from its configuration file does `),$3e=n(Lne,"STRONG",{});var Nzt=s($3e);VGr=r(Nzt,"not"),Nzt.forEach(t),XGr=r(Lne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Wee=n(Lne,"A",{href:!0});var qzt=s(Wee);zGr=r(qzt,"from_pretrained()"),qzt.forEach(t),WGr=r(Lne," to load the model weights."),Lne.forEach(t),QGr=i(hL),T(l3.$$.fragment,hL),hL.forEach(t),HGr=i(si),Vr=n(si,"DIV",{class:!0});var li=s(Vr);T(z$.$$.fragment,li),UGr=i(li),k3e=n(li,"P",{});var jzt=s(k3e);JGr=r(jzt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),jzt.forEach(t),YGr=i(li),Cn=n(li,"P",{});var pL=s(Cn);KGr=r(pL,"The model class to instantiate is selected based on the "),S3e=n(pL,"CODE",{});var Dzt=s(S3e);ZGr=r(Dzt,"model_type"),Dzt.forEach(t),eOr=r(pL,` property of the config object (either
passed as an argument or loaded from `),R3e=n(pL,"CODE",{});var Gzt=s(R3e);oOr=r(Gzt,"pretrained_model_name_or_path"),Gzt.forEach(t),rOr=r(pL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P3e=n(pL,"CODE",{});var Ozt=s(P3e);tOr=r(Ozt,"pretrained_model_name_or_path"),Ozt.forEach(t),aOr=r(pL,":"),pL.forEach(t),nOr=i(li),ce=n(li,"UL",{});var pe=s(ce);i3=n(pe,"LI",{});var uXe=s(i3);B3e=n(uXe,"STRONG",{});var Vzt=s(B3e);sOr=r(Vzt,"albert"),Vzt.forEach(t),lOr=r(uXe," \u2014 "),Qee=n(uXe,"A",{href:!0});var Xzt=s(Qee);iOr=r(Xzt,"TFAlbertForQuestionAnswering"),Xzt.forEach(t),dOr=r(uXe," (ALBERT model)"),uXe.forEach(t),cOr=i(pe),d3=n(pe,"LI",{});var bXe=s(d3);I3e=n(bXe,"STRONG",{});var zzt=s(I3e);fOr=r(zzt,"bert"),zzt.forEach(t),mOr=r(bXe," \u2014 "),Hee=n(bXe,"A",{href:!0});var Wzt=s(Hee);gOr=r(Wzt,"TFBertForQuestionAnswering"),Wzt.forEach(t),hOr=r(bXe," (BERT model)"),bXe.forEach(t),pOr=i(pe),c3=n(pe,"LI",{});var vXe=s(c3);N3e=n(vXe,"STRONG",{});var Qzt=s(N3e);_Or=r(Qzt,"camembert"),Qzt.forEach(t),uOr=r(vXe," \u2014 "),Uee=n(vXe,"A",{href:!0});var Hzt=s(Uee);bOr=r(Hzt,"TFCamembertForQuestionAnswering"),Hzt.forEach(t),vOr=r(vXe," (CamemBERT model)"),vXe.forEach(t),FOr=i(pe),f3=n(pe,"LI",{});var FXe=s(f3);q3e=n(FXe,"STRONG",{});var Uzt=s(q3e);TOr=r(Uzt,"convbert"),Uzt.forEach(t),MOr=r(FXe," \u2014 "),Jee=n(FXe,"A",{href:!0});var Jzt=s(Jee);EOr=r(Jzt,"TFConvBertForQuestionAnswering"),Jzt.forEach(t),COr=r(FXe," (ConvBERT model)"),FXe.forEach(t),wOr=i(pe),m3=n(pe,"LI",{});var TXe=s(m3);j3e=n(TXe,"STRONG",{});var Yzt=s(j3e);AOr=r(Yzt,"deberta"),Yzt.forEach(t),LOr=r(TXe," \u2014 "),Yee=n(TXe,"A",{href:!0});var Kzt=s(Yee);yOr=r(Kzt,"TFDebertaForQuestionAnswering"),Kzt.forEach(t),xOr=r(TXe," (DeBERTa model)"),TXe.forEach(t),$Or=i(pe),g3=n(pe,"LI",{});var MXe=s(g3);D3e=n(MXe,"STRONG",{});var Zzt=s(D3e);kOr=r(Zzt,"deberta-v2"),Zzt.forEach(t),SOr=r(MXe," \u2014 "),Kee=n(MXe,"A",{href:!0});var eWt=s(Kee);ROr=r(eWt,"TFDebertaV2ForQuestionAnswering"),eWt.forEach(t),POr=r(MXe," (DeBERTa-v2 model)"),MXe.forEach(t),BOr=i(pe),h3=n(pe,"LI",{});var EXe=s(h3);G3e=n(EXe,"STRONG",{});var oWt=s(G3e);IOr=r(oWt,"distilbert"),oWt.forEach(t),NOr=r(EXe," \u2014 "),Zee=n(EXe,"A",{href:!0});var rWt=s(Zee);qOr=r(rWt,"TFDistilBertForQuestionAnswering"),rWt.forEach(t),jOr=r(EXe," (DistilBERT model)"),EXe.forEach(t),DOr=i(pe),p3=n(pe,"LI",{});var CXe=s(p3);O3e=n(CXe,"STRONG",{});var tWt=s(O3e);GOr=r(tWt,"electra"),tWt.forEach(t),OOr=r(CXe," \u2014 "),eoe=n(CXe,"A",{href:!0});var aWt=s(eoe);VOr=r(aWt,"TFElectraForQuestionAnswering"),aWt.forEach(t),XOr=r(CXe," (ELECTRA model)"),CXe.forEach(t),zOr=i(pe),_3=n(pe,"LI",{});var wXe=s(_3);V3e=n(wXe,"STRONG",{});var nWt=s(V3e);WOr=r(nWt,"flaubert"),nWt.forEach(t),QOr=r(wXe," \u2014 "),ooe=n(wXe,"A",{href:!0});var sWt=s(ooe);HOr=r(sWt,"TFFlaubertForQuestionAnsweringSimple"),sWt.forEach(t),UOr=r(wXe," (FlauBERT model)"),wXe.forEach(t),JOr=i(pe),u3=n(pe,"LI",{});var AXe=s(u3);X3e=n(AXe,"STRONG",{});var lWt=s(X3e);YOr=r(lWt,"funnel"),lWt.forEach(t),KOr=r(AXe," \u2014 "),roe=n(AXe,"A",{href:!0});var iWt=s(roe);ZOr=r(iWt,"TFFunnelForQuestionAnswering"),iWt.forEach(t),eVr=r(AXe," (Funnel Transformer model)"),AXe.forEach(t),oVr=i(pe),b3=n(pe,"LI",{});var LXe=s(b3);z3e=n(LXe,"STRONG",{});var dWt=s(z3e);rVr=r(dWt,"gptj"),dWt.forEach(t),tVr=r(LXe," \u2014 "),toe=n(LXe,"A",{href:!0});var cWt=s(toe);aVr=r(cWt,"TFGPTJForQuestionAnswering"),cWt.forEach(t),nVr=r(LXe," (GPT-J model)"),LXe.forEach(t),sVr=i(pe),v3=n(pe,"LI",{});var yXe=s(v3);W3e=n(yXe,"STRONG",{});var fWt=s(W3e);lVr=r(fWt,"longformer"),fWt.forEach(t),iVr=r(yXe," \u2014 "),aoe=n(yXe,"A",{href:!0});var mWt=s(aoe);dVr=r(mWt,"TFLongformerForQuestionAnswering"),mWt.forEach(t),cVr=r(yXe," (Longformer model)"),yXe.forEach(t),fVr=i(pe),F3=n(pe,"LI",{});var xXe=s(F3);Q3e=n(xXe,"STRONG",{});var gWt=s(Q3e);mVr=r(gWt,"mobilebert"),gWt.forEach(t),gVr=r(xXe," \u2014 "),noe=n(xXe,"A",{href:!0});var hWt=s(noe);hVr=r(hWt,"TFMobileBertForQuestionAnswering"),hWt.forEach(t),pVr=r(xXe," (MobileBERT model)"),xXe.forEach(t),_Vr=i(pe),T3=n(pe,"LI",{});var $Xe=s(T3);H3e=n($Xe,"STRONG",{});var pWt=s(H3e);uVr=r(pWt,"mpnet"),pWt.forEach(t),bVr=r($Xe," \u2014 "),soe=n($Xe,"A",{href:!0});var _Wt=s(soe);vVr=r(_Wt,"TFMPNetForQuestionAnswering"),_Wt.forEach(t),FVr=r($Xe," (MPNet model)"),$Xe.forEach(t),TVr=i(pe),M3=n(pe,"LI",{});var kXe=s(M3);U3e=n(kXe,"STRONG",{});var uWt=s(U3e);MVr=r(uWt,"rembert"),uWt.forEach(t),EVr=r(kXe," \u2014 "),loe=n(kXe,"A",{href:!0});var bWt=s(loe);CVr=r(bWt,"TFRemBertForQuestionAnswering"),bWt.forEach(t),wVr=r(kXe," (RemBERT model)"),kXe.forEach(t),AVr=i(pe),E3=n(pe,"LI",{});var SXe=s(E3);J3e=n(SXe,"STRONG",{});var vWt=s(J3e);LVr=r(vWt,"roberta"),vWt.forEach(t),yVr=r(SXe," \u2014 "),ioe=n(SXe,"A",{href:!0});var FWt=s(ioe);xVr=r(FWt,"TFRobertaForQuestionAnswering"),FWt.forEach(t),$Vr=r(SXe," (RoBERTa model)"),SXe.forEach(t),kVr=i(pe),C3=n(pe,"LI",{});var RXe=s(C3);Y3e=n(RXe,"STRONG",{});var TWt=s(Y3e);SVr=r(TWt,"roformer"),TWt.forEach(t),RVr=r(RXe," \u2014 "),doe=n(RXe,"A",{href:!0});var MWt=s(doe);PVr=r(MWt,"TFRoFormerForQuestionAnswering"),MWt.forEach(t),BVr=r(RXe," (RoFormer model)"),RXe.forEach(t),IVr=i(pe),w3=n(pe,"LI",{});var PXe=s(w3);K3e=n(PXe,"STRONG",{});var EWt=s(K3e);NVr=r(EWt,"xlm"),EWt.forEach(t),qVr=r(PXe," \u2014 "),coe=n(PXe,"A",{href:!0});var CWt=s(coe);jVr=r(CWt,"TFXLMForQuestionAnsweringSimple"),CWt.forEach(t),DVr=r(PXe," (XLM model)"),PXe.forEach(t),GVr=i(pe),A3=n(pe,"LI",{});var BXe=s(A3);Z3e=n(BXe,"STRONG",{});var wWt=s(Z3e);OVr=r(wWt,"xlm-roberta"),wWt.forEach(t),VVr=r(BXe," \u2014 "),foe=n(BXe,"A",{href:!0});var AWt=s(foe);XVr=r(AWt,"TFXLMRobertaForQuestionAnswering"),AWt.forEach(t),zVr=r(BXe," (XLM-RoBERTa model)"),BXe.forEach(t),WVr=i(pe),L3=n(pe,"LI",{});var IXe=s(L3);ewe=n(IXe,"STRONG",{});var LWt=s(ewe);QVr=r(LWt,"xlnet"),LWt.forEach(t),HVr=r(IXe," \u2014 "),moe=n(IXe,"A",{href:!0});var yWt=s(moe);UVr=r(yWt,"TFXLNetForQuestionAnsweringSimple"),yWt.forEach(t),JVr=r(IXe," (XLNet model)"),IXe.forEach(t),pe.forEach(t),YVr=i(li),T(y3.$$.fragment,li),li.forEach(t),si.forEach(t),MHe=i(f),Zc=n(f,"H2",{class:!0});var RJe=s(Zc);x3=n(RJe,"A",{id:!0,class:!0,href:!0});var xWt=s(x3);owe=n(xWt,"SPAN",{});var $Wt=s(owe);T(W$.$$.fragment,$Wt),$Wt.forEach(t),xWt.forEach(t),KVr=i(RJe),rwe=n(RJe,"SPAN",{});var kWt=s(rwe);ZVr=r(kWt,"TFAutoModelForVision2Seq"),kWt.forEach(t),RJe.forEach(t),EHe=i(f),_r=n(f,"DIV",{class:!0});var ii=s(_r);T(Q$.$$.fragment,ii),eXr=i(ii),ef=n(ii,"P",{});var yne=s(ef);oXr=r(yne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),goe=n(yne,"A",{href:!0});var SWt=s(goe);rXr=r(SWt,"from_pretrained()"),SWt.forEach(t),tXr=r(yne," class method or the "),hoe=n(yne,"A",{href:!0});var RWt=s(hoe);aXr=r(RWt,"from_config()"),RWt.forEach(t),nXr=r(yne,` class
method.`),yne.forEach(t),sXr=i(ii),H$=n(ii,"P",{});var PJe=s(H$);lXr=r(PJe,"This class cannot be instantiated directly using "),twe=n(PJe,"CODE",{});var PWt=s(twe);iXr=r(PWt,"__init__()"),PWt.forEach(t),dXr=r(PJe," (throws an error)."),PJe.forEach(t),cXr=i(ii),Ht=n(ii,"DIV",{class:!0});var _L=s(Ht);T(U$.$$.fragment,_L),fXr=i(_L),awe=n(_L,"P",{});var BWt=s(awe);mXr=r(BWt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),BWt.forEach(t),gXr=i(_L),of=n(_L,"P",{});var xne=s(of);hXr=r(xne,`Note:
Loading a model from its configuration file does `),nwe=n(xne,"STRONG",{});var IWt=s(nwe);pXr=r(IWt,"not"),IWt.forEach(t),_Xr=r(xne,` load the model weights. It only affects the
model\u2019s configuration. Use `),poe=n(xne,"A",{href:!0});var NWt=s(poe);uXr=r(NWt,"from_pretrained()"),NWt.forEach(t),bXr=r(xne," to load the model weights."),xne.forEach(t),vXr=i(_L),T($3.$$.fragment,_L),_L.forEach(t),FXr=i(ii),Xr=n(ii,"DIV",{class:!0});var di=s(Xr);T(J$.$$.fragment,di),TXr=i(di),swe=n(di,"P",{});var qWt=s(swe);MXr=r(qWt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),qWt.forEach(t),EXr=i(di),wn=n(di,"P",{});var uL=s(wn);CXr=r(uL,"The model class to instantiate is selected based on the "),lwe=n(uL,"CODE",{});var jWt=s(lwe);wXr=r(jWt,"model_type"),jWt.forEach(t),AXr=r(uL,` property of the config object (either
passed as an argument or loaded from `),iwe=n(uL,"CODE",{});var DWt=s(iwe);LXr=r(DWt,"pretrained_model_name_or_path"),DWt.forEach(t),yXr=r(uL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dwe=n(uL,"CODE",{});var GWt=s(dwe);xXr=r(GWt,"pretrained_model_name_or_path"),GWt.forEach(t),$Xr=r(uL,":"),uL.forEach(t),kXr=i(di),cwe=n(di,"UL",{});var OWt=s(cwe);k3=n(OWt,"LI",{});var NXe=s(k3);fwe=n(NXe,"STRONG",{});var VWt=s(fwe);SXr=r(VWt,"vision-encoder-decoder"),VWt.forEach(t),RXr=r(NXe," \u2014 "),_oe=n(NXe,"A",{href:!0});var XWt=s(_oe);PXr=r(XWt,"TFVisionEncoderDecoderModel"),XWt.forEach(t),BXr=r(NXe," (Vision Encoder decoder model)"),NXe.forEach(t),OWt.forEach(t),IXr=i(di),T(S3.$$.fragment,di),di.forEach(t),ii.forEach(t),CHe=i(f),rf=n(f,"H2",{class:!0});var BJe=s(rf);R3=n(BJe,"A",{id:!0,class:!0,href:!0});var zWt=s(R3);mwe=n(zWt,"SPAN",{});var WWt=s(mwe);T(Y$.$$.fragment,WWt),WWt.forEach(t),zWt.forEach(t),NXr=i(BJe),gwe=n(BJe,"SPAN",{});var QWt=s(gwe);qXr=r(QWt,"TFAutoModelForSpeechSeq2Seq"),QWt.forEach(t),BJe.forEach(t),wHe=i(f),ur=n(f,"DIV",{class:!0});var ci=s(ur);T(K$.$$.fragment,ci),jXr=i(ci),tf=n(ci,"P",{});var $ne=s(tf);DXr=r($ne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uoe=n($ne,"A",{href:!0});var HWt=s(uoe);GXr=r(HWt,"from_pretrained()"),HWt.forEach(t),OXr=r($ne," class method or the "),boe=n($ne,"A",{href:!0});var UWt=s(boe);VXr=r(UWt,"from_config()"),UWt.forEach(t),XXr=r($ne,` class
method.`),$ne.forEach(t),zXr=i(ci),Z$=n(ci,"P",{});var IJe=s(Z$);WXr=r(IJe,"This class cannot be instantiated directly using "),hwe=n(IJe,"CODE",{});var JWt=s(hwe);QXr=r(JWt,"__init__()"),JWt.forEach(t),HXr=r(IJe," (throws an error)."),IJe.forEach(t),UXr=i(ci),Ut=n(ci,"DIV",{class:!0});var bL=s(Ut);T(ek.$$.fragment,bL),JXr=i(bL),pwe=n(bL,"P",{});var YWt=s(pwe);YXr=r(YWt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),YWt.forEach(t),KXr=i(bL),af=n(bL,"P",{});var kne=s(af);ZXr=r(kne,`Note:
Loading a model from its configuration file does `),_we=n(kne,"STRONG",{});var KWt=s(_we);ezr=r(KWt,"not"),KWt.forEach(t),ozr=r(kne,` load the model weights. It only affects the
model\u2019s configuration. Use `),voe=n(kne,"A",{href:!0});var ZWt=s(voe);rzr=r(ZWt,"from_pretrained()"),ZWt.forEach(t),tzr=r(kne," to load the model weights."),kne.forEach(t),azr=i(bL),T(P3.$$.fragment,bL),bL.forEach(t),nzr=i(ci),zr=n(ci,"DIV",{class:!0});var fi=s(zr);T(ok.$$.fragment,fi),szr=i(fi),uwe=n(fi,"P",{});var eQt=s(uwe);lzr=r(eQt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),eQt.forEach(t),izr=i(fi),An=n(fi,"P",{});var vL=s(An);dzr=r(vL,"The model class to instantiate is selected based on the "),bwe=n(vL,"CODE",{});var oQt=s(bwe);czr=r(oQt,"model_type"),oQt.forEach(t),fzr=r(vL,` property of the config object (either
passed as an argument or loaded from `),vwe=n(vL,"CODE",{});var rQt=s(vwe);mzr=r(rQt,"pretrained_model_name_or_path"),rQt.forEach(t),gzr=r(vL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Fwe=n(vL,"CODE",{});var tQt=s(Fwe);hzr=r(tQt,"pretrained_model_name_or_path"),tQt.forEach(t),pzr=r(vL,":"),vL.forEach(t),_zr=i(fi),Twe=n(fi,"UL",{});var aQt=s(Twe);B3=n(aQt,"LI",{});var qXe=s(B3);Mwe=n(qXe,"STRONG",{});var nQt=s(Mwe);uzr=r(nQt,"speech_to_text"),nQt.forEach(t),bzr=r(qXe," \u2014 "),Foe=n(qXe,"A",{href:!0});var sQt=s(Foe);vzr=r(sQt,"TFSpeech2TextForConditionalGeneration"),sQt.forEach(t),Fzr=r(qXe," (Speech2Text model)"),qXe.forEach(t),aQt.forEach(t),Tzr=i(fi),T(I3.$$.fragment,fi),fi.forEach(t),ci.forEach(t),AHe=i(f),nf=n(f,"H2",{class:!0});var NJe=s(nf);N3=n(NJe,"A",{id:!0,class:!0,href:!0});var lQt=s(N3);Ewe=n(lQt,"SPAN",{});var iQt=s(Ewe);T(rk.$$.fragment,iQt),iQt.forEach(t),lQt.forEach(t),Mzr=i(NJe),Cwe=n(NJe,"SPAN",{});var dQt=s(Cwe);Ezr=r(dQt,"FlaxAutoModel"),dQt.forEach(t),NJe.forEach(t),LHe=i(f),br=n(f,"DIV",{class:!0});var mi=s(br);T(tk.$$.fragment,mi),Czr=i(mi),sf=n(mi,"P",{});var Sne=s(sf);wzr=r(Sne,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),Toe=n(Sne,"A",{href:!0});var cQt=s(Toe);Azr=r(cQt,"from_pretrained()"),cQt.forEach(t),Lzr=r(Sne," class method or the "),Moe=n(Sne,"A",{href:!0});var fQt=s(Moe);yzr=r(fQt,"from_config()"),fQt.forEach(t),xzr=r(Sne,` class
method.`),Sne.forEach(t),$zr=i(mi),ak=n(mi,"P",{});var qJe=s(ak);kzr=r(qJe,"This class cannot be instantiated directly using "),wwe=n(qJe,"CODE",{});var mQt=s(wwe);Szr=r(mQt,"__init__()"),mQt.forEach(t),Rzr=r(qJe," (throws an error)."),qJe.forEach(t),Pzr=i(mi),Jt=n(mi,"DIV",{class:!0});var FL=s(Jt);T(nk.$$.fragment,FL),Bzr=i(FL),Awe=n(FL,"P",{});var gQt=s(Awe);Izr=r(gQt,"Instantiates one of the base model classes of the library from a configuration."),gQt.forEach(t),Nzr=i(FL),lf=n(FL,"P",{});var Rne=s(lf);qzr=r(Rne,`Note:
Loading a model from its configuration file does `),Lwe=n(Rne,"STRONG",{});var hQt=s(Lwe);jzr=r(hQt,"not"),hQt.forEach(t),Dzr=r(Rne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Eoe=n(Rne,"A",{href:!0});var pQt=s(Eoe);Gzr=r(pQt,"from_pretrained()"),pQt.forEach(t),Ozr=r(Rne," to load the model weights."),Rne.forEach(t),Vzr=i(FL),T(q3.$$.fragment,FL),FL.forEach(t),Xzr=i(mi),Wr=n(mi,"DIV",{class:!0});var gi=s(Wr);T(sk.$$.fragment,gi),zzr=i(gi),ywe=n(gi,"P",{});var _Qt=s(ywe);Wzr=r(_Qt,"Instantiate one of the base model classes of the library from a pretrained model."),_Qt.forEach(t),Qzr=i(gi),Ln=n(gi,"P",{});var TL=s(Ln);Hzr=r(TL,"The model class to instantiate is selected based on the "),xwe=n(TL,"CODE",{});var uQt=s(xwe);Uzr=r(uQt,"model_type"),uQt.forEach(t),Jzr=r(TL,` property of the config object (either
passed as an argument or loaded from `),$we=n(TL,"CODE",{});var bQt=s($we);Yzr=r(bQt,"pretrained_model_name_or_path"),bQt.forEach(t),Kzr=r(TL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),kwe=n(TL,"CODE",{});var vQt=s(kwe);Zzr=r(vQt,"pretrained_model_name_or_path"),vQt.forEach(t),eWr=r(TL,":"),TL.forEach(t),oWr=i(gi),oe=n(gi,"UL",{});var te=s(oe);j3=n(te,"LI",{});var jXe=s(j3);Swe=n(jXe,"STRONG",{});var FQt=s(Swe);rWr=r(FQt,"albert"),FQt.forEach(t),tWr=r(jXe," \u2014 "),Coe=n(jXe,"A",{href:!0});var TQt=s(Coe);aWr=r(TQt,"FlaxAlbertModel"),TQt.forEach(t),nWr=r(jXe," (ALBERT model)"),jXe.forEach(t),sWr=i(te),D3=n(te,"LI",{});var DXe=s(D3);Rwe=n(DXe,"STRONG",{});var MQt=s(Rwe);lWr=r(MQt,"bart"),MQt.forEach(t),iWr=r(DXe," \u2014 "),woe=n(DXe,"A",{href:!0});var EQt=s(woe);dWr=r(EQt,"FlaxBartModel"),EQt.forEach(t),cWr=r(DXe," (BART model)"),DXe.forEach(t),fWr=i(te),G3=n(te,"LI",{});var GXe=s(G3);Pwe=n(GXe,"STRONG",{});var CQt=s(Pwe);mWr=r(CQt,"beit"),CQt.forEach(t),gWr=r(GXe," \u2014 "),Aoe=n(GXe,"A",{href:!0});var wQt=s(Aoe);hWr=r(wQt,"FlaxBeitModel"),wQt.forEach(t),pWr=r(GXe," (BEiT model)"),GXe.forEach(t),_Wr=i(te),O3=n(te,"LI",{});var OXe=s(O3);Bwe=n(OXe,"STRONG",{});var AQt=s(Bwe);uWr=r(AQt,"bert"),AQt.forEach(t),bWr=r(OXe," \u2014 "),Loe=n(OXe,"A",{href:!0});var LQt=s(Loe);vWr=r(LQt,"FlaxBertModel"),LQt.forEach(t),FWr=r(OXe," (BERT model)"),OXe.forEach(t),TWr=i(te),V3=n(te,"LI",{});var VXe=s(V3);Iwe=n(VXe,"STRONG",{});var yQt=s(Iwe);MWr=r(yQt,"big_bird"),yQt.forEach(t),EWr=r(VXe," \u2014 "),yoe=n(VXe,"A",{href:!0});var xQt=s(yoe);CWr=r(xQt,"FlaxBigBirdModel"),xQt.forEach(t),wWr=r(VXe," (BigBird model)"),VXe.forEach(t),AWr=i(te),X3=n(te,"LI",{});var XXe=s(X3);Nwe=n(XXe,"STRONG",{});var $Qt=s(Nwe);LWr=r($Qt,"blenderbot"),$Qt.forEach(t),yWr=r(XXe," \u2014 "),xoe=n(XXe,"A",{href:!0});var kQt=s(xoe);xWr=r(kQt,"FlaxBlenderbotModel"),kQt.forEach(t),$Wr=r(XXe," (Blenderbot model)"),XXe.forEach(t),kWr=i(te),z3=n(te,"LI",{});var zXe=s(z3);qwe=n(zXe,"STRONG",{});var SQt=s(qwe);SWr=r(SQt,"blenderbot-small"),SQt.forEach(t),RWr=r(zXe," \u2014 "),$oe=n(zXe,"A",{href:!0});var RQt=s($oe);PWr=r(RQt,"FlaxBlenderbotSmallModel"),RQt.forEach(t),BWr=r(zXe," (BlenderbotSmall model)"),zXe.forEach(t),IWr=i(te),W3=n(te,"LI",{});var WXe=s(W3);jwe=n(WXe,"STRONG",{});var PQt=s(jwe);NWr=r(PQt,"bloom"),PQt.forEach(t),qWr=r(WXe," \u2014 "),koe=n(WXe,"A",{href:!0});var BQt=s(koe);jWr=r(BQt,"FlaxBloomModel"),BQt.forEach(t),DWr=r(WXe," (BLOOM model)"),WXe.forEach(t),GWr=i(te),Q3=n(te,"LI",{});var QXe=s(Q3);Dwe=n(QXe,"STRONG",{});var IQt=s(Dwe);OWr=r(IQt,"clip"),IQt.forEach(t),VWr=r(QXe," \u2014 "),Soe=n(QXe,"A",{href:!0});var NQt=s(Soe);XWr=r(NQt,"FlaxCLIPModel"),NQt.forEach(t),zWr=r(QXe," (CLIP model)"),QXe.forEach(t),WWr=i(te),H3=n(te,"LI",{});var HXe=s(H3);Gwe=n(HXe,"STRONG",{});var qQt=s(Gwe);QWr=r(qQt,"distilbert"),qQt.forEach(t),HWr=r(HXe," \u2014 "),Roe=n(HXe,"A",{href:!0});var jQt=s(Roe);UWr=r(jQt,"FlaxDistilBertModel"),jQt.forEach(t),JWr=r(HXe," (DistilBERT model)"),HXe.forEach(t),YWr=i(te),U3=n(te,"LI",{});var UXe=s(U3);Owe=n(UXe,"STRONG",{});var DQt=s(Owe);KWr=r(DQt,"electra"),DQt.forEach(t),ZWr=r(UXe," \u2014 "),Poe=n(UXe,"A",{href:!0});var GQt=s(Poe);eQr=r(GQt,"FlaxElectraModel"),GQt.forEach(t),oQr=r(UXe," (ELECTRA model)"),UXe.forEach(t),rQr=i(te),J3=n(te,"LI",{});var JXe=s(J3);Vwe=n(JXe,"STRONG",{});var OQt=s(Vwe);tQr=r(OQt,"gpt2"),OQt.forEach(t),aQr=r(JXe," \u2014 "),Boe=n(JXe,"A",{href:!0});var VQt=s(Boe);nQr=r(VQt,"FlaxGPT2Model"),VQt.forEach(t),sQr=r(JXe," (OpenAI GPT-2 model)"),JXe.forEach(t),lQr=i(te),Y3=n(te,"LI",{});var YXe=s(Y3);Xwe=n(YXe,"STRONG",{});var XQt=s(Xwe);iQr=r(XQt,"gpt_neo"),XQt.forEach(t),dQr=r(YXe," \u2014 "),Ioe=n(YXe,"A",{href:!0});var zQt=s(Ioe);cQr=r(zQt,"FlaxGPTNeoModel"),zQt.forEach(t),fQr=r(YXe," (GPT Neo model)"),YXe.forEach(t),mQr=i(te),K3=n(te,"LI",{});var KXe=s(K3);zwe=n(KXe,"STRONG",{});var WQt=s(zwe);gQr=r(WQt,"gptj"),WQt.forEach(t),hQr=r(KXe," \u2014 "),Noe=n(KXe,"A",{href:!0});var QQt=s(Noe);pQr=r(QQt,"FlaxGPTJModel"),QQt.forEach(t),_Qr=r(KXe," (GPT-J model)"),KXe.forEach(t),uQr=i(te),Z3=n(te,"LI",{});var ZXe=s(Z3);Wwe=n(ZXe,"STRONG",{});var HQt=s(Wwe);bQr=r(HQt,"longt5"),HQt.forEach(t),vQr=r(ZXe," \u2014 "),qoe=n(ZXe,"A",{href:!0});var UQt=s(qoe);FQr=r(UQt,"FlaxLongT5Model"),UQt.forEach(t),TQr=r(ZXe," (LongT5 model)"),ZXe.forEach(t),MQr=i(te),ew=n(te,"LI",{});var eze=s(ew);Qwe=n(eze,"STRONG",{});var JQt=s(Qwe);EQr=r(JQt,"marian"),JQt.forEach(t),CQr=r(eze," \u2014 "),joe=n(eze,"A",{href:!0});var YQt=s(joe);wQr=r(YQt,"FlaxMarianModel"),YQt.forEach(t),AQr=r(eze," (Marian model)"),eze.forEach(t),LQr=i(te),ow=n(te,"LI",{});var oze=s(ow);Hwe=n(oze,"STRONG",{});var KQt=s(Hwe);yQr=r(KQt,"mbart"),KQt.forEach(t),xQr=r(oze," \u2014 "),Doe=n(oze,"A",{href:!0});var ZQt=s(Doe);$Qr=r(ZQt,"FlaxMBartModel"),ZQt.forEach(t),kQr=r(oze," (mBART model)"),oze.forEach(t),SQr=i(te),rw=n(te,"LI",{});var rze=s(rw);Uwe=n(rze,"STRONG",{});var eHt=s(Uwe);RQr=r(eHt,"mt5"),eHt.forEach(t),PQr=r(rze," \u2014 "),Goe=n(rze,"A",{href:!0});var oHt=s(Goe);BQr=r(oHt,"FlaxMT5Model"),oHt.forEach(t),IQr=r(rze," (MT5 model)"),rze.forEach(t),NQr=i(te),tw=n(te,"LI",{});var tze=s(tw);Jwe=n(tze,"STRONG",{});var rHt=s(Jwe);qQr=r(rHt,"opt"),rHt.forEach(t),jQr=r(tze," \u2014 "),Ooe=n(tze,"A",{href:!0});var tHt=s(Ooe);DQr=r(tHt,"FlaxOPTModel"),tHt.forEach(t),GQr=r(tze," (OPT model)"),tze.forEach(t),OQr=i(te),aw=n(te,"LI",{});var aze=s(aw);Ywe=n(aze,"STRONG",{});var aHt=s(Ywe);VQr=r(aHt,"pegasus"),aHt.forEach(t),XQr=r(aze," \u2014 "),Voe=n(aze,"A",{href:!0});var nHt=s(Voe);zQr=r(nHt,"FlaxPegasusModel"),nHt.forEach(t),WQr=r(aze," (Pegasus model)"),aze.forEach(t),QQr=i(te),nw=n(te,"LI",{});var nze=s(nw);Kwe=n(nze,"STRONG",{});var sHt=s(Kwe);HQr=r(sHt,"roberta"),sHt.forEach(t),UQr=r(nze," \u2014 "),Xoe=n(nze,"A",{href:!0});var lHt=s(Xoe);JQr=r(lHt,"FlaxRobertaModel"),lHt.forEach(t),YQr=r(nze," (RoBERTa model)"),nze.forEach(t),KQr=i(te),sw=n(te,"LI",{});var sze=s(sw);Zwe=n(sze,"STRONG",{});var iHt=s(Zwe);ZQr=r(iHt,"roformer"),iHt.forEach(t),eHr=r(sze," \u2014 "),zoe=n(sze,"A",{href:!0});var dHt=s(zoe);oHr=r(dHt,"FlaxRoFormerModel"),dHt.forEach(t),rHr=r(sze," (RoFormer model)"),sze.forEach(t),tHr=i(te),lw=n(te,"LI",{});var lze=s(lw);e6e=n(lze,"STRONG",{});var cHt=s(e6e);aHr=r(cHt,"t5"),cHt.forEach(t),nHr=r(lze," \u2014 "),Woe=n(lze,"A",{href:!0});var fHt=s(Woe);sHr=r(fHt,"FlaxT5Model"),fHt.forEach(t),lHr=r(lze," (T5 model)"),lze.forEach(t),iHr=i(te),iw=n(te,"LI",{});var ize=s(iw);o6e=n(ize,"STRONG",{});var mHt=s(o6e);dHr=r(mHt,"vision-text-dual-encoder"),mHt.forEach(t),cHr=r(ize," \u2014 "),Qoe=n(ize,"A",{href:!0});var gHt=s(Qoe);fHr=r(gHt,"FlaxVisionTextDualEncoderModel"),gHt.forEach(t),mHr=r(ize," (VisionTextDualEncoder model)"),ize.forEach(t),gHr=i(te),dw=n(te,"LI",{});var dze=s(dw);r6e=n(dze,"STRONG",{});var hHt=s(r6e);hHr=r(hHt,"vit"),hHt.forEach(t),pHr=r(dze," \u2014 "),Hoe=n(dze,"A",{href:!0});var pHt=s(Hoe);_Hr=r(pHt,"FlaxViTModel"),pHt.forEach(t),uHr=r(dze," (ViT model)"),dze.forEach(t),bHr=i(te),cw=n(te,"LI",{});var cze=s(cw);t6e=n(cze,"STRONG",{});var _Ht=s(t6e);vHr=r(_Ht,"wav2vec2"),_Ht.forEach(t),FHr=r(cze," \u2014 "),Uoe=n(cze,"A",{href:!0});var uHt=s(Uoe);THr=r(uHt,"FlaxWav2Vec2Model"),uHt.forEach(t),MHr=r(cze," (Wav2Vec2 model)"),cze.forEach(t),EHr=i(te),fw=n(te,"LI",{});var fze=s(fw);a6e=n(fze,"STRONG",{});var bHt=s(a6e);CHr=r(bHt,"xglm"),bHt.forEach(t),wHr=r(fze," \u2014 "),Joe=n(fze,"A",{href:!0});var vHt=s(Joe);AHr=r(vHt,"FlaxXGLMModel"),vHt.forEach(t),LHr=r(fze," (XGLM model)"),fze.forEach(t),yHr=i(te),mw=n(te,"LI",{});var mze=s(mw);n6e=n(mze,"STRONG",{});var FHt=s(n6e);xHr=r(FHt,"xlm-roberta"),FHt.forEach(t),$Hr=r(mze," \u2014 "),Yoe=n(mze,"A",{href:!0});var THt=s(Yoe);kHr=r(THt,"FlaxXLMRobertaModel"),THt.forEach(t),SHr=r(mze," (XLM-RoBERTa model)"),mze.forEach(t),te.forEach(t),RHr=i(gi),T(gw.$$.fragment,gi),gi.forEach(t),mi.forEach(t),yHe=i(f),df=n(f,"H2",{class:!0});var jJe=s(df);hw=n(jJe,"A",{id:!0,class:!0,href:!0});var MHt=s(hw);s6e=n(MHt,"SPAN",{});var EHt=s(s6e);T(lk.$$.fragment,EHt),EHt.forEach(t),MHt.forEach(t),PHr=i(jJe),l6e=n(jJe,"SPAN",{});var CHt=s(l6e);BHr=r(CHt,"FlaxAutoModelForCausalLM"),CHt.forEach(t),jJe.forEach(t),xHe=i(f),vr=n(f,"DIV",{class:!0});var hi=s(vr);T(ik.$$.fragment,hi),IHr=i(hi),cf=n(hi,"P",{});var Pne=s(cf);NHr=r(Pne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),Koe=n(Pne,"A",{href:!0});var wHt=s(Koe);qHr=r(wHt,"from_pretrained()"),wHt.forEach(t),jHr=r(Pne," class method or the "),Zoe=n(Pne,"A",{href:!0});var AHt=s(Zoe);DHr=r(AHt,"from_config()"),AHt.forEach(t),GHr=r(Pne,` class
method.`),Pne.forEach(t),OHr=i(hi),dk=n(hi,"P",{});var DJe=s(dk);VHr=r(DJe,"This class cannot be instantiated directly using "),i6e=n(DJe,"CODE",{});var LHt=s(i6e);XHr=r(LHt,"__init__()"),LHt.forEach(t),zHr=r(DJe," (throws an error)."),DJe.forEach(t),WHr=i(hi),Yt=n(hi,"DIV",{class:!0});var ML=s(Yt);T(ck.$$.fragment,ML),QHr=i(ML),d6e=n(ML,"P",{});var yHt=s(d6e);HHr=r(yHt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yHt.forEach(t),UHr=i(ML),ff=n(ML,"P",{});var Bne=s(ff);JHr=r(Bne,`Note:
Loading a model from its configuration file does `),c6e=n(Bne,"STRONG",{});var xHt=s(c6e);YHr=r(xHt,"not"),xHt.forEach(t),KHr=r(Bne,` load the model weights. It only affects the
model\u2019s configuration. Use `),ere=n(Bne,"A",{href:!0});var $Ht=s(ere);ZHr=r($Ht,"from_pretrained()"),$Ht.forEach(t),eUr=r(Bne," to load the model weights."),Bne.forEach(t),oUr=i(ML),T(pw.$$.fragment,ML),ML.forEach(t),rUr=i(hi),Qr=n(hi,"DIV",{class:!0});var pi=s(Qr);T(fk.$$.fragment,pi),tUr=i(pi),f6e=n(pi,"P",{});var kHt=s(f6e);aUr=r(kHt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kHt.forEach(t),nUr=i(pi),yn=n(pi,"P",{});var EL=s(yn);sUr=r(EL,"The model class to instantiate is selected based on the "),m6e=n(EL,"CODE",{});var SHt=s(m6e);lUr=r(SHt,"model_type"),SHt.forEach(t),iUr=r(EL,` property of the config object (either
passed as an argument or loaded from `),g6e=n(EL,"CODE",{});var RHt=s(g6e);dUr=r(RHt,"pretrained_model_name_or_path"),RHt.forEach(t),cUr=r(EL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h6e=n(EL,"CODE",{});var PHt=s(h6e);fUr=r(PHt,"pretrained_model_name_or_path"),PHt.forEach(t),mUr=r(EL,":"),EL.forEach(t),gUr=i(pi),Ae=n(pi,"UL",{});var Pe=s(Ae);_w=n(Pe,"LI",{});var gze=s(_w);p6e=n(gze,"STRONG",{});var BHt=s(p6e);hUr=r(BHt,"bart"),BHt.forEach(t),pUr=r(gze," \u2014 "),ore=n(gze,"A",{href:!0});var IHt=s(ore);_Ur=r(IHt,"FlaxBartForCausalLM"),IHt.forEach(t),uUr=r(gze," (BART model)"),gze.forEach(t),bUr=i(Pe),uw=n(Pe,"LI",{});var hze=s(uw);_6e=n(hze,"STRONG",{});var NHt=s(_6e);vUr=r(NHt,"bert"),NHt.forEach(t),FUr=r(hze," \u2014 "),rre=n(hze,"A",{href:!0});var qHt=s(rre);TUr=r(qHt,"FlaxBertForCausalLM"),qHt.forEach(t),MUr=r(hze," (BERT model)"),hze.forEach(t),EUr=i(Pe),bw=n(Pe,"LI",{});var pze=s(bw);u6e=n(pze,"STRONG",{});var jHt=s(u6e);CUr=r(jHt,"big_bird"),jHt.forEach(t),wUr=r(pze," \u2014 "),tre=n(pze,"A",{href:!0});var DHt=s(tre);AUr=r(DHt,"FlaxBigBirdForCausalLM"),DHt.forEach(t),LUr=r(pze," (BigBird model)"),pze.forEach(t),yUr=i(Pe),vw=n(Pe,"LI",{});var _ze=s(vw);b6e=n(_ze,"STRONG",{});var GHt=s(b6e);xUr=r(GHt,"bloom"),GHt.forEach(t),$Ur=r(_ze," \u2014 "),are=n(_ze,"A",{href:!0});var OHt=s(are);kUr=r(OHt,"FlaxBloomForCausalLM"),OHt.forEach(t),SUr=r(_ze," (BLOOM model)"),_ze.forEach(t),RUr=i(Pe),Fw=n(Pe,"LI",{});var uze=s(Fw);v6e=n(uze,"STRONG",{});var VHt=s(v6e);PUr=r(VHt,"electra"),VHt.forEach(t),BUr=r(uze," \u2014 "),nre=n(uze,"A",{href:!0});var XHt=s(nre);IUr=r(XHt,"FlaxElectraForCausalLM"),XHt.forEach(t),NUr=r(uze," (ELECTRA model)"),uze.forEach(t),qUr=i(Pe),Tw=n(Pe,"LI",{});var bze=s(Tw);F6e=n(bze,"STRONG",{});var zHt=s(F6e);jUr=r(zHt,"gpt2"),zHt.forEach(t),DUr=r(bze," \u2014 "),sre=n(bze,"A",{href:!0});var WHt=s(sre);GUr=r(WHt,"FlaxGPT2LMHeadModel"),WHt.forEach(t),OUr=r(bze," (OpenAI GPT-2 model)"),bze.forEach(t),VUr=i(Pe),Mw=n(Pe,"LI",{});var vze=s(Mw);T6e=n(vze,"STRONG",{});var QHt=s(T6e);XUr=r(QHt,"gpt_neo"),QHt.forEach(t),zUr=r(vze," \u2014 "),lre=n(vze,"A",{href:!0});var HHt=s(lre);WUr=r(HHt,"FlaxGPTNeoForCausalLM"),HHt.forEach(t),QUr=r(vze," (GPT Neo model)"),vze.forEach(t),HUr=i(Pe),Ew=n(Pe,"LI",{});var Fze=s(Ew);M6e=n(Fze,"STRONG",{});var UHt=s(M6e);UUr=r(UHt,"gptj"),UHt.forEach(t),JUr=r(Fze," \u2014 "),ire=n(Fze,"A",{href:!0});var JHt=s(ire);YUr=r(JHt,"FlaxGPTJForCausalLM"),JHt.forEach(t),KUr=r(Fze," (GPT-J model)"),Fze.forEach(t),ZUr=i(Pe),Cw=n(Pe,"LI",{});var Tze=s(Cw);E6e=n(Tze,"STRONG",{});var YHt=s(E6e);eJr=r(YHt,"opt"),YHt.forEach(t),oJr=r(Tze," \u2014 "),dre=n(Tze,"A",{href:!0});var KHt=s(dre);rJr=r(KHt,"FlaxOPTForCausalLM"),KHt.forEach(t),tJr=r(Tze," (OPT model)"),Tze.forEach(t),aJr=i(Pe),ww=n(Pe,"LI",{});var Mze=s(ww);C6e=n(Mze,"STRONG",{});var ZHt=s(C6e);nJr=r(ZHt,"roberta"),ZHt.forEach(t),sJr=r(Mze," \u2014 "),cre=n(Mze,"A",{href:!0});var eUt=s(cre);lJr=r(eUt,"FlaxRobertaForCausalLM"),eUt.forEach(t),iJr=r(Mze," (RoBERTa model)"),Mze.forEach(t),dJr=i(Pe),Aw=n(Pe,"LI",{});var Eze=s(Aw);w6e=n(Eze,"STRONG",{});var oUt=s(w6e);cJr=r(oUt,"xglm"),oUt.forEach(t),fJr=r(Eze," \u2014 "),fre=n(Eze,"A",{href:!0});var rUt=s(fre);mJr=r(rUt,"FlaxXGLMForCausalLM"),rUt.forEach(t),gJr=r(Eze," (XGLM model)"),Eze.forEach(t),Pe.forEach(t),hJr=i(pi),T(Lw.$$.fragment,pi),pi.forEach(t),hi.forEach(t),$He=i(f),mf=n(f,"H2",{class:!0});var GJe=s(mf);yw=n(GJe,"A",{id:!0,class:!0,href:!0});var tUt=s(yw);A6e=n(tUt,"SPAN",{});var aUt=s(A6e);T(mk.$$.fragment,aUt),aUt.forEach(t),tUt.forEach(t),pJr=i(GJe),L6e=n(GJe,"SPAN",{});var nUt=s(L6e);_Jr=r(nUt,"FlaxAutoModelForPreTraining"),nUt.forEach(t),GJe.forEach(t),kHe=i(f),Fr=n(f,"DIV",{class:!0});var _i=s(Fr);T(gk.$$.fragment,_i),uJr=i(_i),gf=n(_i,"P",{});var Ine=s(gf);bJr=r(Ine,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),mre=n(Ine,"A",{href:!0});var sUt=s(mre);vJr=r(sUt,"from_pretrained()"),sUt.forEach(t),FJr=r(Ine," class method or the "),gre=n(Ine,"A",{href:!0});var lUt=s(gre);TJr=r(lUt,"from_config()"),lUt.forEach(t),MJr=r(Ine,` class
method.`),Ine.forEach(t),EJr=i(_i),hk=n(_i,"P",{});var OJe=s(hk);CJr=r(OJe,"This class cannot be instantiated directly using "),y6e=n(OJe,"CODE",{});var iUt=s(y6e);wJr=r(iUt,"__init__()"),iUt.forEach(t),AJr=r(OJe," (throws an error)."),OJe.forEach(t),LJr=i(_i),Kt=n(_i,"DIV",{class:!0});var CL=s(Kt);T(pk.$$.fragment,CL),yJr=i(CL),x6e=n(CL,"P",{});var dUt=s(x6e);xJr=r(dUt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),dUt.forEach(t),$Jr=i(CL),hf=n(CL,"P",{});var Nne=s(hf);kJr=r(Nne,`Note:
Loading a model from its configuration file does `),$6e=n(Nne,"STRONG",{});var cUt=s($6e);SJr=r(cUt,"not"),cUt.forEach(t),RJr=r(Nne,` load the model weights. It only affects the
model\u2019s configuration. Use `),hre=n(Nne,"A",{href:!0});var fUt=s(hre);PJr=r(fUt,"from_pretrained()"),fUt.forEach(t),BJr=r(Nne," to load the model weights."),Nne.forEach(t),IJr=i(CL),T(xw.$$.fragment,CL),CL.forEach(t),NJr=i(_i),Hr=n(_i,"DIV",{class:!0});var ui=s(Hr);T(_k.$$.fragment,ui),qJr=i(ui),k6e=n(ui,"P",{});var mUt=s(k6e);jJr=r(mUt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),mUt.forEach(t),DJr=i(ui),xn=n(ui,"P",{});var wL=s(xn);GJr=r(wL,"The model class to instantiate is selected based on the "),S6e=n(wL,"CODE",{});var gUt=s(S6e);OJr=r(gUt,"model_type"),gUt.forEach(t),VJr=r(wL,` property of the config object (either
passed as an argument or loaded from `),R6e=n(wL,"CODE",{});var hUt=s(R6e);XJr=r(hUt,"pretrained_model_name_or_path"),hUt.forEach(t),zJr=r(wL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),P6e=n(wL,"CODE",{});var pUt=s(P6e);WJr=r(pUt,"pretrained_model_name_or_path"),pUt.forEach(t),QJr=r(wL,":"),wL.forEach(t),HJr=i(ui),Ee=n(ui,"UL",{});var we=s(Ee);$w=n(we,"LI",{});var Cze=s($w);B6e=n(Cze,"STRONG",{});var _Ut=s(B6e);UJr=r(_Ut,"albert"),_Ut.forEach(t),JJr=r(Cze," \u2014 "),pre=n(Cze,"A",{href:!0});var uUt=s(pre);YJr=r(uUt,"FlaxAlbertForPreTraining"),uUt.forEach(t),KJr=r(Cze," (ALBERT model)"),Cze.forEach(t),ZJr=i(we),kw=n(we,"LI",{});var wze=s(kw);I6e=n(wze,"STRONG",{});var bUt=s(I6e);eYr=r(bUt,"bart"),bUt.forEach(t),oYr=r(wze," \u2014 "),_re=n(wze,"A",{href:!0});var vUt=s(_re);rYr=r(vUt,"FlaxBartForConditionalGeneration"),vUt.forEach(t),tYr=r(wze," (BART model)"),wze.forEach(t),aYr=i(we),Sw=n(we,"LI",{});var Aze=s(Sw);N6e=n(Aze,"STRONG",{});var FUt=s(N6e);nYr=r(FUt,"bert"),FUt.forEach(t),sYr=r(Aze," \u2014 "),ure=n(Aze,"A",{href:!0});var TUt=s(ure);lYr=r(TUt,"FlaxBertForPreTraining"),TUt.forEach(t),iYr=r(Aze," (BERT model)"),Aze.forEach(t),dYr=i(we),Rw=n(we,"LI",{});var Lze=s(Rw);q6e=n(Lze,"STRONG",{});var MUt=s(q6e);cYr=r(MUt,"big_bird"),MUt.forEach(t),fYr=r(Lze," \u2014 "),bre=n(Lze,"A",{href:!0});var EUt=s(bre);mYr=r(EUt,"FlaxBigBirdForPreTraining"),EUt.forEach(t),gYr=r(Lze," (BigBird model)"),Lze.forEach(t),hYr=i(we),Pw=n(we,"LI",{});var yze=s(Pw);j6e=n(yze,"STRONG",{});var CUt=s(j6e);pYr=r(CUt,"electra"),CUt.forEach(t),_Yr=r(yze," \u2014 "),vre=n(yze,"A",{href:!0});var wUt=s(vre);uYr=r(wUt,"FlaxElectraForPreTraining"),wUt.forEach(t),bYr=r(yze," (ELECTRA model)"),yze.forEach(t),vYr=i(we),Bw=n(we,"LI",{});var xze=s(Bw);D6e=n(xze,"STRONG",{});var AUt=s(D6e);FYr=r(AUt,"longt5"),AUt.forEach(t),TYr=r(xze," \u2014 "),Fre=n(xze,"A",{href:!0});var LUt=s(Fre);MYr=r(LUt,"FlaxLongT5ForConditionalGeneration"),LUt.forEach(t),EYr=r(xze," (LongT5 model)"),xze.forEach(t),CYr=i(we),Iw=n(we,"LI",{});var $ze=s(Iw);G6e=n($ze,"STRONG",{});var yUt=s(G6e);wYr=r(yUt,"mbart"),yUt.forEach(t),AYr=r($ze," \u2014 "),Tre=n($ze,"A",{href:!0});var xUt=s(Tre);LYr=r(xUt,"FlaxMBartForConditionalGeneration"),xUt.forEach(t),yYr=r($ze," (mBART model)"),$ze.forEach(t),xYr=i(we),Nw=n(we,"LI",{});var kze=s(Nw);O6e=n(kze,"STRONG",{});var $Ut=s(O6e);$Yr=r($Ut,"mt5"),$Ut.forEach(t),kYr=r(kze," \u2014 "),Mre=n(kze,"A",{href:!0});var kUt=s(Mre);SYr=r(kUt,"FlaxMT5ForConditionalGeneration"),kUt.forEach(t),RYr=r(kze," (MT5 model)"),kze.forEach(t),PYr=i(we),qw=n(we,"LI",{});var Sze=s(qw);V6e=n(Sze,"STRONG",{});var SUt=s(V6e);BYr=r(SUt,"roberta"),SUt.forEach(t),IYr=r(Sze," \u2014 "),Ere=n(Sze,"A",{href:!0});var RUt=s(Ere);NYr=r(RUt,"FlaxRobertaForMaskedLM"),RUt.forEach(t),qYr=r(Sze," (RoBERTa model)"),Sze.forEach(t),jYr=i(we),jw=n(we,"LI",{});var Rze=s(jw);X6e=n(Rze,"STRONG",{});var PUt=s(X6e);DYr=r(PUt,"roformer"),PUt.forEach(t),GYr=r(Rze," \u2014 "),Cre=n(Rze,"A",{href:!0});var BUt=s(Cre);OYr=r(BUt,"FlaxRoFormerForMaskedLM"),BUt.forEach(t),VYr=r(Rze," (RoFormer model)"),Rze.forEach(t),XYr=i(we),Dw=n(we,"LI",{});var Pze=s(Dw);z6e=n(Pze,"STRONG",{});var IUt=s(z6e);zYr=r(IUt,"t5"),IUt.forEach(t),WYr=r(Pze," \u2014 "),wre=n(Pze,"A",{href:!0});var NUt=s(wre);QYr=r(NUt,"FlaxT5ForConditionalGeneration"),NUt.forEach(t),HYr=r(Pze," (T5 model)"),Pze.forEach(t),UYr=i(we),Gw=n(we,"LI",{});var Bze=s(Gw);W6e=n(Bze,"STRONG",{});var qUt=s(W6e);JYr=r(qUt,"wav2vec2"),qUt.forEach(t),YYr=r(Bze," \u2014 "),Are=n(Bze,"A",{href:!0});var jUt=s(Are);KYr=r(jUt,"FlaxWav2Vec2ForPreTraining"),jUt.forEach(t),ZYr=r(Bze," (Wav2Vec2 model)"),Bze.forEach(t),eKr=i(we),Ow=n(we,"LI",{});var Ize=s(Ow);Q6e=n(Ize,"STRONG",{});var DUt=s(Q6e);oKr=r(DUt,"xlm-roberta"),DUt.forEach(t),rKr=r(Ize," \u2014 "),Lre=n(Ize,"A",{href:!0});var GUt=s(Lre);tKr=r(GUt,"FlaxXLMRobertaForMaskedLM"),GUt.forEach(t),aKr=r(Ize," (XLM-RoBERTa model)"),Ize.forEach(t),we.forEach(t),nKr=i(ui),T(Vw.$$.fragment,ui),ui.forEach(t),_i.forEach(t),SHe=i(f),pf=n(f,"H2",{class:!0});var VJe=s(pf);Xw=n(VJe,"A",{id:!0,class:!0,href:!0});var OUt=s(Xw);H6e=n(OUt,"SPAN",{});var VUt=s(H6e);T(uk.$$.fragment,VUt),VUt.forEach(t),OUt.forEach(t),sKr=i(VJe),U6e=n(VJe,"SPAN",{});var XUt=s(U6e);lKr=r(XUt,"FlaxAutoModelForMaskedLM"),XUt.forEach(t),VJe.forEach(t),RHe=i(f),Tr=n(f,"DIV",{class:!0});var bi=s(Tr);T(bk.$$.fragment,bi),iKr=i(bi),_f=n(bi,"P",{});var qne=s(_f);dKr=r(qne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),yre=n(qne,"A",{href:!0});var zUt=s(yre);cKr=r(zUt,"from_pretrained()"),zUt.forEach(t),fKr=r(qne," class method or the "),xre=n(qne,"A",{href:!0});var WUt=s(xre);mKr=r(WUt,"from_config()"),WUt.forEach(t),gKr=r(qne,` class
method.`),qne.forEach(t),hKr=i(bi),vk=n(bi,"P",{});var XJe=s(vk);pKr=r(XJe,"This class cannot be instantiated directly using "),J6e=n(XJe,"CODE",{});var QUt=s(J6e);_Kr=r(QUt,"__init__()"),QUt.forEach(t),uKr=r(XJe," (throws an error)."),XJe.forEach(t),bKr=i(bi),Zt=n(bi,"DIV",{class:!0});var AL=s(Zt);T(Fk.$$.fragment,AL),vKr=i(AL),Y6e=n(AL,"P",{});var HUt=s(Y6e);FKr=r(HUt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),HUt.forEach(t),TKr=i(AL),uf=n(AL,"P",{});var jne=s(uf);MKr=r(jne,`Note:
Loading a model from its configuration file does `),K6e=n(jne,"STRONG",{});var UUt=s(K6e);EKr=r(UUt,"not"),UUt.forEach(t),CKr=r(jne,` load the model weights. It only affects the
model\u2019s configuration. Use `),$re=n(jne,"A",{href:!0});var JUt=s($re);wKr=r(JUt,"from_pretrained()"),JUt.forEach(t),AKr=r(jne," to load the model weights."),jne.forEach(t),LKr=i(AL),T(zw.$$.fragment,AL),AL.forEach(t),yKr=i(bi),Ur=n(bi,"DIV",{class:!0});var vi=s(Ur);T(Tk.$$.fragment,vi),xKr=i(vi),Z6e=n(vi,"P",{});var YUt=s(Z6e);$Kr=r(YUt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),YUt.forEach(t),kKr=i(vi),$n=n(vi,"P",{});var LL=s($n);SKr=r(LL,"The model class to instantiate is selected based on the "),eAe=n(LL,"CODE",{});var KUt=s(eAe);RKr=r(KUt,"model_type"),KUt.forEach(t),PKr=r(LL,` property of the config object (either
passed as an argument or loaded from `),oAe=n(LL,"CODE",{});var ZUt=s(oAe);BKr=r(ZUt,"pretrained_model_name_or_path"),ZUt.forEach(t),IKr=r(LL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),rAe=n(LL,"CODE",{});var eJt=s(rAe);NKr=r(eJt,"pretrained_model_name_or_path"),eJt.forEach(t),qKr=r(LL,":"),LL.forEach(t),jKr=i(vi),$e=n(vi,"UL",{});var qe=s($e);Ww=n(qe,"LI",{});var Nze=s(Ww);tAe=n(Nze,"STRONG",{});var oJt=s(tAe);DKr=r(oJt,"albert"),oJt.forEach(t),GKr=r(Nze," \u2014 "),kre=n(Nze,"A",{href:!0});var rJt=s(kre);OKr=r(rJt,"FlaxAlbertForMaskedLM"),rJt.forEach(t),VKr=r(Nze," (ALBERT model)"),Nze.forEach(t),XKr=i(qe),Qw=n(qe,"LI",{});var qze=s(Qw);aAe=n(qze,"STRONG",{});var tJt=s(aAe);zKr=r(tJt,"bart"),tJt.forEach(t),WKr=r(qze," \u2014 "),Sre=n(qze,"A",{href:!0});var aJt=s(Sre);QKr=r(aJt,"FlaxBartForConditionalGeneration"),aJt.forEach(t),HKr=r(qze," (BART model)"),qze.forEach(t),UKr=i(qe),Hw=n(qe,"LI",{});var jze=s(Hw);nAe=n(jze,"STRONG",{});var nJt=s(nAe);JKr=r(nJt,"bert"),nJt.forEach(t),YKr=r(jze," \u2014 "),Rre=n(jze,"A",{href:!0});var sJt=s(Rre);KKr=r(sJt,"FlaxBertForMaskedLM"),sJt.forEach(t),ZKr=r(jze," (BERT model)"),jze.forEach(t),eZr=i(qe),Uw=n(qe,"LI",{});var Dze=s(Uw);sAe=n(Dze,"STRONG",{});var lJt=s(sAe);oZr=r(lJt,"big_bird"),lJt.forEach(t),rZr=r(Dze," \u2014 "),Pre=n(Dze,"A",{href:!0});var iJt=s(Pre);tZr=r(iJt,"FlaxBigBirdForMaskedLM"),iJt.forEach(t),aZr=r(Dze," (BigBird model)"),Dze.forEach(t),nZr=i(qe),Jw=n(qe,"LI",{});var Gze=s(Jw);lAe=n(Gze,"STRONG",{});var dJt=s(lAe);sZr=r(dJt,"distilbert"),dJt.forEach(t),lZr=r(Gze," \u2014 "),Bre=n(Gze,"A",{href:!0});var cJt=s(Bre);iZr=r(cJt,"FlaxDistilBertForMaskedLM"),cJt.forEach(t),dZr=r(Gze," (DistilBERT model)"),Gze.forEach(t),cZr=i(qe),Yw=n(qe,"LI",{});var Oze=s(Yw);iAe=n(Oze,"STRONG",{});var fJt=s(iAe);fZr=r(fJt,"electra"),fJt.forEach(t),mZr=r(Oze," \u2014 "),Ire=n(Oze,"A",{href:!0});var mJt=s(Ire);gZr=r(mJt,"FlaxElectraForMaskedLM"),mJt.forEach(t),hZr=r(Oze," (ELECTRA model)"),Oze.forEach(t),pZr=i(qe),Kw=n(qe,"LI",{});var Vze=s(Kw);dAe=n(Vze,"STRONG",{});var gJt=s(dAe);_Zr=r(gJt,"mbart"),gJt.forEach(t),uZr=r(Vze," \u2014 "),Nre=n(Vze,"A",{href:!0});var hJt=s(Nre);bZr=r(hJt,"FlaxMBartForConditionalGeneration"),hJt.forEach(t),vZr=r(Vze," (mBART model)"),Vze.forEach(t),FZr=i(qe),Zw=n(qe,"LI",{});var Xze=s(Zw);cAe=n(Xze,"STRONG",{});var pJt=s(cAe);TZr=r(pJt,"roberta"),pJt.forEach(t),MZr=r(Xze," \u2014 "),qre=n(Xze,"A",{href:!0});var _Jt=s(qre);EZr=r(_Jt,"FlaxRobertaForMaskedLM"),_Jt.forEach(t),CZr=r(Xze," (RoBERTa model)"),Xze.forEach(t),wZr=i(qe),e6=n(qe,"LI",{});var zze=s(e6);fAe=n(zze,"STRONG",{});var uJt=s(fAe);AZr=r(uJt,"roformer"),uJt.forEach(t),LZr=r(zze," \u2014 "),jre=n(zze,"A",{href:!0});var bJt=s(jre);yZr=r(bJt,"FlaxRoFormerForMaskedLM"),bJt.forEach(t),xZr=r(zze," (RoFormer model)"),zze.forEach(t),$Zr=i(qe),o6=n(qe,"LI",{});var Wze=s(o6);mAe=n(Wze,"STRONG",{});var vJt=s(mAe);kZr=r(vJt,"xlm-roberta"),vJt.forEach(t),SZr=r(Wze," \u2014 "),Dre=n(Wze,"A",{href:!0});var FJt=s(Dre);RZr=r(FJt,"FlaxXLMRobertaForMaskedLM"),FJt.forEach(t),PZr=r(Wze," (XLM-RoBERTa model)"),Wze.forEach(t),qe.forEach(t),BZr=i(vi),T(r6.$$.fragment,vi),vi.forEach(t),bi.forEach(t),PHe=i(f),bf=n(f,"H2",{class:!0});var zJe=s(bf);t6=n(zJe,"A",{id:!0,class:!0,href:!0});var TJt=s(t6);gAe=n(TJt,"SPAN",{});var MJt=s(gAe);T(Mk.$$.fragment,MJt),MJt.forEach(t),TJt.forEach(t),IZr=i(zJe),hAe=n(zJe,"SPAN",{});var EJt=s(hAe);NZr=r(EJt,"FlaxAutoModelForSeq2SeqLM"),EJt.forEach(t),zJe.forEach(t),BHe=i(f),Mr=n(f,"DIV",{class:!0});var Fi=s(Mr);T(Ek.$$.fragment,Fi),qZr=i(Fi),vf=n(Fi,"P",{});var Dne=s(vf);jZr=r(Dne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),Gre=n(Dne,"A",{href:!0});var CJt=s(Gre);DZr=r(CJt,"from_pretrained()"),CJt.forEach(t),GZr=r(Dne," class method or the "),Ore=n(Dne,"A",{href:!0});var wJt=s(Ore);OZr=r(wJt,"from_config()"),wJt.forEach(t),VZr=r(Dne,` class
method.`),Dne.forEach(t),XZr=i(Fi),Ck=n(Fi,"P",{});var WJe=s(Ck);zZr=r(WJe,"This class cannot be instantiated directly using "),pAe=n(WJe,"CODE",{});var AJt=s(pAe);WZr=r(AJt,"__init__()"),AJt.forEach(t),QZr=r(WJe," (throws an error)."),WJe.forEach(t),HZr=i(Fi),ea=n(Fi,"DIV",{class:!0});var yL=s(ea);T(wk.$$.fragment,yL),UZr=i(yL),_Ae=n(yL,"P",{});var LJt=s(_Ae);JZr=r(LJt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),LJt.forEach(t),YZr=i(yL),Ff=n(yL,"P",{});var Gne=s(Ff);KZr=r(Gne,`Note:
Loading a model from its configuration file does `),uAe=n(Gne,"STRONG",{});var yJt=s(uAe);ZZr=r(yJt,"not"),yJt.forEach(t),eet=r(Gne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Vre=n(Gne,"A",{href:!0});var xJt=s(Vre);oet=r(xJt,"from_pretrained()"),xJt.forEach(t),ret=r(Gne," to load the model weights."),Gne.forEach(t),tet=i(yL),T(a6.$$.fragment,yL),yL.forEach(t),aet=i(Fi),Jr=n(Fi,"DIV",{class:!0});var Ti=s(Jr);T(Ak.$$.fragment,Ti),net=i(Ti),bAe=n(Ti,"P",{});var $Jt=s(bAe);set=r($Jt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),$Jt.forEach(t),iet=i(Ti),kn=n(Ti,"P",{});var xL=s(kn);det=r(xL,"The model class to instantiate is selected based on the "),vAe=n(xL,"CODE",{});var kJt=s(vAe);cet=r(kJt,"model_type"),kJt.forEach(t),fet=r(xL,` property of the config object (either
passed as an argument or loaded from `),FAe=n(xL,"CODE",{});var SJt=s(FAe);met=r(SJt,"pretrained_model_name_or_path"),SJt.forEach(t),get=r(xL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TAe=n(xL,"CODE",{});var RJt=s(TAe);het=r(RJt,"pretrained_model_name_or_path"),RJt.forEach(t),pet=r(xL,":"),xL.forEach(t),_et=i(Ti),ke=n(Ti,"UL",{});var je=s(ke);n6=n(je,"LI",{});var Qze=s(n6);MAe=n(Qze,"STRONG",{});var PJt=s(MAe);uet=r(PJt,"bart"),PJt.forEach(t),bet=r(Qze," \u2014 "),Xre=n(Qze,"A",{href:!0});var BJt=s(Xre);vet=r(BJt,"FlaxBartForConditionalGeneration"),BJt.forEach(t),Fet=r(Qze," (BART model)"),Qze.forEach(t),Tet=i(je),s6=n(je,"LI",{});var Hze=s(s6);EAe=n(Hze,"STRONG",{});var IJt=s(EAe);Met=r(IJt,"blenderbot"),IJt.forEach(t),Eet=r(Hze," \u2014 "),zre=n(Hze,"A",{href:!0});var NJt=s(zre);Cet=r(NJt,"FlaxBlenderbotForConditionalGeneration"),NJt.forEach(t),wet=r(Hze," (Blenderbot model)"),Hze.forEach(t),Aet=i(je),l6=n(je,"LI",{});var Uze=s(l6);CAe=n(Uze,"STRONG",{});var qJt=s(CAe);Let=r(qJt,"blenderbot-small"),qJt.forEach(t),yet=r(Uze," \u2014 "),Wre=n(Uze,"A",{href:!0});var jJt=s(Wre);xet=r(jJt,"FlaxBlenderbotSmallForConditionalGeneration"),jJt.forEach(t),$et=r(Uze," (BlenderbotSmall model)"),Uze.forEach(t),ket=i(je),i6=n(je,"LI",{});var Jze=s(i6);wAe=n(Jze,"STRONG",{});var DJt=s(wAe);Set=r(DJt,"encoder-decoder"),DJt.forEach(t),Ret=r(Jze," \u2014 "),Qre=n(Jze,"A",{href:!0});var GJt=s(Qre);Pet=r(GJt,"FlaxEncoderDecoderModel"),GJt.forEach(t),Bet=r(Jze," (Encoder decoder model)"),Jze.forEach(t),Iet=i(je),d6=n(je,"LI",{});var Yze=s(d6);AAe=n(Yze,"STRONG",{});var OJt=s(AAe);Net=r(OJt,"longt5"),OJt.forEach(t),qet=r(Yze," \u2014 "),Hre=n(Yze,"A",{href:!0});var VJt=s(Hre);jet=r(VJt,"FlaxLongT5ForConditionalGeneration"),VJt.forEach(t),Det=r(Yze," (LongT5 model)"),Yze.forEach(t),Get=i(je),c6=n(je,"LI",{});var Kze=s(c6);LAe=n(Kze,"STRONG",{});var XJt=s(LAe);Oet=r(XJt,"marian"),XJt.forEach(t),Vet=r(Kze," \u2014 "),Ure=n(Kze,"A",{href:!0});var zJt=s(Ure);Xet=r(zJt,"FlaxMarianMTModel"),zJt.forEach(t),zet=r(Kze," (Marian model)"),Kze.forEach(t),Wet=i(je),f6=n(je,"LI",{});var Zze=s(f6);yAe=n(Zze,"STRONG",{});var WJt=s(yAe);Qet=r(WJt,"mbart"),WJt.forEach(t),Het=r(Zze," \u2014 "),Jre=n(Zze,"A",{href:!0});var QJt=s(Jre);Uet=r(QJt,"FlaxMBartForConditionalGeneration"),QJt.forEach(t),Jet=r(Zze," (mBART model)"),Zze.forEach(t),Yet=i(je),m6=n(je,"LI",{});var eWe=s(m6);xAe=n(eWe,"STRONG",{});var HJt=s(xAe);Ket=r(HJt,"mt5"),HJt.forEach(t),Zet=r(eWe," \u2014 "),Yre=n(eWe,"A",{href:!0});var UJt=s(Yre);eot=r(UJt,"FlaxMT5ForConditionalGeneration"),UJt.forEach(t),oot=r(eWe," (MT5 model)"),eWe.forEach(t),rot=i(je),g6=n(je,"LI",{});var oWe=s(g6);$Ae=n(oWe,"STRONG",{});var JJt=s($Ae);tot=r(JJt,"pegasus"),JJt.forEach(t),aot=r(oWe," \u2014 "),Kre=n(oWe,"A",{href:!0});var YJt=s(Kre);not=r(YJt,"FlaxPegasusForConditionalGeneration"),YJt.forEach(t),sot=r(oWe," (Pegasus model)"),oWe.forEach(t),lot=i(je),h6=n(je,"LI",{});var rWe=s(h6);kAe=n(rWe,"STRONG",{});var KJt=s(kAe);iot=r(KJt,"t5"),KJt.forEach(t),dot=r(rWe," \u2014 "),Zre=n(rWe,"A",{href:!0});var ZJt=s(Zre);cot=r(ZJt,"FlaxT5ForConditionalGeneration"),ZJt.forEach(t),fot=r(rWe," (T5 model)"),rWe.forEach(t),je.forEach(t),mot=i(Ti),T(p6.$$.fragment,Ti),Ti.forEach(t),Fi.forEach(t),IHe=i(f),Tf=n(f,"H2",{class:!0});var QJe=s(Tf);_6=n(QJe,"A",{id:!0,class:!0,href:!0});var eYt=s(_6);SAe=n(eYt,"SPAN",{});var oYt=s(SAe);T(Lk.$$.fragment,oYt),oYt.forEach(t),eYt.forEach(t),got=i(QJe),RAe=n(QJe,"SPAN",{});var rYt=s(RAe);hot=r(rYt,"FlaxAutoModelForSequenceClassification"),rYt.forEach(t),QJe.forEach(t),NHe=i(f),Er=n(f,"DIV",{class:!0});var Mi=s(Er);T(yk.$$.fragment,Mi),pot=i(Mi),Mf=n(Mi,"P",{});var One=s(Mf);_ot=r(One,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),ete=n(One,"A",{href:!0});var tYt=s(ete);uot=r(tYt,"from_pretrained()"),tYt.forEach(t),bot=r(One," class method or the "),ote=n(One,"A",{href:!0});var aYt=s(ote);vot=r(aYt,"from_config()"),aYt.forEach(t),Fot=r(One,` class
method.`),One.forEach(t),Tot=i(Mi),xk=n(Mi,"P",{});var HJe=s(xk);Mot=r(HJe,"This class cannot be instantiated directly using "),PAe=n(HJe,"CODE",{});var nYt=s(PAe);Eot=r(nYt,"__init__()"),nYt.forEach(t),Cot=r(HJe," (throws an error)."),HJe.forEach(t),wot=i(Mi),oa=n(Mi,"DIV",{class:!0});var $L=s(oa);T($k.$$.fragment,$L),Aot=i($L),BAe=n($L,"P",{});var sYt=s(BAe);Lot=r(sYt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),sYt.forEach(t),yot=i($L),Ef=n($L,"P",{});var Vne=s(Ef);xot=r(Vne,`Note:
Loading a model from its configuration file does `),IAe=n(Vne,"STRONG",{});var lYt=s(IAe);$ot=r(lYt,"not"),lYt.forEach(t),kot=r(Vne,` load the model weights. It only affects the
model\u2019s configuration. Use `),rte=n(Vne,"A",{href:!0});var iYt=s(rte);Sot=r(iYt,"from_pretrained()"),iYt.forEach(t),Rot=r(Vne," to load the model weights."),Vne.forEach(t),Pot=i($L),T(u6.$$.fragment,$L),$L.forEach(t),Bot=i(Mi),Yr=n(Mi,"DIV",{class:!0});var Ei=s(Yr);T(kk.$$.fragment,Ei),Iot=i(Ei),NAe=n(Ei,"P",{});var dYt=s(NAe);Not=r(dYt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),dYt.forEach(t),qot=i(Ei),Sn=n(Ei,"P",{});var kL=s(Sn);jot=r(kL,"The model class to instantiate is selected based on the "),qAe=n(kL,"CODE",{});var cYt=s(qAe);Dot=r(cYt,"model_type"),cYt.forEach(t),Got=r(kL,` property of the config object (either
passed as an argument or loaded from `),jAe=n(kL,"CODE",{});var fYt=s(jAe);Oot=r(fYt,"pretrained_model_name_or_path"),fYt.forEach(t),Vot=r(kL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),DAe=n(kL,"CODE",{});var mYt=s(DAe);Xot=r(mYt,"pretrained_model_name_or_path"),mYt.forEach(t),zot=r(kL,":"),kL.forEach(t),Wot=i(Ei),Se=n(Ei,"UL",{});var De=s(Se);b6=n(De,"LI",{});var tWe=s(b6);GAe=n(tWe,"STRONG",{});var gYt=s(GAe);Qot=r(gYt,"albert"),gYt.forEach(t),Hot=r(tWe," \u2014 "),tte=n(tWe,"A",{href:!0});var hYt=s(tte);Uot=r(hYt,"FlaxAlbertForSequenceClassification"),hYt.forEach(t),Jot=r(tWe," (ALBERT model)"),tWe.forEach(t),Yot=i(De),v6=n(De,"LI",{});var aWe=s(v6);OAe=n(aWe,"STRONG",{});var pYt=s(OAe);Kot=r(pYt,"bart"),pYt.forEach(t),Zot=r(aWe," \u2014 "),ate=n(aWe,"A",{href:!0});var _Yt=s(ate);ert=r(_Yt,"FlaxBartForSequenceClassification"),_Yt.forEach(t),ort=r(aWe," (BART model)"),aWe.forEach(t),rrt=i(De),F6=n(De,"LI",{});var nWe=s(F6);VAe=n(nWe,"STRONG",{});var uYt=s(VAe);trt=r(uYt,"bert"),uYt.forEach(t),art=r(nWe," \u2014 "),nte=n(nWe,"A",{href:!0});var bYt=s(nte);nrt=r(bYt,"FlaxBertForSequenceClassification"),bYt.forEach(t),srt=r(nWe," (BERT model)"),nWe.forEach(t),lrt=i(De),T6=n(De,"LI",{});var sWe=s(T6);XAe=n(sWe,"STRONG",{});var vYt=s(XAe);irt=r(vYt,"big_bird"),vYt.forEach(t),drt=r(sWe," \u2014 "),ste=n(sWe,"A",{href:!0});var FYt=s(ste);crt=r(FYt,"FlaxBigBirdForSequenceClassification"),FYt.forEach(t),frt=r(sWe," (BigBird model)"),sWe.forEach(t),mrt=i(De),M6=n(De,"LI",{});var lWe=s(M6);zAe=n(lWe,"STRONG",{});var TYt=s(zAe);grt=r(TYt,"distilbert"),TYt.forEach(t),hrt=r(lWe," \u2014 "),lte=n(lWe,"A",{href:!0});var MYt=s(lte);prt=r(MYt,"FlaxDistilBertForSequenceClassification"),MYt.forEach(t),_rt=r(lWe," (DistilBERT model)"),lWe.forEach(t),urt=i(De),E6=n(De,"LI",{});var iWe=s(E6);WAe=n(iWe,"STRONG",{});var EYt=s(WAe);brt=r(EYt,"electra"),EYt.forEach(t),vrt=r(iWe," \u2014 "),ite=n(iWe,"A",{href:!0});var CYt=s(ite);Frt=r(CYt,"FlaxElectraForSequenceClassification"),CYt.forEach(t),Trt=r(iWe," (ELECTRA model)"),iWe.forEach(t),Mrt=i(De),C6=n(De,"LI",{});var dWe=s(C6);QAe=n(dWe,"STRONG",{});var wYt=s(QAe);Ert=r(wYt,"mbart"),wYt.forEach(t),Crt=r(dWe," \u2014 "),dte=n(dWe,"A",{href:!0});var AYt=s(dte);wrt=r(AYt,"FlaxMBartForSequenceClassification"),AYt.forEach(t),Art=r(dWe," (mBART model)"),dWe.forEach(t),Lrt=i(De),w6=n(De,"LI",{});var cWe=s(w6);HAe=n(cWe,"STRONG",{});var LYt=s(HAe);yrt=r(LYt,"roberta"),LYt.forEach(t),xrt=r(cWe," \u2014 "),cte=n(cWe,"A",{href:!0});var yYt=s(cte);$rt=r(yYt,"FlaxRobertaForSequenceClassification"),yYt.forEach(t),krt=r(cWe," (RoBERTa model)"),cWe.forEach(t),Srt=i(De),A6=n(De,"LI",{});var fWe=s(A6);UAe=n(fWe,"STRONG",{});var xYt=s(UAe);Rrt=r(xYt,"roformer"),xYt.forEach(t),Prt=r(fWe," \u2014 "),fte=n(fWe,"A",{href:!0});var $Yt=s(fte);Brt=r($Yt,"FlaxRoFormerForSequenceClassification"),$Yt.forEach(t),Irt=r(fWe," (RoFormer model)"),fWe.forEach(t),Nrt=i(De),L6=n(De,"LI",{});var mWe=s(L6);JAe=n(mWe,"STRONG",{});var kYt=s(JAe);qrt=r(kYt,"xlm-roberta"),kYt.forEach(t),jrt=r(mWe," \u2014 "),mte=n(mWe,"A",{href:!0});var SYt=s(mte);Drt=r(SYt,"FlaxXLMRobertaForSequenceClassification"),SYt.forEach(t),Grt=r(mWe," (XLM-RoBERTa model)"),mWe.forEach(t),De.forEach(t),Ort=i(Ei),T(y6.$$.fragment,Ei),Ei.forEach(t),Mi.forEach(t),qHe=i(f),Cf=n(f,"H2",{class:!0});var UJe=s(Cf);x6=n(UJe,"A",{id:!0,class:!0,href:!0});var RYt=s(x6);YAe=n(RYt,"SPAN",{});var PYt=s(YAe);T(Sk.$$.fragment,PYt),PYt.forEach(t),RYt.forEach(t),Vrt=i(UJe),KAe=n(UJe,"SPAN",{});var BYt=s(KAe);Xrt=r(BYt,"FlaxAutoModelForQuestionAnswering"),BYt.forEach(t),UJe.forEach(t),jHe=i(f),Cr=n(f,"DIV",{class:!0});var Ci=s(Cr);T(Rk.$$.fragment,Ci),zrt=i(Ci),wf=n(Ci,"P",{});var Xne=s(wf);Wrt=r(Xne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),gte=n(Xne,"A",{href:!0});var IYt=s(gte);Qrt=r(IYt,"from_pretrained()"),IYt.forEach(t),Hrt=r(Xne," class method or the "),hte=n(Xne,"A",{href:!0});var NYt=s(hte);Urt=r(NYt,"from_config()"),NYt.forEach(t),Jrt=r(Xne,` class
method.`),Xne.forEach(t),Yrt=i(Ci),Pk=n(Ci,"P",{});var JJe=s(Pk);Krt=r(JJe,"This class cannot be instantiated directly using "),ZAe=n(JJe,"CODE",{});var qYt=s(ZAe);Zrt=r(qYt,"__init__()"),qYt.forEach(t),ett=r(JJe," (throws an error)."),JJe.forEach(t),ott=i(Ci),ra=n(Ci,"DIV",{class:!0});var SL=s(ra);T(Bk.$$.fragment,SL),rtt=i(SL),e7e=n(SL,"P",{});var jYt=s(e7e);ttt=r(jYt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),jYt.forEach(t),att=i(SL),Af=n(SL,"P",{});var zne=s(Af);ntt=r(zne,`Note:
Loading a model from its configuration file does `),o7e=n(zne,"STRONG",{});var DYt=s(o7e);stt=r(DYt,"not"),DYt.forEach(t),ltt=r(zne,` load the model weights. It only affects the
model\u2019s configuration. Use `),pte=n(zne,"A",{href:!0});var GYt=s(pte);itt=r(GYt,"from_pretrained()"),GYt.forEach(t),dtt=r(zne," to load the model weights."),zne.forEach(t),ctt=i(SL),T($6.$$.fragment,SL),SL.forEach(t),ftt=i(Ci),Kr=n(Ci,"DIV",{class:!0});var wi=s(Kr);T(Ik.$$.fragment,wi),mtt=i(wi),r7e=n(wi,"P",{});var OYt=s(r7e);gtt=r(OYt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),OYt.forEach(t),htt=i(wi),Rn=n(wi,"P",{});var RL=s(Rn);ptt=r(RL,"The model class to instantiate is selected based on the "),t7e=n(RL,"CODE",{});var VYt=s(t7e);_tt=r(VYt,"model_type"),VYt.forEach(t),utt=r(RL,` property of the config object (either
passed as an argument or loaded from `),a7e=n(RL,"CODE",{});var XYt=s(a7e);btt=r(XYt,"pretrained_model_name_or_path"),XYt.forEach(t),vtt=r(RL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),n7e=n(RL,"CODE",{});var zYt=s(n7e);Ftt=r(zYt,"pretrained_model_name_or_path"),zYt.forEach(t),Ttt=r(RL,":"),RL.forEach(t),Mtt=i(wi),Re=n(wi,"UL",{});var Ge=s(Re);k6=n(Ge,"LI",{});var gWe=s(k6);s7e=n(gWe,"STRONG",{});var WYt=s(s7e);Ett=r(WYt,"albert"),WYt.forEach(t),Ctt=r(gWe," \u2014 "),_te=n(gWe,"A",{href:!0});var QYt=s(_te);wtt=r(QYt,"FlaxAlbertForQuestionAnswering"),QYt.forEach(t),Att=r(gWe," (ALBERT model)"),gWe.forEach(t),Ltt=i(Ge),S6=n(Ge,"LI",{});var hWe=s(S6);l7e=n(hWe,"STRONG",{});var HYt=s(l7e);ytt=r(HYt,"bart"),HYt.forEach(t),xtt=r(hWe," \u2014 "),ute=n(hWe,"A",{href:!0});var UYt=s(ute);$tt=r(UYt,"FlaxBartForQuestionAnswering"),UYt.forEach(t),ktt=r(hWe," (BART model)"),hWe.forEach(t),Stt=i(Ge),R6=n(Ge,"LI",{});var pWe=s(R6);i7e=n(pWe,"STRONG",{});var JYt=s(i7e);Rtt=r(JYt,"bert"),JYt.forEach(t),Ptt=r(pWe," \u2014 "),bte=n(pWe,"A",{href:!0});var YYt=s(bte);Btt=r(YYt,"FlaxBertForQuestionAnswering"),YYt.forEach(t),Itt=r(pWe," (BERT model)"),pWe.forEach(t),Ntt=i(Ge),P6=n(Ge,"LI",{});var _We=s(P6);d7e=n(_We,"STRONG",{});var KYt=s(d7e);qtt=r(KYt,"big_bird"),KYt.forEach(t),jtt=r(_We," \u2014 "),vte=n(_We,"A",{href:!0});var ZYt=s(vte);Dtt=r(ZYt,"FlaxBigBirdForQuestionAnswering"),ZYt.forEach(t),Gtt=r(_We," (BigBird model)"),_We.forEach(t),Ott=i(Ge),B6=n(Ge,"LI",{});var uWe=s(B6);c7e=n(uWe,"STRONG",{});var eKt=s(c7e);Vtt=r(eKt,"distilbert"),eKt.forEach(t),Xtt=r(uWe," \u2014 "),Fte=n(uWe,"A",{href:!0});var oKt=s(Fte);ztt=r(oKt,"FlaxDistilBertForQuestionAnswering"),oKt.forEach(t),Wtt=r(uWe," (DistilBERT model)"),uWe.forEach(t),Qtt=i(Ge),I6=n(Ge,"LI",{});var bWe=s(I6);f7e=n(bWe,"STRONG",{});var rKt=s(f7e);Htt=r(rKt,"electra"),rKt.forEach(t),Utt=r(bWe," \u2014 "),Tte=n(bWe,"A",{href:!0});var tKt=s(Tte);Jtt=r(tKt,"FlaxElectraForQuestionAnswering"),tKt.forEach(t),Ytt=r(bWe," (ELECTRA model)"),bWe.forEach(t),Ktt=i(Ge),N6=n(Ge,"LI",{});var vWe=s(N6);m7e=n(vWe,"STRONG",{});var aKt=s(m7e);Ztt=r(aKt,"mbart"),aKt.forEach(t),eat=r(vWe," \u2014 "),Mte=n(vWe,"A",{href:!0});var nKt=s(Mte);oat=r(nKt,"FlaxMBartForQuestionAnswering"),nKt.forEach(t),rat=r(vWe," (mBART model)"),vWe.forEach(t),tat=i(Ge),q6=n(Ge,"LI",{});var FWe=s(q6);g7e=n(FWe,"STRONG",{});var sKt=s(g7e);aat=r(sKt,"roberta"),sKt.forEach(t),nat=r(FWe," \u2014 "),Ete=n(FWe,"A",{href:!0});var lKt=s(Ete);sat=r(lKt,"FlaxRobertaForQuestionAnswering"),lKt.forEach(t),lat=r(FWe," (RoBERTa model)"),FWe.forEach(t),iat=i(Ge),j6=n(Ge,"LI",{});var TWe=s(j6);h7e=n(TWe,"STRONG",{});var iKt=s(h7e);dat=r(iKt,"roformer"),iKt.forEach(t),cat=r(TWe," \u2014 "),Cte=n(TWe,"A",{href:!0});var dKt=s(Cte);fat=r(dKt,"FlaxRoFormerForQuestionAnswering"),dKt.forEach(t),mat=r(TWe," (RoFormer model)"),TWe.forEach(t),gat=i(Ge),D6=n(Ge,"LI",{});var MWe=s(D6);p7e=n(MWe,"STRONG",{});var cKt=s(p7e);hat=r(cKt,"xlm-roberta"),cKt.forEach(t),pat=r(MWe," \u2014 "),wte=n(MWe,"A",{href:!0});var fKt=s(wte);_at=r(fKt,"FlaxXLMRobertaForQuestionAnswering"),fKt.forEach(t),uat=r(MWe," (XLM-RoBERTa model)"),MWe.forEach(t),Ge.forEach(t),bat=i(wi),T(G6.$$.fragment,wi),wi.forEach(t),Ci.forEach(t),DHe=i(f),Lf=n(f,"H2",{class:!0});var YJe=s(Lf);O6=n(YJe,"A",{id:!0,class:!0,href:!0});var mKt=s(O6);_7e=n(mKt,"SPAN",{});var gKt=s(_7e);T(Nk.$$.fragment,gKt),gKt.forEach(t),mKt.forEach(t),vat=i(YJe),u7e=n(YJe,"SPAN",{});var hKt=s(u7e);Fat=r(hKt,"FlaxAutoModelForTokenClassification"),hKt.forEach(t),YJe.forEach(t),GHe=i(f),wr=n(f,"DIV",{class:!0});var Ai=s(wr);T(qk.$$.fragment,Ai),Tat=i(Ai),yf=n(Ai,"P",{});var Wne=s(yf);Mat=r(Wne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Ate=n(Wne,"A",{href:!0});var pKt=s(Ate);Eat=r(pKt,"from_pretrained()"),pKt.forEach(t),Cat=r(Wne," class method or the "),Lte=n(Wne,"A",{href:!0});var _Kt=s(Lte);wat=r(_Kt,"from_config()"),_Kt.forEach(t),Aat=r(Wne,` class
method.`),Wne.forEach(t),Lat=i(Ai),jk=n(Ai,"P",{});var KJe=s(jk);yat=r(KJe,"This class cannot be instantiated directly using "),b7e=n(KJe,"CODE",{});var uKt=s(b7e);xat=r(uKt,"__init__()"),uKt.forEach(t),$at=r(KJe," (throws an error)."),KJe.forEach(t),kat=i(Ai),ta=n(Ai,"DIV",{class:!0});var PL=s(ta);T(Dk.$$.fragment,PL),Sat=i(PL),v7e=n(PL,"P",{});var bKt=s(v7e);Rat=r(bKt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),bKt.forEach(t),Pat=i(PL),xf=n(PL,"P",{});var Qne=s(xf);Bat=r(Qne,`Note:
Loading a model from its configuration file does `),F7e=n(Qne,"STRONG",{});var vKt=s(F7e);Iat=r(vKt,"not"),vKt.forEach(t),Nat=r(Qne,` load the model weights. It only affects the
model\u2019s configuration. Use `),yte=n(Qne,"A",{href:!0});var FKt=s(yte);qat=r(FKt,"from_pretrained()"),FKt.forEach(t),jat=r(Qne," to load the model weights."),Qne.forEach(t),Dat=i(PL),T(V6.$$.fragment,PL),PL.forEach(t),Gat=i(Ai),Zr=n(Ai,"DIV",{class:!0});var Li=s(Zr);T(Gk.$$.fragment,Li),Oat=i(Li),T7e=n(Li,"P",{});var TKt=s(T7e);Vat=r(TKt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),TKt.forEach(t),Xat=i(Li),Pn=n(Li,"P",{});var BL=s(Pn);zat=r(BL,"The model class to instantiate is selected based on the "),M7e=n(BL,"CODE",{});var MKt=s(M7e);Wat=r(MKt,"model_type"),MKt.forEach(t),Qat=r(BL,` property of the config object (either
passed as an argument or loaded from `),E7e=n(BL,"CODE",{});var EKt=s(E7e);Hat=r(EKt,"pretrained_model_name_or_path"),EKt.forEach(t),Uat=r(BL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),C7e=n(BL,"CODE",{});var CKt=s(C7e);Jat=r(CKt,"pretrained_model_name_or_path"),CKt.forEach(t),Yat=r(BL,":"),BL.forEach(t),Kat=i(Li),Xe=n(Li,"UL",{});var Co=s(Xe);X6=n(Co,"LI",{});var EWe=s(X6);w7e=n(EWe,"STRONG",{});var wKt=s(w7e);Zat=r(wKt,"albert"),wKt.forEach(t),ent=r(EWe," \u2014 "),xte=n(EWe,"A",{href:!0});var AKt=s(xte);ont=r(AKt,"FlaxAlbertForTokenClassification"),AKt.forEach(t),rnt=r(EWe," (ALBERT model)"),EWe.forEach(t),tnt=i(Co),z6=n(Co,"LI",{});var CWe=s(z6);A7e=n(CWe,"STRONG",{});var LKt=s(A7e);ant=r(LKt,"bert"),LKt.forEach(t),nnt=r(CWe," \u2014 "),$te=n(CWe,"A",{href:!0});var yKt=s($te);snt=r(yKt,"FlaxBertForTokenClassification"),yKt.forEach(t),lnt=r(CWe," (BERT model)"),CWe.forEach(t),int=i(Co),W6=n(Co,"LI",{});var wWe=s(W6);L7e=n(wWe,"STRONG",{});var xKt=s(L7e);dnt=r(xKt,"big_bird"),xKt.forEach(t),cnt=r(wWe," \u2014 "),kte=n(wWe,"A",{href:!0});var $Kt=s(kte);fnt=r($Kt,"FlaxBigBirdForTokenClassification"),$Kt.forEach(t),mnt=r(wWe," (BigBird model)"),wWe.forEach(t),gnt=i(Co),Q6=n(Co,"LI",{});var AWe=s(Q6);y7e=n(AWe,"STRONG",{});var kKt=s(y7e);hnt=r(kKt,"distilbert"),kKt.forEach(t),pnt=r(AWe," \u2014 "),Ste=n(AWe,"A",{href:!0});var SKt=s(Ste);_nt=r(SKt,"FlaxDistilBertForTokenClassification"),SKt.forEach(t),unt=r(AWe," (DistilBERT model)"),AWe.forEach(t),bnt=i(Co),H6=n(Co,"LI",{});var LWe=s(H6);x7e=n(LWe,"STRONG",{});var RKt=s(x7e);vnt=r(RKt,"electra"),RKt.forEach(t),Fnt=r(LWe," \u2014 "),Rte=n(LWe,"A",{href:!0});var PKt=s(Rte);Tnt=r(PKt,"FlaxElectraForTokenClassification"),PKt.forEach(t),Mnt=r(LWe," (ELECTRA model)"),LWe.forEach(t),Ent=i(Co),U6=n(Co,"LI",{});var yWe=s(U6);$7e=n(yWe,"STRONG",{});var BKt=s($7e);Cnt=r(BKt,"roberta"),BKt.forEach(t),wnt=r(yWe," \u2014 "),Pte=n(yWe,"A",{href:!0});var IKt=s(Pte);Ant=r(IKt,"FlaxRobertaForTokenClassification"),IKt.forEach(t),Lnt=r(yWe," (RoBERTa model)"),yWe.forEach(t),ynt=i(Co),J6=n(Co,"LI",{});var xWe=s(J6);k7e=n(xWe,"STRONG",{});var NKt=s(k7e);xnt=r(NKt,"roformer"),NKt.forEach(t),$nt=r(xWe," \u2014 "),Bte=n(xWe,"A",{href:!0});var qKt=s(Bte);knt=r(qKt,"FlaxRoFormerForTokenClassification"),qKt.forEach(t),Snt=r(xWe," (RoFormer model)"),xWe.forEach(t),Rnt=i(Co),Y6=n(Co,"LI",{});var $We=s(Y6);S7e=n($We,"STRONG",{});var jKt=s(S7e);Pnt=r(jKt,"xlm-roberta"),jKt.forEach(t),Bnt=r($We," \u2014 "),Ite=n($We,"A",{href:!0});var DKt=s(Ite);Int=r(DKt,"FlaxXLMRobertaForTokenClassification"),DKt.forEach(t),Nnt=r($We," (XLM-RoBERTa model)"),$We.forEach(t),Co.forEach(t),qnt=i(Li),T(K6.$$.fragment,Li),Li.forEach(t),Ai.forEach(t),OHe=i(f),$f=n(f,"H2",{class:!0});var ZJe=s($f);Z6=n(ZJe,"A",{id:!0,class:!0,href:!0});var GKt=s(Z6);R7e=n(GKt,"SPAN",{});var OKt=s(R7e);T(Ok.$$.fragment,OKt),OKt.forEach(t),GKt.forEach(t),jnt=i(ZJe),P7e=n(ZJe,"SPAN",{});var VKt=s(P7e);Dnt=r(VKt,"FlaxAutoModelForMultipleChoice"),VKt.forEach(t),ZJe.forEach(t),VHe=i(f),Ar=n(f,"DIV",{class:!0});var yi=s(Ar);T(Vk.$$.fragment,yi),Gnt=i(yi),kf=n(yi,"P",{});var Hne=s(kf);Ont=r(Hne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Nte=n(Hne,"A",{href:!0});var XKt=s(Nte);Vnt=r(XKt,"from_pretrained()"),XKt.forEach(t),Xnt=r(Hne," class method or the "),qte=n(Hne,"A",{href:!0});var zKt=s(qte);znt=r(zKt,"from_config()"),zKt.forEach(t),Wnt=r(Hne,` class
method.`),Hne.forEach(t),Qnt=i(yi),Xk=n(yi,"P",{});var eYe=s(Xk);Hnt=r(eYe,"This class cannot be instantiated directly using "),B7e=n(eYe,"CODE",{});var WKt=s(B7e);Unt=r(WKt,"__init__()"),WKt.forEach(t),Jnt=r(eYe," (throws an error)."),eYe.forEach(t),Ynt=i(yi),aa=n(yi,"DIV",{class:!0});var IL=s(aa);T(zk.$$.fragment,IL),Knt=i(IL),I7e=n(IL,"P",{});var QKt=s(I7e);Znt=r(QKt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),QKt.forEach(t),est=i(IL),Sf=n(IL,"P",{});var Une=s(Sf);ost=r(Une,`Note:
Loading a model from its configuration file does `),N7e=n(Une,"STRONG",{});var HKt=s(N7e);rst=r(HKt,"not"),HKt.forEach(t),tst=r(Une,` load the model weights. It only affects the
model\u2019s configuration. Use `),jte=n(Une,"A",{href:!0});var UKt=s(jte);ast=r(UKt,"from_pretrained()"),UKt.forEach(t),nst=r(Une," to load the model weights."),Une.forEach(t),sst=i(IL),T(eA.$$.fragment,IL),IL.forEach(t),lst=i(yi),et=n(yi,"DIV",{class:!0});var xi=s(et);T(Wk.$$.fragment,xi),ist=i(xi),q7e=n(xi,"P",{});var JKt=s(q7e);dst=r(JKt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),JKt.forEach(t),cst=i(xi),Bn=n(xi,"P",{});var NL=s(Bn);fst=r(NL,"The model class to instantiate is selected based on the "),j7e=n(NL,"CODE",{});var YKt=s(j7e);mst=r(YKt,"model_type"),YKt.forEach(t),gst=r(NL,` property of the config object (either
passed as an argument or loaded from `),D7e=n(NL,"CODE",{});var KKt=s(D7e);hst=r(KKt,"pretrained_model_name_or_path"),KKt.forEach(t),pst=r(NL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),G7e=n(NL,"CODE",{});var ZKt=s(G7e);_st=r(ZKt,"pretrained_model_name_or_path"),ZKt.forEach(t),ust=r(NL,":"),NL.forEach(t),bst=i(xi),ze=n(xi,"UL",{});var wo=s(ze);oA=n(wo,"LI",{});var kWe=s(oA);O7e=n(kWe,"STRONG",{});var eZt=s(O7e);vst=r(eZt,"albert"),eZt.forEach(t),Fst=r(kWe," \u2014 "),Dte=n(kWe,"A",{href:!0});var oZt=s(Dte);Tst=r(oZt,"FlaxAlbertForMultipleChoice"),oZt.forEach(t),Mst=r(kWe," (ALBERT model)"),kWe.forEach(t),Est=i(wo),rA=n(wo,"LI",{});var SWe=s(rA);V7e=n(SWe,"STRONG",{});var rZt=s(V7e);Cst=r(rZt,"bert"),rZt.forEach(t),wst=r(SWe," \u2014 "),Gte=n(SWe,"A",{href:!0});var tZt=s(Gte);Ast=r(tZt,"FlaxBertForMultipleChoice"),tZt.forEach(t),Lst=r(SWe," (BERT model)"),SWe.forEach(t),yst=i(wo),tA=n(wo,"LI",{});var RWe=s(tA);X7e=n(RWe,"STRONG",{});var aZt=s(X7e);xst=r(aZt,"big_bird"),aZt.forEach(t),$st=r(RWe," \u2014 "),Ote=n(RWe,"A",{href:!0});var nZt=s(Ote);kst=r(nZt,"FlaxBigBirdForMultipleChoice"),nZt.forEach(t),Sst=r(RWe," (BigBird model)"),RWe.forEach(t),Rst=i(wo),aA=n(wo,"LI",{});var PWe=s(aA);z7e=n(PWe,"STRONG",{});var sZt=s(z7e);Pst=r(sZt,"distilbert"),sZt.forEach(t),Bst=r(PWe," \u2014 "),Vte=n(PWe,"A",{href:!0});var lZt=s(Vte);Ist=r(lZt,"FlaxDistilBertForMultipleChoice"),lZt.forEach(t),Nst=r(PWe," (DistilBERT model)"),PWe.forEach(t),qst=i(wo),nA=n(wo,"LI",{});var BWe=s(nA);W7e=n(BWe,"STRONG",{});var iZt=s(W7e);jst=r(iZt,"electra"),iZt.forEach(t),Dst=r(BWe," \u2014 "),Xte=n(BWe,"A",{href:!0});var dZt=s(Xte);Gst=r(dZt,"FlaxElectraForMultipleChoice"),dZt.forEach(t),Ost=r(BWe," (ELECTRA model)"),BWe.forEach(t),Vst=i(wo),sA=n(wo,"LI",{});var IWe=s(sA);Q7e=n(IWe,"STRONG",{});var cZt=s(Q7e);Xst=r(cZt,"roberta"),cZt.forEach(t),zst=r(IWe," \u2014 "),zte=n(IWe,"A",{href:!0});var fZt=s(zte);Wst=r(fZt,"FlaxRobertaForMultipleChoice"),fZt.forEach(t),Qst=r(IWe," (RoBERTa model)"),IWe.forEach(t),Hst=i(wo),lA=n(wo,"LI",{});var NWe=s(lA);H7e=n(NWe,"STRONG",{});var mZt=s(H7e);Ust=r(mZt,"roformer"),mZt.forEach(t),Jst=r(NWe," \u2014 "),Wte=n(NWe,"A",{href:!0});var gZt=s(Wte);Yst=r(gZt,"FlaxRoFormerForMultipleChoice"),gZt.forEach(t),Kst=r(NWe," (RoFormer model)"),NWe.forEach(t),Zst=i(wo),iA=n(wo,"LI",{});var qWe=s(iA);U7e=n(qWe,"STRONG",{});var hZt=s(U7e);elt=r(hZt,"xlm-roberta"),hZt.forEach(t),olt=r(qWe," \u2014 "),Qte=n(qWe,"A",{href:!0});var pZt=s(Qte);rlt=r(pZt,"FlaxXLMRobertaForMultipleChoice"),pZt.forEach(t),tlt=r(qWe," (XLM-RoBERTa model)"),qWe.forEach(t),wo.forEach(t),alt=i(xi),T(dA.$$.fragment,xi),xi.forEach(t),yi.forEach(t),XHe=i(f),Rf=n(f,"H2",{class:!0});var oYe=s(Rf);cA=n(oYe,"A",{id:!0,class:!0,href:!0});var _Zt=s(cA);J7e=n(_Zt,"SPAN",{});var uZt=s(J7e);T(Qk.$$.fragment,uZt),uZt.forEach(t),_Zt.forEach(t),nlt=i(oYe),Y7e=n(oYe,"SPAN",{});var bZt=s(Y7e);slt=r(bZt,"FlaxAutoModelForNextSentencePrediction"),bZt.forEach(t),oYe.forEach(t),zHe=i(f),Lr=n(f,"DIV",{class:!0});var $i=s(Lr);T(Hk.$$.fragment,$i),llt=i($i),Pf=n($i,"P",{});var Jne=s(Pf);ilt=r(Jne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),Hte=n(Jne,"A",{href:!0});var vZt=s(Hte);dlt=r(vZt,"from_pretrained()"),vZt.forEach(t),clt=r(Jne," class method or the "),Ute=n(Jne,"A",{href:!0});var FZt=s(Ute);flt=r(FZt,"from_config()"),FZt.forEach(t),mlt=r(Jne,` class
method.`),Jne.forEach(t),glt=i($i),Uk=n($i,"P",{});var rYe=s(Uk);hlt=r(rYe,"This class cannot be instantiated directly using "),K7e=n(rYe,"CODE",{});var TZt=s(K7e);plt=r(TZt,"__init__()"),TZt.forEach(t),_lt=r(rYe," (throws an error)."),rYe.forEach(t),ult=i($i),na=n($i,"DIV",{class:!0});var qL=s(na);T(Jk.$$.fragment,qL),blt=i(qL),Z7e=n(qL,"P",{});var MZt=s(Z7e);vlt=r(MZt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),MZt.forEach(t),Flt=i(qL),Bf=n(qL,"P",{});var Yne=s(Bf);Tlt=r(Yne,`Note:
Loading a model from its configuration file does `),eLe=n(Yne,"STRONG",{});var EZt=s(eLe);Mlt=r(EZt,"not"),EZt.forEach(t),Elt=r(Yne,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jte=n(Yne,"A",{href:!0});var CZt=s(Jte);Clt=r(CZt,"from_pretrained()"),CZt.forEach(t),wlt=r(Yne," to load the model weights."),Yne.forEach(t),Alt=i(qL),T(fA.$$.fragment,qL),qL.forEach(t),Llt=i($i),ot=n($i,"DIV",{class:!0});var ki=s(ot);T(Yk.$$.fragment,ki),ylt=i(ki),oLe=n(ki,"P",{});var wZt=s(oLe);xlt=r(wZt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),wZt.forEach(t),$lt=i(ki),In=n(ki,"P",{});var jL=s(In);klt=r(jL,"The model class to instantiate is selected based on the "),rLe=n(jL,"CODE",{});var AZt=s(rLe);Slt=r(AZt,"model_type"),AZt.forEach(t),Rlt=r(jL,` property of the config object (either
passed as an argument or loaded from `),tLe=n(jL,"CODE",{});var LZt=s(tLe);Plt=r(LZt,"pretrained_model_name_or_path"),LZt.forEach(t),Blt=r(jL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),aLe=n(jL,"CODE",{});var yZt=s(aLe);Ilt=r(yZt,"pretrained_model_name_or_path"),yZt.forEach(t),Nlt=r(jL,":"),jL.forEach(t),qlt=i(ki),nLe=n(ki,"UL",{});var xZt=s(nLe);mA=n(xZt,"LI",{});var jWe=s(mA);sLe=n(jWe,"STRONG",{});var $Zt=s(sLe);jlt=r($Zt,"bert"),$Zt.forEach(t),Dlt=r(jWe," \u2014 "),Yte=n(jWe,"A",{href:!0});var kZt=s(Yte);Glt=r(kZt,"FlaxBertForNextSentencePrediction"),kZt.forEach(t),Olt=r(jWe," (BERT model)"),jWe.forEach(t),xZt.forEach(t),Vlt=i(ki),T(gA.$$.fragment,ki),ki.forEach(t),$i.forEach(t),WHe=i(f),If=n(f,"H2",{class:!0});var tYe=s(If);hA=n(tYe,"A",{id:!0,class:!0,href:!0});var SZt=s(hA);lLe=n(SZt,"SPAN",{});var RZt=s(lLe);T(Kk.$$.fragment,RZt),RZt.forEach(t),SZt.forEach(t),Xlt=i(tYe),iLe=n(tYe,"SPAN",{});var PZt=s(iLe);zlt=r(PZt,"FlaxAutoModelForImageClassification"),PZt.forEach(t),tYe.forEach(t),QHe=i(f),yr=n(f,"DIV",{class:!0});var Si=s(yr);T(Zk.$$.fragment,Si),Wlt=i(Si),Nf=n(Si,"P",{});var Kne=s(Nf);Qlt=r(Kne,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),Kte=n(Kne,"A",{href:!0});var BZt=s(Kte);Hlt=r(BZt,"from_pretrained()"),BZt.forEach(t),Ult=r(Kne," class method or the "),Zte=n(Kne,"A",{href:!0});var IZt=s(Zte);Jlt=r(IZt,"from_config()"),IZt.forEach(t),Ylt=r(Kne,` class
method.`),Kne.forEach(t),Klt=i(Si),eS=n(Si,"P",{});var aYe=s(eS);Zlt=r(aYe,"This class cannot be instantiated directly using "),dLe=n(aYe,"CODE",{});var NZt=s(dLe);eit=r(NZt,"__init__()"),NZt.forEach(t),oit=r(aYe," (throws an error)."),aYe.forEach(t),rit=i(Si),sa=n(Si,"DIV",{class:!0});var DL=s(sa);T(oS.$$.fragment,DL),tit=i(DL),cLe=n(DL,"P",{});var qZt=s(cLe);ait=r(qZt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),qZt.forEach(t),nit=i(DL),qf=n(DL,"P",{});var Zne=s(qf);sit=r(Zne,`Note:
Loading a model from its configuration file does `),fLe=n(Zne,"STRONG",{});var jZt=s(fLe);lit=r(jZt,"not"),jZt.forEach(t),iit=r(Zne,` load the model weights. It only affects the
model\u2019s configuration. Use `),eae=n(Zne,"A",{href:!0});var DZt=s(eae);dit=r(DZt,"from_pretrained()"),DZt.forEach(t),cit=r(Zne," to load the model weights."),Zne.forEach(t),fit=i(DL),T(pA.$$.fragment,DL),DL.forEach(t),mit=i(Si),rt=n(Si,"DIV",{class:!0});var Ri=s(rt);T(rS.$$.fragment,Ri),git=i(Ri),mLe=n(Ri,"P",{});var GZt=s(mLe);hit=r(GZt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),GZt.forEach(t),pit=i(Ri),Nn=n(Ri,"P",{});var GL=s(Nn);_it=r(GL,"The model class to instantiate is selected based on the "),gLe=n(GL,"CODE",{});var OZt=s(gLe);uit=r(OZt,"model_type"),OZt.forEach(t),bit=r(GL,` property of the config object (either
passed as an argument or loaded from `),hLe=n(GL,"CODE",{});var VZt=s(hLe);vit=r(VZt,"pretrained_model_name_or_path"),VZt.forEach(t),Fit=r(GL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),pLe=n(GL,"CODE",{});var XZt=s(pLe);Tit=r(XZt,"pretrained_model_name_or_path"),XZt.forEach(t),Mit=r(GL,":"),GL.forEach(t),Eit=i(Ri),tS=n(Ri,"UL",{});var nYe=s(tS);_A=n(nYe,"LI",{});var DWe=s(_A);_Le=n(DWe,"STRONG",{});var zZt=s(_Le);Cit=r(zZt,"beit"),zZt.forEach(t),wit=r(DWe," \u2014 "),oae=n(DWe,"A",{href:!0});var WZt=s(oae);Ait=r(WZt,"FlaxBeitForImageClassification"),WZt.forEach(t),Lit=r(DWe," (BEiT model)"),DWe.forEach(t),yit=i(nYe),uA=n(nYe,"LI",{});var GWe=s(uA);uLe=n(GWe,"STRONG",{});var QZt=s(uLe);xit=r(QZt,"vit"),QZt.forEach(t),$it=r(GWe," \u2014 "),rae=n(GWe,"A",{href:!0});var HZt=s(rae);kit=r(HZt,"FlaxViTForImageClassification"),HZt.forEach(t),Sit=r(GWe," (ViT model)"),GWe.forEach(t),nYe.forEach(t),Rit=i(Ri),T(bA.$$.fragment,Ri),Ri.forEach(t),Si.forEach(t),HHe=i(f),jf=n(f,"H2",{class:!0});var sYe=s(jf);vA=n(sYe,"A",{id:!0,class:!0,href:!0});var UZt=s(vA);bLe=n(UZt,"SPAN",{});var JZt=s(bLe);T(aS.$$.fragment,JZt),JZt.forEach(t),UZt.forEach(t),Pit=i(sYe),vLe=n(sYe,"SPAN",{});var YZt=s(vLe);Bit=r(YZt,"FlaxAutoModelForVision2Seq"),YZt.forEach(t),sYe.forEach(t),UHe=i(f),xr=n(f,"DIV",{class:!0});var Pi=s(xr);T(nS.$$.fragment,Pi),Iit=i(Pi),Df=n(Pi,"P",{});var ese=s(Df);Nit=r(ese,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),tae=n(ese,"A",{href:!0});var KZt=s(tae);qit=r(KZt,"from_pretrained()"),KZt.forEach(t),jit=r(ese," class method or the "),aae=n(ese,"A",{href:!0});var ZZt=s(aae);Dit=r(ZZt,"from_config()"),ZZt.forEach(t),Git=r(ese,` class
method.`),ese.forEach(t),Oit=i(Pi),sS=n(Pi,"P",{});var lYe=s(sS);Vit=r(lYe,"This class cannot be instantiated directly using "),FLe=n(lYe,"CODE",{});var eea=s(FLe);Xit=r(eea,"__init__()"),eea.forEach(t),zit=r(lYe," (throws an error)."),lYe.forEach(t),Wit=i(Pi),la=n(Pi,"DIV",{class:!0});var OL=s(la);T(lS.$$.fragment,OL),Qit=i(OL),TLe=n(OL,"P",{});var oea=s(TLe);Hit=r(oea,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),oea.forEach(t),Uit=i(OL),Gf=n(OL,"P",{});var ose=s(Gf);Jit=r(ose,`Note:
Loading a model from its configuration file does `),MLe=n(ose,"STRONG",{});var rea=s(MLe);Yit=r(rea,"not"),rea.forEach(t),Kit=r(ose,` load the model weights. It only affects the
model\u2019s configuration. Use `),nae=n(ose,"A",{href:!0});var tea=s(nae);Zit=r(tea,"from_pretrained()"),tea.forEach(t),edt=r(ose," to load the model weights."),ose.forEach(t),odt=i(OL),T(FA.$$.fragment,OL),OL.forEach(t),rdt=i(Pi),tt=n(Pi,"DIV",{class:!0});var Bi=s(tt);T(iS.$$.fragment,Bi),tdt=i(Bi),ELe=n(Bi,"P",{});var aea=s(ELe);adt=r(aea,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),aea.forEach(t),ndt=i(Bi),qn=n(Bi,"P",{});var VL=s(qn);sdt=r(VL,"The model class to instantiate is selected based on the "),CLe=n(VL,"CODE",{});var nea=s(CLe);ldt=r(nea,"model_type"),nea.forEach(t),idt=r(VL,` property of the config object (either
passed as an argument or loaded from `),wLe=n(VL,"CODE",{});var sea=s(wLe);ddt=r(sea,"pretrained_model_name_or_path"),sea.forEach(t),cdt=r(VL,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),ALe=n(VL,"CODE",{});var lea=s(ALe);fdt=r(lea,"pretrained_model_name_or_path"),lea.forEach(t),mdt=r(VL,":"),VL.forEach(t),gdt=i(Bi),LLe=n(Bi,"UL",{});var iea=s(LLe);TA=n(iea,"LI",{});var OWe=s(TA);yLe=n(OWe,"STRONG",{});var dea=s(yLe);hdt=r(dea,"vision-encoder-decoder"),dea.forEach(t),pdt=r(OWe," \u2014 "),sae=n(OWe,"A",{href:!0});var cea=s(sae);_dt=r(cea,"FlaxVisionEncoderDecoderModel"),cea.forEach(t),udt=r(OWe," (Vision Encoder decoder model)"),OWe.forEach(t),iea.forEach(t),bdt=i(Bi),T(MA.$$.fragment,Bi),Bi.forEach(t),Pi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(bra)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Dn,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.AutoConfig"),c(On,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.AutoModel"),c(Vn,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.AutoTokenizer"),c(Oi,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertModel"),c(Uf,"id","extending-the-auto-classes"),c(Uf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uf,"href","#extending-the-auto-classes"),c(Vi,"class","relative group"),c(Yf,"id","transformers.AutoConfig"),c(Yf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Yf,"href","#transformers.AutoConfig"),c(Xi,"class","relative group"),c(qR,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(jR,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertConfig"),c(DR,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartConfig"),c(GR,"href","/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitConfig"),c(OR,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertConfig"),c(VR,"href","/docs/transformers/pr_18022/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(XR,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdConfig"),c(zR,"href","/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(WR,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(QR,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(HR,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomConfig"),c(UR,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertConfig"),c(JR,"href","/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineConfig"),c(YR,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPConfig"),c(KR,"href","/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenConfig"),c(ZR,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertConfig"),c(eP,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextConfig"),c(oP,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLConfig"),c(rP,"href","/docs/transformers/pr_18022/en/model_doc/cvt#transformers.CvtConfig"),c(tP,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(aP,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(nP,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(sP,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaConfig"),c(lP,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(iP,"href","/docs/transformers/pr_18022/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(dP,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTConfig"),c(cP,"href","/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrConfig"),c(fP,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertConfig"),c(mP,"href","/docs/transformers/pr_18022/en/model_doc/dpr#transformers.DPRConfig"),c(gP,"href","/docs/transformers/pr_18022/en/model_doc/dpt#transformers.DPTConfig"),c(hP,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraConfig"),c(pP,"href","/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(_P,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertConfig"),c(uP,"href","/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaConfig"),c(bP,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetConfig"),c(vP,"href","/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTConfig"),c(FP,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelConfig"),c(TP,"href","/docs/transformers/pr_18022/en/model_doc/glpn#transformers.GLPNConfig"),c(MP,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Config"),c(EP,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(CP,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(wP,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJConfig"),c(AP,"href","/docs/transformers/pr_18022/en/model_doc/groupvit#transformers.GroupViTConfig"),c(LP,"href","/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertConfig"),c(yP,"href","/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertConfig"),c(xP,"href","/docs/transformers/pr_18022/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c($P,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(kP,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(SP,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(RP,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDConfig"),c(PP,"href","/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitConfig"),c(BP,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerConfig"),c(IP,"href","/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5Config"),c(NP,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeConfig"),c(qP,"href","/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertConfig"),c(jP,"href","/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100Config"),c(DP,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianConfig"),c(GP,"href","/docs/transformers/pr_18022/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(OP,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartConfig"),c(VP,"href","/docs/transformers/pr_18022/en/model_doc/mctct#transformers.MCTCTConfig"),c(XP,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(zP,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(WP,"href","/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTConfig"),c(QP,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetConfig"),c(HP,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Config"),c(UP,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpConfig"),c(JP,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaConfig"),c(YP,"href","/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(KP,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(ZP,"href","/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTConfig"),c(eB,"href","/docs/transformers/pr_18022/en/model_doc/owlvit#transformers.OwlViTConfig"),c(oB,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusConfig"),c(rB,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverConfig"),c(tB,"href","/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartConfig"),c(aB,"href","/docs/transformers/pr_18022/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(nB,"href","/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(sB,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(lB,"href","/docs/transformers/pr_18022/en/model_doc/rag#transformers.RagConfig"),c(iB,"href","/docs/transformers/pr_18022/en/model_doc/realm#transformers.RealmConfig"),c(dB,"href","/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerConfig"),c(cB,"href","/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetConfig"),c(fB,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertConfig"),c(mB,"href","/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetConfig"),c(gB,"href","/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertConfig"),c(hB,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaConfig"),c(pB,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerConfig"),c(_B,"href","/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerConfig"),c(uB,"href","/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWConfig"),c(bB,"href","/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDConfig"),c(vB,"href","/docs/transformers/pr_18022/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(FB,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(TB,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(MB,"href","/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterConfig"),c(EB,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(CB,"href","/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinConfig"),c(wB,"href","/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2Config"),c(AB,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Config"),c(LB,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasConfig"),c(yB,"href","/docs/transformers/pr_18022/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(xB,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c($B,"href","/docs/transformers/pr_18022/en/model_doc/trocr#transformers.TrOCRConfig"),c(kB,"href","/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(SB,"href","/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(RB,"href","/docs/transformers/pr_18022/en/model_doc/van#transformers.VanConfig"),c(PB,"href","/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEConfig"),c(BB,"href","/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltConfig"),c(IB,"href","/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(NB,"href","/docs/transformers/pr_18022/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(qB,"href","/docs/transformers/pr_18022/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(jB,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTConfig"),c(DB,"href","/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(GB,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(OB,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(VB,"href","/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMConfig"),c(XB,"href","/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMConfig"),c(zB,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMConfig"),c(WB,"href","/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(QB,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(HB,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(UB,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetConfig"),c(JB,"href","/docs/transformers/pr_18022/en/model_doc/yolos#transformers.YolosConfig"),c(YB,"href","/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoConfig"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gh,"id","transformers.AutoTokenizer"),c(gh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gh,"href","#transformers.AutoTokenizer"),c(Wi,"class","relative group"),c(KB,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(ZB,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertTokenizer"),c(eI,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(oI,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartTokenizer"),c(rI,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartTokenizerFast"),c(tI,"href","/docs/transformers/pr_18022/en/model_doc/barthez#transformers.BarthezTokenizer"),c(aI,"href","/docs/transformers/pr_18022/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(nI,"href","/docs/transformers/pr_18022/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(sI,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizer"),c(lI,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizerFast"),c(iI,"href","/docs/transformers/pr_18022/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(dI,"href","/docs/transformers/pr_18022/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(cI,"href","/docs/transformers/pr_18022/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(fI,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(mI,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c(gI,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(hI,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(pI,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(_I,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(uI,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(bI,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(vI,"href","/docs/transformers/pr_18022/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(FI,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertTokenizer"),c(TI,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(MI,"href","/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineTokenizer"),c(EI,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPTokenizer"),c(CI,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(wI,"href","/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenTokenizer"),c(AI,"href","/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenTokenizerFast"),c(LI,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(yI,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(xI,"href","/docs/transformers/pr_18022/en/model_doc/cpm#transformers.CpmTokenizer"),c($I,"href","/docs/transformers/pr_18022/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(kI,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(SI,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaTokenizer"),c(RI,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(PI,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaTokenizer"),c(BI,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(II,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(NI,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(qI,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(jI,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(DI,"href","/docs/transformers/pr_18022/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(GI,"href","/docs/transformers/pr_18022/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(OI,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraTokenizer"),c(VI,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(XI,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(zI,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetTokenizer"),c(WI,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(QI,"href","/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(HI,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelTokenizer"),c(UI,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(JI,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(YI,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(KI,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ZI,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(eN,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(oN,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(rN,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(tN,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPTokenizer"),c(aN,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(nN,"href","/docs/transformers/pr_18022/en/model_doc/herbert#transformers.HerbertTokenizer"),c(sN,"href","/docs/transformers/pr_18022/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(lN,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(iN,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaTokenizer"),c(dN,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(cN,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(fN,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(mN,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(gN,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(hN,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(pN,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(_N,"href","/docs/transformers/pr_18022/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c(uN,"href","/docs/transformers/pr_18022/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(bN,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDTokenizer"),c(vN,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDTokenizerFast"),c(FN,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerTokenizer"),c(TN,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(MN,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.T5Tokenizer"),c(EN,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.T5TokenizerFast"),c(CN,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeTokenizer"),c(wN,"href","/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(AN,"href","/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(LN,"href","/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(yN,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianTokenizer"),c(xN,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartTokenizer"),c($N,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(kN,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(SN,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(RN,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizer"),c(PN,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizerFast"),c(BN,"href","/docs/transformers/pr_18022/en/model_doc/mluke#transformers.MLukeTokenizer"),c(IN,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(NN,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(qN,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(jN,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(DN,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.T5Tokenizer"),c(GN,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.T5TokenizerFast"),c(ON,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpTokenizer"),c(VN,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpTokenizerFast"),c(XN,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizer"),c(zN,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizerFast"),c(WN,"href","/docs/transformers/pr_18022/en/model_doc/nllb#transformers.NllbTokenizer"),c(QN,"href","/docs/transformers/pr_18022/en/model_doc/nllb#transformers.NllbTokenizerFast"),c(HN,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertTokenizer"),c(UN,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(JN,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(YN,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(KN,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(ZN,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPTokenizer"),c(eq,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(oq,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(rq,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(tq,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(aq,"href","/docs/transformers/pr_18022/en/model_doc/phobert#transformers.PhobertTokenizer"),c(nq,"href","/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartTokenizer"),c(sq,"href","/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(lq,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizer"),c(iq,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizerFast"),c(dq,"href","/docs/transformers/pr_18022/en/model_doc/rag#transformers.RagTokenizer"),c(cq,"href","/docs/transformers/pr_18022/en/model_doc/realm#transformers.RealmTokenizer"),c(fq,"href","/docs/transformers/pr_18022/en/model_doc/realm#transformers.RealmTokenizerFast"),c(mq,"href","/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerTokenizer"),c(gq,"href","/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(hq,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertTokenizer"),c(pq,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(_q,"href","/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(uq,"href","/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(bq,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaTokenizer"),c(vq,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Fq,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(Tq,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(Mq,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c(Eq,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(Cq,"href","/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterTokenizer"),c(wq,"href","/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(Aq,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(Lq,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(yq,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.T5Tokenizer"),c(xq,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.T5TokenizerFast"),c($q,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasTokenizer"),c(kq,"href","/docs/transformers/pr_18022/en/model_doc/tapex#transformers.TapexTokenizer"),c(Sq,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(Rq,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizer"),c(Pq,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizerFast"),c(Bq,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizer"),c(Iq,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertTokenizerFast"),c(Nq,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(qq,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(jq,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(Dq,"href","/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMTokenizer"),c(Gq,"href","/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(Oq,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMTokenizer"),c(Vq,"href","/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(Xq,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(zq,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(Wq,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaTokenizer"),c(Qq,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(Hq,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(Uq,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(Jq,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertTokenizer"),c(Yq,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Hh,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uh,"id","transformers.AutoFeatureExtractor"),c(Uh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Uh,"href","#transformers.AutoFeatureExtractor"),c(Qi,"class","relative group"),c(Kq,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(Zq,"href","/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(ej,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(oj,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(rj,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(tj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(aj,"href","/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(nj,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(sj,"href","/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(lj,"href","/docs/transformers/pr_18022/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(ij,"href","/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(dj,"href","/docs/transformers/pr_18022/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(cj,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(fj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(mj,"href","/docs/transformers/pr_18022/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(gj,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(hj,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(pj,"href","/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(_j,"href","/docs/transformers/pr_18022/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(uj,"href","/docs/transformers/pr_18022/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(bj,"href","/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTFeatureExtractor"),c(vj,"href","/docs/transformers/pr_18022/en/model_doc/owlvit#transformers.OwlViTFeatureExtractor"),c(Fj,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(Tj,"href","/docs/transformers/pr_18022/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(Mj,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(Ej,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(Cj,"href","/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(wj,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c(Aj,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Lj,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(yj,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(xj,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTFeatureExtractor"),c($j,"href","/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(kj,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Sj,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(Rj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(Pj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(Bj,"href","/docs/transformers/pr_18022/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ip,"id","transformers.AutoProcessor"),c(Ip,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ip,"href","#transformers.AutoProcessor"),c(Hi,"class","relative group"),c(Ij,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(Nj,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPProcessor"),c(qj,"href","/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaProcessor"),c(jj,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPProcessor"),c(Dj,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(Gj,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(Oj,"href","/docs/transformers/pr_18022/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(Vj,"href","/docs/transformers/pr_18022/en/model_doc/owlvit#transformers.OwlViTProcessor"),c(Xj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Wj,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(Qj,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(Hj,"href","/docs/transformers/pr_18022/en/model_doc/trocr#transformers.TrOCRProcessor"),c(Uj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Jj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Yj,"href","/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltProcessor"),c(Kj,"href","/docs/transformers/pr_18022/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(Zj,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eD,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(oD,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(a_,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n_,"id","transformers.AutoModel"),c(n_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n_,"href","#transformers.AutoModel"),c(Ji,"class","relative group"),c(rD,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tD,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aD,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nD,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertModel"),c(sD,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartModel"),c(lD,"href","/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitModel"),c(iD,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertModel"),c(dD,"href","/docs/transformers/pr_18022/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(cD,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdModel"),c(fD,"href","/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(mD,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(gD,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(hD,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomModel"),c(pD,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertModel"),c(_D,"href","/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineModel"),c(uD,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.CLIPModel"),c(bD,"href","/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenModel"),c(vD,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertModel"),c(FD,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextModel"),c(TD,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLModel"),c(MD,"href","/docs/transformers/pr_18022/en/model_doc/cvt#transformers.CvtModel"),c(ED,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(CD,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(wD,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(AD,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaModel"),c(LD,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(yD,"href","/docs/transformers/pr_18022/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(xD,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTModel"),c($D,"href","/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrModel"),c(kD,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertModel"),c(SD,"href","/docs/transformers/pr_18022/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(RD,"href","/docs/transformers/pr_18022/en/model_doc/dpt#transformers.DPTModel"),c(PD,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraModel"),c(BD,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertModel"),c(ID,"href","/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaModel"),c(ND,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetModel"),c(qD,"href","/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTModel"),c(jD,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelModel"),c(DD,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelBaseModel"),c(GD,"href","/docs/transformers/pr_18022/en/model_doc/glpn#transformers.GLPNModel"),c(OD,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2Model"),c(VD,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(XD,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(zD,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJModel"),c(WD,"href","/docs/transformers/pr_18022/en/model_doc/groupvit#transformers.GroupViTModel"),c(QD,"href","/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertModel"),c(HD,"href","/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertModel"),c(UD,"href","/docs/transformers/pr_18022/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(JD,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(YD,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(KD,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(ZD,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDModel"),c(eG,"href","/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitModel"),c(oG,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerModel"),c(rG,"href","/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5Model"),c(tG,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeModel"),c(aG,"href","/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertModel"),c(nG,"href","/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100Model"),c(sG,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianModel"),c(lG,"href","/docs/transformers/pr_18022/en/model_doc/maskformer#transformers.MaskFormerModel"),c(iG,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartModel"),c(dG,"href","/docs/transformers/pr_18022/en/model_doc/mctct#transformers.MCTCTModel"),c(cG,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(fG,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertModel"),c(mG,"href","/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTModel"),c(gG,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetModel"),c(hG,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5Model"),c(pG,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpModel"),c(_G,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaModel"),c(uG,"href","/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100Model"),c(bG,"href","/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerModel"),c(vG,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(FG,"href","/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTModel"),c(TG,"href","/docs/transformers/pr_18022/en/model_doc/owlvit#transformers.OwlViTModel"),c(MG,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusModel"),c(EG,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverModel"),c(CG,"href","/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartModel"),c(wG,"href","/docs/transformers/pr_18022/en/model_doc/poolformer#transformers.PoolFormerModel"),c(AG,"href","/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(LG,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertModel"),c(yG,"href","/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerModel"),c(xG,"href","/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetModel"),c($G,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertModel"),c(kG,"href","/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetModel"),c(SG,"href","/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertModel"),c(RG,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaModel"),c(PG,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerModel"),c(BG,"href","/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerModel"),c(IG,"href","/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWModel"),c(NG,"href","/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDModel"),c(qG,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(jG,"href","/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterModel"),c(DG,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(GG,"href","/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinModel"),c(OG,"href","/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2Model"),c(VG,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5Model"),c(XG,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasModel"),c(zG,"href","/docs/transformers/pr_18022/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(WG,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(QG,"href","/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechModel"),c(HG,"href","/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(UG,"href","/docs/transformers/pr_18022/en/model_doc/van#transformers.VanModel"),c(JG,"href","/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEModel"),c(YG,"href","/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltModel"),c(KG,"href","/docs/transformers/pr_18022/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(ZG,"href","/docs/transformers/pr_18022/en/model_doc/visual_bert#transformers.VisualBertModel"),c(eO,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTModel"),c(oO,"href","/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(rO,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(tO,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(aO,"href","/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMModel"),c(nO,"href","/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMModel"),c(sO,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMModel"),c(lO,"href","/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(iO,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(dO,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(cO,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetModel"),c(fO,"href","/docs/transformers/pr_18022/en/model_doc/yolos#transformers.YolosModel"),c(mO,"href","/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p2,"id","transformers.AutoModelForPreTraining"),c(p2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p2,"href","#transformers.AutoModelForPreTraining"),c(Zi,"class","relative group"),c(gO,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hO,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pO,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_O,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForPreTraining"),c(uO,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(bO,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForPreTraining"),c(vO,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(FO,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomForCausalLM"),c(TO,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(MO,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(EO,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(CO,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(wO,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(AO,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(LO,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForPreTraining"),c(yO,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(xO,"href","/docs/transformers/pr_18022/en/model_doc/flava#transformers.FlavaForPreTraining"),c($O,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForPreTraining"),c(kO,"href","/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(RO,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(PO,"href","/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(BO,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(IO,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(NO,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForMaskedLM"),c(qO,"href","/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(jO,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c(DO,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(GO,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(OO,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(VO,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(XO,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(zO,"href","/docs/transformers/pr_18022/en/model_doc/retribert#transformers.RetriBertModel"),c(WO,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(QO,"href","/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(HO,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(UO,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(JO,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(YO,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(KO,"href","/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(ZO,"href","/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(eV,"href","/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEForPreTraining"),c(oV,"href","/docs/transformers/pr_18022/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(rV,"href","/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(tV,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(aV,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(nV,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(sV,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(lV,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(iV,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m1,"id","transformers.AutoModelForCausalLM"),c(m1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m1,"href","#transformers.AutoModelForCausalLM"),c(rd,"class","relative group"),c(dV,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(cV,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(fV,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mV,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForCausalLM"),c(gV,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertLMHeadModel"),c(hV,"href","/docs/transformers/pr_18022/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(pV,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(_V,"href","/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(uV,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(bV,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(vV,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomForCausalLM"),c(FV,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(TV,"href","/docs/transformers/pr_18022/en/model_doc/codegen#transformers.CodeGenForCausalLM"),c(MV,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(EV,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(CV,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForCausalLM"),c(wV,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(AV,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(LV,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(yV,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(xV,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianForCausalLM"),c($V,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForCausalLM"),c(kV,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(SV,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForCausalLM"),c(RV,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(PV,"href","/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTForCausalLM"),c(BV,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(IV,"href","/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(NV,"href","/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(qV,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(jV,"href","/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(DV,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(GV,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(OV,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(VV,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c(XV,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(zV,"href","/docs/transformers/pr_18022/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(WV,"href","/docs/transformers/pr_18022/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(QV,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(HV,"href","/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(UV,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(JV,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(YV,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rb,"id","transformers.AutoModelForMaskedLM"),c(rb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(rb,"href","#transformers.AutoModelForMaskedLM"),c(nd,"class","relative group"),c(KV,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZV,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eX,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oX,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(rX,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(tX,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForMaskedLM"),c(aX,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(nX,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(sX,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(lX,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(iX,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(dX,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(cX,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(fX,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(mX,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(gX,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(hX,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(pX,"href","/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(_X,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(uX,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(bX,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForMaskedLM"),c(vX,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(FX,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(TX,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(MX,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(EX,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(CX,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(wX,"href","/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(AX,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(LX,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(yX,"href","/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(xX,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c($X,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(kX,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(SX,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(RX,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(PX,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(BX,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(IX,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(NX,"href","/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xb,"id","transformers.AutoModelForSeq2SeqLM"),c(Xb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xb,"href","#transformers.AutoModelForSeq2SeqLM"),c(id,"class","relative group"),c(qX,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jX,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DX,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GX,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(OX,"href","/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(VX,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(XX,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c(zX,"href","/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(WX,"href","/docs/transformers/pr_18022/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(QX,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(HX,"href","/docs/transformers/pr_18022/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(UX,"href","/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(JX,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.MarianMTModel"),c(YX,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(KX,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(ZX,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForConditionalGeneration"),c(ez,"href","/docs/transformers/pr_18022/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(oz,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(rz,"href","/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(tz,"href","/docs/transformers/pr_18022/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(az,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(nz,"href","/docs/transformers/pr_18022/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gv,"id","transformers.AutoModelForSequenceClassification"),c(gv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(gv,"href","#transformers.AutoModelForSequenceClassification"),c(fd,"class","relative group"),c(sz,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lz,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iz,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dz,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(cz,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForSequenceClassification"),c(fz,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForSequenceClassification"),c(mz,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(gz,"href","/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(hz,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(pz,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(_z,"href","/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(uz,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(bz,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(vz,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(Fz,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(Tz,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(Mz,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(Ez,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(Cz,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(wz,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(Az,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(Lz,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(yz,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(xz,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c($z,"href","/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(kz,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(Sz,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(Rz,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(Pz,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDForSequenceClassification"),c(Bz,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(Iz,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForSequenceClassification"),c(Nz,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(qz,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(jz,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(Dz,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(Gz,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForSequenceClassification"),c(Oz,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(Vz,"href","/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(Xz,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(zz,"href","/docs/transformers/pr_18022/en/model_doc/opt#transformers.OPTForSequenceClassification"),c(Wz,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(Qz,"href","/docs/transformers/pr_18022/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(Hz,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(Uz,"href","/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c(Jz,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(Yz,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(Kz,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(Zz,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(eW,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(oW,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(rW,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(tW,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(aW,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(nW,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(sW,"href","/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(No,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(p0,"id","transformers.AutoModelForMultipleChoice"),c(p0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(p0,"href","#transformers.AutoModelForMultipleChoice"),c(hd,"class","relative group"),c(lW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cW,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(fW,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForMultipleChoice"),c(mW,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(gW,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(hW,"href","/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(pW,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(_W,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(uW,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(bW,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(vW,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(FW,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(TW,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(MW,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(EW,"href","/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(CW,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(wW,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForMultipleChoice"),c(AW,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(LW,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(yW,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(xW,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c($W,"href","/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(kW,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(SW,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(RW,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(PW,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(BW,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(IW,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(NW,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(qW,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(jW,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(DW,"href","/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J0,"id","transformers.AutoModelForNextSentencePrediction"),c(J0,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J0,"href","#transformers.AutoModelForNextSentencePrediction"),c(ud,"class","relative group"),c(GW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XW,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(zW,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(WW,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(QW,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(HW,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(UW,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sF,"id","transformers.AutoModelForTokenClassification"),c(sF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sF,"href","#transformers.AutoModelForTokenClassification"),c(Fd,"class","relative group"),c(JW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KW,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZW,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(eQ,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForTokenClassification"),c(oQ,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(rQ,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(tQ,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(aQ,"href","/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineForTokenClassification"),c(nQ,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(sQ,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(lQ,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(iQ,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(dQ,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(cQ,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(fQ,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(mQ,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(gQ,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(hQ,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(pQ,"href","/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(_Q,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(uQ,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(bQ,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(vQ,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(FQ,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForTokenClassification"),c(TQ,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(MQ,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(EQ,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(CQ,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(wQ,"href","/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(AQ,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(LQ,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(yQ,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(xQ,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c($Q,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(kQ,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(SQ,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(RQ,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(PQ,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(BQ,"href","/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QF,"id","transformers.AutoModelForQuestionAnswering"),c(QF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QF,"href","#transformers.AutoModelForQuestionAnswering"),c(Ed,"class","relative group"),c(IQ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NQ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qQ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jQ,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(DQ,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(GQ,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(OQ,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(VQ,"href","/docs/transformers/pr_18022/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(XQ,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(zQ,"href","/docs/transformers/pr_18022/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(WQ,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(QQ,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(HQ,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(UQ,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(JQ,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(YQ,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c(KQ,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(ZQ,"href","/docs/transformers/pr_18022/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(eH,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(oH,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(rH,"href","/docs/transformers/pr_18022/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(tH,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(aH,"href","/docs/transformers/pr_18022/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(nH,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(sH,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(lH,"href","/docs/transformers/pr_18022/en/model_doc/luke#transformers.LukeForQuestionAnswering"),c(iH,"href","/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(dH,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(cH,"href","/docs/transformers/pr_18022/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(fH,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(mH,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(gH,"href","/docs/transformers/pr_18022/en/model_doc/mvp#transformers.MvpForQuestionAnswering"),c(hH,"href","/docs/transformers/pr_18022/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(pH,"href","/docs/transformers/pr_18022/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(_H,"href","/docs/transformers/pr_18022/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(uH,"href","/docs/transformers/pr_18022/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(bH,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(vH,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(FH,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(TH,"href","/docs/transformers/pr_18022/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(MH,"href","/docs/transformers/pr_18022/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(EH,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(CH,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(wH,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(AH,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(LH,"href","/docs/transformers/pr_18022/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DT,"id","transformers.AutoModelForTableQuestionAnswering"),c(DT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DT,"href","#transformers.AutoModelForTableQuestionAnswering"),c(Ad,"class","relative group"),c(yH,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xH,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($H,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kH,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zT,"id","transformers.AutoModelForImageClassification"),c(zT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(zT,"href","#transformers.AutoModelForImageClassification"),c(xd,"class","relative group"),c(SH,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(RH,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(PH,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BH,"href","/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitForImageClassification"),c(IH,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(NH,"href","/docs/transformers/pr_18022/en/model_doc/cvt#transformers.CvtForImageClassification"),c(qH,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(jH,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTForImageClassification"),c(DH,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(GH,"href","/docs/transformers/pr_18022/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(OH,"href","/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitForImageClassification"),c(VH,"href","/docs/transformers/pr_18022/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(XH,"href","/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTForImageClassification"),c(zH,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(WH,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(QH,"href","/docs/transformers/pr_18022/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(HH,"href","/docs/transformers/pr_18022/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(UH,"href","/docs/transformers/pr_18022/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(JH,"href","/docs/transformers/pr_18022/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(YH,"href","/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(KH,"href","/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinForImageClassification"),c(ZH,"href","/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2ForImageClassification"),c(eU,"href","/docs/transformers/pr_18022/en/model_doc/van#transformers.VanForImageClassification"),c(oU,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTForImageClassification"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(d8,"id","transformers.AutoModelForVideoClassification"),c(d8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(d8,"href","#transformers.AutoModelForVideoClassification"),c(Sd,"class","relative group"),c(rU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nU,"href","/docs/transformers/pr_18022/en/model_doc/videomae#transformers.VideoMAEForVideoClassification"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h8,"id","transformers.AutoModelForVision2Seq"),c(h8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h8,"href","#transformers.AutoModelForVision2Seq"),c(Bd,"class","relative group"),c(sU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dU,"href","/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(v8,"id","transformers.AutoModelForVisualQuestionAnswering"),c(v8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(v8,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(qd,"class","relative group"),c(cU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gU,"href","/docs/transformers/pr_18022/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C8,"id","transformers.AutoModelForAudioClassification"),c(C8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C8,"href","#transformers.AutoModelForAudioClassification"),c(Gd,"class","relative group"),c(hU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_U,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uU,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(bU,"href","/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(vU,"href","/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(FU,"href","/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(TU,"href","/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(MU,"href","/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(EU,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(CU,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(wU,"href","/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N8,"id","transformers.AutoModelForAudioFrameClassification"),c(N8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N8,"href","#transformers.AutoModelForAudioFrameClassification"),c(Xd,"class","relative group"),c(AU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xU,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c($U,"href","/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(kU,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(SU,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(RU,"href","/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(W8,"id","transformers.AutoModelForCTC"),c(W8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(W8,"href","#transformers.AutoModelForCTC"),c(Qd,"class","relative group"),c(PU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NU,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(qU,"href","/docs/transformers/pr_18022/en/model_doc/hubert#transformers.HubertForCTC"),c(jU,"href","/docs/transformers/pr_18022/en/model_doc/mctct#transformers.MCTCTForCTC"),c(DU,"href","/docs/transformers/pr_18022/en/model_doc/sew#transformers.SEWForCTC"),c(GU,"href","/docs/transformers/pr_18022/en/model_doc/sew-d#transformers.SEWDForCTC"),c(OU,"href","/docs/transformers/pr_18022/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(VU,"href","/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(XU,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(zU,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(WU,"href","/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMForCTC"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sM,"id","transformers.AutoModelForSpeechSeq2Seq"),c(sM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(sM,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Jd,"class","relative group"),c(QU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(HU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(UU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(JU,"href","/docs/transformers/pr_18022/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(YU,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mM,"id","transformers.AutoModelForAudioXVector"),c(mM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mM,"href","#transformers.AutoModelForAudioXVector"),c(Zd,"class","relative group"),c(KU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZU,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oJ,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(rJ,"href","/docs/transformers/pr_18022/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(tJ,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(aJ,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(nJ,"href","/docs/transformers/pr_18022/en/model_doc/wavlm#transformers.WavLMForXVector"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TM,"id","transformers.AutoModelForMaskedImageModeling"),c(TM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TM,"href","#transformers.AutoModelForMaskedImageModeling"),c(rc,"class","relative group"),c(sJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(iJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dJ,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(cJ,"href","/docs/transformers/pr_18022/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(fJ,"href","/docs/transformers/pr_18022/en/model_doc/swinv2#transformers.Swinv2ForMaskedImageModeling"),c(mJ,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xM,"id","transformers.AutoModelForObjectDetection"),c(xM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(xM,"href","#transformers.AutoModelForObjectDetection"),c(nc,"class","relative group"),c(gJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_J,"href","/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrForObjectDetection"),c(uJ,"href","/docs/transformers/pr_18022/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(BM,"id","transformers.AutoModelForImageSegmentation"),c(BM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(BM,"href","#transformers.AutoModelForImageSegmentation"),c(ic,"class","relative group"),c(bJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(FJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TJ,"href","/docs/transformers/pr_18022/en/model_doc/detr#transformers.DetrForSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(DM,"id","transformers.AutoModelForSemanticSegmentation"),c(DM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(DM,"href","#transformers.AutoModelForSemanticSegmentation"),c(fc,"class","relative group"),c(MJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wJ,"href","/docs/transformers/pr_18022/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(AJ,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(LJ,"href","/docs/transformers/pr_18022/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(yJ,"href","/docs/transformers/pr_18022/en/model_doc/mobilevit#transformers.MobileViTForSemanticSegmentation"),c(xJ,"href","/docs/transformers/pr_18022/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(To,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UM,"id","transformers.AutoModelForInstanceSegmentation"),c(UM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UM,"href","#transformers.AutoModelForInstanceSegmentation"),c(hc,"class","relative group"),c($J,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RJ,"href","/docs/transformers/pr_18022/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eE,"id","transformers.TFAutoModel"),c(eE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(eE,"href","#transformers.TFAutoModel"),c(uc,"class","relative group"),c(PJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IJ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NJ,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertModel"),c(qJ,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.TFBartModel"),c(jJ,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertModel"),c(DJ,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(GJ,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(OJ,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertModel"),c(VJ,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.TFCLIPModel"),c(XJ,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertModel"),c(zJ,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.TFConvNextModel"),c(WJ,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.TFCTRLModel"),c(QJ,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(HJ,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaModel"),c(UJ,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(JJ,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.TFDeiTModel"),c(YJ,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(KJ,"href","/docs/transformers/pr_18022/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(ZJ,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraModel"),c(eY,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(oY,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelModel"),c(rY,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(tY,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.TFGPT2Model"),c(aY,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.TFGPTJModel"),c(nY,"href","/docs/transformers/pr_18022/en/model_doc/hubert#transformers.TFHubertModel"),c(sY,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(lY,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.TFLEDModel"),c(iY,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerModel"),c(dY,"href","/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.TFLxmertModel"),c(cY,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.TFMarianModel"),c(fY,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.TFMBartModel"),c(mY,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(gY,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetModel"),c(hY,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.TFMT5Model"),c(pY,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(_Y,"href","/docs/transformers/pr_18022/en/model_doc/opt#transformers.TFOPTModel"),c(uY,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.TFPegasusModel"),c(bY,"href","/docs/transformers/pr_18022/en/model_doc/regnet#transformers.TFRegNetModel"),c(vY,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertModel"),c(FY,"href","/docs/transformers/pr_18022/en/model_doc/resnet#transformers.TFResNetModel"),c(TY,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaModel"),c(MY,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerModel"),c(EY,"href","/docs/transformers/pr_18022/en/model_doc/segformer#transformers.TFSegformerModel"),c(CY,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(wY,"href","/docs/transformers/pr_18022/en/model_doc/swin#transformers.TFSwinModel"),c(AY,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.TFT5Model"),c(LY,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasModel"),c(yY,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(xY,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.TFViTModel"),c($Y,"href","/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(kY,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(SY,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMModel"),c(RY,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(PY,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetModel"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZE,"id","transformers.TFAutoModelForPreTraining"),c(ZE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZE,"href","#transformers.TFAutoModelForPreTraining"),c(Fc,"class","relative group"),c(BY,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IY,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NY,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qY,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(jY,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(DY,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForPreTraining"),c(GY,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(OY,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(VY,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(XY,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(zY,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(WY,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(QY,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(HY,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(UY,"href","/docs/transformers/pr_18022/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(JY,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(YY,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(KY,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(ZY,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(eK,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(oK,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(rK,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(tK,"href","/docs/transformers/pr_18022/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(aK,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(nK,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(sK,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(w4,"id","transformers.TFAutoModelForCausalLM"),c(w4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(w4,"href","#transformers.TFAutoModelForCausalLM"),c(Ec,"class","relative group"),c(lK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(iK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(dK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cK,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(fK,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c(mK,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(gK,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(hK,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(pK,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(_K,"href","/docs/transformers/pr_18022/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(uK,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(bK,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(vK,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(FK,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(TK,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(MK,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(G4,"id","transformers.TFAutoModelForImageClassification"),c(G4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(G4,"href","#transformers.TFAutoModelForImageClassification"),c(Ac,"class","relative group"),c(EK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AK,"href","/docs/transformers/pr_18022/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(LK,"href","/docs/transformers/pr_18022/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(yK,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.TFDeiTForImageClassification"),c(xK,"href","/docs/transformers/pr_18022/en/model_doc/deit#transformers.TFDeiTForImageClassificationWithTeacher"),c($K,"href","/docs/transformers/pr_18022/en/model_doc/regnet#transformers.TFRegNetForImageClassification"),c(kK,"href","/docs/transformers/pr_18022/en/model_doc/resnet#transformers.TFResNetForImageClassification"),c(SK,"href","/docs/transformers/pr_18022/en/model_doc/segformer#transformers.TFSegformerForImageClassification"),c(RK,"href","/docs/transformers/pr_18022/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(PK,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.TFViTForImageClassification"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y4,"id","transformers.TFAutoModelForMaskedLM"),c(Y4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y4,"href","#transformers.TFAutoModelForMaskedLM"),c(xc,"class","relative group"),c(BK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(IK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(NK,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qK,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(jK,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(DK,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(GK,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(OK,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(VK,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(XK,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(zK,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(WK,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(QK,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(HK,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(UK,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(JK,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(YK,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(KK,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(ZK,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(eZ,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(oZ,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(rZ,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(tZ,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FC,"id","transformers.TFAutoModelForSeq2SeqLM"),c(FC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(FC,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(Sc,"class","relative group"),c(aZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lZ,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(iZ,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(dZ,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(cZ,"href","/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(fZ,"href","/docs/transformers/pr_18022/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(mZ,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.TFMarianMTModel"),c(gZ,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(hZ,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(pZ,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(_Z,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RC,"id","transformers.TFAutoModelForSequenceClassification"),c(RC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(RC,"href","#transformers.TFAutoModelForSequenceClassification"),c(Bc,"class","relative group"),c(uZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FZ,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(TZ,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(MZ,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(EZ,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(CZ,"href","/docs/transformers/pr_18022/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(wZ,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(AZ,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(LZ,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(yZ,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(xZ,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c($Z,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(kZ,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(SZ,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(RZ,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(PZ,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(BZ,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(IZ,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(NZ,"href","/docs/transformers/pr_18022/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(qZ,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(jZ,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(DZ,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(GZ,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(OZ,"href","/docs/transformers/pr_18022/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(VZ,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(XZ,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(zZ,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(i5,"id","transformers.TFAutoModelForMultipleChoice"),c(i5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(i5,"href","#transformers.TFAutoModelForMultipleChoice"),c(qc,"class","relative group"),c(WZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(HZ,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UZ,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(JZ,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(YZ,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(KZ,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(ZZ,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(eee,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(oee,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(ree,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(tee,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(aee,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(nee,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(see,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(lee,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(iee,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(dee,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(cee,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(fee,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y5,"id","transformers.TFAutoModelForNextSentencePrediction"),c(y5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y5,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Gc,"class","relative group"),c(mee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pee,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(_ee,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R5,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(R5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R5,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Xc,"class","relative group"),c(uee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fee,"href","/docs/transformers/pr_18022/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N5,"id","transformers.TFAutoModelForTokenClassification"),c(N5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N5,"href","#transformers.TFAutoModelForTokenClassification"),c(Qc,"class","relative group"),c(Tee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Eee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cee,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(wee,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(Aee,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(Lee,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(yee,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(xee,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c($ee,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(kee,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(See,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(Ree,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(Pee,"href","/docs/transformers/pr_18022/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(Bee,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(Iee,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(Nee,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(qee,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(jee,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(Dee,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(Gee,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(Oee,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(Vee,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(s3,"id","transformers.TFAutoModelForQuestionAnswering"),c(s3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(s3,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Jc,"class","relative group"),c(Xee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Wee,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qee,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(Hee,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(Uee,"href","/docs/transformers/pr_18022/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(Jee,"href","/docs/transformers/pr_18022/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(Yee,"href","/docs/transformers/pr_18022/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(Kee,"href","/docs/transformers/pr_18022/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(Zee,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(eoe,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(ooe,"href","/docs/transformers/pr_18022/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(roe,"href","/docs/transformers/pr_18022/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(toe,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(aoe,"href","/docs/transformers/pr_18022/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(noe,"href","/docs/transformers/pr_18022/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(soe,"href","/docs/transformers/pr_18022/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(loe,"href","/docs/transformers/pr_18022/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(ioe,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(doe,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(coe,"href","/docs/transformers/pr_18022/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(foe,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(moe,"href","/docs/transformers/pr_18022/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x3,"id","transformers.TFAutoModelForVision2Seq"),c(x3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x3,"href","#transformers.TFAutoModelForVision2Seq"),c(Zc,"class","relative group"),c(goe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hoe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(poe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_oe,"href","/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(R3,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(R3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(R3,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(rf,"class","relative group"),c(uoe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(boe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(voe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Foe,"href","/docs/transformers/pr_18022/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(N3,"id","transformers.FlaxAutoModel"),c(N3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(N3,"href","#transformers.FlaxAutoModel"),c(nf,"class","relative group"),c(Toe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Moe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Eoe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Coe,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertModel"),c(woe,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartModel"),c(Aoe,"href","/docs/transformers/pr_18022/en/model_doc/beit#transformers.FlaxBeitModel"),c(Loe,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertModel"),c(yoe,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(xoe,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c($oe,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(koe,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.FlaxBloomModel"),c(Soe,"href","/docs/transformers/pr_18022/en/model_doc/clip#transformers.FlaxCLIPModel"),c(Roe,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(Poe,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraModel"),c(Boe,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(Ioe,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(Noe,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(qoe,"href","/docs/transformers/pr_18022/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(joe,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.FlaxMarianModel"),c(Doe,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartModel"),c(Goe,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.FlaxMT5Model"),c(Ooe,"href","/docs/transformers/pr_18022/en/model_doc/opt#transformers.FlaxOPTModel"),c(Voe,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(Xoe,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(zoe,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(Woe,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.FlaxT5Model"),c(Qoe,"href","/docs/transformers/pr_18022/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(Hoe,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.FlaxViTModel"),c(Uoe,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(Joe,"href","/docs/transformers/pr_18022/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(Yoe,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hw,"id","transformers.FlaxAutoModelForCausalLM"),c(hw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hw,"href","#transformers.FlaxAutoModelForCausalLM"),c(df,"class","relative group"),c(Koe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zoe,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ere,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ore,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(rre,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(tre,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(are,"href","/docs/transformers/pr_18022/en/model_doc/bloom#transformers.FlaxBloomForCausalLM"),c(nre,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(sre,"href","/docs/transformers/pr_18022/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(lre,"href","/docs/transformers/pr_18022/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(ire,"href","/docs/transformers/pr_18022/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(dre,"href","/docs/transformers/pr_18022/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(cre,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(fre,"href","/docs/transformers/pr_18022/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yw,"id","transformers.FlaxAutoModelForPreTraining"),c(yw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yw,"href","#transformers.FlaxAutoModelForPreTraining"),c(mf,"class","relative group"),c(mre,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gre,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(hre,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pre,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(_re,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(ure,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(bre,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c(vre,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(Fre,"href","/docs/transformers/pr_18022/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Tre,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Mre,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Ere,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(Cre,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(wre,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Are,"href","/docs/transformers/pr_18022/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(Lre,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xw,"id","transformers.FlaxAutoModelForMaskedLM"),c(Xw,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Xw,"href","#transformers.FlaxAutoModelForMaskedLM"),c(pf,"class","relative group"),c(yre,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xre,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c($re,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(kre,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(Sre,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(Rre,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(Pre,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(Bre,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(Ire,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(Nre,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(qre,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(jre,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(Dre,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(t6,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(t6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(t6,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(bf,"class","relative group"),c(Gre,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ore,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Vre,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xre,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(zre,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(Wre,"href","/docs/transformers/pr_18022/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(Qre,"href","/docs/transformers/pr_18022/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(Hre,"href","/docs/transformers/pr_18022/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(Ure,"href","/docs/transformers/pr_18022/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(Jre,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(Yre,"href","/docs/transformers/pr_18022/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(Kre,"href","/docs/transformers/pr_18022/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(Zre,"href","/docs/transformers/pr_18022/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_6,"id","transformers.FlaxAutoModelForSequenceClassification"),c(_6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(_6,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(Tf,"class","relative group"),c(ete,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ote,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(rte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tte,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(ate,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(nte,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(ste,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(lte,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(ite,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(dte,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(cte,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(fte,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(mte,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(x6,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(x6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(x6,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(Cf,"class","relative group"),c(gte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(hte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(pte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ra,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_te,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(ute,"href","/docs/transformers/pr_18022/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(bte,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c(vte,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(Fte,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(Tte,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Mte,"href","/docs/transformers/pr_18022/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Ete,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Cte,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(wte,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(O6,"id","transformers.FlaxAutoModelForTokenClassification"),c(O6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(O6,"href","#transformers.FlaxAutoModelForTokenClassification"),c(Lf,"class","relative group"),c(Ate,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ta,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xte,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c($te,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(kte,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Ste,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Rte,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(Pte,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Bte,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Ite,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z6,"id","transformers.FlaxAutoModelForMultipleChoice"),c(Z6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z6,"href","#transformers.FlaxAutoModelForMultipleChoice"),c($f,"class","relative group"),c(Nte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dte,"href","/docs/transformers/pr_18022/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Gte,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Ote,"href","/docs/transformers/pr_18022/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(Vte,"href","/docs/transformers/pr_18022/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(Xte,"href","/docs/transformers/pr_18022/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(zte,"href","/docs/transformers/pr_18022/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(Wte,"href","/docs/transformers/pr_18022/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(Qte,"href","/docs/transformers/pr_18022/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cA,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(cA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cA,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(Rf,"class","relative group"),c(Hte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ute,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(na,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yte,"href","/docs/transformers/pr_18022/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hA,"id","transformers.FlaxAutoModelForImageClassification"),c(hA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(hA,"href","#transformers.FlaxAutoModelForImageClassification"),c(If,"class","relative group"),c(Kte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zte,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eae,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oae,"href","/docs/transformers/pr_18022/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(rae,"href","/docs/transformers/pr_18022/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vA,"id","transformers.FlaxAutoModelForVision2Seq"),c(vA,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vA,"href","#transformers.FlaxAutoModelForVision2Seq"),c(jf,"class","relative group"),c(tae,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aae,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nae,"href","/docs/transformers/pr_18022/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(la,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sae,"href","/docs/transformers/pr_18022/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Ao),e(Ao,Ii),b(f,zf,u),b(f,dt,u),e(dt,Ni),e(dt,qi),e(qi,XL),e(dt,Wf),b(f,Oe,u),b(f,Qe,u),e(Qe,ji),e(Qe,Dn),e(Dn,zL),e(Qe,Gn),e(Qe,On),e(On,WL),e(Qe,Di),e(Qe,Vn),e(Vn,QL),e(Qe,Gi),b(f,Qf,u),M(Ia,f,u),b(f,He,u),b(f,Le,u),e(Le,SR),e(Le,Oi),e(Oi,RR),e(Le,PR),b(f,Lo,u),b(f,Na,u),e(Na,BR),e(Na,Hf),e(Hf,IR),e(Na,iYe),b(f,VWe,u),b(f,Vi,u),e(Vi,Uf),e(Uf,rse),M(HL,rse,null),e(Vi,dYe),e(Vi,tse),e(tse,cYe),b(f,XWe,u),b(f,Xn,u),e(Xn,fYe),e(Xn,ase),e(ase,mYe),e(Xn,gYe),e(Xn,nse),e(nse,hYe),e(Xn,pYe),b(f,zWe,u),M(UL,f,u),b(f,WWe,u),b(f,NR,u),e(NR,_Ye),b(f,QWe,u),M(Jf,f,u),b(f,HWe,u),b(f,Xi,u),e(Xi,Yf),e(Yf,sse),M(JL,sse,null),e(Xi,uYe),e(Xi,lse),e(lse,bYe),b(f,UWe,u),b(f,yo,u),M(YL,yo,null),e(yo,vYe),e(yo,KL),e(KL,FYe),e(KL,qR),e(qR,TYe),e(KL,MYe),e(yo,EYe),e(yo,ZL),e(ZL,CYe),e(ZL,ise),e(ise,wYe),e(ZL,AYe),e(yo,LYe),e(yo,$r),M(ey,$r,null),e($r,yYe),e($r,dse),e(dse,xYe),e($r,$Ye),e($r,zi),e(zi,kYe),e(zi,cse),e(cse,SYe),e(zi,RYe),e(zi,fse),e(fse,PYe),e(zi,BYe),e($r,IYe),e($r,A),e(A,Kf),e(Kf,mse),e(mse,NYe),e(Kf,qYe),e(Kf,jR),e(jR,jYe),e(Kf,DYe),e(A,GYe),e(A,Zf),e(Zf,gse),e(gse,OYe),e(Zf,VYe),e(Zf,DR),e(DR,XYe),e(Zf,zYe),e(A,WYe),e(A,em),e(em,hse),e(hse,QYe),e(em,HYe),e(em,GR),e(GR,UYe),e(em,JYe),e(A,YYe),e(A,om),e(om,pse),e(pse,KYe),e(om,ZYe),e(om,OR),e(OR,eKe),e(om,oKe),e(A,rKe),e(A,rm),e(rm,_se),e(_se,tKe),e(rm,aKe),e(rm,VR),e(VR,nKe),e(rm,sKe),e(A,lKe),e(A,tm),e(tm,use),e(use,iKe),e(tm,dKe),e(tm,XR),e(XR,cKe),e(tm,fKe),e(A,mKe),e(A,am),e(am,bse),e(bse,gKe),e(am,hKe),e(am,zR),e(zR,pKe),e(am,_Ke),e(A,uKe),e(A,nm),e(nm,vse),e(vse,bKe),e(nm,vKe),e(nm,WR),e(WR,FKe),e(nm,TKe),e(A,MKe),e(A,sm),e(sm,Fse),e(Fse,EKe),e(sm,CKe),e(sm,QR),e(QR,wKe),e(sm,AKe),e(A,LKe),e(A,lm),e(lm,Tse),e(Tse,yKe),e(lm,xKe),e(lm,HR),e(HR,$Ke),e(lm,kKe),e(A,SKe),e(A,im),e(im,Mse),e(Mse,RKe),e(im,PKe),e(im,UR),e(UR,BKe),e(im,IKe),e(A,NKe),e(A,dm),e(dm,Ese),e(Ese,qKe),e(dm,jKe),e(dm,JR),e(JR,DKe),e(dm,GKe),e(A,OKe),e(A,cm),e(cm,Cse),e(Cse,VKe),e(cm,XKe),e(cm,YR),e(YR,zKe),e(cm,WKe),e(A,QKe),e(A,fm),e(fm,wse),e(wse,HKe),e(fm,UKe),e(fm,KR),e(KR,JKe),e(fm,YKe),e(A,KKe),e(A,mm),e(mm,Ase),e(Ase,ZKe),e(mm,eZe),e(mm,ZR),e(ZR,oZe),e(mm,rZe),e(A,tZe),e(A,gm),e(gm,Lse),e(Lse,aZe),e(gm,nZe),e(gm,eP),e(eP,sZe),e(gm,lZe),e(A,iZe),e(A,hm),e(hm,yse),e(yse,dZe),e(hm,cZe),e(hm,oP),e(oP,fZe),e(hm,mZe),e(A,gZe),e(A,pm),e(pm,xse),e(xse,hZe),e(pm,pZe),e(pm,rP),e(rP,_Ze),e(pm,uZe),e(A,bZe),e(A,_m),e(_m,$se),e($se,vZe),e(_m,FZe),e(_m,tP),e(tP,TZe),e(_m,MZe),e(A,EZe),e(A,um),e(um,kse),e(kse,CZe),e(um,wZe),e(um,aP),e(aP,AZe),e(um,LZe),e(A,yZe),e(A,bm),e(bm,Sse),e(Sse,xZe),e(bm,$Ze),e(bm,nP),e(nP,kZe),e(bm,SZe),e(A,RZe),e(A,vm),e(vm,Rse),e(Rse,PZe),e(vm,BZe),e(vm,sP),e(sP,IZe),e(vm,NZe),e(A,qZe),e(A,Fm),e(Fm,Pse),e(Pse,jZe),e(Fm,DZe),e(Fm,lP),e(lP,GZe),e(Fm,OZe),e(A,VZe),e(A,Tm),e(Tm,Bse),e(Bse,XZe),e(Tm,zZe),e(Tm,iP),e(iP,WZe),e(Tm,QZe),e(A,HZe),e(A,Mm),e(Mm,Ise),e(Ise,UZe),e(Mm,JZe),e(Mm,dP),e(dP,YZe),e(Mm,KZe),e(A,ZZe),e(A,Em),e(Em,Nse),e(Nse,eeo),e(Em,oeo),e(Em,cP),e(cP,reo),e(Em,teo),e(A,aeo),e(A,Cm),e(Cm,qse),e(qse,neo),e(Cm,seo),e(Cm,fP),e(fP,leo),e(Cm,ieo),e(A,deo),e(A,wm),e(wm,jse),e(jse,ceo),e(wm,feo),e(wm,mP),e(mP,meo),e(wm,geo),e(A,heo),e(A,Am),e(Am,Dse),e(Dse,peo),e(Am,_eo),e(Am,gP),e(gP,ueo),e(Am,beo),e(A,veo),e(A,Lm),e(Lm,Gse),e(Gse,Feo),e(Lm,Teo),e(Lm,hP),e(hP,Meo),e(Lm,Eeo),e(A,Ceo),e(A,ym),e(ym,Ose),e(Ose,weo),e(ym,Aeo),e(ym,pP),e(pP,Leo),e(ym,yeo),e(A,xeo),e(A,xm),e(xm,Vse),e(Vse,$eo),e(xm,keo),e(xm,_P),e(_P,Seo),e(xm,Reo),e(A,Peo),e(A,$m),e($m,Xse),e(Xse,Beo),e($m,Ieo),e($m,uP),e(uP,Neo),e($m,qeo),e(A,jeo),e(A,km),e(km,zse),e(zse,Deo),e(km,Geo),e(km,bP),e(bP,Oeo),e(km,Veo),e(A,Xeo),e(A,Sm),e(Sm,Wse),e(Wse,zeo),e(Sm,Weo),e(Sm,vP),e(vP,Qeo),e(Sm,Heo),e(A,Ueo),e(A,Rm),e(Rm,Qse),e(Qse,Jeo),e(Rm,Yeo),e(Rm,FP),e(FP,Keo),e(Rm,Zeo),e(A,eoo),e(A,Pm),e(Pm,Hse),e(Hse,ooo),e(Pm,roo),e(Pm,TP),e(TP,too),e(Pm,aoo),e(A,noo),e(A,Bm),e(Bm,Use),e(Use,soo),e(Bm,loo),e(Bm,MP),e(MP,ioo),e(Bm,doo),e(A,coo),e(A,Im),e(Im,Jse),e(Jse,foo),e(Im,moo),e(Im,EP),e(EP,goo),e(Im,hoo),e(A,poo),e(A,Nm),e(Nm,Yse),e(Yse,_oo),e(Nm,uoo),e(Nm,CP),e(CP,boo),e(Nm,voo),e(A,Foo),e(A,qm),e(qm,Kse),e(Kse,Too),e(qm,Moo),e(qm,wP),e(wP,Eoo),e(qm,Coo),e(A,woo),e(A,jm),e(jm,Zse),e(Zse,Aoo),e(jm,Loo),e(jm,AP),e(AP,yoo),e(jm,xoo),e(A,$oo),e(A,Dm),e(Dm,ele),e(ele,koo),e(Dm,Soo),e(Dm,LP),e(LP,Roo),e(Dm,Poo),e(A,Boo),e(A,Gm),e(Gm,ole),e(ole,Ioo),e(Gm,Noo),e(Gm,yP),e(yP,qoo),e(Gm,joo),e(A,Doo),e(A,Om),e(Om,rle),e(rle,Goo),e(Om,Ooo),e(Om,xP),e(xP,Voo),e(Om,Xoo),e(A,zoo),e(A,Vm),e(Vm,tle),e(tle,Woo),e(Vm,Qoo),e(Vm,$P),e($P,Hoo),e(Vm,Uoo),e(A,Joo),e(A,Xm),e(Xm,ale),e(ale,Yoo),e(Xm,Koo),e(Xm,kP),e(kP,Zoo),e(Xm,ero),e(A,oro),e(A,zm),e(zm,nle),e(nle,rro),e(zm,tro),e(zm,SP),e(SP,aro),e(zm,nro),e(A,sro),e(A,Wm),e(Wm,sle),e(sle,lro),e(Wm,iro),e(Wm,RP),e(RP,dro),e(Wm,cro),e(A,fro),e(A,Qm),e(Qm,lle),e(lle,mro),e(Qm,gro),e(Qm,PP),e(PP,hro),e(Qm,pro),e(A,_ro),e(A,Hm),e(Hm,ile),e(ile,uro),e(Hm,bro),e(Hm,BP),e(BP,vro),e(Hm,Fro),e(A,Tro),e(A,Um),e(Um,dle),e(dle,Mro),e(Um,Ero),e(Um,IP),e(IP,Cro),e(Um,wro),e(A,Aro),e(A,Jm),e(Jm,cle),e(cle,Lro),e(Jm,yro),e(Jm,NP),e(NP,xro),e(Jm,$ro),e(A,kro),e(A,Ym),e(Ym,fle),e(fle,Sro),e(Ym,Rro),e(Ym,qP),e(qP,Pro),e(Ym,Bro),e(A,Iro),e(A,Km),e(Km,mle),e(mle,Nro),e(Km,qro),e(Km,jP),e(jP,jro),e(Km,Dro),e(A,Gro),e(A,Zm),e(Zm,gle),e(gle,Oro),e(Zm,Vro),e(Zm,DP),e(DP,Xro),e(Zm,zro),e(A,Wro),e(A,eg),e(eg,hle),e(hle,Qro),e(eg,Hro),e(eg,GP),e(GP,Uro),e(eg,Jro),e(A,Yro),e(A,og),e(og,ple),e(ple,Kro),e(og,Zro),e(og,OP),e(OP,eto),e(og,oto),e(A,rto),e(A,rg),e(rg,_le),e(_le,tto),e(rg,ato),e(rg,VP),e(VP,nto),e(rg,sto),e(A,lto),e(A,tg),e(tg,ule),e(ule,ito),e(tg,dto),e(tg,XP),e(XP,cto),e(tg,fto),e(A,mto),e(A,ag),e(ag,ble),e(ble,gto),e(ag,hto),e(ag,zP),e(zP,pto),e(ag,_to),e(A,uto),e(A,ng),e(ng,vle),e(vle,bto),e(ng,vto),e(ng,WP),e(WP,Fto),e(ng,Tto),e(A,Mto),e(A,sg),e(sg,Fle),e(Fle,Eto),e(sg,Cto),e(sg,QP),e(QP,wto),e(sg,Ato),e(A,Lto),e(A,lg),e(lg,Tle),e(Tle,yto),e(lg,xto),e(lg,HP),e(HP,$to),e(lg,kto),e(A,Sto),e(A,ig),e(ig,Mle),e(Mle,Rto),e(ig,Pto),e(ig,UP),e(UP,Bto),e(ig,Ito),e(A,Nto),e(A,dg),e(dg,Ele),e(Ele,qto),e(dg,jto),e(dg,JP),e(JP,Dto),e(dg,Gto),e(A,Oto),e(A,cg),e(cg,Cle),e(Cle,Vto),e(cg,Xto),e(cg,YP),e(YP,zto),e(cg,Wto),e(A,Qto),e(A,fg),e(fg,wle),e(wle,Hto),e(fg,Uto),e(fg,KP),e(KP,Jto),e(fg,Yto),e(A,Kto),e(A,mg),e(mg,Ale),e(Ale,Zto),e(mg,eao),e(mg,ZP),e(ZP,oao),e(mg,rao),e(A,tao),e(A,gg),e(gg,Lle),e(Lle,aao),e(gg,nao),e(gg,eB),e(eB,sao),e(gg,lao),e(A,iao),e(A,hg),e(hg,yle),e(yle,dao),e(hg,cao),e(hg,oB),e(oB,fao),e(hg,mao),e(A,gao),e(A,pg),e(pg,xle),e(xle,hao),e(pg,pao),e(pg,rB),e(rB,_ao),e(pg,uao),e(A,bao),e(A,_g),e(_g,$le),e($le,vao),e(_g,Fao),e(_g,tB),e(tB,Tao),e(_g,Mao),e(A,Eao),e(A,ug),e(ug,kle),e(kle,Cao),e(ug,wao),e(ug,aB),e(aB,Aao),e(ug,Lao),e(A,yao),e(A,bg),e(bg,Sle),e(Sle,xao),e(bg,$ao),e(bg,nB),e(nB,kao),e(bg,Sao),e(A,Rao),e(A,vg),e(vg,Rle),e(Rle,Pao),e(vg,Bao),e(vg,sB),e(sB,Iao),e(vg,Nao),e(A,qao),e(A,Fg),e(Fg,Ple),e(Ple,jao),e(Fg,Dao),e(Fg,lB),e(lB,Gao),e(Fg,Oao),e(A,Vao),e(A,Tg),e(Tg,Ble),e(Ble,Xao),e(Tg,zao),e(Tg,iB),e(iB,Wao),e(Tg,Qao),e(A,Hao),e(A,Mg),e(Mg,Ile),e(Ile,Uao),e(Mg,Jao),e(Mg,dB),e(dB,Yao),e(Mg,Kao),e(A,Zao),e(A,Eg),e(Eg,Nle),e(Nle,eno),e(Eg,ono),e(Eg,cB),e(cB,rno),e(Eg,tno),e(A,ano),e(A,Cg),e(Cg,qle),e(qle,nno),e(Cg,sno),e(Cg,fB),e(fB,lno),e(Cg,ino),e(A,dno),e(A,wg),e(wg,jle),e(jle,cno),e(wg,fno),e(wg,mB),e(mB,mno),e(wg,gno),e(A,hno),e(A,Ag),e(Ag,Dle),e(Dle,pno),e(Ag,_no),e(Ag,gB),e(gB,uno),e(Ag,bno),e(A,vno),e(A,Lg),e(Lg,Gle),e(Gle,Fno),e(Lg,Tno),e(Lg,hB),e(hB,Mno),e(Lg,Eno),e(A,Cno),e(A,yg),e(yg,Ole),e(Ole,wno),e(yg,Ano),e(yg,pB),e(pB,Lno),e(yg,yno),e(A,xno),e(A,xg),e(xg,Vle),e(Vle,$no),e(xg,kno),e(xg,_B),e(_B,Sno),e(xg,Rno),e(A,Pno),e(A,$g),e($g,Xle),e(Xle,Bno),e($g,Ino),e($g,uB),e(uB,Nno),e($g,qno),e(A,jno),e(A,kg),e(kg,zle),e(zle,Dno),e(kg,Gno),e(kg,bB),e(bB,Ono),e(kg,Vno),e(A,Xno),e(A,Sg),e(Sg,Wle),e(Wle,zno),e(Sg,Wno),e(Sg,vB),e(vB,Qno),e(Sg,Hno),e(A,Uno),e(A,Rg),e(Rg,Qle),e(Qle,Jno),e(Rg,Yno),e(Rg,FB),e(FB,Kno),e(Rg,Zno),e(A,eso),e(A,Pg),e(Pg,Hle),e(Hle,oso),e(Pg,rso),e(Pg,TB),e(TB,tso),e(Pg,aso),e(A,nso),e(A,Bg),e(Bg,Ule),e(Ule,sso),e(Bg,lso),e(Bg,MB),e(MB,iso),e(Bg,dso),e(A,cso),e(A,Ig),e(Ig,Jle),e(Jle,fso),e(Ig,mso),e(Ig,EB),e(EB,gso),e(Ig,hso),e(A,pso),e(A,Ng),e(Ng,Yle),e(Yle,_so),e(Ng,uso),e(Ng,CB),e(CB,bso),e(Ng,vso),e(A,Fso),e(A,qg),e(qg,Kle),e(Kle,Tso),e(qg,Mso),e(qg,wB),e(wB,Eso),e(qg,Cso),e(A,wso),e(A,jg),e(jg,Zle),e(Zle,Aso),e(jg,Lso),e(jg,AB),e(AB,yso),e(jg,xso),e(A,$so),e(A,Dg),e(Dg,eie),e(eie,kso),e(Dg,Sso),e(Dg,LB),e(LB,Rso),e(Dg,Pso),e(A,Bso),e(A,Gg),e(Gg,oie),e(oie,Iso),e(Gg,Nso),e(Gg,yB),e(yB,qso),e(Gg,jso),e(A,Dso),e(A,Og),e(Og,rie),e(rie,Gso),e(Og,Oso),e(Og,xB),e(xB,Vso),e(Og,Xso),e(A,zso),e(A,Vg),e(Vg,tie),e(tie,Wso),e(Vg,Qso),e(Vg,$B),e($B,Hso),e(Vg,Uso),e(A,Jso),e(A,Xg),e(Xg,aie),e(aie,Yso),e(Xg,Kso),e(Xg,kB),e(kB,Zso),e(Xg,elo),e(A,olo),e(A,zg),e(zg,nie),e(nie,rlo),e(zg,tlo),e(zg,SB),e(SB,alo),e(zg,nlo),e(A,slo),e(A,Wg),e(Wg,sie),e(sie,llo),e(Wg,ilo),e(Wg,RB),e(RB,dlo),e(Wg,clo),e(A,flo),e(A,Qg),e(Qg,lie),e(lie,mlo),e(Qg,glo),e(Qg,PB),e(PB,hlo),e(Qg,plo),e(A,_lo),e(A,Hg),e(Hg,iie),e(iie,ulo),e(Hg,blo),e(Hg,BB),e(BB,vlo),e(Hg,Flo),e(A,Tlo),e(A,Ug),e(Ug,die),e(die,Mlo),e(Ug,Elo),e(Ug,IB),e(IB,Clo),e(Ug,wlo),e(A,Alo),e(A,Jg),e(Jg,cie),e(cie,Llo),e(Jg,ylo),e(Jg,NB),e(NB,xlo),e(Jg,$lo),e(A,klo),e(A,Yg),e(Yg,fie),e(fie,Slo),e(Yg,Rlo),e(Yg,qB),e(qB,Plo),e(Yg,Blo),e(A,Ilo),e(A,Kg),e(Kg,mie),e(mie,Nlo),e(Kg,qlo),e(Kg,jB),e(jB,jlo),e(Kg,Dlo),e(A,Glo),e(A,Zg),e(Zg,gie),e(gie,Olo),e(Zg,Vlo),e(Zg,DB),e(DB,Xlo),e(Zg,zlo),e(A,Wlo),e(A,eh),e(eh,hie),e(hie,Qlo),e(eh,Hlo),e(eh,GB),e(GB,Ulo),e(eh,Jlo),e(A,Ylo),e(A,oh),e(oh,pie),e(pie,Klo),e(oh,Zlo),e(oh,OB),e(OB,eio),e(oh,oio),e(A,rio),e(A,rh),e(rh,_ie),e(_ie,tio),e(rh,aio),e(rh,VB),e(VB,nio),e(rh,sio),e(A,lio),e(A,th),e(th,uie),e(uie,iio),e(th,dio),e(th,XB),e(XB,cio),e(th,fio),e(A,mio),e(A,ah),e(ah,bie),e(bie,gio),e(ah,hio),e(ah,zB),e(zB,pio),e(ah,_io),e(A,uio),e(A,nh),e(nh,vie),e(vie,bio),e(nh,vio),e(nh,WB),e(WB,Fio),e(nh,Tio),e(A,Mio),e(A,sh),e(sh,Fie),e(Fie,Eio),e(sh,Cio),e(sh,QB),e(QB,wio),e(sh,Aio),e(A,Lio),e(A,lh),e(lh,Tie),e(Tie,yio),e(lh,xio),e(lh,HB),e(HB,$io),e(lh,kio),e(A,Sio),e(A,ih),e(ih,Mie),e(Mie,Rio),e(ih,Pio),e(ih,UB),e(UB,Bio),e(ih,Iio),e(A,Nio),e(A,dh),e(dh,Eie),e(Eie,qio),e(dh,jio),e(dh,JB),e(JB,Dio),e(dh,Gio),e(A,Oio),e(A,ch),e(ch,Cie),e(Cie,Vio),e(ch,Xio),e(ch,YB),e(YB,zio),e(ch,Wio),e($r,Qio),M(fh,$r,null),e(yo,Hio),e(yo,mh),M(oy,mh,null),e(mh,Uio),e(mh,wie),e(wie,Jio),b(f,JWe,u),b(f,Wi,u),e(Wi,gh),e(gh,Aie),M(ry,Aie,null),e(Wi,Yio),e(Wi,Lie),e(Lie,Kio),b(f,YWe,u),b(f,xo,u),M(ty,xo,null),e(xo,Zio),e(xo,ay),e(ay,edo),e(ay,KB),e(KB,odo),e(ay,rdo),e(xo,tdo),e(xo,ny),e(ny,ado),e(ny,yie),e(yie,ndo),e(ny,sdo),e(xo,ldo),e(xo,kr),M(sy,kr,null),e(kr,ido),e(kr,xie),e(xie,ddo),e(kr,cdo),e(kr,qa),e(qa,fdo),e(qa,$ie),e($ie,mdo),e(qa,gdo),e(qa,kie),e(kie,hdo),e(qa,pdo),e(qa,Sie),e(Sie,_do),e(qa,udo),e(kr,bdo),e(kr,k),e(k,zn),e(zn,Rie),e(Rie,vdo),e(zn,Fdo),e(zn,ZB),e(ZB,Tdo),e(zn,Mdo),e(zn,eI),e(eI,Edo),e(zn,Cdo),e(k,wdo),e(k,Wn),e(Wn,Pie),e(Pie,Ado),e(Wn,Ldo),e(Wn,oI),e(oI,ydo),e(Wn,xdo),e(Wn,rI),e(rI,$do),e(Wn,kdo),e(k,Sdo),e(k,Qn),e(Qn,Bie),e(Bie,Rdo),e(Qn,Pdo),e(Qn,tI),e(tI,Bdo),e(Qn,Ido),e(Qn,aI),e(aI,Ndo),e(Qn,qdo),e(k,jdo),e(k,hh),e(hh,Iie),e(Iie,Ddo),e(hh,Gdo),e(hh,nI),e(nI,Odo),e(hh,Vdo),e(k,Xdo),e(k,Hn),e(Hn,Nie),e(Nie,zdo),e(Hn,Wdo),e(Hn,sI),e(sI,Qdo),e(Hn,Hdo),e(Hn,lI),e(lI,Udo),e(Hn,Jdo),e(k,Ydo),e(k,ph),e(ph,qie),e(qie,Kdo),e(ph,Zdo),e(ph,iI),e(iI,eco),e(ph,oco),e(k,rco),e(k,_h),e(_h,jie),e(jie,tco),e(_h,aco),e(_h,dI),e(dI,nco),e(_h,sco),e(k,lco),e(k,uh),e(uh,Die),e(Die,ico),e(uh,dco),e(uh,cI),e(cI,cco),e(uh,fco),e(k,mco),e(k,Un),e(Un,Gie),e(Gie,gco),e(Un,hco),e(Un,fI),e(fI,pco),e(Un,_co),e(Un,mI),e(mI,uco),e(Un,bco),e(k,vco),e(k,Jn),e(Jn,Oie),e(Oie,Fco),e(Jn,Tco),e(Jn,gI),e(gI,Mco),e(Jn,Eco),e(Jn,hI),e(hI,Cco),e(Jn,wco),e(k,Aco),e(k,Yn),e(Yn,Vie),e(Vie,Lco),e(Yn,yco),e(Yn,pI),e(pI,xco),e(Yn,$co),e(Yn,_I),e(_I,kco),e(Yn,Sco),e(k,Rco),e(k,bh),e(bh,Xie),e(Xie,Pco),e(bh,Bco),e(bh,uI),e(uI,Ico),e(bh,Nco),e(k,qco),e(k,vh),e(vh,zie),e(zie,jco),e(vh,Dco),e(vh,bI),e(bI,Gco),e(vh,Oco),e(k,Vco),e(k,Fh),e(Fh,Wie),e(Wie,Xco),e(Fh,zco),e(Fh,vI),e(vI,Wco),e(Fh,Qco),e(k,Hco),e(k,Kn),e(Kn,Qie),e(Qie,Uco),e(Kn,Jco),e(Kn,FI),e(FI,Yco),e(Kn,Kco),e(Kn,TI),e(TI,Zco),e(Kn,efo),e(k,ofo),e(k,Th),e(Th,Hie),e(Hie,rfo),e(Th,tfo),e(Th,MI),e(MI,afo),e(Th,nfo),e(k,sfo),e(k,Zn),e(Zn,Uie),e(Uie,lfo),e(Zn,ifo),e(Zn,EI),e(EI,dfo),e(Zn,cfo),e(Zn,CI),e(CI,ffo),e(Zn,mfo),e(k,gfo),e(k,es),e(es,Jie),e(Jie,hfo),e(es,pfo),e(es,wI),e(wI,_fo),e(es,ufo),e(es,AI),e(AI,bfo),e(es,vfo),e(k,Ffo),e(k,os),e(os,Yie),e(Yie,Tfo),e(os,Mfo),e(os,LI),e(LI,Efo),e(os,Cfo),e(os,yI),e(yI,wfo),e(os,Afo),e(k,Lfo),e(k,rs),e(rs,Kie),e(Kie,yfo),e(rs,xfo),e(rs,xI),e(xI,$fo),e(rs,kfo),e(rs,$I),e($I,Sfo),e(rs,Rfo),e(k,Pfo),e(k,Mh),e(Mh,Zie),e(Zie,Bfo),e(Mh,Ifo),e(Mh,kI),e(kI,Nfo),e(Mh,qfo),e(k,jfo),e(k,ts),e(ts,ede),e(ede,Dfo),e(ts,Gfo),e(ts,SI),e(SI,Ofo),e(ts,Vfo),e(ts,RI),e(RI,Xfo),e(ts,zfo),e(k,Wfo),e(k,as),e(as,ode),e(ode,Qfo),e(as,Hfo),e(as,PI),e(PI,Ufo),e(as,Jfo),e(as,BI),e(BI,Yfo),e(as,Kfo),e(k,Zfo),e(k,ns),e(ns,rde),e(rde,emo),e(ns,omo),e(ns,II),e(II,rmo),e(ns,tmo),e(ns,NI),e(NI,amo),e(ns,nmo),e(k,smo),e(k,ss),e(ss,tde),e(tde,lmo),e(ss,imo),e(ss,qI),e(qI,dmo),e(ss,cmo),e(ss,jI),e(jI,fmo),e(ss,mmo),e(k,gmo),e(k,ls),e(ls,ade),e(ade,hmo),e(ls,pmo),e(ls,DI),e(DI,_mo),e(ls,umo),e(ls,GI),e(GI,bmo),e(ls,vmo),e(k,Fmo),e(k,is),e(is,nde),e(nde,Tmo),e(is,Mmo),e(is,OI),e(OI,Emo),e(is,Cmo),e(is,VI),e(VI,wmo),e(is,Amo),e(k,Lmo),e(k,Eh),e(Eh,sde),e(sde,ymo),e(Eh,xmo),e(Eh,XI),e(XI,$mo),e(Eh,kmo),e(k,Smo),e(k,ds),e(ds,lde),e(lde,Rmo),e(ds,Pmo),e(ds,zI),e(zI,Bmo),e(ds,Imo),e(ds,WI),e(WI,Nmo),e(ds,qmo),e(k,jmo),e(k,Ch),e(Ch,ide),e(ide,Dmo),e(Ch,Gmo),e(Ch,QI),e(QI,Omo),e(Ch,Vmo),e(k,Xmo),e(k,cs),e(cs,dde),e(dde,zmo),e(cs,Wmo),e(cs,HI),e(HI,Qmo),e(cs,Hmo),e(cs,UI),e(UI,Umo),e(cs,Jmo),e(k,Ymo),e(k,fs),e(fs,cde),e(cde,Kmo),e(fs,Zmo),e(fs,JI),e(JI,ego),e(fs,ogo),e(fs,YI),e(YI,rgo),e(fs,tgo),e(k,ago),e(k,ms),e(ms,fde),e(fde,ngo),e(ms,sgo),e(ms,KI),e(KI,lgo),e(ms,igo),e(ms,ZI),e(ZI,dgo),e(ms,cgo),e(k,fgo),e(k,wh),e(wh,mde),e(mde,mgo),e(wh,ggo),e(wh,eN),e(eN,hgo),e(wh,pgo),e(k,_go),e(k,gs),e(gs,gde),e(gde,ugo),e(gs,bgo),e(gs,oN),e(oN,vgo),e(gs,Fgo),e(gs,rN),e(rN,Tgo),e(gs,Mgo),e(k,Ego),e(k,hs),e(hs,hde),e(hde,Cgo),e(hs,wgo),e(hs,tN),e(tN,Ago),e(hs,Lgo),e(hs,aN),e(aN,ygo),e(hs,xgo),e(k,$go),e(k,ps),e(ps,pde),e(pde,kgo),e(ps,Sgo),e(ps,nN),e(nN,Rgo),e(ps,Pgo),e(ps,sN),e(sN,Bgo),e(ps,Igo),e(k,Ngo),e(k,Ah),e(Ah,_de),e(_de,qgo),e(Ah,jgo),e(Ah,lN),e(lN,Dgo),e(Ah,Ggo),e(k,Ogo),e(k,_s),e(_s,ude),e(ude,Vgo),e(_s,Xgo),e(_s,iN),e(iN,zgo),e(_s,Wgo),e(_s,dN),e(dN,Qgo),e(_s,Hgo),e(k,Ugo),e(k,us),e(us,bde),e(bde,Jgo),e(us,Ygo),e(us,cN),e(cN,Kgo),e(us,Zgo),e(us,fN),e(fN,eho),e(us,oho),e(k,rho),e(k,bs),e(bs,vde),e(vde,tho),e(bs,aho),e(bs,mN),e(mN,nho),e(bs,sho),e(bs,gN),e(gN,lho),e(bs,iho),e(k,dho),e(k,vs),e(vs,Fde),e(Fde,cho),e(vs,fho),e(vs,hN),e(hN,mho),e(vs,gho),e(vs,pN),e(pN,hho),e(vs,pho),e(k,_ho),e(k,Fs),e(Fs,Tde),e(Tde,uho),e(Fs,bho),e(Fs,_N),e(_N,vho),e(Fs,Fho),e(Fs,uN),e(uN,Tho),e(Fs,Mho),e(k,Eho),e(k,Ts),e(Ts,Mde),e(Mde,Cho),e(Ts,who),e(Ts,bN),e(bN,Aho),e(Ts,Lho),e(Ts,vN),e(vN,yho),e(Ts,xho),e(k,$ho),e(k,Ms),e(Ms,Ede),e(Ede,kho),e(Ms,Sho),e(Ms,FN),e(FN,Rho),e(Ms,Pho),e(Ms,TN),e(TN,Bho),e(Ms,Iho),e(k,Nho),e(k,Es),e(Es,Cde),e(Cde,qho),e(Es,jho),e(Es,MN),e(MN,Dho),e(Es,Gho),e(Es,EN),e(EN,Oho),e(Es,Vho),e(k,Xho),e(k,Lh),e(Lh,wde),e(wde,zho),e(Lh,Who),e(Lh,CN),e(CN,Qho),e(Lh,Hho),e(k,Uho),e(k,Cs),e(Cs,Ade),e(Ade,Jho),e(Cs,Yho),e(Cs,wN),e(wN,Kho),e(Cs,Zho),e(Cs,AN),e(AN,epo),e(Cs,opo),e(k,rpo),e(k,yh),e(yh,Lde),e(Lde,tpo),e(yh,apo),e(yh,LN),e(LN,npo),e(yh,spo),e(k,lpo),e(k,xh),e(xh,yde),e(yde,ipo),e(xh,dpo),e(xh,yN),e(yN,cpo),e(xh,fpo),e(k,mpo),e(k,ws),e(ws,xde),e(xde,gpo),e(ws,hpo),e(ws,xN),e(xN,ppo),e(ws,_po),e(ws,$N),e($N,upo),e(ws,bpo),e(k,vpo),e(k,As),e(As,$de),e($de,Fpo),e(As,Tpo),e(As,kN),e(kN,Mpo),e(As,Epo),e(As,SN),e(SN,Cpo),e(As,wpo),e(k,Apo),e(k,Ls),e(Ls,kde),e(kde,Lpo),e(Ls,ypo),e(Ls,RN),e(RN,xpo),e(Ls,$po),e(Ls,PN),e(PN,kpo),e(Ls,Spo),e(k,Rpo),e(k,$h),e($h,Sde),e(Sde,Ppo),e($h,Bpo),e($h,BN),e(BN,Ipo),e($h,Npo),e(k,qpo),e(k,ys),e(ys,Rde),e(Rde,jpo),e(ys,Dpo),e(ys,IN),e(IN,Gpo),e(ys,Opo),e(ys,NN),e(NN,Vpo),e(ys,Xpo),e(k,zpo),e(k,xs),e(xs,Pde),e(Pde,Wpo),e(xs,Qpo),e(xs,qN),e(qN,Hpo),e(xs,Upo),e(xs,jN),e(jN,Jpo),e(xs,Ypo),e(k,Kpo),e(k,$s),e($s,Bde),e(Bde,Zpo),e($s,e_o),e($s,DN),e(DN,o_o),e($s,r_o),e($s,GN),e(GN,t_o),e($s,a_o),e(k,n_o),e(k,ks),e(ks,Ide),e(Ide,s_o),e(ks,l_o),e(ks,ON),e(ON,i_o),e(ks,d_o),e(ks,VN),e(VN,c_o),e(ks,f_o),e(k,m_o),e(k,Ss),e(Ss,Nde),e(Nde,g_o),e(Ss,h_o),e(Ss,XN),e(XN,p_o),e(Ss,__o),e(Ss,zN),e(zN,u_o),e(Ss,b_o),e(k,v_o),e(k,Rs),e(Rs,qde),e(qde,F_o),e(Rs,T_o),e(Rs,WN),e(WN,M_o),e(Rs,E_o),e(Rs,QN),e(QN,C_o),e(Rs,w_o),e(k,A_o),e(k,Ps),e(Ps,jde),e(jde,L_o),e(Ps,y_o),e(Ps,HN),e(HN,x_o),e(Ps,$_o),e(Ps,UN),e(UN,k_o),e(Ps,S_o),e(k,R_o),e(k,Bs),e(Bs,Dde),e(Dde,P_o),e(Bs,B_o),e(Bs,JN),e(JN,I_o),e(Bs,N_o),e(Bs,YN),e(YN,q_o),e(Bs,j_o),e(k,D_o),e(k,kh),e(kh,Gde),e(Gde,G_o),e(kh,O_o),e(kh,KN),e(KN,V_o),e(kh,X_o),e(k,z_o),e(k,Is),e(Is,Ode),e(Ode,W_o),e(Is,Q_o),e(Is,ZN),e(ZN,H_o),e(Is,U_o),e(Is,eq),e(eq,J_o),e(Is,Y_o),e(k,K_o),e(k,Ns),e(Ns,Vde),e(Vde,Z_o),e(Ns,euo),e(Ns,oq),e(oq,ouo),e(Ns,ruo),e(Ns,rq),e(rq,tuo),e(Ns,auo),e(k,nuo),e(k,Sh),e(Sh,Xde),e(Xde,suo),e(Sh,luo),e(Sh,tq),e(tq,iuo),e(Sh,duo),e(k,cuo),e(k,Rh),e(Rh,zde),e(zde,fuo),e(Rh,muo),e(Rh,aq),e(aq,guo),e(Rh,huo),e(k,puo),e(k,Ph),e(Ph,Wde),e(Wde,_uo),e(Ph,uuo),e(Ph,nq),e(nq,buo),e(Ph,vuo),e(k,Fuo),e(k,Bh),e(Bh,Qde),e(Qde,Tuo),e(Bh,Muo),e(Bh,sq),e(sq,Euo),e(Bh,Cuo),e(k,wuo),e(k,qs),e(qs,Hde),e(Hde,Auo),e(qs,Luo),e(qs,lq),e(lq,yuo),e(qs,xuo),e(qs,iq),e(iq,$uo),e(qs,kuo),e(k,Suo),e(k,Ih),e(Ih,Ude),e(Ude,Ruo),e(Ih,Puo),e(Ih,dq),e(dq,Buo),e(Ih,Iuo),e(k,Nuo),e(k,js),e(js,Jde),e(Jde,quo),e(js,juo),e(js,cq),e(cq,Duo),e(js,Guo),e(js,fq),e(fq,Ouo),e(js,Vuo),e(k,Xuo),e(k,Ds),e(Ds,Yde),e(Yde,zuo),e(Ds,Wuo),e(Ds,mq),e(mq,Quo),e(Ds,Huo),e(Ds,gq),e(gq,Uuo),e(Ds,Juo),e(k,Yuo),e(k,Gs),e(Gs,Kde),e(Kde,Kuo),e(Gs,Zuo),e(Gs,hq),e(hq,e2o),e(Gs,o2o),e(Gs,pq),e(pq,r2o),e(Gs,t2o),e(k,a2o),e(k,Os),e(Os,Zde),e(Zde,n2o),e(Os,s2o),e(Os,_q),e(_q,l2o),e(Os,i2o),e(Os,uq),e(uq,d2o),e(Os,c2o),e(k,f2o),e(k,Vs),e(Vs,ece),e(ece,m2o),e(Vs,g2o),e(Vs,bq),e(bq,h2o),e(Vs,p2o),e(Vs,vq),e(vq,_2o),e(Vs,u2o),e(k,b2o),e(k,Xs),e(Xs,oce),e(oce,v2o),e(Xs,F2o),e(Xs,Fq),e(Fq,T2o),e(Xs,M2o),e(Xs,Tq),e(Tq,E2o),e(Xs,C2o),e(k,w2o),e(k,Nh),e(Nh,rce),e(rce,A2o),e(Nh,L2o),e(Nh,Mq),e(Mq,y2o),e(Nh,x2o),e(k,$2o),e(k,qh),e(qh,tce),e(tce,k2o),e(qh,S2o),e(qh,Eq),e(Eq,R2o),e(qh,P2o),e(k,B2o),e(k,zs),e(zs,ace),e(ace,I2o),e(zs,N2o),e(zs,Cq),e(Cq,q2o),e(zs,j2o),e(zs,wq),e(wq,D2o),e(zs,G2o),e(k,O2o),e(k,Ws),e(Ws,nce),e(nce,V2o),e(Ws,X2o),e(Ws,Aq),e(Aq,z2o),e(Ws,W2o),e(Ws,Lq),e(Lq,Q2o),e(Ws,H2o),e(k,U2o),e(k,Qs),e(Qs,sce),e(sce,J2o),e(Qs,Y2o),e(Qs,yq),e(yq,K2o),e(Qs,Z2o),e(Qs,xq),e(xq,e1o),e(Qs,o1o),e(k,r1o),e(k,jh),e(jh,lce),e(lce,t1o),e(jh,a1o),e(jh,$q),e($q,n1o),e(jh,s1o),e(k,l1o),e(k,Dh),e(Dh,ice),e(ice,i1o),e(Dh,d1o),e(Dh,kq),e(kq,c1o),e(Dh,f1o),e(k,m1o),e(k,Gh),e(Gh,dce),e(dce,g1o),e(Gh,h1o),e(Gh,Sq),e(Sq,p1o),e(Gh,_1o),e(k,u1o),e(k,Hs),e(Hs,cce),e(cce,b1o),e(Hs,v1o),e(Hs,Rq),e(Rq,F1o),e(Hs,T1o),e(Hs,Pq),e(Pq,M1o),e(Hs,E1o),e(k,C1o),e(k,Us),e(Us,fce),e(fce,w1o),e(Us,A1o),e(Us,Bq),e(Bq,L1o),e(Us,y1o),e(Us,Iq),e(Iq,x1o),e(Us,$1o),e(k,k1o),e(k,Oh),e(Oh,mce),e(mce,S1o),e(Oh,R1o),e(Oh,Nq),e(Nq,P1o),e(Oh,B1o),e(k,I1o),e(k,Vh),e(Vh,gce),e(gce,N1o),e(Vh,q1o),e(Vh,qq),e(qq,j1o),e(Vh,D1o),e(k,G1o),e(k,Xh),e(Xh,hce),e(hce,O1o),e(Xh,V1o),e(Xh,jq),e(jq,X1o),e(Xh,z1o),e(k,W1o),e(k,Js),e(Js,pce),e(pce,Q1o),e(Js,H1o),e(Js,Dq),e(Dq,U1o),e(Js,J1o),e(Js,Gq),e(Gq,Y1o),e(Js,K1o),e(k,Z1o),e(k,zh),e(zh,_ce),e(_ce,ebo),e(zh,obo),e(zh,Oq),e(Oq,rbo),e(zh,tbo),e(k,abo),e(k,Wh),e(Wh,uce),e(uce,nbo),e(Wh,sbo),e(Wh,Vq),e(Vq,lbo),e(Wh,ibo),e(k,dbo),e(k,Ys),e(Ys,bce),e(bce,cbo),e(Ys,fbo),e(Ys,Xq),e(Xq,mbo),e(Ys,gbo),e(Ys,zq),e(zq,hbo),e(Ys,pbo),e(k,_bo),e(k,Ks),e(Ks,vce),e(vce,ubo),e(Ks,bbo),e(Ks,Wq),e(Wq,vbo),e(Ks,Fbo),e(Ks,Qq),e(Qq,Tbo),e(Ks,Mbo),e(k,Ebo),e(k,Zs),e(Zs,Fce),e(Fce,Cbo),e(Zs,wbo),e(Zs,Hq),e(Hq,Abo),e(Zs,Lbo),e(Zs,Uq),e(Uq,ybo),e(Zs,xbo),e(k,$bo),e(k,el),e(el,Tce),e(Tce,kbo),e(el,Sbo),e(el,Jq),e(Jq,Rbo),e(el,Pbo),e(el,Yq),e(Yq,Bbo),e(el,Ibo),e(kr,Nbo),M(Qh,kr,null),e(xo,qbo),e(xo,Hh),M(ly,Hh,null),e(Hh,jbo),e(Hh,Mce),e(Mce,Dbo),b(f,KWe,u),b(f,Qi,u),e(Qi,Uh),e(Uh,Ece),M(iy,Ece,null),e(Qi,Gbo),e(Qi,Cce),e(Cce,Obo),b(f,ZWe,u),b(f,$o,u),M(dy,$o,null),e($o,Vbo),e($o,cy),e(cy,Xbo),e(cy,Kq),e(Kq,zbo),e(cy,Wbo),e($o,Qbo),e($o,fy),e(fy,Hbo),e(fy,wce),e(wce,Ubo),e(fy,Jbo),e($o,Ybo),e($o,Ue),M(my,Ue,null),e(Ue,Kbo),e(Ue,Ace),e(Ace,Zbo),e(Ue,evo),e(Ue,ja),e(ja,ovo),e(ja,Lce),e(Lce,rvo),e(ja,tvo),e(ja,yce),e(yce,avo),e(ja,nvo),e(ja,xce),e(xce,svo),e(ja,lvo),e(Ue,ivo),e(Ue,H),e(H,Jh),e(Jh,$ce),e($ce,dvo),e(Jh,cvo),e(Jh,Zq),e(Zq,fvo),e(Jh,mvo),e(H,gvo),e(H,Yh),e(Yh,kce),e(kce,hvo),e(Yh,pvo),e(Yh,ej),e(ej,_vo),e(Yh,uvo),e(H,bvo),e(H,Kh),e(Kh,Sce),e(Sce,vvo),e(Kh,Fvo),e(Kh,oj),e(oj,Tvo),e(Kh,Mvo),e(H,Evo),e(H,Zh),e(Zh,Rce),e(Rce,Cvo),e(Zh,wvo),e(Zh,rj),e(rj,Avo),e(Zh,Lvo),e(H,yvo),e(H,ep),e(ep,Pce),e(Pce,xvo),e(ep,$vo),e(ep,tj),e(tj,kvo),e(ep,Svo),e(H,Rvo),e(H,op),e(op,Bce),e(Bce,Pvo),e(op,Bvo),e(op,aj),e(aj,Ivo),e(op,Nvo),e(H,qvo),e(H,rp),e(rp,Ice),e(Ice,jvo),e(rp,Dvo),e(rp,nj),e(nj,Gvo),e(rp,Ovo),e(H,Vvo),e(H,tp),e(tp,Nce),e(Nce,Xvo),e(tp,zvo),e(tp,sj),e(sj,Wvo),e(tp,Qvo),e(H,Hvo),e(H,ap),e(ap,qce),e(qce,Uvo),e(ap,Jvo),e(ap,lj),e(lj,Yvo),e(ap,Kvo),e(H,Zvo),e(H,np),e(np,jce),e(jce,e0o),e(np,o0o),e(np,ij),e(ij,r0o),e(np,t0o),e(H,a0o),e(H,sp),e(sp,Dce),e(Dce,n0o),e(sp,s0o),e(sp,dj),e(dj,l0o),e(sp,i0o),e(H,d0o),e(H,lp),e(lp,Gce),e(Gce,c0o),e(lp,f0o),e(lp,cj),e(cj,m0o),e(lp,g0o),e(H,h0o),e(H,ip),e(ip,Oce),e(Oce,p0o),e(ip,_0o),e(ip,fj),e(fj,u0o),e(ip,b0o),e(H,v0o),e(H,dp),e(dp,Vce),e(Vce,F0o),e(dp,T0o),e(dp,mj),e(mj,M0o),e(dp,E0o),e(H,C0o),e(H,cp),e(cp,Xce),e(Xce,w0o),e(cp,A0o),e(cp,gj),e(gj,L0o),e(cp,y0o),e(H,x0o),e(H,fp),e(fp,zce),e(zce,$0o),e(fp,k0o),e(fp,hj),e(hj,S0o),e(fp,R0o),e(H,P0o),e(H,mp),e(mp,Wce),e(Wce,B0o),e(mp,I0o),e(mp,pj),e(pj,N0o),e(mp,q0o),e(H,j0o),e(H,gp),e(gp,Qce),e(Qce,D0o),e(gp,G0o),e(gp,_j),e(_j,O0o),e(gp,V0o),e(H,X0o),e(H,hp),e(hp,Hce),e(Hce,z0o),e(hp,W0o),e(hp,uj),e(uj,Q0o),e(hp,H0o),e(H,U0o),e(H,pp),e(pp,Uce),e(Uce,J0o),e(pp,Y0o),e(pp,bj),e(bj,K0o),e(pp,Z0o),e(H,eFo),e(H,_p),e(_p,Jce),e(Jce,oFo),e(_p,rFo),e(_p,vj),e(vj,tFo),e(_p,aFo),e(H,nFo),e(H,up),e(up,Yce),e(Yce,sFo),e(up,lFo),e(up,Fj),e(Fj,iFo),e(up,dFo),e(H,cFo),e(H,bp),e(bp,Kce),e(Kce,fFo),e(bp,mFo),e(bp,Tj),e(Tj,gFo),e(bp,hFo),e(H,pFo),e(H,vp),e(vp,Zce),e(Zce,_Fo),e(vp,uFo),e(vp,Mj),e(Mj,bFo),e(vp,vFo),e(H,FFo),e(H,Fp),e(Fp,efe),e(efe,TFo),e(Fp,MFo),e(Fp,Ej),e(Ej,EFo),e(Fp,CFo),e(H,wFo),e(H,Tp),e(Tp,ofe),e(ofe,AFo),e(Tp,LFo),e(Tp,Cj),e(Cj,yFo),e(Tp,xFo),e(H,$Fo),e(H,Mp),e(Mp,rfe),e(rfe,kFo),e(Mp,SFo),e(Mp,wj),e(wj,RFo),e(Mp,PFo),e(H,BFo),e(H,Ep),e(Ep,tfe),e(tfe,IFo),e(Ep,NFo),e(Ep,Aj),e(Aj,qFo),e(Ep,jFo),e(H,DFo),e(H,Cp),e(Cp,afe),e(afe,GFo),e(Cp,OFo),e(Cp,Lj),e(Lj,VFo),e(Cp,XFo),e(H,zFo),e(H,wp),e(wp,nfe),e(nfe,WFo),e(wp,QFo),e(wp,yj),e(yj,HFo),e(wp,UFo),e(H,JFo),e(H,Ap),e(Ap,sfe),e(sfe,YFo),e(Ap,KFo),e(Ap,xj),e(xj,ZFo),e(Ap,eTo),e(H,oTo),e(H,Lp),e(Lp,lfe),e(lfe,rTo),e(Lp,tTo),e(Lp,$j),e($j,aTo),e(Lp,nTo),e(H,sTo),e(H,yp),e(yp,ife),e(ife,lTo),e(yp,iTo),e(yp,kj),e(kj,dTo),e(yp,cTo),e(H,fTo),e(H,xp),e(xp,dfe),e(dfe,mTo),e(xp,gTo),e(xp,Sj),e(Sj,hTo),e(xp,pTo),e(H,_To),e(H,$p),e($p,cfe),e(cfe,uTo),e($p,bTo),e($p,Rj),e(Rj,vTo),e($p,FTo),e(H,TTo),e(H,kp),e(kp,ffe),e(ffe,MTo),e(kp,ETo),e(kp,Pj),e(Pj,CTo),e(kp,wTo),e(H,ATo),e(H,Sp),e(Sp,mfe),e(mfe,LTo),e(Sp,yTo),e(Sp,Bj),e(Bj,xTo),e(Sp,$To),e(Ue,kTo),M(Rp,Ue,null),e(Ue,STo),M(Pp,Ue,null),e($o,RTo),e($o,Bp),M(gy,Bp,null),e(Bp,PTo),e(Bp,gfe),e(gfe,BTo),b(f,eQe,u),b(f,Hi,u),e(Hi,Ip),e(Ip,hfe),M(hy,hfe,null),e(Hi,ITo),e(Hi,pfe),e(pfe,NTo),b(f,oQe,u),b(f,ko,u),M(py,ko,null),e(ko,qTo),e(ko,_y),e(_y,jTo),e(_y,Ij),e(Ij,DTo),e(_y,GTo),e(ko,OTo),e(ko,uy),e(uy,VTo),e(uy,_fe),e(_fe,XTo),e(uy,zTo),e(ko,WTo),e(ko,Je),M(by,Je,null),e(Je,QTo),e(Je,ufe),e(ufe,HTo),e(Je,UTo),e(Je,Ui),e(Ui,JTo),e(Ui,bfe),e(bfe,YTo),e(Ui,KTo),e(Ui,vfe),e(vfe,ZTo),e(Ui,e8o),e(Je,o8o),e(Je,fe),e(fe,Np),e(Np,Ffe),e(Ffe,r8o),e(Np,t8o),e(Np,Nj),e(Nj,a8o),e(Np,n8o),e(fe,s8o),e(fe,qp),e(qp,Tfe),e(Tfe,l8o),e(qp,i8o),e(qp,qj),e(qj,d8o),e(qp,c8o),e(fe,f8o),e(fe,jp),e(jp,Mfe),e(Mfe,m8o),e(jp,g8o),e(jp,jj),e(jj,h8o),e(jp,p8o),e(fe,_8o),e(fe,Dp),e(Dp,Efe),e(Efe,u8o),e(Dp,b8o),e(Dp,Dj),e(Dj,v8o),e(Dp,F8o),e(fe,T8o),e(fe,Gp),e(Gp,Cfe),e(Cfe,M8o),e(Gp,E8o),e(Gp,Gj),e(Gj,C8o),e(Gp,w8o),e(fe,A8o),e(fe,Op),e(Op,wfe),e(wfe,L8o),e(Op,y8o),e(Op,Oj),e(Oj,x8o),e(Op,$8o),e(fe,k8o),e(fe,Vp),e(Vp,Afe),e(Afe,S8o),e(Vp,R8o),e(Vp,Vj),e(Vj,P8o),e(Vp,B8o),e(fe,I8o),e(fe,Xp),e(Xp,Lfe),e(Lfe,N8o),e(Xp,q8o),e(Xp,Xj),e(Xj,j8o),e(Xp,D8o),e(fe,G8o),e(fe,zp),e(zp,yfe),e(yfe,O8o),e(zp,V8o),e(zp,zj),e(zj,X8o),e(zp,z8o),e(fe,W8o),e(fe,Wp),e(Wp,xfe),e(xfe,Q8o),e(Wp,H8o),e(Wp,Wj),e(Wj,U8o),e(Wp,J8o),e(fe,Y8o),e(fe,Qp),e(Qp,$fe),e($fe,K8o),e(Qp,Z8o),e(Qp,Qj),e(Qj,eMo),e(Qp,oMo),e(fe,rMo),e(fe,Hp),e(Hp,kfe),e(kfe,tMo),e(Hp,aMo),e(Hp,Hj),e(Hj,nMo),e(Hp,sMo),e(fe,lMo),e(fe,Up),e(Up,Sfe),e(Sfe,iMo),e(Up,dMo),e(Up,Uj),e(Uj,cMo),e(Up,fMo),e(fe,mMo),e(fe,Jp),e(Jp,Rfe),e(Rfe,gMo),e(Jp,hMo),e(Jp,Jj),e(Jj,pMo),e(Jp,_Mo),e(fe,uMo),e(fe,Yp),e(Yp,Pfe),e(Pfe,bMo),e(Yp,vMo),e(Yp,Yj),e(Yj,FMo),e(Yp,TMo),e(fe,MMo),e(fe,Kp),e(Kp,Bfe),e(Bfe,EMo),e(Kp,CMo),e(Kp,Kj),e(Kj,wMo),e(Kp,AMo),e(fe,LMo),e(fe,Zp),e(Zp,Ife),e(Ife,yMo),e(Zp,xMo),e(Zp,Zj),e(Zj,$Mo),e(Zp,kMo),e(fe,SMo),e(fe,e_),e(e_,Nfe),e(Nfe,RMo),e(e_,PMo),e(e_,eD),e(eD,BMo),e(e_,IMo),e(fe,NMo),e(fe,o_),e(o_,qfe),e(qfe,qMo),e(o_,jMo),e(o_,oD),e(oD,DMo),e(o_,GMo),e(Je,OMo),M(r_,Je,null),e(Je,VMo),M(t_,Je,null),e(ko,XMo),e(ko,a_),M(vy,a_,null),e(a_,zMo),e(a_,jfe),e(jfe,WMo),b(f,rQe,u),b(f,Ji,u),e(Ji,n_),e(n_,Dfe),M(Fy,Dfe,null),e(Ji,QMo),e(Ji,Gfe),e(Gfe,HMo),b(f,tQe,u),b(f,So,u),M(Ty,So,null),e(So,UMo),e(So,Yi),e(Yi,JMo),e(Yi,rD),e(rD,YMo),e(Yi,KMo),e(Yi,tD),e(tD,ZMo),e(Yi,eEo),e(So,oEo),e(So,My),e(My,rEo),e(My,Ofe),e(Ofe,tEo),e(My,aEo),e(So,nEo),e(So,ct),M(Ey,ct,null),e(ct,sEo),e(ct,Vfe),e(Vfe,lEo),e(ct,iEo),e(ct,Ki),e(Ki,dEo),e(Ki,Xfe),e(Xfe,cEo),e(Ki,fEo),e(Ki,aD),e(aD,mEo),e(Ki,gEo),e(ct,hEo),M(s_,ct,null),e(So,pEo),e(So,Ye),M(Cy,Ye,null),e(Ye,_Eo),e(Ye,zfe),e(zfe,uEo),e(Ye,bEo),e(Ye,Da),e(Da,vEo),e(Da,Wfe),e(Wfe,FEo),e(Da,TEo),e(Da,Qfe),e(Qfe,MEo),e(Da,EEo),e(Da,Hfe),e(Hfe,CEo),e(Da,wEo),e(Ye,AEo),e(Ye,y),e(y,l_),e(l_,Ufe),e(Ufe,LEo),e(l_,yEo),e(l_,nD),e(nD,xEo),e(l_,$Eo),e(y,kEo),e(y,i_),e(i_,Jfe),e(Jfe,SEo),e(i_,REo),e(i_,sD),e(sD,PEo),e(i_,BEo),e(y,IEo),e(y,d_),e(d_,Yfe),e(Yfe,NEo),e(d_,qEo),e(d_,lD),e(lD,jEo),e(d_,DEo),e(y,GEo),e(y,c_),e(c_,Kfe),e(Kfe,OEo),e(c_,VEo),e(c_,iD),e(iD,XEo),e(c_,zEo),e(y,WEo),e(y,f_),e(f_,Zfe),e(Zfe,QEo),e(f_,HEo),e(f_,dD),e(dD,UEo),e(f_,JEo),e(y,YEo),e(y,m_),e(m_,eme),e(eme,KEo),e(m_,ZEo),e(m_,cD),e(cD,e4o),e(m_,o4o),e(y,r4o),e(y,g_),e(g_,ome),e(ome,t4o),e(g_,a4o),e(g_,fD),e(fD,n4o),e(g_,s4o),e(y,l4o),e(y,h_),e(h_,rme),e(rme,i4o),e(h_,d4o),e(h_,mD),e(mD,c4o),e(h_,f4o),e(y,m4o),e(y,p_),e(p_,tme),e(tme,g4o),e(p_,h4o),e(p_,gD),e(gD,p4o),e(p_,_4o),e(y,u4o),e(y,__),e(__,ame),e(ame,b4o),e(__,v4o),e(__,hD),e(hD,F4o),e(__,T4o),e(y,M4o),e(y,u_),e(u_,nme),e(nme,E4o),e(u_,C4o),e(u_,pD),e(pD,w4o),e(u_,A4o),e(y,L4o),e(y,b_),e(b_,sme),e(sme,y4o),e(b_,x4o),e(b_,_D),e(_D,$4o),e(b_,k4o),e(y,S4o),e(y,v_),e(v_,lme),e(lme,R4o),e(v_,P4o),e(v_,uD),e(uD,B4o),e(v_,I4o),e(y,N4o),e(y,F_),e(F_,ime),e(ime,q4o),e(F_,j4o),e(F_,bD),e(bD,D4o),e(F_,G4o),e(y,O4o),e(y,T_),e(T_,dme),e(dme,V4o),e(T_,X4o),e(T_,vD),e(vD,z4o),e(T_,W4o),e(y,Q4o),e(y,M_),e(M_,cme),e(cme,H4o),e(M_,U4o),e(M_,FD),e(FD,J4o),e(M_,Y4o),e(y,K4o),e(y,E_),e(E_,fme),e(fme,Z4o),e(E_,eCo),e(E_,TD),e(TD,oCo),e(E_,rCo),e(y,tCo),e(y,C_),e(C_,mme),e(mme,aCo),e(C_,nCo),e(C_,MD),e(MD,sCo),e(C_,lCo),e(y,iCo),e(y,w_),e(w_,gme),e(gme,dCo),e(w_,cCo),e(w_,ED),e(ED,fCo),e(w_,mCo),e(y,gCo),e(y,A_),e(A_,hme),e(hme,hCo),e(A_,pCo),e(A_,CD),e(CD,_Co),e(A_,uCo),e(y,bCo),e(y,L_),e(L_,pme),e(pme,vCo),e(L_,FCo),e(L_,wD),e(wD,TCo),e(L_,MCo),e(y,ECo),e(y,y_),e(y_,_me),e(_me,CCo),e(y_,wCo),e(y_,AD),e(AD,ACo),e(y_,LCo),e(y,yCo),e(y,x_),e(x_,ume),e(ume,xCo),e(x_,$Co),e(x_,LD),e(LD,kCo),e(x_,SCo),e(y,RCo),e(y,$_),e($_,bme),e(bme,PCo),e($_,BCo),e($_,yD),e(yD,ICo),e($_,NCo),e(y,qCo),e(y,k_),e(k_,vme),e(vme,jCo),e(k_,DCo),e(k_,xD),e(xD,GCo),e(k_,OCo),e(y,VCo),e(y,S_),e(S_,Fme),e(Fme,XCo),e(S_,zCo),e(S_,$D),e($D,WCo),e(S_,QCo),e(y,HCo),e(y,R_),e(R_,Tme),e(Tme,UCo),e(R_,JCo),e(R_,kD),e(kD,YCo),e(R_,KCo),e(y,ZCo),e(y,P_),e(P_,Mme),e(Mme,e5o),e(P_,o5o),e(P_,SD),e(SD,r5o),e(P_,t5o),e(y,a5o),e(y,B_),e(B_,Eme),e(Eme,n5o),e(B_,s5o),e(B_,RD),e(RD,l5o),e(B_,i5o),e(y,d5o),e(y,I_),e(I_,Cme),e(Cme,c5o),e(I_,f5o),e(I_,PD),e(PD,m5o),e(I_,g5o),e(y,h5o),e(y,N_),e(N_,wme),e(wme,p5o),e(N_,_5o),e(N_,BD),e(BD,u5o),e(N_,b5o),e(y,v5o),e(y,q_),e(q_,Ame),e(Ame,F5o),e(q_,T5o),e(q_,ID),e(ID,M5o),e(q_,E5o),e(y,C5o),e(y,j_),e(j_,Lme),e(Lme,w5o),e(j_,A5o),e(j_,ND),e(ND,L5o),e(j_,y5o),e(y,x5o),e(y,D_),e(D_,yme),e(yme,$5o),e(D_,k5o),e(D_,qD),e(qD,S5o),e(D_,R5o),e(y,P5o),e(y,ol),e(ol,xme),e(xme,B5o),e(ol,I5o),e(ol,jD),e(jD,N5o),e(ol,q5o),e(ol,DD),e(DD,j5o),e(ol,D5o),e(y,G5o),e(y,G_),e(G_,$me),e($me,O5o),e(G_,V5o),e(G_,GD),e(GD,X5o),e(G_,z5o),e(y,W5o),e(y,O_),e(O_,kme),e(kme,Q5o),e(O_,H5o),e(O_,OD),e(OD,U5o),e(O_,J5o),e(y,Y5o),e(y,V_),e(V_,Sme),e(Sme,K5o),e(V_,Z5o),e(V_,VD),e(VD,e3o),e(V_,o3o),e(y,r3o),e(y,X_),e(X_,Rme),e(Rme,t3o),e(X_,a3o),e(X_,XD),e(XD,n3o),e(X_,s3o),e(y,l3o),e(y,z_),e(z_,Pme),e(Pme,i3o),e(z_,d3o),e(z_,zD),e(zD,c3o),e(z_,f3o),e(y,m3o),e(y,W_),e(W_,Bme),e(Bme,g3o),e(W_,h3o),e(W_,WD),e(WD,p3o),e(W_,_3o),e(y,u3o),e(y,Q_),e(Q_,Ime),e(Ime,b3o),e(Q_,v3o),e(Q_,QD),e(QD,F3o),e(Q_,T3o),e(y,M3o),e(y,H_),e(H_,Nme),e(Nme,E3o),e(H_,C3o),e(H_,HD),e(HD,w3o),e(H_,A3o),e(y,L3o),e(y,U_),e(U_,qme),e(qme,y3o),e(U_,x3o),e(U_,UD),e(UD,$3o),e(U_,k3o),e(y,S3o),e(y,J_),e(J_,jme),e(jme,R3o),e(J_,P3o),e(J_,JD),e(JD,B3o),e(J_,I3o),e(y,N3o),e(y,Y_),e(Y_,Dme),e(Dme,q3o),e(Y_,j3o),e(Y_,YD),e(YD,D3o),e(Y_,G3o),e(y,O3o),e(y,K_),e(K_,Gme),e(Gme,V3o),e(K_,X3o),e(K_,KD),e(KD,z3o),e(K_,W3o),e(y,Q3o),e(y,Z_),e(Z_,Ome),e(Ome,H3o),e(Z_,U3o),e(Z_,ZD),e(ZD,J3o),e(Z_,Y3o),e(y,K3o),e(y,eu),e(eu,Vme),e(Vme,Z3o),e(eu,ewo),e(eu,eG),e(eG,owo),e(eu,rwo),e(y,two),e(y,ou),e(ou,Xme),e(Xme,awo),e(ou,nwo),e(ou,oG),e(oG,swo),e(ou,lwo),e(y,iwo),e(y,ru),e(ru,zme),e(zme,dwo),e(ru,cwo),e(ru,rG),e(rG,fwo),e(ru,mwo),e(y,gwo),e(y,tu),e(tu,Wme),e(Wme,hwo),e(tu,pwo),e(tu,tG),e(tG,_wo),e(tu,uwo),e(y,bwo),e(y,au),e(au,Qme),e(Qme,vwo),e(au,Fwo),e(au,aG),e(aG,Two),e(au,Mwo),e(y,Ewo),e(y,nu),e(nu,Hme),e(Hme,Cwo),e(nu,wwo),e(nu,nG),e(nG,Awo),e(nu,Lwo),e(y,ywo),e(y,su),e(su,Ume),e(Ume,xwo),e(su,$wo),e(su,sG),e(sG,kwo),e(su,Swo),e(y,Rwo),e(y,lu),e(lu,Jme),e(Jme,Pwo),e(lu,Bwo),e(lu,lG),e(lG,Iwo),e(lu,Nwo),e(y,qwo),e(y,iu),e(iu,Yme),e(Yme,jwo),e(iu,Dwo),e(iu,iG),e(iG,Gwo),e(iu,Owo),e(y,Vwo),e(y,du),e(du,Kme),e(Kme,Xwo),e(du,zwo),e(du,dG),e(dG,Wwo),e(du,Qwo),e(y,Hwo),e(y,cu),e(cu,Zme),e(Zme,Uwo),e(cu,Jwo),e(cu,cG),e(cG,Ywo),e(cu,Kwo),e(y,Zwo),e(y,fu),e(fu,ege),e(ege,e6o),e(fu,o6o),e(fu,fG),e(fG,r6o),e(fu,t6o),e(y,a6o),e(y,mu),e(mu,oge),e(oge,n6o),e(mu,s6o),e(mu,mG),e(mG,l6o),e(mu,i6o),e(y,d6o),e(y,gu),e(gu,rge),e(rge,c6o),e(gu,f6o),e(gu,gG),e(gG,m6o),e(gu,g6o),e(y,h6o),e(y,hu),e(hu,tge),e(tge,p6o),e(hu,_6o),e(hu,hG),e(hG,u6o),e(hu,b6o),e(y,v6o),e(y,pu),e(pu,age),e(age,F6o),e(pu,T6o),e(pu,pG),e(pG,M6o),e(pu,E6o),e(y,C6o),e(y,_u),e(_u,nge),e(nge,w6o),e(_u,A6o),e(_u,_G),e(_G,L6o),e(_u,y6o),e(y,x6o),e(y,uu),e(uu,sge),e(sge,$6o),e(uu,k6o),e(uu,uG),e(uG,S6o),e(uu,R6o),e(y,P6o),e(y,bu),e(bu,lge),e(lge,B6o),e(bu,I6o),e(bu,bG),e(bG,N6o),e(bu,q6o),e(y,j6o),e(y,vu),e(vu,ige),e(ige,D6o),e(vu,G6o),e(vu,vG),e(vG,O6o),e(vu,V6o),e(y,X6o),e(y,Fu),e(Fu,dge),e(dge,z6o),e(Fu,W6o),e(Fu,FG),e(FG,Q6o),e(Fu,H6o),e(y,U6o),e(y,Tu),e(Tu,cge),e(cge,J6o),e(Tu,Y6o),e(Tu,TG),e(TG,K6o),e(Tu,Z6o),e(y,eAo),e(y,Mu),e(Mu,fge),e(fge,oAo),e(Mu,rAo),e(Mu,MG),e(MG,tAo),e(Mu,aAo),e(y,nAo),e(y,Eu),e(Eu,mge),e(mge,sAo),e(Eu,lAo),e(Eu,EG),e(EG,iAo),e(Eu,dAo),e(y,cAo),e(y,Cu),e(Cu,gge),e(gge,fAo),e(Cu,mAo),e(Cu,CG),e(CG,gAo),e(Cu,hAo),e(y,pAo),e(y,wu),e(wu,hge),e(hge,_Ao),e(wu,uAo),e(wu,wG),e(wG,bAo),e(wu,vAo),e(y,FAo),e(y,Au),e(Au,pge),e(pge,TAo),e(Au,MAo),e(Au,AG),e(AG,EAo),e(Au,CAo),e(y,wAo),e(y,Lu),e(Lu,_ge),e(_ge,AAo),e(Lu,LAo),e(Lu,LG),e(LG,yAo),e(Lu,xAo),e(y,$Ao),e(y,yu),e(yu,uge),e(uge,kAo),e(yu,SAo),e(yu,yG),e(yG,RAo),e(yu,PAo),e(y,BAo),e(y,xu),e(xu,bge),e(bge,IAo),e(xu,NAo),e(xu,xG),e(xG,qAo),e(xu,jAo),e(y,DAo),e(y,$u),e($u,vge),e(vge,GAo),e($u,OAo),e($u,$G),e($G,VAo),e($u,XAo),e(y,zAo),e(y,ku),e(ku,Fge),e(Fge,WAo),e(ku,QAo),e(ku,kG),e(kG,HAo),e(ku,UAo),e(y,JAo),e(y,Su),e(Su,Tge),e(Tge,YAo),e(Su,KAo),e(Su,SG),e(SG,ZAo),e(Su,e7o),e(y,o7o),e(y,Ru),e(Ru,Mge),e(Mge,r7o),e(Ru,t7o),e(Ru,RG),e(RG,a7o),e(Ru,n7o),e(y,s7o),e(y,Pu),e(Pu,Ege),e(Ege,l7o),e(Pu,i7o),e(Pu,PG),e(PG,d7o),e(Pu,c7o),e(y,f7o),e(y,Bu),e(Bu,Cge),e(Cge,m7o),e(Bu,g7o),e(Bu,BG),e(BG,h7o),e(Bu,p7o),e(y,_7o),e(y,Iu),e(Iu,wge),e(wge,u7o),e(Iu,b7o),e(Iu,IG),e(IG,v7o),e(Iu,F7o),e(y,T7o),e(y,Nu),e(Nu,Age),e(Age,M7o),e(Nu,E7o),e(Nu,NG),e(NG,C7o),e(Nu,w7o),e(y,A7o),e(y,qu),e(qu,Lge),e(Lge,L7o),e(qu,y7o),e(qu,qG),e(qG,x7o),e(qu,$7o),e(y,k7o),e(y,ju),e(ju,yge),e(yge,S7o),e(ju,R7o),e(ju,jG),e(jG,P7o),e(ju,B7o),e(y,I7o),e(y,Du),e(Du,xge),e(xge,N7o),e(Du,q7o),e(Du,DG),e(DG,j7o),e(Du,D7o),e(y,G7o),e(y,Gu),e(Gu,$ge),e($ge,O7o),e(Gu,V7o),e(Gu,GG),e(GG,X7o),e(Gu,z7o),e(y,W7o),e(y,Ou),e(Ou,kge),e(kge,Q7o),e(Ou,H7o),e(Ou,OG),e(OG,U7o),e(Ou,J7o),e(y,Y7o),e(y,Vu),e(Vu,Sge),e(Sge,K7o),e(Vu,Z7o),e(Vu,VG),e(VG,eLo),e(Vu,oLo),e(y,rLo),e(y,Xu),e(Xu,Rge),e(Rge,tLo),e(Xu,aLo),e(Xu,XG),e(XG,nLo),e(Xu,sLo),e(y,lLo),e(y,zu),e(zu,Pge),e(Pge,iLo),e(zu,dLo),e(zu,zG),e(zG,cLo),e(zu,fLo),e(y,mLo),e(y,Wu),e(Wu,Bge),e(Bge,gLo),e(Wu,hLo),e(Wu,WG),e(WG,pLo),e(Wu,_Lo),e(y,uLo),e(y,Qu),e(Qu,Ige),e(Ige,bLo),e(Qu,vLo),e(Qu,QG),e(QG,FLo),e(Qu,TLo),e(y,MLo),e(y,Hu),e(Hu,Nge),e(Nge,ELo),e(Hu,CLo),e(Hu,HG),e(HG,wLo),e(Hu,ALo),e(y,LLo),e(y,Uu),e(Uu,qge),e(qge,yLo),e(Uu,xLo),e(Uu,UG),e(UG,$Lo),e(Uu,kLo),e(y,SLo),e(y,Ju),e(Ju,jge),e(jge,RLo),e(Ju,PLo),e(Ju,JG),e(JG,BLo),e(Ju,ILo),e(y,NLo),e(y,Yu),e(Yu,Dge),e(Dge,qLo),e(Yu,jLo),e(Yu,YG),e(YG,DLo),e(Yu,GLo),e(y,OLo),e(y,Ku),e(Ku,Gge),e(Gge,VLo),e(Ku,XLo),e(Ku,KG),e(KG,zLo),e(Ku,WLo),e(y,QLo),e(y,Zu),e(Zu,Oge),e(Oge,HLo),e(Zu,ULo),e(Zu,ZG),e(ZG,JLo),e(Zu,YLo),e(y,KLo),e(y,e2),e(e2,Vge),e(Vge,ZLo),e(e2,eyo),e(e2,eO),e(eO,oyo),e(e2,ryo),e(y,tyo),e(y,o2),e(o2,Xge),e(Xge,ayo),e(o2,nyo),e(o2,oO),e(oO,syo),e(o2,lyo),e(y,iyo),e(y,r2),e(r2,zge),e(zge,dyo),e(r2,cyo),e(r2,rO),e(rO,fyo),e(r2,myo),e(y,gyo),e(y,t2),e(t2,Wge),e(Wge,hyo),e(t2,pyo),e(t2,tO),e(tO,_yo),e(t2,uyo),e(y,byo),e(y,a2),e(a2,Qge),e(Qge,vyo),e(a2,Fyo),e(a2,aO),e(aO,Tyo),e(a2,Myo),e(y,Eyo),e(y,n2),e(n2,Hge),e(Hge,Cyo),e(n2,wyo),e(n2,nO),e(nO,Ayo),e(n2,Lyo),e(y,yyo),e(y,s2),e(s2,Uge),e(Uge,xyo),e(s2,$yo),e(s2,sO),e(sO,kyo),e(s2,Syo),e(y,Ryo),e(y,l2),e(l2,Jge),e(Jge,Pyo),e(l2,Byo),e(l2,lO),e(lO,Iyo),e(l2,Nyo),e(y,qyo),e(y,i2),e(i2,Yge),e(Yge,jyo),e(i2,Dyo),e(i2,iO),e(iO,Gyo),e(i2,Oyo),e(y,Vyo),e(y,d2),e(d2,Kge),e(Kge,Xyo),e(d2,zyo),e(d2,dO),e(dO,Wyo),e(d2,Qyo),e(y,Hyo),e(y,c2),e(c2,Zge),e(Zge,Uyo),e(c2,Jyo),e(c2,cO),e(cO,Yyo),e(c2,Kyo),e(y,Zyo),e(y,f2),e(f2,ehe),e(ehe,e9o),e(f2,o9o),e(f2,fO),e(fO,r9o),e(f2,t9o),e(y,a9o),e(y,m2),e(m2,ohe),e(ohe,n9o),e(m2,s9o),e(m2,mO),e(mO,l9o),e(m2,i9o),e(Ye,d9o),e(Ye,g2),e(g2,c9o),e(g2,rhe),e(rhe,f9o),e(g2,m9o),e(g2,the),e(the,g9o),e(Ye,h9o),M(h2,Ye,null),b(f,aQe,u),b(f,Zi,u),e(Zi,p2),e(p2,ahe),M(wy,ahe,null),e(Zi,p9o),e(Zi,nhe),e(nhe,_9o),b(f,nQe,u),b(f,Ro,u),M(Ay,Ro,null),e(Ro,u9o),e(Ro,ed),e(ed,b9o),e(ed,gO),e(gO,v9o),e(ed,F9o),e(ed,hO),e(hO,T9o),e(ed,M9o),e(Ro,E9o),e(Ro,Ly),e(Ly,C9o),e(Ly,she),e(she,w9o),e(Ly,A9o),e(Ro,L9o),e(Ro,ft),M(yy,ft,null),e(ft,y9o),e(ft,lhe),e(lhe,x9o),e(ft,$9o),e(ft,od),e(od,k9o),e(od,ihe),e(ihe,S9o),e(od,R9o),e(od,pO),e(pO,P9o),e(od,B9o),e(ft,I9o),M(_2,ft,null),e(Ro,N9o),e(Ro,Ke),M(xy,Ke,null),e(Ke,q9o),e(Ke,dhe),e(dhe,j9o),e(Ke,D9o),e(Ke,Ga),e(Ga,G9o),e(Ga,che),e(che,O9o),e(Ga,V9o),e(Ga,fhe),e(fhe,X9o),e(Ga,z9o),e(Ga,mhe),e(mhe,W9o),e(Ga,Q9o),e(Ke,H9o),e(Ke,G),e(G,u2),e(u2,ghe),e(ghe,U9o),e(u2,J9o),e(u2,_O),e(_O,Y9o),e(u2,K9o),e(G,Z9o),e(G,b2),e(b2,hhe),e(hhe,exo),e(b2,oxo),e(b2,uO),e(uO,rxo),e(b2,txo),e(G,axo),e(G,v2),e(v2,phe),e(phe,nxo),e(v2,sxo),e(v2,bO),e(bO,lxo),e(v2,ixo),e(G,dxo),e(G,F2),e(F2,_he),e(_he,cxo),e(F2,fxo),e(F2,vO),e(vO,mxo),e(F2,gxo),e(G,hxo),e(G,T2),e(T2,uhe),e(uhe,pxo),e(T2,_xo),e(T2,FO),e(FO,uxo),e(T2,bxo),e(G,vxo),e(G,M2),e(M2,bhe),e(bhe,Fxo),e(M2,Txo),e(M2,TO),e(TO,Mxo),e(M2,Exo),e(G,Cxo),e(G,E2),e(E2,vhe),e(vhe,wxo),e(E2,Axo),e(E2,MO),e(MO,Lxo),e(E2,yxo),e(G,xxo),e(G,C2),e(C2,Fhe),e(Fhe,$xo),e(C2,kxo),e(C2,EO),e(EO,Sxo),e(C2,Rxo),e(G,Pxo),e(G,w2),e(w2,The),e(The,Bxo),e(w2,Ixo),e(w2,CO),e(CO,Nxo),e(w2,qxo),e(G,jxo),e(G,A2),e(A2,Mhe),e(Mhe,Dxo),e(A2,Gxo),e(A2,wO),e(wO,Oxo),e(A2,Vxo),e(G,Xxo),e(G,L2),e(L2,Ehe),e(Ehe,zxo),e(L2,Wxo),e(L2,AO),e(AO,Qxo),e(L2,Hxo),e(G,Uxo),e(G,y2),e(y2,Che),e(Che,Jxo),e(y2,Yxo),e(y2,LO),e(LO,Kxo),e(y2,Zxo),e(G,e$o),e(G,x2),e(x2,whe),e(whe,o$o),e(x2,r$o),e(x2,yO),e(yO,t$o),e(x2,a$o),e(G,n$o),e(G,$2),e($2,Ahe),e(Ahe,s$o),e($2,l$o),e($2,xO),e(xO,i$o),e($2,d$o),e(G,c$o),e(G,k2),e(k2,Lhe),e(Lhe,f$o),e(k2,m$o),e(k2,$O),e($O,g$o),e(k2,h$o),e(G,p$o),e(G,S2),e(S2,yhe),e(yhe,_$o),e(S2,u$o),e(S2,kO),e(kO,b$o),e(S2,v$o),e(G,F$o),e(G,R2),e(R2,xhe),e(xhe,T$o),e(R2,M$o),e(R2,SO),e(SO,E$o),e(R2,C$o),e(G,w$o),e(G,P2),e(P2,$he),e($he,A$o),e(P2,L$o),e(P2,RO),e(RO,y$o),e(P2,x$o),e(G,$$o),e(G,B2),e(B2,khe),e(khe,k$o),e(B2,S$o),e(B2,PO),e(PO,R$o),e(B2,P$o),e(G,B$o),e(G,I2),e(I2,She),e(She,I$o),e(I2,N$o),e(I2,BO),e(BO,q$o),e(I2,j$o),e(G,D$o),e(G,N2),e(N2,Rhe),e(Rhe,G$o),e(N2,O$o),e(N2,IO),e(IO,V$o),e(N2,X$o),e(G,z$o),e(G,q2),e(q2,Phe),e(Phe,W$o),e(q2,Q$o),e(q2,NO),e(NO,H$o),e(q2,U$o),e(G,J$o),e(G,j2),e(j2,Bhe),e(Bhe,Y$o),e(j2,K$o),e(j2,qO),e(qO,Z$o),e(j2,eko),e(G,oko),e(G,D2),e(D2,Ihe),e(Ihe,rko),e(D2,tko),e(D2,jO),e(jO,ako),e(D2,nko),e(G,sko),e(G,G2),e(G2,Nhe),e(Nhe,lko),e(G2,iko),e(G2,DO),e(DO,dko),e(G2,cko),e(G,fko),e(G,O2),e(O2,qhe),e(qhe,mko),e(O2,gko),e(O2,GO),e(GO,hko),e(O2,pko),e(G,_ko),e(G,V2),e(V2,jhe),e(jhe,uko),e(V2,bko),e(V2,OO),e(OO,vko),e(V2,Fko),e(G,Tko),e(G,X2),e(X2,Dhe),e(Dhe,Mko),e(X2,Eko),e(X2,VO),e(VO,Cko),e(X2,wko),e(G,Ako),e(G,z2),e(z2,Ghe),e(Ghe,Lko),e(z2,yko),e(z2,XO),e(XO,xko),e(z2,$ko),e(G,kko),e(G,W2),e(W2,Ohe),e(Ohe,Sko),e(W2,Rko),e(W2,zO),e(zO,Pko),e(W2,Bko),e(G,Iko),e(G,Q2),e(Q2,Vhe),e(Vhe,Nko),e(Q2,qko),e(Q2,WO),e(WO,jko),e(Q2,Dko),e(G,Gko),e(G,H2),e(H2,Xhe),e(Xhe,Oko),e(H2,Vko),e(H2,QO),e(QO,Xko),e(H2,zko),e(G,Wko),e(G,U2),e(U2,zhe),e(zhe,Qko),e(U2,Hko),e(U2,HO),e(HO,Uko),e(U2,Jko),e(G,Yko),e(G,J2),e(J2,Whe),e(Whe,Kko),e(J2,Zko),e(J2,UO),e(UO,eSo),e(J2,oSo),e(G,rSo),e(G,Y2),e(Y2,Qhe),e(Qhe,tSo),e(Y2,aSo),e(Y2,JO),e(JO,nSo),e(Y2,sSo),e(G,lSo),e(G,K2),e(K2,Hhe),e(Hhe,iSo),e(K2,dSo),e(K2,YO),e(YO,cSo),e(K2,fSo),e(G,mSo),e(G,Z2),e(Z2,Uhe),e(Uhe,gSo),e(Z2,hSo),e(Z2,KO),e(KO,pSo),e(Z2,_So),e(G,uSo),e(G,e1),e(e1,Jhe),e(Jhe,bSo),e(e1,vSo),e(e1,ZO),e(ZO,FSo),e(e1,TSo),e(G,MSo),e(G,o1),e(o1,Yhe),e(Yhe,ESo),e(o1,CSo),e(o1,eV),e(eV,wSo),e(o1,ASo),e(G,LSo),e(G,r1),e(r1,Khe),e(Khe,ySo),e(r1,xSo),e(r1,oV),e(oV,$So),e(r1,kSo),e(G,SSo),e(G,t1),e(t1,Zhe),e(Zhe,RSo),e(t1,PSo),e(t1,rV),e(rV,BSo),e(t1,ISo),e(G,NSo),e(G,a1),e(a1,epe),e(epe,qSo),e(a1,jSo),e(a1,tV),e(tV,DSo),e(a1,GSo),e(G,OSo),e(G,n1),e(n1,ope),e(ope,VSo),e(n1,XSo),e(n1,aV),e(aV,zSo),e(n1,WSo),e(G,QSo),e(G,s1),e(s1,rpe),e(rpe,HSo),e(s1,USo),e(s1,nV),e(nV,JSo),e(s1,YSo),e(G,KSo),e(G,l1),e(l1,tpe),e(tpe,ZSo),e(l1,eRo),e(l1,sV),e(sV,oRo),e(l1,rRo),e(G,tRo),e(G,i1),e(i1,ape),e(ape,aRo),e(i1,nRo),e(i1,lV),e(lV,sRo),e(i1,lRo),e(G,iRo),e(G,d1),e(d1,npe),e(npe,dRo),e(d1,cRo),e(d1,iV),e(iV,fRo),e(d1,mRo),e(Ke,gRo),e(Ke,c1),e(c1,hRo),e(c1,spe),e(spe,pRo),e(c1,_Ro),e(c1,lpe),e(lpe,uRo),e(Ke,bRo),M(f1,Ke,null),b(f,sQe,u),b(f,rd,u),e(rd,m1),e(m1,ipe),M($y,ipe,null),e(rd,vRo),e(rd,dpe),e(dpe,FRo),b(f,lQe,u),b(f,Po,u),M(ky,Po,null),e(Po,TRo),e(Po,td),e(td,MRo),e(td,dV),e(dV,ERo),e(td,CRo),e(td,cV),e(cV,wRo),e(td,ARo),e(Po,LRo),e(Po,Sy),e(Sy,yRo),e(Sy,cpe),e(cpe,xRo),e(Sy,$Ro),e(Po,kRo),e(Po,mt),M(Ry,mt,null),e(mt,SRo),e(mt,fpe),e(fpe,RRo),e(mt,PRo),e(mt,ad),e(ad,BRo),e(ad,mpe),e(mpe,IRo),e(ad,NRo),e(ad,fV),e(fV,qRo),e(ad,jRo),e(mt,DRo),M(g1,mt,null),e(Po,GRo),e(Po,Ze),M(Py,Ze,null),e(Ze,ORo),e(Ze,gpe),e(gpe,VRo),e(Ze,XRo),e(Ze,Oa),e(Oa,zRo),e(Oa,hpe),e(hpe,WRo),e(Oa,QRo),e(Oa,ppe),e(ppe,HRo),e(Oa,URo),e(Oa,_pe),e(_pe,JRo),e(Oa,YRo),e(Ze,KRo),e(Ze,z),e(z,h1),e(h1,upe),e(upe,ZRo),e(h1,ePo),e(h1,mV),e(mV,oPo),e(h1,rPo),e(z,tPo),e(z,p1),e(p1,bpe),e(bpe,aPo),e(p1,nPo),e(p1,gV),e(gV,sPo),e(p1,lPo),e(z,iPo),e(z,_1),e(_1,vpe),e(vpe,dPo),e(_1,cPo),e(_1,hV),e(hV,fPo),e(_1,mPo),e(z,gPo),e(z,u1),e(u1,Fpe),e(Fpe,hPo),e(u1,pPo),e(u1,pV),e(pV,_Po),e(u1,uPo),e(z,bPo),e(z,b1),e(b1,Tpe),e(Tpe,vPo),e(b1,FPo),e(b1,_V),e(_V,TPo),e(b1,MPo),e(z,EPo),e(z,v1),e(v1,Mpe),e(Mpe,CPo),e(v1,wPo),e(v1,uV),e(uV,APo),e(v1,LPo),e(z,yPo),e(z,F1),e(F1,Epe),e(Epe,xPo),e(F1,$Po),e(F1,bV),e(bV,kPo),e(F1,SPo),e(z,RPo),e(z,T1),e(T1,Cpe),e(Cpe,PPo),e(T1,BPo),e(T1,vV),e(vV,IPo),e(T1,NPo),e(z,qPo),e(z,M1),e(M1,wpe),e(wpe,jPo),e(M1,DPo),e(M1,FV),e(FV,GPo),e(M1,OPo),e(z,VPo),e(z,E1),e(E1,Ape),e(Ape,XPo),e(E1,zPo),e(E1,TV),e(TV,WPo),e(E1,QPo),e(z,HPo),e(z,C1),e(C1,Lpe),e(Lpe,UPo),e(C1,JPo),e(C1,MV),e(MV,YPo),e(C1,KPo),e(z,ZPo),e(z,w1),e(w1,ype),e(ype,eBo),e(w1,oBo),e(w1,EV),e(EV,rBo),e(w1,tBo),e(z,aBo),e(z,A1),e(A1,xpe),e(xpe,nBo),e(A1,sBo),e(A1,CV),e(CV,lBo),e(A1,iBo),e(z,dBo),e(z,L1),e(L1,$pe),e($pe,cBo),e(L1,fBo),e(L1,wV),e(wV,mBo),e(L1,gBo),e(z,hBo),e(z,y1),e(y1,kpe),e(kpe,pBo),e(y1,_Bo),e(y1,AV),e(AV,uBo),e(y1,bBo),e(z,vBo),e(z,x1),e(x1,Spe),e(Spe,FBo),e(x1,TBo),e(x1,LV),e(LV,MBo),e(x1,EBo),e(z,CBo),e(z,$1),e($1,Rpe),e(Rpe,wBo),e($1,ABo),e($1,yV),e(yV,LBo),e($1,yBo),e(z,xBo),e(z,k1),e(k1,Ppe),e(Ppe,$Bo),e(k1,kBo),e(k1,xV),e(xV,SBo),e(k1,RBo),e(z,PBo),e(z,S1),e(S1,Bpe),e(Bpe,BBo),e(S1,IBo),e(S1,$V),e($V,NBo),e(S1,qBo),e(z,jBo),e(z,R1),e(R1,Ipe),e(Ipe,DBo),e(R1,GBo),e(R1,kV),e(kV,OBo),e(R1,VBo),e(z,XBo),e(z,P1),e(P1,Npe),e(Npe,zBo),e(P1,WBo),e(P1,SV),e(SV,QBo),e(P1,HBo),e(z,UBo),e(z,B1),e(B1,qpe),e(qpe,JBo),e(B1,YBo),e(B1,RV),e(RV,KBo),e(B1,ZBo),e(z,eIo),e(z,I1),e(I1,jpe),e(jpe,oIo),e(I1,rIo),e(I1,PV),e(PV,tIo),e(I1,aIo),e(z,nIo),e(z,N1),e(N1,Dpe),e(Dpe,sIo),e(N1,lIo),e(N1,BV),e(BV,iIo),e(N1,dIo),e(z,cIo),e(z,q1),e(q1,Gpe),e(Gpe,fIo),e(q1,mIo),e(q1,IV),e(IV,gIo),e(q1,hIo),e(z,pIo),e(z,j1),e(j1,Ope),e(Ope,_Io),e(j1,uIo),e(j1,NV),e(NV,bIo),e(j1,vIo),e(z,FIo),e(z,D1),e(D1,Vpe),e(Vpe,TIo),e(D1,MIo),e(D1,qV),e(qV,EIo),e(D1,CIo),e(z,wIo),e(z,G1),e(G1,Xpe),e(Xpe,AIo),e(G1,LIo),e(G1,jV),e(jV,yIo),e(G1,xIo),e(z,$Io),e(z,O1),e(O1,zpe),e(zpe,kIo),e(O1,SIo),e(O1,DV),e(DV,RIo),e(O1,PIo),e(z,BIo),e(z,V1),e(V1,Wpe),e(Wpe,IIo),e(V1,NIo),e(V1,GV),e(GV,qIo),e(V1,jIo),e(z,DIo),e(z,X1),e(X1,Qpe),e(Qpe,GIo),e(X1,OIo),e(X1,OV),e(OV,VIo),e(X1,XIo),e(z,zIo),e(z,z1),e(z1,Hpe),e(Hpe,WIo),e(z1,QIo),e(z1,VV),e(VV,HIo),e(z1,UIo),e(z,JIo),e(z,W1),e(W1,Upe),e(Upe,YIo),e(W1,KIo),e(W1,XV),e(XV,ZIo),e(W1,eNo),e(z,oNo),e(z,Q1),e(Q1,Jpe),e(Jpe,rNo),e(Q1,tNo),e(Q1,zV),e(zV,aNo),e(Q1,nNo),e(z,sNo),e(z,H1),e(H1,Ype),e(Ype,lNo),e(H1,iNo),e(H1,WV),e(WV,dNo),e(H1,cNo),e(z,fNo),e(z,U1),e(U1,Kpe),e(Kpe,mNo),e(U1,gNo),e(U1,QV),e(QV,hNo),e(U1,pNo),e(z,_No),e(z,J1),e(J1,Zpe),e(Zpe,uNo),e(J1,bNo),e(J1,HV),e(HV,vNo),e(J1,FNo),e(z,TNo),e(z,Y1),e(Y1,e_e),e(e_e,MNo),e(Y1,ENo),e(Y1,UV),e(UV,CNo),e(Y1,wNo),e(z,ANo),e(z,K1),e(K1,o_e),e(o_e,LNo),e(K1,yNo),e(K1,JV),e(JV,xNo),e(K1,$No),e(z,kNo),e(z,Z1),e(Z1,r_e),e(r_e,SNo),e(Z1,RNo),e(Z1,YV),e(YV,PNo),e(Z1,BNo),e(Ze,INo),e(Ze,eb),e(eb,NNo),e(eb,t_e),e(t_e,qNo),e(eb,jNo),e(eb,a_e),e(a_e,DNo),e(Ze,GNo),M(ob,Ze,null),b(f,iQe,u),b(f,nd,u),e(nd,rb),e(rb,n_e),M(By,n_e,null),e(nd,ONo),e(nd,s_e),e(s_e,VNo),b(f,dQe,u),b(f,Bo,u),M(Iy,Bo,null),e(Bo,XNo),e(Bo,sd),e(sd,zNo),e(sd,KV),e(KV,WNo),e(sd,QNo),e(sd,ZV),e(ZV,HNo),e(sd,UNo),e(Bo,JNo),e(Bo,Ny),e(Ny,YNo),e(Ny,l_e),e(l_e,KNo),e(Ny,ZNo),e(Bo,eqo),e(Bo,gt),M(qy,gt,null),e(gt,oqo),e(gt,i_e),e(i_e,rqo),e(gt,tqo),e(gt,ld),e(ld,aqo),e(ld,d_e),e(d_e,nqo),e(ld,sqo),e(ld,eX),e(eX,lqo),e(ld,iqo),e(gt,dqo),M(tb,gt,null),e(Bo,cqo),e(Bo,eo),M(jy,eo,null),e(eo,fqo),e(eo,c_e),e(c_e,mqo),e(eo,gqo),e(eo,Va),e(Va,hqo),e(Va,f_e),e(f_e,pqo),e(Va,_qo),e(Va,m_e),e(m_e,uqo),e(Va,bqo),e(Va,g_e),e(g_e,vqo),e(Va,Fqo),e(eo,Tqo),e(eo,Q),e(Q,ab),e(ab,h_e),e(h_e,Mqo),e(ab,Eqo),e(ab,oX),e(oX,Cqo),e(ab,wqo),e(Q,Aqo),e(Q,nb),e(nb,p_e),e(p_e,Lqo),e(nb,yqo),e(nb,rX),e(rX,xqo),e(nb,$qo),e(Q,kqo),e(Q,sb),e(sb,__e),e(__e,Sqo),e(sb,Rqo),e(sb,tX),e(tX,Pqo),e(sb,Bqo),e(Q,Iqo),e(Q,lb),e(lb,u_e),e(u_e,Nqo),e(lb,qqo),e(lb,aX),e(aX,jqo),e(lb,Dqo),e(Q,Gqo),e(Q,ib),e(ib,b_e),e(b_e,Oqo),e(ib,Vqo),e(ib,nX),e(nX,Xqo),e(ib,zqo),e(Q,Wqo),e(Q,db),e(db,v_e),e(v_e,Qqo),e(db,Hqo),e(db,sX),e(sX,Uqo),e(db,Jqo),e(Q,Yqo),e(Q,cb),e(cb,F_e),e(F_e,Kqo),e(cb,Zqo),e(cb,lX),e(lX,ejo),e(cb,ojo),e(Q,rjo),e(Q,fb),e(fb,T_e),e(T_e,tjo),e(fb,ajo),e(fb,iX),e(iX,njo),e(fb,sjo),e(Q,ljo),e(Q,mb),e(mb,M_e),e(M_e,ijo),e(mb,djo),e(mb,dX),e(dX,cjo),e(mb,fjo),e(Q,mjo),e(Q,gb),e(gb,E_e),e(E_e,gjo),e(gb,hjo),e(gb,cX),e(cX,pjo),e(gb,_jo),e(Q,ujo),e(Q,hb),e(hb,C_e),e(C_e,bjo),e(hb,vjo),e(hb,fX),e(fX,Fjo),e(hb,Tjo),e(Q,Mjo),e(Q,pb),e(pb,w_e),e(w_e,Ejo),e(pb,Cjo),e(pb,mX),e(mX,wjo),e(pb,Ajo),e(Q,Ljo),e(Q,_b),e(_b,A_e),e(A_e,yjo),e(_b,xjo),e(_b,gX),e(gX,$jo),e(_b,kjo),e(Q,Sjo),e(Q,ub),e(ub,L_e),e(L_e,Rjo),e(ub,Pjo),e(ub,hX),e(hX,Bjo),e(ub,Ijo),e(Q,Njo),e(Q,bb),e(bb,y_e),e(y_e,qjo),e(bb,jjo),e(bb,pX),e(pX,Djo),e(bb,Gjo),e(Q,Ojo),e(Q,vb),e(vb,x_e),e(x_e,Vjo),e(vb,Xjo),e(vb,_X),e(_X,zjo),e(vb,Wjo),e(Q,Qjo),e(Q,Fb),e(Fb,$_e),e($_e,Hjo),e(Fb,Ujo),e(Fb,uX),e(uX,Jjo),e(Fb,Yjo),e(Q,Kjo),e(Q,Tb),e(Tb,k_e),e(k_e,Zjo),e(Tb,eDo),e(Tb,bX),e(bX,oDo),e(Tb,rDo),e(Q,tDo),e(Q,Mb),e(Mb,S_e),e(S_e,aDo),e(Mb,nDo),e(Mb,vX),e(vX,sDo),e(Mb,lDo),e(Q,iDo),e(Q,Eb),e(Eb,R_e),e(R_e,dDo),e(Eb,cDo),e(Eb,FX),e(FX,fDo),e(Eb,mDo),e(Q,gDo),e(Q,Cb),e(Cb,P_e),e(P_e,hDo),e(Cb,pDo),e(Cb,TX),e(TX,_Do),e(Cb,uDo),e(Q,bDo),e(Q,wb),e(wb,B_e),e(B_e,vDo),e(wb,FDo),e(wb,MX),e(MX,TDo),e(wb,MDo),e(Q,EDo),e(Q,Ab),e(Ab,I_e),e(I_e,CDo),e(Ab,wDo),e(Ab,EX),e(EX,ADo),e(Ab,LDo),e(Q,yDo),e(Q,Lb),e(Lb,N_e),e(N_e,xDo),e(Lb,$Do),e(Lb,CX),e(CX,kDo),e(Lb,SDo),e(Q,RDo),e(Q,yb),e(yb,q_e),e(q_e,PDo),e(yb,BDo),e(yb,wX),e(wX,IDo),e(yb,NDo),e(Q,qDo),e(Q,xb),e(xb,j_e),e(j_e,jDo),e(xb,DDo),e(xb,AX),e(AX,GDo),e(xb,ODo),e(Q,VDo),e(Q,$b),e($b,D_e),e(D_e,XDo),e($b,zDo),e($b,LX),e(LX,WDo),e($b,QDo),e(Q,HDo),e(Q,kb),e(kb,G_e),e(G_e,UDo),e(kb,JDo),e(kb,yX),e(yX,YDo),e(kb,KDo),e(Q,ZDo),e(Q,Sb),e(Sb,O_e),e(O_e,eGo),e(Sb,oGo),e(Sb,xX),e(xX,rGo),e(Sb,tGo),e(Q,aGo),e(Q,Rb),e(Rb,V_e),e(V_e,nGo),e(Rb,sGo),e(Rb,$X),e($X,lGo),e(Rb,iGo),e(Q,dGo),e(Q,Pb),e(Pb,X_e),e(X_e,cGo),e(Pb,fGo),e(Pb,kX),e(kX,mGo),e(Pb,gGo),e(Q,hGo),e(Q,Bb),e(Bb,z_e),e(z_e,pGo),e(Bb,_Go),e(Bb,SX),e(SX,uGo),e(Bb,bGo),e(Q,vGo),e(Q,Ib),e(Ib,W_e),e(W_e,FGo),e(Ib,TGo),e(Ib,RX),e(RX,MGo),e(Ib,EGo),e(Q,CGo),e(Q,Nb),e(Nb,Q_e),e(Q_e,wGo),e(Nb,AGo),e(Nb,H_e),e(H_e,LGo),e(Nb,yGo),e(Q,xGo),e(Q,qb),e(qb,U_e),e(U_e,$Go),e(qb,kGo),e(qb,PX),e(PX,SGo),e(qb,RGo),e(Q,PGo),e(Q,jb),e(jb,J_e),e(J_e,BGo),e(jb,IGo),e(jb,BX),e(BX,NGo),e(jb,qGo),e(Q,jGo),e(Q,Db),e(Db,Y_e),e(Y_e,DGo),e(Db,GGo),e(Db,IX),e(IX,OGo),e(Db,VGo),e(Q,XGo),e(Q,Gb),e(Gb,K_e),e(K_e,zGo),e(Gb,WGo),e(Gb,NX),e(NX,QGo),e(Gb,HGo),e(eo,UGo),e(eo,Ob),e(Ob,JGo),e(Ob,Z_e),e(Z_e,YGo),e(Ob,KGo),e(Ob,eue),e(eue,ZGo),e(eo,eOo),M(Vb,eo,null),b(f,cQe,u),b(f,id,u),e(id,Xb),e(Xb,oue),M(Dy,oue,null),e(id,oOo),e(id,rue),e(rue,rOo),b(f,fQe,u),b(f,Io,u),M(Gy,Io,null),e(Io,tOo),e(Io,dd),e(dd,aOo),e(dd,qX),e(qX,nOo),e(dd,sOo),e(dd,jX),e(jX,lOo),e(dd,iOo),e(Io,dOo),e(Io,Oy),e(Oy,cOo),e(Oy,tue),e(tue,fOo),e(Oy,mOo),e(Io,gOo),e(Io,ht),M(Vy,ht,null),e(ht,hOo),e(ht,aue),e(aue,pOo),e(ht,_Oo),e(ht,cd),e(cd,uOo),e(cd,nue),e(nue,bOo),e(cd,vOo),e(cd,DX),e(DX,FOo),e(cd,TOo),e(ht,MOo),M(zb,ht,null),e(Io,EOo),e(Io,oo),M(Xy,oo,null),e(oo,COo),e(oo,sue),e(sue,wOo),e(oo,AOo),e(oo,Xa),e(Xa,LOo),e(Xa,lue),e(lue,yOo),e(Xa,xOo),e(Xa,iue),e(iue,$Oo),e(Xa,kOo),e(Xa,due),e(due,SOo),e(Xa,ROo),e(oo,POo),e(oo,me),e(me,Wb),e(Wb,cue),e(cue,BOo),e(Wb,IOo),e(Wb,GX),e(GX,NOo),e(Wb,qOo),e(me,jOo),e(me,Qb),e(Qb,fue),e(fue,DOo),e(Qb,GOo),e(Qb,OX),e(OX,OOo),e(Qb,VOo),e(me,XOo),e(me,Hb),e(Hb,mue),e(mue,zOo),e(Hb,WOo),e(Hb,VX),e(VX,QOo),e(Hb,HOo),e(me,UOo),e(me,Ub),e(Ub,gue),e(gue,JOo),e(Ub,YOo),e(Ub,XX),e(XX,KOo),e(Ub,ZOo),e(me,eVo),e(me,Jb),e(Jb,hue),e(hue,oVo),e(Jb,rVo),e(Jb,zX),e(zX,tVo),e(Jb,aVo),e(me,nVo),e(me,Yb),e(Yb,pue),e(pue,sVo),e(Yb,lVo),e(Yb,WX),e(WX,iVo),e(Yb,dVo),e(me,cVo),e(me,Kb),e(Kb,_ue),e(_ue,fVo),e(Kb,mVo),e(Kb,QX),e(QX,gVo),e(Kb,hVo),e(me,pVo),e(me,Zb),e(Zb,uue),e(uue,_Vo),e(Zb,uVo),e(Zb,HX),e(HX,bVo),e(Zb,vVo),e(me,FVo),e(me,ev),e(ev,bue),e(bue,TVo),e(ev,MVo),e(ev,UX),e(UX,EVo),e(ev,CVo),e(me,wVo),e(me,ov),e(ov,vue),e(vue,AVo),e(ov,LVo),e(ov,JX),e(JX,yVo),e(ov,xVo),e(me,$Vo),e(me,rv),e(rv,Fue),e(Fue,kVo),e(rv,SVo),e(rv,YX),e(YX,RVo),e(rv,PVo),e(me,BVo),e(me,tv),e(tv,Tue),e(Tue,IVo),e(tv,NVo),e(tv,KX),e(KX,qVo),e(tv,jVo),e(me,DVo),e(me,av),e(av,Mue),e(Mue,GVo),e(av,OVo),e(av,ZX),e(ZX,VVo),e(av,XVo),e(me,zVo),e(me,nv),e(nv,Eue),e(Eue,WVo),e(nv,QVo),e(nv,ez),e(ez,HVo),e(nv,UVo),e(me,JVo),e(me,sv),e(sv,Cue),e(Cue,YVo),e(sv,KVo),e(sv,oz),e(oz,ZVo),e(sv,eXo),e(me,oXo),e(me,lv),e(lv,wue),e(wue,rXo),e(lv,tXo),e(lv,rz),e(rz,aXo),e(lv,nXo),e(me,sXo),e(me,iv),e(iv,Aue),e(Aue,lXo),e(iv,iXo),e(iv,tz),e(tz,dXo),e(iv,cXo),e(me,fXo),e(me,dv),e(dv,Lue),e(Lue,mXo),e(dv,gXo),e(dv,az),e(az,hXo),e(dv,pXo),e(me,_Xo),e(me,cv),e(cv,yue),e(yue,uXo),e(cv,bXo),e(cv,nz),e(nz,vXo),e(cv,FXo),e(oo,TXo),e(oo,fv),e(fv,MXo),e(fv,xue),e(xue,EXo),e(fv,CXo),e(fv,$ue),e($ue,wXo),e(oo,AXo),M(mv,oo,null),b(f,mQe,u),b(f,fd,u),e(fd,gv),e(gv,kue),M(zy,kue,null),e(fd,LXo),e(fd,Sue),e(Sue,yXo),b(f,gQe,u),b(f,No,u),M(Wy,No,null),e(No,xXo),e(No,md),e(md,$Xo),e(md,sz),e(sz,kXo),e(md,SXo),e(md,lz),e(lz,RXo),e(md,PXo),e(No,BXo),e(No,Qy),e(Qy,IXo),e(Qy,Rue),e(Rue,NXo),e(Qy,qXo),e(No,jXo),e(No,pt),M(Hy,pt,null),e(pt,DXo),e(pt,Pue),e(Pue,GXo),e(pt,OXo),e(pt,gd),e(gd,VXo),e(gd,Bue),e(Bue,XXo),e(gd,zXo),e(gd,iz),e(iz,WXo),e(gd,QXo),e(pt,HXo),M(hv,pt,null),e(No,UXo),e(No,ro),M(Uy,ro,null),e(ro,JXo),e(ro,Iue),e(Iue,YXo),e(ro,KXo),e(ro,za),e(za,ZXo),e(za,Nue),e(Nue,ezo),e(za,ozo),e(za,que),e(que,rzo),e(za,tzo),e(za,jue),e(jue,azo),e(za,nzo),e(ro,szo),e(ro,B),e(B,pv),e(pv,Due),e(Due,lzo),e(pv,izo),e(pv,dz),e(dz,dzo),e(pv,czo),e(B,fzo),e(B,_v),e(_v,Gue),e(Gue,mzo),e(_v,gzo),e(_v,cz),e(cz,hzo),e(_v,pzo),e(B,_zo),e(B,uv),e(uv,Oue),e(Oue,uzo),e(uv,bzo),e(uv,fz),e(fz,vzo),e(uv,Fzo),e(B,Tzo),e(B,bv),e(bv,Vue),e(Vue,Mzo),e(bv,Ezo),e(bv,mz),e(mz,Czo),e(bv,wzo),e(B,Azo),e(B,vv),e(vv,Xue),e(Xue,Lzo),e(vv,yzo),e(vv,gz),e(gz,xzo),e(vv,$zo),e(B,kzo),e(B,Fv),e(Fv,zue),e(zue,Szo),e(Fv,Rzo),e(Fv,hz),e(hz,Pzo),e(Fv,Bzo),e(B,Izo),e(B,Tv),e(Tv,Wue),e(Wue,Nzo),e(Tv,qzo),e(Tv,pz),e(pz,jzo),e(Tv,Dzo),e(B,Gzo),e(B,Mv),e(Mv,Que),e(Que,Ozo),e(Mv,Vzo),e(Mv,_z),e(_z,Xzo),e(Mv,zzo),e(B,Wzo),e(B,Ev),e(Ev,Hue),e(Hue,Qzo),e(Ev,Hzo),e(Ev,uz),e(uz,Uzo),e(Ev,Jzo),e(B,Yzo),e(B,Cv),e(Cv,Uue),e(Uue,Kzo),e(Cv,Zzo),e(Cv,bz),e(bz,eWo),e(Cv,oWo),e(B,rWo),e(B,wv),e(wv,Jue),e(Jue,tWo),e(wv,aWo),e(wv,vz),e(vz,nWo),e(wv,sWo),e(B,lWo),e(B,Av),e(Av,Yue),e(Yue,iWo),e(Av,dWo),e(Av,Fz),e(Fz,cWo),e(Av,fWo),e(B,mWo),e(B,Lv),e(Lv,Kue),e(Kue,gWo),e(Lv,hWo),e(Lv,Tz),e(Tz,pWo),e(Lv,_Wo),e(B,uWo),e(B,yv),e(yv,Zue),e(Zue,bWo),e(yv,vWo),e(yv,Mz),e(Mz,FWo),e(yv,TWo),e(B,MWo),e(B,xv),e(xv,e2e),e(e2e,EWo),e(xv,CWo),e(xv,Ez),e(Ez,wWo),e(xv,AWo),e(B,LWo),e(B,$v),e($v,o2e),e(o2e,yWo),e($v,xWo),e($v,Cz),e(Cz,$Wo),e($v,kWo),e(B,SWo),e(B,kv),e(kv,r2e),e(r2e,RWo),e(kv,PWo),e(kv,wz),e(wz,BWo),e(kv,IWo),e(B,NWo),e(B,Sv),e(Sv,t2e),e(t2e,qWo),e(Sv,jWo),e(Sv,Az),e(Az,DWo),e(Sv,GWo),e(B,OWo),e(B,Rv),e(Rv,a2e),e(a2e,VWo),e(Rv,XWo),e(Rv,Lz),e(Lz,zWo),e(Rv,WWo),e(B,QWo),e(B,Pv),e(Pv,n2e),e(n2e,HWo),e(Pv,UWo),e(Pv,yz),e(yz,JWo),e(Pv,YWo),e(B,KWo),e(B,Bv),e(Bv,s2e),e(s2e,ZWo),e(Bv,eQo),e(Bv,xz),e(xz,oQo),e(Bv,rQo),e(B,tQo),e(B,Iv),e(Iv,l2e),e(l2e,aQo),e(Iv,nQo),e(Iv,$z),e($z,sQo),e(Iv,lQo),e(B,iQo),e(B,Nv),e(Nv,i2e),e(i2e,dQo),e(Nv,cQo),e(Nv,kz),e(kz,fQo),e(Nv,mQo),e(B,gQo),e(B,qv),e(qv,d2e),e(d2e,hQo),e(qv,pQo),e(qv,Sz),e(Sz,_Qo),e(qv,uQo),e(B,bQo),e(B,jv),e(jv,c2e),e(c2e,vQo),e(jv,FQo),e(jv,Rz),e(Rz,TQo),e(jv,MQo),e(B,EQo),e(B,Dv),e(Dv,f2e),e(f2e,CQo),e(Dv,wQo),e(Dv,Pz),e(Pz,AQo),e(Dv,LQo),e(B,yQo),e(B,Gv),e(Gv,m2e),e(m2e,xQo),e(Gv,$Qo),e(Gv,Bz),e(Bz,kQo),e(Gv,SQo),e(B,RQo),e(B,Ov),e(Ov,g2e),e(g2e,PQo),e(Ov,BQo),e(Ov,Iz),e(Iz,IQo),e(Ov,NQo),e(B,qQo),e(B,Vv),e(Vv,h2e),e(h2e,jQo),e(Vv,DQo),e(Vv,Nz),e(Nz,GQo),e(Vv,OQo),e(B,VQo),e(B,Xv),e(Xv,p2e),e(p2e,XQo),e(Xv,zQo),e(Xv,qz),e(qz,WQo),e(Xv,QQo),e(B,HQo),e(B,zv),e(zv,_2e),e(_2e,UQo),e(zv,JQo),e(zv,jz),e(jz,YQo),e(zv,KQo),e(B,ZQo),e(B,Wv),e(Wv,u2e),e(u2e,eHo),e(Wv,oHo),e(Wv,Dz),e(Dz,rHo),e(Wv,tHo),e(B,aHo),e(B,Qv),e(Qv,b2e),e(b2e,nHo),e(Qv,sHo),e(Qv,Gz),e(Gz,lHo),e(Qv,iHo),e(B,dHo),e(B,Hv),e(Hv,v2e),e(v2e,cHo),e(Hv,fHo),e(Hv,Oz),e(Oz,mHo),e(Hv,gHo),e(B,hHo),e(B,Uv),e(Uv,F2e),e(F2e,pHo),e(Uv,_Ho),e(Uv,Vz),e(Vz,uHo),e(Uv,bHo),e(B,vHo),e(B,Jv),e(Jv,T2e),e(T2e,FHo),e(Jv,THo),e(Jv,Xz),e(Xz,MHo),e(Jv,EHo),e(B,CHo),e(B,Yv),e(Yv,M2e),e(M2e,wHo),e(Yv,AHo),e(Yv,zz),e(zz,LHo),e(Yv,yHo),e(B,xHo),e(B,Kv),e(Kv,E2e),e(E2e,$Ho),e(Kv,kHo),e(Kv,Wz),e(Wz,SHo),e(Kv,RHo),e(B,PHo),e(B,Zv),e(Zv,C2e),e(C2e,BHo),e(Zv,IHo),e(Zv,Qz),e(Qz,NHo),e(Zv,qHo),e(B,jHo),e(B,e0),e(e0,w2e),e(w2e,DHo),e(e0,GHo),e(e0,Hz),e(Hz,OHo),e(e0,VHo),e(B,XHo),e(B,o0),e(o0,A2e),e(A2e,zHo),e(o0,WHo),e(o0,Uz),e(Uz,QHo),e(o0,HHo),e(B,UHo),e(B,r0),e(r0,L2e),e(L2e,JHo),e(r0,YHo),e(r0,Jz),e(Jz,KHo),e(r0,ZHo),e(B,eUo),e(B,t0),e(t0,y2e),e(y2e,oUo),e(t0,rUo),e(t0,Yz),e(Yz,tUo),e(t0,aUo),e(B,nUo),e(B,a0),e(a0,x2e),e(x2e,sUo),e(a0,lUo),e(a0,Kz),e(Kz,iUo),e(a0,dUo),e(B,cUo),e(B,n0),e(n0,$2e),e($2e,fUo),e(n0,mUo),e(n0,Zz),e(Zz,gUo),e(n0,hUo),e(B,pUo),e(B,s0),e(s0,k2e),e(k2e,_Uo),e(s0,uUo),e(s0,eW),e(eW,bUo),e(s0,vUo),e(B,FUo),e(B,l0),e(l0,S2e),e(S2e,TUo),e(l0,MUo),e(l0,oW),e(oW,EUo),e(l0,CUo),e(B,wUo),e(B,i0),e(i0,R2e),e(R2e,AUo),e(i0,LUo),e(i0,rW),e(rW,yUo),e(i0,xUo),e(B,$Uo),e(B,d0),e(d0,P2e),e(P2e,kUo),e(d0,SUo),e(d0,tW),e(tW,RUo),e(d0,PUo),e(B,BUo),e(B,c0),e(c0,B2e),e(B2e,IUo),e(c0,NUo),e(c0,aW),e(aW,qUo),e(c0,jUo),e(B,DUo),e(B,f0),e(f0,I2e),e(I2e,GUo),e(f0,OUo),e(f0,nW),e(nW,VUo),e(f0,XUo),e(B,zUo),e(B,m0),e(m0,N2e),e(N2e,WUo),e(m0,QUo),e(m0,sW),e(sW,HUo),e(m0,UUo),e(ro,JUo),e(ro,g0),e(g0,YUo),e(g0,q2e),e(q2e,KUo),e(g0,ZUo),e(g0,j2e),e(j2e,eJo),e(ro,oJo),M(h0,ro,null),b(f,hQe,u),b(f,hd,u),e(hd,p0),e(p0,D2e),M(Jy,D2e,null),e(hd,rJo),e(hd,G2e),e(G2e,tJo),b(f,pQe,u),b(f,qo,u),M(Yy,qo,null),e(qo,aJo),e(qo,pd),e(pd,nJo),e(pd,lW),e(lW,sJo),e(pd,lJo),e(pd,iW),e(iW,iJo),e(pd,dJo),e(qo,cJo),e(qo,Ky),e(Ky,fJo),e(Ky,O2e),e(O2e,mJo),e(Ky,gJo),e(qo,hJo),e(qo,_t),M(Zy,_t,null),e(_t,pJo),e(_t,V2e),e(V2e,_Jo),e(_t,uJo),e(_t,_d),e(_d,bJo),e(_d,X2e),e(X2e,vJo),e(_d,FJo),e(_d,dW),e(dW,TJo),e(_d,MJo),e(_t,EJo),M(_0,_t,null),e(qo,CJo),e(qo,to),M(e9,to,null),e(to,wJo),e(to,z2e),e(z2e,AJo),e(to,LJo),e(to,Wa),e(Wa,yJo),e(Wa,W2e),e(W2e,xJo),e(Wa,$Jo),e(Wa,Q2e),e(Q2e,kJo),e(Wa,SJo),e(Wa,H2e),e(H2e,RJo),e(Wa,PJo),e(to,BJo),e(to,Z),e(Z,u0),e(u0,U2e),e(U2e,IJo),e(u0,NJo),e(u0,cW),e(cW,qJo),e(u0,jJo),e(Z,DJo),e(Z,b0),e(b0,J2e),e(J2e,GJo),e(b0,OJo),e(b0,fW),e(fW,VJo),e(b0,XJo),e(Z,zJo),e(Z,v0),e(v0,Y2e),e(Y2e,WJo),e(v0,QJo),e(v0,mW),e(mW,HJo),e(v0,UJo),e(Z,JJo),e(Z,F0),e(F0,K2e),e(K2e,YJo),e(F0,KJo),e(F0,gW),e(gW,ZJo),e(F0,eYo),e(Z,oYo),e(Z,T0),e(T0,Z2e),e(Z2e,rYo),e(T0,tYo),e(T0,hW),e(hW,aYo),e(T0,nYo),e(Z,sYo),e(Z,M0),e(M0,e1e),e(e1e,lYo),e(M0,iYo),e(M0,pW),e(pW,dYo),e(M0,cYo),e(Z,fYo),e(Z,E0),e(E0,o1e),e(o1e,mYo),e(E0,gYo),e(E0,_W),e(_W,hYo),e(E0,pYo),e(Z,_Yo),e(Z,C0),e(C0,r1e),e(r1e,uYo),e(C0,bYo),e(C0,uW),e(uW,vYo),e(C0,FYo),e(Z,TYo),e(Z,w0),e(w0,t1e),e(t1e,MYo),e(w0,EYo),e(w0,bW),e(bW,CYo),e(w0,wYo),e(Z,AYo),e(Z,A0),e(A0,a1e),e(a1e,LYo),e(A0,yYo),e(A0,vW),e(vW,xYo),e(A0,$Yo),e(Z,kYo),e(Z,L0),e(L0,n1e),e(n1e,SYo),e(L0,RYo),e(L0,FW),e(FW,PYo),e(L0,BYo),e(Z,IYo),e(Z,y0),e(y0,s1e),e(s1e,NYo),e(y0,qYo),e(y0,TW),e(TW,jYo),e(y0,DYo),e(Z,GYo),e(Z,x0),e(x0,l1e),e(l1e,OYo),e(x0,VYo),e(x0,MW),e(MW,XYo),e(x0,zYo),e(Z,WYo),e(Z,$0),e($0,i1e),e(i1e,QYo),e($0,HYo),e($0,EW),e(EW,UYo),e($0,JYo),e(Z,YYo),e(Z,k0),e(k0,d1e),e(d1e,KYo),e(k0,ZYo),e(k0,CW),e(CW,eKo),e(k0,oKo),e(Z,rKo),e(Z,S0),e(S0,c1e),e(c1e,tKo),e(S0,aKo),e(S0,wW),e(wW,nKo),e(S0,sKo),e(Z,lKo),e(Z,R0),e(R0,f1e),e(f1e,iKo),e(R0,dKo),e(R0,AW),e(AW,cKo),e(R0,fKo),e(Z,mKo),e(Z,P0),e(P0,m1e),e(m1e,gKo),e(P0,hKo),e(P0,LW),e(LW,pKo),e(P0,_Ko),e(Z,uKo),e(Z,B0),e(B0,g1e),e(g1e,bKo),e(B0,vKo),e(B0,yW),e(yW,FKo),e(B0,TKo),e(Z,MKo),e(Z,I0),e(I0,h1e),e(h1e,EKo),e(I0,CKo),e(I0,xW),e(xW,wKo),e(I0,AKo),e(Z,LKo),e(Z,N0),e(N0,p1e),e(p1e,yKo),e(N0,xKo),e(N0,$W),e($W,$Ko),e(N0,kKo),e(Z,SKo),e(Z,q0),e(q0,_1e),e(_1e,RKo),e(q0,PKo),e(q0,kW),e(kW,BKo),e(q0,IKo),e(Z,NKo),e(Z,j0),e(j0,u1e),e(u1e,qKo),e(j0,jKo),e(j0,SW),e(SW,DKo),e(j0,GKo),e(Z,OKo),e(Z,D0),e(D0,b1e),e(b1e,VKo),e(D0,XKo),e(D0,RW),e(RW,zKo),e(D0,WKo),e(Z,QKo),e(Z,G0),e(G0,v1e),e(v1e,HKo),e(G0,UKo),e(G0,PW),e(PW,JKo),e(G0,YKo),e(Z,KKo),e(Z,O0),e(O0,F1e),e(F1e,ZKo),e(O0,eZo),e(O0,BW),e(BW,oZo),e(O0,rZo),e(Z,tZo),e(Z,V0),e(V0,T1e),e(T1e,aZo),e(V0,nZo),e(V0,IW),e(IW,sZo),e(V0,lZo),e(Z,iZo),e(Z,X0),e(X0,M1e),e(M1e,dZo),e(X0,cZo),e(X0,NW),e(NW,fZo),e(X0,mZo),e(Z,gZo),e(Z,z0),e(z0,E1e),e(E1e,hZo),e(z0,pZo),e(z0,qW),e(qW,_Zo),e(z0,uZo),e(Z,bZo),e(Z,W0),e(W0,C1e),e(C1e,vZo),e(W0,FZo),e(W0,jW),e(jW,TZo),e(W0,MZo),e(Z,EZo),e(Z,Q0),e(Q0,w1e),e(w1e,CZo),e(Q0,wZo),e(Q0,DW),e(DW,AZo),e(Q0,LZo),e(to,yZo),e(to,H0),e(H0,xZo),e(H0,A1e),e(A1e,$Zo),e(H0,kZo),e(H0,L1e),e(L1e,SZo),e(to,RZo),M(U0,to,null),b(f,_Qe,u),b(f,ud,u),e(ud,J0),e(J0,y1e),M(o9,y1e,null),e(ud,PZo),e(ud,x1e),e(x1e,BZo),b(f,uQe,u),b(f,jo,u),M(r9,jo,null),e(jo,IZo),e(jo,bd),e(bd,NZo),e(bd,GW),e(GW,qZo),e(bd,jZo),e(bd,OW),e(OW,DZo),e(bd,GZo),e(jo,OZo),e(jo,t9),e(t9,VZo),e(t9,$1e),e($1e,XZo),e(t9,zZo),e(jo,WZo),e(jo,ut),M(a9,ut,null),e(ut,QZo),e(ut,k1e),e(k1e,HZo),e(ut,UZo),e(ut,vd),e(vd,JZo),e(vd,S1e),e(S1e,YZo),e(vd,KZo),e(vd,VW),e(VW,ZZo),e(vd,eer),e(ut,oer),M(Y0,ut,null),e(jo,rer),e(jo,ao),M(n9,ao,null),e(ao,ter),e(ao,R1e),e(R1e,aer),e(ao,ner),e(ao,Qa),e(Qa,ser),e(Qa,P1e),e(P1e,ler),e(Qa,ier),e(Qa,B1e),e(B1e,der),e(Qa,cer),e(Qa,I1e),e(I1e,fer),e(Qa,mer),e(ao,ger),e(ao,Do),e(Do,K0),e(K0,N1e),e(N1e,her),e(K0,per),e(K0,XW),e(XW,_er),e(K0,uer),e(Do,ber),e(Do,Z0),e(Z0,q1e),e(q1e,ver),e(Z0,Fer),e(Z0,zW),e(zW,Ter),e(Z0,Mer),e(Do,Eer),e(Do,eF),e(eF,j1e),e(j1e,Cer),e(eF,wer),e(eF,WW),e(WW,Aer),e(eF,Ler),e(Do,yer),e(Do,oF),e(oF,D1e),e(D1e,xer),e(oF,$er),e(oF,QW),e(QW,ker),e(oF,Ser),e(Do,Rer),e(Do,rF),e(rF,G1e),e(G1e,Per),e(rF,Ber),e(rF,HW),e(HW,Ier),e(rF,Ner),e(Do,qer),e(Do,tF),e(tF,O1e),e(O1e,jer),e(tF,Der),e(tF,UW),e(UW,Ger),e(tF,Oer),e(ao,Ver),e(ao,aF),e(aF,Xer),e(aF,V1e),e(V1e,zer),e(aF,Wer),e(aF,X1e),e(X1e,Qer),e(ao,Her),M(nF,ao,null),b(f,bQe,u),b(f,Fd,u),e(Fd,sF),e(sF,z1e),M(s9,z1e,null),e(Fd,Uer),e(Fd,W1e),e(W1e,Jer),b(f,vQe,u),b(f,Go,u),M(l9,Go,null),e(Go,Yer),e(Go,Td),e(Td,Ker),e(Td,JW),e(JW,Zer),e(Td,eor),e(Td,YW),e(YW,oor),e(Td,ror),e(Go,tor),e(Go,i9),e(i9,aor),e(i9,Q1e),e(Q1e,nor),e(i9,sor),e(Go,lor),e(Go,bt),M(d9,bt,null),e(bt,ior),e(bt,H1e),e(H1e,dor),e(bt,cor),e(bt,Md),e(Md,mor),e(Md,U1e),e(U1e,gor),e(Md,hor),e(Md,KW),e(KW,por),e(Md,_or),e(bt,uor),M(lF,bt,null),e(Go,bor),e(Go,no),M(c9,no,null),e(no,vor),e(no,J1e),e(J1e,For),e(no,Tor),e(no,Ha),e(Ha,Mor),e(Ha,Y1e),e(Y1e,Eor),e(Ha,Cor),e(Ha,K1e),e(K1e,wor),e(Ha,Aor),e(Ha,Z1e),e(Z1e,Lor),e(Ha,yor),e(no,xor),e(no,U),e(U,iF),e(iF,ebe),e(ebe,$or),e(iF,kor),e(iF,ZW),e(ZW,Sor),e(iF,Ror),e(U,Por),e(U,dF),e(dF,obe),e(obe,Bor),e(dF,Ior),e(dF,eQ),e(eQ,Nor),e(dF,qor),e(U,jor),e(U,cF),e(cF,rbe),e(rbe,Dor),e(cF,Gor),e(cF,oQ),e(oQ,Oor),e(cF,Vor),e(U,Xor),e(U,fF),e(fF,tbe),e(tbe,zor),e(fF,Wor),e(fF,rQ),e(rQ,Qor),e(fF,Hor),e(U,Uor),e(U,mF),e(mF,abe),e(abe,Jor),e(mF,Yor),e(mF,tQ),e(tQ,Kor),e(mF,Zor),e(U,err),e(U,gF),e(gF,nbe),e(nbe,orr),e(gF,rrr),e(gF,aQ),e(aQ,trr),e(gF,arr),e(U,nrr),e(U,hF),e(hF,sbe),e(sbe,srr),e(hF,lrr),e(hF,nQ),e(nQ,irr),e(hF,drr),e(U,crr),e(U,pF),e(pF,lbe),e(lbe,frr),e(pF,mrr),e(pF,sQ),e(sQ,grr),e(pF,hrr),e(U,prr),e(U,_F),e(_F,ibe),e(ibe,_rr),e(_F,urr),e(_F,lQ),e(lQ,brr),e(_F,vrr),e(U,Frr),e(U,uF),e(uF,dbe),e(dbe,Trr),e(uF,Mrr),e(uF,iQ),e(iQ,Err),e(uF,Crr),e(U,wrr),e(U,bF),e(bF,cbe),e(cbe,Arr),e(bF,Lrr),e(bF,dQ),e(dQ,yrr),e(bF,xrr),e(U,$rr),e(U,vF),e(vF,fbe),e(fbe,krr),e(vF,Srr),e(vF,cQ),e(cQ,Rrr),e(vF,Prr),e(U,Brr),e(U,FF),e(FF,mbe),e(mbe,Irr),e(FF,Nrr),e(FF,fQ),e(fQ,qrr),e(FF,jrr),e(U,Drr),e(U,TF),e(TF,gbe),e(gbe,Grr),e(TF,Orr),e(TF,mQ),e(mQ,Vrr),e(TF,Xrr),e(U,zrr),e(U,MF),e(MF,hbe),e(hbe,Wrr),e(MF,Qrr),e(MF,gQ),e(gQ,Hrr),e(MF,Urr),e(U,Jrr),e(U,EF),e(EF,pbe),e(pbe,Yrr),e(EF,Krr),e(EF,hQ),e(hQ,Zrr),e(EF,etr),e(U,otr),e(U,CF),e(CF,_be),e(_be,rtr),e(CF,ttr),e(CF,pQ),e(pQ,atr),e(CF,ntr),e(U,str),e(U,wF),e(wF,ube),e(ube,ltr),e(wF,itr),e(wF,_Q),e(_Q,dtr),e(wF,ctr),e(U,ftr),e(U,AF),e(AF,bbe),e(bbe,mtr),e(AF,gtr),e(AF,uQ),e(uQ,htr),e(AF,ptr),e(U,_tr),e(U,LF),e(LF,vbe),e(vbe,utr),e(LF,btr),e(LF,bQ),e(bQ,vtr),e(LF,Ftr),e(U,Ttr),e(U,yF),e(yF,Fbe),e(Fbe,Mtr),e(yF,Etr),e(yF,vQ),e(vQ,Ctr),e(yF,wtr),e(U,Atr),e(U,xF),e(xF,Tbe),e(Tbe,Ltr),e(xF,ytr),e(xF,FQ),e(FQ,xtr),e(xF,$tr),e(U,ktr),e(U,$F),e($F,Mbe),e(Mbe,Str),e($F,Rtr),e($F,TQ),e(TQ,Ptr),e($F,Btr),e(U,Itr),e(U,kF),e(kF,Ebe),e(Ebe,Ntr),e(kF,qtr),e(kF,MQ),e(MQ,jtr),e(kF,Dtr),e(U,Gtr),e(U,SF),e(SF,Cbe),e(Cbe,Otr),e(SF,Vtr),e(SF,EQ),e(EQ,Xtr),e(SF,ztr),e(U,Wtr),e(U,RF),e(RF,wbe),e(wbe,Qtr),e(RF,Htr),e(RF,CQ),e(CQ,Utr),e(RF,Jtr),e(U,Ytr),e(U,PF),e(PF,Abe),e(Abe,Ktr),e(PF,Ztr),e(PF,wQ),e(wQ,ear),e(PF,oar),e(U,rar),e(U,BF),e(BF,Lbe),e(Lbe,tar),e(BF,aar),e(BF,AQ),e(AQ,nar),e(BF,sar),e(U,lar),e(U,IF),e(IF,ybe),e(ybe,iar),e(IF,dar),e(IF,LQ),e(LQ,car),e(IF,far),e(U,mar),e(U,NF),e(NF,xbe),e(xbe,gar),e(NF,har),e(NF,yQ),e(yQ,par),e(NF,_ar),e(U,uar),e(U,qF),e(qF,$be),e($be,bar),e(qF,Far),e(qF,xQ),e(xQ,Tar),e(qF,Mar),e(U,Ear),e(U,jF),e(jF,kbe),e(kbe,Car),e(jF,war),e(jF,$Q),e($Q,Aar),e(jF,Lar),e(U,yar),e(U,DF),e(DF,Sbe),e(Sbe,xar),e(DF,$ar),e(DF,kQ),e(kQ,kar),e(DF,Sar),e(U,Rar),e(U,GF),e(GF,Rbe),e(Rbe,Par),e(GF,Bar),e(GF,SQ),e(SQ,Iar),e(GF,Nar),e(U,qar),e(U,OF),e(OF,Pbe),e(Pbe,jar),e(OF,Dar),e(OF,RQ),e(RQ,Gar),e(OF,Oar),e(U,Var),e(U,VF),e(VF,Bbe),e(Bbe,Xar),e(VF,zar),e(VF,PQ),e(PQ,War),e(VF,Qar),e(U,Har),e(U,XF),e(XF,Ibe),e(Ibe,Uar),e(XF,Jar),e(XF,BQ),e(BQ,Yar),e(XF,Kar),e(no,Zar),e(no,zF),e(zF,enr),e(zF,Nbe),e(Nbe,onr),e(zF,rnr),e(zF,qbe),e(qbe,tnr),e(no,anr),M(WF,no,null),b(f,FQe,u),b(f,Ed,u),e(Ed,QF),e(QF,jbe),M(f9,jbe,null),e(Ed,nnr),e(Ed,Dbe),e(Dbe,snr),b(f,TQe,u),b(f,Oo,u),M(m9,Oo,null),e(Oo,lnr),e(Oo,Cd),e(Cd,inr),e(Cd,IQ),e(IQ,dnr),e(Cd,cnr),e(Cd,NQ),e(NQ,fnr),e(Cd,mnr),e(Oo,gnr),e(Oo,g9),e(g9,hnr),e(g9,Gbe),e(Gbe,pnr),e(g9,_nr),e(Oo,unr),e(Oo,vt),M(h9,vt,null),e(vt,bnr),e(vt,Obe),e(Obe,vnr),e(vt,Fnr),e(vt,wd),e(wd,Tnr),e(wd,Vbe),e(Vbe,Mnr),e(wd,Enr),e(wd,qQ),e(qQ,Cnr),e(wd,wnr),e(vt,Anr),M(HF,vt,null),e(Oo,Lnr),e(Oo,so),M(p9,so,null),e(so,ynr),e(so,Xbe),e(Xbe,xnr),e(so,$nr),e(so,Ua),e(Ua,knr),e(Ua,zbe),e(zbe,Snr),e(Ua,Rnr),e(Ua,Wbe),e(Wbe,Pnr),e(Ua,Bnr),e(Ua,Qbe),e(Qbe,Inr),e(Ua,Nnr),e(so,qnr),e(so,V),e(V,UF),e(UF,Hbe),e(Hbe,jnr),e(UF,Dnr),e(UF,jQ),e(jQ,Gnr),e(UF,Onr),e(V,Vnr),e(V,JF),e(JF,Ube),e(Ube,Xnr),e(JF,znr),e(JF,DQ),e(DQ,Wnr),e(JF,Qnr),e(V,Hnr),e(V,YF),e(YF,Jbe),e(Jbe,Unr),e(YF,Jnr),e(YF,GQ),e(GQ,Ynr),e(YF,Knr),e(V,Znr),e(V,KF),e(KF,Ybe),e(Ybe,esr),e(KF,osr),e(KF,OQ),e(OQ,rsr),e(KF,tsr),e(V,asr),e(V,ZF),e(ZF,Kbe),e(Kbe,nsr),e(ZF,ssr),e(ZF,VQ),e(VQ,lsr),e(ZF,isr),e(V,dsr),e(V,eT),e(eT,Zbe),e(Zbe,csr),e(eT,fsr),e(eT,XQ),e(XQ,msr),e(eT,gsr),e(V,hsr),e(V,oT),e(oT,eve),e(eve,psr),e(oT,_sr),e(oT,zQ),e(zQ,usr),e(oT,bsr),e(V,vsr),e(V,rT),e(rT,ove),e(ove,Fsr),e(rT,Tsr),e(rT,WQ),e(WQ,Msr),e(rT,Esr),e(V,Csr),e(V,tT),e(tT,rve),e(rve,wsr),e(tT,Asr),e(tT,QQ),e(QQ,Lsr),e(tT,ysr),e(V,xsr),e(V,aT),e(aT,tve),e(tve,$sr),e(aT,ksr),e(aT,HQ),e(HQ,Ssr),e(aT,Rsr),e(V,Psr),e(V,nT),e(nT,ave),e(ave,Bsr),e(nT,Isr),e(nT,UQ),e(UQ,Nsr),e(nT,qsr),e(V,jsr),e(V,sT),e(sT,nve),e(nve,Dsr),e(sT,Gsr),e(sT,JQ),e(JQ,Osr),e(sT,Vsr),e(V,Xsr),e(V,lT),e(lT,sve),e(sve,zsr),e(lT,Wsr),e(lT,YQ),e(YQ,Qsr),e(lT,Hsr),e(V,Usr),e(V,iT),e(iT,lve),e(lve,Jsr),e(iT,Ysr),e(iT,KQ),e(KQ,Ksr),e(iT,Zsr),e(V,elr),e(V,dT),e(dT,ive),e(ive,olr),e(dT,rlr),e(dT,ZQ),e(ZQ,tlr),e(dT,alr),e(V,nlr),e(V,cT),e(cT,dve),e(dve,slr),e(cT,llr),e(cT,eH),e(eH,ilr),e(cT,dlr),e(V,clr),e(V,fT),e(fT,cve),e(cve,flr),e(fT,mlr),e(fT,oH),e(oH,glr),e(fT,hlr),e(V,plr),e(V,mT),e(mT,fve),e(fve,_lr),e(mT,ulr),e(mT,rH),e(rH,blr),e(mT,vlr),e(V,Flr),e(V,gT),e(gT,mve),e(mve,Tlr),e(gT,Mlr),e(gT,tH),e(tH,Elr),e(gT,Clr),e(V,wlr),e(V,hT),e(hT,gve),e(gve,Alr),e(hT,Llr),e(hT,aH),e(aH,ylr),e(hT,xlr),e(V,$lr),e(V,pT),e(pT,hve),e(hve,klr),e(pT,Slr),e(pT,nH),e(nH,Rlr),e(pT,Plr),e(V,Blr),e(V,_T),e(_T,pve),e(pve,Ilr),e(_T,Nlr),e(_T,sH),e(sH,qlr),e(_T,jlr),e(V,Dlr),e(V,uT),e(uT,_ve),e(_ve,Glr),e(uT,Olr),e(uT,lH),e(lH,Vlr),e(uT,Xlr),e(V,zlr),e(V,bT),e(bT,uve),e(uve,Wlr),e(bT,Qlr),e(bT,iH),e(iH,Hlr),e(bT,Ulr),e(V,Jlr),e(V,vT),e(vT,bve),e(bve,Ylr),e(vT,Klr),e(vT,dH),e(dH,Zlr),e(vT,eir),e(V,oir),e(V,FT),e(FT,vve),e(vve,rir),e(FT,tir),e(FT,cH),e(cH,air),e(FT,nir),e(V,sir),e(V,TT),e(TT,Fve),e(Fve,lir),e(TT,iir),e(TT,fH),e(fH,dir),e(TT,cir),e(V,fir),e(V,MT),e(MT,Tve),e(Tve,mir),e(MT,gir),e(MT,mH),e(mH,hir),e(MT,pir),e(V,_ir),e(V,ET),e(ET,Mve),e(Mve,uir),e(ET,bir),e(ET,gH),e(gH,vir),e(ET,Fir),e(V,Tir),e(V,CT),e(CT,Eve),e(Eve,Mir),e(CT,Eir),e(CT,hH),e(hH,Cir),e(CT,wir),e(V,Air),e(V,wT),e(wT,Cve),e(Cve,Lir),e(wT,yir),e(wT,pH),e(pH,xir),e(wT,$ir),e(V,kir),e(V,AT),e(AT,wve),e(wve,Sir),e(AT,Rir),e(AT,_H),e(_H,Pir),e(AT,Bir),e(V,Iir),e(V,LT),e(LT,Ave),e(Ave,Nir),e(LT,qir),e(LT,uH),e(uH,jir),e(LT,Dir),e(V,Gir),e(V,yT),e(yT,Lve),e(Lve,Oir),e(yT,Vir),e(yT,bH),e(bH,Xir),e(yT,zir),e(V,Wir),e(V,xT),e(xT,yve),e(yve,Qir),e(xT,Hir),e(xT,vH),e(vH,Uir),e(xT,Jir),e(V,Yir),e(V,$T),e($T,xve),e(xve,Kir),e($T,Zir),e($T,FH),e(FH,edr),e($T,odr),e(V,rdr),e(V,kT),e(kT,$ve),e($ve,tdr),e(kT,adr),e(kT,TH),e(TH,ndr),e(kT,sdr),e(V,ldr),e(V,ST),e(ST,kve),e(kve,idr),e(ST,ddr),e(ST,MH),e(MH,cdr),e(ST,fdr),e(V,mdr),e(V,RT),e(RT,Sve),e(Sve,gdr),e(RT,hdr),e(RT,EH),e(EH,pdr),e(RT,_dr),e(V,udr),e(V,PT),e(PT,Rve),e(Rve,bdr),e(PT,vdr),e(PT,CH),e(CH,Fdr),e(PT,Tdr),e(V,Mdr),e(V,BT),e(BT,Pve),e(Pve,Edr),e(BT,Cdr),e(BT,wH),e(wH,wdr),e(BT,Adr),e(V,Ldr),e(V,IT),e(IT,Bve),e(Bve,ydr),e(IT,xdr),e(IT,AH),e(AH,$dr),e(IT,kdr),e(V,Sdr),e(V,NT),e(NT,Ive),e(Ive,Rdr),e(NT,Pdr),e(NT,LH),e(LH,Bdr),e(NT,Idr),e(so,Ndr),e(so,qT),e(qT,qdr),e(qT,Nve),e(Nve,jdr),e(qT,Ddr),e(qT,qve),e(qve,Gdr),e(so,Odr),M(jT,so,null),b(f,MQe,u),b(f,Ad,u),e(Ad,DT),e(DT,jve),M(_9,jve,null),e(Ad,Vdr),e(Ad,Dve),e(Dve,Xdr),b(f,EQe,u),b(f,Vo,u),M(u9,Vo,null),e(Vo,zdr),e(Vo,Ld),e(Ld,Wdr),e(Ld,yH),e(yH,Qdr),e(Ld,Hdr),e(Ld,xH),e(xH,Udr),e(Ld,Jdr),e(Vo,Ydr),e(Vo,b9),e(b9,Kdr),e(b9,Gve),e(Gve,Zdr),e(b9,ecr),e(Vo,ocr),e(Vo,Ft),M(v9,Ft,null),e(Ft,rcr),e(Ft,Ove),e(Ove,tcr),e(Ft,acr),e(Ft,yd),e(yd,ncr),e(yd,Vve),e(Vve,scr),e(yd,lcr),e(yd,$H),e($H,icr),e(yd,dcr),e(Ft,ccr),M(GT,Ft,null),e(Vo,fcr),e(Vo,lo),M(F9,lo,null),e(lo,mcr),e(lo,Xve),e(Xve,gcr),e(lo,hcr),e(lo,Ja),e(Ja,pcr),e(Ja,zve),e(zve,_cr),e(Ja,ucr),e(Ja,Wve),e(Wve,bcr),e(Ja,vcr),e(Ja,Qve),e(Qve,Fcr),e(Ja,Tcr),e(lo,Mcr),e(lo,Hve),e(Hve,OT),e(OT,Uve),e(Uve,Ecr),e(OT,Ccr),e(OT,kH),e(kH,wcr),e(OT,Acr),e(lo,Lcr),e(lo,VT),e(VT,ycr),e(VT,Jve),e(Jve,xcr),e(VT,$cr),e(VT,Yve),e(Yve,kcr),e(lo,Scr),M(XT,lo,null),b(f,CQe,u),b(f,xd,u),e(xd,zT),e(zT,Kve),M(T9,Kve,null),e(xd,Rcr),e(xd,Zve),e(Zve,Pcr),b(f,wQe,u),b(f,Xo,u),M(M9,Xo,null),e(Xo,Bcr),e(Xo,$d),e($d,Icr),e($d,SH),e(SH,Ncr),e($d,qcr),e($d,RH),e(RH,jcr),e($d,Dcr),e(Xo,Gcr),e(Xo,E9),e(E9,Ocr),e(E9,e0e),e(e0e,Vcr),e(E9,Xcr),e(Xo,zcr),e(Xo,Tt),M(C9,Tt,null),e(Tt,Wcr),e(Tt,o0e),e(o0e,Qcr),e(Tt,Hcr),e(Tt,kd),e(kd,Ucr),e(kd,r0e),e(r0e,Jcr),e(kd,Ycr),e(kd,PH),e(PH,Kcr),e(kd,Zcr),e(Tt,efr),M(WT,Tt,null),e(Xo,ofr),e(Xo,io),M(w9,io,null),e(io,rfr),e(io,t0e),e(t0e,tfr),e(io,afr),e(io,Ya),e(Ya,nfr),e(Ya,a0e),e(a0e,sfr),e(Ya,lfr),e(Ya,n0e),e(n0e,ifr),e(Ya,dfr),e(Ya,s0e),e(s0e,cfr),e(Ya,ffr),e(io,mfr),e(io,be),e(be,QT),e(QT,l0e),e(l0e,gfr),e(QT,hfr),e(QT,BH),e(BH,pfr),e(QT,_fr),e(be,ufr),e(be,HT),e(HT,i0e),e(i0e,bfr),e(HT,vfr),e(HT,IH),e(IH,Ffr),e(HT,Tfr),e(be,Mfr),e(be,UT),e(UT,d0e),e(d0e,Efr),e(UT,Cfr),e(UT,NH),e(NH,wfr),e(UT,Afr),e(be,Lfr),e(be,JT),e(JT,c0e),e(c0e,yfr),e(JT,xfr),e(JT,qH),e(qH,$fr),e(JT,kfr),e(be,Sfr),e(be,rl),e(rl,f0e),e(f0e,Rfr),e(rl,Pfr),e(rl,jH),e(jH,Bfr),e(rl,Ifr),e(rl,DH),e(DH,Nfr),e(rl,qfr),e(be,jfr),e(be,YT),e(YT,m0e),e(m0e,Dfr),e(YT,Gfr),e(YT,GH),e(GH,Ofr),e(YT,Vfr),e(be,Xfr),e(be,tl),e(tl,g0e),e(g0e,zfr),e(tl,Wfr),e(tl,OH),e(OH,Qfr),e(tl,Hfr),e(tl,VH),e(VH,Ufr),e(tl,Jfr),e(be,Yfr),e(be,KT),e(KT,h0e),e(h0e,Kfr),e(KT,Zfr),e(KT,XH),e(XH,emr),e(KT,omr),e(be,rmr),e(be,Mt),e(Mt,p0e),e(p0e,tmr),e(Mt,amr),e(Mt,zH),e(zH,nmr),e(Mt,smr),e(Mt,WH),e(WH,lmr),e(Mt,imr),e(Mt,QH),e(QH,dmr),e(Mt,cmr),e(be,fmr),e(be,ZT),e(ZT,_0e),e(_0e,mmr),e(ZT,gmr),e(ZT,HH),e(HH,hmr),e(ZT,pmr),e(be,_mr),e(be,e8),e(e8,u0e),e(u0e,umr),e(e8,bmr),e(e8,UH),e(UH,vmr),e(e8,Fmr),e(be,Tmr),e(be,o8),e(o8,b0e),e(b0e,Mmr),e(o8,Emr),e(o8,JH),e(JH,Cmr),e(o8,wmr),e(be,Amr),e(be,r8),e(r8,v0e),e(v0e,Lmr),e(r8,ymr),e(r8,YH),e(YH,xmr),e(r8,$mr),e(be,kmr),e(be,t8),e(t8,F0e),e(F0e,Smr),e(t8,Rmr),e(t8,KH),e(KH,Pmr),e(t8,Bmr),e(be,Imr),e(be,a8),e(a8,T0e),e(T0e,Nmr),e(a8,qmr),e(a8,ZH),e(ZH,jmr),e(a8,Dmr),e(be,Gmr),e(be,n8),e(n8,M0e),e(M0e,Omr),e(n8,Vmr),e(n8,eU),e(eU,Xmr),e(n8,zmr),e(be,Wmr),e(be,s8),e(s8,E0e),e(E0e,Qmr),e(s8,Hmr),e(s8,oU),e(oU,Umr),e(s8,Jmr),e(io,Ymr),e(io,l8),e(l8,Kmr),e(l8,C0e),e(C0e,Zmr),e(l8,egr),e(l8,w0e),e(w0e,ogr),e(io,rgr),M(i8,io,null),b(f,AQe,u),b(f,Sd,u),e(Sd,d8),e(d8,A0e),M(A9,A0e,null),e(Sd,tgr),e(Sd,L0e),e(L0e,agr),b(f,LQe,u),b(f,zo,u),M(L9,zo,null),e(zo,ngr),e(zo,Rd),e(Rd,sgr),e(Rd,rU),e(rU,lgr),e(Rd,igr),e(Rd,tU),e(tU,dgr),e(Rd,cgr),e(zo,fgr),e(zo,y9),e(y9,mgr),e(y9,y0e),e(y0e,ggr),e(y9,hgr),e(zo,pgr),e(zo,Et),M(x9,Et,null),e(Et,_gr),e(Et,x0e),e(x0e,ugr),e(Et,bgr),e(Et,Pd),e(Pd,vgr),e(Pd,$0e),e($0e,Fgr),e(Pd,Tgr),e(Pd,aU),e(aU,Mgr),e(Pd,Egr),e(Et,Cgr),M(c8,Et,null),e(zo,wgr),e(zo,co),M($9,co,null),e(co,Agr),e(co,k0e),e(k0e,Lgr),e(co,ygr),e(co,Ka),e(Ka,xgr),e(Ka,S0e),e(S0e,$gr),e(Ka,kgr),e(Ka,R0e),e(R0e,Sgr),e(Ka,Rgr),e(Ka,P0e),e(P0e,Pgr),e(Ka,Bgr),e(co,Igr),e(co,B0e),e(B0e,f8),e(f8,I0e),e(I0e,Ngr),e(f8,qgr),e(f8,nU),e(nU,jgr),e(f8,Dgr),e(co,Ggr),e(co,m8),e(m8,Ogr),e(m8,N0e),e(N0e,Vgr),e(m8,Xgr),e(m8,q0e),e(q0e,zgr),e(co,Wgr),M(g8,co,null),b(f,yQe,u),b(f,Bd,u),e(Bd,h8),e(h8,j0e),M(k9,j0e,null),e(Bd,Qgr),e(Bd,D0e),e(D0e,Hgr),b(f,xQe,u),b(f,Wo,u),M(S9,Wo,null),e(Wo,Ugr),e(Wo,Id),e(Id,Jgr),e(Id,sU),e(sU,Ygr),e(Id,Kgr),e(Id,lU),e(lU,Zgr),e(Id,ehr),e(Wo,ohr),e(Wo,R9),e(R9,rhr),e(R9,G0e),e(G0e,thr),e(R9,ahr),e(Wo,nhr),e(Wo,Ct),M(P9,Ct,null),e(Ct,shr),e(Ct,O0e),e(O0e,lhr),e(Ct,ihr),e(Ct,Nd),e(Nd,dhr),e(Nd,V0e),e(V0e,chr),e(Nd,fhr),e(Nd,iU),e(iU,mhr),e(Nd,ghr),e(Ct,hhr),M(p8,Ct,null),e(Wo,phr),e(Wo,fo),M(B9,fo,null),e(fo,_hr),e(fo,X0e),e(X0e,uhr),e(fo,bhr),e(fo,Za),e(Za,vhr),e(Za,z0e),e(z0e,Fhr),e(Za,Thr),e(Za,W0e),e(W0e,Mhr),e(Za,Ehr),e(Za,Q0e),e(Q0e,Chr),e(Za,whr),e(fo,Ahr),e(fo,H0e),e(H0e,_8),e(_8,U0e),e(U0e,Lhr),e(_8,yhr),e(_8,dU),e(dU,xhr),e(_8,$hr),e(fo,khr),e(fo,u8),e(u8,Shr),e(u8,J0e),e(J0e,Rhr),e(u8,Phr),e(u8,Y0e),e(Y0e,Bhr),e(fo,Ihr),M(b8,fo,null),b(f,$Qe,u),b(f,qd,u),e(qd,v8),e(v8,K0e),M(I9,K0e,null),e(qd,Nhr),e(qd,Z0e),e(Z0e,qhr),b(f,kQe,u),b(f,Qo,u),M(N9,Qo,null),e(Qo,jhr),e(Qo,jd),e(jd,Dhr),e(jd,cU),e(cU,Ghr),e(jd,Ohr),e(jd,fU),e(fU,Vhr),e(jd,Xhr),e(Qo,zhr),e(Qo,q9),e(q9,Whr),e(q9,eFe),e(eFe,Qhr),e(q9,Hhr),e(Qo,Uhr),e(Qo,wt),M(j9,wt,null),e(wt,Jhr),e(wt,oFe),e(oFe,Yhr),e(wt,Khr),e(wt,Dd),e(Dd,Zhr),e(Dd,rFe),e(rFe,epr),e(Dd,opr),e(Dd,mU),e(mU,rpr),e(Dd,tpr),e(wt,apr),M(F8,wt,null),e(Qo,npr),e(Qo,mo),M(D9,mo,null),e(mo,spr),e(mo,tFe),e(tFe,lpr),e(mo,ipr),e(mo,en),e(en,dpr),e(en,aFe),e(aFe,cpr),e(en,fpr),e(en,nFe),e(nFe,mpr),e(en,gpr),e(en,sFe),e(sFe,hpr),e(en,ppr),e(mo,_pr),e(mo,lFe),e(lFe,T8),e(T8,iFe),e(iFe,upr),e(T8,bpr),e(T8,gU),e(gU,vpr),e(T8,Fpr),e(mo,Tpr),e(mo,M8),e(M8,Mpr),e(M8,dFe),e(dFe,Epr),e(M8,Cpr),e(M8,cFe),e(cFe,wpr),e(mo,Apr),M(E8,mo,null),b(f,SQe,u),b(f,Gd,u),e(Gd,C8),e(C8,fFe),M(G9,fFe,null),e(Gd,Lpr),e(Gd,mFe),e(mFe,ypr),b(f,RQe,u),b(f,Ho,u),M(O9,Ho,null),e(Ho,xpr),e(Ho,Od),e(Od,$pr),e(Od,hU),e(hU,kpr),e(Od,Spr),e(Od,pU),e(pU,Rpr),e(Od,Ppr),e(Ho,Bpr),e(Ho,V9),e(V9,Ipr),e(V9,gFe),e(gFe,Npr),e(V9,qpr),e(Ho,jpr),e(Ho,At),M(X9,At,null),e(At,Dpr),e(At,hFe),e(hFe,Gpr),e(At,Opr),e(At,Vd),e(Vd,Vpr),e(Vd,pFe),e(pFe,Xpr),e(Vd,zpr),e(Vd,_U),e(_U,Wpr),e(Vd,Qpr),e(At,Hpr),M(w8,At,null),e(Ho,Upr),e(Ho,go),M(z9,go,null),e(go,Jpr),e(go,_Fe),e(_Fe,Ypr),e(go,Kpr),e(go,on),e(on,Zpr),e(on,uFe),e(uFe,e_r),e(on,o_r),e(on,bFe),e(bFe,r_r),e(on,t_r),e(on,vFe),e(vFe,a_r),e(on,n_r),e(go,s_r),e(go,Be),e(Be,A8),e(A8,FFe),e(FFe,l_r),e(A8,i_r),e(A8,uU),e(uU,d_r),e(A8,c_r),e(Be,f_r),e(Be,L8),e(L8,TFe),e(TFe,m_r),e(L8,g_r),e(L8,bU),e(bU,h_r),e(L8,p_r),e(Be,__r),e(Be,y8),e(y8,MFe),e(MFe,u_r),e(y8,b_r),e(y8,vU),e(vU,v_r),e(y8,F_r),e(Be,T_r),e(Be,x8),e(x8,EFe),e(EFe,M_r),e(x8,E_r),e(x8,FU),e(FU,C_r),e(x8,w_r),e(Be,A_r),e(Be,$8),e($8,CFe),e(CFe,L_r),e($8,y_r),e($8,TU),e(TU,x_r),e($8,$_r),e(Be,k_r),e(Be,k8),e(k8,wFe),e(wFe,S_r),e(k8,R_r),e(k8,MU),e(MU,P_r),e(k8,B_r),e(Be,I_r),e(Be,S8),e(S8,AFe),e(AFe,N_r),e(S8,q_r),e(S8,EU),e(EU,j_r),e(S8,D_r),e(Be,G_r),e(Be,R8),e(R8,LFe),e(LFe,O_r),e(R8,V_r),e(R8,CU),e(CU,X_r),e(R8,z_r),e(Be,W_r),e(Be,P8),e(P8,yFe),e(yFe,Q_r),e(P8,H_r),e(P8,wU),e(wU,U_r),e(P8,J_r),e(go,Y_r),e(go,B8),e(B8,K_r),e(B8,xFe),e(xFe,Z_r),e(B8,eur),e(B8,$Fe),e($Fe,our),e(go,rur),M(I8,go,null),b(f,PQe,u),b(f,Xd,u),e(Xd,N8),e(N8,kFe),M(W9,kFe,null),e(Xd,tur),e(Xd,SFe),e(SFe,aur),b(f,BQe,u),b(f,Uo,u),M(Q9,Uo,null),e(Uo,nur),e(Uo,zd),e(zd,sur),e(zd,AU),e(AU,lur),e(zd,iur),e(zd,LU),e(LU,dur),e(zd,cur),e(Uo,fur),e(Uo,H9),e(H9,mur),e(H9,RFe),e(RFe,gur),e(H9,hur),e(Uo,pur),e(Uo,Lt),M(U9,Lt,null),e(Lt,_ur),e(Lt,PFe),e(PFe,uur),e(Lt,bur),e(Lt,Wd),e(Wd,vur),e(Wd,BFe),e(BFe,Fur),e(Wd,Tur),e(Wd,yU),e(yU,Mur),e(Wd,Eur),e(Lt,Cur),M(q8,Lt,null),e(Uo,wur),e(Uo,ho),M(J9,ho,null),e(ho,Aur),e(ho,IFe),e(IFe,Lur),e(ho,yur),e(ho,rn),e(rn,xur),e(rn,NFe),e(NFe,$ur),e(rn,kur),e(rn,qFe),e(qFe,Sur),e(rn,Rur),e(rn,jFe),e(jFe,Pur),e(rn,Bur),e(ho,Iur),e(ho,at),e(at,j8),e(j8,DFe),e(DFe,Nur),e(j8,qur),e(j8,xU),e(xU,jur),e(j8,Dur),e(at,Gur),e(at,D8),e(D8,GFe),e(GFe,Our),e(D8,Vur),e(D8,$U),e($U,Xur),e(D8,zur),e(at,Wur),e(at,G8),e(G8,OFe),e(OFe,Qur),e(G8,Hur),e(G8,kU),e(kU,Uur),e(G8,Jur),e(at,Yur),e(at,O8),e(O8,VFe),e(VFe,Kur),e(O8,Zur),e(O8,SU),e(SU,e2r),e(O8,o2r),e(at,r2r),e(at,V8),e(V8,XFe),e(XFe,t2r),e(V8,a2r),e(V8,RU),e(RU,n2r),e(V8,s2r),e(ho,l2r),e(ho,X8),e(X8,i2r),e(X8,zFe),e(zFe,d2r),e(X8,c2r),e(X8,WFe),e(WFe,f2r),e(ho,m2r),M(z8,ho,null),b(f,IQe,u),b(f,Qd,u),e(Qd,W8),e(W8,QFe),M(Y9,QFe,null),e(Qd,g2r),e(Qd,HFe),e(HFe,h2r),b(f,NQe,u),b(f,Jo,u),M(K9,Jo,null),e(Jo,p2r),e(Jo,Hd),e(Hd,_2r),e(Hd,PU),e(PU,u2r),e(Hd,b2r),e(Hd,BU),e(BU,v2r),e(Hd,F2r),e(Jo,T2r),e(Jo,Z9),e(Z9,M2r),e(Z9,UFe),e(UFe,E2r),e(Z9,C2r),e(Jo,w2r),e(Jo,yt),M(ex,yt,null),e(yt,A2r),e(yt,JFe),e(JFe,L2r),e(yt,y2r),e(yt,Ud),e(Ud,x2r),e(Ud,YFe),e(YFe,$2r),e(Ud,k2r),e(Ud,IU),e(IU,S2r),e(Ud,R2r),e(yt,P2r),M(Q8,yt,null),e(Jo,B2r),e(Jo,po),M(ox,po,null),e(po,I2r),e(po,KFe),e(KFe,N2r),e(po,q2r),e(po,tn),e(tn,j2r),e(tn,ZFe),e(ZFe,D2r),e(tn,G2r),e(tn,eTe),e(eTe,O2r),e(tn,V2r),e(tn,oTe),e(oTe,X2r),e(tn,z2r),e(po,W2r),e(po,ye),e(ye,H8),e(H8,rTe),e(rTe,Q2r),e(H8,H2r),e(H8,NU),e(NU,U2r),e(H8,J2r),e(ye,Y2r),e(ye,U8),e(U8,tTe),e(tTe,K2r),e(U8,Z2r),e(U8,qU),e(qU,e1r),e(U8,o1r),e(ye,r1r),e(ye,J8),e(J8,aTe),e(aTe,t1r),e(J8,a1r),e(J8,jU),e(jU,n1r),e(J8,s1r),e(ye,l1r),e(ye,Y8),e(Y8,nTe),e(nTe,i1r),e(Y8,d1r),e(Y8,DU),e(DU,c1r),e(Y8,f1r),e(ye,m1r),e(ye,K8),e(K8,sTe),e(sTe,g1r),e(K8,h1r),e(K8,GU),e(GU,p1r),e(K8,_1r),e(ye,u1r),e(ye,Z8),e(Z8,lTe),e(lTe,b1r),e(Z8,v1r),e(Z8,OU),e(OU,F1r),e(Z8,T1r),e(ye,M1r),e(ye,eM),e(eM,iTe),e(iTe,E1r),e(eM,C1r),e(eM,VU),e(VU,w1r),e(eM,A1r),e(ye,L1r),e(ye,oM),e(oM,dTe),e(dTe,y1r),e(oM,x1r),e(oM,XU),e(XU,$1r),e(oM,k1r),e(ye,S1r),e(ye,rM),e(rM,cTe),e(cTe,R1r),e(rM,P1r),e(rM,zU),e(zU,B1r),e(rM,I1r),e(ye,N1r),e(ye,tM),e(tM,fTe),e(fTe,q1r),e(tM,j1r),e(tM,WU),e(WU,D1r),e(tM,G1r),e(po,O1r),e(po,aM),e(aM,V1r),e(aM,mTe),e(mTe,X1r),e(aM,z1r),e(aM,gTe),e(gTe,W1r),e(po,Q1r),M(nM,po,null),b(f,qQe,u),b(f,Jd,u),e(Jd,sM),e(sM,hTe),M(rx,hTe,null),e(Jd,H1r),e(Jd,pTe),e(pTe,U1r),b(f,jQe,u),b(f,Yo,u),M(tx,Yo,null),e(Yo,J1r),e(Yo,Yd),e(Yd,Y1r),e(Yd,QU),e(QU,K1r),e(Yd,Z1r),e(Yd,HU),e(HU,ebr),e(Yd,obr),e(Yo,rbr),e(Yo,ax),e(ax,tbr),e(ax,_Te),e(_Te,abr),e(ax,nbr),e(Yo,sbr),e(Yo,xt),M(nx,xt,null),e(xt,lbr),e(xt,uTe),e(uTe,ibr),e(xt,dbr),e(xt,Kd),e(Kd,cbr),e(Kd,bTe),e(bTe,fbr),e(Kd,mbr),e(Kd,UU),e(UU,gbr),e(Kd,hbr),e(xt,pbr),M(lM,xt,null),e(Yo,_br),e(Yo,_o),M(sx,_o,null),e(_o,ubr),e(_o,vTe),e(vTe,bbr),e(_o,vbr),e(_o,an),e(an,Fbr),e(an,FTe),e(FTe,Tbr),e(an,Mbr),e(an,TTe),e(TTe,Ebr),e(an,Cbr),e(an,MTe),e(MTe,wbr),e(an,Abr),e(_o,Lbr),e(_o,lx),e(lx,iM),e(iM,ETe),e(ETe,ybr),e(iM,xbr),e(iM,JU),e(JU,$br),e(iM,kbr),e(lx,Sbr),e(lx,dM),e(dM,CTe),e(CTe,Rbr),e(dM,Pbr),e(dM,YU),e(YU,Bbr),e(dM,Ibr),e(_o,Nbr),e(_o,cM),e(cM,qbr),e(cM,wTe),e(wTe,jbr),e(cM,Dbr),e(cM,ATe),e(ATe,Gbr),e(_o,Obr),M(fM,_o,null),b(f,DQe,u),b(f,Zd,u),e(Zd,mM),e(mM,LTe),M(ix,LTe,null),e(Zd,Vbr),e(Zd,yTe),e(yTe,Xbr),b(f,GQe,u),b(f,Ko,u),M(dx,Ko,null),e(Ko,zbr),e(Ko,ec),e(ec,Wbr),e(ec,KU),e(KU,Qbr),e(ec,Hbr),e(ec,ZU),e(ZU,Ubr),e(ec,Jbr),e(Ko,Ybr),e(Ko,cx),e(cx,Kbr),e(cx,xTe),e(xTe,Zbr),e(cx,evr),e(Ko,ovr),e(Ko,$t),M(fx,$t,null),e($t,rvr),e($t,$Te),e($Te,tvr),e($t,avr),e($t,oc),e(oc,nvr),e(oc,kTe),e(kTe,svr),e(oc,lvr),e(oc,eJ),e(eJ,ivr),e(oc,dvr),e($t,cvr),M(gM,$t,null),e(Ko,fvr),e(Ko,uo),M(mx,uo,null),e(uo,mvr),e(uo,STe),e(STe,gvr),e(uo,hvr),e(uo,nn),e(nn,pvr),e(nn,RTe),e(RTe,_vr),e(nn,uvr),e(nn,PTe),e(PTe,bvr),e(nn,vvr),e(nn,BTe),e(BTe,Fvr),e(nn,Tvr),e(uo,Mvr),e(uo,nt),e(nt,hM),e(hM,ITe),e(ITe,Evr),e(hM,Cvr),e(hM,oJ),e(oJ,wvr),e(hM,Avr),e(nt,Lvr),e(nt,pM),e(pM,NTe),e(NTe,yvr),e(pM,xvr),e(pM,rJ),e(rJ,$vr),e(pM,kvr),e(nt,Svr),e(nt,_M),e(_M,qTe),e(qTe,Rvr),e(_M,Pvr),e(_M,tJ),e(tJ,Bvr),e(_M,Ivr),e(nt,Nvr),e(nt,uM),e(uM,jTe),e(jTe,qvr),e(uM,jvr),e(uM,aJ),e(aJ,Dvr),e(uM,Gvr),e(nt,Ovr),e(nt,bM),e(bM,DTe),e(DTe,Vvr),e(bM,Xvr),e(bM,nJ),e(nJ,zvr),e(bM,Wvr),e(uo,Qvr),e(uo,vM),e(vM,Hvr),e(vM,GTe),e(GTe,Uvr),e(vM,Jvr),e(vM,OTe),e(OTe,Yvr),e(uo,Kvr),M(FM,uo,null),b(f,OQe,u),b(f,rc,u),e(rc,TM),e(TM,VTe),M(gx,VTe,null),e(rc,Zvr),e(rc,XTe),e(XTe,e0r),b(f,VQe,u),b(f,Zo,u),M(hx,Zo,null),e(Zo,o0r),e(Zo,tc),e(tc,r0r),e(tc,sJ),e(sJ,t0r),e(tc,a0r),e(tc,lJ),e(lJ,n0r),e(tc,s0r),e(Zo,l0r),e(Zo,px),e(px,i0r),e(px,zTe),e(zTe,d0r),e(px,c0r),e(Zo,f0r),e(Zo,kt),M(_x,kt,null),e(kt,m0r),e(kt,WTe),e(WTe,g0r),e(kt,h0r),e(kt,ac),e(ac,p0r),e(ac,QTe),e(QTe,_0r),e(ac,u0r),e(ac,iJ),e(iJ,b0r),e(ac,v0r),e(kt,F0r),M(MM,kt,null),e(Zo,T0r),e(Zo,bo),M(ux,bo,null),e(bo,M0r),e(bo,HTe),e(HTe,E0r),e(bo,C0r),e(bo,sn),e(sn,w0r),e(sn,UTe),e(UTe,A0r),e(sn,L0r),e(sn,JTe),e(JTe,y0r),e(sn,x0r),e(sn,YTe),e(YTe,$0r),e(sn,k0r),e(bo,S0r),e(bo,ln),e(ln,EM),e(EM,KTe),e(KTe,R0r),e(EM,P0r),e(EM,dJ),e(dJ,B0r),e(EM,I0r),e(ln,N0r),e(ln,CM),e(CM,ZTe),e(ZTe,q0r),e(CM,j0r),e(CM,cJ),e(cJ,D0r),e(CM,G0r),e(ln,O0r),e(ln,wM),e(wM,e8e),e(e8e,V0r),e(wM,X0r),e(wM,fJ),e(fJ,z0r),e(wM,W0r),e(ln,Q0r),e(ln,AM),e(AM,o8e),e(o8e,H0r),e(AM,U0r),e(AM,mJ),e(mJ,J0r),e(AM,Y0r),e(bo,K0r),e(bo,LM),e(LM,Z0r),e(LM,r8e),e(r8e,eFr),e(LM,oFr),e(LM,t8e),e(t8e,rFr),e(bo,tFr),M(yM,bo,null),b(f,XQe,u),b(f,nc,u),e(nc,xM),e(xM,a8e),M(bx,a8e,null),e(nc,aFr),e(nc,n8e),e(n8e,nFr),b(f,zQe,u),b(f,er,u),M(vx,er,null),e(er,sFr),e(er,sc),e(sc,lFr),e(sc,gJ),e(gJ,iFr),e(sc,dFr),e(sc,hJ),e(hJ,cFr),e(sc,fFr),e(er,mFr),e(er,Fx),e(Fx,gFr),e(Fx,s8e),e(s8e,hFr),e(Fx,pFr),e(er,_Fr),e(er,St),M(Tx,St,null),e(St,uFr),e(St,l8e),e(l8e,bFr),e(St,vFr),e(St,lc),e(lc,FFr),e(lc,i8e),e(i8e,TFr),e(lc,MFr),e(lc,pJ),e(pJ,EFr),e(lc,CFr),e(St,wFr),M($M,St,null),e(er,AFr),e(er,vo),M(Mx,vo,null),e(vo,LFr),e(vo,d8e),e(d8e,yFr),e(vo,xFr),e(vo,dn),e(dn,$Fr),e(dn,c8e),e(c8e,kFr),e(dn,SFr),e(dn,f8e),e(f8e,RFr),e(dn,PFr),e(dn,m8e),e(m8e,BFr),e(dn,IFr),e(vo,NFr),e(vo,Ex),e(Ex,kM),e(kM,g8e),e(g8e,qFr),e(kM,jFr),e(kM,_J),e(_J,DFr),e(kM,GFr),e(Ex,OFr),e(Ex,SM),e(SM,h8e),e(h8e,VFr),e(SM,XFr),e(SM,uJ),e(uJ,zFr),e(SM,WFr),e(vo,QFr),e(vo,RM),e(RM,HFr),e(RM,p8e),e(p8e,UFr),e(RM,JFr),e(RM,_8e),e(_8e,YFr),e(vo,KFr),M(PM,vo,null),b(f,WQe,u),b(f,ic,u),e(ic,BM),e(BM,u8e),M(Cx,u8e,null),e(ic,ZFr),e(ic,b8e),e(b8e,eTr),b(f,QQe,u),b(f,or,u),M(wx,or,null),e(or,oTr),e(or,dc),e(dc,rTr),e(dc,bJ),e(bJ,tTr),e(dc,aTr),e(dc,vJ),e(vJ,nTr),e(dc,sTr),e(or,lTr),e(or,Ax),e(Ax,iTr),e(Ax,v8e),e(v8e,dTr),e(Ax,cTr),e(or,fTr),e(or,Rt),M(Lx,Rt,null),e(Rt,mTr),e(Rt,F8e),e(F8e,gTr),e(Rt,hTr),e(Rt,cc),e(cc,pTr),e(cc,T8e),e(T8e,_Tr),e(cc,uTr),e(cc,FJ),e(FJ,bTr),e(cc,vTr),e(Rt,FTr),M(IM,Rt,null),e(or,TTr),e(or,Fo),M(yx,Fo,null),e(Fo,MTr),e(Fo,M8e),e(M8e,ETr),e(Fo,CTr),e(Fo,cn),e(cn,wTr),e(cn,E8e),e(E8e,ATr),e(cn,LTr),e(cn,C8e),e(C8e,yTr),e(cn,xTr),e(cn,w8e),e(w8e,$Tr),e(cn,kTr),e(Fo,STr),e(Fo,A8e),e(A8e,NM),e(NM,L8e),e(L8e,RTr),e(NM,PTr),e(NM,TJ),e(TJ,BTr),e(NM,ITr),e(Fo,NTr),e(Fo,qM),e(qM,qTr),e(qM,y8e),e(y8e,jTr),e(qM,DTr),e(qM,x8e),e(x8e,GTr),e(Fo,OTr),M(jM,Fo,null),b(f,HQe,u),b(f,fc,u),e(fc,DM),e(DM,$8e),M(xx,$8e,null),e(fc,VTr),e(fc,k8e),e(k8e,XTr),b(f,UQe,u),b(f,rr,u),M($x,rr,null),e(rr,zTr),e(rr,mc),e(mc,WTr),e(mc,MJ),e(MJ,QTr),e(mc,HTr),e(mc,EJ),e(EJ,UTr),e(mc,JTr),e(rr,YTr),e(rr,kx),e(kx,KTr),e(kx,S8e),e(S8e,ZTr),e(kx,e8r),e(rr,o8r),e(rr,Pt),M(Sx,Pt,null),e(Pt,r8r),e(Pt,R8e),e(R8e,t8r),e(Pt,a8r),e(Pt,gc),e(gc,n8r),e(gc,P8e),e(P8e,s8r),e(gc,l8r),e(gc,CJ),e(CJ,i8r),e(gc,d8r),e(Pt,c8r),M(GM,Pt,null),e(rr,f8r),e(rr,To),M(Rx,To,null),e(To,m8r),e(To,B8e),e(B8e,g8r),e(To,h8r),e(To,fn),e(fn,p8r),e(fn,I8e),e(I8e,_8r),e(fn,u8r),e(fn,N8e),e(N8e,b8r),e(fn,v8r),e(fn,q8e),e(q8e,F8r),e(fn,T8r),e(To,M8r),e(To,st),e(st,OM),e(OM,j8e),e(j8e,E8r),e(OM,C8r),e(OM,wJ),e(wJ,w8r),e(OM,A8r),e(st,L8r),e(st,VM),e(VM,D8e),e(D8e,y8r),e(VM,x8r),e(VM,AJ),e(AJ,$8r),e(VM,k8r),e(st,S8r),e(st,XM),e(XM,G8e),e(G8e,R8r),e(XM,P8r),e(XM,LJ),e(LJ,B8r),e(XM,I8r),e(st,N8r),e(st,zM),e(zM,O8e),e(O8e,q8r),e(zM,j8r),e(zM,yJ),e(yJ,D8r),e(zM,G8r),e(st,O8r),e(st,WM),e(WM,V8e),e(V8e,V8r),e(WM,X8r),e(WM,xJ),e(xJ,z8r),e(WM,W8r),e(To,Q8r),e(To,QM),e(QM,H8r),e(QM,X8e),e(X8e,U8r),e(QM,J8r),e(QM,z8e),e(z8e,Y8r),e(To,K8r),M(HM,To,null),b(f,JQe,u),b(f,hc,u),e(hc,UM),e(UM,W8e),M(Px,W8e,null),e(hc,Z8r),e(hc,Q8e),e(Q8e,eMr),b(f,YQe,u),b(f,tr,u),M(Bx,tr,null),e(tr,oMr),e(tr,pc),e(pc,rMr),e(pc,$J),e($J,tMr),e(pc,aMr),e(pc,kJ),e(kJ,nMr),e(pc,sMr),e(tr,lMr),e(tr,Ix),e(Ix,iMr),e(Ix,H8e),e(H8e,dMr),e(Ix,cMr),e(tr,fMr),e(tr,Bt),M(Nx,Bt,null),e(Bt,mMr),e(Bt,U8e),e(U8e,gMr),e(Bt,hMr),e(Bt,_c),e(_c,pMr),e(_c,J8e),e(J8e,_Mr),e(_c,uMr),e(_c,SJ),e(SJ,bMr),e(_c,vMr),e(Bt,FMr),M(JM,Bt,null),e(tr,TMr),e(tr,Mo),M(qx,Mo,null),e(Mo,MMr),e(Mo,Y8e),e(Y8e,EMr),e(Mo,CMr),e(Mo,mn),e(mn,wMr),e(mn,K8e),e(K8e,AMr),e(mn,LMr),e(mn,Z8e),e(Z8e,yMr),e(mn,xMr),e(mn,eMe),e(eMe,$Mr),e(mn,kMr),e(Mo,SMr),e(Mo,oMe),e(oMe,YM),e(YM,rMe),e(rMe,RMr),e(YM,PMr),e(YM,RJ),e(RJ,BMr),e(YM,IMr),e(Mo,NMr),e(Mo,KM),e(KM,qMr),e(KM,tMe),e(tMe,jMr),e(KM,DMr),e(KM,aMe),e(aMe,GMr),e(Mo,OMr),M(ZM,Mo,null),b(f,KQe,u),b(f,uc,u),e(uc,eE),e(eE,nMe),M(jx,nMe,null),e(uc,VMr),e(uc,sMe),e(sMe,XMr),b(f,ZQe,u),b(f,ar,u),M(Dx,ar,null),e(ar,zMr),e(ar,bc),e(bc,WMr),e(bc,PJ),e(PJ,QMr),e(bc,HMr),e(bc,BJ),e(BJ,UMr),e(bc,JMr),e(ar,YMr),e(ar,Gx),e(Gx,KMr),e(Gx,lMe),e(lMe,ZMr),e(Gx,eEr),e(ar,oEr),e(ar,It),M(Ox,It,null),e(It,rEr),e(It,iMe),e(iMe,tEr),e(It,aEr),e(It,vc),e(vc,nEr),e(vc,dMe),e(dMe,sEr),e(vc,lEr),e(vc,IJ),e(IJ,iEr),e(vc,dEr),e(It,cEr),M(oE,It,null),e(ar,fEr),e(ar,Sr),M(Vx,Sr,null),e(Sr,mEr),e(Sr,cMe),e(cMe,gEr),e(Sr,hEr),e(Sr,gn),e(gn,pEr),e(gn,fMe),e(fMe,_Er),e(gn,uEr),e(gn,mMe),e(mMe,bEr),e(gn,vEr),e(gn,gMe),e(gMe,FEr),e(gn,TEr),e(Sr,MEr),e(Sr,q),e(q,rE),e(rE,hMe),e(hMe,EEr),e(rE,CEr),e(rE,NJ),e(NJ,wEr),e(rE,AEr),e(q,LEr),e(q,tE),e(tE,pMe),e(pMe,yEr),e(tE,xEr),e(tE,qJ),e(qJ,$Er),e(tE,kEr),e(q,SEr),e(q,aE),e(aE,_Me),e(_Me,REr),e(aE,PEr),e(aE,jJ),e(jJ,BEr),e(aE,IEr),e(q,NEr),e(q,nE),e(nE,uMe),e(uMe,qEr),e(nE,jEr),e(nE,DJ),e(DJ,DEr),e(nE,GEr),e(q,OEr),e(q,sE),e(sE,bMe),e(bMe,VEr),e(sE,XEr),e(sE,GJ),e(GJ,zEr),e(sE,WEr),e(q,QEr),e(q,lE),e(lE,vMe),e(vMe,HEr),e(lE,UEr),e(lE,OJ),e(OJ,JEr),e(lE,YEr),e(q,KEr),e(q,iE),e(iE,FMe),e(FMe,ZEr),e(iE,e4r),e(iE,VJ),e(VJ,o4r),e(iE,r4r),e(q,t4r),e(q,dE),e(dE,TMe),e(TMe,a4r),e(dE,n4r),e(dE,XJ),e(XJ,s4r),e(dE,l4r),e(q,i4r),e(q,cE),e(cE,MMe),e(MMe,d4r),e(cE,c4r),e(cE,zJ),e(zJ,f4r),e(cE,m4r),e(q,g4r),e(q,fE),e(fE,EMe),e(EMe,h4r),e(fE,p4r),e(fE,WJ),e(WJ,_4r),e(fE,u4r),e(q,b4r),e(q,mE),e(mE,CMe),e(CMe,v4r),e(mE,F4r),e(mE,QJ),e(QJ,T4r),e(mE,M4r),e(q,E4r),e(q,gE),e(gE,wMe),e(wMe,C4r),e(gE,w4r),e(gE,HJ),e(HJ,A4r),e(gE,L4r),e(q,y4r),e(q,hE),e(hE,AMe),e(AMe,x4r),e(hE,$4r),e(hE,UJ),e(UJ,k4r),e(hE,S4r),e(q,R4r),e(q,pE),e(pE,LMe),e(LMe,P4r),e(pE,B4r),e(pE,JJ),e(JJ,I4r),e(pE,N4r),e(q,q4r),e(q,_E),e(_E,yMe),e(yMe,j4r),e(_E,D4r),e(_E,YJ),e(YJ,G4r),e(_E,O4r),e(q,V4r),e(q,uE),e(uE,xMe),e(xMe,X4r),e(uE,z4r),e(uE,KJ),e(KJ,W4r),e(uE,Q4r),e(q,H4r),e(q,bE),e(bE,$Me),e($Me,U4r),e(bE,J4r),e(bE,ZJ),e(ZJ,Y4r),e(bE,K4r),e(q,Z4r),e(q,vE),e(vE,kMe),e(kMe,eCr),e(vE,oCr),e(vE,eY),e(eY,rCr),e(vE,tCr),e(q,aCr),e(q,al),e(al,SMe),e(SMe,nCr),e(al,sCr),e(al,oY),e(oY,lCr),e(al,iCr),e(al,rY),e(rY,dCr),e(al,cCr),e(q,fCr),e(q,FE),e(FE,RMe),e(RMe,mCr),e(FE,gCr),e(FE,tY),e(tY,hCr),e(FE,pCr),e(q,_Cr),e(q,TE),e(TE,PMe),e(PMe,uCr),e(TE,bCr),e(TE,aY),e(aY,vCr),e(TE,FCr),e(q,TCr),e(q,ME),e(ME,BMe),e(BMe,MCr),e(ME,ECr),e(ME,nY),e(nY,CCr),e(ME,wCr),e(q,ACr),e(q,EE),e(EE,IMe),e(IMe,LCr),e(EE,yCr),e(EE,sY),e(sY,xCr),e(EE,$Cr),e(q,kCr),e(q,CE),e(CE,NMe),e(NMe,SCr),e(CE,RCr),e(CE,lY),e(lY,PCr),e(CE,BCr),e(q,ICr),e(q,wE),e(wE,qMe),e(qMe,NCr),e(wE,qCr),e(wE,iY),e(iY,jCr),e(wE,DCr),e(q,GCr),e(q,AE),e(AE,jMe),e(jMe,OCr),e(AE,VCr),e(AE,dY),e(dY,XCr),e(AE,zCr),e(q,WCr),e(q,LE),e(LE,DMe),e(DMe,QCr),e(LE,HCr),e(LE,cY),e(cY,UCr),e(LE,JCr),e(q,YCr),e(q,yE),e(yE,GMe),e(GMe,KCr),e(yE,ZCr),e(yE,fY),e(fY,e5r),e(yE,o5r),e(q,r5r),e(q,xE),e(xE,OMe),e(OMe,t5r),e(xE,a5r),e(xE,mY),e(mY,n5r),e(xE,s5r),e(q,l5r),e(q,$E),e($E,VMe),e(VMe,i5r),e($E,d5r),e($E,gY),e(gY,c5r),e($E,f5r),e(q,m5r),e(q,kE),e(kE,XMe),e(XMe,g5r),e(kE,h5r),e(kE,hY),e(hY,p5r),e(kE,_5r),e(q,u5r),e(q,SE),e(SE,zMe),e(zMe,b5r),e(SE,v5r),e(SE,pY),e(pY,F5r),e(SE,T5r),e(q,M5r),e(q,RE),e(RE,WMe),e(WMe,E5r),e(RE,C5r),e(RE,_Y),e(_Y,w5r),e(RE,A5r),e(q,L5r),e(q,PE),e(PE,QMe),e(QMe,y5r),e(PE,x5r),e(PE,uY),e(uY,$5r),e(PE,k5r),e(q,S5r),e(q,BE),e(BE,HMe),e(HMe,R5r),e(BE,P5r),e(BE,bY),e(bY,B5r),e(BE,I5r),e(q,N5r),e(q,IE),e(IE,UMe),e(UMe,q5r),e(IE,j5r),e(IE,vY),e(vY,D5r),e(IE,G5r),e(q,O5r),e(q,NE),e(NE,JMe),e(JMe,V5r),e(NE,X5r),e(NE,FY),e(FY,z5r),e(NE,W5r),e(q,Q5r),e(q,qE),e(qE,YMe),e(YMe,H5r),e(qE,U5r),e(qE,TY),e(TY,J5r),e(qE,Y5r),e(q,K5r),e(q,jE),e(jE,KMe),e(KMe,Z5r),e(jE,e3r),e(jE,MY),e(MY,o3r),e(jE,r3r),e(q,t3r),e(q,DE),e(DE,ZMe),e(ZMe,a3r),e(DE,n3r),e(DE,EY),e(EY,s3r),e(DE,l3r),e(q,i3r),e(q,GE),e(GE,eEe),e(eEe,d3r),e(GE,c3r),e(GE,CY),e(CY,f3r),e(GE,m3r),e(q,g3r),e(q,OE),e(OE,oEe),e(oEe,h3r),e(OE,p3r),e(OE,wY),e(wY,_3r),e(OE,u3r),e(q,b3r),e(q,VE),e(VE,rEe),e(rEe,v3r),e(VE,F3r),e(VE,AY),e(AY,T3r),e(VE,M3r),e(q,E3r),e(q,XE),e(XE,tEe),e(tEe,C3r),e(XE,w3r),e(XE,LY),e(LY,A3r),e(XE,L3r),e(q,y3r),e(q,zE),e(zE,aEe),e(aEe,x3r),e(zE,$3r),e(zE,yY),e(yY,k3r),e(zE,S3r),e(q,R3r),e(q,WE),e(WE,nEe),e(nEe,P3r),e(WE,B3r),e(WE,xY),e(xY,I3r),e(WE,N3r),e(q,q3r),e(q,QE),e(QE,sEe),e(sEe,j3r),e(QE,D3r),e(QE,$Y),e($Y,G3r),e(QE,O3r),e(q,V3r),e(q,HE),e(HE,lEe),e(lEe,X3r),e(HE,z3r),e(HE,kY),e(kY,W3r),e(HE,Q3r),e(q,H3r),e(q,UE),e(UE,iEe),e(iEe,U3r),e(UE,J3r),e(UE,SY),e(SY,Y3r),e(UE,K3r),e(q,Z3r),e(q,JE),e(JE,dEe),e(dEe,ewr),e(JE,owr),e(JE,RY),e(RY,rwr),e(JE,twr),e(q,awr),e(q,YE),e(YE,cEe),e(cEe,nwr),e(YE,swr),e(YE,PY),e(PY,lwr),e(YE,iwr),e(Sr,dwr),M(KE,Sr,null),b(f,eHe,u),b(f,Fc,u),e(Fc,ZE),e(ZE,fEe),M(Xx,fEe,null),e(Fc,cwr),e(Fc,mEe),e(mEe,fwr),b(f,oHe,u),b(f,nr,u),M(zx,nr,null),e(nr,mwr),e(nr,Tc),e(Tc,gwr),e(Tc,BY),e(BY,hwr),e(Tc,pwr),e(Tc,IY),e(IY,_wr),e(Tc,uwr),e(nr,bwr),e(nr,Wx),e(Wx,vwr),e(Wx,gEe),e(gEe,Fwr),e(Wx,Twr),e(nr,Mwr),e(nr,Nt),M(Qx,Nt,null),e(Nt,Ewr),e(Nt,hEe),e(hEe,Cwr),e(Nt,wwr),e(Nt,Mc),e(Mc,Awr),e(Mc,pEe),e(pEe,Lwr),e(Mc,ywr),e(Mc,NY),e(NY,xwr),e(Mc,$wr),e(Nt,kwr),M(e4,Nt,null),e(nr,Swr),e(nr,Rr),M(Hx,Rr,null),e(Rr,Rwr),e(Rr,_Ee),e(_Ee,Pwr),e(Rr,Bwr),e(Rr,hn),e(hn,Iwr),e(hn,uEe),e(uEe,Nwr),e(hn,qwr),e(hn,bEe),e(bEe,jwr),e(hn,Dwr),e(hn,vEe),e(vEe,Gwr),e(hn,Owr),e(Rr,Vwr),e(Rr,se),e(se,o4),e(o4,FEe),e(FEe,Xwr),e(o4,zwr),e(o4,qY),e(qY,Wwr),e(o4,Qwr),e(se,Hwr),e(se,r4),e(r4,TEe),e(TEe,Uwr),e(r4,Jwr),e(r4,jY),e(jY,Ywr),e(r4,Kwr),e(se,Zwr),e(se,t4),e(t4,MEe),e(MEe,e6r),e(t4,o6r),e(t4,DY),e(DY,r6r),e(t4,t6r),e(se,a6r),e(se,a4),e(a4,EEe),e(EEe,n6r),e(a4,s6r),e(a4,GY),e(GY,l6r),e(a4,i6r),e(se,d6r),e(se,n4),e(n4,CEe),e(CEe,c6r),e(n4,f6r),e(n4,OY),e(OY,m6r),e(n4,g6r),e(se,h6r),e(se,s4),e(s4,wEe),e(wEe,p6r),e(s4,_6r),e(s4,VY),e(VY,u6r),e(s4,b6r),e(se,v6r),e(se,l4),e(l4,AEe),e(AEe,F6r),e(l4,T6r),e(l4,XY),e(XY,M6r),e(l4,E6r),e(se,C6r),e(se,i4),e(i4,LEe),e(LEe,w6r),e(i4,A6r),e(i4,zY),e(zY,L6r),e(i4,y6r),e(se,x6r),e(se,d4),e(d4,yEe),e(yEe,$6r),e(d4,k6r),e(d4,WY),e(WY,S6r),e(d4,R6r),e(se,P6r),e(se,c4),e(c4,xEe),e(xEe,B6r),e(c4,I6r),e(c4,QY),e(QY,N6r),e(c4,q6r),e(se,j6r),e(se,f4),e(f4,$Ee),e($Ee,D6r),e(f4,G6r),e(f4,HY),e(HY,O6r),e(f4,V6r),e(se,X6r),e(se,m4),e(m4,kEe),e(kEe,z6r),e(m4,W6r),e(m4,UY),e(UY,Q6r),e(m4,H6r),e(se,U6r),e(se,g4),e(g4,SEe),e(SEe,J6r),e(g4,Y6r),e(g4,JY),e(JY,K6r),e(g4,Z6r),e(se,eAr),e(se,h4),e(h4,REe),e(REe,oAr),e(h4,rAr),e(h4,YY),e(YY,tAr),e(h4,aAr),e(se,nAr),e(se,p4),e(p4,PEe),e(PEe,sAr),e(p4,lAr),e(p4,KY),e(KY,iAr),e(p4,dAr),e(se,cAr),e(se,_4),e(_4,BEe),e(BEe,fAr),e(_4,mAr),e(_4,ZY),e(ZY,gAr),e(_4,hAr),e(se,pAr),e(se,u4),e(u4,IEe),e(IEe,_Ar),e(u4,uAr),e(u4,eK),e(eK,bAr),e(u4,vAr),e(se,FAr),e(se,b4),e(b4,NEe),e(NEe,TAr),e(b4,MAr),e(b4,oK),e(oK,EAr),e(b4,CAr),e(se,wAr),e(se,v4),e(v4,qEe),e(qEe,AAr),e(v4,LAr),e(v4,rK),e(rK,yAr),e(v4,xAr),e(se,$Ar),e(se,F4),e(F4,jEe),e(jEe,kAr),e(F4,SAr),e(F4,tK),e(tK,RAr),e(F4,PAr),e(se,BAr),e(se,T4),e(T4,DEe),e(DEe,IAr),e(T4,NAr),e(T4,aK),e(aK,qAr),e(T4,jAr),e(se,DAr),e(se,M4),e(M4,GEe),e(GEe,GAr),e(M4,OAr),e(M4,nK),e(nK,VAr),e(M4,XAr),e(se,zAr),e(se,E4),e(E4,OEe),e(OEe,WAr),e(E4,QAr),e(E4,sK),e(sK,HAr),e(E4,UAr),e(Rr,JAr),M(C4,Rr,null),b(f,rHe,u),b(f,Ec,u),e(Ec,w4),e(w4,VEe),M(Ux,VEe,null),e(Ec,YAr),e(Ec,XEe),e(XEe,KAr),b(f,tHe,u),b(f,sr,u),M(Jx,sr,null),e(sr,ZAr),e(sr,Cc),e(Cc,e7r),e(Cc,lK),e(lK,o7r),e(Cc,r7r),e(Cc,iK),e(iK,t7r),e(Cc,a7r),e(sr,n7r),e(sr,Yx),e(Yx,s7r),e(Yx,zEe),e(zEe,l7r),e(Yx,i7r),e(sr,d7r),e(sr,qt),M(Kx,qt,null),e(qt,c7r),e(qt,WEe),e(WEe,f7r),e(qt,m7r),e(qt,wc),e(wc,g7r),e(wc,QEe),e(QEe,h7r),e(wc,p7r),e(wc,dK),e(dK,_7r),e(wc,u7r),e(qt,b7r),M(A4,qt,null),e(sr,v7r),e(sr,Pr),M(Zx,Pr,null),e(Pr,F7r),e(Pr,HEe),e(HEe,T7r),e(Pr,M7r),e(Pr,pn),e(pn,E7r),e(pn,UEe),e(UEe,C7r),e(pn,w7r),e(pn,JEe),e(JEe,A7r),e(pn,L7r),e(pn,YEe),e(YEe,y7r),e(pn,x7r),e(Pr,$7r),e(Pr,Me),e(Me,L4),e(L4,KEe),e(KEe,k7r),e(L4,S7r),e(L4,cK),e(cK,R7r),e(L4,P7r),e(Me,B7r),e(Me,y4),e(y4,ZEe),e(ZEe,I7r),e(y4,N7r),e(y4,fK),e(fK,q7r),e(y4,j7r),e(Me,D7r),e(Me,x4),e(x4,e4e),e(e4e,G7r),e(x4,O7r),e(x4,mK),e(mK,V7r),e(x4,X7r),e(Me,z7r),e(Me,$4),e($4,o4e),e(o4e,W7r),e($4,Q7r),e($4,gK),e(gK,H7r),e($4,U7r),e(Me,J7r),e(Me,k4),e(k4,r4e),e(r4e,Y7r),e(k4,K7r),e(k4,hK),e(hK,Z7r),e(k4,eLr),e(Me,oLr),e(Me,S4),e(S4,t4e),e(t4e,rLr),e(S4,tLr),e(S4,pK),e(pK,aLr),e(S4,nLr),e(Me,sLr),e(Me,R4),e(R4,a4e),e(a4e,lLr),e(R4,iLr),e(R4,_K),e(_K,dLr),e(R4,cLr),e(Me,fLr),e(Me,P4),e(P4,n4e),e(n4e,mLr),e(P4,gLr),e(P4,uK),e(uK,hLr),e(P4,pLr),e(Me,_Lr),e(Me,B4),e(B4,s4e),e(s4e,uLr),e(B4,bLr),e(B4,bK),e(bK,vLr),e(B4,FLr),e(Me,TLr),e(Me,I4),e(I4,l4e),e(l4e,MLr),e(I4,ELr),e(I4,vK),e(vK,CLr),e(I4,wLr),e(Me,ALr),e(Me,N4),e(N4,i4e),e(i4e,LLr),e(N4,yLr),e(N4,FK),e(FK,xLr),e(N4,$Lr),e(Me,kLr),e(Me,q4),e(q4,d4e),e(d4e,SLr),e(q4,RLr),e(q4,TK),e(TK,PLr),e(q4,BLr),e(Me,ILr),e(Me,j4),e(j4,c4e),e(c4e,NLr),e(j4,qLr),e(j4,MK),e(MK,jLr),e(j4,DLr),e(Pr,GLr),M(D4,Pr,null),b(f,aHe,u),b(f,Ac,u),e(Ac,G4),e(G4,f4e),M(e$,f4e,null),e(Ac,OLr),e(Ac,m4e),e(m4e,VLr),b(f,nHe,u),b(f,lr,u),M(o$,lr,null),e(lr,XLr),e(lr,Lc),e(Lc,zLr),e(Lc,EK),e(EK,WLr),e(Lc,QLr),e(Lc,CK),e(CK,HLr),e(Lc,ULr),e(lr,JLr),e(lr,r$),e(r$,YLr),e(r$,g4e),e(g4e,KLr),e(r$,ZLr),e(lr,eyr),e(lr,jt),M(t$,jt,null),e(jt,oyr),e(jt,h4e),e(h4e,ryr),e(jt,tyr),e(jt,yc),e(yc,ayr),e(yc,p4e),e(p4e,nyr),e(yc,syr),e(yc,wK),e(wK,lyr),e(yc,iyr),e(jt,dyr),M(O4,jt,null),e(lr,cyr),e(lr,Br),M(a$,Br,null),e(Br,fyr),e(Br,_4e),e(_4e,myr),e(Br,gyr),e(Br,_n),e(_n,hyr),e(_n,u4e),e(u4e,pyr),e(_n,_yr),e(_n,b4e),e(b4e,uyr),e(_n,byr),e(_n,v4e),e(v4e,vyr),e(_n,Fyr),e(Br,Tyr),e(Br,Ve),e(Ve,V4),e(V4,F4e),e(F4e,Myr),e(V4,Eyr),e(V4,AK),e(AK,Cyr),e(V4,wyr),e(Ve,Ayr),e(Ve,X4),e(X4,T4e),e(T4e,Lyr),e(X4,yyr),e(X4,LK),e(LK,xyr),e(X4,$yr),e(Ve,kyr),e(Ve,nl),e(nl,M4e),e(M4e,Syr),e(nl,Ryr),e(nl,yK),e(yK,Pyr),e(nl,Byr),e(nl,xK),e(xK,Iyr),e(nl,Nyr),e(Ve,qyr),e(Ve,z4),e(z4,E4e),e(E4e,jyr),e(z4,Dyr),e(z4,$K),e($K,Gyr),e(z4,Oyr),e(Ve,Vyr),e(Ve,W4),e(W4,C4e),e(C4e,Xyr),e(W4,zyr),e(W4,kK),e(kK,Wyr),e(W4,Qyr),e(Ve,Hyr),e(Ve,Q4),e(Q4,w4e),e(w4e,Uyr),e(Q4,Jyr),e(Q4,SK),e(SK,Yyr),e(Q4,Kyr),e(Ve,Zyr),e(Ve,H4),e(H4,A4e),e(A4e,e9r),e(H4,o9r),e(H4,RK),e(RK,r9r),e(H4,t9r),e(Ve,a9r),e(Ve,U4),e(U4,L4e),e(L4e,n9r),e(U4,s9r),e(U4,PK),e(PK,l9r),e(U4,i9r),e(Br,d9r),M(J4,Br,null),b(f,sHe,u),b(f,xc,u),e(xc,Y4),e(Y4,y4e),M(n$,y4e,null),e(xc,c9r),e(xc,x4e),e(x4e,f9r),b(f,lHe,u),b(f,ir,u),M(s$,ir,null),e(ir,m9r),e(ir,$c),e($c,g9r),e($c,BK),e(BK,h9r),e($c,p9r),e($c,IK),e(IK,_9r),e($c,u9r),e(ir,b9r),e(ir,l$),e(l$,v9r),e(l$,$4e),e($4e,F9r),e(l$,T9r),e(ir,M9r),e(ir,Dt),M(i$,Dt,null),e(Dt,E9r),e(Dt,k4e),e(k4e,C9r),e(Dt,w9r),e(Dt,kc),e(kc,A9r),e(kc,S4e),e(S4e,L9r),e(kc,y9r),e(kc,NK),e(NK,x9r),e(kc,$9r),e(Dt,k9r),M(K4,Dt,null),e(ir,S9r),e(ir,Ir),M(d$,Ir,null),e(Ir,R9r),e(Ir,R4e),e(R4e,P9r),e(Ir,B9r),e(Ir,un),e(un,I9r),e(un,P4e),e(P4e,N9r),e(un,q9r),e(un,B4e),e(B4e,j9r),e(un,D9r),e(un,I4e),e(I4e,G9r),e(un,O9r),e(Ir,V9r),e(Ir,ie),e(ie,Z4),e(Z4,N4e),e(N4e,X9r),e(Z4,z9r),e(Z4,qK),e(qK,W9r),e(Z4,Q9r),e(ie,H9r),e(ie,eC),e(eC,q4e),e(q4e,U9r),e(eC,J9r),e(eC,jK),e(jK,Y9r),e(eC,K9r),e(ie,Z9r),e(ie,oC),e(oC,j4e),e(j4e,exr),e(oC,oxr),e(oC,DK),e(DK,rxr),e(oC,txr),e(ie,axr),e(ie,rC),e(rC,D4e),e(D4e,nxr),e(rC,sxr),e(rC,GK),e(GK,lxr),e(rC,ixr),e(ie,dxr),e(ie,tC),e(tC,G4e),e(G4e,cxr),e(tC,fxr),e(tC,OK),e(OK,mxr),e(tC,gxr),e(ie,hxr),e(ie,aC),e(aC,O4e),e(O4e,pxr),e(aC,_xr),e(aC,VK),e(VK,uxr),e(aC,bxr),e(ie,vxr),e(ie,nC),e(nC,V4e),e(V4e,Fxr),e(nC,Txr),e(nC,XK),e(XK,Mxr),e(nC,Exr),e(ie,Cxr),e(ie,sC),e(sC,X4e),e(X4e,wxr),e(sC,Axr),e(sC,zK),e(zK,Lxr),e(sC,yxr),e(ie,xxr),e(ie,lC),e(lC,z4e),e(z4e,$xr),e(lC,kxr),e(lC,WK),e(WK,Sxr),e(lC,Rxr),e(ie,Pxr),e(ie,iC),e(iC,W4e),e(W4e,Bxr),e(iC,Ixr),e(iC,QK),e(QK,Nxr),e(iC,qxr),e(ie,jxr),e(ie,dC),e(dC,Q4e),e(Q4e,Dxr),e(dC,Gxr),e(dC,HK),e(HK,Oxr),e(dC,Vxr),e(ie,Xxr),e(ie,cC),e(cC,H4e),e(H4e,zxr),e(cC,Wxr),e(cC,UK),e(UK,Qxr),e(cC,Hxr),e(ie,Uxr),e(ie,fC),e(fC,U4e),e(U4e,Jxr),e(fC,Yxr),e(fC,JK),e(JK,Kxr),e(fC,Zxr),e(ie,e$r),e(ie,mC),e(mC,J4e),e(J4e,o$r),e(mC,r$r),e(mC,YK),e(YK,t$r),e(mC,a$r),e(ie,n$r),e(ie,gC),e(gC,Y4e),e(Y4e,s$r),e(gC,l$r),e(gC,KK),e(KK,i$r),e(gC,d$r),e(ie,c$r),e(ie,hC),e(hC,K4e),e(K4e,f$r),e(hC,m$r),e(hC,ZK),e(ZK,g$r),e(hC,h$r),e(ie,p$r),e(ie,pC),e(pC,Z4e),e(Z4e,_$r),e(pC,u$r),e(pC,eZ),e(eZ,b$r),e(pC,v$r),e(ie,F$r),e(ie,_C),e(_C,eCe),e(eCe,T$r),e(_C,M$r),e(_C,oZ),e(oZ,E$r),e(_C,C$r),e(ie,w$r),e(ie,uC),e(uC,oCe),e(oCe,A$r),e(uC,L$r),e(uC,rZ),e(rZ,y$r),e(uC,x$r),e(ie,$$r),e(ie,bC),e(bC,rCe),e(rCe,k$r),e(bC,S$r),e(bC,tZ),e(tZ,R$r),e(bC,P$r),e(Ir,B$r),M(vC,Ir,null),b(f,iHe,u),b(f,Sc,u),e(Sc,FC),e(FC,tCe),M(c$,tCe,null),e(Sc,I$r),e(Sc,aCe),e(aCe,N$r),b(f,dHe,u),b(f,dr,u),M(f$,dr,null),e(dr,q$r),e(dr,Rc),e(Rc,j$r),e(Rc,aZ),e(aZ,D$r),e(Rc,G$r),e(Rc,nZ),e(nZ,O$r),e(Rc,V$r),e(dr,X$r),e(dr,m$),e(m$,z$r),e(m$,nCe),e(nCe,W$r),e(m$,Q$r),e(dr,H$r),e(dr,Gt),M(g$,Gt,null),e(Gt,U$r),e(Gt,sCe),e(sCe,J$r),e(Gt,Y$r),e(Gt,Pc),e(Pc,K$r),e(Pc,lCe),e(lCe,Z$r),e(Pc,ekr),e(Pc,sZ),e(sZ,okr),e(Pc,rkr),e(Gt,tkr),M(TC,Gt,null),e(dr,akr),e(dr,Nr),M(h$,Nr,null),e(Nr,nkr),e(Nr,iCe),e(iCe,skr),e(Nr,lkr),e(Nr,bn),e(bn,ikr),e(bn,dCe),e(dCe,dkr),e(bn,ckr),e(bn,cCe),e(cCe,fkr),e(bn,mkr),e(bn,fCe),e(fCe,gkr),e(bn,hkr),e(Nr,pkr),e(Nr,xe),e(xe,MC),e(MC,mCe),e(mCe,_kr),e(MC,ukr),e(MC,lZ),e(lZ,bkr),e(MC,vkr),e(xe,Fkr),e(xe,EC),e(EC,gCe),e(gCe,Tkr),e(EC,Mkr),e(EC,iZ),e(iZ,Ekr),e(EC,Ckr),e(xe,wkr),e(xe,CC),e(CC,hCe),e(hCe,Akr),e(CC,Lkr),e(CC,dZ),e(dZ,ykr),e(CC,xkr),e(xe,$kr),e(xe,wC),e(wC,pCe),e(pCe,kkr),e(wC,Skr),e(wC,cZ),e(cZ,Rkr),e(wC,Pkr),e(xe,Bkr),e(xe,AC),e(AC,_Ce),e(_Ce,Ikr),e(AC,Nkr),e(AC,fZ),e(fZ,qkr),e(AC,jkr),e(xe,Dkr),e(xe,LC),e(LC,uCe),e(uCe,Gkr),e(LC,Okr),e(LC,mZ),e(mZ,Vkr),e(LC,Xkr),e(xe,zkr),e(xe,yC),e(yC,bCe),e(bCe,Wkr),e(yC,Qkr),e(yC,gZ),e(gZ,Hkr),e(yC,Ukr),e(xe,Jkr),e(xe,xC),e(xC,vCe),e(vCe,Ykr),e(xC,Kkr),e(xC,hZ),e(hZ,Zkr),e(xC,eSr),e(xe,oSr),e(xe,$C),e($C,FCe),e(FCe,rSr),e($C,tSr),e($C,pZ),e(pZ,aSr),e($C,nSr),e(xe,sSr),e(xe,kC),e(kC,TCe),e(TCe,lSr),e(kC,iSr),e(kC,_Z),e(_Z,dSr),e(kC,cSr),e(Nr,fSr),M(SC,Nr,null),b(f,cHe,u),b(f,Bc,u),e(Bc,RC),e(RC,MCe),M(p$,MCe,null),e(Bc,mSr),e(Bc,ECe),e(ECe,gSr),b(f,fHe,u),b(f,cr,u),M(_$,cr,null),e(cr,hSr),e(cr,Ic),e(Ic,pSr),e(Ic,uZ),e(uZ,_Sr),e(Ic,uSr),e(Ic,bZ),e(bZ,bSr),e(Ic,vSr),e(cr,FSr),e(cr,u$),e(u$,TSr),e(u$,CCe),e(CCe,MSr),e(u$,ESr),e(cr,CSr),e(cr,Ot),M(b$,Ot,null),e(Ot,wSr),e(Ot,wCe),e(wCe,ASr),e(Ot,LSr),e(Ot,Nc),e(Nc,ySr),e(Nc,ACe),e(ACe,xSr),e(Nc,$Sr),e(Nc,vZ),e(vZ,kSr),e(Nc,SSr),e(Ot,RSr),M(PC,Ot,null),e(cr,PSr),e(cr,qr),M(v$,qr,null),e(qr,BSr),e(qr,LCe),e(LCe,ISr),e(qr,NSr),e(qr,vn),e(vn,qSr),e(vn,yCe),e(yCe,jSr),e(vn,DSr),e(vn,xCe),e(xCe,GSr),e(vn,OSr),e(vn,$Ce),e($Ce,VSr),e(vn,XSr),e(qr,zSr),e(qr,ae),e(ae,BC),e(BC,kCe),e(kCe,WSr),e(BC,QSr),e(BC,FZ),e(FZ,HSr),e(BC,USr),e(ae,JSr),e(ae,IC),e(IC,SCe),e(SCe,YSr),e(IC,KSr),e(IC,TZ),e(TZ,ZSr),e(IC,eRr),e(ae,oRr),e(ae,NC),e(NC,RCe),e(RCe,rRr),e(NC,tRr),e(NC,MZ),e(MZ,aRr),e(NC,nRr),e(ae,sRr),e(ae,qC),e(qC,PCe),e(PCe,lRr),e(qC,iRr),e(qC,EZ),e(EZ,dRr),e(qC,cRr),e(ae,fRr),e(ae,jC),e(jC,BCe),e(BCe,mRr),e(jC,gRr),e(jC,CZ),e(CZ,hRr),e(jC,pRr),e(ae,_Rr),e(ae,DC),e(DC,ICe),e(ICe,uRr),e(DC,bRr),e(DC,wZ),e(wZ,vRr),e(DC,FRr),e(ae,TRr),e(ae,GC),e(GC,NCe),e(NCe,MRr),e(GC,ERr),e(GC,AZ),e(AZ,CRr),e(GC,wRr),e(ae,ARr),e(ae,OC),e(OC,qCe),e(qCe,LRr),e(OC,yRr),e(OC,LZ),e(LZ,xRr),e(OC,$Rr),e(ae,kRr),e(ae,VC),e(VC,jCe),e(jCe,SRr),e(VC,RRr),e(VC,yZ),e(yZ,PRr),e(VC,BRr),e(ae,IRr),e(ae,XC),e(XC,DCe),e(DCe,NRr),e(XC,qRr),e(XC,xZ),e(xZ,jRr),e(XC,DRr),e(ae,GRr),e(ae,zC),e(zC,GCe),e(GCe,ORr),e(zC,VRr),e(zC,$Z),e($Z,XRr),e(zC,zRr),e(ae,WRr),e(ae,WC),e(WC,OCe),e(OCe,QRr),e(WC,HRr),e(WC,kZ),e(kZ,URr),e(WC,JRr),e(ae,YRr),e(ae,QC),e(QC,VCe),e(VCe,KRr),e(QC,ZRr),e(QC,SZ),e(SZ,ePr),e(QC,oPr),e(ae,rPr),e(ae,HC),e(HC,XCe),e(XCe,tPr),e(HC,aPr),e(HC,RZ),e(RZ,nPr),e(HC,sPr),e(ae,lPr),e(ae,UC),e(UC,zCe),e(zCe,iPr),e(UC,dPr),e(UC,PZ),e(PZ,cPr),e(UC,fPr),e(ae,mPr),e(ae,JC),e(JC,WCe),e(WCe,gPr),e(JC,hPr),e(JC,BZ),e(BZ,pPr),e(JC,_Pr),e(ae,uPr),e(ae,YC),e(YC,QCe),e(QCe,bPr),e(YC,vPr),e(YC,IZ),e(IZ,FPr),e(YC,TPr),e(ae,MPr),e(ae,KC),e(KC,HCe),e(HCe,EPr),e(KC,CPr),e(KC,NZ),e(NZ,wPr),e(KC,APr),e(ae,LPr),e(ae,ZC),e(ZC,UCe),e(UCe,yPr),e(ZC,xPr),e(ZC,qZ),e(qZ,$Pr),e(ZC,kPr),e(ae,SPr),e(ae,e5),e(e5,JCe),e(JCe,RPr),e(e5,PPr),e(e5,jZ),e(jZ,BPr),e(e5,IPr),e(ae,NPr),e(ae,o5),e(o5,YCe),e(YCe,qPr),e(o5,jPr),e(o5,DZ),e(DZ,DPr),e(o5,GPr),e(ae,OPr),e(ae,r5),e(r5,KCe),e(KCe,VPr),e(r5,XPr),e(r5,GZ),e(GZ,zPr),e(r5,WPr),e(ae,QPr),e(ae,t5),e(t5,ZCe),e(ZCe,HPr),e(t5,UPr),e(t5,OZ),e(OZ,JPr),e(t5,YPr),e(ae,KPr),e(ae,a5),e(a5,e5e),e(e5e,ZPr),e(a5,eBr),e(a5,VZ),e(VZ,oBr),e(a5,rBr),e(ae,tBr),e(ae,n5),e(n5,o5e),e(o5e,aBr),e(n5,nBr),e(n5,XZ),e(XZ,sBr),e(n5,lBr),e(ae,iBr),e(ae,s5),e(s5,r5e),e(r5e,dBr),e(s5,cBr),e(s5,zZ),e(zZ,fBr),e(s5,mBr),e(qr,gBr),M(l5,qr,null),b(f,mHe,u),b(f,qc,u),e(qc,i5),e(i5,t5e),M(F$,t5e,null),e(qc,hBr),e(qc,a5e),e(a5e,pBr),b(f,gHe,u),b(f,fr,u),M(T$,fr,null),e(fr,_Br),e(fr,jc),e(jc,uBr),e(jc,WZ),e(WZ,bBr),e(jc,vBr),e(jc,QZ),e(QZ,FBr),e(jc,TBr),e(fr,MBr),e(fr,M$),e(M$,EBr),e(M$,n5e),e(n5e,CBr),e(M$,wBr),e(fr,ABr),e(fr,Vt),M(E$,Vt,null),e(Vt,LBr),e(Vt,s5e),e(s5e,yBr),e(Vt,xBr),e(Vt,Dc),e(Dc,$Br),e(Dc,l5e),e(l5e,kBr),e(Dc,SBr),e(Dc,HZ),e(HZ,RBr),e(Dc,PBr),e(Vt,BBr),M(d5,Vt,null),e(fr,IBr),e(fr,jr),M(C$,jr,null),e(jr,NBr),e(jr,i5e),e(i5e,qBr),e(jr,jBr),e(jr,Fn),e(Fn,DBr),e(Fn,d5e),e(d5e,GBr),e(Fn,OBr),e(Fn,c5e),e(c5e,VBr),e(Fn,XBr),e(Fn,f5e),e(f5e,zBr),e(Fn,WBr),e(jr,QBr),e(jr,ve),e(ve,c5),e(c5,m5e),e(m5e,HBr),e(c5,UBr),e(c5,UZ),e(UZ,JBr),e(c5,YBr),e(ve,KBr),e(ve,f5),e(f5,g5e),e(g5e,ZBr),e(f5,eIr),e(f5,JZ),e(JZ,oIr),e(f5,rIr),e(ve,tIr),e(ve,m5),e(m5,h5e),e(h5e,aIr),e(m5,nIr),e(m5,YZ),e(YZ,sIr),e(m5,lIr),e(ve,iIr),e(ve,g5),e(g5,p5e),e(p5e,dIr),e(g5,cIr),e(g5,KZ),e(KZ,fIr),e(g5,mIr),e(ve,gIr),e(ve,h5),e(h5,_5e),e(_5e,hIr),e(h5,pIr),e(h5,ZZ),e(ZZ,_Ir),e(h5,uIr),e(ve,bIr),e(ve,p5),e(p5,u5e),e(u5e,vIr),e(p5,FIr),e(p5,eee),e(eee,TIr),e(p5,MIr),e(ve,EIr),e(ve,_5),e(_5,b5e),e(b5e,CIr),e(_5,wIr),e(_5,oee),e(oee,AIr),e(_5,LIr),e(ve,yIr),e(ve,u5),e(u5,v5e),e(v5e,xIr),e(u5,$Ir),e(u5,ree),e(ree,kIr),e(u5,SIr),e(ve,RIr),e(ve,b5),e(b5,F5e),e(F5e,PIr),e(b5,BIr),e(b5,tee),e(tee,IIr),e(b5,NIr),e(ve,qIr),e(ve,v5),e(v5,T5e),e(T5e,jIr),e(v5,DIr),e(v5,aee),e(aee,GIr),e(v5,OIr),e(ve,VIr),e(ve,F5),e(F5,M5e),e(M5e,XIr),e(F5,zIr),e(F5,nee),e(nee,WIr),e(F5,QIr),e(ve,HIr),e(ve,T5),e(T5,E5e),e(E5e,UIr),e(T5,JIr),e(T5,see),e(see,YIr),e(T5,KIr),e(ve,ZIr),e(ve,M5),e(M5,C5e),e(C5e,eNr),e(M5,oNr),e(M5,lee),e(lee,rNr),e(M5,tNr),e(ve,aNr),e(ve,E5),e(E5,w5e),e(w5e,nNr),e(E5,sNr),e(E5,iee),e(iee,lNr),e(E5,iNr),e(ve,dNr),e(ve,C5),e(C5,A5e),e(A5e,cNr),e(C5,fNr),e(C5,dee),e(dee,mNr),e(C5,gNr),e(ve,hNr),e(ve,w5),e(w5,L5e),e(L5e,pNr),e(w5,_Nr),e(w5,cee),e(cee,uNr),e(w5,bNr),e(ve,vNr),e(ve,A5),e(A5,y5e),e(y5e,FNr),e(A5,TNr),e(A5,fee),e(fee,MNr),e(A5,ENr),e(jr,CNr),M(L5,jr,null),b(f,hHe,u),b(f,Gc,u),e(Gc,y5),e(y5,x5e),M(w$,x5e,null),e(Gc,wNr),e(Gc,$5e),e($5e,ANr),b(f,pHe,u),b(f,mr,u),M(A$,mr,null),e(mr,LNr),e(mr,Oc),e(Oc,yNr),e(Oc,mee),e(mee,xNr),e(Oc,$Nr),e(Oc,gee),e(gee,kNr),e(Oc,SNr),e(mr,RNr),e(mr,L$),e(L$,PNr),e(L$,k5e),e(k5e,BNr),e(L$,INr),e(mr,NNr),e(mr,Xt),M(y$,Xt,null),e(Xt,qNr),e(Xt,S5e),e(S5e,jNr),e(Xt,DNr),e(Xt,Vc),e(Vc,GNr),e(Vc,R5e),e(R5e,ONr),e(Vc,VNr),e(Vc,hee),e(hee,XNr),e(Vc,zNr),e(Xt,WNr),M(x5,Xt,null),e(mr,QNr),e(mr,Dr),M(x$,Dr,null),e(Dr,HNr),e(Dr,P5e),e(P5e,UNr),e(Dr,JNr),e(Dr,Tn),e(Tn,YNr),e(Tn,B5e),e(B5e,KNr),e(Tn,ZNr),e(Tn,I5e),e(I5e,eqr),e(Tn,oqr),e(Tn,N5e),e(N5e,rqr),e(Tn,tqr),e(Dr,aqr),e(Dr,$$),e($$,$5),e($5,q5e),e(q5e,nqr),e($5,sqr),e($5,pee),e(pee,lqr),e($5,iqr),e($$,dqr),e($$,k5),e(k5,j5e),e(j5e,cqr),e(k5,fqr),e(k5,_ee),e(_ee,mqr),e(k5,gqr),e(Dr,hqr),M(S5,Dr,null),b(f,_He,u),b(f,Xc,u),e(Xc,R5),e(R5,D5e),M(k$,D5e,null),e(Xc,pqr),e(Xc,G5e),e(G5e,_qr),b(f,uHe,u),b(f,gr,u),M(S$,gr,null),e(gr,uqr),e(gr,zc),e(zc,bqr),e(zc,uee),e(uee,vqr),e(zc,Fqr),e(zc,bee),e(bee,Tqr),e(zc,Mqr),e(gr,Eqr),e(gr,R$),e(R$,Cqr),e(R$,O5e),e(O5e,wqr),e(R$,Aqr),e(gr,Lqr),e(gr,zt),M(P$,zt,null),e(zt,yqr),e(zt,V5e),e(V5e,xqr),e(zt,$qr),e(zt,Wc),e(Wc,kqr),e(Wc,X5e),e(X5e,Sqr),e(Wc,Rqr),e(Wc,vee),e(vee,Pqr),e(Wc,Bqr),e(zt,Iqr),M(P5,zt,null),e(gr,Nqr),e(gr,Gr),M(B$,Gr,null),e(Gr,qqr),e(Gr,z5e),e(z5e,jqr),e(Gr,Dqr),e(Gr,Mn),e(Mn,Gqr),e(Mn,W5e),e(W5e,Oqr),e(Mn,Vqr),e(Mn,Q5e),e(Q5e,Xqr),e(Mn,zqr),e(Mn,H5e),e(H5e,Wqr),e(Mn,Qqr),e(Gr,Hqr),e(Gr,U5e),e(U5e,B5),e(B5,J5e),e(J5e,Uqr),e(B5,Jqr),e(B5,Fee),e(Fee,Yqr),e(B5,Kqr),e(Gr,Zqr),M(I5,Gr,null),b(f,bHe,u),b(f,Qc,u),e(Qc,N5),e(N5,Y5e),M(I$,Y5e,null),e(Qc,ejr),e(Qc,K5e),e(K5e,ojr),b(f,vHe,u),b(f,hr,u),M(N$,hr,null),e(hr,rjr),e(hr,Hc),e(Hc,tjr),e(Hc,Tee),e(Tee,ajr),e(Hc,njr),e(Hc,Mee),e(Mee,sjr),e(Hc,ljr),e(hr,ijr),e(hr,q$),e(q$,djr),e(q$,Z5e),e(Z5e,cjr),e(q$,fjr),e(hr,mjr),e(hr,Wt),M(j$,Wt,null),e(Wt,gjr),e(Wt,e3e),e(e3e,hjr),e(Wt,pjr),e(Wt,Uc),e(Uc,_jr),e(Uc,o3e),e(o3e,ujr),e(Uc,bjr),e(Uc,Eee),e(Eee,vjr),e(Uc,Fjr),e(Wt,Tjr),M(q5,Wt,null),e(hr,Mjr),e(hr,Or),M(D$,Or,null),e(Or,Ejr),e(Or,r3e),e(r3e,Cjr),e(Or,wjr),e(Or,En),e(En,Ajr),e(En,t3e),e(t3e,Ljr),e(En,yjr),e(En,a3e),e(a3e,xjr),e(En,$jr),e(En,n3e),e(n3e,kjr),e(En,Sjr),e(Or,Rjr),e(Or,de),e(de,j5),e(j5,s3e),e(s3e,Pjr),e(j5,Bjr),e(j5,Cee),e(Cee,Ijr),e(j5,Njr),e(de,qjr),e(de,D5),e(D5,l3e),e(l3e,jjr),e(D5,Djr),e(D5,wee),e(wee,Gjr),e(D5,Ojr),e(de,Vjr),e(de,G5),e(G5,i3e),e(i3e,Xjr),e(G5,zjr),e(G5,Aee),e(Aee,Wjr),e(G5,Qjr),e(de,Hjr),e(de,O5),e(O5,d3e),e(d3e,Ujr),e(O5,Jjr),e(O5,Lee),e(Lee,Yjr),e(O5,Kjr),e(de,Zjr),e(de,V5),e(V5,c3e),e(c3e,eDr),e(V5,oDr),e(V5,yee),e(yee,rDr),e(V5,tDr),e(de,aDr),e(de,X5),e(X5,f3e),e(f3e,nDr),e(X5,sDr),e(X5,xee),e(xee,lDr),e(X5,iDr),e(de,dDr),e(de,z5),e(z5,m3e),e(m3e,cDr),e(z5,fDr),e(z5,$ee),e($ee,mDr),e(z5,gDr),e(de,hDr),e(de,W5),e(W5,g3e),e(g3e,pDr),e(W5,_Dr),e(W5,kee),e(kee,uDr),e(W5,bDr),e(de,vDr),e(de,Q5),e(Q5,h3e),e(h3e,FDr),e(Q5,TDr),e(Q5,See),e(See,MDr),e(Q5,EDr),e(de,CDr),e(de,H5),e(H5,p3e),e(p3e,wDr),e(H5,ADr),e(H5,Ree),e(Ree,LDr),e(H5,yDr),e(de,xDr),e(de,U5),e(U5,_3e),e(_3e,$Dr),e(U5,kDr),e(U5,Pee),e(Pee,SDr),e(U5,RDr),e(de,PDr),e(de,J5),e(J5,u3e),e(u3e,BDr),e(J5,IDr),e(J5,Bee),e(Bee,NDr),e(J5,qDr),e(de,jDr),e(de,Y5),e(Y5,b3e),e(b3e,DDr),e(Y5,GDr),e(Y5,Iee),e(Iee,ODr),e(Y5,VDr),e(de,XDr),e(de,K5),e(K5,v3e),e(v3e,zDr),e(K5,WDr),e(K5,Nee),e(Nee,QDr),e(K5,HDr),e(de,UDr),e(de,Z5),e(Z5,F3e),e(F3e,JDr),e(Z5,YDr),e(Z5,qee),e(qee,KDr),e(Z5,ZDr),e(de,eGr),e(de,e3),e(e3,T3e),e(T3e,oGr),e(e3,rGr),e(e3,jee),e(jee,tGr),e(e3,aGr),e(de,nGr),e(de,o3),e(o3,M3e),e(M3e,sGr),e(o3,lGr),e(o3,Dee),e(Dee,iGr),e(o3,dGr),e(de,cGr),e(de,r3),e(r3,E3e),e(E3e,fGr),e(r3,mGr),e(r3,Gee),e(Gee,gGr),e(r3,hGr),e(de,pGr),e(de,t3),e(t3,C3e),e(C3e,_Gr),e(t3,uGr),e(t3,Oee),e(Oee,bGr),e(t3,vGr),e(de,FGr),e(de,a3),e(a3,w3e),e(w3e,TGr),e(a3,MGr),e(a3,Vee),e(Vee,EGr),e(a3,CGr),e(Or,wGr),M(n3,Or,null),b(f,FHe,u),b(f,Jc,u),e(Jc,s3),e(s3,A3e),M(G$,A3e,null),e(Jc,AGr),e(Jc,L3e),e(L3e,LGr),b(f,THe,u),b(f,pr,u),M(O$,pr,null),e(pr,yGr),e(pr,Yc),e(Yc,xGr),e(Yc,Xee),e(Xee,$Gr),e(Yc,kGr),e(Yc,zee),e(zee,SGr),e(Yc,RGr),e(pr,PGr),e(pr,V$),e(V$,BGr),e(V$,y3e),e(y3e,IGr),e(V$,NGr),e(pr,qGr),e(pr,Qt),M(X$,Qt,null),e(Qt,jGr),e(Qt,x3e),e(x3e,DGr),e(Qt,GGr),e(Qt,Kc),e(Kc,OGr),e(Kc,$3e),e($3e,VGr),e(Kc,XGr),e(Kc,Wee),e(Wee,zGr),e(Kc,WGr),e(Qt,QGr),M(l3,Qt,null),e(pr,HGr),e(pr,Vr),M(z$,Vr,null),e(Vr,UGr),e(Vr,k3e),e(k3e,JGr),e(Vr,YGr),e(Vr,Cn),e(Cn,KGr),e(Cn,S3e),e(S3e,ZGr),e(Cn,eOr),e(Cn,R3e),e(R3e,oOr),e(Cn,rOr),e(Cn,P3e),e(P3e,tOr),e(Cn,aOr),e(Vr,nOr),e(Vr,ce),e(ce,i3),e(i3,B3e),e(B3e,sOr),e(i3,lOr),e(i3,Qee),e(Qee,iOr),e(i3,dOr),e(ce,cOr),e(ce,d3),e(d3,I3e),e(I3e,fOr),e(d3,mOr),e(d3,Hee),e(Hee,gOr),e(d3,hOr),e(ce,pOr),e(ce,c3),e(c3,N3e),e(N3e,_Or),e(c3,uOr),e(c3,Uee),e(Uee,bOr),e(c3,vOr),e(ce,FOr),e(ce,f3),e(f3,q3e),e(q3e,TOr),e(f3,MOr),e(f3,Jee),e(Jee,EOr),e(f3,COr),e(ce,wOr),e(ce,m3),e(m3,j3e),e(j3e,AOr),e(m3,LOr),e(m3,Yee),e(Yee,yOr),e(m3,xOr),e(ce,$Or),e(ce,g3),e(g3,D3e),e(D3e,kOr),e(g3,SOr),e(g3,Kee),e(Kee,ROr),e(g3,POr),e(ce,BOr),e(ce,h3),e(h3,G3e),e(G3e,IOr),e(h3,NOr),e(h3,Zee),e(Zee,qOr),e(h3,jOr),e(ce,DOr),e(ce,p3),e(p3,O3e),e(O3e,GOr),e(p3,OOr),e(p3,eoe),e(eoe,VOr),e(p3,XOr),e(ce,zOr),e(ce,_3),e(_3,V3e),e(V3e,WOr),e(_3,QOr),e(_3,ooe),e(ooe,HOr),e(_3,UOr),e(ce,JOr),e(ce,u3),e(u3,X3e),e(X3e,YOr),e(u3,KOr),e(u3,roe),e(roe,ZOr),e(u3,eVr),e(ce,oVr),e(ce,b3),e(b3,z3e),e(z3e,rVr),e(b3,tVr),e(b3,toe),e(toe,aVr),e(b3,nVr),e(ce,sVr),e(ce,v3),e(v3,W3e),e(W3e,lVr),e(v3,iVr),e(v3,aoe),e(aoe,dVr),e(v3,cVr),e(ce,fVr),e(ce,F3),e(F3,Q3e),e(Q3e,mVr),e(F3,gVr),e(F3,noe),e(noe,hVr),e(F3,pVr),e(ce,_Vr),e(ce,T3),e(T3,H3e),e(H3e,uVr),e(T3,bVr),e(T3,soe),e(soe,vVr),e(T3,FVr),e(ce,TVr),e(ce,M3),e(M3,U3e),e(U3e,MVr),e(M3,EVr),e(M3,loe),e(loe,CVr),e(M3,wVr),e(ce,AVr),e(ce,E3),e(E3,J3e),e(J3e,LVr),e(E3,yVr),e(E3,ioe),e(ioe,xVr),e(E3,$Vr),e(ce,kVr),e(ce,C3),e(C3,Y3e),e(Y3e,SVr),e(C3,RVr),e(C3,doe),e(doe,PVr),e(C3,BVr),e(ce,IVr),e(ce,w3),e(w3,K3e),e(K3e,NVr),e(w3,qVr),e(w3,coe),e(coe,jVr),e(w3,DVr),e(ce,GVr),e(ce,A3),e(A3,Z3e),e(Z3e,OVr),e(A3,VVr),e(A3,foe),e(foe,XVr),e(A3,zVr),e(ce,WVr),e(ce,L3),e(L3,ewe),e(ewe,QVr),e(L3,HVr),e(L3,moe),e(moe,UVr),e(L3,JVr),e(Vr,YVr),M(y3,Vr,null),b(f,MHe,u),b(f,Zc,u),e(Zc,x3),e(x3,owe),M(W$,owe,null),e(Zc,KVr),e(Zc,rwe),e(rwe,ZVr),b(f,EHe,u),b(f,_r,u),M(Q$,_r,null),e(_r,eXr),e(_r,ef),e(ef,oXr),e(ef,goe),e(goe,rXr),e(ef,tXr),e(ef,hoe),e(hoe,aXr),e(ef,nXr),e(_r,sXr),e(_r,H$),e(H$,lXr),e(H$,twe),e(twe,iXr),e(H$,dXr),e(_r,cXr),e(_r,Ht),M(U$,Ht,null),e(Ht,fXr),e(Ht,awe),e(awe,mXr),e(Ht,gXr),e(Ht,of),e(of,hXr),e(of,nwe),e(nwe,pXr),e(of,_Xr),e(of,poe),e(poe,uXr),e(of,bXr),e(Ht,vXr),M($3,Ht,null),e(_r,FXr),e(_r,Xr),M(J$,Xr,null),e(Xr,TXr),e(Xr,swe),e(swe,MXr),e(Xr,EXr),e(Xr,wn),e(wn,CXr),e(wn,lwe),e(lwe,wXr),e(wn,AXr),e(wn,iwe),e(iwe,LXr),e(wn,yXr),e(wn,dwe),e(dwe,xXr),e(wn,$Xr),e(Xr,kXr),e(Xr,cwe),e(cwe,k3),e(k3,fwe),e(fwe,SXr),e(k3,RXr),e(k3,_oe),e(_oe,PXr),e(k3,BXr),e(Xr,IXr),M(S3,Xr,null),b(f,CHe,u),b(f,rf,u),e(rf,R3),e(R3,mwe),M(Y$,mwe,null),e(rf,NXr),e(rf,gwe),e(gwe,qXr),b(f,wHe,u),b(f,ur,u),M(K$,ur,null),e(ur,jXr),e(ur,tf),e(tf,DXr),e(tf,uoe),e(uoe,GXr),e(tf,OXr),e(tf,boe),e(boe,VXr),e(tf,XXr),e(ur,zXr),e(ur,Z$),e(Z$,WXr),e(Z$,hwe),e(hwe,QXr),e(Z$,HXr),e(ur,UXr),e(ur,Ut),M(ek,Ut,null),e(Ut,JXr),e(Ut,pwe),e(pwe,YXr),e(Ut,KXr),e(Ut,af),e(af,ZXr),e(af,_we),e(_we,ezr),e(af,ozr),e(af,voe),e(voe,rzr),e(af,tzr),e(Ut,azr),M(P3,Ut,null),e(ur,nzr),e(ur,zr),M(ok,zr,null),e(zr,szr),e(zr,uwe),e(uwe,lzr),e(zr,izr),e(zr,An),e(An,dzr),e(An,bwe),e(bwe,czr),e(An,fzr),e(An,vwe),e(vwe,mzr),e(An,gzr),e(An,Fwe),e(Fwe,hzr),e(An,pzr),e(zr,_zr),e(zr,Twe),e(Twe,B3),e(B3,Mwe),e(Mwe,uzr),e(B3,bzr),e(B3,Foe),e(Foe,vzr),e(B3,Fzr),e(zr,Tzr),M(I3,zr,null),b(f,AHe,u),b(f,nf,u),e(nf,N3),e(N3,Ewe),M(rk,Ewe,null),e(nf,Mzr),e(nf,Cwe),e(Cwe,Ezr),b(f,LHe,u),b(f,br,u),M(tk,br,null),e(br,Czr),e(br,sf),e(sf,wzr),e(sf,Toe),e(Toe,Azr),e(sf,Lzr),e(sf,Moe),e(Moe,yzr),e(sf,xzr),e(br,$zr),e(br,ak),e(ak,kzr),e(ak,wwe),e(wwe,Szr),e(ak,Rzr),e(br,Pzr),e(br,Jt),M(nk,Jt,null),e(Jt,Bzr),e(Jt,Awe),e(Awe,Izr),e(Jt,Nzr),e(Jt,lf),e(lf,qzr),e(lf,Lwe),e(Lwe,jzr),e(lf,Dzr),e(lf,Eoe),e(Eoe,Gzr),e(lf,Ozr),e(Jt,Vzr),M(q3,Jt,null),e(br,Xzr),e(br,Wr),M(sk,Wr,null),e(Wr,zzr),e(Wr,ywe),e(ywe,Wzr),e(Wr,Qzr),e(Wr,Ln),e(Ln,Hzr),e(Ln,xwe),e(xwe,Uzr),e(Ln,Jzr),e(Ln,$we),e($we,Yzr),e(Ln,Kzr),e(Ln,kwe),e(kwe,Zzr),e(Ln,eWr),e(Wr,oWr),e(Wr,oe),e(oe,j3),e(j3,Swe),e(Swe,rWr),e(j3,tWr),e(j3,Coe),e(Coe,aWr),e(j3,nWr),e(oe,sWr),e(oe,D3),e(D3,Rwe),e(Rwe,lWr),e(D3,iWr),e(D3,woe),e(woe,dWr),e(D3,cWr),e(oe,fWr),e(oe,G3),e(G3,Pwe),e(Pwe,mWr),e(G3,gWr),e(G3,Aoe),e(Aoe,hWr),e(G3,pWr),e(oe,_Wr),e(oe,O3),e(O3,Bwe),e(Bwe,uWr),e(O3,bWr),e(O3,Loe),e(Loe,vWr),e(O3,FWr),e(oe,TWr),e(oe,V3),e(V3,Iwe),e(Iwe,MWr),e(V3,EWr),e(V3,yoe),e(yoe,CWr),e(V3,wWr),e(oe,AWr),e(oe,X3),e(X3,Nwe),e(Nwe,LWr),e(X3,yWr),e(X3,xoe),e(xoe,xWr),e(X3,$Wr),e(oe,kWr),e(oe,z3),e(z3,qwe),e(qwe,SWr),e(z3,RWr),e(z3,$oe),e($oe,PWr),e(z3,BWr),e(oe,IWr),e(oe,W3),e(W3,jwe),e(jwe,NWr),e(W3,qWr),e(W3,koe),e(koe,jWr),e(W3,DWr),e(oe,GWr),e(oe,Q3),e(Q3,Dwe),e(Dwe,OWr),e(Q3,VWr),e(Q3,Soe),e(Soe,XWr),e(Q3,zWr),e(oe,WWr),e(oe,H3),e(H3,Gwe),e(Gwe,QWr),e(H3,HWr),e(H3,Roe),e(Roe,UWr),e(H3,JWr),e(oe,YWr),e(oe,U3),e(U3,Owe),e(Owe,KWr),e(U3,ZWr),e(U3,Poe),e(Poe,eQr),e(U3,oQr),e(oe,rQr),e(oe,J3),e(J3,Vwe),e(Vwe,tQr),e(J3,aQr),e(J3,Boe),e(Boe,nQr),e(J3,sQr),e(oe,lQr),e(oe,Y3),e(Y3,Xwe),e(Xwe,iQr),e(Y3,dQr),e(Y3,Ioe),e(Ioe,cQr),e(Y3,fQr),e(oe,mQr),e(oe,K3),e(K3,zwe),e(zwe,gQr),e(K3,hQr),e(K3,Noe),e(Noe,pQr),e(K3,_Qr),e(oe,uQr),e(oe,Z3),e(Z3,Wwe),e(Wwe,bQr),e(Z3,vQr),e(Z3,qoe),e(qoe,FQr),e(Z3,TQr),e(oe,MQr),e(oe,ew),e(ew,Qwe),e(Qwe,EQr),e(ew,CQr),e(ew,joe),e(joe,wQr),e(ew,AQr),e(oe,LQr),e(oe,ow),e(ow,Hwe),e(Hwe,yQr),e(ow,xQr),e(ow,Doe),e(Doe,$Qr),e(ow,kQr),e(oe,SQr),e(oe,rw),e(rw,Uwe),e(Uwe,RQr),e(rw,PQr),e(rw,Goe),e(Goe,BQr),e(rw,IQr),e(oe,NQr),e(oe,tw),e(tw,Jwe),e(Jwe,qQr),e(tw,jQr),e(tw,Ooe),e(Ooe,DQr),e(tw,GQr),e(oe,OQr),e(oe,aw),e(aw,Ywe),e(Ywe,VQr),e(aw,XQr),e(aw,Voe),e(Voe,zQr),e(aw,WQr),e(oe,QQr),e(oe,nw),e(nw,Kwe),e(Kwe,HQr),e(nw,UQr),e(nw,Xoe),e(Xoe,JQr),e(nw,YQr),e(oe,KQr),e(oe,sw),e(sw,Zwe),e(Zwe,ZQr),e(sw,eHr),e(sw,zoe),e(zoe,oHr),e(sw,rHr),e(oe,tHr),e(oe,lw),e(lw,e6e),e(e6e,aHr),e(lw,nHr),e(lw,Woe),e(Woe,sHr),e(lw,lHr),e(oe,iHr),e(oe,iw),e(iw,o6e),e(o6e,dHr),e(iw,cHr),e(iw,Qoe),e(Qoe,fHr),e(iw,mHr),e(oe,gHr),e(oe,dw),e(dw,r6e),e(r6e,hHr),e(dw,pHr),e(dw,Hoe),e(Hoe,_Hr),e(dw,uHr),e(oe,bHr),e(oe,cw),e(cw,t6e),e(t6e,vHr),e(cw,FHr),e(cw,Uoe),e(Uoe,THr),e(cw,MHr),e(oe,EHr),e(oe,fw),e(fw,a6e),e(a6e,CHr),e(fw,wHr),e(fw,Joe),e(Joe,AHr),e(fw,LHr),e(oe,yHr),e(oe,mw),e(mw,n6e),e(n6e,xHr),e(mw,$Hr),e(mw,Yoe),e(Yoe,kHr),e(mw,SHr),e(Wr,RHr),M(gw,Wr,null),b(f,yHe,u),b(f,df,u),e(df,hw),e(hw,s6e),M(lk,s6e,null),e(df,PHr),e(df,l6e),e(l6e,BHr),b(f,xHe,u),b(f,vr,u),M(ik,vr,null),e(vr,IHr),e(vr,cf),e(cf,NHr),e(cf,Koe),e(Koe,qHr),e(cf,jHr),e(cf,Zoe),e(Zoe,DHr),e(cf,GHr),e(vr,OHr),e(vr,dk),e(dk,VHr),e(dk,i6e),e(i6e,XHr),e(dk,zHr),e(vr,WHr),e(vr,Yt),M(ck,Yt,null),e(Yt,QHr),e(Yt,d6e),e(d6e,HHr),e(Yt,UHr),e(Yt,ff),e(ff,JHr),e(ff,c6e),e(c6e,YHr),e(ff,KHr),e(ff,ere),e(ere,ZHr),e(ff,eUr),e(Yt,oUr),M(pw,Yt,null),e(vr,rUr),e(vr,Qr),M(fk,Qr,null),e(Qr,tUr),e(Qr,f6e),e(f6e,aUr),e(Qr,nUr),e(Qr,yn),e(yn,sUr),e(yn,m6e),e(m6e,lUr),e(yn,iUr),e(yn,g6e),e(g6e,dUr),e(yn,cUr),e(yn,h6e),e(h6e,fUr),e(yn,mUr),e(Qr,gUr),e(Qr,Ae),e(Ae,_w),e(_w,p6e),e(p6e,hUr),e(_w,pUr),e(_w,ore),e(ore,_Ur),e(_w,uUr),e(Ae,bUr),e(Ae,uw),e(uw,_6e),e(_6e,vUr),e(uw,FUr),e(uw,rre),e(rre,TUr),e(uw,MUr),e(Ae,EUr),e(Ae,bw),e(bw,u6e),e(u6e,CUr),e(bw,wUr),e(bw,tre),e(tre,AUr),e(bw,LUr),e(Ae,yUr),e(Ae,vw),e(vw,b6e),e(b6e,xUr),e(vw,$Ur),e(vw,are),e(are,kUr),e(vw,SUr),e(Ae,RUr),e(Ae,Fw),e(Fw,v6e),e(v6e,PUr),e(Fw,BUr),e(Fw,nre),e(nre,IUr),e(Fw,NUr),e(Ae,qUr),e(Ae,Tw),e(Tw,F6e),e(F6e,jUr),e(Tw,DUr),e(Tw,sre),e(sre,GUr),e(Tw,OUr),e(Ae,VUr),e(Ae,Mw),e(Mw,T6e),e(T6e,XUr),e(Mw,zUr),e(Mw,lre),e(lre,WUr),e(Mw,QUr),e(Ae,HUr),e(Ae,Ew),e(Ew,M6e),e(M6e,UUr),e(Ew,JUr),e(Ew,ire),e(ire,YUr),e(Ew,KUr),e(Ae,ZUr),e(Ae,Cw),e(Cw,E6e),e(E6e,eJr),e(Cw,oJr),e(Cw,dre),e(dre,rJr),e(Cw,tJr),e(Ae,aJr),e(Ae,ww),e(ww,C6e),e(C6e,nJr),e(ww,sJr),e(ww,cre),e(cre,lJr),e(ww,iJr),e(Ae,dJr),e(Ae,Aw),e(Aw,w6e),e(w6e,cJr),e(Aw,fJr),e(Aw,fre),e(fre,mJr),e(Aw,gJr),e(Qr,hJr),M(Lw,Qr,null),b(f,$He,u),b(f,mf,u),e(mf,yw),e(yw,A6e),M(mk,A6e,null),e(mf,pJr),e(mf,L6e),e(L6e,_Jr),b(f,kHe,u),b(f,Fr,u),M(gk,Fr,null),e(Fr,uJr),e(Fr,gf),e(gf,bJr),e(gf,mre),e(mre,vJr),e(gf,FJr),e(gf,gre),e(gre,TJr),e(gf,MJr),e(Fr,EJr),e(Fr,hk),e(hk,CJr),e(hk,y6e),e(y6e,wJr),e(hk,AJr),e(Fr,LJr),e(Fr,Kt),M(pk,Kt,null),e(Kt,yJr),e(Kt,x6e),e(x6e,xJr),e(Kt,$Jr),e(Kt,hf),e(hf,kJr),e(hf,$6e),e($6e,SJr),e(hf,RJr),e(hf,hre),e(hre,PJr),e(hf,BJr),e(Kt,IJr),M(xw,Kt,null),e(Fr,NJr),e(Fr,Hr),M(_k,Hr,null),e(Hr,qJr),e(Hr,k6e),e(k6e,jJr),e(Hr,DJr),e(Hr,xn),e(xn,GJr),e(xn,S6e),e(S6e,OJr),e(xn,VJr),e(xn,R6e),e(R6e,XJr),e(xn,zJr),e(xn,P6e),e(P6e,WJr),e(xn,QJr),e(Hr,HJr),e(Hr,Ee),e(Ee,$w),e($w,B6e),e(B6e,UJr),e($w,JJr),e($w,pre),e(pre,YJr),e($w,KJr),e(Ee,ZJr),e(Ee,kw),e(kw,I6e),e(I6e,eYr),e(kw,oYr),e(kw,_re),e(_re,rYr),e(kw,tYr),e(Ee,aYr),e(Ee,Sw),e(Sw,N6e),e(N6e,nYr),e(Sw,sYr),e(Sw,ure),e(ure,lYr),e(Sw,iYr),e(Ee,dYr),e(Ee,Rw),e(Rw,q6e),e(q6e,cYr),e(Rw,fYr),e(Rw,bre),e(bre,mYr),e(Rw,gYr),e(Ee,hYr),e(Ee,Pw),e(Pw,j6e),e(j6e,pYr),e(Pw,_Yr),e(Pw,vre),e(vre,uYr),e(Pw,bYr),e(Ee,vYr),e(Ee,Bw),e(Bw,D6e),e(D6e,FYr),e(Bw,TYr),e(Bw,Fre),e(Fre,MYr),e(Bw,EYr),e(Ee,CYr),e(Ee,Iw),e(Iw,G6e),e(G6e,wYr),e(Iw,AYr),e(Iw,Tre),e(Tre,LYr),e(Iw,yYr),e(Ee,xYr),e(Ee,Nw),e(Nw,O6e),e(O6e,$Yr),e(Nw,kYr),e(Nw,Mre),e(Mre,SYr),e(Nw,RYr),e(Ee,PYr),e(Ee,qw),e(qw,V6e),e(V6e,BYr),e(qw,IYr),e(qw,Ere),e(Ere,NYr),e(qw,qYr),e(Ee,jYr),e(Ee,jw),e(jw,X6e),e(X6e,DYr),e(jw,GYr),e(jw,Cre),e(Cre,OYr),e(jw,VYr),e(Ee,XYr),e(Ee,Dw),e(Dw,z6e),e(z6e,zYr),e(Dw,WYr),e(Dw,wre),e(wre,QYr),e(Dw,HYr),e(Ee,UYr),e(Ee,Gw),e(Gw,W6e),e(W6e,JYr),e(Gw,YYr),e(Gw,Are),e(Are,KYr),e(Gw,ZYr),e(Ee,eKr),e(Ee,Ow),e(Ow,Q6e),e(Q6e,oKr),e(Ow,rKr),e(Ow,Lre),e(Lre,tKr),e(Ow,aKr),e(Hr,nKr),M(Vw,Hr,null),b(f,SHe,u),b(f,pf,u),e(pf,Xw),e(Xw,H6e),M(uk,H6e,null),e(pf,sKr),e(pf,U6e),e(U6e,lKr),b(f,RHe,u),b(f,Tr,u),M(bk,Tr,null),e(Tr,iKr),e(Tr,_f),e(_f,dKr),e(_f,yre),e(yre,cKr),e(_f,fKr),e(_f,xre),e(xre,mKr),e(_f,gKr),e(Tr,hKr),e(Tr,vk),e(vk,pKr),e(vk,J6e),e(J6e,_Kr),e(vk,uKr),e(Tr,bKr),e(Tr,Zt),M(Fk,Zt,null),e(Zt,vKr),e(Zt,Y6e),e(Y6e,FKr),e(Zt,TKr),e(Zt,uf),e(uf,MKr),e(uf,K6e),e(K6e,EKr),e(uf,CKr),e(uf,$re),e($re,wKr),e(uf,AKr),e(Zt,LKr),M(zw,Zt,null),e(Tr,yKr),e(Tr,Ur),M(Tk,Ur,null),e(Ur,xKr),e(Ur,Z6e),e(Z6e,$Kr),e(Ur,kKr),e(Ur,$n),e($n,SKr),e($n,eAe),e(eAe,RKr),e($n,PKr),e($n,oAe),e(oAe,BKr),e($n,IKr),e($n,rAe),e(rAe,NKr),e($n,qKr),e(Ur,jKr),e(Ur,$e),e($e,Ww),e(Ww,tAe),e(tAe,DKr),e(Ww,GKr),e(Ww,kre),e(kre,OKr),e(Ww,VKr),e($e,XKr),e($e,Qw),e(Qw,aAe),e(aAe,zKr),e(Qw,WKr),e(Qw,Sre),e(Sre,QKr),e(Qw,HKr),e($e,UKr),e($e,Hw),e(Hw,nAe),e(nAe,JKr),e(Hw,YKr),e(Hw,Rre),e(Rre,KKr),e(Hw,ZKr),e($e,eZr),e($e,Uw),e(Uw,sAe),e(sAe,oZr),e(Uw,rZr),e(Uw,Pre),e(Pre,tZr),e(Uw,aZr),e($e,nZr),e($e,Jw),e(Jw,lAe),e(lAe,sZr),e(Jw,lZr),e(Jw,Bre),e(Bre,iZr),e(Jw,dZr),e($e,cZr),e($e,Yw),e(Yw,iAe),e(iAe,fZr),e(Yw,mZr),e(Yw,Ire),e(Ire,gZr),e(Yw,hZr),e($e,pZr),e($e,Kw),e(Kw,dAe),e(dAe,_Zr),e(Kw,uZr),e(Kw,Nre),e(Nre,bZr),e(Kw,vZr),e($e,FZr),e($e,Zw),e(Zw,cAe),e(cAe,TZr),e(Zw,MZr),e(Zw,qre),e(qre,EZr),e(Zw,CZr),e($e,wZr),e($e,e6),e(e6,fAe),e(fAe,AZr),e(e6,LZr),e(e6,jre),e(jre,yZr),e(e6,xZr),e($e,$Zr),e($e,o6),e(o6,mAe),e(mAe,kZr),e(o6,SZr),e(o6,Dre),e(Dre,RZr),e(o6,PZr),e(Ur,BZr),M(r6,Ur,null),b(f,PHe,u),b(f,bf,u),e(bf,t6),e(t6,gAe),M(Mk,gAe,null),e(bf,IZr),e(bf,hAe),e(hAe,NZr),b(f,BHe,u),b(f,Mr,u),M(Ek,Mr,null),e(Mr,qZr),e(Mr,vf),e(vf,jZr),e(vf,Gre),e(Gre,DZr),e(vf,GZr),e(vf,Ore),e(Ore,OZr),e(vf,VZr),e(Mr,XZr),e(Mr,Ck),e(Ck,zZr),e(Ck,pAe),e(pAe,WZr),e(Ck,QZr),e(Mr,HZr),e(Mr,ea),M(wk,ea,null),e(ea,UZr),e(ea,_Ae),e(_Ae,JZr),e(ea,YZr),e(ea,Ff),e(Ff,KZr),e(Ff,uAe),e(uAe,ZZr),e(Ff,eet),e(Ff,Vre),e(Vre,oet),e(Ff,ret),e(ea,tet),M(a6,ea,null),e(Mr,aet),e(Mr,Jr),M(Ak,Jr,null),e(Jr,net),e(Jr,bAe),e(bAe,set),e(Jr,iet),e(Jr,kn),e(kn,det),e(kn,vAe),e(vAe,cet),e(kn,fet),e(kn,FAe),e(FAe,met),e(kn,get),e(kn,TAe),e(TAe,het),e(kn,pet),e(Jr,_et),e(Jr,ke),e(ke,n6),e(n6,MAe),e(MAe,uet),e(n6,bet),e(n6,Xre),e(Xre,vet),e(n6,Fet),e(ke,Tet),e(ke,s6),e(s6,EAe),e(EAe,Met),e(s6,Eet),e(s6,zre),e(zre,Cet),e(s6,wet),e(ke,Aet),e(ke,l6),e(l6,CAe),e(CAe,Let),e(l6,yet),e(l6,Wre),e(Wre,xet),e(l6,$et),e(ke,ket),e(ke,i6),e(i6,wAe),e(wAe,Set),e(i6,Ret),e(i6,Qre),e(Qre,Pet),e(i6,Bet),e(ke,Iet),e(ke,d6),e(d6,AAe),e(AAe,Net),e(d6,qet),e(d6,Hre),e(Hre,jet),e(d6,Det),e(ke,Get),e(ke,c6),e(c6,LAe),e(LAe,Oet),e(c6,Vet),e(c6,Ure),e(Ure,Xet),e(c6,zet),e(ke,Wet),e(ke,f6),e(f6,yAe),e(yAe,Qet),e(f6,Het),e(f6,Jre),e(Jre,Uet),e(f6,Jet),e(ke,Yet),e(ke,m6),e(m6,xAe),e(xAe,Ket),e(m6,Zet),e(m6,Yre),e(Yre,eot),e(m6,oot),e(ke,rot),e(ke,g6),e(g6,$Ae),e($Ae,tot),e(g6,aot),e(g6,Kre),e(Kre,not),e(g6,sot),e(ke,lot),e(ke,h6),e(h6,kAe),e(kAe,iot),e(h6,dot),e(h6,Zre),e(Zre,cot),e(h6,fot),e(Jr,mot),M(p6,Jr,null),b(f,IHe,u),b(f,Tf,u),e(Tf,_6),e(_6,SAe),M(Lk,SAe,null),e(Tf,got),e(Tf,RAe),e(RAe,hot),b(f,NHe,u),b(f,Er,u),M(yk,Er,null),e(Er,pot),e(Er,Mf),e(Mf,_ot),e(Mf,ete),e(ete,uot),e(Mf,bot),e(Mf,ote),e(ote,vot),e(Mf,Fot),e(Er,Tot),e(Er,xk),e(xk,Mot),e(xk,PAe),e(PAe,Eot),e(xk,Cot),e(Er,wot),e(Er,oa),M($k,oa,null),e(oa,Aot),e(oa,BAe),e(BAe,Lot),e(oa,yot),e(oa,Ef),e(Ef,xot),e(Ef,IAe),e(IAe,$ot),e(Ef,kot),e(Ef,rte),e(rte,Sot),e(Ef,Rot),e(oa,Pot),M(u6,oa,null),e(Er,Bot),e(Er,Yr),M(kk,Yr,null),e(Yr,Iot),e(Yr,NAe),e(NAe,Not),e(Yr,qot),e(Yr,Sn),e(Sn,jot),e(Sn,qAe),e(qAe,Dot),e(Sn,Got),e(Sn,jAe),e(jAe,Oot),e(Sn,Vot),e(Sn,DAe),e(DAe,Xot),e(Sn,zot),e(Yr,Wot),e(Yr,Se),e(Se,b6),e(b6,GAe),e(GAe,Qot),e(b6,Hot),e(b6,tte),e(tte,Uot),e(b6,Jot),e(Se,Yot),e(Se,v6),e(v6,OAe),e(OAe,Kot),e(v6,Zot),e(v6,ate),e(ate,ert),e(v6,ort),e(Se,rrt),e(Se,F6),e(F6,VAe),e(VAe,trt),e(F6,art),e(F6,nte),e(nte,nrt),e(F6,srt),e(Se,lrt),e(Se,T6),e(T6,XAe),e(XAe,irt),e(T6,drt),e(T6,ste),e(ste,crt),e(T6,frt),e(Se,mrt),e(Se,M6),e(M6,zAe),e(zAe,grt),e(M6,hrt),e(M6,lte),e(lte,prt),e(M6,_rt),e(Se,urt),e(Se,E6),e(E6,WAe),e(WAe,brt),e(E6,vrt),e(E6,ite),e(ite,Frt),e(E6,Trt),e(Se,Mrt),e(Se,C6),e(C6,QAe),e(QAe,Ert),e(C6,Crt),e(C6,dte),e(dte,wrt),e(C6,Art),e(Se,Lrt),e(Se,w6),e(w6,HAe),e(HAe,yrt),e(w6,xrt),e(w6,cte),e(cte,$rt),e(w6,krt),e(Se,Srt),e(Se,A6),e(A6,UAe),e(UAe,Rrt),e(A6,Prt),e(A6,fte),e(fte,Brt),e(A6,Irt),e(Se,Nrt),e(Se,L6),e(L6,JAe),e(JAe,qrt),e(L6,jrt),e(L6,mte),e(mte,Drt),e(L6,Grt),e(Yr,Ort),M(y6,Yr,null),b(f,qHe,u),b(f,Cf,u),e(Cf,x6),e(x6,YAe),M(Sk,YAe,null),e(Cf,Vrt),e(Cf,KAe),e(KAe,Xrt),b(f,jHe,u),b(f,Cr,u),M(Rk,Cr,null),e(Cr,zrt),e(Cr,wf),e(wf,Wrt),e(wf,gte),e(gte,Qrt),e(wf,Hrt),e(wf,hte),e(hte,Urt),e(wf,Jrt),e(Cr,Yrt),e(Cr,Pk),e(Pk,Krt),e(Pk,ZAe),e(ZAe,Zrt),e(Pk,ett),e(Cr,ott),e(Cr,ra),M(Bk,ra,null),e(ra,rtt),e(ra,e7e),e(e7e,ttt),e(ra,att),e(ra,Af),e(Af,ntt),e(Af,o7e),e(o7e,stt),e(Af,ltt),e(Af,pte),e(pte,itt),e(Af,dtt),e(ra,ctt),M($6,ra,null),e(Cr,ftt),e(Cr,Kr),M(Ik,Kr,null),e(Kr,mtt),e(Kr,r7e),e(r7e,gtt),e(Kr,htt),e(Kr,Rn),e(Rn,ptt),e(Rn,t7e),e(t7e,_tt),e(Rn,utt),e(Rn,a7e),e(a7e,btt),e(Rn,vtt),e(Rn,n7e),e(n7e,Ftt),e(Rn,Ttt),e(Kr,Mtt),e(Kr,Re),e(Re,k6),e(k6,s7e),e(s7e,Ett),e(k6,Ctt),e(k6,_te),e(_te,wtt),e(k6,Att),e(Re,Ltt),e(Re,S6),e(S6,l7e),e(l7e,ytt),e(S6,xtt),e(S6,ute),e(ute,$tt),e(S6,ktt),e(Re,Stt),e(Re,R6),e(R6,i7e),e(i7e,Rtt),e(R6,Ptt),e(R6,bte),e(bte,Btt),e(R6,Itt),e(Re,Ntt),e(Re,P6),e(P6,d7e),e(d7e,qtt),e(P6,jtt),e(P6,vte),e(vte,Dtt),e(P6,Gtt),e(Re,Ott),e(Re,B6),e(B6,c7e),e(c7e,Vtt),e(B6,Xtt),e(B6,Fte),e(Fte,ztt),e(B6,Wtt),e(Re,Qtt),e(Re,I6),e(I6,f7e),e(f7e,Htt),e(I6,Utt),e(I6,Tte),e(Tte,Jtt),e(I6,Ytt),e(Re,Ktt),e(Re,N6),e(N6,m7e),e(m7e,Ztt),e(N6,eat),e(N6,Mte),e(Mte,oat),e(N6,rat),e(Re,tat),e(Re,q6),e(q6,g7e),e(g7e,aat),e(q6,nat),e(q6,Ete),e(Ete,sat),e(q6,lat),e(Re,iat),e(Re,j6),e(j6,h7e),e(h7e,dat),e(j6,cat),e(j6,Cte),e(Cte,fat),e(j6,mat),e(Re,gat),e(Re,D6),e(D6,p7e),e(p7e,hat),e(D6,pat),e(D6,wte),e(wte,_at),e(D6,uat),e(Kr,bat),M(G6,Kr,null),b(f,DHe,u),b(f,Lf,u),e(Lf,O6),e(O6,_7e),M(Nk,_7e,null),e(Lf,vat),e(Lf,u7e),e(u7e,Fat),b(f,GHe,u),b(f,wr,u),M(qk,wr,null),e(wr,Tat),e(wr,yf),e(yf,Mat),e(yf,Ate),e(Ate,Eat),e(yf,Cat),e(yf,Lte),e(Lte,wat),e(yf,Aat),e(wr,Lat),e(wr,jk),e(jk,yat),e(jk,b7e),e(b7e,xat),e(jk,$at),e(wr,kat),e(wr,ta),M(Dk,ta,null),e(ta,Sat),e(ta,v7e),e(v7e,Rat),e(ta,Pat),e(ta,xf),e(xf,Bat),e(xf,F7e),e(F7e,Iat),e(xf,Nat),e(xf,yte),e(yte,qat),e(xf,jat),e(ta,Dat),M(V6,ta,null),e(wr,Gat),e(wr,Zr),M(Gk,Zr,null),e(Zr,Oat),e(Zr,T7e),e(T7e,Vat),e(Zr,Xat),e(Zr,Pn),e(Pn,zat),e(Pn,M7e),e(M7e,Wat),e(Pn,Qat),e(Pn,E7e),e(E7e,Hat),e(Pn,Uat),e(Pn,C7e),e(C7e,Jat),e(Pn,Yat),e(Zr,Kat),e(Zr,Xe),e(Xe,X6),e(X6,w7e),e(w7e,Zat),e(X6,ent),e(X6,xte),e(xte,ont),e(X6,rnt),e(Xe,tnt),e(Xe,z6),e(z6,A7e),e(A7e,ant),e(z6,nnt),e(z6,$te),e($te,snt),e(z6,lnt),e(Xe,int),e(Xe,W6),e(W6,L7e),e(L7e,dnt),e(W6,cnt),e(W6,kte),e(kte,fnt),e(W6,mnt),e(Xe,gnt),e(Xe,Q6),e(Q6,y7e),e(y7e,hnt),e(Q6,pnt),e(Q6,Ste),e(Ste,_nt),e(Q6,unt),e(Xe,bnt),e(Xe,H6),e(H6,x7e),e(x7e,vnt),e(H6,Fnt),e(H6,Rte),e(Rte,Tnt),e(H6,Mnt),e(Xe,Ent),e(Xe,U6),e(U6,$7e),e($7e,Cnt),e(U6,wnt),e(U6,Pte),e(Pte,Ant),e(U6,Lnt),e(Xe,ynt),e(Xe,J6),e(J6,k7e),e(k7e,xnt),e(J6,$nt),e(J6,Bte),e(Bte,knt),e(J6,Snt),e(Xe,Rnt),e(Xe,Y6),e(Y6,S7e),e(S7e,Pnt),e(Y6,Bnt),e(Y6,Ite),e(Ite,Int),e(Y6,Nnt),e(Zr,qnt),M(K6,Zr,null),b(f,OHe,u),b(f,$f,u),e($f,Z6),e(Z6,R7e),M(Ok,R7e,null),e($f,jnt),e($f,P7e),e(P7e,Dnt),b(f,VHe,u),b(f,Ar,u),M(Vk,Ar,null),e(Ar,Gnt),e(Ar,kf),e(kf,Ont),e(kf,Nte),e(Nte,Vnt),e(kf,Xnt),e(kf,qte),e(qte,znt),e(kf,Wnt),e(Ar,Qnt),e(Ar,Xk),e(Xk,Hnt),e(Xk,B7e),e(B7e,Unt),e(Xk,Jnt),e(Ar,Ynt),e(Ar,aa),M(zk,aa,null),e(aa,Knt),e(aa,I7e),e(I7e,Znt),e(aa,est),e(aa,Sf),e(Sf,ost),e(Sf,N7e),e(N7e,rst),e(Sf,tst),e(Sf,jte),e(jte,ast),e(Sf,nst),e(aa,sst),M(eA,aa,null),e(Ar,lst),e(Ar,et),M(Wk,et,null),e(et,ist),e(et,q7e),e(q7e,dst),e(et,cst),e(et,Bn),e(Bn,fst),e(Bn,j7e),e(j7e,mst),e(Bn,gst),e(Bn,D7e),e(D7e,hst),e(Bn,pst),e(Bn,G7e),e(G7e,_st),e(Bn,ust),e(et,bst),e(et,ze),e(ze,oA),e(oA,O7e),e(O7e,vst),e(oA,Fst),e(oA,Dte),e(Dte,Tst),e(oA,Mst),e(ze,Est),e(ze,rA),e(rA,V7e),e(V7e,Cst),e(rA,wst),e(rA,Gte),e(Gte,Ast),e(rA,Lst),e(ze,yst),e(ze,tA),e(tA,X7e),e(X7e,xst),e(tA,$st),e(tA,Ote),e(Ote,kst),e(tA,Sst),e(ze,Rst),e(ze,aA),e(aA,z7e),e(z7e,Pst),e(aA,Bst),e(aA,Vte),e(Vte,Ist),e(aA,Nst),e(ze,qst),e(ze,nA),e(nA,W7e),e(W7e,jst),e(nA,Dst),e(nA,Xte),e(Xte,Gst),e(nA,Ost),e(ze,Vst),e(ze,sA),e(sA,Q7e),e(Q7e,Xst),e(sA,zst),e(sA,zte),e(zte,Wst),e(sA,Qst),e(ze,Hst),e(ze,lA),e(lA,H7e),e(H7e,Ust),e(lA,Jst),e(lA,Wte),e(Wte,Yst),e(lA,Kst),e(ze,Zst),e(ze,iA),e(iA,U7e),e(U7e,elt),e(iA,olt),e(iA,Qte),e(Qte,rlt),e(iA,tlt),e(et,alt),M(dA,et,null),b(f,XHe,u),b(f,Rf,u),e(Rf,cA),e(cA,J7e),M(Qk,J7e,null),e(Rf,nlt),e(Rf,Y7e),e(Y7e,slt),b(f,zHe,u),b(f,Lr,u),M(Hk,Lr,null),e(Lr,llt),e(Lr,Pf),e(Pf,ilt),e(Pf,Hte),e(Hte,dlt),e(Pf,clt),e(Pf,Ute),e(Ute,flt),e(Pf,mlt),e(Lr,glt),e(Lr,Uk),e(Uk,hlt),e(Uk,K7e),e(K7e,plt),e(Uk,_lt),e(Lr,ult),e(Lr,na),M(Jk,na,null),e(na,blt),e(na,Z7e),e(Z7e,vlt),e(na,Flt),e(na,Bf),e(Bf,Tlt),e(Bf,eLe),e(eLe,Mlt),e(Bf,Elt),e(Bf,Jte),e(Jte,Clt),e(Bf,wlt),e(na,Alt),M(fA,na,null),e(Lr,Llt),e(Lr,ot),M(Yk,ot,null),e(ot,ylt),e(ot,oLe),e(oLe,xlt),e(ot,$lt),e(ot,In),e(In,klt),e(In,rLe),e(rLe,Slt),e(In,Rlt),e(In,tLe),e(tLe,Plt),e(In,Blt),e(In,aLe),e(aLe,Ilt),e(In,Nlt),e(ot,qlt),e(ot,nLe),e(nLe,mA),e(mA,sLe),e(sLe,jlt),e(mA,Dlt),e(mA,Yte),e(Yte,Glt),e(mA,Olt),e(ot,Vlt),M(gA,ot,null),b(f,WHe,u),b(f,If,u),e(If,hA),e(hA,lLe),M(Kk,lLe,null),e(If,Xlt),e(If,iLe),e(iLe,zlt),b(f,QHe,u),b(f,yr,u),M(Zk,yr,null),e(yr,Wlt),e(yr,Nf),e(Nf,Qlt),e(Nf,Kte),e(Kte,Hlt),e(Nf,Ult),e(Nf,Zte),e(Zte,Jlt),e(Nf,Ylt),e(yr,Klt),e(yr,eS),e(eS,Zlt),e(eS,dLe),e(dLe,eit),e(eS,oit),e(yr,rit),e(yr,sa),M(oS,sa,null),e(sa,tit),e(sa,cLe),e(cLe,ait),e(sa,nit),e(sa,qf),e(qf,sit),e(qf,fLe),e(fLe,lit),e(qf,iit),e(qf,eae),e(eae,dit),e(qf,cit),e(sa,fit),M(pA,sa,null),e(yr,mit),e(yr,rt),M(rS,rt,null),e(rt,git),e(rt,mLe),e(mLe,hit),e(rt,pit),e(rt,Nn),e(Nn,_it),e(Nn,gLe),e(gLe,uit),e(Nn,bit),e(Nn,hLe),e(hLe,vit),e(Nn,Fit),e(Nn,pLe),e(pLe,Tit),e(Nn,Mit),e(rt,Eit),e(rt,tS),e(tS,_A),e(_A,_Le),e(_Le,Cit),e(_A,wit),e(_A,oae),e(oae,Ait),e(_A,Lit),e(tS,yit),e(tS,uA),e(uA,uLe),e(uLe,xit),e(uA,$it),e(uA,rae),e(rae,kit),e(uA,Sit),e(rt,Rit),M(bA,rt,null),b(f,HHe,u),b(f,jf,u),e(jf,vA),e(vA,bLe),M(aS,bLe,null),e(jf,Pit),e(jf,vLe),e(vLe,Bit),b(f,UHe,u),b(f,xr,u),M(nS,xr,null),e(xr,Iit),e(xr,Df),e(Df,Nit),e(Df,tae),e(tae,qit),e(Df,jit),e(Df,aae),e(aae,Dit),e(Df,Git),e(xr,Oit),e(xr,sS),e(sS,Vit),e(sS,FLe),e(FLe,Xit),e(sS,zit),e(xr,Wit),e(xr,la),M(lS,la,null),e(la,Qit),e(la,TLe),e(TLe,Hit),e(la,Uit),e(la,Gf),e(Gf,Jit),e(Gf,MLe),e(MLe,Yit),e(Gf,Kit),e(Gf,nae),e(nae,Zit),e(Gf,edt),e(la,odt),M(FA,la,null),e(xr,rdt),e(xr,tt),M(iS,tt,null),e(tt,tdt),e(tt,ELe),e(ELe,adt),e(tt,ndt),e(tt,qn),e(qn,sdt),e(qn,CLe),e(CLe,ldt),e(qn,idt),e(qn,wLe),e(wLe,ddt),e(qn,cdt),e(qn,ALe),e(ALe,fdt),e(qn,mdt),e(tt,gdt),e(tt,LLe),e(LLe,TA),e(TA,yLe),e(yLe,hdt),e(TA,pdt),e(TA,sae),e(sae,_dt),e(TA,udt),e(tt,bdt),M(MA,tt,null),JHe=!0},p(f,[u]){const dS={};u&2&&(dS.$$scope={dirty:u,ctx:f}),Jf.$set(dS);const xLe={};u&2&&(xLe.$$scope={dirty:u,ctx:f}),fh.$set(xLe);const $Le={};u&2&&($Le.$$scope={dirty:u,ctx:f}),Qh.$set($Le);const kLe={};u&2&&(kLe.$$scope={dirty:u,ctx:f}),Rp.$set(kLe);const cS={};u&2&&(cS.$$scope={dirty:u,ctx:f}),Pp.$set(cS);const SLe={};u&2&&(SLe.$$scope={dirty:u,ctx:f}),r_.$set(SLe);const jn={};u&2&&(jn.$$scope={dirty:u,ctx:f}),t_.$set(jn);const RLe={};u&2&&(RLe.$$scope={dirty:u,ctx:f}),s_.$set(RLe);const PLe={};u&2&&(PLe.$$scope={dirty:u,ctx:f}),h2.$set(PLe);const BLe={};u&2&&(BLe.$$scope={dirty:u,ctx:f}),_2.$set(BLe);const fS={};u&2&&(fS.$$scope={dirty:u,ctx:f}),f1.$set(fS);const ILe={};u&2&&(ILe.$$scope={dirty:u,ctx:f}),g1.$set(ILe);const mS={};u&2&&(mS.$$scope={dirty:u,ctx:f}),ob.$set(mS);const NLe={};u&2&&(NLe.$$scope={dirty:u,ctx:f}),tb.$set(NLe);const gS={};u&2&&(gS.$$scope={dirty:u,ctx:f}),Vb.$set(gS);const qLe={};u&2&&(qLe.$$scope={dirty:u,ctx:f}),zb.$set(qLe);const jLe={};u&2&&(jLe.$$scope={dirty:u,ctx:f}),mv.$set(jLe);const DLe={};u&2&&(DLe.$$scope={dirty:u,ctx:f}),hv.$set(DLe);const Of={};u&2&&(Of.$$scope={dirty:u,ctx:f}),h0.$set(Of);const GLe={};u&2&&(GLe.$$scope={dirty:u,ctx:f}),_0.$set(GLe);const OLe={};u&2&&(OLe.$$scope={dirty:u,ctx:f}),U0.$set(OLe);const VLe={};u&2&&(VLe.$$scope={dirty:u,ctx:f}),Y0.$set(VLe);const hS={};u&2&&(hS.$$scope={dirty:u,ctx:f}),nF.$set(hS);const XLe={};u&2&&(XLe.$$scope={dirty:u,ctx:f}),lF.$set(XLe);const zLe={};u&2&&(zLe.$$scope={dirty:u,ctx:f}),WF.$set(zLe);const WLe={};u&2&&(WLe.$$scope={dirty:u,ctx:f}),HF.$set(WLe);const lt={};u&2&&(lt.$$scope={dirty:u,ctx:f}),jT.$set(lt);const pS={};u&2&&(pS.$$scope={dirty:u,ctx:f}),GT.$set(pS);const QLe={};u&2&&(QLe.$$scope={dirty:u,ctx:f}),XT.$set(QLe);const _S={};u&2&&(_S.$$scope={dirty:u,ctx:f}),WT.$set(_S);const HLe={};u&2&&(HLe.$$scope={dirty:u,ctx:f}),i8.$set(HLe);const it={};u&2&&(it.$$scope={dirty:u,ctx:f}),c8.$set(it);const ULe={};u&2&&(ULe.$$scope={dirty:u,ctx:f}),g8.$set(ULe);const Vf={};u&2&&(Vf.$$scope={dirty:u,ctx:f}),p8.$set(Vf);const JLe={};u&2&&(JLe.$$scope={dirty:u,ctx:f}),b8.$set(JLe);const YLe={};u&2&&(YLe.$$scope={dirty:u,ctx:f}),F8.$set(YLe);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),E8.$set(L);const EA={};u&2&&(EA.$$scope={dirty:u,ctx:f}),w8.$set(EA);const KLe={};u&2&&(KLe.$$scope={dirty:u,ctx:f}),I8.$set(KLe);const ZLe={};u&2&&(ZLe.$$scope={dirty:u,ctx:f}),q8.$set(ZLe);const CA={};u&2&&(CA.$$scope={dirty:u,ctx:f}),z8.$set(CA);const eye={};u&2&&(eye.$$scope={dirty:u,ctx:f}),Q8.$set(eye);const oye={};u&2&&(oye.$$scope={dirty:u,ctx:f}),nM.$set(oye);const wA={};u&2&&(wA.$$scope={dirty:u,ctx:f}),lM.$set(wA);const rye={};u&2&&(rye.$$scope={dirty:u,ctx:f}),fM.$set(rye);const tye={};u&2&&(tye.$$scope={dirty:u,ctx:f}),gM.$set(tye);const AA={};u&2&&(AA.$$scope={dirty:u,ctx:f}),FM.$set(AA);const aye={};u&2&&(aye.$$scope={dirty:u,ctx:f}),MM.$set(aye);const nye={};u&2&&(nye.$$scope={dirty:u,ctx:f}),yM.$set(nye);const LA={};u&2&&(LA.$$scope={dirty:u,ctx:f}),$M.$set(LA);const sye={};u&2&&(sye.$$scope={dirty:u,ctx:f}),PM.$set(sye);const lye={};u&2&&(lye.$$scope={dirty:u,ctx:f}),IM.$set(lye);const yA={};u&2&&(yA.$$scope={dirty:u,ctx:f}),jM.$set(yA);const iye={};u&2&&(iye.$$scope={dirty:u,ctx:f}),GM.$set(iye);const dye={};u&2&&(dye.$$scope={dirty:u,ctx:f}),HM.$set(dye);const xA={};u&2&&(xA.$$scope={dirty:u,ctx:f}),JM.$set(xA);const cye={};u&2&&(cye.$$scope={dirty:u,ctx:f}),ZM.$set(cye);const fye={};u&2&&(fye.$$scope={dirty:u,ctx:f}),oE.$set(fye);const $A={};u&2&&($A.$$scope={dirty:u,ctx:f}),KE.$set($A);const mye={};u&2&&(mye.$$scope={dirty:u,ctx:f}),e4.$set(mye);const gye={};u&2&&(gye.$$scope={dirty:u,ctx:f}),C4.$set(gye);const kA={};u&2&&(kA.$$scope={dirty:u,ctx:f}),A4.$set(kA);const hye={};u&2&&(hye.$$scope={dirty:u,ctx:f}),D4.$set(hye);const pye={};u&2&&(pye.$$scope={dirty:u,ctx:f}),O4.$set(pye);const SA={};u&2&&(SA.$$scope={dirty:u,ctx:f}),J4.$set(SA);const _ye={};u&2&&(_ye.$$scope={dirty:u,ctx:f}),K4.$set(_ye);const uye={};u&2&&(uye.$$scope={dirty:u,ctx:f}),vC.$set(uye);const RA={};u&2&&(RA.$$scope={dirty:u,ctx:f}),TC.$set(RA);const bye={};u&2&&(bye.$$scope={dirty:u,ctx:f}),SC.$set(bye);const vye={};u&2&&(vye.$$scope={dirty:u,ctx:f}),PC.$set(vye);const PA={};u&2&&(PA.$$scope={dirty:u,ctx:f}),l5.$set(PA);const Fye={};u&2&&(Fye.$$scope={dirty:u,ctx:f}),d5.$set(Fye);const Tye={};u&2&&(Tye.$$scope={dirty:u,ctx:f}),L5.$set(Tye);const BA={};u&2&&(BA.$$scope={dirty:u,ctx:f}),x5.$set(BA);const Mye={};u&2&&(Mye.$$scope={dirty:u,ctx:f}),S5.$set(Mye);const Eye={};u&2&&(Eye.$$scope={dirty:u,ctx:f}),P5.$set(Eye);const IA={};u&2&&(IA.$$scope={dirty:u,ctx:f}),I5.$set(IA);const Cye={};u&2&&(Cye.$$scope={dirty:u,ctx:f}),q5.$set(Cye);const wye={};u&2&&(wye.$$scope={dirty:u,ctx:f}),n3.$set(wye);const NA={};u&2&&(NA.$$scope={dirty:u,ctx:f}),l3.$set(NA);const Aye={};u&2&&(Aye.$$scope={dirty:u,ctx:f}),y3.$set(Aye);const Lye={};u&2&&(Lye.$$scope={dirty:u,ctx:f}),$3.$set(Lye);const qA={};u&2&&(qA.$$scope={dirty:u,ctx:f}),S3.$set(qA);const yye={};u&2&&(yye.$$scope={dirty:u,ctx:f}),P3.$set(yye);const xye={};u&2&&(xye.$$scope={dirty:u,ctx:f}),I3.$set(xye);const jA={};u&2&&(jA.$$scope={dirty:u,ctx:f}),q3.$set(jA);const $ye={};u&2&&($ye.$$scope={dirty:u,ctx:f}),gw.$set($ye);const kye={};u&2&&(kye.$$scope={dirty:u,ctx:f}),pw.$set(kye);const DA={};u&2&&(DA.$$scope={dirty:u,ctx:f}),Lw.$set(DA);const Sye={};u&2&&(Sye.$$scope={dirty:u,ctx:f}),xw.$set(Sye);const Rye={};u&2&&(Rye.$$scope={dirty:u,ctx:f}),Vw.$set(Rye);const GA={};u&2&&(GA.$$scope={dirty:u,ctx:f}),zw.$set(GA);const Pye={};u&2&&(Pye.$$scope={dirty:u,ctx:f}),r6.$set(Pye);const Bye={};u&2&&(Bye.$$scope={dirty:u,ctx:f}),a6.$set(Bye);const OA={};u&2&&(OA.$$scope={dirty:u,ctx:f}),p6.$set(OA);const Iye={};u&2&&(Iye.$$scope={dirty:u,ctx:f}),u6.$set(Iye);const Nye={};u&2&&(Nye.$$scope={dirty:u,ctx:f}),y6.$set(Nye);const VA={};u&2&&(VA.$$scope={dirty:u,ctx:f}),$6.$set(VA);const qye={};u&2&&(qye.$$scope={dirty:u,ctx:f}),G6.$set(qye);const jye={};u&2&&(jye.$$scope={dirty:u,ctx:f}),V6.$set(jye);const XA={};u&2&&(XA.$$scope={dirty:u,ctx:f}),K6.$set(XA);const Dye={};u&2&&(Dye.$$scope={dirty:u,ctx:f}),eA.$set(Dye);const Gye={};u&2&&(Gye.$$scope={dirty:u,ctx:f}),dA.$set(Gye);const zA={};u&2&&(zA.$$scope={dirty:u,ctx:f}),fA.$set(zA);const Oye={};u&2&&(Oye.$$scope={dirty:u,ctx:f}),gA.$set(Oye);const Vye={};u&2&&(Vye.$$scope={dirty:u,ctx:f}),pA.$set(Vye);const WA={};u&2&&(WA.$$scope={dirty:u,ctx:f}),bA.$set(WA);const Xye={};u&2&&(Xye.$$scope={dirty:u,ctx:f}),FA.$set(Xye);const zye={};u&2&&(zye.$$scope={dirty:u,ctx:f}),MA.$set(zye)},i(f){JHe||(E(d.$$.fragment,f),E(Ia.$$.fragment,f),E(HL.$$.fragment,f),E(UL.$$.fragment,f),E(Jf.$$.fragment,f),E(JL.$$.fragment,f),E(YL.$$.fragment,f),E(ey.$$.fragment,f),E(fh.$$.fragment,f),E(oy.$$.fragment,f),E(ry.$$.fragment,f),E(ty.$$.fragment,f),E(sy.$$.fragment,f),E(Qh.$$.fragment,f),E(ly.$$.fragment,f),E(iy.$$.fragment,f),E(dy.$$.fragment,f),E(my.$$.fragment,f),E(Rp.$$.fragment,f),E(Pp.$$.fragment,f),E(gy.$$.fragment,f),E(hy.$$.fragment,f),E(py.$$.fragment,f),E(by.$$.fragment,f),E(r_.$$.fragment,f),E(t_.$$.fragment,f),E(vy.$$.fragment,f),E(Fy.$$.fragment,f),E(Ty.$$.fragment,f),E(Ey.$$.fragment,f),E(s_.$$.fragment,f),E(Cy.$$.fragment,f),E(h2.$$.fragment,f),E(wy.$$.fragment,f),E(Ay.$$.fragment,f),E(yy.$$.fragment,f),E(_2.$$.fragment,f),E(xy.$$.fragment,f),E(f1.$$.fragment,f),E($y.$$.fragment,f),E(ky.$$.fragment,f),E(Ry.$$.fragment,f),E(g1.$$.fragment,f),E(Py.$$.fragment,f),E(ob.$$.fragment,f),E(By.$$.fragment,f),E(Iy.$$.fragment,f),E(qy.$$.fragment,f),E(tb.$$.fragment,f),E(jy.$$.fragment,f),E(Vb.$$.fragment,f),E(Dy.$$.fragment,f),E(Gy.$$.fragment,f),E(Vy.$$.fragment,f),E(zb.$$.fragment,f),E(Xy.$$.fragment,f),E(mv.$$.fragment,f),E(zy.$$.fragment,f),E(Wy.$$.fragment,f),E(Hy.$$.fragment,f),E(hv.$$.fragment,f),E(Uy.$$.fragment,f),E(h0.$$.fragment,f),E(Jy.$$.fragment,f),E(Yy.$$.fragment,f),E(Zy.$$.fragment,f),E(_0.$$.fragment,f),E(e9.$$.fragment,f),E(U0.$$.fragment,f),E(o9.$$.fragment,f),E(r9.$$.fragment,f),E(a9.$$.fragment,f),E(Y0.$$.fragment,f),E(n9.$$.fragment,f),E(nF.$$.fragment,f),E(s9.$$.fragment,f),E(l9.$$.fragment,f),E(d9.$$.fragment,f),E(lF.$$.fragment,f),E(c9.$$.fragment,f),E(WF.$$.fragment,f),E(f9.$$.fragment,f),E(m9.$$.fragment,f),E(h9.$$.fragment,f),E(HF.$$.fragment,f),E(p9.$$.fragment,f),E(jT.$$.fragment,f),E(_9.$$.fragment,f),E(u9.$$.fragment,f),E(v9.$$.fragment,f),E(GT.$$.fragment,f),E(F9.$$.fragment,f),E(XT.$$.fragment,f),E(T9.$$.fragment,f),E(M9.$$.fragment,f),E(C9.$$.fragment,f),E(WT.$$.fragment,f),E(w9.$$.fragment,f),E(i8.$$.fragment,f),E(A9.$$.fragment,f),E(L9.$$.fragment,f),E(x9.$$.fragment,f),E(c8.$$.fragment,f),E($9.$$.fragment,f),E(g8.$$.fragment,f),E(k9.$$.fragment,f),E(S9.$$.fragment,f),E(P9.$$.fragment,f),E(p8.$$.fragment,f),E(B9.$$.fragment,f),E(b8.$$.fragment,f),E(I9.$$.fragment,f),E(N9.$$.fragment,f),E(j9.$$.fragment,f),E(F8.$$.fragment,f),E(D9.$$.fragment,f),E(E8.$$.fragment,f),E(G9.$$.fragment,f),E(O9.$$.fragment,f),E(X9.$$.fragment,f),E(w8.$$.fragment,f),E(z9.$$.fragment,f),E(I8.$$.fragment,f),E(W9.$$.fragment,f),E(Q9.$$.fragment,f),E(U9.$$.fragment,f),E(q8.$$.fragment,f),E(J9.$$.fragment,f),E(z8.$$.fragment,f),E(Y9.$$.fragment,f),E(K9.$$.fragment,f),E(ex.$$.fragment,f),E(Q8.$$.fragment,f),E(ox.$$.fragment,f),E(nM.$$.fragment,f),E(rx.$$.fragment,f),E(tx.$$.fragment,f),E(nx.$$.fragment,f),E(lM.$$.fragment,f),E(sx.$$.fragment,f),E(fM.$$.fragment,f),E(ix.$$.fragment,f),E(dx.$$.fragment,f),E(fx.$$.fragment,f),E(gM.$$.fragment,f),E(mx.$$.fragment,f),E(FM.$$.fragment,f),E(gx.$$.fragment,f),E(hx.$$.fragment,f),E(_x.$$.fragment,f),E(MM.$$.fragment,f),E(ux.$$.fragment,f),E(yM.$$.fragment,f),E(bx.$$.fragment,f),E(vx.$$.fragment,f),E(Tx.$$.fragment,f),E($M.$$.fragment,f),E(Mx.$$.fragment,f),E(PM.$$.fragment,f),E(Cx.$$.fragment,f),E(wx.$$.fragment,f),E(Lx.$$.fragment,f),E(IM.$$.fragment,f),E(yx.$$.fragment,f),E(jM.$$.fragment,f),E(xx.$$.fragment,f),E($x.$$.fragment,f),E(Sx.$$.fragment,f),E(GM.$$.fragment,f),E(Rx.$$.fragment,f),E(HM.$$.fragment,f),E(Px.$$.fragment,f),E(Bx.$$.fragment,f),E(Nx.$$.fragment,f),E(JM.$$.fragment,f),E(qx.$$.fragment,f),E(ZM.$$.fragment,f),E(jx.$$.fragment,f),E(Dx.$$.fragment,f),E(Ox.$$.fragment,f),E(oE.$$.fragment,f),E(Vx.$$.fragment,f),E(KE.$$.fragment,f),E(Xx.$$.fragment,f),E(zx.$$.fragment,f),E(Qx.$$.fragment,f),E(e4.$$.fragment,f),E(Hx.$$.fragment,f),E(C4.$$.fragment,f),E(Ux.$$.fragment,f),E(Jx.$$.fragment,f),E(Kx.$$.fragment,f),E(A4.$$.fragment,f),E(Zx.$$.fragment,f),E(D4.$$.fragment,f),E(e$.$$.fragment,f),E(o$.$$.fragment,f),E(t$.$$.fragment,f),E(O4.$$.fragment,f),E(a$.$$.fragment,f),E(J4.$$.fragment,f),E(n$.$$.fragment,f),E(s$.$$.fragment,f),E(i$.$$.fragment,f),E(K4.$$.fragment,f),E(d$.$$.fragment,f),E(vC.$$.fragment,f),E(c$.$$.fragment,f),E(f$.$$.fragment,f),E(g$.$$.fragment,f),E(TC.$$.fragment,f),E(h$.$$.fragment,f),E(SC.$$.fragment,f),E(p$.$$.fragment,f),E(_$.$$.fragment,f),E(b$.$$.fragment,f),E(PC.$$.fragment,f),E(v$.$$.fragment,f),E(l5.$$.fragment,f),E(F$.$$.fragment,f),E(T$.$$.fragment,f),E(E$.$$.fragment,f),E(d5.$$.fragment,f),E(C$.$$.fragment,f),E(L5.$$.fragment,f),E(w$.$$.fragment,f),E(A$.$$.fragment,f),E(y$.$$.fragment,f),E(x5.$$.fragment,f),E(x$.$$.fragment,f),E(S5.$$.fragment,f),E(k$.$$.fragment,f),E(S$.$$.fragment,f),E(P$.$$.fragment,f),E(P5.$$.fragment,f),E(B$.$$.fragment,f),E(I5.$$.fragment,f),E(I$.$$.fragment,f),E(N$.$$.fragment,f),E(j$.$$.fragment,f),E(q5.$$.fragment,f),E(D$.$$.fragment,f),E(n3.$$.fragment,f),E(G$.$$.fragment,f),E(O$.$$.fragment,f),E(X$.$$.fragment,f),E(l3.$$.fragment,f),E(z$.$$.fragment,f),E(y3.$$.fragment,f),E(W$.$$.fragment,f),E(Q$.$$.fragment,f),E(U$.$$.fragment,f),E($3.$$.fragment,f),E(J$.$$.fragment,f),E(S3.$$.fragment,f),E(Y$.$$.fragment,f),E(K$.$$.fragment,f),E(ek.$$.fragment,f),E(P3.$$.fragment,f),E(ok.$$.fragment,f),E(I3.$$.fragment,f),E(rk.$$.fragment,f),E(tk.$$.fragment,f),E(nk.$$.fragment,f),E(q3.$$.fragment,f),E(sk.$$.fragment,f),E(gw.$$.fragment,f),E(lk.$$.fragment,f),E(ik.$$.fragment,f),E(ck.$$.fragment,f),E(pw.$$.fragment,f),E(fk.$$.fragment,f),E(Lw.$$.fragment,f),E(mk.$$.fragment,f),E(gk.$$.fragment,f),E(pk.$$.fragment,f),E(xw.$$.fragment,f),E(_k.$$.fragment,f),E(Vw.$$.fragment,f),E(uk.$$.fragment,f),E(bk.$$.fragment,f),E(Fk.$$.fragment,f),E(zw.$$.fragment,f),E(Tk.$$.fragment,f),E(r6.$$.fragment,f),E(Mk.$$.fragment,f),E(Ek.$$.fragment,f),E(wk.$$.fragment,f),E(a6.$$.fragment,f),E(Ak.$$.fragment,f),E(p6.$$.fragment,f),E(Lk.$$.fragment,f),E(yk.$$.fragment,f),E($k.$$.fragment,f),E(u6.$$.fragment,f),E(kk.$$.fragment,f),E(y6.$$.fragment,f),E(Sk.$$.fragment,f),E(Rk.$$.fragment,f),E(Bk.$$.fragment,f),E($6.$$.fragment,f),E(Ik.$$.fragment,f),E(G6.$$.fragment,f),E(Nk.$$.fragment,f),E(qk.$$.fragment,f),E(Dk.$$.fragment,f),E(V6.$$.fragment,f),E(Gk.$$.fragment,f),E(K6.$$.fragment,f),E(Ok.$$.fragment,f),E(Vk.$$.fragment,f),E(zk.$$.fragment,f),E(eA.$$.fragment,f),E(Wk.$$.fragment,f),E(dA.$$.fragment,f),E(Qk.$$.fragment,f),E(Hk.$$.fragment,f),E(Jk.$$.fragment,f),E(fA.$$.fragment,f),E(Yk.$$.fragment,f),E(gA.$$.fragment,f),E(Kk.$$.fragment,f),E(Zk.$$.fragment,f),E(oS.$$.fragment,f),E(pA.$$.fragment,f),E(rS.$$.fragment,f),E(bA.$$.fragment,f),E(aS.$$.fragment,f),E(nS.$$.fragment,f),E(lS.$$.fragment,f),E(FA.$$.fragment,f),E(iS.$$.fragment,f),E(MA.$$.fragment,f),JHe=!0)},o(f){C(d.$$.fragment,f),C(Ia.$$.fragment,f),C(HL.$$.fragment,f),C(UL.$$.fragment,f),C(Jf.$$.fragment,f),C(JL.$$.fragment,f),C(YL.$$.fragment,f),C(ey.$$.fragment,f),C(fh.$$.fragment,f),C(oy.$$.fragment,f),C(ry.$$.fragment,f),C(ty.$$.fragment,f),C(sy.$$.fragment,f),C(Qh.$$.fragment,f),C(ly.$$.fragment,f),C(iy.$$.fragment,f),C(dy.$$.fragment,f),C(my.$$.fragment,f),C(Rp.$$.fragment,f),C(Pp.$$.fragment,f),C(gy.$$.fragment,f),C(hy.$$.fragment,f),C(py.$$.fragment,f),C(by.$$.fragment,f),C(r_.$$.fragment,f),C(t_.$$.fragment,f),C(vy.$$.fragment,f),C(Fy.$$.fragment,f),C(Ty.$$.fragment,f),C(Ey.$$.fragment,f),C(s_.$$.fragment,f),C(Cy.$$.fragment,f),C(h2.$$.fragment,f),C(wy.$$.fragment,f),C(Ay.$$.fragment,f),C(yy.$$.fragment,f),C(_2.$$.fragment,f),C(xy.$$.fragment,f),C(f1.$$.fragment,f),C($y.$$.fragment,f),C(ky.$$.fragment,f),C(Ry.$$.fragment,f),C(g1.$$.fragment,f),C(Py.$$.fragment,f),C(ob.$$.fragment,f),C(By.$$.fragment,f),C(Iy.$$.fragment,f),C(qy.$$.fragment,f),C(tb.$$.fragment,f),C(jy.$$.fragment,f),C(Vb.$$.fragment,f),C(Dy.$$.fragment,f),C(Gy.$$.fragment,f),C(Vy.$$.fragment,f),C(zb.$$.fragment,f),C(Xy.$$.fragment,f),C(mv.$$.fragment,f),C(zy.$$.fragment,f),C(Wy.$$.fragment,f),C(Hy.$$.fragment,f),C(hv.$$.fragment,f),C(Uy.$$.fragment,f),C(h0.$$.fragment,f),C(Jy.$$.fragment,f),C(Yy.$$.fragment,f),C(Zy.$$.fragment,f),C(_0.$$.fragment,f),C(e9.$$.fragment,f),C(U0.$$.fragment,f),C(o9.$$.fragment,f),C(r9.$$.fragment,f),C(a9.$$.fragment,f),C(Y0.$$.fragment,f),C(n9.$$.fragment,f),C(nF.$$.fragment,f),C(s9.$$.fragment,f),C(l9.$$.fragment,f),C(d9.$$.fragment,f),C(lF.$$.fragment,f),C(c9.$$.fragment,f),C(WF.$$.fragment,f),C(f9.$$.fragment,f),C(m9.$$.fragment,f),C(h9.$$.fragment,f),C(HF.$$.fragment,f),C(p9.$$.fragment,f),C(jT.$$.fragment,f),C(_9.$$.fragment,f),C(u9.$$.fragment,f),C(v9.$$.fragment,f),C(GT.$$.fragment,f),C(F9.$$.fragment,f),C(XT.$$.fragment,f),C(T9.$$.fragment,f),C(M9.$$.fragment,f),C(C9.$$.fragment,f),C(WT.$$.fragment,f),C(w9.$$.fragment,f),C(i8.$$.fragment,f),C(A9.$$.fragment,f),C(L9.$$.fragment,f),C(x9.$$.fragment,f),C(c8.$$.fragment,f),C($9.$$.fragment,f),C(g8.$$.fragment,f),C(k9.$$.fragment,f),C(S9.$$.fragment,f),C(P9.$$.fragment,f),C(p8.$$.fragment,f),C(B9.$$.fragment,f),C(b8.$$.fragment,f),C(I9.$$.fragment,f),C(N9.$$.fragment,f),C(j9.$$.fragment,f),C(F8.$$.fragment,f),C(D9.$$.fragment,f),C(E8.$$.fragment,f),C(G9.$$.fragment,f),C(O9.$$.fragment,f),C(X9.$$.fragment,f),C(w8.$$.fragment,f),C(z9.$$.fragment,f),C(I8.$$.fragment,f),C(W9.$$.fragment,f),C(Q9.$$.fragment,f),C(U9.$$.fragment,f),C(q8.$$.fragment,f),C(J9.$$.fragment,f),C(z8.$$.fragment,f),C(Y9.$$.fragment,f),C(K9.$$.fragment,f),C(ex.$$.fragment,f),C(Q8.$$.fragment,f),C(ox.$$.fragment,f),C(nM.$$.fragment,f),C(rx.$$.fragment,f),C(tx.$$.fragment,f),C(nx.$$.fragment,f),C(lM.$$.fragment,f),C(sx.$$.fragment,f),C(fM.$$.fragment,f),C(ix.$$.fragment,f),C(dx.$$.fragment,f),C(fx.$$.fragment,f),C(gM.$$.fragment,f),C(mx.$$.fragment,f),C(FM.$$.fragment,f),C(gx.$$.fragment,f),C(hx.$$.fragment,f),C(_x.$$.fragment,f),C(MM.$$.fragment,f),C(ux.$$.fragment,f),C(yM.$$.fragment,f),C(bx.$$.fragment,f),C(vx.$$.fragment,f),C(Tx.$$.fragment,f),C($M.$$.fragment,f),C(Mx.$$.fragment,f),C(PM.$$.fragment,f),C(Cx.$$.fragment,f),C(wx.$$.fragment,f),C(Lx.$$.fragment,f),C(IM.$$.fragment,f),C(yx.$$.fragment,f),C(jM.$$.fragment,f),C(xx.$$.fragment,f),C($x.$$.fragment,f),C(Sx.$$.fragment,f),C(GM.$$.fragment,f),C(Rx.$$.fragment,f),C(HM.$$.fragment,f),C(Px.$$.fragment,f),C(Bx.$$.fragment,f),C(Nx.$$.fragment,f),C(JM.$$.fragment,f),C(qx.$$.fragment,f),C(ZM.$$.fragment,f),C(jx.$$.fragment,f),C(Dx.$$.fragment,f),C(Ox.$$.fragment,f),C(oE.$$.fragment,f),C(Vx.$$.fragment,f),C(KE.$$.fragment,f),C(Xx.$$.fragment,f),C(zx.$$.fragment,f),C(Qx.$$.fragment,f),C(e4.$$.fragment,f),C(Hx.$$.fragment,f),C(C4.$$.fragment,f),C(Ux.$$.fragment,f),C(Jx.$$.fragment,f),C(Kx.$$.fragment,f),C(A4.$$.fragment,f),C(Zx.$$.fragment,f),C(D4.$$.fragment,f),C(e$.$$.fragment,f),C(o$.$$.fragment,f),C(t$.$$.fragment,f),C(O4.$$.fragment,f),C(a$.$$.fragment,f),C(J4.$$.fragment,f),C(n$.$$.fragment,f),C(s$.$$.fragment,f),C(i$.$$.fragment,f),C(K4.$$.fragment,f),C(d$.$$.fragment,f),C(vC.$$.fragment,f),C(c$.$$.fragment,f),C(f$.$$.fragment,f),C(g$.$$.fragment,f),C(TC.$$.fragment,f),C(h$.$$.fragment,f),C(SC.$$.fragment,f),C(p$.$$.fragment,f),C(_$.$$.fragment,f),C(b$.$$.fragment,f),C(PC.$$.fragment,f),C(v$.$$.fragment,f),C(l5.$$.fragment,f),C(F$.$$.fragment,f),C(T$.$$.fragment,f),C(E$.$$.fragment,f),C(d5.$$.fragment,f),C(C$.$$.fragment,f),C(L5.$$.fragment,f),C(w$.$$.fragment,f),C(A$.$$.fragment,f),C(y$.$$.fragment,f),C(x5.$$.fragment,f),C(x$.$$.fragment,f),C(S5.$$.fragment,f),C(k$.$$.fragment,f),C(S$.$$.fragment,f),C(P$.$$.fragment,f),C(P5.$$.fragment,f),C(B$.$$.fragment,f),C(I5.$$.fragment,f),C(I$.$$.fragment,f),C(N$.$$.fragment,f),C(j$.$$.fragment,f),C(q5.$$.fragment,f),C(D$.$$.fragment,f),C(n3.$$.fragment,f),C(G$.$$.fragment,f),C(O$.$$.fragment,f),C(X$.$$.fragment,f),C(l3.$$.fragment,f),C(z$.$$.fragment,f),C(y3.$$.fragment,f),C(W$.$$.fragment,f),C(Q$.$$.fragment,f),C(U$.$$.fragment,f),C($3.$$.fragment,f),C(J$.$$.fragment,f),C(S3.$$.fragment,f),C(Y$.$$.fragment,f),C(K$.$$.fragment,f),C(ek.$$.fragment,f),C(P3.$$.fragment,f),C(ok.$$.fragment,f),C(I3.$$.fragment,f),C(rk.$$.fragment,f),C(tk.$$.fragment,f),C(nk.$$.fragment,f),C(q3.$$.fragment,f),C(sk.$$.fragment,f),C(gw.$$.fragment,f),C(lk.$$.fragment,f),C(ik.$$.fragment,f),C(ck.$$.fragment,f),C(pw.$$.fragment,f),C(fk.$$.fragment,f),C(Lw.$$.fragment,f),C(mk.$$.fragment,f),C(gk.$$.fragment,f),C(pk.$$.fragment,f),C(xw.$$.fragment,f),C(_k.$$.fragment,f),C(Vw.$$.fragment,f),C(uk.$$.fragment,f),C(bk.$$.fragment,f),C(Fk.$$.fragment,f),C(zw.$$.fragment,f),C(Tk.$$.fragment,f),C(r6.$$.fragment,f),C(Mk.$$.fragment,f),C(Ek.$$.fragment,f),C(wk.$$.fragment,f),C(a6.$$.fragment,f),C(Ak.$$.fragment,f),C(p6.$$.fragment,f),C(Lk.$$.fragment,f),C(yk.$$.fragment,f),C($k.$$.fragment,f),C(u6.$$.fragment,f),C(kk.$$.fragment,f),C(y6.$$.fragment,f),C(Sk.$$.fragment,f),C(Rk.$$.fragment,f),C(Bk.$$.fragment,f),C($6.$$.fragment,f),C(Ik.$$.fragment,f),C(G6.$$.fragment,f),C(Nk.$$.fragment,f),C(qk.$$.fragment,f),C(Dk.$$.fragment,f),C(V6.$$.fragment,f),C(Gk.$$.fragment,f),C(K6.$$.fragment,f),C(Ok.$$.fragment,f),C(Vk.$$.fragment,f),C(zk.$$.fragment,f),C(eA.$$.fragment,f),C(Wk.$$.fragment,f),C(dA.$$.fragment,f),C(Qk.$$.fragment,f),C(Hk.$$.fragment,f),C(Jk.$$.fragment,f),C(fA.$$.fragment,f),C(Yk.$$.fragment,f),C(gA.$$.fragment,f),C(Kk.$$.fragment,f),C(Zk.$$.fragment,f),C(oS.$$.fragment,f),C(pA.$$.fragment,f),C(rS.$$.fragment,f),C(bA.$$.fragment,f),C(aS.$$.fragment,f),C(nS.$$.fragment,f),C(lS.$$.fragment,f),C(FA.$$.fragment,f),C(iS.$$.fragment,f),C(MA.$$.fragment,f),JHe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(zf),f&&t(dt),f&&t(Oe),f&&t(Qe),f&&t(Qf),w(Ia,f),f&&t(He),f&&t(Le),f&&t(Lo),f&&t(Na),f&&t(VWe),f&&t(Vi),w(HL),f&&t(XWe),f&&t(Xn),f&&t(zWe),w(UL,f),f&&t(WWe),f&&t(NR),f&&t(QWe),w(Jf,f),f&&t(HWe),f&&t(Xi),w(JL),f&&t(UWe),f&&t(yo),w(YL),w(ey),w(fh),w(oy),f&&t(JWe),f&&t(Wi),w(ry),f&&t(YWe),f&&t(xo),w(ty),w(sy),w(Qh),w(ly),f&&t(KWe),f&&t(Qi),w(iy),f&&t(ZWe),f&&t($o),w(dy),w(my),w(Rp),w(Pp),w(gy),f&&t(eQe),f&&t(Hi),w(hy),f&&t(oQe),f&&t(ko),w(py),w(by),w(r_),w(t_),w(vy),f&&t(rQe),f&&t(Ji),w(Fy),f&&t(tQe),f&&t(So),w(Ty),w(Ey),w(s_),w(Cy),w(h2),f&&t(aQe),f&&t(Zi),w(wy),f&&t(nQe),f&&t(Ro),w(Ay),w(yy),w(_2),w(xy),w(f1),f&&t(sQe),f&&t(rd),w($y),f&&t(lQe),f&&t(Po),w(ky),w(Ry),w(g1),w(Py),w(ob),f&&t(iQe),f&&t(nd),w(By),f&&t(dQe),f&&t(Bo),w(Iy),w(qy),w(tb),w(jy),w(Vb),f&&t(cQe),f&&t(id),w(Dy),f&&t(fQe),f&&t(Io),w(Gy),w(Vy),w(zb),w(Xy),w(mv),f&&t(mQe),f&&t(fd),w(zy),f&&t(gQe),f&&t(No),w(Wy),w(Hy),w(hv),w(Uy),w(h0),f&&t(hQe),f&&t(hd),w(Jy),f&&t(pQe),f&&t(qo),w(Yy),w(Zy),w(_0),w(e9),w(U0),f&&t(_Qe),f&&t(ud),w(o9),f&&t(uQe),f&&t(jo),w(r9),w(a9),w(Y0),w(n9),w(nF),f&&t(bQe),f&&t(Fd),w(s9),f&&t(vQe),f&&t(Go),w(l9),w(d9),w(lF),w(c9),w(WF),f&&t(FQe),f&&t(Ed),w(f9),f&&t(TQe),f&&t(Oo),w(m9),w(h9),w(HF),w(p9),w(jT),f&&t(MQe),f&&t(Ad),w(_9),f&&t(EQe),f&&t(Vo),w(u9),w(v9),w(GT),w(F9),w(XT),f&&t(CQe),f&&t(xd),w(T9),f&&t(wQe),f&&t(Xo),w(M9),w(C9),w(WT),w(w9),w(i8),f&&t(AQe),f&&t(Sd),w(A9),f&&t(LQe),f&&t(zo),w(L9),w(x9),w(c8),w($9),w(g8),f&&t(yQe),f&&t(Bd),w(k9),f&&t(xQe),f&&t(Wo),w(S9),w(P9),w(p8),w(B9),w(b8),f&&t($Qe),f&&t(qd),w(I9),f&&t(kQe),f&&t(Qo),w(N9),w(j9),w(F8),w(D9),w(E8),f&&t(SQe),f&&t(Gd),w(G9),f&&t(RQe),f&&t(Ho),w(O9),w(X9),w(w8),w(z9),w(I8),f&&t(PQe),f&&t(Xd),w(W9),f&&t(BQe),f&&t(Uo),w(Q9),w(U9),w(q8),w(J9),w(z8),f&&t(IQe),f&&t(Qd),w(Y9),f&&t(NQe),f&&t(Jo),w(K9),w(ex),w(Q8),w(ox),w(nM),f&&t(qQe),f&&t(Jd),w(rx),f&&t(jQe),f&&t(Yo),w(tx),w(nx),w(lM),w(sx),w(fM),f&&t(DQe),f&&t(Zd),w(ix),f&&t(GQe),f&&t(Ko),w(dx),w(fx),w(gM),w(mx),w(FM),f&&t(OQe),f&&t(rc),w(gx),f&&t(VQe),f&&t(Zo),w(hx),w(_x),w(MM),w(ux),w(yM),f&&t(XQe),f&&t(nc),w(bx),f&&t(zQe),f&&t(er),w(vx),w(Tx),w($M),w(Mx),w(PM),f&&t(WQe),f&&t(ic),w(Cx),f&&t(QQe),f&&t(or),w(wx),w(Lx),w(IM),w(yx),w(jM),f&&t(HQe),f&&t(fc),w(xx),f&&t(UQe),f&&t(rr),w($x),w(Sx),w(GM),w(Rx),w(HM),f&&t(JQe),f&&t(hc),w(Px),f&&t(YQe),f&&t(tr),w(Bx),w(Nx),w(JM),w(qx),w(ZM),f&&t(KQe),f&&t(uc),w(jx),f&&t(ZQe),f&&t(ar),w(Dx),w(Ox),w(oE),w(Vx),w(KE),f&&t(eHe),f&&t(Fc),w(Xx),f&&t(oHe),f&&t(nr),w(zx),w(Qx),w(e4),w(Hx),w(C4),f&&t(rHe),f&&t(Ec),w(Ux),f&&t(tHe),f&&t(sr),w(Jx),w(Kx),w(A4),w(Zx),w(D4),f&&t(aHe),f&&t(Ac),w(e$),f&&t(nHe),f&&t(lr),w(o$),w(t$),w(O4),w(a$),w(J4),f&&t(sHe),f&&t(xc),w(n$),f&&t(lHe),f&&t(ir),w(s$),w(i$),w(K4),w(d$),w(vC),f&&t(iHe),f&&t(Sc),w(c$),f&&t(dHe),f&&t(dr),w(f$),w(g$),w(TC),w(h$),w(SC),f&&t(cHe),f&&t(Bc),w(p$),f&&t(fHe),f&&t(cr),w(_$),w(b$),w(PC),w(v$),w(l5),f&&t(mHe),f&&t(qc),w(F$),f&&t(gHe),f&&t(fr),w(T$),w(E$),w(d5),w(C$),w(L5),f&&t(hHe),f&&t(Gc),w(w$),f&&t(pHe),f&&t(mr),w(A$),w(y$),w(x5),w(x$),w(S5),f&&t(_He),f&&t(Xc),w(k$),f&&t(uHe),f&&t(gr),w(S$),w(P$),w(P5),w(B$),w(I5),f&&t(bHe),f&&t(Qc),w(I$),f&&t(vHe),f&&t(hr),w(N$),w(j$),w(q5),w(D$),w(n3),f&&t(FHe),f&&t(Jc),w(G$),f&&t(THe),f&&t(pr),w(O$),w(X$),w(l3),w(z$),w(y3),f&&t(MHe),f&&t(Zc),w(W$),f&&t(EHe),f&&t(_r),w(Q$),w(U$),w($3),w(J$),w(S3),f&&t(CHe),f&&t(rf),w(Y$),f&&t(wHe),f&&t(ur),w(K$),w(ek),w(P3),w(ok),w(I3),f&&t(AHe),f&&t(nf),w(rk),f&&t(LHe),f&&t(br),w(tk),w(nk),w(q3),w(sk),w(gw),f&&t(yHe),f&&t(df),w(lk),f&&t(xHe),f&&t(vr),w(ik),w(ck),w(pw),w(fk),w(Lw),f&&t($He),f&&t(mf),w(mk),f&&t(kHe),f&&t(Fr),w(gk),w(pk),w(xw),w(_k),w(Vw),f&&t(SHe),f&&t(pf),w(uk),f&&t(RHe),f&&t(Tr),w(bk),w(Fk),w(zw),w(Tk),w(r6),f&&t(PHe),f&&t(bf),w(Mk),f&&t(BHe),f&&t(Mr),w(Ek),w(wk),w(a6),w(Ak),w(p6),f&&t(IHe),f&&t(Tf),w(Lk),f&&t(NHe),f&&t(Er),w(yk),w($k),w(u6),w(kk),w(y6),f&&t(qHe),f&&t(Cf),w(Sk),f&&t(jHe),f&&t(Cr),w(Rk),w(Bk),w($6),w(Ik),w(G6),f&&t(DHe),f&&t(Lf),w(Nk),f&&t(GHe),f&&t(wr),w(qk),w(Dk),w(V6),w(Gk),w(K6),f&&t(OHe),f&&t($f),w(Ok),f&&t(VHe),f&&t(Ar),w(Vk),w(zk),w(eA),w(Wk),w(dA),f&&t(XHe),f&&t(Rf),w(Qk),f&&t(zHe),f&&t(Lr),w(Hk),w(Jk),w(fA),w(Yk),w(gA),f&&t(WHe),f&&t(If),w(Kk),f&&t(QHe),f&&t(yr),w(Zk),w(oS),w(pA),w(rS),w(bA),f&&t(HHe),f&&t(jf),w(aS),f&&t(UHe),f&&t(xr),w(nS),w(lS),w(FA),w(iS),w(MA)}}}const bra={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVideoClassification",title:"AutoModelForVideoClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function vra($){return pea(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ara extends fea{constructor(g){super();mea(this,g,vra,ura,gea,{})}}export{Ara as default,bra as metadata};
