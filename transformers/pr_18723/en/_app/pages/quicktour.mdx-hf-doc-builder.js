import{S as Sf,i as If,s as Of,e as l,k as d,w as b,t as o,M as Nf,c as i,d as s,m as $,a as p,x as A,h as n,b as h,G as t,g as u,y as T,q as E,o as j,B as q,v as Df,L as ye}from"../chunks/vendor-hf-doc-builder.js";import{T as ha}from"../chunks/Tip-hf-doc-builder.js";import{Y as Cf}from"../chunks/Youtube-hf-doc-builder.js";import{I as Ce}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as U}from"../chunks/CodeBlock-hf-doc-builder.js";import{D as Hf}from"../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as cs,M as fe}from"../chunks/Markdown-hf-doc-builder.js";function Wf(F){let a,m;return a=new U({props:{code:"pip install torch",highlighted:"pip install torch"}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p:ye,i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Lf(F){let a,m;return a=new fe({props:{$$slots:{default:[Wf]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Uf(F){let a,m;return a=new U({props:{code:"pip install tensorflow",highlighted:"pip install tensorflow"}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p:ye,i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Yf(F){let a,m;return a=new fe({props:{$$slots:{default:[Uf]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Rf(F){let a,m,r,c,g,y,w,P,_,k,C,N,I,D;return I=new U({props:{code:`from transformers import AutoTokenizer, AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){a=l("p"),m=o("Use "),r=l("a"),c=o("AutoModelForSequenceClassification"),g=o(" and "),y=l("a"),w=o("AutoTokenizer"),P=o(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),_=l("code"),k=o("AutoClass"),C=o(" in the next section):"),N=d(),b(I.$$.fragment),this.h()},l(x){a=i(x,"P",{});var z=p(a);m=n(z,"Use "),r=i(z,"A",{href:!0});var v=p(r);c=n(v,"AutoModelForSequenceClassification"),v.forEach(s),g=n(z," and "),y=i(z,"A",{href:!0});var O=p(y);w=n(O,"AutoTokenizer"),O.forEach(s),P=n(z," to load the pretrained model and it\u2019s associated tokenizer (more on an "),_=i(z,"CODE",{});var Y=p(_);k=n(Y,"AutoClass"),Y.forEach(s),C=n(z," in the next section):"),z.forEach(s),N=$(x),A(I.$$.fragment,x),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoModelForSequenceClassification"),h(y,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoTokenizer")},m(x,z){u(x,a,z),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P),t(a,_),t(_,k),t(a,C),u(x,N,z),T(I,x,z),D=!0},p:ye,i(x){D||(E(I.$$.fragment,x),D=!0)},o(x){j(I.$$.fragment,x),D=!1},d(x){x&&s(a),x&&s(N),q(I,x)}}}function Gf(F){let a,m;return a=new fe({props:{$$slots:{default:[Rf]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Bf(F){let a,m,r,c,g,y,w,P,_,k,C,N,I,D;return I=new U({props:{code:`from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),{c(){a=l("p"),m=o("Use "),r=l("a"),c=o("TFAutoModelForSequenceClassification"),g=o(" and "),y=l("a"),w=o("AutoTokenizer"),P=o(" to load the pretrained model and it\u2019s associated tokenizer (more on an "),_=l("code"),k=o("TFAutoClass"),C=o(" in the next section):"),N=d(),b(I.$$.fragment),this.h()},l(x){a=i(x,"P",{});var z=p(a);m=n(z,"Use "),r=i(z,"A",{href:!0});var v=p(r);c=n(v,"TFAutoModelForSequenceClassification"),v.forEach(s),g=n(z," and "),y=i(z,"A",{href:!0});var O=p(y);w=n(O,"AutoTokenizer"),O.forEach(s),P=n(z," to load the pretrained model and it\u2019s associated tokenizer (more on an "),_=i(z,"CODE",{});var Y=p(_);k=n(Y,"TFAutoClass"),Y.forEach(s),C=n(z," in the next section):"),z.forEach(s),N=$(x),A(I.$$.fragment,x),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification"),h(y,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoTokenizer")},m(x,z){u(x,a,z),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P),t(a,_),t(_,k),t(a,C),u(x,N,z),T(I,x,z),D=!0},p:ye,i(x){D||(E(I.$$.fragment,x),D=!0)},o(x){j(I.$$.fragment,x),D=!1},d(x){x&&s(a),x&&s(N),q(I,x)}}}function Vf(F){let a,m;return a=new fe({props:{$$slots:{default:[Bf]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Jf(F){let a,m;return a=new U({props:{code:`pt_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="pt",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p:ye,i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Qf(F){let a,m;return a=new fe({props:{$$slots:{default:[Jf]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Kf(F){let a,m;return a=new U({props:{code:`tf_batch = tokenizer(
    ["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=512,
    return_tensors="tf",
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p:ye,i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Zf(F){let a,m;return a=new fe({props:{$$slots:{default:[Kf]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function Xf(F){let a,m,r,c,g,y,w,P,_,k,C;return{c(){a=l("p"),m=o("Check out the "),r=l("a"),c=o("preprocess"),g=o(" tutorial for more details about tokenization, and how to use an "),y=l("a"),w=o("AutoFeatureExtractor"),P=o(" and "),_=l("a"),k=o("AutoProcessor"),C=o(" to preprocess image, audio, and multimodal inputs."),this.h()},l(N){a=i(N,"P",{});var I=p(a);m=n(I,"Check out the "),r=i(I,"A",{href:!0});var D=p(r);c=n(D,"preprocess"),D.forEach(s),g=n(I," tutorial for more details about tokenization, and how to use an "),y=i(I,"A",{href:!0});var x=p(y);w=n(x,"AutoFeatureExtractor"),x.forEach(s),P=n(I," and "),_=i(I,"A",{href:!0});var z=p(_);k=n(z,"AutoProcessor"),z.forEach(s),C=n(I," to preprocess image, audio, and multimodal inputs."),I.forEach(s),this.h()},h(){h(r,"href","./preprocessing"),h(y,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoFeatureExtractor"),h(_,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoProcessor")},m(N,I){u(N,a,I),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P),t(a,_),t(_,k),t(a,C)},d(N){N&&s(a)}}}function eu(F){let a,m,r,c,g,y,w,P;return{c(){a=l("p"),m=o("See the "),r=l("a"),c=o("task summary"),g=o(" for tasks supported by an "),y=l("a"),w=o("AutoModel"),P=o(" class."),this.h()},l(_){a=i(_,"P",{});var k=p(a);m=n(k,"See the "),r=i(k,"A",{href:!0});var C=p(r);c=n(C,"task summary"),C.forEach(s),g=n(k," for tasks supported by an "),y=i(k,"A",{href:!0});var N=p(y);w=n(N,"AutoModel"),N.forEach(s),P=n(k," class."),k.forEach(s),this.h()},h(){h(r,"href","./task_summary"),h(y,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoModel")},m(_,k){u(_,a,k),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P)},d(_){_&&s(a)}}}function tu(F){let a,m,r,c,g,y,w,P,_,k,C,N,I,D,x,z,v,O,Y,L,R,Z,B,te,G,Q,X,V,ue,se,ve,ae,re,K,me,M,H,J;return z=new U({props:{code:`from transformers import AutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`}}),O=new ha({props:{$$slots:{default:[eu]},$$scope:{ctx:F}}}),Q=new U({props:{code:"pt_outputs = pt_model(**pt_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)'}}),H=new U({props:{code:`from torch import nn

pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)
print(pt_predictions)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`}}),{c(){a=l("p"),m=o("\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=l("a"),c=o("AutoModel"),g=o(" like you would load an "),y=l("a"),w=o("AutoTokenizer"),P=o(". The only difference is selecting the correct "),_=l("a"),k=o("AutoModel"),C=o(" for the task. For text (or sequence) classification, you should load "),N=l("a"),I=o("AutoModelForSequenceClassification"),D=o(":"),x=d(),b(z.$$.fragment),v=d(),b(O.$$.fragment),Y=d(),L=l("p"),R=o("Now pass your preprocessed batch of inputs directly to the model. You just have to unpack the dictionary by adding "),Z=l("code"),B=o("**"),te=o(":"),G=d(),b(Q.$$.fragment),X=d(),V=l("p"),ue=o("The model outputs the final activations in the "),se=l("code"),ve=o("logits"),ae=o(" attribute. Apply the softmax function to the "),re=l("code"),K=o("logits"),me=o(" to retrieve the probabilities:"),M=d(),b(H.$$.fragment),this.h()},l(S){a=i(S,"P",{});var W=p(a);m=n(W,"\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=i(W,"A",{href:!0});var ce=p(r);c=n(ce,"AutoModel"),ce.forEach(s),g=n(W," like you would load an "),y=i(W,"A",{href:!0});var Se=p(y);w=n(Se,"AutoTokenizer"),Se.forEach(s),P=n(W,". The only difference is selecting the correct "),_=i(W,"A",{href:!0});var oe=p(_);k=n(oe,"AutoModel"),oe.forEach(s),C=n(W," for the task. For text (or sequence) classification, you should load "),N=i(W,"A",{href:!0});var he=p(N);I=n(he,"AutoModelForSequenceClassification"),he.forEach(s),D=n(W,":"),W.forEach(s),x=$(S),A(z.$$.fragment,S),v=$(S),A(O.$$.fragment,S),Y=$(S),L=i(S,"P",{});var ke=p(L);R=n(ke,"Now pass your preprocessed batch of inputs directly to the model. You just have to unpack the dictionary by adding "),Z=i(ke,"CODE",{});var jt=p(Z);B=n(jt,"**"),jt.forEach(s),te=n(ke,":"),ke.forEach(s),G=$(S),A(Q.$$.fragment,S),X=$(S),V=i(S,"P",{});var ne=p(V);ue=n(ne,"The model outputs the final activations in the "),se=i(ne,"CODE",{});var qt=p(se);ve=n(qt,"logits"),qt.forEach(s),ae=n(ne," attribute. Apply the softmax function to the "),re=i(ne,"CODE",{});var Ie=p(re);K=n(Ie,"logits"),Ie.forEach(s),me=n(ne," to retrieve the probabilities:"),ne.forEach(s),M=$(S),A(H.$$.fragment,S),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoModel"),h(y,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoTokenizer"),h(_,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoModel"),h(N,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoModelForSequenceClassification")},m(S,W){u(S,a,W),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P),t(a,_),t(_,k),t(a,C),t(a,N),t(N,I),t(a,D),u(S,x,W),T(z,S,W),u(S,v,W),T(O,S,W),u(S,Y,W),u(S,L,W),t(L,R),t(L,Z),t(Z,B),t(L,te),u(S,G,W),T(Q,S,W),u(S,X,W),u(S,V,W),t(V,ue),t(V,se),t(se,ve),t(V,ae),t(V,re),t(re,K),t(V,me),u(S,M,W),T(H,S,W),J=!0},p(S,W){const ce={};W&2&&(ce.$$scope={dirty:W,ctx:S}),O.$set(ce)},i(S){J||(E(z.$$.fragment,S),E(O.$$.fragment,S),E(Q.$$.fragment,S),E(H.$$.fragment,S),J=!0)},o(S){j(z.$$.fragment,S),j(O.$$.fragment,S),j(Q.$$.fragment,S),j(H.$$.fragment,S),J=!1},d(S){S&&s(a),S&&s(x),q(z,S),S&&s(v),q(O,S),S&&s(Y),S&&s(L),S&&s(G),q(Q,S),S&&s(X),S&&s(V),S&&s(M),q(H,S)}}}function su(F){let a,m;return a=new fe({props:{$$slots:{default:[tu]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function au(F){let a,m,r,c,g,y,w,P;return{c(){a=l("p"),m=o("See the "),r=l("a"),c=o("task summary"),g=o(" for tasks supported by an "),y=l("a"),w=o("AutoModel"),P=o(" class."),this.h()},l(_){a=i(_,"P",{});var k=p(a);m=n(k,"See the "),r=i(k,"A",{href:!0});var C=p(r);c=n(C,"task summary"),C.forEach(s),g=n(k," for tasks supported by an "),y=i(k,"A",{href:!0});var N=p(y);w=n(N,"AutoModel"),N.forEach(s),P=n(k," class."),k.forEach(s),this.h()},h(){h(r,"href","./task_summary"),h(y,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoModel")},m(_,k){u(_,a,k),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P)},d(_){_&&s(a)}}}function ru(F){let a,m,r,c,g,y,w,P,_,k,C,N,I,D,x,z,v,O,Y,L,R,Z,B,te,G,Q,X,V,ue,se,ve,ae,re,K,me;return z=new U({props:{code:`from transformers import TFAutoModelForSequenceClassification

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`}}),O=new ha({props:{$$slots:{default:[au]},$$scope:{ctx:F}}}),B=new U({props:{code:"tf_outputs = tf_model(tf_batch)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)'}}),K=new U({props:{code:`import tensorflow as tf

tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)
tf_predictions`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`}}),{c(){a=l("p"),m=o("\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=l("a"),c=o("TFAutoModel"),g=o(" like you would load an "),y=l("a"),w=o("AutoTokenizer"),P=o(". The only difference is selecting the correct "),_=l("a"),k=o("TFAutoModel"),C=o(" for the task. For text (or sequence) classification, you should load "),N=l("a"),I=o("TFAutoModelForSequenceClassification"),D=o(":"),x=d(),b(z.$$.fragment),v=d(),b(O.$$.fragment),Y=d(),L=l("p"),R=o("Now pass your preprocessed batch of inputs directly to the model by passing the dictionary keys directly to the tensors:"),Z=d(),b(B.$$.fragment),te=d(),G=l("p"),Q=o("The model outputs the final activations in the "),X=l("code"),V=o("logits"),ue=o(" attribute. Apply the softmax function to the "),se=l("code"),ve=o("logits"),ae=o(" to retrieve the probabilities:"),re=d(),b(K.$$.fragment),this.h()},l(M){a=i(M,"P",{});var H=p(a);m=n(H,"\u{1F917} Transformers provides a simple and unified way to load pretrained instances. This means you can load an "),r=i(H,"A",{href:!0});var J=p(r);c=n(J,"TFAutoModel"),J.forEach(s),g=n(H," like you would load an "),y=i(H,"A",{href:!0});var S=p(y);w=n(S,"AutoTokenizer"),S.forEach(s),P=n(H,". The only difference is selecting the correct "),_=i(H,"A",{href:!0});var W=p(_);k=n(W,"TFAutoModel"),W.forEach(s),C=n(H," for the task. For text (or sequence) classification, you should load "),N=i(H,"A",{href:!0});var ce=p(N);I=n(ce,"TFAutoModelForSequenceClassification"),ce.forEach(s),D=n(H,":"),H.forEach(s),x=$(M),A(z.$$.fragment,M),v=$(M),A(O.$$.fragment,M),Y=$(M),L=i(M,"P",{});var Se=p(L);R=n(Se,"Now pass your preprocessed batch of inputs directly to the model by passing the dictionary keys directly to the tensors:"),Se.forEach(s),Z=$(M),A(B.$$.fragment,M),te=$(M),G=i(M,"P",{});var oe=p(G);Q=n(oe,"The model outputs the final activations in the "),X=i(oe,"CODE",{});var he=p(X);V=n(he,"logits"),he.forEach(s),ue=n(oe," attribute. Apply the softmax function to the "),se=i(oe,"CODE",{});var ke=p(se);ve=n(ke,"logits"),ke.forEach(s),ae=n(oe," to retrieve the probabilities:"),oe.forEach(s),re=$(M),A(K.$$.fragment,M),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.TFAutoModel"),h(y,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoTokenizer"),h(_,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.TFAutoModel"),h(N,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.TFAutoModelForSequenceClassification")},m(M,H){u(M,a,H),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P),t(a,_),t(_,k),t(a,C),t(a,N),t(N,I),t(a,D),u(M,x,H),T(z,M,H),u(M,v,H),T(O,M,H),u(M,Y,H),u(M,L,H),t(L,R),u(M,Z,H),T(B,M,H),u(M,te,H),u(M,G,H),t(G,Q),t(G,X),t(X,V),t(G,ue),t(G,se),t(se,ve),t(G,ae),u(M,re,H),T(K,M,H),me=!0},p(M,H){const J={};H&2&&(J.$$scope={dirty:H,ctx:M}),O.$set(J)},i(M){me||(E(z.$$.fragment,M),E(O.$$.fragment,M),E(B.$$.fragment,M),E(K.$$.fragment,M),me=!0)},o(M){j(z.$$.fragment,M),j(O.$$.fragment,M),j(B.$$.fragment,M),j(K.$$.fragment,M),me=!1},d(M){M&&s(a),M&&s(x),q(z,M),M&&s(v),q(O,M),M&&s(Y),M&&s(L),M&&s(Z),q(B,M),M&&s(te),M&&s(G),M&&s(re),q(K,M)}}}function ou(F){let a,m;return a=new fe({props:{$$slots:{default:[ru]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function nu(F){let a,m,r,c,g;return{c(){a=l("p"),m=o("All \u{1F917} Transformers models (PyTorch or TensorFlow) output the tensors "),r=l("em"),c=o("before"),g=o(` the final activation
function (like softmax) because the final activation function is often fused with the loss. Model outputs are special dataclasses so their attributes are autocompleted in an IDE. The model outputs behave like a tuple or a dictionary (you can index with an integer, a slice or a string) in which case, attributes that are None are ignored.`)},l(y){a=i(y,"P",{});var w=p(a);m=n(w,"All \u{1F917} Transformers models (PyTorch or TensorFlow) output the tensors "),r=i(w,"EM",{});var P=p(r);c=n(P,"before"),P.forEach(s),g=n(w,` the final activation
function (like softmax) because the final activation function is often fused with the loss. Model outputs are special dataclasses so their attributes are autocompleted in an IDE. The model outputs behave like a tuple or a dictionary (you can index with an integer, a slice or a string) in which case, attributes that are None are ignored.`),w.forEach(s)},m(y,w){u(y,a,w),t(a,m),t(a,r),t(r,c),t(a,g)},d(y){y&&s(a)}}}function lu(F){let a,m,r,c,g,y,w,P,_,k,C,N,I,D,x,z;return w=new U({props:{code:`pt_save_directory = "./pt_save_pretrained"
tokenizer.save_pretrained(pt_save_directory)
pt_model.save_pretrained(pt_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`}}),x=new U({props:{code:'pt_model = AutoModelForSequenceClassification.from_pretrained("./pt_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)'}}),{c(){a=l("p"),m=o("Once your model is fine-tuned, you can save it with its tokenizer using "),r=l("a"),c=o("PreTrainedModel.save_pretrained()"),g=o(":"),y=d(),b(w.$$.fragment),P=d(),_=l("p"),k=o("When you are ready to use the model again, reload it with "),C=l("a"),N=o("PreTrainedModel.from_pretrained()"),I=o(":"),D=d(),b(x.$$.fragment),this.h()},l(v){a=i(v,"P",{});var O=p(a);m=n(O,"Once your model is fine-tuned, you can save it with its tokenizer using "),r=i(O,"A",{href:!0});var Y=p(r);c=n(Y,"PreTrainedModel.save_pretrained()"),Y.forEach(s),g=n(O,":"),O.forEach(s),y=$(v),A(w.$$.fragment,v),P=$(v),_=i(v,"P",{});var L=p(_);k=n(L,"When you are ready to use the model again, reload it with "),C=i(L,"A",{href:!0});var R=p(C);N=n(R,"PreTrainedModel.from_pretrained()"),R.forEach(s),I=n(L,":"),L.forEach(s),D=$(v),A(x.$$.fragment,v),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/main_classes/model#transformers.PreTrainedModel.save_pretrained"),h(C,"href","/docs/transformers/pr_18723/en/main_classes/model#transformers.PreTrainedModel.from_pretrained")},m(v,O){u(v,a,O),t(a,m),t(a,r),t(r,c),t(a,g),u(v,y,O),T(w,v,O),u(v,P,O),u(v,_,O),t(_,k),t(_,C),t(C,N),t(_,I),u(v,D,O),T(x,v,O),z=!0},p:ye,i(v){z||(E(w.$$.fragment,v),E(x.$$.fragment,v),z=!0)},o(v){j(w.$$.fragment,v),j(x.$$.fragment,v),z=!1},d(v){v&&s(a),v&&s(y),q(w,v),v&&s(P),v&&s(_),v&&s(D),q(x,v)}}}function iu(F){let a,m;return a=new fe({props:{$$slots:{default:[lu]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function pu(F){let a,m,r,c,g,y,w,P,_,k,C,N,I,D,x,z;return w=new U({props:{code:`tf_save_directory = "./tf_save_pretrained"
tokenizer.save_pretrained(tf_save_directory)
tf_model.save_pretrained(tf_save_directory)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`}}),x=new U({props:{code:'tf_model = TFAutoModelForSequenceClassification.from_pretrained("./tf_save_pretrained")',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)'}}),{c(){a=l("p"),m=o("Once your model is fine-tuned, you can save it with its tokenizer using "),r=l("a"),c=o("TFPreTrainedModel.save_pretrained()"),g=o(":"),y=d(),b(w.$$.fragment),P=d(),_=l("p"),k=o("When you are ready to use the model again, reload it with "),C=l("a"),N=o("TFPreTrainedModel.from_pretrained()"),I=o(":"),D=d(),b(x.$$.fragment),this.h()},l(v){a=i(v,"P",{});var O=p(a);m=n(O,"Once your model is fine-tuned, you can save it with its tokenizer using "),r=i(O,"A",{href:!0});var Y=p(r);c=n(Y,"TFPreTrainedModel.save_pretrained()"),Y.forEach(s),g=n(O,":"),O.forEach(s),y=$(v),A(w.$$.fragment,v),P=$(v),_=i(v,"P",{});var L=p(_);k=n(L,"When you are ready to use the model again, reload it with "),C=i(L,"A",{href:!0});var R=p(C);N=n(R,"TFPreTrainedModel.from_pretrained()"),R.forEach(s),I=n(L,":"),L.forEach(s),D=$(v),A(x.$$.fragment,v),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/main_classes/model#transformers.TFPreTrainedModel.save_pretrained"),h(C,"href","/docs/transformers/pr_18723/en/main_classes/model#transformers.TFPreTrainedModel.from_pretrained")},m(v,O){u(v,a,O),t(a,m),t(a,r),t(r,c),t(a,g),u(v,y,O),T(w,v,O),u(v,P,O),u(v,_,O),t(_,k),t(_,C),t(C,N),t(_,I),u(v,D,O),T(x,v,O),z=!0},p:ye,i(v){z||(E(w.$$.fragment,v),E(x.$$.fragment,v),z=!0)},o(v){j(w.$$.fragment,v),j(x.$$.fragment,v),z=!1},d(v){v&&s(a),v&&s(y),q(w,v),v&&s(P),v&&s(_),v&&s(D),q(x,v)}}}function fu(F){let a,m;return a=new fe({props:{$$slots:{default:[pu]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function uu(F){let a,m;return a=new U({props:{code:`from transformers import AutoModel

tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p:ye,i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function mu(F){let a,m;return a=new fe({props:{$$slots:{default:[uu]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function cu(F){let a,m;return a=new U({props:{code:`from transformers import TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p:ye,i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function hu(F){let a,m;return a=new fe({props:{$$slots:{default:[cu]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function du(F){let a,m,r,c,g,y,w,P;return w=new U({props:{code:`from transformers import AutoModel

my_model = AutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = AutoModel.from_config(my_config)`}}),{c(){a=l("p"),m=o("Create a model from your custom configuration with "),r=l("a"),c=o("AutoModel.from_config()"),g=o(":"),y=d(),b(w.$$.fragment),this.h()},l(_){a=i(_,"P",{});var k=p(a);m=n(k,"Create a model from your custom configuration with "),r=i(k,"A",{href:!0});var C=p(r);c=n(C,"AutoModel.from_config()"),C.forEach(s),g=n(k,":"),k.forEach(s),y=$(_),A(w.$$.fragment,_),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config")},m(_,k){u(_,a,k),t(a,m),t(a,r),t(r,c),t(a,g),u(_,y,k),T(w,_,k),P=!0},p:ye,i(_){P||(E(w.$$.fragment,_),P=!0)},o(_){j(w.$$.fragment,_),P=!1},d(_){_&&s(a),_&&s(y),q(w,_)}}}function $u(F){let a,m;return a=new fe({props:{$$slots:{default:[du]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function _u(F){let a,m,r,c,g,y,w,P;return w=new U({props:{code:`from transformers import TFAutoModel

my_model = TFAutoModel.from_config(my_config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = TFAutoModel.from_config(my_config)`}}),{c(){a=l("p"),m=o("Create a model from your custom configuration with "),r=l("a"),c=o("TFAutoModel.from_config()"),g=o(":"),y=d(),b(w.$$.fragment),this.h()},l(_){a=i(_,"P",{});var k=p(a);m=n(k,"Create a model from your custom configuration with "),r=i(k,"A",{href:!0});var C=p(r);c=n(C,"TFAutoModel.from_config()"),C.forEach(s),g=n(k,":"),k.forEach(s),y=$(_),A(w.$$.fragment,_),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config")},m(_,k){u(_,a,k),t(a,m),t(a,r),t(r,c),t(a,g),u(_,y,k),T(w,_,k),P=!0},p:ye,i(_){P||(E(w.$$.fragment,_),P=!0)},o(_){j(w.$$.fragment,_),P=!1},d(_){_&&s(a),_&&s(y),q(w,_)}}}function gu(F){let a,m;return a=new fe({props:{$$slots:{default:[_u]},$$scope:{ctx:F}}}),{c(){b(a.$$.fragment)},l(r){A(a.$$.fragment,r)},m(r,c){T(a,r,c),m=!0},p(r,c){const g={};c&2&&(g.$$scope={dirty:c,ctx:r}),a.$set(g)},i(r){m||(E(a.$$.fragment,r),m=!0)},o(r){j(a.$$.fragment,r),m=!1},d(r){q(a,r)}}}function yu(F){let a,m,r,c,g,y,w,P,_,k,C,N,I,D,x,z,v,O,Y;return{c(){a=l("p"),m=o("For TensorFlow, use "),r=l("a"),c=o("prepare_tf_dataset()"),g=o(" to prepare your dataset as a "),y=l("code"),w=o("tf.data.Dataset"),P=o(". Then you can "),_=l("a"),k=l("code"),C=o("compile"),N=o(" and "),I=l("a"),D=l("code"),x=o("fit"),z=o(" your model with the usual Keras methods. Take a look at the "),v=l("a"),O=o("finetuning tutorial"),Y=o(" for more details."),this.h()},l(L){a=i(L,"P",{});var R=p(a);m=n(R,"For TensorFlow, use "),r=i(R,"A",{href:!0});var Z=p(r);c=n(Z,"prepare_tf_dataset()"),Z.forEach(s),g=n(R," to prepare your dataset as a "),y=i(R,"CODE",{});var B=p(y);w=n(B,"tf.data.Dataset"),B.forEach(s),P=n(R,". Then you can "),_=i(R,"A",{href:!0,rel:!0});var te=p(_);k=i(te,"CODE",{});var G=p(k);C=n(G,"compile"),G.forEach(s),te.forEach(s),N=n(R," and "),I=i(R,"A",{href:!0,rel:!0});var Q=p(I);D=i(Q,"CODE",{});var X=p(D);x=n(X,"fit"),X.forEach(s),Q.forEach(s),z=n(R," your model with the usual Keras methods. Take a look at the "),v=i(R,"A",{href:!0});var V=p(v);O=n(V,"finetuning tutorial"),V.forEach(s),Y=n(R," for more details."),R.forEach(s),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset"),h(_,"href","https://keras.io/api/models/model_training_apis/#compile-method"),h(_,"rel","nofollow"),h(I,"href","https://keras.io/api/models/model_training_apis/#fit-method"),h(I,"rel","nofollow"),h(v,"href","./training#convert-dataset-to-tensorflow-format")},m(L,R){u(L,a,R),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P),t(a,_),t(_,k),t(k,C),t(a,N),t(a,I),t(I,D),t(D,x),t(a,z),t(a,v),t(v,O),t(a,Y)},d(L){L&&s(a)}}}function vu(F){let a,m,r,c,g,y,w,P;return{c(){a=l("p"),m=o("For tasks that use a sequence-to-sequence model like translation or summarization, use the "),r=l("a"),c=o("Seq2SeqTrainer"),g=o(" and "),y=l("a"),w=o("Seq2SeqTrainingArguments"),P=o(" classes instead."),this.h()},l(_){a=i(_,"P",{});var k=p(a);m=n(k,"For tasks that use a sequence-to-sequence model like translation or summarization, use the "),r=i(k,"A",{href:!0});var C=p(r);c=n(C,"Seq2SeqTrainer"),C.forEach(s),g=n(k," and "),y=i(k,"A",{href:!0});var N=p(y);w=n(N,"Seq2SeqTrainingArguments"),N.forEach(s),P=n(k," classes instead."),k.forEach(s),this.h()},h(){h(r,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Seq2SeqTrainer"),h(y,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments")},m(_,k){u(_,a,k),t(a,m),t(a,r),t(r,c),t(a,g),t(a,y),t(y,w),t(a,P)},d(_){_&&s(a)}}}function ku(F){let a,m,r,c,g,y,w,P,_,k,C,N,I,D,x,z,v,O,Y,L,R,Z,B,te,G,Q,X,V,ue,se,ve,ae,re,K,me,M,H,J,S,W,ce,Se,oe,he,ke,jt,ne,qt,Ie,No,er,Be,tr,Oe,Ve,da,zt,Do,$a,Ho,sr,de,Wo,hs,Lo,Uo,ds,Yo,Ro,$s,Go,Bo,ar,xt,rr,le,Vo,_s,Jo,Qo,gs,Ko,Zo,ys,Xo,en,vs,tn,sn,or,Pt,nr,$e,an,ks,rn,on,Ft,nn,ln,_a,pn,fn,lr,Mt,ir,Je,un,ws,mn,cn,pr,Ct,fr,Qe,hn,bs,dn,$n,ur,St,mr,be,_n,It,gn,yn,Ot,vn,kn,cr,Nt,hr,Ke,wn,Dt,ga,bn,An,dr,Ht,$r,Ze,Tn,ya,En,jn,_r,Wt,gr,Xe,qn,As,zn,xn,yr,Ne,et,va,Lt,Pn,ka,Fn,vr,ie,Mn,Ts,Cn,Sn,Ut,In,On,Es,Nn,Dn,Yt,Hn,Wn,kr,Rt,wr,tt,br,Ae,Ln,js,Un,Yn,wa,Rn,Gn,Ar,Gt,Tr,Te,Bn,qs,Vn,Jn,zs,Qn,Kn,Er,De,st,ba,Bt,Zn,Aa,Xn,jr,Vt,qr,ee,el,xs,tl,sl,Ps,al,rl,Fs,ol,nl,Ms,ll,il,Ta,pl,fl,zr,Ee,ul,Ea,ml,cl,Cs,hl,dl,xr,He,at,ja,Jt,$l,qa,_l,Pr,rt,gl,Ss,yl,vl,Fr,ot,kl,Is,wl,bl,Mr,Qt,Cr,Os,Al,Sr,Kt,Ir,Ns,Tl,Or,nt,Ds,Hs,El,jl,ql,Ws,Ls,zl,xl,Nr,Us,Pl,Dr,lt,Hr,it,Wr,We,pt,za,Zt,Fl,xa,Ml,Lr,ft,Ur,ut,Yr,Le,mt,Pa,Xt,Cl,Fa,Sl,Rr,ct,Gr,je,Il,Ma,Ol,Nl,Ca,Dl,Hl,Br,ht,Vr,Ue,dt,Sa,es,Wl,Ia,Ll,Jr,Ys,Ul,Qr,qe,Yl,Rs,Rl,Gl,Gs,Bl,Vl,Kr,ts,Zr,$t,Xr,_t,Jl,Bs,Ql,Kl,eo,Ye,gt,Oa,ss,Zl,Na,Xl,to,_e,ei,as,Da,ti,si,rs,Ha,ai,ri,Vs,oi,ni,so,yt,ao,vt,li,Js,ii,pi,ro,pe,Re,fi,Qs,ui,mi,os,Wa,ci,hi,di,Ks,Zs,$i,_i,gi,La,yi,vi,Ua,ki,wi,ns,bi,Ya,Ai,Ti,oo,ls,no,kt,Ei,Xs,ji,qi,lo,is,io,wt,po,ze,zi,ea,xi,Pi,ta,Fi,Mi,fo,xe,Ci,sa,Si,Ii,aa,Oi,Ni,uo,Ge,bt,Ra,ps,Di,Ga,Hi,mo,ra,Wi,co;return y=new Ce({}),C=new Hf({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/quicktour.ipynb"}]}}),ne=new U({props:{code:"pip install transformers datasets",highlighted:"pip install transformers datasets"}}),Be=new cs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Yf],pytorch:[Lf]},$$scope:{ctx:F}}}),zt=new Ce({}),xt=new Cf({props:{id:"tiZFewofSLM"}}),Pt=new U({props:{code:`from transformers import pipeline

classifier = pipeline("sentiment-analysis")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)`}}),Mt=new U({props:{code:'classifier("We are very happy to show you the \u{1F917} Transformers library.")',highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9998</span>}]`}}),Ct=new U({props:{code:`results = classifier(["We are very happy to show you the \u{1F917} Transformers library.", "We hope you don't hate it."])
for result in results:
    print(f"label: {result['label']}, with score: {round(result['score'], 4)}")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>results = classifier([<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;label: <span class="hljs-subst">{result[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, with score: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(result[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
label: POSITIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.9998</span>
label: NEGATIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.5309</span>`}}),St=new U({props:{code:`import torch
from transformers import pipeline

speech_recognizer = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>speech_recognizer = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`}}),Nt=new U({props:{code:`from datasets import load_dataset, Audio

dataset = load_dataset("PolyAI/minds14", name="en-US", split="train")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`}}),Ht=new U({props:{code:'dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))'}}),Wt=new U({props:{code:`result = speech_recognizer(dataset[:4]["audio"])
print([d["text"] for d in result])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>result = speech_recognizer(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> result])
[<span class="hljs-string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="hljs-string">&quot;FODING HOW I&#x27;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="hljs-string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="hljs-string">&#x27;HOW DO I THURN A JOIN A COUNT&#x27;</span>]`}}),Lt=new Ce({}),Rt=new U({props:{code:'model_name = "nlptown/bert-base-multilingual-uncased-sentiment"',highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>'}}),tt=new cs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Vf],pytorch:[Gf]},$$scope:{ctx:F}}}),Gt=new U({props:{code:`classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier("Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr\xE8s heureux de vous pr\xE9senter la biblioth\xE8que \u{1F917} Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`}}),Bt=new Ce({}),Vt=new Cf({props:{id:"AhChOFRegn4"}}),Jt=new Ce({}),Qt=new U({props:{code:`from transformers import AutoTokenizer

model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`}}),Kt=new U({props:{code:`encoding = tokenizer("We are very happy to show you the \u{1F917} Transformers library.")
print(encoding)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;We are very happy to show you the \u{1F917} Transformers library.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">11312</span>, <span class="hljs-number">10320</span>, <span class="hljs-number">12495</span>, <span class="hljs-number">19308</span>, <span class="hljs-number">10114</span>, <span class="hljs-number">11391</span>, <span class="hljs-number">10855</span>, <span class="hljs-number">10103</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">13299</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),lt=new cs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Zf],pytorch:[Qf]},$$scope:{ctx:F}}}),it=new ha({props:{$$slots:{default:[Xf]},$$scope:{ctx:F}}}),Zt=new Ce({}),ft=new cs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ou],pytorch:[su]},$$scope:{ctx:F}}}),ut=new ha({props:{$$slots:{default:[nu]},$$scope:{ctx:F}}}),Xt=new Ce({}),ct=new cs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[fu],pytorch:[iu]},$$scope:{ctx:F}}}),ht=new cs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[hu],pytorch:[mu]},$$scope:{ctx:F}}}),es=new Ce({}),ts=new U({props:{code:`from transformers import AutoConfig

my_config = AutoConfig.from_pretrained("distilbert-base-uncased", n_heads=12)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>, n_heads=<span class="hljs-number">12</span>)`}}),$t=new cs({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[gu],pytorch:[$u]},$$scope:{ctx:F}}}),ss=new Ce({}),yt=new ha({props:{$$slots:{default:[yu]},$$scope:{ctx:F}}}),ls=new U({props:{code:`from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    tokenizer=tokenizer,
    data_collator=data_collator,
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)`}}),is=new U({props:{code:"trainer.train()",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()'}}),wt=new ha({props:{$$slots:{default:[vu]},$$scope:{ctx:F}}}),ps=new Ce({}),{c(){a=l("meta"),m=d(),r=l("h1"),c=l("a"),g=l("span"),b(y.$$.fragment),w=d(),P=l("span"),_=o("Quick tour"),k=d(),b(C.$$.fragment),N=d(),I=l("p"),D=o("The \u{1F917} Transformers library is built around four major concepts to maximize user-friendliness and flexibility:"),x=d(),z=l("ul"),v=l("li"),O=o("Start using the "),Y=l("a"),L=o("pipeline()"),R=o(" for rapid inference."),Z=d(),B=l("li"),te=o("Load a pretrained model from the "),G=l("a"),Q=o("Hub"),X=o("."),V=d(),ue=l("li"),se=o("Customize a base configuration, preprocessor, and model to modify how a model is built."),ve=d(),ae=l("li"),re=o("Use the "),K=l("a"),me=o("Trainer"),M=o(" class - a PyTorch training loop optimized for \u{1F917} Transformers models - to train a model."),H=d(),J=l("p"),S=o("Whether you\u2019re a new or seasoned developer, this quick tour will help you get started and show you how to use our library. If you\u2019re a beginner, we recommend starting our tutorials or "),W=l("a"),ce=o("course"),Se=o(" for a more in-depth introduction."),oe=d(),he=l("p"),ke=o("Before you begin, make sure you have all the necessary libraries installed:"),jt=d(),b(ne.$$.fragment),qt=d(),Ie=l("p"),No=o("You\u2019ll also need to install a machine learning framework of choice:"),er=d(),b(Be.$$.fragment),tr=d(),Oe=l("h2"),Ve=l("a"),da=l("span"),b(zt.$$.fragment),Do=d(),$a=l("span"),Ho=o("Pipeline"),sr=d(),de=l("p"),Wo=o("The "),hs=l("a"),Lo=o("pipeline()"),Uo=o(" is the easiest way to use a pretrained model for inference. You can use the "),ds=l("a"),Yo=o("pipeline()"),Ro=o(" out-of-the-box for many tasks across different modalities. It supports common NLP tasks like sentiment analysis, text generation, named entity recognition, summarization and translation. But you can also use the "),$s=l("a"),Go=o("pipeline()"),Bo=o(" for computer vision tasks such as image classification and semantic segmentation, and speech tasks like audio classification and automatic speech recognition."),ar=d(),b(xt.$$.fragment),rr=d(),le=l("p"),Vo=o("Start by creating an instance of "),_s=l("a"),Jo=o("pipeline()"),Qo=o(" and specifying a task you want to use it for. You can use the "),gs=l("a"),Ko=o("pipeline()"),Zo=o(" for any of the previously mentioned tasks, and for a complete list of supported tasks, take a look at the "),ys=l("a"),Xo=o("pipeline API reference"),en=o(". In this guide though, you\u2019ll use the "),vs=l("a"),tn=o("pipeline()"),sn=o(" for sentiment analysis as an example:"),or=d(),b(Pt.$$.fragment),nr=d(),$e=l("p"),an=o("The "),ks=l("a"),rn=o("pipeline()"),on=o(" downloads and caches a default "),Ft=l("a"),nn=o("pretrained model"),ln=o(" and tokenizer for sentiment analysis. Now you can use the "),_a=l("code"),pn=o("classifier"),fn=o(" on your target text:"),lr=d(),b(Mt.$$.fragment),ir=d(),Je=l("p"),un=o("If you have more than one input, pass your inputs as a list to the "),ws=l("a"),mn=o("pipeline()"),cn=o(" to return a list of dictionaries:"),pr=d(),b(Ct.$$.fragment),fr=d(),Qe=l("p"),hn=o("The "),bs=l("a"),dn=o("pipeline()"),$n=o(" can also iterate over an entire dataset for any task you like. For this example, let\u2019s choose automatic speech recognition as our task:"),ur=d(),b(St.$$.fragment),mr=d(),be=l("p"),_n=o("Load an audio dataset (see the \u{1F917} Datasets "),It=l("a"),gn=o("Quick Start"),yn=o(" for more details) you\u2019d like to iterate over. For example, load the "),Ot=l("a"),vn=o("MInDS-14"),kn=o(" dataset:"),cr=d(),b(Nt.$$.fragment),hr=d(),Ke=l("p"),wn=o(`You need to make sure the sampling rate of the dataset matches the sampling
rate `),Dt=l("a"),ga=l("code"),bn=o("facebook/wav2vec2-base-960h"),An=o(" was trained on:"),dr=d(),b(Ht.$$.fragment),$r=d(),Ze=l("p"),Tn=o("The audio files are automatically loaded and resampled when calling the "),ya=l("code"),En=o('"audio"'),jn=o(` column.
Extract the raw waveform arrays from the first 4 samples and pass it as a list to the pipeline:`),_r=d(),b(Wt.$$.fragment),gr=d(),Xe=l("p"),qn=o("For larger datasets where the inputs are big (like in speech or vision), you\u2019ll want to pass a generator instead of a list to load all the inputs in memory. Take a look at the "),As=l("a"),zn=o("pipeline API reference"),xn=o(" for more information."),yr=d(),Ne=l("h3"),et=l("a"),va=l("span"),b(Lt.$$.fragment),Pn=d(),ka=l("span"),Fn=o("Use another model and tokenizer in the pipeline"),vr=d(),ie=l("p"),Mn=o("The "),Ts=l("a"),Cn=o("pipeline()"),Sn=o(" can accommodate any model from the "),Ut=l("a"),In=o("Hub"),On=o(", making it easy to adapt the "),Es=l("a"),Nn=o("pipeline()"),Dn=o(" for other use-cases. For example, if you\u2019d like a model capable of handling French text, use the tags on the Hub to filter for an appropriate model. The top filtered result returns a multilingual "),Yt=l("a"),Hn=o("BERT model"),Wn=o(" finetuned for sentiment analysis you can use for French text:"),kr=d(),b(Rt.$$.fragment),wr=d(),b(tt.$$.fragment),br=d(),Ae=l("p"),Ln=o("Specify the model and tokenizer in the "),js=l("a"),Un=o("pipeline()"),Yn=o(", and now you can apply the "),wa=l("code"),Rn=o("classifier"),Gn=o(" on French text:"),Ar=d(),b(Gt.$$.fragment),Tr=d(),Te=l("p"),Bn=o("If you can\u2019t find a model for your use-case, you\u2019ll need to finetune a pretrained model on your data. Take a look at our "),qs=l("a"),Vn=o("finetuning tutorial"),Jn=o(" to learn how. Finally, after you\u2019ve finetuned your pretrained model, please consider "),zs=l("a"),Qn=o("sharing"),Kn=o(" the model with the community on the Hub to democratize machine learning for everyone! \u{1F917}"),Er=d(),De=l("h2"),st=l("a"),ba=l("span"),b(Bt.$$.fragment),Zn=d(),Aa=l("span"),Xn=o("AutoClass"),jr=d(),b(Vt.$$.fragment),qr=d(),ee=l("p"),el=o("Under the hood, the "),xs=l("a"),tl=o("AutoModelForSequenceClassification"),sl=o(" and "),Ps=l("a"),al=o("AutoTokenizer"),rl=o(" classes work together to power the "),Fs=l("a"),ol=o("pipeline()"),nl=o(" you used above. An "),Ms=l("a"),ll=o("AutoClass"),il=o(" is a shortcut that automatically retrieves the architecture of a pretrained model from it\u2019s name or path. You only need to select the appropriate "),Ta=l("code"),pl=o("AutoClass"),fl=o(" for your task and it\u2019s associated preprocessing class."),zr=d(),Ee=l("p"),ul=o("Let\u2019s return to the example from the previous section and see how you can use the "),Ea=l("code"),ml=o("AutoClass"),cl=o(" to replicate the results of the "),Cs=l("a"),hl=o("pipeline()"),dl=o("."),xr=d(),He=l("h3"),at=l("a"),ja=l("span"),b(Jt.$$.fragment),$l=d(),qa=l("span"),_l=o("AutoTokenizer"),Pr=d(),rt=l("p"),gl=o("A tokenizer is responsible for preprocessing text into an array of numbers as inputs to a model. There are multiple rules that govern the tokenization process, including how to split a word and at what level words should be split (learn more about tokenization in the "),Ss=l("a"),yl=o("tokenizer summary"),vl=o("). The most important thing to remember is you need to instantiate a tokenizer with the same model name to ensure you\u2019re using the same tokenization rules a model was pretrained with."),Fr=d(),ot=l("p"),kl=o("Load a tokenizer with "),Is=l("a"),wl=o("AutoTokenizer"),bl=o(":"),Mr=d(),b(Qt.$$.fragment),Cr=d(),Os=l("p"),Al=o("Pass your text to the tokenizer:"),Sr=d(),b(Kt.$$.fragment),Ir=d(),Ns=l("p"),Tl=o("The tokenizer returns a dictionary containing:"),Or=d(),nt=l("ul"),Ds=l("li"),Hs=l("a"),El=o("input_ids"),jl=o(": numerical representions of your tokens."),ql=d(),Ws=l("li"),Ls=l("a"),zl=o("atttention_mask"),xl=o(": indicates which tokens should be attended to."),Nr=d(),Us=l("p"),Pl=o("A tokenizer can also accept a list of inputs, and pad and truncate the text to return a batch with uniform length:"),Dr=d(),b(lt.$$.fragment),Hr=d(),b(it.$$.fragment),Wr=d(),We=l("h3"),pt=l("a"),za=l("span"),b(Zt.$$.fragment),Fl=d(),xa=l("span"),Ml=o("AutoModel"),Lr=d(),b(ft.$$.fragment),Ur=d(),b(ut.$$.fragment),Yr=d(),Le=l("h3"),mt=l("a"),Pa=l("span"),b(Xt.$$.fragment),Cl=d(),Fa=l("span"),Sl=o("Save a model"),Rr=d(),b(ct.$$.fragment),Gr=d(),je=l("p"),Il=o("One particularly cool \u{1F917} Transformers feature is the ability to save a model and reload it as either a PyTorch or TensorFlow model. The "),Ma=l("code"),Ol=o("from_pt"),Nl=o(" or "),Ca=l("code"),Dl=o("from_tf"),Hl=o(" parameter can convert the model from one framework to the other:"),Br=d(),b(ht.$$.fragment),Vr=d(),Ue=l("h2"),dt=l("a"),Sa=l("span"),b(es.$$.fragment),Wl=d(),Ia=l("span"),Ll=o("Custom model builds"),Jr=d(),Ys=l("p"),Ul=o("You can modify the model\u2019s configuration class to change how a model is built. The configuration specifies a model\u2019s attributes, such as the number of hidden layers or attention heads. You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you\u2019ll need to train the model before you can use it to get meaningful results."),Qr=d(),qe=l("p"),Yl=o("Start by importing "),Rs=l("a"),Rl=o("AutoConfig"),Gl=o(", and then load the pretrained model you want to modify. Within "),Gs=l("a"),Bl=o("AutoConfig.from_pretrained()"),Vl=o(", you can specify the attribute you want to change, such as the number of attention heads:"),Kr=d(),b(ts.$$.fragment),Zr=d(),b($t.$$.fragment),Xr=d(),_t=l("p"),Jl=o("Take a look at the "),Bs=l("a"),Ql=o("Create a custom architecture"),Kl=o(" guide for more information about building custom configurations."),eo=d(),Ye=l("h2"),gt=l("a"),Oa=l("span"),b(ss.$$.fragment),Zl=d(),Na=l("span"),Xl=o("PyTorch Trainer"),to=d(),_e=l("p"),ei=o("All models are a standard "),as=l("a"),Da=l("code"),ti=o("torch.nn.Module"),si=o(" or a "),rs=l("a"),Ha=l("code"),ai=o("tf.keras.Model"),ri=o(" so you can use them in any standard training loop. While you can write your own training loop, \u{1F917} Transformers provides a "),Vs=l("a"),oi=o("Trainer"),ni=o(" class for PyTorch, which contains the basic training loop and adds additional functionality for features like distributed training, mixed precision, and more."),so=d(),b(yt.$$.fragment),ao=d(),vt=l("p"),li=o("Depending on your task, you\u2019ll typically pass the following parameters to "),Js=l("a"),ii=o("Trainer"),pi=o(":"),ro=d(),pe=l("ol"),Re=l("li"),fi=o("A "),Qs=l("a"),ui=o("PreTrainedModel"),mi=o(" or a "),os=l("a"),Wa=l("code"),ci=o("torch.nn.Module"),hi=o("."),di=d(),Ks=l("li"),Zs=l("a"),$i=o("TrainingArguments"),_i=o(" contains the model hyperparameters you can change like learning rate, batch size, and the number of epochs to train for. The default values are used if you don\u2019t specify any training arguments."),gi=d(),La=l("li"),yi=o("Your train and test datasets."),vi=d(),Ua=l("li"),ki=o("A preprocessing class like a tokenizer, feature extractor, or processor."),wi=d(),ns=l("li"),bi=o("A "),Ya=l("code"),Ai=o("DataCollator()"),Ti=o(" to create a batch of examples from your dataset."),oo=d(),b(ls.$$.fragment),no=d(),kt=l("p"),Ei=o("When you\u2019re ready, call "),Xs=l("a"),ji=o("train()"),qi=o(" to start training:"),lo=d(),b(is.$$.fragment),io=d(),b(wt.$$.fragment),po=d(),ze=l("p"),zi=o("You can customize the training loop behavior by subclassing the methods inside "),ea=l("a"),xi=o("Trainer"),Pi=o(". This allows you to customize features such as the loss function, optimizer, and scheduler. Take a look at the "),ta=l("a"),Fi=o("Trainer"),Mi=o(" reference for which methods can be subclassed."),fo=d(),xe=l("p"),Ci=o("The other way to customize the training loop is by using "),sa=l("a"),Si=o("Callbacks"),Ii=o(". You can use callbacks to integrate with other libraries and inspect the training loop to report on progress or stop the training early. Callbacks do not modify anything in the training loop itself. To customize something like the loss function, you need to subclass the "),aa=l("a"),Oi=o("Trainer"),Ni=o(" instead."),uo=d(),Ge=l("h2"),bt=l("a"),Ra=l("span"),b(ps.$$.fragment),Di=d(),Ga=l("span"),Hi=o("What's next?"),mo=d(),ra=l("p"),Wi=o("Now that you\u2019ve completed the \u{1F917} Transformers quick tour, check out our guides and learn how to do more specific things like writing a custom model, fine-tuning a model for a task, and how to train a model with a script. If you\u2019re interested in learning more about \u{1F917} Transformers core concepts, grab a cup of coffee and take a look at our Conceptual Guides!"),this.h()},l(e){const f=Nf('[data-svelte="svelte-1phssyn"]',document.head);a=i(f,"META",{name:!0,content:!0}),f.forEach(s),m=$(e),r=i(e,"H1",{class:!0});var fs=p(r);c=i(fs,"A",{id:!0,class:!0,href:!0});var Ba=p(c);g=i(Ba,"SPAN",{});var Va=p(g);A(y.$$.fragment,Va),Va.forEach(s),Ba.forEach(s),w=$(fs),P=i(fs,"SPAN",{});var Ja=p(P);_=n(Ja,"Quick tour"),Ja.forEach(s),fs.forEach(s),k=$(e),A(C.$$.fragment,e),N=$(e),I=i(e,"P",{});var Qa=p(I);D=n(Qa,"The \u{1F917} Transformers library is built around four major concepts to maximize user-friendliness and flexibility:"),Qa.forEach(s),x=$(e),z=i(e,"UL",{});var we=p(z);v=i(we,"LI",{});var us=p(v);O=n(us,"Start using the "),Y=i(us,"A",{href:!0});var Ka=p(Y);L=n(Ka,"pipeline()"),Ka.forEach(s),R=n(us," for rapid inference."),us.forEach(s),Z=$(we),B=i(we,"LI",{});var ms=p(B);te=n(ms,"Load a pretrained model from the "),G=i(ms,"A",{href:!0,rel:!0});var Za=p(G);Q=n(Za,"Hub"),Za.forEach(s),X=n(ms,"."),ms.forEach(s),V=$(we),ue=i(we,"LI",{});var Xa=p(ue);se=n(Xa,"Customize a base configuration, preprocessor, and model to modify how a model is built."),Xa.forEach(s),ve=$(we),ae=i(we,"LI",{});var ho=p(ae);re=n(ho,"Use the "),K=i(ho,"A",{href:!0});var Ri=p(K);me=n(Ri,"Trainer"),Ri.forEach(s),M=n(ho," class - a PyTorch training loop optimized for \u{1F917} Transformers models - to train a model."),ho.forEach(s),we.forEach(s),H=$(e),J=i(e,"P",{});var $o=p(J);S=n($o,"Whether you\u2019re a new or seasoned developer, this quick tour will help you get started and show you how to use our library. If you\u2019re a beginner, we recommend starting our tutorials or "),W=i($o,"A",{href:!0,rel:!0});var Gi=p(W);ce=n(Gi,"course"),Gi.forEach(s),Se=n($o," for a more in-depth introduction."),$o.forEach(s),oe=$(e),he=i(e,"P",{});var Bi=p(he);ke=n(Bi,"Before you begin, make sure you have all the necessary libraries installed:"),Bi.forEach(s),jt=$(e),A(ne.$$.fragment,e),qt=$(e),Ie=i(e,"P",{});var Vi=p(Ie);No=n(Vi,"You\u2019ll also need to install a machine learning framework of choice:"),Vi.forEach(s),er=$(e),A(Be.$$.fragment,e),tr=$(e),Oe=i(e,"H2",{class:!0});var _o=p(Oe);Ve=i(_o,"A",{id:!0,class:!0,href:!0});var Ji=p(Ve);da=i(Ji,"SPAN",{});var Qi=p(da);A(zt.$$.fragment,Qi),Qi.forEach(s),Ji.forEach(s),Do=$(_o),$a=i(_o,"SPAN",{});var Ki=p($a);Ho=n(Ki,"Pipeline"),Ki.forEach(s),_o.forEach(s),sr=$(e),de=i(e,"P",{});var At=p(de);Wo=n(At,"The "),hs=i(At,"A",{href:!0});var Zi=p(hs);Lo=n(Zi,"pipeline()"),Zi.forEach(s),Uo=n(At," is the easiest way to use a pretrained model for inference. You can use the "),ds=i(At,"A",{href:!0});var Xi=p(ds);Yo=n(Xi,"pipeline()"),Xi.forEach(s),Ro=n(At," out-of-the-box for many tasks across different modalities. It supports common NLP tasks like sentiment analysis, text generation, named entity recognition, summarization and translation. But you can also use the "),$s=i(At,"A",{href:!0});var ep=p($s);Go=n(ep,"pipeline()"),ep.forEach(s),Bo=n(At," for computer vision tasks such as image classification and semantic segmentation, and speech tasks like audio classification and automatic speech recognition."),At.forEach(s),ar=$(e),A(xt.$$.fragment,e),rr=$(e),le=i(e,"P",{});var Pe=p(le);Vo=n(Pe,"Start by creating an instance of "),_s=i(Pe,"A",{href:!0});var tp=p(_s);Jo=n(tp,"pipeline()"),tp.forEach(s),Qo=n(Pe," and specifying a task you want to use it for. You can use the "),gs=i(Pe,"A",{href:!0});var sp=p(gs);Ko=n(sp,"pipeline()"),sp.forEach(s),Zo=n(Pe," for any of the previously mentioned tasks, and for a complete list of supported tasks, take a look at the "),ys=i(Pe,"A",{href:!0});var ap=p(ys);Xo=n(ap,"pipeline API reference"),ap.forEach(s),en=n(Pe,". In this guide though, you\u2019ll use the "),vs=i(Pe,"A",{href:!0});var rp=p(vs);tn=n(rp,"pipeline()"),rp.forEach(s),sn=n(Pe," for sentiment analysis as an example:"),Pe.forEach(s),or=$(e),A(Pt.$$.fragment,e),nr=$(e),$e=i(e,"P",{});var Tt=p($e);an=n(Tt,"The "),ks=i(Tt,"A",{href:!0});var op=p(ks);rn=n(op,"pipeline()"),op.forEach(s),on=n(Tt," downloads and caches a default "),Ft=i(Tt,"A",{href:!0,rel:!0});var np=p(Ft);nn=n(np,"pretrained model"),np.forEach(s),ln=n(Tt," and tokenizer for sentiment analysis. Now you can use the "),_a=i(Tt,"CODE",{});var lp=p(_a);pn=n(lp,"classifier"),lp.forEach(s),fn=n(Tt," on your target text:"),Tt.forEach(s),lr=$(e),A(Mt.$$.fragment,e),ir=$(e),Je=i(e,"P",{});var go=p(Je);un=n(go,"If you have more than one input, pass your inputs as a list to the "),ws=i(go,"A",{href:!0});var ip=p(ws);mn=n(ip,"pipeline()"),ip.forEach(s),cn=n(go," to return a list of dictionaries:"),go.forEach(s),pr=$(e),A(Ct.$$.fragment,e),fr=$(e),Qe=i(e,"P",{});var yo=p(Qe);hn=n(yo,"The "),bs=i(yo,"A",{href:!0});var pp=p(bs);dn=n(pp,"pipeline()"),pp.forEach(s),$n=n(yo," can also iterate over an entire dataset for any task you like. For this example, let\u2019s choose automatic speech recognition as our task:"),yo.forEach(s),ur=$(e),A(St.$$.fragment,e),mr=$(e),be=i(e,"P",{});var oa=p(be);_n=n(oa,"Load an audio dataset (see the \u{1F917} Datasets "),It=i(oa,"A",{href:!0,rel:!0});var fp=p(It);gn=n(fp,"Quick Start"),fp.forEach(s),yn=n(oa," for more details) you\u2019d like to iterate over. For example, load the "),Ot=i(oa,"A",{href:!0,rel:!0});var up=p(Ot);vn=n(up,"MInDS-14"),up.forEach(s),kn=n(oa," dataset:"),oa.forEach(s),cr=$(e),A(Nt.$$.fragment,e),hr=$(e),Ke=i(e,"P",{});var vo=p(Ke);wn=n(vo,`You need to make sure the sampling rate of the dataset matches the sampling
rate `),Dt=i(vo,"A",{href:!0,rel:!0});var mp=p(Dt);ga=i(mp,"CODE",{});var cp=p(ga);bn=n(cp,"facebook/wav2vec2-base-960h"),cp.forEach(s),mp.forEach(s),An=n(vo," was trained on:"),vo.forEach(s),dr=$(e),A(Ht.$$.fragment,e),$r=$(e),Ze=i(e,"P",{});var ko=p(Ze);Tn=n(ko,"The audio files are automatically loaded and resampled when calling the "),ya=i(ko,"CODE",{});var hp=p(ya);En=n(hp,'"audio"'),hp.forEach(s),jn=n(ko,` column.
Extract the raw waveform arrays from the first 4 samples and pass it as a list to the pipeline:`),ko.forEach(s),_r=$(e),A(Wt.$$.fragment,e),gr=$(e),Xe=i(e,"P",{});var wo=p(Xe);qn=n(wo,"For larger datasets where the inputs are big (like in speech or vision), you\u2019ll want to pass a generator instead of a list to load all the inputs in memory. Take a look at the "),As=i(wo,"A",{href:!0});var dp=p(As);zn=n(dp,"pipeline API reference"),dp.forEach(s),xn=n(wo," for more information."),wo.forEach(s),yr=$(e),Ne=i(e,"H3",{class:!0});var bo=p(Ne);et=i(bo,"A",{id:!0,class:!0,href:!0});var $p=p(et);va=i($p,"SPAN",{});var _p=p(va);A(Lt.$$.fragment,_p),_p.forEach(s),$p.forEach(s),Pn=$(bo),ka=i(bo,"SPAN",{});var gp=p(ka);Fn=n(gp,"Use another model and tokenizer in the pipeline"),gp.forEach(s),bo.forEach(s),vr=$(e),ie=i(e,"P",{});var Fe=p(ie);Mn=n(Fe,"The "),Ts=i(Fe,"A",{href:!0});var yp=p(Ts);Cn=n(yp,"pipeline()"),yp.forEach(s),Sn=n(Fe," can accommodate any model from the "),Ut=i(Fe,"A",{href:!0,rel:!0});var vp=p(Ut);In=n(vp,"Hub"),vp.forEach(s),On=n(Fe,", making it easy to adapt the "),Es=i(Fe,"A",{href:!0});var kp=p(Es);Nn=n(kp,"pipeline()"),kp.forEach(s),Dn=n(Fe," for other use-cases. For example, if you\u2019d like a model capable of handling French text, use the tags on the Hub to filter for an appropriate model. The top filtered result returns a multilingual "),Yt=i(Fe,"A",{href:!0,rel:!0});var wp=p(Yt);Hn=n(wp,"BERT model"),wp.forEach(s),Wn=n(Fe," finetuned for sentiment analysis you can use for French text:"),Fe.forEach(s),kr=$(e),A(Rt.$$.fragment,e),wr=$(e),A(tt.$$.fragment,e),br=$(e),Ae=i(e,"P",{});var na=p(Ae);Ln=n(na,"Specify the model and tokenizer in the "),js=i(na,"A",{href:!0});var bp=p(js);Un=n(bp,"pipeline()"),bp.forEach(s),Yn=n(na,", and now you can apply the "),wa=i(na,"CODE",{});var Ap=p(wa);Rn=n(Ap,"classifier"),Ap.forEach(s),Gn=n(na," on French text:"),na.forEach(s),Ar=$(e),A(Gt.$$.fragment,e),Tr=$(e),Te=i(e,"P",{});var la=p(Te);Bn=n(la,"If you can\u2019t find a model for your use-case, you\u2019ll need to finetune a pretrained model on your data. Take a look at our "),qs=i(la,"A",{href:!0});var Tp=p(qs);Vn=n(Tp,"finetuning tutorial"),Tp.forEach(s),Jn=n(la," to learn how. Finally, after you\u2019ve finetuned your pretrained model, please consider "),zs=i(la,"A",{href:!0});var Ep=p(zs);Qn=n(Ep,"sharing"),Ep.forEach(s),Kn=n(la," the model with the community on the Hub to democratize machine learning for everyone! \u{1F917}"),la.forEach(s),Er=$(e),De=i(e,"H2",{class:!0});var Ao=p(De);st=i(Ao,"A",{id:!0,class:!0,href:!0});var jp=p(st);ba=i(jp,"SPAN",{});var qp=p(ba);A(Bt.$$.fragment,qp),qp.forEach(s),jp.forEach(s),Zn=$(Ao),Aa=i(Ao,"SPAN",{});var zp=p(Aa);Xn=n(zp,"AutoClass"),zp.forEach(s),Ao.forEach(s),jr=$(e),A(Vt.$$.fragment,e),qr=$(e),ee=i(e,"P",{});var ge=p(ee);el=n(ge,"Under the hood, the "),xs=i(ge,"A",{href:!0});var xp=p(xs);tl=n(xp,"AutoModelForSequenceClassification"),xp.forEach(s),sl=n(ge," and "),Ps=i(ge,"A",{href:!0});var Pp=p(Ps);al=n(Pp,"AutoTokenizer"),Pp.forEach(s),rl=n(ge," classes work together to power the "),Fs=i(ge,"A",{href:!0});var Fp=p(Fs);ol=n(Fp,"pipeline()"),Fp.forEach(s),nl=n(ge," you used above. An "),Ms=i(ge,"A",{href:!0});var Mp=p(Ms);ll=n(Mp,"AutoClass"),Mp.forEach(s),il=n(ge," is a shortcut that automatically retrieves the architecture of a pretrained model from it\u2019s name or path. You only need to select the appropriate "),Ta=i(ge,"CODE",{});var Cp=p(Ta);pl=n(Cp,"AutoClass"),Cp.forEach(s),fl=n(ge," for your task and it\u2019s associated preprocessing class."),ge.forEach(s),zr=$(e),Ee=i(e,"P",{});var ia=p(Ee);ul=n(ia,"Let\u2019s return to the example from the previous section and see how you can use the "),Ea=i(ia,"CODE",{});var Sp=p(Ea);ml=n(Sp,"AutoClass"),Sp.forEach(s),cl=n(ia," to replicate the results of the "),Cs=i(ia,"A",{href:!0});var Ip=p(Cs);hl=n(Ip,"pipeline()"),Ip.forEach(s),dl=n(ia,"."),ia.forEach(s),xr=$(e),He=i(e,"H3",{class:!0});var To=p(He);at=i(To,"A",{id:!0,class:!0,href:!0});var Op=p(at);ja=i(Op,"SPAN",{});var Np=p(ja);A(Jt.$$.fragment,Np),Np.forEach(s),Op.forEach(s),$l=$(To),qa=i(To,"SPAN",{});var Dp=p(qa);_l=n(Dp,"AutoTokenizer"),Dp.forEach(s),To.forEach(s),Pr=$(e),rt=i(e,"P",{});var Eo=p(rt);gl=n(Eo,"A tokenizer is responsible for preprocessing text into an array of numbers as inputs to a model. There are multiple rules that govern the tokenization process, including how to split a word and at what level words should be split (learn more about tokenization in the "),Ss=i(Eo,"A",{href:!0});var Hp=p(Ss);yl=n(Hp,"tokenizer summary"),Hp.forEach(s),vl=n(Eo,"). The most important thing to remember is you need to instantiate a tokenizer with the same model name to ensure you\u2019re using the same tokenization rules a model was pretrained with."),Eo.forEach(s),Fr=$(e),ot=i(e,"P",{});var jo=p(ot);kl=n(jo,"Load a tokenizer with "),Is=i(jo,"A",{href:!0});var Wp=p(Is);wl=n(Wp,"AutoTokenizer"),Wp.forEach(s),bl=n(jo,":"),jo.forEach(s),Mr=$(e),A(Qt.$$.fragment,e),Cr=$(e),Os=i(e,"P",{});var Lp=p(Os);Al=n(Lp,"Pass your text to the tokenizer:"),Lp.forEach(s),Sr=$(e),A(Kt.$$.fragment,e),Ir=$(e),Ns=i(e,"P",{});var Up=p(Ns);Tl=n(Up,"The tokenizer returns a dictionary containing:"),Up.forEach(s),Or=$(e),nt=i(e,"UL",{});var qo=p(nt);Ds=i(qo,"LI",{});var Li=p(Ds);Hs=i(Li,"A",{href:!0});var Yp=p(Hs);El=n(Yp,"input_ids"),Yp.forEach(s),jl=n(Li,": numerical representions of your tokens."),Li.forEach(s),ql=$(qo),Ws=i(qo,"LI",{});var Ui=p(Ws);Ls=i(Ui,"A",{href:!0});var Rp=p(Ls);zl=n(Rp,"atttention_mask"),Rp.forEach(s),xl=n(Ui,": indicates which tokens should be attended to."),Ui.forEach(s),qo.forEach(s),Nr=$(e),Us=i(e,"P",{});var Gp=p(Us);Pl=n(Gp,"A tokenizer can also accept a list of inputs, and pad and truncate the text to return a batch with uniform length:"),Gp.forEach(s),Dr=$(e),A(lt.$$.fragment,e),Hr=$(e),A(it.$$.fragment,e),Wr=$(e),We=i(e,"H3",{class:!0});var zo=p(We);pt=i(zo,"A",{id:!0,class:!0,href:!0});var Bp=p(pt);za=i(Bp,"SPAN",{});var Vp=p(za);A(Zt.$$.fragment,Vp),Vp.forEach(s),Bp.forEach(s),Fl=$(zo),xa=i(zo,"SPAN",{});var Jp=p(xa);Ml=n(Jp,"AutoModel"),Jp.forEach(s),zo.forEach(s),Lr=$(e),A(ft.$$.fragment,e),Ur=$(e),A(ut.$$.fragment,e),Yr=$(e),Le=i(e,"H3",{class:!0});var xo=p(Le);mt=i(xo,"A",{id:!0,class:!0,href:!0});var Qp=p(mt);Pa=i(Qp,"SPAN",{});var Kp=p(Pa);A(Xt.$$.fragment,Kp),Kp.forEach(s),Qp.forEach(s),Cl=$(xo),Fa=i(xo,"SPAN",{});var Zp=p(Fa);Sl=n(Zp,"Save a model"),Zp.forEach(s),xo.forEach(s),Rr=$(e),A(ct.$$.fragment,e),Gr=$(e),je=i(e,"P",{});var pa=p(je);Il=n(pa,"One particularly cool \u{1F917} Transformers feature is the ability to save a model and reload it as either a PyTorch or TensorFlow model. The "),Ma=i(pa,"CODE",{});var Xp=p(Ma);Ol=n(Xp,"from_pt"),Xp.forEach(s),Nl=n(pa," or "),Ca=i(pa,"CODE",{});var ef=p(Ca);Dl=n(ef,"from_tf"),ef.forEach(s),Hl=n(pa," parameter can convert the model from one framework to the other:"),pa.forEach(s),Br=$(e),A(ht.$$.fragment,e),Vr=$(e),Ue=i(e,"H2",{class:!0});var Po=p(Ue);dt=i(Po,"A",{id:!0,class:!0,href:!0});var tf=p(dt);Sa=i(tf,"SPAN",{});var sf=p(Sa);A(es.$$.fragment,sf),sf.forEach(s),tf.forEach(s),Wl=$(Po),Ia=i(Po,"SPAN",{});var af=p(Ia);Ll=n(af,"Custom model builds"),af.forEach(s),Po.forEach(s),Jr=$(e),Ys=i(e,"P",{});var rf=p(Ys);Ul=n(rf,"You can modify the model\u2019s configuration class to change how a model is built. The configuration specifies a model\u2019s attributes, such as the number of hidden layers or attention heads. You start from scratch when you initialize a model from a custom configuration class. The model attributes are randomly initialized, and you\u2019ll need to train the model before you can use it to get meaningful results."),rf.forEach(s),Qr=$(e),qe=i(e,"P",{});var fa=p(qe);Yl=n(fa,"Start by importing "),Rs=i(fa,"A",{href:!0});var of=p(Rs);Rl=n(of,"AutoConfig"),of.forEach(s),Gl=n(fa,", and then load the pretrained model you want to modify. Within "),Gs=i(fa,"A",{href:!0});var nf=p(Gs);Bl=n(nf,"AutoConfig.from_pretrained()"),nf.forEach(s),Vl=n(fa,", you can specify the attribute you want to change, such as the number of attention heads:"),fa.forEach(s),Kr=$(e),A(ts.$$.fragment,e),Zr=$(e),A($t.$$.fragment,e),Xr=$(e),_t=i(e,"P",{});var Fo=p(_t);Jl=n(Fo,"Take a look at the "),Bs=i(Fo,"A",{href:!0});var lf=p(Bs);Ql=n(lf,"Create a custom architecture"),lf.forEach(s),Kl=n(Fo," guide for more information about building custom configurations."),Fo.forEach(s),eo=$(e),Ye=i(e,"H2",{class:!0});var Mo=p(Ye);gt=i(Mo,"A",{id:!0,class:!0,href:!0});var pf=p(gt);Oa=i(pf,"SPAN",{});var ff=p(Oa);A(ss.$$.fragment,ff),ff.forEach(s),pf.forEach(s),Zl=$(Mo),Na=i(Mo,"SPAN",{});var uf=p(Na);Xl=n(uf,"PyTorch Trainer"),uf.forEach(s),Mo.forEach(s),to=$(e),_e=i(e,"P",{});var Et=p(_e);ei=n(Et,"All models are a standard "),as=i(Et,"A",{href:!0,rel:!0});var mf=p(as);Da=i(mf,"CODE",{});var cf=p(Da);ti=n(cf,"torch.nn.Module"),cf.forEach(s),mf.forEach(s),si=n(Et," or a "),rs=i(Et,"A",{href:!0,rel:!0});var hf=p(rs);Ha=i(hf,"CODE",{});var df=p(Ha);ai=n(df,"tf.keras.Model"),df.forEach(s),hf.forEach(s),ri=n(Et," so you can use them in any standard training loop. While you can write your own training loop, \u{1F917} Transformers provides a "),Vs=i(Et,"A",{href:!0});var $f=p(Vs);oi=n($f,"Trainer"),$f.forEach(s),ni=n(Et," class for PyTorch, which contains the basic training loop and adds additional functionality for features like distributed training, mixed precision, and more."),Et.forEach(s),so=$(e),A(yt.$$.fragment,e),ao=$(e),vt=i(e,"P",{});var Co=p(vt);li=n(Co,"Depending on your task, you\u2019ll typically pass the following parameters to "),Js=i(Co,"A",{href:!0});var _f=p(Js);ii=n(_f,"Trainer"),_f.forEach(s),pi=n(Co,":"),Co.forEach(s),ro=$(e),pe=i(e,"OL",{});var Me=p(pe);Re=i(Me,"LI",{});var ua=p(Re);fi=n(ua,"A "),Qs=i(ua,"A",{href:!0});var gf=p(Qs);ui=n(gf,"PreTrainedModel"),gf.forEach(s),mi=n(ua," or a "),os=i(ua,"A",{href:!0,rel:!0});var yf=p(os);Wa=i(yf,"CODE",{});var vf=p(Wa);ci=n(vf,"torch.nn.Module"),vf.forEach(s),yf.forEach(s),hi=n(ua,"."),ua.forEach(s),di=$(Me),Ks=i(Me,"LI",{});var Yi=p(Ks);Zs=i(Yi,"A",{href:!0});var kf=p(Zs);$i=n(kf,"TrainingArguments"),kf.forEach(s),_i=n(Yi," contains the model hyperparameters you can change like learning rate, batch size, and the number of epochs to train for. The default values are used if you don\u2019t specify any training arguments."),Yi.forEach(s),gi=$(Me),La=i(Me,"LI",{});var wf=p(La);yi=n(wf,"Your train and test datasets."),wf.forEach(s),vi=$(Me),Ua=i(Me,"LI",{});var bf=p(Ua);ki=n(bf,"A preprocessing class like a tokenizer, feature extractor, or processor."),bf.forEach(s),wi=$(Me),ns=i(Me,"LI",{});var So=p(ns);bi=n(So,"A "),Ya=i(So,"CODE",{});var Af=p(Ya);Ai=n(Af,"DataCollator()"),Af.forEach(s),Ti=n(So," to create a batch of examples from your dataset."),So.forEach(s),Me.forEach(s),oo=$(e),A(ls.$$.fragment,e),no=$(e),kt=i(e,"P",{});var Io=p(kt);Ei=n(Io,"When you\u2019re ready, call "),Xs=i(Io,"A",{href:!0});var Tf=p(Xs);ji=n(Tf,"train()"),Tf.forEach(s),qi=n(Io," to start training:"),Io.forEach(s),lo=$(e),A(is.$$.fragment,e),io=$(e),A(wt.$$.fragment,e),po=$(e),ze=i(e,"P",{});var ma=p(ze);zi=n(ma,"You can customize the training loop behavior by subclassing the methods inside "),ea=i(ma,"A",{href:!0});var Ef=p(ea);xi=n(Ef,"Trainer"),Ef.forEach(s),Pi=n(ma,". This allows you to customize features such as the loss function, optimizer, and scheduler. Take a look at the "),ta=i(ma,"A",{href:!0});var jf=p(ta);Fi=n(jf,"Trainer"),jf.forEach(s),Mi=n(ma," reference for which methods can be subclassed."),ma.forEach(s),fo=$(e),xe=i(e,"P",{});var ca=p(xe);Ci=n(ca,"The other way to customize the training loop is by using "),sa=i(ca,"A",{href:!0});var qf=p(sa);Si=n(qf,"Callbacks"),qf.forEach(s),Ii=n(ca,". You can use callbacks to integrate with other libraries and inspect the training loop to report on progress or stop the training early. Callbacks do not modify anything in the training loop itself. To customize something like the loss function, you need to subclass the "),aa=i(ca,"A",{href:!0});var zf=p(aa);Oi=n(zf,"Trainer"),zf.forEach(s),Ni=n(ca," instead."),ca.forEach(s),uo=$(e),Ge=i(e,"H2",{class:!0});var Oo=p(Ge);bt=i(Oo,"A",{id:!0,class:!0,href:!0});var xf=p(bt);Ra=i(xf,"SPAN",{});var Pf=p(Ra);A(ps.$$.fragment,Pf),Pf.forEach(s),xf.forEach(s),Di=$(Oo),Ga=i(Oo,"SPAN",{});var Ff=p(Ga);Hi=n(Ff,"What's next?"),Ff.forEach(s),Oo.forEach(s),mo=$(e),ra=i(e,"P",{});var Mf=p(ra);Wi=n(Mf,"Now that you\u2019ve completed the \u{1F917} Transformers quick tour, check out our guides and learn how to do more specific things like writing a custom model, fine-tuning a model for a task, and how to train a model with a script. If you\u2019re interested in learning more about \u{1F917} Transformers core concepts, grab a cup of coffee and take a look at our Conceptual Guides!"),Mf.forEach(s),this.h()},h(){h(a,"name","hf:doc:metadata"),h(a,"content",JSON.stringify(wu)),h(c,"id","quick-tour"),h(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(c,"href","#quick-tour"),h(r,"class","relative group"),h(Y,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(G,"href","https://huggingface.co/models"),h(G,"rel","nofollow"),h(K,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Trainer"),h(W,"href","https://huggingface.co/course/chapter1/1"),h(W,"rel","nofollow"),h(Ve,"id","pipeline"),h(Ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ve,"href","#pipeline"),h(Oe,"class","relative group"),h(hs,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(ds,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h($s,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(_s,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(gs,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(ys,"href","./main_classes/pipelines"),h(vs,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(ks,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(Ft,"href","https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english"),h(Ft,"rel","nofollow"),h(ws,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(bs,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(It,"href","https://huggingface.co/docs/datasets/quickstart#audio"),h(It,"rel","nofollow"),h(Ot,"href","https://huggingface.co/datasets/PolyAI/minds14"),h(Ot,"rel","nofollow"),h(Dt,"href","https://huggingface.co/facebook/wav2vec2-base-960h"),h(Dt,"rel","nofollow"),h(As,"href","./main_classes/pipelines"),h(et,"id","use-another-model-and-tokenizer-in-the-pipeline"),h(et,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(et,"href","#use-another-model-and-tokenizer-in-the-pipeline"),h(Ne,"class","relative group"),h(Ts,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(Ut,"href","https://huggingface.co/models"),h(Ut,"rel","nofollow"),h(Es,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(Yt,"href","https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment"),h(Yt,"rel","nofollow"),h(js,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(qs,"href","./training"),h(zs,"href","./model_sharing"),h(st,"id","autoclass"),h(st,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(st,"href","#autoclass"),h(De,"class","relative group"),h(xs,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoModelForSequenceClassification"),h(Ps,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoTokenizer"),h(Fs,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(Ms,"href","./model_doc/auto"),h(Cs,"href","/docs/transformers/pr_18723/en/main_classes/pipelines#transformers.pipeline"),h(at,"id","autotokenizer"),h(at,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(at,"href","#autotokenizer"),h(He,"class","relative group"),h(Ss,"href","./tokenizer_summary"),h(Is,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoTokenizer"),h(Hs,"href","./glossary#input-ids"),h(Ls,"href",".glossary#attention-mask"),h(pt,"id","automodel"),h(pt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(pt,"href","#automodel"),h(We,"class","relative group"),h(mt,"id","save-a-model"),h(mt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(mt,"href","#save-a-model"),h(Le,"class","relative group"),h(dt,"id","custom-model-builds"),h(dt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(dt,"href","#custom-model-builds"),h(Ue,"class","relative group"),h(Rs,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoConfig"),h(Gs,"href","/docs/transformers/pr_18723/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),h(Bs,"href","./create_a_model"),h(gt,"id","pytorch-trainer"),h(gt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(gt,"href","#pytorch-trainer"),h(Ye,"class","relative group"),h(as,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(as,"rel","nofollow"),h(rs,"href","https://www.tensorflow.org/api_docs/python/tf/keras/Model"),h(rs,"rel","nofollow"),h(Vs,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Trainer"),h(Js,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Trainer"),h(Qs,"href","/docs/transformers/pr_18723/en/main_classes/model#transformers.PreTrainedModel"),h(os,"href","https://pytorch.org/docs/stable/nn.html#torch.nn.Module"),h(os,"rel","nofollow"),h(Zs,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.TrainingArguments"),h(Xs,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Trainer.train"),h(ea,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Trainer"),h(ta,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Trainer"),h(sa,"href","./main_classes/callbacks"),h(aa,"href","/docs/transformers/pr_18723/en/main_classes/trainer#transformers.Trainer"),h(bt,"id","whats-next"),h(bt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(bt,"href","#whats-next"),h(Ge,"class","relative group")},m(e,f){t(document.head,a),u(e,m,f),u(e,r,f),t(r,c),t(c,g),T(y,g,null),t(r,w),t(r,P),t(P,_),u(e,k,f),T(C,e,f),u(e,N,f),u(e,I,f),t(I,D),u(e,x,f),u(e,z,f),t(z,v),t(v,O),t(v,Y),t(Y,L),t(v,R),t(z,Z),t(z,B),t(B,te),t(B,G),t(G,Q),t(B,X),t(z,V),t(z,ue),t(ue,se),t(z,ve),t(z,ae),t(ae,re),t(ae,K),t(K,me),t(ae,M),u(e,H,f),u(e,J,f),t(J,S),t(J,W),t(W,ce),t(J,Se),u(e,oe,f),u(e,he,f),t(he,ke),u(e,jt,f),T(ne,e,f),u(e,qt,f),u(e,Ie,f),t(Ie,No),u(e,er,f),T(Be,e,f),u(e,tr,f),u(e,Oe,f),t(Oe,Ve),t(Ve,da),T(zt,da,null),t(Oe,Do),t(Oe,$a),t($a,Ho),u(e,sr,f),u(e,de,f),t(de,Wo),t(de,hs),t(hs,Lo),t(de,Uo),t(de,ds),t(ds,Yo),t(de,Ro),t(de,$s),t($s,Go),t(de,Bo),u(e,ar,f),T(xt,e,f),u(e,rr,f),u(e,le,f),t(le,Vo),t(le,_s),t(_s,Jo),t(le,Qo),t(le,gs),t(gs,Ko),t(le,Zo),t(le,ys),t(ys,Xo),t(le,en),t(le,vs),t(vs,tn),t(le,sn),u(e,or,f),T(Pt,e,f),u(e,nr,f),u(e,$e,f),t($e,an),t($e,ks),t(ks,rn),t($e,on),t($e,Ft),t(Ft,nn),t($e,ln),t($e,_a),t(_a,pn),t($e,fn),u(e,lr,f),T(Mt,e,f),u(e,ir,f),u(e,Je,f),t(Je,un),t(Je,ws),t(ws,mn),t(Je,cn),u(e,pr,f),T(Ct,e,f),u(e,fr,f),u(e,Qe,f),t(Qe,hn),t(Qe,bs),t(bs,dn),t(Qe,$n),u(e,ur,f),T(St,e,f),u(e,mr,f),u(e,be,f),t(be,_n),t(be,It),t(It,gn),t(be,yn),t(be,Ot),t(Ot,vn),t(be,kn),u(e,cr,f),T(Nt,e,f),u(e,hr,f),u(e,Ke,f),t(Ke,wn),t(Ke,Dt),t(Dt,ga),t(ga,bn),t(Ke,An),u(e,dr,f),T(Ht,e,f),u(e,$r,f),u(e,Ze,f),t(Ze,Tn),t(Ze,ya),t(ya,En),t(Ze,jn),u(e,_r,f),T(Wt,e,f),u(e,gr,f),u(e,Xe,f),t(Xe,qn),t(Xe,As),t(As,zn),t(Xe,xn),u(e,yr,f),u(e,Ne,f),t(Ne,et),t(et,va),T(Lt,va,null),t(Ne,Pn),t(Ne,ka),t(ka,Fn),u(e,vr,f),u(e,ie,f),t(ie,Mn),t(ie,Ts),t(Ts,Cn),t(ie,Sn),t(ie,Ut),t(Ut,In),t(ie,On),t(ie,Es),t(Es,Nn),t(ie,Dn),t(ie,Yt),t(Yt,Hn),t(ie,Wn),u(e,kr,f),T(Rt,e,f),u(e,wr,f),T(tt,e,f),u(e,br,f),u(e,Ae,f),t(Ae,Ln),t(Ae,js),t(js,Un),t(Ae,Yn),t(Ae,wa),t(wa,Rn),t(Ae,Gn),u(e,Ar,f),T(Gt,e,f),u(e,Tr,f),u(e,Te,f),t(Te,Bn),t(Te,qs),t(qs,Vn),t(Te,Jn),t(Te,zs),t(zs,Qn),t(Te,Kn),u(e,Er,f),u(e,De,f),t(De,st),t(st,ba),T(Bt,ba,null),t(De,Zn),t(De,Aa),t(Aa,Xn),u(e,jr,f),T(Vt,e,f),u(e,qr,f),u(e,ee,f),t(ee,el),t(ee,xs),t(xs,tl),t(ee,sl),t(ee,Ps),t(Ps,al),t(ee,rl),t(ee,Fs),t(Fs,ol),t(ee,nl),t(ee,Ms),t(Ms,ll),t(ee,il),t(ee,Ta),t(Ta,pl),t(ee,fl),u(e,zr,f),u(e,Ee,f),t(Ee,ul),t(Ee,Ea),t(Ea,ml),t(Ee,cl),t(Ee,Cs),t(Cs,hl),t(Ee,dl),u(e,xr,f),u(e,He,f),t(He,at),t(at,ja),T(Jt,ja,null),t(He,$l),t(He,qa),t(qa,_l),u(e,Pr,f),u(e,rt,f),t(rt,gl),t(rt,Ss),t(Ss,yl),t(rt,vl),u(e,Fr,f),u(e,ot,f),t(ot,kl),t(ot,Is),t(Is,wl),t(ot,bl),u(e,Mr,f),T(Qt,e,f),u(e,Cr,f),u(e,Os,f),t(Os,Al),u(e,Sr,f),T(Kt,e,f),u(e,Ir,f),u(e,Ns,f),t(Ns,Tl),u(e,Or,f),u(e,nt,f),t(nt,Ds),t(Ds,Hs),t(Hs,El),t(Ds,jl),t(nt,ql),t(nt,Ws),t(Ws,Ls),t(Ls,zl),t(Ws,xl),u(e,Nr,f),u(e,Us,f),t(Us,Pl),u(e,Dr,f),T(lt,e,f),u(e,Hr,f),T(it,e,f),u(e,Wr,f),u(e,We,f),t(We,pt),t(pt,za),T(Zt,za,null),t(We,Fl),t(We,xa),t(xa,Ml),u(e,Lr,f),T(ft,e,f),u(e,Ur,f),T(ut,e,f),u(e,Yr,f),u(e,Le,f),t(Le,mt),t(mt,Pa),T(Xt,Pa,null),t(Le,Cl),t(Le,Fa),t(Fa,Sl),u(e,Rr,f),T(ct,e,f),u(e,Gr,f),u(e,je,f),t(je,Il),t(je,Ma),t(Ma,Ol),t(je,Nl),t(je,Ca),t(Ca,Dl),t(je,Hl),u(e,Br,f),T(ht,e,f),u(e,Vr,f),u(e,Ue,f),t(Ue,dt),t(dt,Sa),T(es,Sa,null),t(Ue,Wl),t(Ue,Ia),t(Ia,Ll),u(e,Jr,f),u(e,Ys,f),t(Ys,Ul),u(e,Qr,f),u(e,qe,f),t(qe,Yl),t(qe,Rs),t(Rs,Rl),t(qe,Gl),t(qe,Gs),t(Gs,Bl),t(qe,Vl),u(e,Kr,f),T(ts,e,f),u(e,Zr,f),T($t,e,f),u(e,Xr,f),u(e,_t,f),t(_t,Jl),t(_t,Bs),t(Bs,Ql),t(_t,Kl),u(e,eo,f),u(e,Ye,f),t(Ye,gt),t(gt,Oa),T(ss,Oa,null),t(Ye,Zl),t(Ye,Na),t(Na,Xl),u(e,to,f),u(e,_e,f),t(_e,ei),t(_e,as),t(as,Da),t(Da,ti),t(_e,si),t(_e,rs),t(rs,Ha),t(Ha,ai),t(_e,ri),t(_e,Vs),t(Vs,oi),t(_e,ni),u(e,so,f),T(yt,e,f),u(e,ao,f),u(e,vt,f),t(vt,li),t(vt,Js),t(Js,ii),t(vt,pi),u(e,ro,f),u(e,pe,f),t(pe,Re),t(Re,fi),t(Re,Qs),t(Qs,ui),t(Re,mi),t(Re,os),t(os,Wa),t(Wa,ci),t(Re,hi),t(pe,di),t(pe,Ks),t(Ks,Zs),t(Zs,$i),t(Ks,_i),t(pe,gi),t(pe,La),t(La,yi),t(pe,vi),t(pe,Ua),t(Ua,ki),t(pe,wi),t(pe,ns),t(ns,bi),t(ns,Ya),t(Ya,Ai),t(ns,Ti),u(e,oo,f),T(ls,e,f),u(e,no,f),u(e,kt,f),t(kt,Ei),t(kt,Xs),t(Xs,ji),t(kt,qi),u(e,lo,f),T(is,e,f),u(e,io,f),T(wt,e,f),u(e,po,f),u(e,ze,f),t(ze,zi),t(ze,ea),t(ea,xi),t(ze,Pi),t(ze,ta),t(ta,Fi),t(ze,Mi),u(e,fo,f),u(e,xe,f),t(xe,Ci),t(xe,sa),t(sa,Si),t(xe,Ii),t(xe,aa),t(aa,Oi),t(xe,Ni),u(e,uo,f),u(e,Ge,f),t(Ge,bt),t(bt,Ra),T(ps,Ra,null),t(Ge,Di),t(Ge,Ga),t(Ga,Hi),u(e,mo,f),u(e,ra,f),t(ra,Wi),co=!0},p(e,[f]){const fs={};f&2&&(fs.$$scope={dirty:f,ctx:e}),Be.$set(fs);const Ba={};f&2&&(Ba.$$scope={dirty:f,ctx:e}),tt.$set(Ba);const Va={};f&2&&(Va.$$scope={dirty:f,ctx:e}),lt.$set(Va);const Ja={};f&2&&(Ja.$$scope={dirty:f,ctx:e}),it.$set(Ja);const Qa={};f&2&&(Qa.$$scope={dirty:f,ctx:e}),ft.$set(Qa);const we={};f&2&&(we.$$scope={dirty:f,ctx:e}),ut.$set(we);const us={};f&2&&(us.$$scope={dirty:f,ctx:e}),ct.$set(us);const Ka={};f&2&&(Ka.$$scope={dirty:f,ctx:e}),ht.$set(Ka);const ms={};f&2&&(ms.$$scope={dirty:f,ctx:e}),$t.$set(ms);const Za={};f&2&&(Za.$$scope={dirty:f,ctx:e}),yt.$set(Za);const Xa={};f&2&&(Xa.$$scope={dirty:f,ctx:e}),wt.$set(Xa)},i(e){co||(E(y.$$.fragment,e),E(C.$$.fragment,e),E(ne.$$.fragment,e),E(Be.$$.fragment,e),E(zt.$$.fragment,e),E(xt.$$.fragment,e),E(Pt.$$.fragment,e),E(Mt.$$.fragment,e),E(Ct.$$.fragment,e),E(St.$$.fragment,e),E(Nt.$$.fragment,e),E(Ht.$$.fragment,e),E(Wt.$$.fragment,e),E(Lt.$$.fragment,e),E(Rt.$$.fragment,e),E(tt.$$.fragment,e),E(Gt.$$.fragment,e),E(Bt.$$.fragment,e),E(Vt.$$.fragment,e),E(Jt.$$.fragment,e),E(Qt.$$.fragment,e),E(Kt.$$.fragment,e),E(lt.$$.fragment,e),E(it.$$.fragment,e),E(Zt.$$.fragment,e),E(ft.$$.fragment,e),E(ut.$$.fragment,e),E(Xt.$$.fragment,e),E(ct.$$.fragment,e),E(ht.$$.fragment,e),E(es.$$.fragment,e),E(ts.$$.fragment,e),E($t.$$.fragment,e),E(ss.$$.fragment,e),E(yt.$$.fragment,e),E(ls.$$.fragment,e),E(is.$$.fragment,e),E(wt.$$.fragment,e),E(ps.$$.fragment,e),co=!0)},o(e){j(y.$$.fragment,e),j(C.$$.fragment,e),j(ne.$$.fragment,e),j(Be.$$.fragment,e),j(zt.$$.fragment,e),j(xt.$$.fragment,e),j(Pt.$$.fragment,e),j(Mt.$$.fragment,e),j(Ct.$$.fragment,e),j(St.$$.fragment,e),j(Nt.$$.fragment,e),j(Ht.$$.fragment,e),j(Wt.$$.fragment,e),j(Lt.$$.fragment,e),j(Rt.$$.fragment,e),j(tt.$$.fragment,e),j(Gt.$$.fragment,e),j(Bt.$$.fragment,e),j(Vt.$$.fragment,e),j(Jt.$$.fragment,e),j(Qt.$$.fragment,e),j(Kt.$$.fragment,e),j(lt.$$.fragment,e),j(it.$$.fragment,e),j(Zt.$$.fragment,e),j(ft.$$.fragment,e),j(ut.$$.fragment,e),j(Xt.$$.fragment,e),j(ct.$$.fragment,e),j(ht.$$.fragment,e),j(es.$$.fragment,e),j(ts.$$.fragment,e),j($t.$$.fragment,e),j(ss.$$.fragment,e),j(yt.$$.fragment,e),j(ls.$$.fragment,e),j(is.$$.fragment,e),j(wt.$$.fragment,e),j(ps.$$.fragment,e),co=!1},d(e){s(a),e&&s(m),e&&s(r),q(y),e&&s(k),q(C,e),e&&s(N),e&&s(I),e&&s(x),e&&s(z),e&&s(H),e&&s(J),e&&s(oe),e&&s(he),e&&s(jt),q(ne,e),e&&s(qt),e&&s(Ie),e&&s(er),q(Be,e),e&&s(tr),e&&s(Oe),q(zt),e&&s(sr),e&&s(de),e&&s(ar),q(xt,e),e&&s(rr),e&&s(le),e&&s(or),q(Pt,e),e&&s(nr),e&&s($e),e&&s(lr),q(Mt,e),e&&s(ir),e&&s(Je),e&&s(pr),q(Ct,e),e&&s(fr),e&&s(Qe),e&&s(ur),q(St,e),e&&s(mr),e&&s(be),e&&s(cr),q(Nt,e),e&&s(hr),e&&s(Ke),e&&s(dr),q(Ht,e),e&&s($r),e&&s(Ze),e&&s(_r),q(Wt,e),e&&s(gr),e&&s(Xe),e&&s(yr),e&&s(Ne),q(Lt),e&&s(vr),e&&s(ie),e&&s(kr),q(Rt,e),e&&s(wr),q(tt,e),e&&s(br),e&&s(Ae),e&&s(Ar),q(Gt,e),e&&s(Tr),e&&s(Te),e&&s(Er),e&&s(De),q(Bt),e&&s(jr),q(Vt,e),e&&s(qr),e&&s(ee),e&&s(zr),e&&s(Ee),e&&s(xr),e&&s(He),q(Jt),e&&s(Pr),e&&s(rt),e&&s(Fr),e&&s(ot),e&&s(Mr),q(Qt,e),e&&s(Cr),e&&s(Os),e&&s(Sr),q(Kt,e),e&&s(Ir),e&&s(Ns),e&&s(Or),e&&s(nt),e&&s(Nr),e&&s(Us),e&&s(Dr),q(lt,e),e&&s(Hr),q(it,e),e&&s(Wr),e&&s(We),q(Zt),e&&s(Lr),q(ft,e),e&&s(Ur),q(ut,e),e&&s(Yr),e&&s(Le),q(Xt),e&&s(Rr),q(ct,e),e&&s(Gr),e&&s(je),e&&s(Br),q(ht,e),e&&s(Vr),e&&s(Ue),q(es),e&&s(Jr),e&&s(Ys),e&&s(Qr),e&&s(qe),e&&s(Kr),q(ts,e),e&&s(Zr),q($t,e),e&&s(Xr),e&&s(_t),e&&s(eo),e&&s(Ye),q(ss),e&&s(to),e&&s(_e),e&&s(so),q(yt,e),e&&s(ao),e&&s(vt),e&&s(ro),e&&s(pe),e&&s(oo),q(ls,e),e&&s(no),e&&s(kt),e&&s(lo),q(is,e),e&&s(io),q(wt,e),e&&s(po),e&&s(ze),e&&s(fo),e&&s(xe),e&&s(uo),e&&s(Ge),q(ps),e&&s(mo),e&&s(ra)}}}const wu={local:"quick-tour",sections:[{local:"pipeline",sections:[{local:"use-another-model-and-tokenizer-in-the-pipeline",title:"Use another model and tokenizer in the pipeline"}],title:"Pipeline"},{local:"autoclass",sections:[{local:"autotokenizer",title:"AutoTokenizer"},{local:"automodel",title:"AutoModel"},{local:"save-a-model",title:"Save a model"}],title:"AutoClass"},{local:"custom-model-builds",title:"Custom model builds"},{local:"pytorch-trainer",title:"PyTorch Trainer"},{local:"whats-next",title:"What's next?"}],title:"Quick tour"};function bu(F){return Df(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Pu extends Sf{constructor(a){super();If(this,a,bu,ku,Of,{})}}export{Pu as default,wu as metadata};
