import{S as Z_,i as F_,s as j_,e as l,k as c,w as P,t as r,M as B_,c as o,d as i,m as d,a as t,x as h,h as n,b as u,N as X,G as a,g as p,y as z,L as Q_,q as b,o as _,B as E,v as V_}from"../chunks/vendor-hf-doc-builder.js";import{I as y}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as Vc}from"../chunks/CodeBlock-hf-doc-builder.js";function H_(Gz){let Y,Pn,W,fe,No,We,Hc,Ro,Xc,hn,J,ve,Zo,Je,Yc,Fo,Wc,zn,La,Jc,bn,Pe,jo,Kc,ed,Bo,id,_n,Ua,ad,En,Ga,ld,gn,K,he,Qo,Ke,od,Vo,td,Ln,Da,rd,Un,g,Ho,nd,sd,Xo,pd,cd,Yo,dd,ud,Wo,md,fd,Jo,vd,Gn,ee,ze,Ko,ei,Pd,et,hd,Dn,O,zd,it,bd,_d,at,Ed,gd,wn,ie,be,lt,ii,Ld,ot,Ud,Sn,ae,Gd,ai,Dd,wd,wa,Dz,In,_e,Sd,tt,Id,Ad,An,Sa,qd,qn,li,yn,Ia,yd,On,Aa,Od,Mn,oi,$n,qa,Md,Tn,ya,$d,Cn,ti,kn,Oa,Td,xn,Ma,Cd,Nn,$a,kd,Rn,Ta,xd,Zn,Ca,Nd,Fn,ka,Rd,jn,xa,Zd,Bn,Na,Fd,Qn,Ra,jd,Vn,M,rt,Bd,Qd,nt,Vd,Hd,st,Xd,Hn,Za,Yd,Xn,Fa,Wd,Yn,ja,Jd,Wn,Ba,Kd,Jn,Qa,eu,Kn,$,Va,ri,iu,au,lu,Ha,ni,ou,tu,ru,pt,si,nu,ct,su,es,le,Ee,dt,pi,pu,ut,cu,is,ge,du,mt,uu,mu,as,Xa,fu,ls,ci,os,Ya,vu,ts,Le,Pu,hu,zu,rs,Wa,bu,ns,Ja,_u,ss,Ue,ft,Eu,gu,vt,Lu,ps,Ka,Uu,cs,Ge,Gu,di,Du,wu,ds,el,il,wz,us,al,Su,ms,ll,Iu,fs,T,Au,Pt,qu,yu,ht,Ou,Mu,vs,De,$u,zt,Tu,Cu,Ps,we,ku,bt,xu,Nu,hs,C,Ru,_t,Zu,Fu,Et,ju,Bu,zs,ol,Qu,bs,k,Vu,gt,Hu,Xu,Lt,Yu,Wu,_s,w,Ju,Ut,Ku,em,Gt,im,am,Dt,lm,om,Es,tl,tm,gs,rl,rm,Ls,S,wt,nm,sm,St,pm,cm,It,dm,um,At,mm,Us,nl,fm,Gs,Se,qt,vm,Pm,yt,hm,Ds,sl,zm,ws,I,ui,bm,Ot,_m,Em,gm,pl,Lm,mi,Um,Gm,Mt,Dm,wm,$t,Sm,Ss,cl,Im,Is,dl,Am,As,f,Ie,fi,qm,ym,vi,Om,Mm,$m,Tt,Pi,Tm,Cm,Ct,hi,km,xm,ul,zi,Nm,Rm,Zm,kt,bi,Fm,jm,ml,_i,Bm,Qm,Vm,fl,Ei,Hm,Xm,qs,Ae,Ym,xt,Wm,Jm,ys,vl,Km,Os,oe,ef,gi,af,lf,Pl,Sz,Ms,hl,of,$s,zl,tf,Ts,qe,rf,Nt,nf,sf,Cs,te,ye,Rt,Li,pf,Zt,cf,ks,bl,df,xs,x,uf,Ui,mf,ff,Gi,vf,Pf,Ns,N,hf,Ft,zf,bf,jt,_f,Ef,Rs,L,gf,Bt,Lf,Uf,Qt,Gf,Df,Vt,wf,Sf,Ht,If,Af,Zs,Di,qf,_l,Iz,Fs,m,yf,Xt,Of,Mf,Yt,$f,Tf,Wt,Cf,kf,Jt,xf,Nf,Kt,Rf,Zf,er,Ff,jf,ir,Bf,Qf,El,Az,js,wi,Vf,gl,qz,Bs,Si,Hf,Ll,yz,Qs,Ul,Xf,Vs,R,Yf,Ii,Wf,Jf,Ai,Kf,ev,Hs,Gl,iv,Xs,Dl,av,Ys,wl,Sl,lv,qi,ov,Ws,Il,tv,Js,A,Al,yi,rv,nv,sv,ql,Oi,pv,cv,dv,yl,Mi,uv,mv,fv,Ol,$i,vv,Pv,Ks,Ml,hv,ep,Z,ar,zv,bv,Ti,_v,Ci,Ev,gv,Lv,$l,Uv,ki,Gv,ip,re,Oe,lr,xi,Dv,or,wv,ap,Me,Sv,Ni,Iv,Av,lp,Tl,Cl,Oz,op,kl,qv,tp,xl,yv,rp,Nl,Ov,np,U,tr,Ri,Mv,$v,rr,Zi,Tv,Cv,nr,Fi,kv,xv,sr,ji,Nv,Rv,pr,Bi,Zv,sp,Rl,Fv,pp,ne,$e,cr,Qi,jv,dr,Bv,cp,Zl,Qv,dp,Fl,jl,Mz,up,Te,Vv,Vi,Hv,Xv,mp,Bl,Yv,fp,Ql,Wv,vp,G,Vl,Hi,Jv,Kv,eP,ur,Xi,iP,aP,mr,Yi,lP,oP,fr,Wi,tP,rP,vr,Ji,nP,Pp,Hl,sP,hp,se,Ce,Pr,Ki,pP,hr,cP,zp,ke,dP,Xl,uP,mP,bp,Yl,fP,_p,Wl,vP,Ep,xe,PP,zr,hP,zP,gp,Jl,bP,Lp,Kl,_P,Up,eo,EP,Gp,Ne,Re,ea,gP,LP,ia,UP,GP,DP,br,aa,wP,Dp,io,SP,wp,ao,_r,la,IP,Sp,lo,AP,Ip,pe,Ze,Er,oa,qP,gr,yP,Ap,ta,ra,OP,MP,qp,na,$P,sa,TP,yp,oo,CP,Op,q,Lr,kP,xP,Ur,NP,RP,Gr,ZP,FP,Dr,jP,Mp,to,BP,$p,ro,wr,QP,Tp,no,VP,Cp,so,Sr,HP,kp,po,XP,xp,co,Ir,YP,Np,uo,WP,Rp,mo,Ar,JP,Zp,fo,KP,Fp,vo,Po,$z,jp,ho,eh,Bp,zo,ih,Qp,bo,ah,Vp,Fe,lh,pa,oh,th,Hp,ce,je,qr,ca,rh,yr,nh,Xp,_o,sh,Yp,Eo,Or,ph,Wp,F,da,Mr,ch,dh,$r,Tr,uh,mh,ua,Cr,fh,vh,ma,kr,Ph,hh,xr,zh,bh,Nr,Rr,_h,Jp,go,de,Eh,fa,gh,Lh,Zr,Uh,Gh,Kp,Lo,Fr,Dh,ec,j,va,jr,wh,Sh,Pa,Br,Ih,Ah,Qr,qh,yh,ha,Vr,Oh,Mh,ue,Hr,Xr,$h,Th,Yr,Wr,Ch,kh,me,Jr,xh,Nh,Kr,Rh,Zh,en,Fh,jh,za,an,Bh,Qh,ba,ln,Vh,Hh,on,Xh,ic,Uo,tn,Yh,ac,Be,_a,rn,Wh,Jh,Ea,nn,Kh,ez,sn,iz,az,ga,pn,lz,oz,cn,dn,tz,lc;return We=new y({}),Je=new y({}),Ke=new y({}),ei=new y({}),ii=new y({}),li=new Vc({props:{code:`La | Lb | Lc
---|----|---
a0 | b0 | c0
a1 | b1 | c1
a2 | b2 | c2`,highlighted:`La |<span class="hljs-string"> Lb </span>|<span class="hljs-string"> Lc
---</span>|<span class="hljs-string">----</span>|<span class="hljs-string">---
a0 </span>|<span class="hljs-string"> b0 </span>|<span class="hljs-string"> c0
a1 </span>|<span class="hljs-string"> b1 </span>|<span class="hljs-string"> c1
a2 </span>|<span class="hljs-string"> b2 </span>|<span class="hljs-string"> c2</span>`}}),oi=new Vc({props:{code:`GPU0:
La | Lb | Lc
---|----|---
a0 | b0 | c0

GPU1:
La | Lb | Lc
---|----|---
a1 | b1 | c1

GPU2:
La | Lb | Lc
---|----|---
a2 | b2 | c2`,highlighted:`GPU0:
La |<span class="hljs-string"> Lb </span>|<span class="hljs-string"> Lc
---</span>|<span class="hljs-string">----</span>|<span class="hljs-string">---
a0 </span>|<span class="hljs-string"> b0 </span>|<span class="hljs-string"> c0

GPU1:
La </span>|<span class="hljs-string"> Lb </span>|<span class="hljs-string"> Lc
---</span>|<span class="hljs-string">----</span>|<span class="hljs-string">---
a1 </span>|<span class="hljs-string"> b1 </span>|<span class="hljs-string"> c1

GPU2:
La </span>|<span class="hljs-string"> Lb </span>|<span class="hljs-string"> Lc
---</span>|<span class="hljs-string">----</span>|<span class="hljs-string">---
a2 </span>|<span class="hljs-string"> b2 </span>|<span class="hljs-string"> c2</span>`}}),ti=new Vc({props:{code:`x0 => GPU0
x1 => GPU1
x2 => GPU2`,highlighted:`<span class="hljs-attribute">x0</span> <span class="hljs-operator">=</span>&gt; GPU0
<span class="hljs-attribute">x1</span> <span class="hljs-operator">=</span>&gt; GPU1
<span class="hljs-attribute">x2</span> <span class="hljs-operator">=</span>&gt; GPU2`}}),pi=new y({}),ci=new Vc({props:{code:`===================  ===================
|  0 | 1 | 2 | 3  |  |  4 | 5 | 6 | 7  |
===================  ===================
        gpu0                 gpu1`,highlighted:`===================  ===================
|<span class="hljs-string">  0 </span>|<span class="hljs-string"> 1 </span>|<span class="hljs-string"> 2 </span>|<span class="hljs-string"> 3  </span>|<span class="hljs-string">  </span>|<span class="hljs-string">  4 </span>|<span class="hljs-string"> 5 </span>|<span class="hljs-string"> 6 </span>|<span class="hljs-string"> 7  </span>|
===================  ===================
        gpu0                 gpu1`}}),Li=new y({}),xi=new y({}),Qi=new y({}),Ki=new y({}),oa=new y({}),ca=new y({}),{c(){Y=l("meta"),Pn=c(),W=l("h1"),fe=l("a"),No=l("span"),P(We.$$.fragment),Hc=c(),Ro=l("span"),Xc=r("Parallelizzazione dei modelli"),hn=c(),J=l("h2"),ve=l("a"),Zo=l("span"),P(Je.$$.fragment),Yc=c(),Fo=l("span"),Wc=r("Panoramica della parallelizzazione"),zn=c(),La=l("p"),Jc=r("I vari approcci della parallelizzazione sono usati nel machine learning moderno per:"),bn=c(),Pe=l("ol"),jo=l("li"),Kc=r("adattare modelli molto grandi in hardware limitati - ad esempio, i soli parametri del modello t5-11b pesano 45GB"),ed=c(),Bo=l("li"),id=r("velocizzare significativamente l\u2019allenamento - terminando in poche ore allenamenti che impiegherebbero un anno"),_n=c(),Ua=l("p"),ad=r(`Inizieremo discutendo in dettaglio diverse tecniche di parallelizzazione 1D, i loro pro e contro e come queste possano essere combinate in
parallelizzazione 2D e 3D per consentire un allenamento ancora pi\xF9 veloce e supportare modelli ancora pi\xF9 grandi. Diversi potenti approcci alternativi saranno presentati.`),En=c(),Ga=l("p"),ld=r("Sebbene i concetti principali siano applicabili ad ogni altro framework, questo articolo \xE8 incentrato sulle implementazioni basate su Pytorch."),gn=c(),K=l("h2"),he=l("a"),Qo=l("span"),P(Ke.$$.fragment),od=c(),Vo=l("span"),td=r("Concetti"),Ln=c(),Da=l("p"),rd=r("Segue una breve descrizione dei concetti principali che verranno dettagliatamente descritti in questo documento."),Un=c(),g=l("ol"),Ho=l("li"),nd=r("DataParallel (DP) - lo stesso setup \xE8 replicato pi\xF9 volte, passando ciascuna volta una parte dei dati. Il processing \xE8 eseguito in parallelo e tutti i setup sono sincronizzati alla fine di ogni iterazione di allenamento."),sd=c(),Xo=l("li"),pd=r("TensorParallel (TP) - ogni tensore \xE8 diviso in pi\xF9 blocchi, in questo modo anzich\xE8 dover essere collocato interamente in un\u2019unica GPU, ciascun blocco di tensore risieder\xE0 nella GPU ad esso assegnata. Durante il processing, ogni blocco \xE8 processato separatamente e in parallelo su differenti GPU ed i risultati sono poi sincronizzati alla fine dello step. Questo processo \xE8 talvolta definito parallelizzazione orizzontale poich\xE8 lo splitting avviene su un livello orizzontale."),cd=c(),Yo=l("li"),dd=r("PipelineParallel (PP) - il modello \xE8 diviso verticalmente (layer-level) su pi\xF9 GPU, cos\xEC che solo uno o pi\xF9 layers del modello risiedano in un\u2019unica GPU. Ciascuna GPU esegue in parallelo le differenti fase della pipeline e lavora su una porzione ridotta della batch."),ud=c(),Wo=l("li"),md=r("Zero Redundancy Optimizer (ZeRO) - esegue una divisione simile al metodo TP, con l\u2019eccezione che l\u2019intero tensore viene poi ricostruito per una computazione in avanti (forward) o all\u2019indietro (backward), per cui il modello non deve essere modificato. Supporta anche diverse tecniche di offloading per compensare in casi di memoria GPU limitata."),fd=c(),Jo=l("li"),vd=r("Sharded DDP - \xE8 un altro nome per il metodo ZeRO in diverse altre implementazioni di ZeRO."),Gn=c(),ee=l("h2"),ze=l("a"),Ko=l("span"),P(ei.$$.fragment),Pd=c(),et=l("span"),hd=r("Parallelizzazione dei Dati"),Dn=c(),O=l("p"),zd=r("La maggior parte degli utenti con sole 2 GPU godono gi\xE0 di una velocit\xE0 di allenamento migliorata grazie a "),it=l("code"),bd=r("DataParallel"),_d=r(" (DP) e "),at=l("code"),Ed=r("DistributedDataParallel"),gd=r(` (DDP)
che sono pressoch\xE8 banali da utilizzare. Questa \xE8 una funzionalit\xE0 built-in di Pytorch.`),wn=c(),ie=l("h2"),be=l("a"),lt=l("span"),P(ii.$$.fragment),Ld=c(),ot=l("span"),Ud=r("Parallelizzazione dei Dati con ZeRO"),Sn=c(),ae=l("p"),Gd=r("La parallelizzazione dei dati ZeRO-powered (ZeRO-DP) \xE8 descritta dal seguente diagramma preso da questo "),ai=l("a"),Dd=r("post:"),wd=c(),wa=l("img"),In=c(),_e=l("p"),Sd=r("Pu\xF2 essere difficile da comprendere, ma in realt\xE0 il concetto \xE8 relativamente semplice. Consiste nel comune "),tt=l("code"),Id=r("DataParallel"),Ad=r(` (DP),
dove anzich\xE8 replicare tutti i parametri del modello, gradienti e stati degli ottimizzatori, ogni GPU ne memorizza soltanto una parte.
Dopodich\xE8, nel momento del run-time in cui tutti i parametri di quel layer sono necessari, le GPU si sincronizzano per dare l\u2019un l\u2019altra le parti mancanti - tutto qui.`),An=c(),Sa=l("p"),qd=r("Considera questo semplice modello con 3 layer, dove ogni layer ha 3 parametri:"),qn=c(),P(li.$$.fragment),yn=c(),Ia=l("p"),yd=r("Il layer La ha pesi a0, a1 ed a2."),On=c(),Aa=l("p"),Od=r("Se abbiamo 3 GPU, lo Shared DDP (o Zero-DP) divide il modello in 3 GPU come segue:"),Mn=c(),P(oi.$$.fragment),$n=c(),qa=l("p"),Md=r(`In un certo senso, questo \xE8 lo stesso di fare slicing orizzontale, come nella parallelzzazione dei tensori, se immaginiamo il tipico diagramma DNN.
Lo slicing verticale invece si ha quando inseriamo interi layer (o gruppi di layer) su diverse GPU. Ma questo \xE8 soltanto l\u2019inizio.`),Tn=c(),ya=l("p"),$d=r("Adesso, ogni GPU ricever\xE0 le classiche mini-batch come nel DP:"),Cn=c(),P(ti.$$.fragment),kn=c(),Oa=l("p"),Td=r("Gli input sono invariati, come se venissero processati dal modello normale."),xn=c(),Ma=l("p"),Cd=r("Innanzitutto, gli input entrano nel layer La."),Nn=c(),$a=l("p"),kd=r("Concentriamoci solo su GPU0: x0 necessita dei parametri a0, a1 e a2 per il suo percorso in avanti, ma GPU0 ha solo a0 - per cui riceve a1 da GPU1 e a2 da GPU2, ricostruendo insieme tutte le parti del modello."),Rn=c(),Ta=l("p"),xd=r("In parallelo, GPU1 riceve la mini-batch x1 ed ha soltanto a1, ma richiede anche a0 e a2, per cui li ottiene da GPU0 e GPU2."),Zn=c(),Ca=l("p"),Nd=r("Lo stesso avviene a GPU2 che riceve l\u2019input x2. Riceve a0 e a1 da GPU0 e GPU1 e assieme al suo a2 ricostruisce l\u2019intero tensore."),Fn=c(),ka=l("p"),Rd=r("Tutte e 3 le GPU ottengono i tensori completi ed il passaggio in avanti viene effettuato."),jn=c(),xa=l("p"),Zd=r("Non appena i calcoli sono effettuati, i dati che non sono pi\xF9 necessari vengono rimossi - sono utilizzati soltanto durante il calcolo. La ricostruzione \xE8 effettuata in modo efficiente tramite un pre-fetch."),Bn=c(),Na=l("p"),Fd=r("L\u2019intero procedimento \xE8 ripetuto per il layer Lb ed Lc nel passaggio in avanti, e poi all\u2019indietro Lc -> Lb -> La."),Qn=c(),Ra=l("p"),jd=r("Sembra proprio un\u2019efficiente strategia con cui distribuire i pesi:"),Vn=c(),M=l("ol"),rt=l("li"),Bd=r("La persona A porta la tenda,"),Qd=c(),nt=l("li"),Vd=r("La persona B porta il fornello,"),Hd=c(),st=l("li"),Xd=r("La persona C porta l\u2019ascia."),Hn=c(),Za=l("p"),Yd=r(`Ogni notte, condividono quello che hanno con gli altri e ricevono dagli altri quello che non hanno, e la mattina riprendono l\u2019equipaggiamento a
loro assegnato e continuano per la loro strada. Questo \xE8 lo Shared DDP / Zero DP.`),Xn=c(),Fa=l("p"),Wd=r(`Comparando questa strategia con quella pi\xF9 semplice, in cui ogni persona si porta la propria tenda, fornello ed ascia, quest\u2019ultima sarebbe molto pi\xF9 inefficiente.
Questo \xE8 il DataParallel (DP e DDP) su Pytorch.`),Yn=c(),ja=l("p"),Jd=r("Leggendo la letteratura su questo argomento, potrai incontrare i seguenti sinonimi: condiviso (shared), partizionato (partitioned)."),Wn=c(),Ba=l("p"),Kd=r(`Se presti molta attenzione al metodo in cui ZeRO suddivide i pesi del modello, noterai che \xE8 molto simile alla parallelizzazione dei tensori
che discuteremo pi\xF9 avanti. Questo perch\xE8 divide il peso di ogni layer, al contrario della parallelizzazione verticale che verr\xE0 discussa di seguito.`),Jn=c(),Qa=l("p"),eu=r("Implementazione:"),Kn=c(),$=l("ul"),Va=l("li"),ri=l("a"),iu=r("DeepSpeed"),au=r(" ZeRO-DP stages 1+2+3"),lu=c(),Ha=l("li"),ni=l("a"),ou=r("Fairscale"),tu=r(" ZeRO-DP stages 1+2+3"),ru=c(),pt=l("li"),si=l("a"),nu=r("Integrazione "),ct=l("code"),su=r("transformers"),es=c(),le=l("h2"),Ee=l("a"),dt=l("span"),P(pi.$$.fragment),pu=c(),ut=l("span"),cu=r("Parallelizzazione Ingenua del Modello (Verticale) e Parallelizzazione di Pipeline"),is=c(),ge=l("p"),du=r(`La Naive Model Parallelism (MP) si ha quando dividiamo parti dei layer di un modello su pi\xF9 GPU. Il meccanismo \xE8 relativamente semplice - i layer desiderati sono
indirizzati ai dispositivi che desideriamo tramite `),mt=l("code"),uu=r(".to()"),mu=r(" e ogniqualvolta i dati entrano ed escono dai layer, questi passano per lo stesso dispositivo e lasciano gli altri invariati."),as=c(),Xa=l("p"),fu=r(`Ci riferiamo a questo metodo come MP Verticale, perch\xE8 se ricordiamo come la maggior parte dei modelli sono disegnati, stiamo dividendo i modelli in verticale.
Ad esempio, il seguente diagramma mostra un modello con 8 layer:`),ls=c(),P(ci.$$.fragment),os=c(),Ya=l("p"),vu=r("Abbiamo semplicemente diviso il modello in 2 in verticale, inserendo i layer da 0 a 3 nella GPU0 e da 4 a 7 nella GPU1."),ts=c(),Le=l("p"),Pu=r(`Finch\xE8 i dati viaggiano dal layer 0 a 1, da 1 a 2, da 2 a 3, questi percorrono il modello in modo tradizionale.
Quando per\xF2 i dati passano dal layer 3 al layer 4, deve viaggiare dalla GPU0 alla GPU1, introducendo un communication overhead.
Se le GPU che partecipano sono sullo stesso nodo computazionale (ad esempio, la stessa macchina fisica), questo passaggio
\xE8 piuttosto veloce, ma se le GPU si trovano in diversi nodi computazionali (ad esempio, su pi\xF9 macchine), il tempo richiesto per la comunicazione`),hu=l("br"),zu=r(`
potrebbe essere molto grande.`),rs=c(),Wa=l("p"),bu=r(`Infine, il passaggio dal layer 4 al 5, al 6 ed infine al 7 tornano ad essere quelli del modello normale, e quando il passaggio al layer 7 \xE8 completato,
spesso dobbiamo re-inviare i dati indietro al layer 0, in cui sono presenti le labels (oppure, dobbiamo far passare le labels all\u2019ultimo layer).
A questo punto, la funzione di perdita pu\xF2 essere calcolata e l\u2019ottimizzatore pu\xF2 fare il suo lavoro.`),ns=c(),Ja=l("p"),_u=r("Problemi:"),ss=c(),Ue=l("ul"),ft=l("li"),Eu=r("la principale lacuna del metodo, da cui il nome MP \u201Cingenuo\u201D, \xE8 che soltanto una GPU \xE8 attiva in ogni momento. Perci\xF2, se 4 GPU sono utilizzate, \xE8 quasi identico a quadruplicare la quantit\xE0 di memoria di una singola GPU, ignorando il resto dell\u2019hardware. Inoltre, si aggiunge il costo di copiare i dati fra diversi dispositivi. Quindi 4x GPU da 6GB sarebbero in grado di accomodare la stessa dimensione di una GPU da 24GB, ma quest\u2019ultima completerebbe l\u2019allenamento in modo pi\xF9 veloce, dal momento che non ha il costo di copiare i dati. Ma, qualora dovessimo avere GPU da 40GB per contenere un modello da 45GB, questo metodo ci permetterebbe di eseguire l\u2019allenamento."),gu=c(),vt=l("li"),Lu=r("rappresentazioni (embedding) condivise potrebbero dover essere copiate avanti e indietro fra le GPU."),ps=c(),Ka=l("p"),Uu=r("La parallelizzazione delle Pipeline (PP) \xE8 pressoch\xE8 identica al metodo MP ingenuo, ma risolve il problema dell\u2019utilizzo di una sola GPU alla volta, dividendo la batch di dati in entrata in mini-batches e creando artificialmente una pipeline che consente alle differenti GPU di partecipare congiuntamente al processo computazionale."),cs=c(),Ge=l("p"),Gu=r("La seguente immagine dal "),di=l("a"),Du=r("paper GPipe"),wu=r(`
mostra il MP ingenuo in alto ed il PP in basso:`),ds=c(),el=l("p"),il=l("img"),us=c(),al=l("p"),Su=r("In basso nel diagramma possiamo facilmente notare come il PP ha meno tempi morti in cui le GPU non lavorano. Le parti in cui le GPU non lavorano sono spesso chiamate \u201Cbolle\u201D."),ms=c(),ll=l("p"),Iu=r(`Il grado di parallelizzazione in entrambe le parti dei diagrammi \xE8 4. Ci\xF2 significa che 4 GPU partecipano nel processo.
Per cui abbiamo un percorso in avanti di 4 passaggi, F0, F1, F2 e F3, seguito da un passaggio all\u2019indietro da B3, B2, B1 e B0.`),fs=c(),T=l("p"),Au=r("PP introduce un nuovo iperparametro da aggiustare: "),Pt=l("code"),qu=r("chunks"),yu=r(`, che definisce quanti blocchi di dati sono inviati allo stesso passaggio nella pipeline. Ad esempio,
nel diagramma in basso possiamo vedere che `),ht=l("code"),Ou=r("chunks=4"),Mu=r(`. GPU0 effettua lo stesso passaggio sui blocchi 0, 1, 2 e 3 (F0,0, F0,1, F0,2, F0,3) dopodich\xE8
attende che le altre GPU facciano il loro lavoro e, quando stanno per terminare, GPU0 ricomincia a lavorare per il passaggio all\u2019indietro dei blocchi 3, 2, 1 e 0 (B0,3, B0,2, B0,1, B0,0).`),vs=c(),De=l("p"),$u=r("Notiamo inoltre che concettualmente, questo \xE8 lo stesso concetto di uno step di accumulazione del gradiente (GAS). Pytorch utilizza "),zt=l("code"),Tu=r("chunks"),Cu=r(`
mentre DeepSpeed si riferisce allo stesso iperparametro come GAS.`),Ps=c(),we=l("p"),ku=r(`A causa dei blocchi, PP introduce il concetto di micro-batches (MBS). DP divide la bath size globale in mini-batches, quindi se abbiamo un grado di DP pari a 4,
una batch globale di dimensione 1024 vien divisa in 4 mini-batches da 256 ciascuna (1024/4). E se il numero di `),bt=l("code"),xu=r("chunks"),Nu=r(` (o GAS) \xE8 pari a 32, otteniamo
una micro-batch di dimensione 8 (256/32). Ogni passaggio della Pipeline funziona con una sola micro-batch alla volta.`),hs=c(),C=l("p"),Ru=r("Per calcolare la dimensione globale della batch di DP + PP possiamo eseguire: "),_t=l("code"),Zu=r("mbs*chunks*dp_degree"),Fu=r(" ("),Et=l("code"),ju=r("8*32*4=1024"),Bu=r(")."),zs=c(),ol=l("p"),Qu=r("Torniamo al diagramma."),bs=c(),k=l("p"),Vu=r("Con "),gt=l("code"),Hu=r("chunks=1"),Xu=r(" otteniamo il MP ingenuo, che \xE8 molto inefficiente. Con valori "),Lt=l("code"),Yu=r("chunks"),Wu=r(` molto grandi, otteniamo micro-batch di dimensioni troppo piccole, che
risultano anch\u2019esse non efficienti. Occorre quindi sperimentare per trovare il valore che porta al pi\xF9 efficiente utilizzo delle GPU.`),_s=c(),w=l("p"),Ju=r("Poich\xE8 il diagramma mostra che c\u2019\xE8 una bolla di tempo \u201Cmorto\u201D che non pu\xF2 essere parallelizzato perch\xE8 l\u2019ultimo passaggio "),Ut=l("code"),Ku=r("forward"),em=r(` deve aspettare il
completamento del `),Gt=l("code"),im=r("backward"),am=r(", lo scopo di trovare il miglior valore possibile per "),Dt=l("code"),lm=r("chunks"),om=r(` sta nel consentire una buona collaborazione fra le GPU partecipanti,
minimizzando la dimensione di questa bolla.`),Es=c(),tl=l("p"),tm=r("Ci sono 2 gruppi di soluzione - i metodi tradizionali della API Pipeline e soluzioni pi\xF9 moderne che rendono le cose pi\xF9 semplici per l\u2019utente finale."),gs=c(),rl=l("p"),rm=r("Soluzioni tradizionali della API Pipeline:"),Ls=c(),S=l("ul"),wt=l("li"),nm=r("PyTorch"),sm=c(),St=l("li"),pm=r("FairScale"),cm=c(),It=l("li"),dm=r("DeepSpeed"),um=c(),At=l("li"),mm=r("Megatron-LM"),Us=c(),nl=l("p"),fm=r("Soluzioni moderne:"),Gs=c(),Se=l("ul"),qt=l("li"),vm=r("Varuna"),Pm=c(),yt=l("li"),hm=r("Sagemaker"),Ds=c(),sl=l("p"),zm=r("Problemi delle soluzioni tradizionali della API Pipeline:"),ws=c(),I=l("ul"),ui=l("li"),bm=r("richiede di modificare il modello piuttosto pesantemente, perch\xE8 Pipeline richiede di riscrivere il modello dei moduli in sequenze "),Ot=l("code"),_m=r("nn.Sequential"),Em=r(", che potrebbero richiedere modifiche nel design del modello."),gm=c(),pl=l("li"),Lm=r("al momento, l\u2019API \xE8 molto limitata. Se hai diverse variabili python da inserire nel primo step della Pipeline, dovrai trovare un modo alternativo. Al momento, l\u2019interfaccia Pipeline necessit\xE0 o di un singolo tensore, o una tupla di tensori come unico input ed output. Questi tensori devono avere la batch size come prima dimensione, dal momento che la pipeline divider\xE0 le mini-batches in micro-batches. Possibili miglioramenti sono in discussione qua: "),mi=l("a"),Um=r("https://github.com/pytorch/pytorch/pull/50693"),Gm=c(),Mt=l("li"),Dm=r("il controllo del flusso condizionale al livello dei vari step della Pipeline non \xE8 possibile - ad esempio, modelli Encoder-Decoder come T5 richiedono speciali soluzioni per gestire i vari step di encoding condizionale."),wm=c(),$t=l("li"),Sm=r("richiede di organizzare ciascun layer in modo che l\u2019output di un modello diventi l\u2019input dell\u2019altro."),Ss=c(),cl=l("p"),Im=r("Necessitiamo ancora di sperimentare con Varuna e SageMaker, ma i loro paper riportano di aver superato la lista dei problemi menzionati in precedenza e dicono di richiedere cambiamenti molto minori nel modello dell\u2019utente."),Is=c(),dl=l("p"),Am=r("Implementazioni:"),As=c(),f=l("ul"),Ie=l("li"),fi=l("a"),qm=r("Pytorch"),ym=r(" (supporto iniziale in pytorch-1.8, progressivamente migliorato in 1.9 e 1.10). Alcuni "),vi=l("a"),Om=r("esempi"),Mm=r("."),$m=c(),Tt=l("li"),Pi=l("a"),Tm=r("FairScale"),Cm=c(),Ct=l("li"),hi=l("a"),km=r("DeepSpeed"),xm=c(),ul=l("li"),zi=l("a"),Nm=r("Megatron-LM"),Rm=r(" ha un\u2019implementazione interna - no API."),Zm=c(),kt=l("li"),bi=l("a"),Fm=r("Varuna"),jm=c(),ml=l("li"),_i=l("a"),Bm=r("SageMaker"),Qm=r(" - questa \xE8 una soluzione proprietaria che pu\xF2 essere solo utilizata su AWS."),Vm=c(),fl=l("li"),Ei=l("a"),Hm=r("OSLO"),Xm=r(" - questa implementazione \xE8 basata su Hugging Face Transformers."),qs=c(),Ae=l("p"),Ym=r(`\u{1F917} Transformers status: al momento della scrittura di questa guida, nessuno dei modelli supporta full-PP. I modelli GPT2 e T5 hanno un supporto per il MP ingenuo.
Il principale ostacolo \xE8 l\u2019incapacit\xE0 di convertire i modelli in `),xt=l("code"),Wm=r("nn.Sequential"),Jm=r(` e che tutti gli input siano Tensori. Questo \xE8 dovuto al fatto che, al momento,
i modelli includono molte features che rendono la conversione molto complicata, e necessitano di essere rimosse per raggiungere questo obiettivo.`),ys=c(),vl=l("p"),Km=r("Altri approcci:"),Os=c(),oe=l("p"),ef=r("DeepSpeed, Varuna e SageMaker usano il concetto di una "),gi=l("a"),af=r("Interleaved Pipeline"),lf=c(),Pl=l("img"),Ms=c(),hl=l("p"),of=r("Qua la bolla (tempi morti) \xE8 ulteriormente minimizzata prioritizzando i passaggi all\u2019indietro."),$s=c(),zl=l("p"),tf=r("Varuna cerca ulteriormente di migliorare la struttura utilizzando simulazioni per individuare il pi\xF9 efficiente scheduling."),Ts=c(),qe=l("p"),rf=r("OSLO ha una parallelizzazione di pipeline implementata basandosi su Transformers senza la conversione a "),Nt=l("code"),nf=r("nn.Sequential"),sf=r("."),Cs=c(),te=l("h2"),ye=l("a"),Rt=l("span"),P(Li.$$.fragment),pf=c(),Zt=l("span"),cf=r("Parallelizzazione dei Tensori"),ks=c(),bl=l("p"),df=r("Nella parallelizzazione dei tensori ogni GPU processa soltando una parte di un tensore ed aggrega il tensore completo soltanto per le operazioni che lo richiedono."),xs=c(),x=l("p"),uf=r("In questa sezione usiamo concetti e diagrammi dal paper "),Ui=l("a"),mf=r("Megatron-LM"),ff=r(": "),Gi=l("a"),vf=r("Efficient Large-Scale Language Model Training on GPU Clusters"),Pf=r("."),Ns=c(),N=l("p"),hf=r("Il blocco principale di ogni modello transformer \xE8 un layer fully connected "),Ft=l("code"),zf=r("nn.Linear"),bf=r(" seguito da una funzione di attivazione non lineare "),jt=l("code"),_f=r("GeLU"),Ef=r("."),Rs=c(),L=l("p"),gf=r("Seguento la notazione del paper di Megatron, possiamo scrivere il dot-product come "),Bt=l("code"),Lf=r("Y = GeLU(XA)"),Uf=r(", dove "),Qt=l("code"),Gf=r("X"),Df=r(" ed "),Vt=l("code"),wf=r("Y"),Sf=r(" sono i vettori di input ed ouput ed "),Ht=l("code"),If=r("A"),Af=r(" \xE8 la matrice dei pesi."),Zs=c(),Di=l("p"),qf=r(`Se osserviamo i calcoli in forma matriciale, \xE8 facile notare come la moltiplicazione fra matrici pu\xF2 essere suddivisa fra pi\xF9 GPU:
`),_l=l("img"),Fs=c(),m=l("p"),yf=r("Se dividiamo la matrice di pesi "),Xt=l("code"),Of=r("A"),Mf=r(" in colonne, su "),Yt=l("code"),$f=r("N"),Tf=r("GPU e performiamo le moltiplicazioni fra matrici da "),Wt=l("code"),Cf=r("XA_1"),kf=r(" a "),Jt=l("code"),xf=r("XA_n"),Nf=r(" in parallelo, rimarremo con "),Kt=l("code"),Rf=r("N"),Zf=r(`
vettori di output `),er=l("code"),Ff=r("Y_1, Y_2, ..., Y_n"),jf=r(" che possono essere inviati a "),ir=l("code"),Bf=r("GeLU"),Qf=r(` in modo indipendente:
`),El=l("img"),js=c(),wi=l("p"),Vf=r(`Secondo questo principio, possiamo aggiornare un MLP di profondit\xE0 arbitraria senza il bisogno di sincronizzare le GPU fino alla fine del procedimento,
al termine del quale necessiteremo di ricostruire l\u2019output dai singoli blocchi. Gli autori del paper Megatron-LM hanno realizzato un\u2019illustrazione utile per questo:
`),gl=l("img"),Bs=c(),Si=l("p"),Hf=r(`Parallelizzare i layer di multi-head attention \xE8 perfino pi\xF9 semplice, dal momento che sono gi\xE0 per loro natura paralleli grazie al fatto che hanno pi\xF9 heads indipendenti!
`),Ll=l("img"),Qs=c(),Ul=l("p"),Xf=r(`Considerazioni speciali: TP richiede una rete di GPU molto veloce, per cui non \xE8 suggeribile effettuare TP su pi\xF9 nodi (macchine).
In pratica, se un nodo ha 4 GPU, il maggior grado di TP pu\xF2 essere 4. Se necessiti di un TP di grado 8, dovrai utilizzare nodi che hanno almeno 8 GPU.`),Vs=c(),R=l("p"),Yf=r("Questa sezione \xE8 basata sull\u2019originale e molto pi\xF9 dettagliata  TP overview]("),Ii=l("a"),Wf=r("https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530"),Jf=r(`).
by `),Ai=l("a"),Kf=r("@anton-l"),ev=r("."),Hs=c(),Gl=l("p"),iv=r("SageMaker combina TP con DP per un processing pi\xF9 efficiente."),Xs=c(),Dl=l("p"),av=r("Nomi alternativi:"),Ys=c(),wl=l("ul"),Sl=l("li"),lv=r("DeepSpeed lo chiama "),qi=l("a"),ov=r("tensor slicing"),Ws=c(),Il=l("p"),tv=r("Implementazioni:"),Js=c(),A=l("ul"),Al=l("li"),yi=l("a"),rv=r("Megatron-LM"),nv=r(" ha un\u2019implementazione interna, molto specifica per quel modello"),sv=c(),ql=l("li"),Oi=l("a"),pv=r("parallelformers"),cv=r(" (al momento, solo per l\u2019inferenza)"),dv=c(),yl=l("li"),Mi=l("a"),uv=r("SageMaker"),mv=r(" - soluzione proprietaria di AWS"),fv=c(),Ol=l("li"),$i=l("a"),vv=r("OSLO"),Pv=r(" ha un\u2019implementazione di TP basata su Transformers."),Ks=c(),Ml=l("p"),hv=r("\u{1F917} Transformers status:"),ep=c(),Z=l("ul"),ar=l("li"),zv=r("core: non ancora implementato"),bv=c(),Ti=l("li"),_v=r("ma se vuoi fare inferenza, "),Ci=l("a"),Ev=r("parallelformers"),gv=r(" offre questo supporto per la maggior parte dei nostri modelli. Finch\xE8 questo non \xE8 implementato nella libreria princiaple, puoi usare questa libreria. Ci auguriamo anche che diventi disponibile in fase di allenamento oltre che per l\u2019inferenza."),Lv=c(),$l=l("li"),Uv=r("Deepspeed-Inference supporta anche BERT, GPT-2 e GPT-Neo nella loro super-veloce modalit\xE0 di inferenza basata su CUDA-kernel, vedi "),ki=l("a"),Gv=r("qui"),ip=c(),re=l("h2"),Oe=l("a"),lr=l("span"),P(xi.$$.fragment),Dv=c(),or=l("span"),wv=r("DP+PP"),ap=c(),Me=l("p"),Sv=r("Il seguente diagramma del "),Ni=l("a"),Iv=r("tutorial di DeepSpeed"),Av=r(" dimostra come combinare DP con PP."),lp=c(),Tl=l("p"),Cl=l("img"),op=c(),kl=l("p"),qv=r(`Qua \xE8 importante notare come il rango 0 di DP non vede la GPU2 e il DP di rango 1 non vede la GPU3. Per il DP \xE8 come se ci fossero soltanto GPU0 e GPU1, ai
quali passa i dati come se ci fossero solo 2 GPU. GPU0 \u201Csegretamente\u201D passa parte del suo carico alla GPU2 tramite PP, e lo stesso vale per GPU1 con GPU3.`),tp=c(),xl=l("p"),yv=r("Dal momento che ciascuna dimensione richiede almeno 2 GPU, in questo caso sarebbero necessarie almeno 4 GPU."),rp=c(),Nl=l("p"),Ov=r("Implementazioni:"),np=c(),U=l("ul"),tr=l("li"),Ri=l("a"),Mv=r("DeepSpeed"),$v=c(),rr=l("li"),Zi=l("a"),Tv=r("Megatron-LM"),Cv=c(),nr=l("li"),Fi=l("a"),kv=r("Varuna"),xv=c(),sr=l("li"),ji=l("a"),Nv=r("SageMaker"),Rv=c(),pr=l("li"),Bi=l("a"),Zv=r("OSLO"),sp=c(),Rl=l("p"),Fv=r("\u{1F917} Transformers status: non ancora implementato."),pp=c(),ne=l("h2"),$e=l("a"),cr=l("span"),P(Qi.$$.fragment),jv=c(),dr=l("span"),Bv=r("DP+PP+TP"),cp=c(),Zl=l("p"),Qv=r("Per avere un allenamento ancora pi\xF9 efficiente, una parallelizzazione 3D pu\xF2 essere utilizzata, combinando TP, DP e PP. Possiamo osservarlo nel seguente diagramma:"),dp=c(),Fl=l("p"),jl=l("img"),up=c(),Te=l("p"),Vv=r("Questo diagramma \xE8 stato preso dal post "),Vi=l("a"),Hv=r("3D parallelism: Scaling to trillion-parameter models"),Xv=r(", che \xE8 una lettura interessante sull\u2019argomento."),mp=c(),Bl=l("p"),Yv=r("Dal momento che ciascuan dimensione richiede almeno 2 GPU, in questo caso sono necessarie almeno 8 GPU."),fp=c(),Ql=l("p"),Wv=r("Implementazioni:"),vp=c(),G=l("ul"),Vl=l("li"),Hi=l("a"),Jv=r("DeepSpeed"),Kv=r(" - DeepSpeed include anche una versione di DP pi\xF9 efficiente, chiamata ZeRO-DP."),eP=c(),ur=l("li"),Xi=l("a"),iP=r("Megatron-LM"),aP=c(),mr=l("li"),Yi=l("a"),lP=r("Varuna"),oP=c(),fr=l("li"),Wi=l("a"),tP=r("SageMaker"),rP=c(),vr=l("li"),Ji=l("a"),nP=r("OSLO"),Pp=c(),Hl=l("p"),sP=r("\u{1F917} Transformers status: non ancora implementato, dato che non abbiamo ancora PP e TP."),hp=c(),se=l("h2"),Ce=l("a"),Pr=l("span"),P(Ki.$$.fragment),pP=c(),hr=l("span"),cP=r("ZeRO DP+PP+TP"),zp=c(),ke=l("p"),dP=r("Una delle funzionalit\xE0 principali di DeepSpeed \xE8 ZeRO, che \xE8 un\u2019estensione super scalabile di DP. Questa \xE8 gi\xE0 stata discussa in "),Xl=l("a"),uP=r("ZeRO Data Parallelism"),mP=r(`.
Normalmente, \xE8 una funzionalit\xE0 a s\xE8 stante, che non richiede PP o TP, ma pu\xF2 essere combinata con PP e TP.`),bp=c(),Yl=l("p"),fP=r("Quando ZeRO-DP \xE8 combinata con PP (e opzionalmente TP) tipicalmente permette soltanto ZeRO stage 1 (optimizer sharding)."),_p=c(),Wl=l("p"),vP=r(`Sebbene sia teoricamente possibile utilizzare ZeRO stage 2 (gradient sharding) con la parallelizzazione della Pipeline, questo porta a impatti negativi sulla performance.
Sarebbe necessario avere un addizionale riduttore di dispersione per ogni micro-batch per ri-aggregare i gradienti prima di dividerli, che aggiunge un overhead di comunicazione
potenzialmente molto significativo. Per natura del PP, vengono utilizzate delle piccole micro-batches e invece lo scopo \xE8 bilanciare l\u2019intensit\xE0 aritmetica (micro-batch size) con
la minimizzazione della bolla della Pipeline (numero di micro-batches). Per cui, i costi di comunicazione cresceranno.`),Ep=c(),xe=l("p"),PP=r(`Inoltre, ci sono gi\xE0 meno layer del solito grazie al PP, per cui il risparmio in termini di memoria non risulta particolarmente rilevante.
PP riduce gi\xE0 il gradiente di  `),zr=l("code"),hP=r("1/PP"),zP=r(", per cui il risparmio ottenuto dividendo i gradienti sono meno significativi rispetto al puro DP."),gp=c(),Jl=l("p"),bP=r("Allo stesso modo, ZeRO stage 3 non \xE8 una buona scelta per lo stesso motivo - pi\xF9 comunicazioni fra nodi sono richieste."),Lp=c(),Kl=l("p"),_P=r("Dal momento che abbiamo ZeRO, un altro beneficio \xE8 lo ZeRO-Offload. Dal momento che questo \xE8 uno stage 1 optimizer, possiamo scaricare in CPU gli stati del modello."),Up=c(),eo=l("p"),EP=r("Implementazioni:"),Gp=c(),Ne=l("ul"),Re=l("li"),ea=l("a"),gP=r("Megatron-DeepSpeed"),LP=r(" e "),ia=l("a"),UP=r("Megatron-Deepspeed from BigScience"),GP=r(", che \xE8 una fork della repo precedente."),DP=c(),br=l("li"),aa=l("a"),wP=r("OSLO"),Dp=c(),io=l("p"),SP=r("Paper importanti:"),wp=c(),ao=l("ul"),_r=l("li"),la=l("a"),IP=r("Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"),Sp=c(),lo=l("p"),AP=r("\u{1F917} Transformers status: non ancora implementato, dal momento che non abbiamo ancora PP e TP."),Ip=c(),pe=l("h2"),Ze=l("a"),Er=l("span"),P(oa.$$.fragment),qP=c(),gr=l("span"),yP=r("FlexFlow"),Ap=c(),ta=l("p"),ra=l("a"),OP=r("FlexFlow"),MP=r(" risolve il problema di parallelizzazione in un approccio leggermente diverso."),qp=c(),na=l("p"),$P=r("Paper: "),sa=l("a"),TP=r("\u201CBeyond Data and Model Parallelism for Deep Neural Networks\u201D by Zhihao Jia, Matei Zaharia, Alex Aiken"),yp=c(),oo=l("p"),CP=r("Effettua una sorta di parallelizzazione 4D su Campione-Operatore-Attributi-Parametri:"),Op=c(),q=l("ol"),Lr=l("li"),kP=r("Campione = Data Parallelism (parallelizzazione per campione)"),xP=c(),Ur=l("li"),NP=r("Operatore = Parallelizza una singola operazione in pi\xF9 sotto-operazioni"),RP=c(),Gr=l("li"),ZP=r("Attributi = Data Parallelism (parallelizzazione length-wise)"),FP=c(),Dr=l("li"),jP=r("Parametri = Model Parallelism (a prescindere dalla dimensione, orizzontale o verticale)"),Mp=c(),to=l("p"),BP=r("Esempi:"),$p=c(),ro=l("ul"),wr=l("li"),QP=r("Campione"),Tp=c(),no=l("p"),VP=r("Prendiamo 10 batches di lunghezza 512, 10 x 512. Se parallelizzate su due dispositivi, otteniamo 5 x 2 x 512."),Cp=c(),so=l("ul"),Sr=l("li"),HP=r("Operatore"),kp=c(),po=l("p"),XP=r(`Se effettuiamo l\u2019operazione di normalizzazione per i layer, possiamo calcolare prima la deviazione standard, poi la media, e poi normalizzare i dati.
Parallelizzare per operatore consente di calcolare la deviazione standard e la media in parallelo. Per cui se li parallelizzassimo fra due dispositivi
(cuda:0, cuda:1), possiamo prima copiare i dati in entrambi i dispositivi, dopodich\xE8 cuda:0 calcola la deviazione standard e cuda:1 calcola la media allo stesso tempo.`),xp=c(),co=l("ul"),Ir=l("li"),YP=r("Attributi"),Np=c(),uo=l("p"),WP=r("Se abbiamo 10 batches di lunghezza 512, parallelizzandoli per la dimensione degli attributi otteniamo 10 x 2 x 256."),Rp=c(),mo=l("ul"),Ar=l("li"),JP=r("Parametri"),Zp=c(),fo=l("p"),KP=r("Funziona in modo simile alla parallelizzazione dei tensori o alla parallelizzazione ingenua dei layer."),Fp=c(),vo=l("p"),Po=l("img"),jp=c(),ho=l("p"),eh=r(`L\u2019importanza di questo framweork \xE8 che prende risorse come (1) GPU/TPU/CPU vs. (2) RAM/DRAM vs. (3) inter-connessioni veloci/inter-connessioni lente ed
automaticamente le ottimizza tramite un algoritmo, che decide quale parallelizzazione usare.`),Bp=c(),zo=l("p"),ih=r(`Un aspetto molto importante \xE8 che FlexFlow \xE8 pensato per ottimizzare parallelizzazioni per modelli con carichi di lavoro statici e fissati,poich\xE8
modelli dinamici potrebbero preferire differenti strategie di parallelizzazione fra le differenti iterazioni.`),Qp=c(),bo=l("p"),ah=r(`La promessa \xE8 molto invitante - effettua una simulazione di 30 minuti su un cluster ed elabora la miglior strategia da utilizzare per l\u2019ambiente specifico.
Se qualche parte venisse aggiunta/rimossa/modificata, l\u2019algoritmo ri-parte e ri-ottimizza il piano di parallelizzazione, dopodich\xE8 potrai tornare ad allenare il modello.
Ciascuna impostazione avr\xE0 la sua ottimizzazione specifica.`),Vp=c(),Fe=l("p"),lh=r("\u{1F917} Transformers status: non ancora implementato. Abbiamo modelli FX-trace-able in "),pa=l("a"),oh=r("transformers.utils.fx"),th=r(`,
che \xE8 un prerequisito per utilizzare FlexFlow, perci\xF2 qualcuno dovr\xE0 capire cosa \xE8 necessario fare per far funzionare FlexFlow con i nostri modelli.`),Hp=c(),ce=l("h2"),je=l("a"),qr=l("span"),P(ca.$$.fragment),rh=c(),yr=l("span"),nh=r("Quale Strategia Usare e Quando"),Xp=c(),_o=l("p"),sh=r("Segue uno schema molto approssimativo di quale strategia di parallelizzazione usare e quando. Il primo di ogni lista \xE8 tipicamente il pi\xF9 veloce."),Yp=c(),Eo=l("p"),Or=l("strong"),ph=r("\u21E8 Una sola GPU"),Wp=c(),F=l("ul"),da=l("li"),Mr=l("p"),ch=r("Se il modello riesce a stare dentro una singola GPU:"),dh=c(),$r=l("ol"),Tr=l("li"),uh=r("Utilizzo normale"),mh=c(),ua=l("li"),Cr=l("p"),fh=r("Se il modello non riesce a stare dentro una singola GPU:"),vh=c(),ma=l("ol"),kr=l("li"),Ph=r("ZeRO + Offload CPU e opzionalmente NVMe"),hh=c(),xr=l("li"),zh=r("come sopra, pi\xF9 Memory Centric Tiling (vedi sotto per maggiori dettagli) se il layer pi\xF9 grande non riesce a stare in una singola GPU"),bh=c(),Nr=l("li"),Rr=l("p"),_h=r("Se il layer pi\xF9 grande non riesce a stare dentro una singola GPU:"),Jp=c(),go=l("ol"),de=l("li"),Eh=r("ZeRO - Attiva "),fa=l("a"),gh=r("Memory Centric Tiling"),Lh=r(" (MCT). Consente di allenare layer arbitrariamente grandi dividendoli ed eseguendoli sequenzialmente. MCT riduce il numero di parametri attivi in una GPU, ma non ha effetto sulla memoria di attivazione. Dal momento che questa necessit\xE0 \xE8 molto rara, nel momento in cui scriviamo questa guida spetta all\u2019utente effettuare una sovrascrizione manuale di "),Zr=l("code"),Uh=r("torch.nn.Linear"),Gh=r("."),Kp=c(),Lo=l("p"),Fr=l("strong"),Dh=r("\u21E8 Un solo nodo / Multi-GPU"),ec=c(),j=l("ul"),va=l("li"),jr=l("p"),wh=r("Se il modello riesce a stare dentro una singola GPU:"),Sh=c(),Pa=l("ol"),Br=l("li"),Ih=r("DDP - DP distribuito"),Ah=c(),Qr=l("li"),qh=r("ZeRO - potrebbe o meno essere pi\xF9 veloce a seconda della configurazione utilizzata"),yh=c(),ha=l("li"),Vr=l("p"),Oh=r("Se il modello non riesce a stare dentro una singola GPU:"),Mh=c(),ue=l("ol"),Hr=l("li"),Xr=l("p"),$h=r("PP"),Th=c(),Yr=l("li"),Wr=l("p"),Ch=r("ZeRO"),kh=c(),me=l("li"),Jr=l("p"),xh=r("TP"),Nh=c(),Kr=l("p"),Rh=r("Con connettivit\xE0 fra nodi ultraveloce (NVLINK o NVSwitch) tutti e tre i metodi dovrebbero essere prevalentemente alla pari, senza questi invece il PP dovrebbe essere il pi\xF9 veloce. Il grado di TP potrebbe inoltre  fare la differenza. Il metodo migliore sta nello sperimentare finch\xE8 non troverai il miglior metodo per le tue impostazioni."),Zh=c(),en=l("p"),Fh=r("TP \xE8 quasi sempre utilizzato all\u2019interno dello stesso nodo. Per cui, dimensione del TP <= GPU di ciascun nodo."),jh=c(),za=l("li"),an=l("p"),Bh=r("Se il layer pi\xF9 grande non riesce a stare dentro una singola GPU:"),Qh=c(),ba=l("ol"),ln=l("li"),Vh=r("Se non utilizzi ZeRO - devi utilizzare TP dal momento che PP da solo non sar\xE0 in grado di far stare il layer nella GPU."),Hh=c(),on=l("li"),Xh=r("Con ZeRO vedi il punto precedente \u201CUna sola GPU\u201D"),ic=c(),Uo=l("p"),tn=l("strong"),Yh=r("\u21E8 Multi-Node / Multi-GPU"),ac=c(),Be=l("ul"),_a=l("li"),rn=l("p"),Wh=r("Se hai una veloce connettivit\xE0 fra nodi:"),Jh=c(),Ea=l("ol"),nn=l("li"),Kh=r("ZeRO - poich\xE8 non richiede pressoch\xE8 alcuna modifica al modello"),ez=c(),sn=l("li"),iz=r("PP+TP+DP - meno comunicazioni, ma richiede importanti modifiche al modello"),az=c(),ga=l("li"),pn=l("p"),lz=r("Se hai una connettivit\xE0 fra nodi lenta e una memoria GPU scarsa:"),oz=c(),cn=l("ol"),dn=l("li"),tz=r("DP+PP+TP+ZeRO-1"),this.h()},l(e){const s=B_('[data-svelte="svelte-1phssyn"]',document.head);Y=o(s,"META",{name:!0,content:!0}),s.forEach(i),Pn=d(e),W=o(e,"H1",{class:!0});var oc=t(W);fe=o(oc,"A",{id:!0,class:!0,href:!0});var Tz=t(fe);No=o(Tz,"SPAN",{});var Cz=t(No);h(We.$$.fragment,Cz),Cz.forEach(i),Tz.forEach(i),Hc=d(oc),Ro=o(oc,"SPAN",{});var kz=t(Ro);Xc=n(kz,"Parallelizzazione dei modelli"),kz.forEach(i),oc.forEach(i),hn=d(e),J=o(e,"H2",{class:!0});var tc=t(J);ve=o(tc,"A",{id:!0,class:!0,href:!0});var xz=t(ve);Zo=o(xz,"SPAN",{});var Nz=t(Zo);h(Je.$$.fragment,Nz),Nz.forEach(i),xz.forEach(i),Yc=d(tc),Fo=o(tc,"SPAN",{});var Rz=t(Fo);Wc=n(Rz,"Panoramica della parallelizzazione"),Rz.forEach(i),tc.forEach(i),zn=d(e),La=o(e,"P",{});var Zz=t(La);Jc=n(Zz,"I vari approcci della parallelizzazione sono usati nel machine learning moderno per:"),Zz.forEach(i),bn=d(e),Pe=o(e,"OL",{});var rc=t(Pe);jo=o(rc,"LI",{});var Fz=t(jo);Kc=n(Fz,"adattare modelli molto grandi in hardware limitati - ad esempio, i soli parametri del modello t5-11b pesano 45GB"),Fz.forEach(i),ed=d(rc),Bo=o(rc,"LI",{});var jz=t(Bo);id=n(jz,"velocizzare significativamente l\u2019allenamento - terminando in poche ore allenamenti che impiegherebbero un anno"),jz.forEach(i),rc.forEach(i),_n=d(e),Ua=o(e,"P",{});var Bz=t(Ua);ad=n(Bz,`Inizieremo discutendo in dettaglio diverse tecniche di parallelizzazione 1D, i loro pro e contro e come queste possano essere combinate in
parallelizzazione 2D e 3D per consentire un allenamento ancora pi\xF9 veloce e supportare modelli ancora pi\xF9 grandi. Diversi potenti approcci alternativi saranno presentati.`),Bz.forEach(i),En=d(e),Ga=o(e,"P",{});var Qz=t(Ga);ld=n(Qz,"Sebbene i concetti principali siano applicabili ad ogni altro framework, questo articolo \xE8 incentrato sulle implementazioni basate su Pytorch."),Qz.forEach(i),gn=d(e),K=o(e,"H2",{class:!0});var nc=t(K);he=o(nc,"A",{id:!0,class:!0,href:!0});var Vz=t(he);Qo=o(Vz,"SPAN",{});var Hz=t(Qo);h(Ke.$$.fragment,Hz),Hz.forEach(i),Vz.forEach(i),od=d(nc),Vo=o(nc,"SPAN",{});var Xz=t(Vo);td=n(Xz,"Concetti"),Xz.forEach(i),nc.forEach(i),Ln=d(e),Da=o(e,"P",{});var Yz=t(Da);rd=n(Yz,"Segue una breve descrizione dei concetti principali che verranno dettagliatamente descritti in questo documento."),Yz.forEach(i),Un=d(e),g=o(e,"OL",{});var B=t(g);Ho=o(B,"LI",{});var Wz=t(Ho);nd=n(Wz,"DataParallel (DP) - lo stesso setup \xE8 replicato pi\xF9 volte, passando ciascuna volta una parte dei dati. Il processing \xE8 eseguito in parallelo e tutti i setup sono sincronizzati alla fine di ogni iterazione di allenamento."),Wz.forEach(i),sd=d(B),Xo=o(B,"LI",{});var Jz=t(Xo);pd=n(Jz,"TensorParallel (TP) - ogni tensore \xE8 diviso in pi\xF9 blocchi, in questo modo anzich\xE8 dover essere collocato interamente in un\u2019unica GPU, ciascun blocco di tensore risieder\xE0 nella GPU ad esso assegnata. Durante il processing, ogni blocco \xE8 processato separatamente e in parallelo su differenti GPU ed i risultati sono poi sincronizzati alla fine dello step. Questo processo \xE8 talvolta definito parallelizzazione orizzontale poich\xE8 lo splitting avviene su un livello orizzontale."),Jz.forEach(i),cd=d(B),Yo=o(B,"LI",{});var Kz=t(Yo);dd=n(Kz,"PipelineParallel (PP) - il modello \xE8 diviso verticalmente (layer-level) su pi\xF9 GPU, cos\xEC che solo uno o pi\xF9 layers del modello risiedano in un\u2019unica GPU. Ciascuna GPU esegue in parallelo le differenti fase della pipeline e lavora su una porzione ridotta della batch."),Kz.forEach(i),ud=d(B),Wo=o(B,"LI",{});var e1=t(Wo);md=n(e1,"Zero Redundancy Optimizer (ZeRO) - esegue una divisione simile al metodo TP, con l\u2019eccezione che l\u2019intero tensore viene poi ricostruito per una computazione in avanti (forward) o all\u2019indietro (backward), per cui il modello non deve essere modificato. Supporta anche diverse tecniche di offloading per compensare in casi di memoria GPU limitata."),e1.forEach(i),fd=d(B),Jo=o(B,"LI",{});var i1=t(Jo);vd=n(i1,"Sharded DDP - \xE8 un altro nome per il metodo ZeRO in diverse altre implementazioni di ZeRO."),i1.forEach(i),B.forEach(i),Gn=d(e),ee=o(e,"H2",{class:!0});var sc=t(ee);ze=o(sc,"A",{id:!0,class:!0,href:!0});var a1=t(ze);Ko=o(a1,"SPAN",{});var l1=t(Ko);h(ei.$$.fragment,l1),l1.forEach(i),a1.forEach(i),Pd=d(sc),et=o(sc,"SPAN",{});var o1=t(et);hd=n(o1,"Parallelizzazione dei Dati"),o1.forEach(i),sc.forEach(i),Dn=d(e),O=o(e,"P",{});var Go=t(O);zd=n(Go,"La maggior parte degli utenti con sole 2 GPU godono gi\xE0 di una velocit\xE0 di allenamento migliorata grazie a "),it=o(Go,"CODE",{});var t1=t(it);bd=n(t1,"DataParallel"),t1.forEach(i),_d=n(Go," (DP) e "),at=o(Go,"CODE",{});var r1=t(at);Ed=n(r1,"DistributedDataParallel"),r1.forEach(i),gd=n(Go,` (DDP)
che sono pressoch\xE8 banali da utilizzare. Questa \xE8 una funzionalit\xE0 built-in di Pytorch.`),Go.forEach(i),wn=d(e),ie=o(e,"H2",{class:!0});var pc=t(ie);be=o(pc,"A",{id:!0,class:!0,href:!0});var n1=t(be);lt=o(n1,"SPAN",{});var s1=t(lt);h(ii.$$.fragment,s1),s1.forEach(i),n1.forEach(i),Ld=d(pc),ot=o(pc,"SPAN",{});var p1=t(ot);Ud=n(p1,"Parallelizzazione dei Dati con ZeRO"),p1.forEach(i),pc.forEach(i),Sn=d(e),ae=o(e,"P",{});var un=t(ae);Gd=n(un,"La parallelizzazione dei dati ZeRO-powered (ZeRO-DP) \xE8 descritta dal seguente diagramma preso da questo "),ai=o(un,"A",{href:!0,rel:!0});var c1=t(ai);Dd=n(c1,"post:"),c1.forEach(i),wd=d(un),wa=o(un,"IMG",{src:!0,alt:!0}),un.forEach(i),In=d(e),_e=o(e,"P",{});var cc=t(_e);Sd=n(cc,"Pu\xF2 essere difficile da comprendere, ma in realt\xE0 il concetto \xE8 relativamente semplice. Consiste nel comune "),tt=o(cc,"CODE",{});var d1=t(tt);Id=n(d1,"DataParallel"),d1.forEach(i),Ad=n(cc,` (DP),
dove anzich\xE8 replicare tutti i parametri del modello, gradienti e stati degli ottimizzatori, ogni GPU ne memorizza soltanto una parte.
Dopodich\xE8, nel momento del run-time in cui tutti i parametri di quel layer sono necessari, le GPU si sincronizzano per dare l\u2019un l\u2019altra le parti mancanti - tutto qui.`),cc.forEach(i),An=d(e),Sa=o(e,"P",{});var u1=t(Sa);qd=n(u1,"Considera questo semplice modello con 3 layer, dove ogni layer ha 3 parametri:"),u1.forEach(i),qn=d(e),h(li.$$.fragment,e),yn=d(e),Ia=o(e,"P",{});var m1=t(Ia);yd=n(m1,"Il layer La ha pesi a0, a1 ed a2."),m1.forEach(i),On=d(e),Aa=o(e,"P",{});var f1=t(Aa);Od=n(f1,"Se abbiamo 3 GPU, lo Shared DDP (o Zero-DP) divide il modello in 3 GPU come segue:"),f1.forEach(i),Mn=d(e),h(oi.$$.fragment,e),$n=d(e),qa=o(e,"P",{});var v1=t(qa);Md=n(v1,`In un certo senso, questo \xE8 lo stesso di fare slicing orizzontale, come nella parallelzzazione dei tensori, se immaginiamo il tipico diagramma DNN.
Lo slicing verticale invece si ha quando inseriamo interi layer (o gruppi di layer) su diverse GPU. Ma questo \xE8 soltanto l\u2019inizio.`),v1.forEach(i),Tn=d(e),ya=o(e,"P",{});var P1=t(ya);$d=n(P1,"Adesso, ogni GPU ricever\xE0 le classiche mini-batch come nel DP:"),P1.forEach(i),Cn=d(e),h(ti.$$.fragment,e),kn=d(e),Oa=o(e,"P",{});var h1=t(Oa);Td=n(h1,"Gli input sono invariati, come se venissero processati dal modello normale."),h1.forEach(i),xn=d(e),Ma=o(e,"P",{});var z1=t(Ma);Cd=n(z1,"Innanzitutto, gli input entrano nel layer La."),z1.forEach(i),Nn=d(e),$a=o(e,"P",{});var b1=t($a);kd=n(b1,"Concentriamoci solo su GPU0: x0 necessita dei parametri a0, a1 e a2 per il suo percorso in avanti, ma GPU0 ha solo a0 - per cui riceve a1 da GPU1 e a2 da GPU2, ricostruendo insieme tutte le parti del modello."),b1.forEach(i),Rn=d(e),Ta=o(e,"P",{});var _1=t(Ta);xd=n(_1,"In parallelo, GPU1 riceve la mini-batch x1 ed ha soltanto a1, ma richiede anche a0 e a2, per cui li ottiene da GPU0 e GPU2."),_1.forEach(i),Zn=d(e),Ca=o(e,"P",{});var E1=t(Ca);Nd=n(E1,"Lo stesso avviene a GPU2 che riceve l\u2019input x2. Riceve a0 e a1 da GPU0 e GPU1 e assieme al suo a2 ricostruisce l\u2019intero tensore."),E1.forEach(i),Fn=d(e),ka=o(e,"P",{});var g1=t(ka);Rd=n(g1,"Tutte e 3 le GPU ottengono i tensori completi ed il passaggio in avanti viene effettuato."),g1.forEach(i),jn=d(e),xa=o(e,"P",{});var L1=t(xa);Zd=n(L1,"Non appena i calcoli sono effettuati, i dati che non sono pi\xF9 necessari vengono rimossi - sono utilizzati soltanto durante il calcolo. La ricostruzione \xE8 effettuata in modo efficiente tramite un pre-fetch."),L1.forEach(i),Bn=d(e),Na=o(e,"P",{});var U1=t(Na);Fd=n(U1,"L\u2019intero procedimento \xE8 ripetuto per il layer Lb ed Lc nel passaggio in avanti, e poi all\u2019indietro Lc -> Lb -> La."),U1.forEach(i),Qn=d(e),Ra=o(e,"P",{});var G1=t(Ra);jd=n(G1,"Sembra proprio un\u2019efficiente strategia con cui distribuire i pesi:"),G1.forEach(i),Vn=d(e),M=o(e,"OL",{});var Do=t(M);rt=o(Do,"LI",{});var D1=t(rt);Bd=n(D1,"La persona A porta la tenda,"),D1.forEach(i),Qd=d(Do),nt=o(Do,"LI",{});var w1=t(nt);Vd=n(w1,"La persona B porta il fornello,"),w1.forEach(i),Hd=d(Do),st=o(Do,"LI",{});var S1=t(st);Xd=n(S1,"La persona C porta l\u2019ascia."),S1.forEach(i),Do.forEach(i),Hn=d(e),Za=o(e,"P",{});var I1=t(Za);Yd=n(I1,`Ogni notte, condividono quello che hanno con gli altri e ricevono dagli altri quello che non hanno, e la mattina riprendono l\u2019equipaggiamento a
loro assegnato e continuano per la loro strada. Questo \xE8 lo Shared DDP / Zero DP.`),I1.forEach(i),Xn=d(e),Fa=o(e,"P",{});var A1=t(Fa);Wd=n(A1,`Comparando questa strategia con quella pi\xF9 semplice, in cui ogni persona si porta la propria tenda, fornello ed ascia, quest\u2019ultima sarebbe molto pi\xF9 inefficiente.
Questo \xE8 il DataParallel (DP e DDP) su Pytorch.`),A1.forEach(i),Yn=d(e),ja=o(e,"P",{});var q1=t(ja);Jd=n(q1,"Leggendo la letteratura su questo argomento, potrai incontrare i seguenti sinonimi: condiviso (shared), partizionato (partitioned)."),q1.forEach(i),Wn=d(e),Ba=o(e,"P",{});var y1=t(Ba);Kd=n(y1,`Se presti molta attenzione al metodo in cui ZeRO suddivide i pesi del modello, noterai che \xE8 molto simile alla parallelizzazione dei tensori
che discuteremo pi\xF9 avanti. Questo perch\xE8 divide il peso di ogni layer, al contrario della parallelizzazione verticale che verr\xE0 discussa di seguito.`),y1.forEach(i),Jn=d(e),Qa=o(e,"P",{});var O1=t(Qa);eu=n(O1,"Implementazione:"),O1.forEach(i),Kn=d(e),$=o(e,"UL",{});var wo=t($);Va=o(wo,"LI",{});var rz=t(Va);ri=o(rz,"A",{href:!0,rel:!0});var M1=t(ri);iu=n(M1,"DeepSpeed"),M1.forEach(i),au=n(rz," ZeRO-DP stages 1+2+3"),rz.forEach(i),lu=d(wo),Ha=o(wo,"LI",{});var nz=t(Ha);ni=o(nz,"A",{href:!0,rel:!0});var $1=t(ni);ou=n($1,"Fairscale"),$1.forEach(i),tu=n(nz," ZeRO-DP stages 1+2+3"),nz.forEach(i),ru=d(wo),pt=o(wo,"LI",{});var T1=t(pt);si=o(T1,"A",{href:!0});var sz=t(si);nu=n(sz,"Integrazione "),ct=o(sz,"CODE",{});var C1=t(ct);su=n(C1,"transformers"),C1.forEach(i),sz.forEach(i),T1.forEach(i),wo.forEach(i),es=d(e),le=o(e,"H2",{class:!0});var dc=t(le);Ee=o(dc,"A",{id:!0,class:!0,href:!0});var k1=t(Ee);dt=o(k1,"SPAN",{});var x1=t(dt);h(pi.$$.fragment,x1),x1.forEach(i),k1.forEach(i),pu=d(dc),ut=o(dc,"SPAN",{});var N1=t(ut);cu=n(N1,"Parallelizzazione Ingenua del Modello (Verticale) e Parallelizzazione di Pipeline"),N1.forEach(i),dc.forEach(i),is=d(e),ge=o(e,"P",{});var uc=t(ge);du=n(uc,`La Naive Model Parallelism (MP) si ha quando dividiamo parti dei layer di un modello su pi\xF9 GPU. Il meccanismo \xE8 relativamente semplice - i layer desiderati sono
indirizzati ai dispositivi che desideriamo tramite `),mt=o(uc,"CODE",{});var R1=t(mt);uu=n(R1,".to()"),R1.forEach(i),mu=n(uc," e ogniqualvolta i dati entrano ed escono dai layer, questi passano per lo stesso dispositivo e lasciano gli altri invariati."),uc.forEach(i),as=d(e),Xa=o(e,"P",{});var Z1=t(Xa);fu=n(Z1,`Ci riferiamo a questo metodo come MP Verticale, perch\xE8 se ricordiamo come la maggior parte dei modelli sono disegnati, stiamo dividendo i modelli in verticale.
Ad esempio, il seguente diagramma mostra un modello con 8 layer:`),Z1.forEach(i),ls=d(e),h(ci.$$.fragment,e),os=d(e),Ya=o(e,"P",{});var F1=t(Ya);vu=n(F1,"Abbiamo semplicemente diviso il modello in 2 in verticale, inserendo i layer da 0 a 3 nella GPU0 e da 4 a 7 nella GPU1."),F1.forEach(i),ts=d(e),Le=o(e,"P",{});var mc=t(Le);Pu=n(mc,`Finch\xE8 i dati viaggiano dal layer 0 a 1, da 1 a 2, da 2 a 3, questi percorrono il modello in modo tradizionale.
Quando per\xF2 i dati passano dal layer 3 al layer 4, deve viaggiare dalla GPU0 alla GPU1, introducendo un communication overhead.
Se le GPU che partecipano sono sullo stesso nodo computazionale (ad esempio, la stessa macchina fisica), questo passaggio
\xE8 piuttosto veloce, ma se le GPU si trovano in diversi nodi computazionali (ad esempio, su pi\xF9 macchine), il tempo richiesto per la comunicazione`),hu=o(mc,"BR",{}),zu=n(mc,`
potrebbe essere molto grande.`),mc.forEach(i),rs=d(e),Wa=o(e,"P",{});var j1=t(Wa);bu=n(j1,`Infine, il passaggio dal layer 4 al 5, al 6 ed infine al 7 tornano ad essere quelli del modello normale, e quando il passaggio al layer 7 \xE8 completato,
spesso dobbiamo re-inviare i dati indietro al layer 0, in cui sono presenti le labels (oppure, dobbiamo far passare le labels all\u2019ultimo layer).
A questo punto, la funzione di perdita pu\xF2 essere calcolata e l\u2019ottimizzatore pu\xF2 fare il suo lavoro.`),j1.forEach(i),ns=d(e),Ja=o(e,"P",{});var B1=t(Ja);_u=n(B1,"Problemi:"),B1.forEach(i),ss=d(e),Ue=o(e,"UL",{});var fc=t(Ue);ft=o(fc,"LI",{});var Q1=t(ft);Eu=n(Q1,"la principale lacuna del metodo, da cui il nome MP \u201Cingenuo\u201D, \xE8 che soltanto una GPU \xE8 attiva in ogni momento. Perci\xF2, se 4 GPU sono utilizzate, \xE8 quasi identico a quadruplicare la quantit\xE0 di memoria di una singola GPU, ignorando il resto dell\u2019hardware. Inoltre, si aggiunge il costo di copiare i dati fra diversi dispositivi. Quindi 4x GPU da 6GB sarebbero in grado di accomodare la stessa dimensione di una GPU da 24GB, ma quest\u2019ultima completerebbe l\u2019allenamento in modo pi\xF9 veloce, dal momento che non ha il costo di copiare i dati. Ma, qualora dovessimo avere GPU da 40GB per contenere un modello da 45GB, questo metodo ci permetterebbe di eseguire l\u2019allenamento."),Q1.forEach(i),gu=d(fc),vt=o(fc,"LI",{});var V1=t(vt);Lu=n(V1,"rappresentazioni (embedding) condivise potrebbero dover essere copiate avanti e indietro fra le GPU."),V1.forEach(i),fc.forEach(i),ps=d(e),Ka=o(e,"P",{});var H1=t(Ka);Uu=n(H1,"La parallelizzazione delle Pipeline (PP) \xE8 pressoch\xE8 identica al metodo MP ingenuo, ma risolve il problema dell\u2019utilizzo di una sola GPU alla volta, dividendo la batch di dati in entrata in mini-batches e creando artificialmente una pipeline che consente alle differenti GPU di partecipare congiuntamente al processo computazionale."),H1.forEach(i),cs=d(e),Ge=o(e,"P",{});var vc=t(Ge);Gu=n(vc,"La seguente immagine dal "),di=o(vc,"A",{href:!0,rel:!0});var X1=t(di);Du=n(X1,"paper GPipe"),X1.forEach(i),wu=n(vc,`
mostra il MP ingenuo in alto ed il PP in basso:`),vc.forEach(i),ds=d(e),el=o(e,"P",{});var Y1=t(el);il=o(Y1,"IMG",{src:!0,alt:!0}),Y1.forEach(i),us=d(e),al=o(e,"P",{});var W1=t(al);Su=n(W1,"In basso nel diagramma possiamo facilmente notare come il PP ha meno tempi morti in cui le GPU non lavorano. Le parti in cui le GPU non lavorano sono spesso chiamate \u201Cbolle\u201D."),W1.forEach(i),ms=d(e),ll=o(e,"P",{});var J1=t(ll);Iu=n(J1,`Il grado di parallelizzazione in entrambe le parti dei diagrammi \xE8 4. Ci\xF2 significa che 4 GPU partecipano nel processo.
Per cui abbiamo un percorso in avanti di 4 passaggi, F0, F1, F2 e F3, seguito da un passaggio all\u2019indietro da B3, B2, B1 e B0.`),J1.forEach(i),fs=d(e),T=o(e,"P",{});var So=t(T);Au=n(So,"PP introduce un nuovo iperparametro da aggiustare: "),Pt=o(So,"CODE",{});var K1=t(Pt);qu=n(K1,"chunks"),K1.forEach(i),yu=n(So,`, che definisce quanti blocchi di dati sono inviati allo stesso passaggio nella pipeline. Ad esempio,
nel diagramma in basso possiamo vedere che `),ht=o(So,"CODE",{});var e2=t(ht);Ou=n(e2,"chunks=4"),e2.forEach(i),Mu=n(So,`. GPU0 effettua lo stesso passaggio sui blocchi 0, 1, 2 e 3 (F0,0, F0,1, F0,2, F0,3) dopodich\xE8
attende che le altre GPU facciano il loro lavoro e, quando stanno per terminare, GPU0 ricomincia a lavorare per il passaggio all\u2019indietro dei blocchi 3, 2, 1 e 0 (B0,3, B0,2, B0,1, B0,0).`),So.forEach(i),vs=d(e),De=o(e,"P",{});var Pc=t(De);$u=n(Pc,"Notiamo inoltre che concettualmente, questo \xE8 lo stesso concetto di uno step di accumulazione del gradiente (GAS). Pytorch utilizza "),zt=o(Pc,"CODE",{});var i2=t(zt);Tu=n(i2,"chunks"),i2.forEach(i),Cu=n(Pc,`
mentre DeepSpeed si riferisce allo stesso iperparametro come GAS.`),Pc.forEach(i),Ps=d(e),we=o(e,"P",{});var hc=t(we);ku=n(hc,`A causa dei blocchi, PP introduce il concetto di micro-batches (MBS). DP divide la bath size globale in mini-batches, quindi se abbiamo un grado di DP pari a 4,
una batch globale di dimensione 1024 vien divisa in 4 mini-batches da 256 ciascuna (1024/4). E se il numero di `),bt=o(hc,"CODE",{});var a2=t(bt);xu=n(a2,"chunks"),a2.forEach(i),Nu=n(hc,` (o GAS) \xE8 pari a 32, otteniamo
una micro-batch di dimensione 8 (256/32). Ogni passaggio della Pipeline funziona con una sola micro-batch alla volta.`),hc.forEach(i),hs=d(e),C=o(e,"P",{});var Io=t(C);Ru=n(Io,"Per calcolare la dimensione globale della batch di DP + PP possiamo eseguire: "),_t=o(Io,"CODE",{});var l2=t(_t);Zu=n(l2,"mbs*chunks*dp_degree"),l2.forEach(i),Fu=n(Io," ("),Et=o(Io,"CODE",{});var o2=t(Et);ju=n(o2,"8*32*4=1024"),o2.forEach(i),Bu=n(Io,")."),Io.forEach(i),zs=d(e),ol=o(e,"P",{});var t2=t(ol);Qu=n(t2,"Torniamo al diagramma."),t2.forEach(i),bs=d(e),k=o(e,"P",{});var Ao=t(k);Vu=n(Ao,"Con "),gt=o(Ao,"CODE",{});var r2=t(gt);Hu=n(r2,"chunks=1"),r2.forEach(i),Xu=n(Ao," otteniamo il MP ingenuo, che \xE8 molto inefficiente. Con valori "),Lt=o(Ao,"CODE",{});var n2=t(Lt);Yu=n(n2,"chunks"),n2.forEach(i),Wu=n(Ao,` molto grandi, otteniamo micro-batch di dimensioni troppo piccole, che
risultano anch\u2019esse non efficienti. Occorre quindi sperimentare per trovare il valore che porta al pi\xF9 efficiente utilizzo delle GPU.`),Ao.forEach(i),_s=d(e),w=o(e,"P",{});var Qe=t(w);Ju=n(Qe,"Poich\xE8 il diagramma mostra che c\u2019\xE8 una bolla di tempo \u201Cmorto\u201D che non pu\xF2 essere parallelizzato perch\xE8 l\u2019ultimo passaggio "),Ut=o(Qe,"CODE",{});var s2=t(Ut);Ku=n(s2,"forward"),s2.forEach(i),em=n(Qe,` deve aspettare il
completamento del `),Gt=o(Qe,"CODE",{});var p2=t(Gt);im=n(p2,"backward"),p2.forEach(i),am=n(Qe,", lo scopo di trovare il miglior valore possibile per "),Dt=o(Qe,"CODE",{});var c2=t(Dt);lm=n(c2,"chunks"),c2.forEach(i),om=n(Qe,` sta nel consentire una buona collaborazione fra le GPU partecipanti,
minimizzando la dimensione di questa bolla.`),Qe.forEach(i),Es=d(e),tl=o(e,"P",{});var d2=t(tl);tm=n(d2,"Ci sono 2 gruppi di soluzione - i metodi tradizionali della API Pipeline e soluzioni pi\xF9 moderne che rendono le cose pi\xF9 semplici per l\u2019utente finale."),d2.forEach(i),gs=d(e),rl=o(e,"P",{});var u2=t(rl);rm=n(u2,"Soluzioni tradizionali della API Pipeline:"),u2.forEach(i),Ls=d(e),S=o(e,"UL",{});var Ve=t(S);wt=o(Ve,"LI",{});var m2=t(wt);nm=n(m2,"PyTorch"),m2.forEach(i),sm=d(Ve),St=o(Ve,"LI",{});var f2=t(St);pm=n(f2,"FairScale"),f2.forEach(i),cm=d(Ve),It=o(Ve,"LI",{});var v2=t(It);dm=n(v2,"DeepSpeed"),v2.forEach(i),um=d(Ve),At=o(Ve,"LI",{});var P2=t(At);mm=n(P2,"Megatron-LM"),P2.forEach(i),Ve.forEach(i),Us=d(e),nl=o(e,"P",{});var h2=t(nl);fm=n(h2,"Soluzioni moderne:"),h2.forEach(i),Gs=d(e),Se=o(e,"UL",{});var zc=t(Se);qt=o(zc,"LI",{});var z2=t(qt);vm=n(z2,"Varuna"),z2.forEach(i),Pm=d(zc),yt=o(zc,"LI",{});var b2=t(yt);hm=n(b2,"Sagemaker"),b2.forEach(i),zc.forEach(i),Ds=d(e),sl=o(e,"P",{});var _2=t(sl);zm=n(_2,"Problemi delle soluzioni tradizionali della API Pipeline:"),_2.forEach(i),ws=d(e),I=o(e,"UL",{});var He=t(I);ui=o(He,"LI",{});var bc=t(ui);bm=n(bc,"richiede di modificare il modello piuttosto pesantemente, perch\xE8 Pipeline richiede di riscrivere il modello dei moduli in sequenze "),Ot=o(bc,"CODE",{});var E2=t(Ot);_m=n(E2,"nn.Sequential"),E2.forEach(i),Em=n(bc,", che potrebbero richiedere modifiche nel design del modello."),bc.forEach(i),gm=d(He),pl=o(He,"LI",{});var pz=t(pl);Lm=n(pz,"al momento, l\u2019API \xE8 molto limitata. Se hai diverse variabili python da inserire nel primo step della Pipeline, dovrai trovare un modo alternativo. Al momento, l\u2019interfaccia Pipeline necessit\xE0 o di un singolo tensore, o una tupla di tensori come unico input ed output. Questi tensori devono avere la batch size come prima dimensione, dal momento che la pipeline divider\xE0 le mini-batches in micro-batches. Possibili miglioramenti sono in discussione qua: "),mi=o(pz,"A",{href:!0,rel:!0});var g2=t(mi);Um=n(g2,"https://github.com/pytorch/pytorch/pull/50693"),g2.forEach(i),pz.forEach(i),Gm=d(He),Mt=o(He,"LI",{});var L2=t(Mt);Dm=n(L2,"il controllo del flusso condizionale al livello dei vari step della Pipeline non \xE8 possibile - ad esempio, modelli Encoder-Decoder come T5 richiedono speciali soluzioni per gestire i vari step di encoding condizionale."),L2.forEach(i),wm=d(He),$t=o(He,"LI",{});var U2=t($t);Sm=n(U2,"richiede di organizzare ciascun layer in modo che l\u2019output di un modello diventi l\u2019input dell\u2019altro."),U2.forEach(i),He.forEach(i),Ss=d(e),cl=o(e,"P",{});var G2=t(cl);Im=n(G2,"Necessitiamo ancora di sperimentare con Varuna e SageMaker, ma i loro paper riportano di aver superato la lista dei problemi menzionati in precedenza e dicono di richiedere cambiamenti molto minori nel modello dell\u2019utente."),G2.forEach(i),Is=d(e),dl=o(e,"P",{});var D2=t(dl);Am=n(D2,"Implementazioni:"),D2.forEach(i),As=d(e),f=o(e,"UL",{});var D=t(f);Ie=o(D,"LI",{});var mn=t(Ie);fi=o(mn,"A",{href:!0,rel:!0});var w2=t(fi);qm=n(w2,"Pytorch"),w2.forEach(i),ym=n(mn," (supporto iniziale in pytorch-1.8, progressivamente migliorato in 1.9 e 1.10). Alcuni "),vi=o(mn,"A",{href:!0,rel:!0});var S2=t(vi);Om=n(S2,"esempi"),S2.forEach(i),Mm=n(mn,"."),mn.forEach(i),$m=d(D),Tt=o(D,"LI",{});var I2=t(Tt);Pi=o(I2,"A",{href:!0,rel:!0});var A2=t(Pi);Tm=n(A2,"FairScale"),A2.forEach(i),I2.forEach(i),Cm=d(D),Ct=o(D,"LI",{});var q2=t(Ct);hi=o(q2,"A",{href:!0,rel:!0});var y2=t(hi);km=n(y2,"DeepSpeed"),y2.forEach(i),q2.forEach(i),xm=d(D),ul=o(D,"LI",{});var cz=t(ul);zi=o(cz,"A",{href:!0,rel:!0});var O2=t(zi);Nm=n(O2,"Megatron-LM"),O2.forEach(i),Rm=n(cz," ha un\u2019implementazione interna - no API."),cz.forEach(i),Zm=d(D),kt=o(D,"LI",{});var M2=t(kt);bi=o(M2,"A",{href:!0,rel:!0});var $2=t(bi);Fm=n($2,"Varuna"),$2.forEach(i),M2.forEach(i),jm=d(D),ml=o(D,"LI",{});var dz=t(ml);_i=o(dz,"A",{href:!0,rel:!0});var T2=t(_i);Bm=n(T2,"SageMaker"),T2.forEach(i),Qm=n(dz," - questa \xE8 una soluzione proprietaria che pu\xF2 essere solo utilizata su AWS."),dz.forEach(i),Vm=d(D),fl=o(D,"LI",{});var uz=t(fl);Ei=o(uz,"A",{href:!0,rel:!0});var C2=t(Ei);Hm=n(C2,"OSLO"),C2.forEach(i),Xm=n(uz," - questa implementazione \xE8 basata su Hugging Face Transformers."),uz.forEach(i),D.forEach(i),qs=d(e),Ae=o(e,"P",{});var _c=t(Ae);Ym=n(_c,`\u{1F917} Transformers status: al momento della scrittura di questa guida, nessuno dei modelli supporta full-PP. I modelli GPT2 e T5 hanno un supporto per il MP ingenuo.
Il principale ostacolo \xE8 l\u2019incapacit\xE0 di convertire i modelli in `),xt=o(_c,"CODE",{});var k2=t(xt);Wm=n(k2,"nn.Sequential"),k2.forEach(i),Jm=n(_c,` e che tutti gli input siano Tensori. Questo \xE8 dovuto al fatto che, al momento,
i modelli includono molte features che rendono la conversione molto complicata, e necessitano di essere rimosse per raggiungere questo obiettivo.`),_c.forEach(i),ys=d(e),vl=o(e,"P",{});var x2=t(vl);Km=n(x2,"Altri approcci:"),x2.forEach(i),Os=d(e),oe=o(e,"P",{});var fn=t(oe);ef=n(fn,"DeepSpeed, Varuna e SageMaker usano il concetto di una "),gi=o(fn,"A",{href:!0,rel:!0});var N2=t(gi);af=n(N2,"Interleaved Pipeline"),N2.forEach(i),lf=d(fn),Pl=o(fn,"IMG",{src:!0,alt:!0}),fn.forEach(i),Ms=d(e),hl=o(e,"P",{});var R2=t(hl);of=n(R2,"Qua la bolla (tempi morti) \xE8 ulteriormente minimizzata prioritizzando i passaggi all\u2019indietro."),R2.forEach(i),$s=d(e),zl=o(e,"P",{});var Z2=t(zl);tf=n(Z2,"Varuna cerca ulteriormente di migliorare la struttura utilizzando simulazioni per individuare il pi\xF9 efficiente scheduling."),Z2.forEach(i),Ts=d(e),qe=o(e,"P",{});var Ec=t(qe);rf=n(Ec,"OSLO ha una parallelizzazione di pipeline implementata basandosi su Transformers senza la conversione a "),Nt=o(Ec,"CODE",{});var F2=t(Nt);nf=n(F2,"nn.Sequential"),F2.forEach(i),sf=n(Ec,"."),Ec.forEach(i),Cs=d(e),te=o(e,"H2",{class:!0});var gc=t(te);ye=o(gc,"A",{id:!0,class:!0,href:!0});var j2=t(ye);Rt=o(j2,"SPAN",{});var B2=t(Rt);h(Li.$$.fragment,B2),B2.forEach(i),j2.forEach(i),pf=d(gc),Zt=o(gc,"SPAN",{});var Q2=t(Zt);cf=n(Q2,"Parallelizzazione dei Tensori"),Q2.forEach(i),gc.forEach(i),ks=d(e),bl=o(e,"P",{});var V2=t(bl);df=n(V2,"Nella parallelizzazione dei tensori ogni GPU processa soltando una parte di un tensore ed aggrega il tensore completo soltanto per le operazioni che lo richiedono."),V2.forEach(i),xs=d(e),x=o(e,"P",{});var qo=t(x);uf=n(qo,"In questa sezione usiamo concetti e diagrammi dal paper "),Ui=o(qo,"A",{href:!0,rel:!0});var H2=t(Ui);mf=n(H2,"Megatron-LM"),H2.forEach(i),ff=n(qo,": "),Gi=o(qo,"A",{href:!0,rel:!0});var X2=t(Gi);vf=n(X2,"Efficient Large-Scale Language Model Training on GPU Clusters"),X2.forEach(i),Pf=n(qo,"."),qo.forEach(i),Ns=d(e),N=o(e,"P",{});var yo=t(N);hf=n(yo,"Il blocco principale di ogni modello transformer \xE8 un layer fully connected "),Ft=o(yo,"CODE",{});var Y2=t(Ft);zf=n(Y2,"nn.Linear"),Y2.forEach(i),bf=n(yo," seguito da una funzione di attivazione non lineare "),jt=o(yo,"CODE",{});var W2=t(jt);_f=n(W2,"GeLU"),W2.forEach(i),Ef=n(yo,"."),yo.forEach(i),Rs=d(e),L=o(e,"P",{});var Q=t(L);gf=n(Q,"Seguento la notazione del paper di Megatron, possiamo scrivere il dot-product come "),Bt=o(Q,"CODE",{});var J2=t(Bt);Lf=n(J2,"Y = GeLU(XA)"),J2.forEach(i),Uf=n(Q,", dove "),Qt=o(Q,"CODE",{});var K2=t(Qt);Gf=n(K2,"X"),K2.forEach(i),Df=n(Q," ed "),Vt=o(Q,"CODE",{});var eb=t(Vt);wf=n(eb,"Y"),eb.forEach(i),Sf=n(Q," sono i vettori di input ed ouput ed "),Ht=o(Q,"CODE",{});var ib=t(Ht);If=n(ib,"A"),ib.forEach(i),Af=n(Q," \xE8 la matrice dei pesi."),Q.forEach(i),Zs=d(e),Di=o(e,"P",{});var mz=t(Di);qf=n(mz,`Se osserviamo i calcoli in forma matriciale, \xE8 facile notare come la moltiplicazione fra matrici pu\xF2 essere suddivisa fra pi\xF9 GPU:
`),_l=o(mz,"IMG",{src:!0,alt:!0}),mz.forEach(i),Fs=d(e),m=o(e,"P",{});var v=t(m);yf=n(v,"Se dividiamo la matrice di pesi "),Xt=o(v,"CODE",{});var ab=t(Xt);Of=n(ab,"A"),ab.forEach(i),Mf=n(v," in colonne, su "),Yt=o(v,"CODE",{});var lb=t(Yt);$f=n(lb,"N"),lb.forEach(i),Tf=n(v,"GPU e performiamo le moltiplicazioni fra matrici da "),Wt=o(v,"CODE",{});var ob=t(Wt);Cf=n(ob,"XA_1"),ob.forEach(i),kf=n(v," a "),Jt=o(v,"CODE",{});var tb=t(Jt);xf=n(tb,"XA_n"),tb.forEach(i),Nf=n(v," in parallelo, rimarremo con "),Kt=o(v,"CODE",{});var rb=t(Kt);Rf=n(rb,"N"),rb.forEach(i),Zf=n(v,`
vettori di output `),er=o(v,"CODE",{});var nb=t(er);Ff=n(nb,"Y_1, Y_2, ..., Y_n"),nb.forEach(i),jf=n(v," che possono essere inviati a "),ir=o(v,"CODE",{});var sb=t(ir);Bf=n(sb,"GeLU"),sb.forEach(i),Qf=n(v,` in modo indipendente:
`),El=o(v,"IMG",{src:!0,alt:!0}),v.forEach(i),js=d(e),wi=o(e,"P",{});var fz=t(wi);Vf=n(fz,`Secondo questo principio, possiamo aggiornare un MLP di profondit\xE0 arbitraria senza il bisogno di sincronizzare le GPU fino alla fine del procedimento,
al termine del quale necessiteremo di ricostruire l\u2019output dai singoli blocchi. Gli autori del paper Megatron-LM hanno realizzato un\u2019illustrazione utile per questo:
`),gl=o(fz,"IMG",{src:!0,alt:!0}),fz.forEach(i),Bs=d(e),Si=o(e,"P",{});var vz=t(Si);Hf=n(vz,`Parallelizzare i layer di multi-head attention \xE8 perfino pi\xF9 semplice, dal momento che sono gi\xE0 per loro natura paralleli grazie al fatto che hanno pi\xF9 heads indipendenti!
`),Ll=o(vz,"IMG",{src:!0,alt:!0}),vz.forEach(i),Qs=d(e),Ul=o(e,"P",{});var pb=t(Ul);Xf=n(pb,`Considerazioni speciali: TP richiede una rete di GPU molto veloce, per cui non \xE8 suggeribile effettuare TP su pi\xF9 nodi (macchine).
In pratica, se un nodo ha 4 GPU, il maggior grado di TP pu\xF2 essere 4. Se necessiti di un TP di grado 8, dovrai utilizzare nodi che hanno almeno 8 GPU.`),pb.forEach(i),Vs=d(e),R=o(e,"P",{});var Oo=t(R);Yf=n(Oo,"Questa sezione \xE8 basata sull\u2019originale e molto pi\xF9 dettagliata  TP overview]("),Ii=o(Oo,"A",{href:!0,rel:!0});var cb=t(Ii);Wf=n(cb,"https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530"),cb.forEach(i),Jf=n(Oo,`).
by `),Ai=o(Oo,"A",{href:!0,rel:!0});var db=t(Ai);Kf=n(db,"@anton-l"),db.forEach(i),ev=n(Oo,"."),Oo.forEach(i),Hs=d(e),Gl=o(e,"P",{});var ub=t(Gl);iv=n(ub,"SageMaker combina TP con DP per un processing pi\xF9 efficiente."),ub.forEach(i),Xs=d(e),Dl=o(e,"P",{});var mb=t(Dl);av=n(mb,"Nomi alternativi:"),mb.forEach(i),Ys=d(e),wl=o(e,"UL",{});var fb=t(wl);Sl=o(fb,"LI",{});var Pz=t(Sl);lv=n(Pz,"DeepSpeed lo chiama "),qi=o(Pz,"A",{href:!0,rel:!0});var vb=t(qi);ov=n(vb,"tensor slicing"),vb.forEach(i),Pz.forEach(i),fb.forEach(i),Ws=d(e),Il=o(e,"P",{});var Pb=t(Il);tv=n(Pb,"Implementazioni:"),Pb.forEach(i),Js=d(e),A=o(e,"UL",{});var Xe=t(A);Al=o(Xe,"LI",{});var hz=t(Al);yi=o(hz,"A",{href:!0,rel:!0});var hb=t(yi);rv=n(hb,"Megatron-LM"),hb.forEach(i),nv=n(hz," ha un\u2019implementazione interna, molto specifica per quel modello"),hz.forEach(i),sv=d(Xe),ql=o(Xe,"LI",{});var zz=t(ql);Oi=o(zz,"A",{href:!0,rel:!0});var zb=t(Oi);pv=n(zb,"parallelformers"),zb.forEach(i),cv=n(zz," (al momento, solo per l\u2019inferenza)"),zz.forEach(i),dv=d(Xe),yl=o(Xe,"LI",{});var bz=t(yl);Mi=o(bz,"A",{href:!0,rel:!0});var bb=t(Mi);uv=n(bb,"SageMaker"),bb.forEach(i),mv=n(bz," - soluzione proprietaria di AWS"),bz.forEach(i),fv=d(Xe),Ol=o(Xe,"LI",{});var _z=t(Ol);$i=o(_z,"A",{href:!0,rel:!0});var _b=t($i);vv=n(_b,"OSLO"),_b.forEach(i),Pv=n(_z," ha un\u2019implementazione di TP basata su Transformers."),_z.forEach(i),Xe.forEach(i),Ks=d(e),Ml=o(e,"P",{});var Eb=t(Ml);hv=n(Eb,"\u{1F917} Transformers status:"),Eb.forEach(i),ep=d(e),Z=o(e,"UL",{});var Mo=t(Z);ar=o(Mo,"LI",{});var gb=t(ar);zv=n(gb,"core: non ancora implementato"),gb.forEach(i),bv=d(Mo),Ti=o(Mo,"LI",{});var Lc=t(Ti);_v=n(Lc,"ma se vuoi fare inferenza, "),Ci=o(Lc,"A",{href:!0,rel:!0});var Lb=t(Ci);Ev=n(Lb,"parallelformers"),Lb.forEach(i),gv=n(Lc," offre questo supporto per la maggior parte dei nostri modelli. Finch\xE8 questo non \xE8 implementato nella libreria princiaple, puoi usare questa libreria. Ci auguriamo anche che diventi disponibile in fase di allenamento oltre che per l\u2019inferenza."),Lc.forEach(i),Lv=d(Mo),$l=o(Mo,"LI",{});var Ez=t($l);Uv=n(Ez,"Deepspeed-Inference supporta anche BERT, GPT-2 e GPT-Neo nella loro super-veloce modalit\xE0 di inferenza basata su CUDA-kernel, vedi "),ki=o(Ez,"A",{href:!0,rel:!0});var Ub=t(ki);Gv=n(Ub,"qui"),Ub.forEach(i),Ez.forEach(i),Mo.forEach(i),ip=d(e),re=o(e,"H2",{class:!0});var Uc=t(re);Oe=o(Uc,"A",{id:!0,class:!0,href:!0});var Gb=t(Oe);lr=o(Gb,"SPAN",{});var Db=t(lr);h(xi.$$.fragment,Db),Db.forEach(i),Gb.forEach(i),Dv=d(Uc),or=o(Uc,"SPAN",{});var wb=t(or);wv=n(wb,"DP+PP"),wb.forEach(i),Uc.forEach(i),ap=d(e),Me=o(e,"P",{});var Gc=t(Me);Sv=n(Gc,"Il seguente diagramma del "),Ni=o(Gc,"A",{href:!0,rel:!0});var Sb=t(Ni);Iv=n(Sb,"tutorial di DeepSpeed"),Sb.forEach(i),Av=n(Gc," dimostra come combinare DP con PP."),Gc.forEach(i),lp=d(e),Tl=o(e,"P",{});var Ib=t(Tl);Cl=o(Ib,"IMG",{src:!0,alt:!0}),Ib.forEach(i),op=d(e),kl=o(e,"P",{});var Ab=t(kl);qv=n(Ab,`Qua \xE8 importante notare come il rango 0 di DP non vede la GPU2 e il DP di rango 1 non vede la GPU3. Per il DP \xE8 come se ci fossero soltanto GPU0 e GPU1, ai
quali passa i dati come se ci fossero solo 2 GPU. GPU0 \u201Csegretamente\u201D passa parte del suo carico alla GPU2 tramite PP, e lo stesso vale per GPU1 con GPU3.`),Ab.forEach(i),tp=d(e),xl=o(e,"P",{});var qb=t(xl);yv=n(qb,"Dal momento che ciascuna dimensione richiede almeno 2 GPU, in questo caso sarebbero necessarie almeno 4 GPU."),qb.forEach(i),rp=d(e),Nl=o(e,"P",{});var yb=t(Nl);Ov=n(yb,"Implementazioni:"),yb.forEach(i),np=d(e),U=o(e,"UL",{});var V=t(U);tr=o(V,"LI",{});var Ob=t(tr);Ri=o(Ob,"A",{href:!0,rel:!0});var Mb=t(Ri);Mv=n(Mb,"DeepSpeed"),Mb.forEach(i),Ob.forEach(i),$v=d(V),rr=o(V,"LI",{});var $b=t(rr);Zi=o($b,"A",{href:!0,rel:!0});var Tb=t(Zi);Tv=n(Tb,"Megatron-LM"),Tb.forEach(i),$b.forEach(i),Cv=d(V),nr=o(V,"LI",{});var Cb=t(nr);Fi=o(Cb,"A",{href:!0,rel:!0});var kb=t(Fi);kv=n(kb,"Varuna"),kb.forEach(i),Cb.forEach(i),xv=d(V),sr=o(V,"LI",{});var xb=t(sr);ji=o(xb,"A",{href:!0,rel:!0});var Nb=t(ji);Nv=n(Nb,"SageMaker"),Nb.forEach(i),xb.forEach(i),Rv=d(V),pr=o(V,"LI",{});var Rb=t(pr);Bi=o(Rb,"A",{href:!0,rel:!0});var Zb=t(Bi);Zv=n(Zb,"OSLO"),Zb.forEach(i),Rb.forEach(i),V.forEach(i),sp=d(e),Rl=o(e,"P",{});var Fb=t(Rl);Fv=n(Fb,"\u{1F917} Transformers status: non ancora implementato."),Fb.forEach(i),pp=d(e),ne=o(e,"H2",{class:!0});var Dc=t(ne);$e=o(Dc,"A",{id:!0,class:!0,href:!0});var jb=t($e);cr=o(jb,"SPAN",{});var Bb=t(cr);h(Qi.$$.fragment,Bb),Bb.forEach(i),jb.forEach(i),jv=d(Dc),dr=o(Dc,"SPAN",{});var Qb=t(dr);Bv=n(Qb,"DP+PP+TP"),Qb.forEach(i),Dc.forEach(i),cp=d(e),Zl=o(e,"P",{});var Vb=t(Zl);Qv=n(Vb,"Per avere un allenamento ancora pi\xF9 efficiente, una parallelizzazione 3D pu\xF2 essere utilizzata, combinando TP, DP e PP. Possiamo osservarlo nel seguente diagramma:"),Vb.forEach(i),dp=d(e),Fl=o(e,"P",{});var Hb=t(Fl);jl=o(Hb,"IMG",{src:!0,alt:!0}),Hb.forEach(i),up=d(e),Te=o(e,"P",{});var wc=t(Te);Vv=n(wc,"Questo diagramma \xE8 stato preso dal post "),Vi=o(wc,"A",{href:!0,rel:!0});var Xb=t(Vi);Hv=n(Xb,"3D parallelism: Scaling to trillion-parameter models"),Xb.forEach(i),Xv=n(wc,", che \xE8 una lettura interessante sull\u2019argomento."),wc.forEach(i),mp=d(e),Bl=o(e,"P",{});var Yb=t(Bl);Yv=n(Yb,"Dal momento che ciascuan dimensione richiede almeno 2 GPU, in questo caso sono necessarie almeno 8 GPU."),Yb.forEach(i),fp=d(e),Ql=o(e,"P",{});var Wb=t(Ql);Wv=n(Wb,"Implementazioni:"),Wb.forEach(i),vp=d(e),G=o(e,"UL",{});var H=t(G);Vl=o(H,"LI",{});var gz=t(Vl);Hi=o(gz,"A",{href:!0,rel:!0});var Jb=t(Hi);Jv=n(Jb,"DeepSpeed"),Jb.forEach(i),Kv=n(gz," - DeepSpeed include anche una versione di DP pi\xF9 efficiente, chiamata ZeRO-DP."),gz.forEach(i),eP=d(H),ur=o(H,"LI",{});var Kb=t(ur);Xi=o(Kb,"A",{href:!0,rel:!0});var e3=t(Xi);iP=n(e3,"Megatron-LM"),e3.forEach(i),Kb.forEach(i),aP=d(H),mr=o(H,"LI",{});var i3=t(mr);Yi=o(i3,"A",{href:!0,rel:!0});var a3=t(Yi);lP=n(a3,"Varuna"),a3.forEach(i),i3.forEach(i),oP=d(H),fr=o(H,"LI",{});var l3=t(fr);Wi=o(l3,"A",{href:!0,rel:!0});var o3=t(Wi);tP=n(o3,"SageMaker"),o3.forEach(i),l3.forEach(i),rP=d(H),vr=o(H,"LI",{});var t3=t(vr);Ji=o(t3,"A",{href:!0,rel:!0});var r3=t(Ji);nP=n(r3,"OSLO"),r3.forEach(i),t3.forEach(i),H.forEach(i),Pp=d(e),Hl=o(e,"P",{});var n3=t(Hl);sP=n(n3,"\u{1F917} Transformers status: non ancora implementato, dato che non abbiamo ancora PP e TP."),n3.forEach(i),hp=d(e),se=o(e,"H2",{class:!0});var Sc=t(se);Ce=o(Sc,"A",{id:!0,class:!0,href:!0});var s3=t(Ce);Pr=o(s3,"SPAN",{});var p3=t(Pr);h(Ki.$$.fragment,p3),p3.forEach(i),s3.forEach(i),pP=d(Sc),hr=o(Sc,"SPAN",{});var c3=t(hr);cP=n(c3,"ZeRO DP+PP+TP"),c3.forEach(i),Sc.forEach(i),zp=d(e),ke=o(e,"P",{});var Ic=t(ke);dP=n(Ic,"Una delle funzionalit\xE0 principali di DeepSpeed \xE8 ZeRO, che \xE8 un\u2019estensione super scalabile di DP. Questa \xE8 gi\xE0 stata discussa in "),Xl=o(Ic,"A",{href:!0});var d3=t(Xl);uP=n(d3,"ZeRO Data Parallelism"),d3.forEach(i),mP=n(Ic,`.
Normalmente, \xE8 una funzionalit\xE0 a s\xE8 stante, che non richiede PP o TP, ma pu\xF2 essere combinata con PP e TP.`),Ic.forEach(i),bp=d(e),Yl=o(e,"P",{});var u3=t(Yl);fP=n(u3,"Quando ZeRO-DP \xE8 combinata con PP (e opzionalmente TP) tipicalmente permette soltanto ZeRO stage 1 (optimizer sharding)."),u3.forEach(i),_p=d(e),Wl=o(e,"P",{});var m3=t(Wl);vP=n(m3,`Sebbene sia teoricamente possibile utilizzare ZeRO stage 2 (gradient sharding) con la parallelizzazione della Pipeline, questo porta a impatti negativi sulla performance.
Sarebbe necessario avere un addizionale riduttore di dispersione per ogni micro-batch per ri-aggregare i gradienti prima di dividerli, che aggiunge un overhead di comunicazione
potenzialmente molto significativo. Per natura del PP, vengono utilizzate delle piccole micro-batches e invece lo scopo \xE8 bilanciare l\u2019intensit\xE0 aritmetica (micro-batch size) con
la minimizzazione della bolla della Pipeline (numero di micro-batches). Per cui, i costi di comunicazione cresceranno.`),m3.forEach(i),Ep=d(e),xe=o(e,"P",{});var Ac=t(xe);PP=n(Ac,`Inoltre, ci sono gi\xE0 meno layer del solito grazie al PP, per cui il risparmio in termini di memoria non risulta particolarmente rilevante.
PP riduce gi\xE0 il gradiente di  `),zr=o(Ac,"CODE",{});var f3=t(zr);hP=n(f3,"1/PP"),f3.forEach(i),zP=n(Ac,", per cui il risparmio ottenuto dividendo i gradienti sono meno significativi rispetto al puro DP."),Ac.forEach(i),gp=d(e),Jl=o(e,"P",{});var v3=t(Jl);bP=n(v3,"Allo stesso modo, ZeRO stage 3 non \xE8 una buona scelta per lo stesso motivo - pi\xF9 comunicazioni fra nodi sono richieste."),v3.forEach(i),Lp=d(e),Kl=o(e,"P",{});var P3=t(Kl);_P=n(P3,"Dal momento che abbiamo ZeRO, un altro beneficio \xE8 lo ZeRO-Offload. Dal momento che questo \xE8 uno stage 1 optimizer, possiamo scaricare in CPU gli stati del modello."),P3.forEach(i),Up=d(e),eo=o(e,"P",{});var h3=t(eo);EP=n(h3,"Implementazioni:"),h3.forEach(i),Gp=d(e),Ne=o(e,"UL",{});var qc=t(Ne);Re=o(qc,"LI",{});var vn=t(Re);ea=o(vn,"A",{href:!0,rel:!0});var z3=t(ea);gP=n(z3,"Megatron-DeepSpeed"),z3.forEach(i),LP=n(vn," e "),ia=o(vn,"A",{href:!0,rel:!0});var b3=t(ia);UP=n(b3,"Megatron-Deepspeed from BigScience"),b3.forEach(i),GP=n(vn,", che \xE8 una fork della repo precedente."),vn.forEach(i),DP=d(qc),br=o(qc,"LI",{});var _3=t(br);aa=o(_3,"A",{href:!0,rel:!0});var E3=t(aa);wP=n(E3,"OSLO"),E3.forEach(i),_3.forEach(i),qc.forEach(i),Dp=d(e),io=o(e,"P",{});var g3=t(io);SP=n(g3,"Paper importanti:"),g3.forEach(i),wp=d(e),ao=o(e,"UL",{});var L3=t(ao);_r=o(L3,"LI",{});var U3=t(_r);la=o(U3,"A",{href:!0,rel:!0});var G3=t(la);IP=n(G3,"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model"),G3.forEach(i),U3.forEach(i),L3.forEach(i),Sp=d(e),lo=o(e,"P",{});var D3=t(lo);AP=n(D3,"\u{1F917} Transformers status: non ancora implementato, dal momento che non abbiamo ancora PP e TP."),D3.forEach(i),Ip=d(e),pe=o(e,"H2",{class:!0});var yc=t(pe);Ze=o(yc,"A",{id:!0,class:!0,href:!0});var w3=t(Ze);Er=o(w3,"SPAN",{});var S3=t(Er);h(oa.$$.fragment,S3),S3.forEach(i),w3.forEach(i),qP=d(yc),gr=o(yc,"SPAN",{});var I3=t(gr);yP=n(I3,"FlexFlow"),I3.forEach(i),yc.forEach(i),Ap=d(e),ta=o(e,"P",{});var Lz=t(ta);ra=o(Lz,"A",{href:!0,rel:!0});var A3=t(ra);OP=n(A3,"FlexFlow"),A3.forEach(i),MP=n(Lz," risolve il problema di parallelizzazione in un approccio leggermente diverso."),Lz.forEach(i),qp=d(e),na=o(e,"P",{});var Uz=t(na);$P=n(Uz,"Paper: "),sa=o(Uz,"A",{href:!0,rel:!0});var q3=t(sa);TP=n(q3,"\u201CBeyond Data and Model Parallelism for Deep Neural Networks\u201D by Zhihao Jia, Matei Zaharia, Alex Aiken"),q3.forEach(i),Uz.forEach(i),yp=d(e),oo=o(e,"P",{});var y3=t(oo);CP=n(y3,"Effettua una sorta di parallelizzazione 4D su Campione-Operatore-Attributi-Parametri:"),y3.forEach(i),Op=d(e),q=o(e,"OL",{});var Ye=t(q);Lr=o(Ye,"LI",{});var O3=t(Lr);kP=n(O3,"Campione = Data Parallelism (parallelizzazione per campione)"),O3.forEach(i),xP=d(Ye),Ur=o(Ye,"LI",{});var M3=t(Ur);NP=n(M3,"Operatore = Parallelizza una singola operazione in pi\xF9 sotto-operazioni"),M3.forEach(i),RP=d(Ye),Gr=o(Ye,"LI",{});var $3=t(Gr);ZP=n($3,"Attributi = Data Parallelism (parallelizzazione length-wise)"),$3.forEach(i),FP=d(Ye),Dr=o(Ye,"LI",{});var T3=t(Dr);jP=n(T3,"Parametri = Model Parallelism (a prescindere dalla dimensione, orizzontale o verticale)"),T3.forEach(i),Ye.forEach(i),Mp=d(e),to=o(e,"P",{});var C3=t(to);BP=n(C3,"Esempi:"),C3.forEach(i),$p=d(e),ro=o(e,"UL",{});var k3=t(ro);wr=o(k3,"LI",{});var x3=t(wr);QP=n(x3,"Campione"),x3.forEach(i),k3.forEach(i),Tp=d(e),no=o(e,"P",{});var N3=t(no);VP=n(N3,"Prendiamo 10 batches di lunghezza 512, 10 x 512. Se parallelizzate su due dispositivi, otteniamo 5 x 2 x 512."),N3.forEach(i),Cp=d(e),so=o(e,"UL",{});var R3=t(so);Sr=o(R3,"LI",{});var Z3=t(Sr);HP=n(Z3,"Operatore"),Z3.forEach(i),R3.forEach(i),kp=d(e),po=o(e,"P",{});var F3=t(po);XP=n(F3,`Se effettuiamo l\u2019operazione di normalizzazione per i layer, possiamo calcolare prima la deviazione standard, poi la media, e poi normalizzare i dati.
Parallelizzare per operatore consente di calcolare la deviazione standard e la media in parallelo. Per cui se li parallelizzassimo fra due dispositivi
(cuda:0, cuda:1), possiamo prima copiare i dati in entrambi i dispositivi, dopodich\xE8 cuda:0 calcola la deviazione standard e cuda:1 calcola la media allo stesso tempo.`),F3.forEach(i),xp=d(e),co=o(e,"UL",{});var j3=t(co);Ir=o(j3,"LI",{});var B3=t(Ir);YP=n(B3,"Attributi"),B3.forEach(i),j3.forEach(i),Np=d(e),uo=o(e,"P",{});var Q3=t(uo);WP=n(Q3,"Se abbiamo 10 batches di lunghezza 512, parallelizzandoli per la dimensione degli attributi otteniamo 10 x 2 x 256."),Q3.forEach(i),Rp=d(e),mo=o(e,"UL",{});var V3=t(mo);Ar=o(V3,"LI",{});var H3=t(Ar);JP=n(H3,"Parametri"),H3.forEach(i),V3.forEach(i),Zp=d(e),fo=o(e,"P",{});var X3=t(fo);KP=n(X3,"Funziona in modo simile alla parallelizzazione dei tensori o alla parallelizzazione ingenua dei layer."),X3.forEach(i),Fp=d(e),vo=o(e,"P",{});var Y3=t(vo);Po=o(Y3,"IMG",{src:!0,alt:!0}),Y3.forEach(i),jp=d(e),ho=o(e,"P",{});var W3=t(ho);eh=n(W3,`L\u2019importanza di questo framweork \xE8 che prende risorse come (1) GPU/TPU/CPU vs. (2) RAM/DRAM vs. (3) inter-connessioni veloci/inter-connessioni lente ed
automaticamente le ottimizza tramite un algoritmo, che decide quale parallelizzazione usare.`),W3.forEach(i),Bp=d(e),zo=o(e,"P",{});var J3=t(zo);ih=n(J3,`Un aspetto molto importante \xE8 che FlexFlow \xE8 pensato per ottimizzare parallelizzazioni per modelli con carichi di lavoro statici e fissati,poich\xE8
modelli dinamici potrebbero preferire differenti strategie di parallelizzazione fra le differenti iterazioni.`),J3.forEach(i),Qp=d(e),bo=o(e,"P",{});var K3=t(bo);ah=n(K3,`La promessa \xE8 molto invitante - effettua una simulazione di 30 minuti su un cluster ed elabora la miglior strategia da utilizzare per l\u2019ambiente specifico.
Se qualche parte venisse aggiunta/rimossa/modificata, l\u2019algoritmo ri-parte e ri-ottimizza il piano di parallelizzazione, dopodich\xE8 potrai tornare ad allenare il modello.
Ciascuna impostazione avr\xE0 la sua ottimizzazione specifica.`),K3.forEach(i),Vp=d(e),Fe=o(e,"P",{});var Oc=t(Fe);lh=n(Oc,"\u{1F917} Transformers status: non ancora implementato. Abbiamo modelli FX-trace-able in "),pa=o(Oc,"A",{href:!0,rel:!0});var e_=t(pa);oh=n(e_,"transformers.utils.fx"),e_.forEach(i),th=n(Oc,`,
che \xE8 un prerequisito per utilizzare FlexFlow, perci\xF2 qualcuno dovr\xE0 capire cosa \xE8 necessario fare per far funzionare FlexFlow con i nostri modelli.`),Oc.forEach(i),Hp=d(e),ce=o(e,"H2",{class:!0});var Mc=t(ce);je=o(Mc,"A",{id:!0,class:!0,href:!0});var i_=t(je);qr=o(i_,"SPAN",{});var a_=t(qr);h(ca.$$.fragment,a_),a_.forEach(i),i_.forEach(i),rh=d(Mc),yr=o(Mc,"SPAN",{});var l_=t(yr);nh=n(l_,"Quale Strategia Usare e Quando"),l_.forEach(i),Mc.forEach(i),Xp=d(e),_o=o(e,"P",{});var o_=t(_o);sh=n(o_,"Segue uno schema molto approssimativo di quale strategia di parallelizzazione usare e quando. Il primo di ogni lista \xE8 tipicamente il pi\xF9 veloce."),o_.forEach(i),Yp=d(e),Eo=o(e,"P",{});var t_=t(Eo);Or=o(t_,"STRONG",{});var r_=t(Or);ph=n(r_,"\u21E8 Una sola GPU"),r_.forEach(i),t_.forEach(i),Wp=d(e),F=o(e,"UL",{});var $o=t(F);da=o($o,"LI",{});var $c=t(da);Mr=o($c,"P",{});var n_=t(Mr);ch=n(n_,"Se il modello riesce a stare dentro una singola GPU:"),n_.forEach(i),dh=d($c),$r=o($c,"OL",{});var s_=t($r);Tr=o(s_,"LI",{});var p_=t(Tr);uh=n(p_,"Utilizzo normale"),p_.forEach(i),s_.forEach(i),$c.forEach(i),mh=d($o),ua=o($o,"LI",{});var Tc=t(ua);Cr=o(Tc,"P",{});var c_=t(Cr);fh=n(c_,"Se il modello non riesce a stare dentro una singola GPU:"),c_.forEach(i),vh=d(Tc),ma=o(Tc,"OL",{});var Cc=t(ma);kr=o(Cc,"LI",{});var d_=t(kr);Ph=n(d_,"ZeRO + Offload CPU e opzionalmente NVMe"),d_.forEach(i),hh=d(Cc),xr=o(Cc,"LI",{});var u_=t(xr);zh=n(u_,"come sopra, pi\xF9 Memory Centric Tiling (vedi sotto per maggiori dettagli) se il layer pi\xF9 grande non riesce a stare in una singola GPU"),u_.forEach(i),Cc.forEach(i),Tc.forEach(i),bh=d($o),Nr=o($o,"LI",{});var m_=t(Nr);Rr=o(m_,"P",{});var f_=t(Rr);_h=n(f_,"Se il layer pi\xF9 grande non riesce a stare dentro una singola GPU:"),f_.forEach(i),m_.forEach(i),$o.forEach(i),Jp=d(e),go=o(e,"OL",{});var v_=t(go);de=o(v_,"LI",{});var To=t(de);Eh=n(To,"ZeRO - Attiva "),fa=o(To,"A",{href:!0,rel:!0});var P_=t(fa);gh=n(P_,"Memory Centric Tiling"),P_.forEach(i),Lh=n(To," (MCT). Consente di allenare layer arbitrariamente grandi dividendoli ed eseguendoli sequenzialmente. MCT riduce il numero di parametri attivi in una GPU, ma non ha effetto sulla memoria di attivazione. Dal momento che questa necessit\xE0 \xE8 molto rara, nel momento in cui scriviamo questa guida spetta all\u2019utente effettuare una sovrascrizione manuale di "),Zr=o(To,"CODE",{});var h_=t(Zr);Uh=n(h_,"torch.nn.Linear"),h_.forEach(i),Gh=n(To,"."),To.forEach(i),v_.forEach(i),Kp=d(e),Lo=o(e,"P",{});var z_=t(Lo);Fr=o(z_,"STRONG",{});var b_=t(Fr);Dh=n(b_,"\u21E8 Un solo nodo / Multi-GPU"),b_.forEach(i),z_.forEach(i),ec=d(e),j=o(e,"UL",{});var Co=t(j);va=o(Co,"LI",{});var kc=t(va);jr=o(kc,"P",{});var __=t(jr);wh=n(__,"Se il modello riesce a stare dentro una singola GPU:"),__.forEach(i),Sh=d(kc),Pa=o(kc,"OL",{});var xc=t(Pa);Br=o(xc,"LI",{});var E_=t(Br);Ih=n(E_,"DDP - DP distribuito"),E_.forEach(i),Ah=d(xc),Qr=o(xc,"LI",{});var g_=t(Qr);qh=n(g_,"ZeRO - potrebbe o meno essere pi\xF9 veloce a seconda della configurazione utilizzata"),g_.forEach(i),xc.forEach(i),kc.forEach(i),yh=d(Co),ha=o(Co,"LI",{});var Nc=t(ha);Vr=o(Nc,"P",{});var L_=t(Vr);Oh=n(L_,"Se il modello non riesce a stare dentro una singola GPU:"),L_.forEach(i),Mh=d(Nc),ue=o(Nc,"OL",{});var ko=t(ue);Hr=o(ko,"LI",{});var U_=t(Hr);Xr=o(U_,"P",{});var G_=t(Xr);$h=n(G_,"PP"),G_.forEach(i),U_.forEach(i),Th=d(ko),Yr=o(ko,"LI",{});var D_=t(Yr);Wr=o(D_,"P",{});var w_=t(Wr);Ch=n(w_,"ZeRO"),w_.forEach(i),D_.forEach(i),kh=d(ko),me=o(ko,"LI",{});var xo=t(me);Jr=o(xo,"P",{});var S_=t(Jr);xh=n(S_,"TP"),S_.forEach(i),Nh=d(xo),Kr=o(xo,"P",{});var I_=t(Kr);Rh=n(I_,"Con connettivit\xE0 fra nodi ultraveloce (NVLINK o NVSwitch) tutti e tre i metodi dovrebbero essere prevalentemente alla pari, senza questi invece il PP dovrebbe essere il pi\xF9 veloce. Il grado di TP potrebbe inoltre  fare la differenza. Il metodo migliore sta nello sperimentare finch\xE8 non troverai il miglior metodo per le tue impostazioni."),I_.forEach(i),Zh=d(xo),en=o(xo,"P",{});var A_=t(en);Fh=n(A_,"TP \xE8 quasi sempre utilizzato all\u2019interno dello stesso nodo. Per cui, dimensione del TP <= GPU di ciascun nodo."),A_.forEach(i),xo.forEach(i),ko.forEach(i),Nc.forEach(i),jh=d(Co),za=o(Co,"LI",{});var Rc=t(za);an=o(Rc,"P",{});var q_=t(an);Bh=n(q_,"Se il layer pi\xF9 grande non riesce a stare dentro una singola GPU:"),q_.forEach(i),Qh=d(Rc),ba=o(Rc,"OL",{});var Zc=t(ba);ln=o(Zc,"LI",{});var y_=t(ln);Vh=n(y_,"Se non utilizzi ZeRO - devi utilizzare TP dal momento che PP da solo non sar\xE0 in grado di far stare il layer nella GPU."),y_.forEach(i),Hh=d(Zc),on=o(Zc,"LI",{});var O_=t(on);Xh=n(O_,"Con ZeRO vedi il punto precedente \u201CUna sola GPU\u201D"),O_.forEach(i),Zc.forEach(i),Rc.forEach(i),Co.forEach(i),ic=d(e),Uo=o(e,"P",{});var M_=t(Uo);tn=o(M_,"STRONG",{});var $_=t(tn);Yh=n($_,"\u21E8 Multi-Node / Multi-GPU"),$_.forEach(i),M_.forEach(i),ac=d(e),Be=o(e,"UL",{});var Fc=t(Be);_a=o(Fc,"LI",{});var jc=t(_a);rn=o(jc,"P",{});var T_=t(rn);Wh=n(T_,"Se hai una veloce connettivit\xE0 fra nodi:"),T_.forEach(i),Jh=d(jc),Ea=o(jc,"OL",{});var Bc=t(Ea);nn=o(Bc,"LI",{});var C_=t(nn);Kh=n(C_,"ZeRO - poich\xE8 non richiede pressoch\xE8 alcuna modifica al modello"),C_.forEach(i),ez=d(Bc),sn=o(Bc,"LI",{});var k_=t(sn);iz=n(k_,"PP+TP+DP - meno comunicazioni, ma richiede importanti modifiche al modello"),k_.forEach(i),Bc.forEach(i),jc.forEach(i),az=d(Fc),ga=o(Fc,"LI",{});var Qc=t(ga);pn=o(Qc,"P",{});var x_=t(pn);lz=n(x_,"Se hai una connettivit\xE0 fra nodi lenta e una memoria GPU scarsa:"),x_.forEach(i),oz=d(Qc),cn=o(Qc,"OL",{});var N_=t(cn);dn=o(N_,"LI",{});var R_=t(dn);tz=n(R_,"DP+PP+TP+ZeRO-1"),R_.forEach(i),N_.forEach(i),Qc.forEach(i),Fc.forEach(i),this.h()},h(){u(Y,"name","hf:doc:metadata"),u(Y,"content",JSON.stringify(X_)),u(fe,"id","parallelizzazione-dei-modelli"),u(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(fe,"href","#parallelizzazione-dei-modelli"),u(W,"class","relative group"),u(ve,"id","panoramica-della-parallelizzazione"),u(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ve,"href","#panoramica-della-parallelizzazione"),u(J,"class","relative group"),u(he,"id","concetti"),u(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(he,"href","#concetti"),u(K,"class","relative group"),u(ze,"id","parallelizzazione-dei-dati"),u(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ze,"href","#parallelizzazione-dei-dati"),u(ee,"class","relative group"),u(be,"id","parallelizzazione-dei-dati-con-zero"),u(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(be,"href","#parallelizzazione-dei-dati-con-zero"),u(ie,"class","relative group"),u(ai,"href","https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/"),u(ai,"rel","nofollow"),X(wa.src,Dz="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-zero.png")||u(wa,"src",Dz),u(wa,"alt","DeepSpeed-Image-1"),u(ri,"href","https://www.deepspeed.ai/features/#the-zero-redundancy-optimizer"),u(ri,"rel","nofollow"),u(ni,"href","https://github.com/facebookresearch/fairscale/#optimizer-state-sharding-zero"),u(ni,"rel","nofollow"),u(si,"href","main_classes/trainer#trainer-integrations"),u(Ee,"id","parallelizzazione-ingenua-del-modello-verticale-e-parallelizzazione-di-pipeline"),u(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Ee,"href","#parallelizzazione-ingenua-del-modello-verticale-e-parallelizzazione-di-pipeline"),u(le,"class","relative group"),u(di,"href","https://ai.googleblog.com/2019/03/introducing-gpipe-open-source-library.html"),u(di,"rel","nofollow"),X(il.src,wz="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-gpipe-bubble.png")||u(il,"src",wz),u(il,"alt","mp-pp"),u(mi,"href","https://github.com/pytorch/pytorch/pull/50693"),u(mi,"rel","nofollow"),u(fi,"href","https://pytorch.org/docs/stable/pipeline.html"),u(fi,"rel","nofollow"),u(vi,"href","https://github.com/pytorch/pytorch/blob/master/benchmarks/distributed/pipeline/pipe.py"),u(vi,"rel","nofollow"),u(Pi,"href","https://fairscale.readthedocs.io/en/latest/tutorials/pipe.html"),u(Pi,"rel","nofollow"),u(hi,"href","https://www.deepspeed.ai/tutorials/pipeline/"),u(hi,"rel","nofollow"),u(zi,"href","https://github.com/NVIDIA/Megatron-LM"),u(zi,"rel","nofollow"),u(bi,"href","https://github.com/microsoft/varuna"),u(bi,"rel","nofollow"),u(_i,"href","https://arxiv.org/abs/2111.05972"),u(_i,"rel","nofollow"),u(Ei,"href","https://github.com/tunib-ai/oslo"),u(Ei,"rel","nofollow"),u(gi,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-core-features.html"),u(gi,"rel","nofollow"),X(Pl.src,Sz="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-sagemaker-interleaved-pipeline.png")||u(Pl,"src",Sz),u(Pl,"alt","interleaved-pipeline-execution"),u(ye,"id","parallelizzazione-dei-tensori"),u(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ye,"href","#parallelizzazione-dei-tensori"),u(te,"class","relative group"),u(Ui,"href","https://github.com/NVIDIA/Megatron-LM"),u(Ui,"rel","nofollow"),u(Gi,"href","https://arxiv.org/abs/2104.04473"),u(Gi,"rel","nofollow"),X(_l.src,Iz="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-tp-parallel_gemm.png")||u(_l,"src",Iz),u(_l,"alt","Parallel GEMM"),X(El.src,Az="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-tp-independent-gelu.png")||u(El,"src",Az),u(El,"alt","independent GeLU"),X(gl.src,qz="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-tp-parallel_shard_processing.png")||u(gl,"src",qz),u(gl,"alt","parallel shard processing"),X(Ll.src,yz="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-tp-parallel_self_attention.png")||u(Ll,"src",yz),u(Ll,"alt","parallel self-attention"),u(Ii,"href","https://github.com/huggingface/transformers/issues/10321#issuecomment-783543530"),u(Ii,"rel","nofollow"),u(Ai,"href","https://github.com/anton-l"),u(Ai,"rel","nofollow"),u(qi,"href","https://www.deepspeed.ai/features/#model-parallelism"),u(qi,"rel","nofollow"),u(yi,"href","https://github.com/NVIDIA/Megatron-LM"),u(yi,"rel","nofollow"),u(Oi,"href","https://github.com/tunib-ai/parallelformers"),u(Oi,"rel","nofollow"),u(Mi,"href","https://arxiv.org/abs/2111.05972"),u(Mi,"rel","nofollow"),u($i,"href","https://github.com/tunib-ai/oslo"),u($i,"rel","nofollow"),u(Ci,"href","https://github.com/tunib-ai/parallelformers"),u(Ci,"rel","nofollow"),u(ki,"href","https://www.deepspeed.ai/tutorials/inference-tutorial/"),u(ki,"rel","nofollow"),u(Oe,"id","dppp"),u(Oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Oe,"href","#dppp"),u(re,"class","relative group"),u(Ni,"href","https://www.deepspeed.ai/tutorials/pipeline/"),u(Ni,"rel","nofollow"),X(Cl.src,Oz="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-zero-dp-pp.png")||u(Cl,"src",Oz),u(Cl,"alt","dp-pp-2d"),u(Ri,"href","https://github.com/microsoft/DeepSpeed"),u(Ri,"rel","nofollow"),u(Zi,"href","https://github.com/NVIDIA/Megatron-LM"),u(Zi,"rel","nofollow"),u(Fi,"href","https://github.com/microsoft/varuna"),u(Fi,"rel","nofollow"),u(ji,"href","https://arxiv.org/abs/2111.05972"),u(ji,"rel","nofollow"),u(Bi,"href","https://github.com/tunib-ai/oslo"),u(Bi,"rel","nofollow"),u($e,"id","dppptp"),u($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u($e,"href","#dppptp"),u(ne,"class","relative group"),X(jl.src,Mz="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-deepspeed-3d.png")||u(jl,"src",Mz),u(jl,"alt","dp-pp-tp-3d"),u(Vi,"href","https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/"),u(Vi,"rel","nofollow"),u(Hi,"href","https://github.com/microsoft/DeepSpeed"),u(Hi,"rel","nofollow"),u(Xi,"href","https://github.com/NVIDIA/Megatron-LM"),u(Xi,"rel","nofollow"),u(Yi,"href","https://github.com/microsoft/varuna"),u(Yi,"rel","nofollow"),u(Wi,"href","https://arxiv.org/abs/2111.05972"),u(Wi,"rel","nofollow"),u(Ji,"href","https://github.com/tunib-ai/oslo"),u(Ji,"rel","nofollow"),u(Ce,"id","zero-dppptp"),u(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Ce,"href","#zero-dppptp"),u(se,"class","relative group"),u(Xl,"href","#zero-data-parallelism"),u(ea,"href","https://github.com/microsoft/Megatron-DeepSpeed"),u(ea,"rel","nofollow"),u(ia,"href","https://github.com/bigscience-workshop/Megatron-DeepSpeed"),u(ia,"rel","nofollow"),u(aa,"href","https://github.com/tunib-ai/oslo"),u(aa,"rel","nofollow"),u(la,"href","https://arxiv.org/abs/2201.11990"),u(la,"rel","nofollow"),u(Ze,"id","flexflow"),u(Ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Ze,"href","#flexflow"),u(pe,"class","relative group"),u(ra,"href","https://github.com/flexflow/FlexFlow"),u(ra,"rel","nofollow"),u(sa,"href","https://arxiv.org/abs/1807.05358"),u(sa,"rel","nofollow"),X(Po.src,$z="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/parallelism-flexflow.jpeg")||u(Po,"src",$z),u(Po,"alt","flex-flow-soap"),u(pa,"href","https://github.com/huggingface/transformers/blob/main/src/transformers/utils/fx.py"),u(pa,"rel","nofollow"),u(je,"id","quale-strategia-usare-e-quando"),u(je,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(je,"href","#quale-strategia-usare-e-quando"),u(ce,"class","relative group"),u(fa,"href","https://deepspeed.readthedocs.io/en/latest/zero3.html#memory-centric-tiling"),u(fa,"rel","nofollow")},m(e,s){a(document.head,Y),p(e,Pn,s),p(e,W,s),a(W,fe),a(fe,No),z(We,No,null),a(W,Hc),a(W,Ro),a(Ro,Xc),p(e,hn,s),p(e,J,s),a(J,ve),a(ve,Zo),z(Je,Zo,null),a(J,Yc),a(J,Fo),a(Fo,Wc),p(e,zn,s),p(e,La,s),a(La,Jc),p(e,bn,s),p(e,Pe,s),a(Pe,jo),a(jo,Kc),a(Pe,ed),a(Pe,Bo),a(Bo,id),p(e,_n,s),p(e,Ua,s),a(Ua,ad),p(e,En,s),p(e,Ga,s),a(Ga,ld),p(e,gn,s),p(e,K,s),a(K,he),a(he,Qo),z(Ke,Qo,null),a(K,od),a(K,Vo),a(Vo,td),p(e,Ln,s),p(e,Da,s),a(Da,rd),p(e,Un,s),p(e,g,s),a(g,Ho),a(Ho,nd),a(g,sd),a(g,Xo),a(Xo,pd),a(g,cd),a(g,Yo),a(Yo,dd),a(g,ud),a(g,Wo),a(Wo,md),a(g,fd),a(g,Jo),a(Jo,vd),p(e,Gn,s),p(e,ee,s),a(ee,ze),a(ze,Ko),z(ei,Ko,null),a(ee,Pd),a(ee,et),a(et,hd),p(e,Dn,s),p(e,O,s),a(O,zd),a(O,it),a(it,bd),a(O,_d),a(O,at),a(at,Ed),a(O,gd),p(e,wn,s),p(e,ie,s),a(ie,be),a(be,lt),z(ii,lt,null),a(ie,Ld),a(ie,ot),a(ot,Ud),p(e,Sn,s),p(e,ae,s),a(ae,Gd),a(ae,ai),a(ai,Dd),a(ae,wd),a(ae,wa),p(e,In,s),p(e,_e,s),a(_e,Sd),a(_e,tt),a(tt,Id),a(_e,Ad),p(e,An,s),p(e,Sa,s),a(Sa,qd),p(e,qn,s),z(li,e,s),p(e,yn,s),p(e,Ia,s),a(Ia,yd),p(e,On,s),p(e,Aa,s),a(Aa,Od),p(e,Mn,s),z(oi,e,s),p(e,$n,s),p(e,qa,s),a(qa,Md),p(e,Tn,s),p(e,ya,s),a(ya,$d),p(e,Cn,s),z(ti,e,s),p(e,kn,s),p(e,Oa,s),a(Oa,Td),p(e,xn,s),p(e,Ma,s),a(Ma,Cd),p(e,Nn,s),p(e,$a,s),a($a,kd),p(e,Rn,s),p(e,Ta,s),a(Ta,xd),p(e,Zn,s),p(e,Ca,s),a(Ca,Nd),p(e,Fn,s),p(e,ka,s),a(ka,Rd),p(e,jn,s),p(e,xa,s),a(xa,Zd),p(e,Bn,s),p(e,Na,s),a(Na,Fd),p(e,Qn,s),p(e,Ra,s),a(Ra,jd),p(e,Vn,s),p(e,M,s),a(M,rt),a(rt,Bd),a(M,Qd),a(M,nt),a(nt,Vd),a(M,Hd),a(M,st),a(st,Xd),p(e,Hn,s),p(e,Za,s),a(Za,Yd),p(e,Xn,s),p(e,Fa,s),a(Fa,Wd),p(e,Yn,s),p(e,ja,s),a(ja,Jd),p(e,Wn,s),p(e,Ba,s),a(Ba,Kd),p(e,Jn,s),p(e,Qa,s),a(Qa,eu),p(e,Kn,s),p(e,$,s),a($,Va),a(Va,ri),a(ri,iu),a(Va,au),a($,lu),a($,Ha),a(Ha,ni),a(ni,ou),a(Ha,tu),a($,ru),a($,pt),a(pt,si),a(si,nu),a(si,ct),a(ct,su),p(e,es,s),p(e,le,s),a(le,Ee),a(Ee,dt),z(pi,dt,null),a(le,pu),a(le,ut),a(ut,cu),p(e,is,s),p(e,ge,s),a(ge,du),a(ge,mt),a(mt,uu),a(ge,mu),p(e,as,s),p(e,Xa,s),a(Xa,fu),p(e,ls,s),z(ci,e,s),p(e,os,s),p(e,Ya,s),a(Ya,vu),p(e,ts,s),p(e,Le,s),a(Le,Pu),a(Le,hu),a(Le,zu),p(e,rs,s),p(e,Wa,s),a(Wa,bu),p(e,ns,s),p(e,Ja,s),a(Ja,_u),p(e,ss,s),p(e,Ue,s),a(Ue,ft),a(ft,Eu),a(Ue,gu),a(Ue,vt),a(vt,Lu),p(e,ps,s),p(e,Ka,s),a(Ka,Uu),p(e,cs,s),p(e,Ge,s),a(Ge,Gu),a(Ge,di),a(di,Du),a(Ge,wu),p(e,ds,s),p(e,el,s),a(el,il),p(e,us,s),p(e,al,s),a(al,Su),p(e,ms,s),p(e,ll,s),a(ll,Iu),p(e,fs,s),p(e,T,s),a(T,Au),a(T,Pt),a(Pt,qu),a(T,yu),a(T,ht),a(ht,Ou),a(T,Mu),p(e,vs,s),p(e,De,s),a(De,$u),a(De,zt),a(zt,Tu),a(De,Cu),p(e,Ps,s),p(e,we,s),a(we,ku),a(we,bt),a(bt,xu),a(we,Nu),p(e,hs,s),p(e,C,s),a(C,Ru),a(C,_t),a(_t,Zu),a(C,Fu),a(C,Et),a(Et,ju),a(C,Bu),p(e,zs,s),p(e,ol,s),a(ol,Qu),p(e,bs,s),p(e,k,s),a(k,Vu),a(k,gt),a(gt,Hu),a(k,Xu),a(k,Lt),a(Lt,Yu),a(k,Wu),p(e,_s,s),p(e,w,s),a(w,Ju),a(w,Ut),a(Ut,Ku),a(w,em),a(w,Gt),a(Gt,im),a(w,am),a(w,Dt),a(Dt,lm),a(w,om),p(e,Es,s),p(e,tl,s),a(tl,tm),p(e,gs,s),p(e,rl,s),a(rl,rm),p(e,Ls,s),p(e,S,s),a(S,wt),a(wt,nm),a(S,sm),a(S,St),a(St,pm),a(S,cm),a(S,It),a(It,dm),a(S,um),a(S,At),a(At,mm),p(e,Us,s),p(e,nl,s),a(nl,fm),p(e,Gs,s),p(e,Se,s),a(Se,qt),a(qt,vm),a(Se,Pm),a(Se,yt),a(yt,hm),p(e,Ds,s),p(e,sl,s),a(sl,zm),p(e,ws,s),p(e,I,s),a(I,ui),a(ui,bm),a(ui,Ot),a(Ot,_m),a(ui,Em),a(I,gm),a(I,pl),a(pl,Lm),a(pl,mi),a(mi,Um),a(I,Gm),a(I,Mt),a(Mt,Dm),a(I,wm),a(I,$t),a($t,Sm),p(e,Ss,s),p(e,cl,s),a(cl,Im),p(e,Is,s),p(e,dl,s),a(dl,Am),p(e,As,s),p(e,f,s),a(f,Ie),a(Ie,fi),a(fi,qm),a(Ie,ym),a(Ie,vi),a(vi,Om),a(Ie,Mm),a(f,$m),a(f,Tt),a(Tt,Pi),a(Pi,Tm),a(f,Cm),a(f,Ct),a(Ct,hi),a(hi,km),a(f,xm),a(f,ul),a(ul,zi),a(zi,Nm),a(ul,Rm),a(f,Zm),a(f,kt),a(kt,bi),a(bi,Fm),a(f,jm),a(f,ml),a(ml,_i),a(_i,Bm),a(ml,Qm),a(f,Vm),a(f,fl),a(fl,Ei),a(Ei,Hm),a(fl,Xm),p(e,qs,s),p(e,Ae,s),a(Ae,Ym),a(Ae,xt),a(xt,Wm),a(Ae,Jm),p(e,ys,s),p(e,vl,s),a(vl,Km),p(e,Os,s),p(e,oe,s),a(oe,ef),a(oe,gi),a(gi,af),a(oe,lf),a(oe,Pl),p(e,Ms,s),p(e,hl,s),a(hl,of),p(e,$s,s),p(e,zl,s),a(zl,tf),p(e,Ts,s),p(e,qe,s),a(qe,rf),a(qe,Nt),a(Nt,nf),a(qe,sf),p(e,Cs,s),p(e,te,s),a(te,ye),a(ye,Rt),z(Li,Rt,null),a(te,pf),a(te,Zt),a(Zt,cf),p(e,ks,s),p(e,bl,s),a(bl,df),p(e,xs,s),p(e,x,s),a(x,uf),a(x,Ui),a(Ui,mf),a(x,ff),a(x,Gi),a(Gi,vf),a(x,Pf),p(e,Ns,s),p(e,N,s),a(N,hf),a(N,Ft),a(Ft,zf),a(N,bf),a(N,jt),a(jt,_f),a(N,Ef),p(e,Rs,s),p(e,L,s),a(L,gf),a(L,Bt),a(Bt,Lf),a(L,Uf),a(L,Qt),a(Qt,Gf),a(L,Df),a(L,Vt),a(Vt,wf),a(L,Sf),a(L,Ht),a(Ht,If),a(L,Af),p(e,Zs,s),p(e,Di,s),a(Di,qf),a(Di,_l),p(e,Fs,s),p(e,m,s),a(m,yf),a(m,Xt),a(Xt,Of),a(m,Mf),a(m,Yt),a(Yt,$f),a(m,Tf),a(m,Wt),a(Wt,Cf),a(m,kf),a(m,Jt),a(Jt,xf),a(m,Nf),a(m,Kt),a(Kt,Rf),a(m,Zf),a(m,er),a(er,Ff),a(m,jf),a(m,ir),a(ir,Bf),a(m,Qf),a(m,El),p(e,js,s),p(e,wi,s),a(wi,Vf),a(wi,gl),p(e,Bs,s),p(e,Si,s),a(Si,Hf),a(Si,Ll),p(e,Qs,s),p(e,Ul,s),a(Ul,Xf),p(e,Vs,s),p(e,R,s),a(R,Yf),a(R,Ii),a(Ii,Wf),a(R,Jf),a(R,Ai),a(Ai,Kf),a(R,ev),p(e,Hs,s),p(e,Gl,s),a(Gl,iv),p(e,Xs,s),p(e,Dl,s),a(Dl,av),p(e,Ys,s),p(e,wl,s),a(wl,Sl),a(Sl,lv),a(Sl,qi),a(qi,ov),p(e,Ws,s),p(e,Il,s),a(Il,tv),p(e,Js,s),p(e,A,s),a(A,Al),a(Al,yi),a(yi,rv),a(Al,nv),a(A,sv),a(A,ql),a(ql,Oi),a(Oi,pv),a(ql,cv),a(A,dv),a(A,yl),a(yl,Mi),a(Mi,uv),a(yl,mv),a(A,fv),a(A,Ol),a(Ol,$i),a($i,vv),a(Ol,Pv),p(e,Ks,s),p(e,Ml,s),a(Ml,hv),p(e,ep,s),p(e,Z,s),a(Z,ar),a(ar,zv),a(Z,bv),a(Z,Ti),a(Ti,_v),a(Ti,Ci),a(Ci,Ev),a(Ti,gv),a(Z,Lv),a(Z,$l),a($l,Uv),a($l,ki),a(ki,Gv),p(e,ip,s),p(e,re,s),a(re,Oe),a(Oe,lr),z(xi,lr,null),a(re,Dv),a(re,or),a(or,wv),p(e,ap,s),p(e,Me,s),a(Me,Sv),a(Me,Ni),a(Ni,Iv),a(Me,Av),p(e,lp,s),p(e,Tl,s),a(Tl,Cl),p(e,op,s),p(e,kl,s),a(kl,qv),p(e,tp,s),p(e,xl,s),a(xl,yv),p(e,rp,s),p(e,Nl,s),a(Nl,Ov),p(e,np,s),p(e,U,s),a(U,tr),a(tr,Ri),a(Ri,Mv),a(U,$v),a(U,rr),a(rr,Zi),a(Zi,Tv),a(U,Cv),a(U,nr),a(nr,Fi),a(Fi,kv),a(U,xv),a(U,sr),a(sr,ji),a(ji,Nv),a(U,Rv),a(U,pr),a(pr,Bi),a(Bi,Zv),p(e,sp,s),p(e,Rl,s),a(Rl,Fv),p(e,pp,s),p(e,ne,s),a(ne,$e),a($e,cr),z(Qi,cr,null),a(ne,jv),a(ne,dr),a(dr,Bv),p(e,cp,s),p(e,Zl,s),a(Zl,Qv),p(e,dp,s),p(e,Fl,s),a(Fl,jl),p(e,up,s),p(e,Te,s),a(Te,Vv),a(Te,Vi),a(Vi,Hv),a(Te,Xv),p(e,mp,s),p(e,Bl,s),a(Bl,Yv),p(e,fp,s),p(e,Ql,s),a(Ql,Wv),p(e,vp,s),p(e,G,s),a(G,Vl),a(Vl,Hi),a(Hi,Jv),a(Vl,Kv),a(G,eP),a(G,ur),a(ur,Xi),a(Xi,iP),a(G,aP),a(G,mr),a(mr,Yi),a(Yi,lP),a(G,oP),a(G,fr),a(fr,Wi),a(Wi,tP),a(G,rP),a(G,vr),a(vr,Ji),a(Ji,nP),p(e,Pp,s),p(e,Hl,s),a(Hl,sP),p(e,hp,s),p(e,se,s),a(se,Ce),a(Ce,Pr),z(Ki,Pr,null),a(se,pP),a(se,hr),a(hr,cP),p(e,zp,s),p(e,ke,s),a(ke,dP),a(ke,Xl),a(Xl,uP),a(ke,mP),p(e,bp,s),p(e,Yl,s),a(Yl,fP),p(e,_p,s),p(e,Wl,s),a(Wl,vP),p(e,Ep,s),p(e,xe,s),a(xe,PP),a(xe,zr),a(zr,hP),a(xe,zP),p(e,gp,s),p(e,Jl,s),a(Jl,bP),p(e,Lp,s),p(e,Kl,s),a(Kl,_P),p(e,Up,s),p(e,eo,s),a(eo,EP),p(e,Gp,s),p(e,Ne,s),a(Ne,Re),a(Re,ea),a(ea,gP),a(Re,LP),a(Re,ia),a(ia,UP),a(Re,GP),a(Ne,DP),a(Ne,br),a(br,aa),a(aa,wP),p(e,Dp,s),p(e,io,s),a(io,SP),p(e,wp,s),p(e,ao,s),a(ao,_r),a(_r,la),a(la,IP),p(e,Sp,s),p(e,lo,s),a(lo,AP),p(e,Ip,s),p(e,pe,s),a(pe,Ze),a(Ze,Er),z(oa,Er,null),a(pe,qP),a(pe,gr),a(gr,yP),p(e,Ap,s),p(e,ta,s),a(ta,ra),a(ra,OP),a(ta,MP),p(e,qp,s),p(e,na,s),a(na,$P),a(na,sa),a(sa,TP),p(e,yp,s),p(e,oo,s),a(oo,CP),p(e,Op,s),p(e,q,s),a(q,Lr),a(Lr,kP),a(q,xP),a(q,Ur),a(Ur,NP),a(q,RP),a(q,Gr),a(Gr,ZP),a(q,FP),a(q,Dr),a(Dr,jP),p(e,Mp,s),p(e,to,s),a(to,BP),p(e,$p,s),p(e,ro,s),a(ro,wr),a(wr,QP),p(e,Tp,s),p(e,no,s),a(no,VP),p(e,Cp,s),p(e,so,s),a(so,Sr),a(Sr,HP),p(e,kp,s),p(e,po,s),a(po,XP),p(e,xp,s),p(e,co,s),a(co,Ir),a(Ir,YP),p(e,Np,s),p(e,uo,s),a(uo,WP),p(e,Rp,s),p(e,mo,s),a(mo,Ar),a(Ar,JP),p(e,Zp,s),p(e,fo,s),a(fo,KP),p(e,Fp,s),p(e,vo,s),a(vo,Po),p(e,jp,s),p(e,ho,s),a(ho,eh),p(e,Bp,s),p(e,zo,s),a(zo,ih),p(e,Qp,s),p(e,bo,s),a(bo,ah),p(e,Vp,s),p(e,Fe,s),a(Fe,lh),a(Fe,pa),a(pa,oh),a(Fe,th),p(e,Hp,s),p(e,ce,s),a(ce,je),a(je,qr),z(ca,qr,null),a(ce,rh),a(ce,yr),a(yr,nh),p(e,Xp,s),p(e,_o,s),a(_o,sh),p(e,Yp,s),p(e,Eo,s),a(Eo,Or),a(Or,ph),p(e,Wp,s),p(e,F,s),a(F,da),a(da,Mr),a(Mr,ch),a(da,dh),a(da,$r),a($r,Tr),a(Tr,uh),a(F,mh),a(F,ua),a(ua,Cr),a(Cr,fh),a(ua,vh),a(ua,ma),a(ma,kr),a(kr,Ph),a(ma,hh),a(ma,xr),a(xr,zh),a(F,bh),a(F,Nr),a(Nr,Rr),a(Rr,_h),p(e,Jp,s),p(e,go,s),a(go,de),a(de,Eh),a(de,fa),a(fa,gh),a(de,Lh),a(de,Zr),a(Zr,Uh),a(de,Gh),p(e,Kp,s),p(e,Lo,s),a(Lo,Fr),a(Fr,Dh),p(e,ec,s),p(e,j,s),a(j,va),a(va,jr),a(jr,wh),a(va,Sh),a(va,Pa),a(Pa,Br),a(Br,Ih),a(Pa,Ah),a(Pa,Qr),a(Qr,qh),a(j,yh),a(j,ha),a(ha,Vr),a(Vr,Oh),a(ha,Mh),a(ha,ue),a(ue,Hr),a(Hr,Xr),a(Xr,$h),a(ue,Th),a(ue,Yr),a(Yr,Wr),a(Wr,Ch),a(ue,kh),a(ue,me),a(me,Jr),a(Jr,xh),a(me,Nh),a(me,Kr),a(Kr,Rh),a(me,Zh),a(me,en),a(en,Fh),a(j,jh),a(j,za),a(za,an),a(an,Bh),a(za,Qh),a(za,ba),a(ba,ln),a(ln,Vh),a(ba,Hh),a(ba,on),a(on,Xh),p(e,ic,s),p(e,Uo,s),a(Uo,tn),a(tn,Yh),p(e,ac,s),p(e,Be,s),a(Be,_a),a(_a,rn),a(rn,Wh),a(_a,Jh),a(_a,Ea),a(Ea,nn),a(nn,Kh),a(Ea,ez),a(Ea,sn),a(sn,iz),a(Be,az),a(Be,ga),a(ga,pn),a(pn,lz),a(ga,oz),a(ga,cn),a(cn,dn),a(dn,tz),lc=!0},p:Q_,i(e){lc||(b(We.$$.fragment,e),b(Je.$$.fragment,e),b(Ke.$$.fragment,e),b(ei.$$.fragment,e),b(ii.$$.fragment,e),b(li.$$.fragment,e),b(oi.$$.fragment,e),b(ti.$$.fragment,e),b(pi.$$.fragment,e),b(ci.$$.fragment,e),b(Li.$$.fragment,e),b(xi.$$.fragment,e),b(Qi.$$.fragment,e),b(Ki.$$.fragment,e),b(oa.$$.fragment,e),b(ca.$$.fragment,e),lc=!0)},o(e){_(We.$$.fragment,e),_(Je.$$.fragment,e),_(Ke.$$.fragment,e),_(ei.$$.fragment,e),_(ii.$$.fragment,e),_(li.$$.fragment,e),_(oi.$$.fragment,e),_(ti.$$.fragment,e),_(pi.$$.fragment,e),_(ci.$$.fragment,e),_(Li.$$.fragment,e),_(xi.$$.fragment,e),_(Qi.$$.fragment,e),_(Ki.$$.fragment,e),_(oa.$$.fragment,e),_(ca.$$.fragment,e),lc=!1},d(e){i(Y),e&&i(Pn),e&&i(W),E(We),e&&i(hn),e&&i(J),E(Je),e&&i(zn),e&&i(La),e&&i(bn),e&&i(Pe),e&&i(_n),e&&i(Ua),e&&i(En),e&&i(Ga),e&&i(gn),e&&i(K),E(Ke),e&&i(Ln),e&&i(Da),e&&i(Un),e&&i(g),e&&i(Gn),e&&i(ee),E(ei),e&&i(Dn),e&&i(O),e&&i(wn),e&&i(ie),E(ii),e&&i(Sn),e&&i(ae),e&&i(In),e&&i(_e),e&&i(An),e&&i(Sa),e&&i(qn),E(li,e),e&&i(yn),e&&i(Ia),e&&i(On),e&&i(Aa),e&&i(Mn),E(oi,e),e&&i($n),e&&i(qa),e&&i(Tn),e&&i(ya),e&&i(Cn),E(ti,e),e&&i(kn),e&&i(Oa),e&&i(xn),e&&i(Ma),e&&i(Nn),e&&i($a),e&&i(Rn),e&&i(Ta),e&&i(Zn),e&&i(Ca),e&&i(Fn),e&&i(ka),e&&i(jn),e&&i(xa),e&&i(Bn),e&&i(Na),e&&i(Qn),e&&i(Ra),e&&i(Vn),e&&i(M),e&&i(Hn),e&&i(Za),e&&i(Xn),e&&i(Fa),e&&i(Yn),e&&i(ja),e&&i(Wn),e&&i(Ba),e&&i(Jn),e&&i(Qa),e&&i(Kn),e&&i($),e&&i(es),e&&i(le),E(pi),e&&i(is),e&&i(ge),e&&i(as),e&&i(Xa),e&&i(ls),E(ci,e),e&&i(os),e&&i(Ya),e&&i(ts),e&&i(Le),e&&i(rs),e&&i(Wa),e&&i(ns),e&&i(Ja),e&&i(ss),e&&i(Ue),e&&i(ps),e&&i(Ka),e&&i(cs),e&&i(Ge),e&&i(ds),e&&i(el),e&&i(us),e&&i(al),e&&i(ms),e&&i(ll),e&&i(fs),e&&i(T),e&&i(vs),e&&i(De),e&&i(Ps),e&&i(we),e&&i(hs),e&&i(C),e&&i(zs),e&&i(ol),e&&i(bs),e&&i(k),e&&i(_s),e&&i(w),e&&i(Es),e&&i(tl),e&&i(gs),e&&i(rl),e&&i(Ls),e&&i(S),e&&i(Us),e&&i(nl),e&&i(Gs),e&&i(Se),e&&i(Ds),e&&i(sl),e&&i(ws),e&&i(I),e&&i(Ss),e&&i(cl),e&&i(Is),e&&i(dl),e&&i(As),e&&i(f),e&&i(qs),e&&i(Ae),e&&i(ys),e&&i(vl),e&&i(Os),e&&i(oe),e&&i(Ms),e&&i(hl),e&&i($s),e&&i(zl),e&&i(Ts),e&&i(qe),e&&i(Cs),e&&i(te),E(Li),e&&i(ks),e&&i(bl),e&&i(xs),e&&i(x),e&&i(Ns),e&&i(N),e&&i(Rs),e&&i(L),e&&i(Zs),e&&i(Di),e&&i(Fs),e&&i(m),e&&i(js),e&&i(wi),e&&i(Bs),e&&i(Si),e&&i(Qs),e&&i(Ul),e&&i(Vs),e&&i(R),e&&i(Hs),e&&i(Gl),e&&i(Xs),e&&i(Dl),e&&i(Ys),e&&i(wl),e&&i(Ws),e&&i(Il),e&&i(Js),e&&i(A),e&&i(Ks),e&&i(Ml),e&&i(ep),e&&i(Z),e&&i(ip),e&&i(re),E(xi),e&&i(ap),e&&i(Me),e&&i(lp),e&&i(Tl),e&&i(op),e&&i(kl),e&&i(tp),e&&i(xl),e&&i(rp),e&&i(Nl),e&&i(np),e&&i(U),e&&i(sp),e&&i(Rl),e&&i(pp),e&&i(ne),E(Qi),e&&i(cp),e&&i(Zl),e&&i(dp),e&&i(Fl),e&&i(up),e&&i(Te),e&&i(mp),e&&i(Bl),e&&i(fp),e&&i(Ql),e&&i(vp),e&&i(G),e&&i(Pp),e&&i(Hl),e&&i(hp),e&&i(se),E(Ki),e&&i(zp),e&&i(ke),e&&i(bp),e&&i(Yl),e&&i(_p),e&&i(Wl),e&&i(Ep),e&&i(xe),e&&i(gp),e&&i(Jl),e&&i(Lp),e&&i(Kl),e&&i(Up),e&&i(eo),e&&i(Gp),e&&i(Ne),e&&i(Dp),e&&i(io),e&&i(wp),e&&i(ao),e&&i(Sp),e&&i(lo),e&&i(Ip),e&&i(pe),E(oa),e&&i(Ap),e&&i(ta),e&&i(qp),e&&i(na),e&&i(yp),e&&i(oo),e&&i(Op),e&&i(q),e&&i(Mp),e&&i(to),e&&i($p),e&&i(ro),e&&i(Tp),e&&i(no),e&&i(Cp),e&&i(so),e&&i(kp),e&&i(po),e&&i(xp),e&&i(co),e&&i(Np),e&&i(uo),e&&i(Rp),e&&i(mo),e&&i(Zp),e&&i(fo),e&&i(Fp),e&&i(vo),e&&i(jp),e&&i(ho),e&&i(Bp),e&&i(zo),e&&i(Qp),e&&i(bo),e&&i(Vp),e&&i(Fe),e&&i(Hp),e&&i(ce),E(ca),e&&i(Xp),e&&i(_o),e&&i(Yp),e&&i(Eo),e&&i(Wp),e&&i(F),e&&i(Jp),e&&i(go),e&&i(Kp),e&&i(Lo),e&&i(ec),e&&i(j),e&&i(ic),e&&i(Uo),e&&i(ac),e&&i(Be)}}}const X_={local:"parallelizzazione-dei-modelli",sections:[{local:"panoramica-della-parallelizzazione",title:"Panoramica della parallelizzazione"},{local:"concetti",title:"Concetti"},{local:"parallelizzazione-dei-dati",title:"Parallelizzazione dei Dati "},{local:"parallelizzazione-dei-dati-con-zero",title:"Parallelizzazione dei Dati con ZeRO "},{local:"parallelizzazione-ingenua-del-modello-verticale-e-parallelizzazione-di-pipeline",title:"Parallelizzazione Ingenua del Modello (Verticale) e Parallelizzazione di Pipeline"},{local:"parallelizzazione-dei-tensori",title:"Parallelizzazione dei Tensori"},{local:"dppp",title:"DP+PP"},{local:"dppptp",title:"DP+PP+TP"},{local:"zero-dppptp",title:"ZeRO DP+PP+TP"},{local:"flexflow",title:"FlexFlow"},{local:"quale-strategia-usare-e-quando",title:"Quale Strategia Usare e Quando"}],title:"Parallelizzazione dei modelli"};function Y_(Gz){return V_(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class eE extends Z_{constructor(Y){super();F_(this,Y,Y_,H_,j_,{})}}export{eE as default,X_ as metadata};
