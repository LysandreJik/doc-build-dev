import{S as kr,i as xr,s as Mr,e as s,k as f,w as k,t as o,M as qr,c as i,d as a,m,a as n,x,h as r,b as u,G as t,g as p,y as M,q,o as z,B as C,v as zr}from"../chunks/vendor-hf-doc-builder.js";import{T as oa}from"../chunks/Tip-hf-doc-builder.js";import{I as Ae}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ar}from"../chunks/CodeBlock-hf-doc-builder.js";function Cr(j){let h,v,c,d,E;return{c(){h=s("p"),v=o(`In lazy mode, the first couple of training iterations may be slower due to graph compilations.
In order to not take them into account in the computation of the throughput at the end of the training, you can add the following training argument: `),c=s("code"),d=o("throughput_warmup_steps=2"),E=o(".")},l(_){h=i(_,"P",{});var $=n(h);v=r($,`In lazy mode, the first couple of training iterations may be slower due to graph compilations.
In order to not take them into account in the computation of the throughput at the end of the training, you can add the following training argument: `),c=i($,"CODE",{});var P=n(c);d=r(P,"throughput_warmup_steps=2"),P.forEach(a),E=r($,"."),$.forEach(a)},m(_,$){p(_,h,$),t(h,v),t(h,c),t(c,d),t(h,E)},d(_){_&&a(h)}}}function Or(j){let h,v,c,d,E,_,$,P;return{c(){h=s("p"),v=o("Please refer to the "),c=s("a"),d=o("list of supported PyTorch operators"),E=o(" beforehand to make sure the ones you are interested in are compatible with "),_=s("em"),$=o("bf16"),P=o("."),this.h()},l(T){h=i(T,"P",{});var w=n(h);v=r(w,"Please refer to the "),c=i(w,"A",{href:!0,rel:!0});var A=n(c);d=r(A,"list of supported PyTorch operators"),A.forEach(a),E=r(w," beforehand to make sure the ones you are interested in are compatible with "),_=i(w,"EM",{});var O=n(_);$=r(O,"bf16"),O.forEach(a),P=r(w,"."),w.forEach(a),this.h()},h(){u(c,"href","https://docs.habana.ai/en/latest/PyTorch/Pytorch_Operators/Pytorch_Operators.html"),u(c,"rel","nofollow")},m(T,w){p(T,h,w),t(h,v),t(h,c),t(c,d),t(h,E),t(h,_),t(_,$),t(h,P)},d(T){T&&a(h)}}}function Hr(j){let h,v,c,d,E,_,$,P,T,w,A,O,G,fe;return{c(){h=s("p"),v=o("The default value of "),c=s("em"),d=o("epsilon"),E=o(" is "),_=s("code"),$=o("1e-6"),P=o(" for the Habana fused ADAM optimizer, while it is "),T=s("code"),w=o("1e-8"),A=o(" for "),O=s("code"),G=o("torch.optim.AdamW"),fe=o(".")},l(F){h=i(F,"P",{});var b=n(h);v=r(b,"The default value of "),c=i(b,"EM",{});var H=n(c);d=r(H,"epsilon"),H.forEach(a),E=r(b," is "),_=i(b,"CODE",{});var I=n(_);$=r(I,"1e-6"),I.forEach(a),P=r(b," for the Habana fused ADAM optimizer, while it is "),T=i(b,"CODE",{});var K=n(T);w=r(K,"1e-8"),K.forEach(a),A=r(b," for "),O=i(b,"CODE",{});var D=n(O);G=r(D,"torch.optim.AdamW"),D.forEach(a),fe=r(b,"."),b.forEach(a)},m(F,b){p(F,h,b),t(h,v),t(h,c),t(c,d),t(h,E),t(h,_),t(_,$),t(h,P),t(h,T),t(T,w),t(h,A),t(h,O),t(O,G),t(h,fe)},d(F){F&&a(h)}}}function Ir(j){let h,v;return{c(){h=s("p"),v=o("In distributed mode, memory stats are communicated only by the main process.")},l(c){h=i(c,"P",{});var d=n(h);v=r(d,"In distributed mode, memory stats are communicated only by the main process."),d.forEach(a)},m(c,d){p(c,h,d),t(h,v)},d(c){c&&a(h)}}}function jr(j){let h,v,c,d,E,_,$,P,T,w,A,O,G,fe,F,b,H,I,K,D,ra,Ge,sa,Et,ke,ia,wt,Q,xe,De,na,la,pa,Me,Ne,ha,ua,bt,qe,fa,Pt,ze,ma,Tt,me,At,V,kt,Y,X,Se,ce,ca,Le,da,xt,N,_a,Ue,ga,va,Fe,ya,$a,Mt,Z,qt,g,Ea,Ye,wa,ba,Be,Pa,Ta,Re,Aa,ka,We,xa,Ma,Je,qa,za,Ke,Ca,Oa,Qe,Ha,Ia,Ve,ja,Ga,de,Da,Na,zt,_e,Ct,B,ee,Xe,ge,Sa,Ze,La,Ot,te,Ua,ve,Fa,Ya,Ht,R,ae,et,ye,Ba,tt,Ra,It,S,Wa,$e,Ja,Ka,at,Qa,Va,jt,oe,Gt,W,re,ot,Ee,Xa,rt,Za,Dt,L,eo,we,to,ao,st,oo,ro,Nt,J,se,it,be,so,nt,io,St,ie,no,lt,lo,po,Lt,U,ne,pt,ho,uo,ht,fo,mo,co,le,ut,_o,go,ft,vo,yo,$o,pe,mt,Eo,wo,ct,bo,Po,Ut,Ce,To,Ft,he,Yt,ue,Ao,Pe,ko,xo,Bt;return _=new Ae({}),D=new Ae({}),me=new Ar({props:{code:`args = GaudiTrainingArguments(
    # same arguments as in Transformers,
    use_habana=True,
    use_lazy_mode=True,
    gaudi_config_name=path_to_my_gaudi_config
)`,highlighted:`args = GaudiTrainingArguments(
    <span class="hljs-comment"># same arguments as in Transformers,</span>
    use_habana=<span class="hljs-literal">True</span>,
    use_lazy_mode=<span class="hljs-literal">True</span>,
    gaudi_config_name=path_to_my_gaudi_config
)`}}),V=new oa({props:{$$slots:{default:[Cr]},$$scope:{ctx:j}}}),ce=new Ae({}),Z=new oa({props:{warning:!0,$$slots:{default:[Or]},$$scope:{ctx:j}}}),_e=new Ar({props:{code:`"hmp_bf16_ops": [
    "add",
    "addmm",
    "bmm",
    "div",
    "dropout",
    "gelu",
    "iadd",
    "linear",
    "layer_norm",
    "matmul",
    "mm",
    "rsub",
    "softmax",
    "truediv"
],
"hmp_fp32_ops": [
    "embedding",
    "nll_loss",
    "log_softmax"
]`,highlighted:`<span class="hljs-string">&quot;hmp_bf16_ops&quot;</span>: [
    <span class="hljs-string">&quot;add&quot;</span>,
    <span class="hljs-string">&quot;addmm&quot;</span>,
    <span class="hljs-string">&quot;bmm&quot;</span>,
    <span class="hljs-string">&quot;div&quot;</span>,
    <span class="hljs-string">&quot;dropout&quot;</span>,
    <span class="hljs-string">&quot;gelu&quot;</span>,
    <span class="hljs-string">&quot;iadd&quot;</span>,
    <span class="hljs-string">&quot;linear&quot;</span>,
    <span class="hljs-string">&quot;layer_norm&quot;</span>,
    <span class="hljs-string">&quot;matmul&quot;</span>,
    <span class="hljs-string">&quot;mm&quot;</span>,
    <span class="hljs-string">&quot;rsub&quot;</span>,
    <span class="hljs-string">&quot;softmax&quot;</span>,
    <span class="hljs-string">&quot;truediv&quot;</span>
],
<span class="hljs-string">&quot;hmp_fp32_ops&quot;</span>: [
    <span class="hljs-string">&quot;embedding&quot;</span>,
    <span class="hljs-string">&quot;nll_loss&quot;</span>,
    <span class="hljs-string">&quot;log_softmax&quot;</span>
]`}}),ge=new Ae({}),ye=new Ae({}),oe=new oa({props:{warning:!0,$$slots:{default:[Hr]},$$scope:{ctx:j}}}),Ee=new Ae({}),be=new Ae({}),he=new oa({props:{warning:!0,$$slots:{default:[Ir]},$$scope:{ctx:j}}}),{c(){h=s("meta"),v=f(),c=s("h1"),d=s("a"),E=s("span"),k(_.$$.fragment),$=f(),P=s("span"),T=o("Accelerating Training"),w=f(),A=s("p"),O=o(`Gaudi offers several possibilities to make training faster.
They are all compatible with each other and can be coupled with `),G=s("a"),fe=o("distributed training"),F=o("."),b=f(),H=s("h2"),I=s("a"),K=s("span"),k(D.$$.fragment),ra=f(),Ge=s("span"),sa=o("Lazy Mode"),Et=f(),ke=s("p"),ia=o("Two execution modes are proposed:"),wt=f(),Q=s("ul"),xe=s("li"),De=s("em"),na=o("Lazy mode"),la=o(", where the Habana bridge internally accumulates operations in a graph. The execution of the operations in the accumulated graph is triggered in a lazy manner. This allows the bridge to construct a graph with multiple operations, which provides the graph compiler the opportunity to optimize the device execution for these operations."),pa=f(),Me=s("li"),Ne=s("em"),ha=o("Eager mode"),ua=o(", where one operation at a time is executed."),bt=f(),qe=s("p"),fa=o("In lazy mode, the graph compiler generates optimized binary code that implements the given model topology on Gaudi. It performs operator fusion, data layout management, parallelization, pipelining and memory management, as well as graph-level optimizations."),Pt=f(),ze=s("p"),ma=o("To execute your training in lazy mode, you must provide the following training arguments:"),Tt=f(),k(me.$$.fragment),At=f(),k(V.$$.fragment),kt=f(),Y=s("h2"),X=s("a"),Se=s("span"),k(ce.$$.fragment),ca=f(),Le=s("span"),da=o("Mixed-Precision Training"),xt=f(),N=s("p"),_a=o(`Mixed-precision training enables to compute some operations using lighter data types to accelerate training.
Habana Mixed Preicision (HMP) proposes to mix `),Ue=s("em"),ga=o("fp32"),va=o(" and "),Fe=s("em"),ya=o("bf16"),$a=o(" operations."),Mt=f(),k(Z.$$.fragment),qt=f(),g=s("p"),Ea=o("In order to apply HMP, you must set "),Ye=s("code"),wa=o('"use_habana_mixed_precision"'),ba=o(" to "),Be=s("code"),Pa=o("true"),Ta=o(" and "),Re=s("code"),Aa=o('"hmp_opt_level"'),ka=o(" to "),We=s("code"),xa=o('"O1"'),Ma=o(` in the Gaudi configuration file.
Then, you can specify which operators to compute in `),Je=s("em"),qa=o("bf16"),za=o(" with "),Ke=s("code"),Ca=o('"hmp_bf16_ops"'),Oa=o(" and which operators to compute in "),Qe=s("em"),Ha=o("fp32"),Ia=o(" with "),Ve=s("code"),ja=o('"hmp_fp32_ops"'),Ga=o(`.
If these operators are not specified, their default values are set to be the ones written in the `),de=s("a"),Da=o("Gaudi configuration file of BERT"),Na=o(", which is a good starting point for applying HMP:"),zt=f(),k(_e.$$.fragment),Ct=f(),B=s("h2"),ee=s("a"),Xe=s("span"),k(ge.$$.fragment),Sa=f(),Ze=s("span"),La=o("Custom Operators"),Ot=f(),te=s("p"),Ua=o(`Habana probides a few custom operators that achieve better performance than their PyTorch counterparts on Gaudi.
You can also define your own custom operator for Gaudi as described `),ve=s("a"),Fa=o("here"),Ya=o("."),Ht=f(),R=s("h3"),ae=s("a"),et=s("span"),k(ye.$$.fragment),Ba=f(),tt=s("span"),Ra=o("Fused ADAM"),It=f(),S=s("p"),Wa=o("Habana provides a "),$e=s("a"),Ja=o("custom fused ADAM implementation"),Ka=o(`.
It can be used by specifying `),at=s("code"),Qa=o('"use_fused_adam": true'),Va=o(" in the Gaudi configuration file."),jt=f(),k(oe.$$.fragment),Gt=f(),W=s("h3"),re=s("a"),ot=s("span"),k(Ee.$$.fragment),Xa=f(),rt=s("span"),Za=o("Fused Gradient Norm Clipping"),Dt=f(),L=s("p"),eo=o("Habana provides a "),we=s("a"),to=o("custom gradient norm clipping implementation"),ao=o(`.
It can be used by specifying `),st=s("code"),oo=o('"use_fused_clip_norm": true'),ro=o(" in the Gaudi configuration file."),Nt=f(),J=s("h2"),se=s("a"),it=s("span"),k(be.$$.fragment),so=f(),nt=s("span"),io=o("Tracking Memory Usage"),St=f(),ie=s("p"),no=o("You can pass the argument "),lt=s("code"),lo=o("gaudi_memory_stats=True"),po=o(" to display live memory statistics in the trainer\u2019s progress bar:"),Lt=f(),U=s("ul"),ne=s("li"),pt=s("code"),ho=o("mem"),uo=o(" refers to the "),ht=s("em"),fo=o("current"),mo=o(" memory consumption,"),co=f(),le=s("li"),ut=s("code"),_o=o("max"),go=o(" refers to the "),ft=s("em"),vo=o("maximum"),yo=o(" memory consumption reached during the run,"),$o=f(),pe=s("li"),mt=s("code"),Eo=o("total"),wo=o(" refers to the "),ct=s("em"),bo=o("total"),Po=o(" memory on the device."),Ut=f(),Ce=s("p"),To=o("These metrics can help you to adjust the batch size of your runs."),Ft=f(),k(he.$$.fragment),Yt=f(),ue=s("p"),Ao=o("You can take a look at "),Pe=s("a"),ko=o("Habana Gaudi\u2019s official documentation"),xo=o(" for more information about the memory stats API."),this.h()},l(e){const l=qr('[data-svelte="svelte-1phssyn"]',document.head);h=i(l,"META",{name:!0,content:!0}),l.forEach(a),v=m(e),c=i(e,"H1",{class:!0});var Te=n(c);d=i(Te,"A",{id:!0,class:!0,href:!0});var dt=n(d);E=i(dt,"SPAN",{});var _t=n(E);x(_.$$.fragment,_t),_t.forEach(a),dt.forEach(a),$=m(Te),P=i(Te,"SPAN",{});var gt=n(P);T=r(gt,"Accelerating Training"),gt.forEach(a),Te.forEach(a),w=m(e),A=i(e,"P",{});var Rt=n(A);O=r(Rt,`Gaudi offers several possibilities to make training faster.
They are all compatible with each other and can be coupled with `),G=i(Rt,"A",{href:!0});var zo=n(G);fe=r(zo,"distributed training"),zo.forEach(a),F=r(Rt,"."),Rt.forEach(a),b=m(e),H=i(e,"H2",{class:!0});var Wt=n(H);I=i(Wt,"A",{id:!0,class:!0,href:!0});var Co=n(I);K=i(Co,"SPAN",{});var Oo=n(K);x(D.$$.fragment,Oo),Oo.forEach(a),Co.forEach(a),ra=m(Wt),Ge=i(Wt,"SPAN",{});var Ho=n(Ge);sa=r(Ho,"Lazy Mode"),Ho.forEach(a),Wt.forEach(a),Et=m(e),ke=i(e,"P",{});var Io=n(ke);ia=r(Io,"Two execution modes are proposed:"),Io.forEach(a),wt=m(e),Q=i(e,"UL",{});var Jt=n(Q);xe=i(Jt,"LI",{});var Mo=n(xe);De=i(Mo,"EM",{});var jo=n(De);na=r(jo,"Lazy mode"),jo.forEach(a),la=r(Mo,", where the Habana bridge internally accumulates operations in a graph. The execution of the operations in the accumulated graph is triggered in a lazy manner. This allows the bridge to construct a graph with multiple operations, which provides the graph compiler the opportunity to optimize the device execution for these operations."),Mo.forEach(a),pa=m(Jt),Me=i(Jt,"LI",{});var qo=n(Me);Ne=i(qo,"EM",{});var Go=n(Ne);ha=r(Go,"Eager mode"),Go.forEach(a),ua=r(qo,", where one operation at a time is executed."),qo.forEach(a),Jt.forEach(a),bt=m(e),qe=i(e,"P",{});var Do=n(qe);fa=r(Do,"In lazy mode, the graph compiler generates optimized binary code that implements the given model topology on Gaudi. It performs operator fusion, data layout management, parallelization, pipelining and memory management, as well as graph-level optimizations."),Do.forEach(a),Pt=m(e),ze=i(e,"P",{});var No=n(ze);ma=r(No,"To execute your training in lazy mode, you must provide the following training arguments:"),No.forEach(a),Tt=m(e),x(me.$$.fragment,e),At=m(e),x(V.$$.fragment,e),kt=m(e),Y=i(e,"H2",{class:!0});var Kt=n(Y);X=i(Kt,"A",{id:!0,class:!0,href:!0});var So=n(X);Se=i(So,"SPAN",{});var Lo=n(Se);x(ce.$$.fragment,Lo),Lo.forEach(a),So.forEach(a),ca=m(Kt),Le=i(Kt,"SPAN",{});var Uo=n(Le);da=r(Uo,"Mixed-Precision Training"),Uo.forEach(a),Kt.forEach(a),xt=m(e),N=i(e,"P",{});var Oe=n(N);_a=r(Oe,`Mixed-precision training enables to compute some operations using lighter data types to accelerate training.
Habana Mixed Preicision (HMP) proposes to mix `),Ue=i(Oe,"EM",{});var Fo=n(Ue);ga=r(Fo,"fp32"),Fo.forEach(a),va=r(Oe," and "),Fe=i(Oe,"EM",{});var Yo=n(Fe);ya=r(Yo,"bf16"),Yo.forEach(a),$a=r(Oe," operations."),Oe.forEach(a),Mt=m(e),x(Z.$$.fragment,e),qt=m(e),g=i(e,"P",{});var y=n(g);Ea=r(y,"In order to apply HMP, you must set "),Ye=i(y,"CODE",{});var Bo=n(Ye);wa=r(Bo,'"use_habana_mixed_precision"'),Bo.forEach(a),ba=r(y," to "),Be=i(y,"CODE",{});var Ro=n(Be);Pa=r(Ro,"true"),Ro.forEach(a),Ta=r(y," and "),Re=i(y,"CODE",{});var Wo=n(Re);Aa=r(Wo,'"hmp_opt_level"'),Wo.forEach(a),ka=r(y," to "),We=i(y,"CODE",{});var Jo=n(We);xa=r(Jo,'"O1"'),Jo.forEach(a),Ma=r(y,` in the Gaudi configuration file.
Then, you can specify which operators to compute in `),Je=i(y,"EM",{});var Ko=n(Je);qa=r(Ko,"bf16"),Ko.forEach(a),za=r(y," with "),Ke=i(y,"CODE",{});var Qo=n(Ke);Ca=r(Qo,'"hmp_bf16_ops"'),Qo.forEach(a),Oa=r(y," and which operators to compute in "),Qe=i(y,"EM",{});var Vo=n(Qe);Ha=r(Vo,"fp32"),Vo.forEach(a),Ia=r(y," with "),Ve=i(y,"CODE",{});var Xo=n(Ve);ja=r(Xo,'"hmp_fp32_ops"'),Xo.forEach(a),Ga=r(y,`.
If these operators are not specified, their default values are set to be the ones written in the `),de=i(y,"A",{href:!0,rel:!0});var Zo=n(de);Da=r(Zo,"Gaudi configuration file of BERT"),Zo.forEach(a),Na=r(y,", which is a good starting point for applying HMP:"),y.forEach(a),zt=m(e),x(_e.$$.fragment,e),Ct=m(e),B=i(e,"H2",{class:!0});var Qt=n(B);ee=i(Qt,"A",{id:!0,class:!0,href:!0});var er=n(ee);Xe=i(er,"SPAN",{});var tr=n(Xe);x(ge.$$.fragment,tr),tr.forEach(a),er.forEach(a),Sa=m(Qt),Ze=i(Qt,"SPAN",{});var ar=n(Ze);La=r(ar,"Custom Operators"),ar.forEach(a),Qt.forEach(a),Ot=m(e),te=i(e,"P",{});var Vt=n(te);Ua=r(Vt,`Habana probides a few custom operators that achieve better performance than their PyTorch counterparts on Gaudi.
You can also define your own custom operator for Gaudi as described `),ve=i(Vt,"A",{href:!0,rel:!0});var or=n(ve);Fa=r(or,"here"),or.forEach(a),Ya=r(Vt,"."),Vt.forEach(a),Ht=m(e),R=i(e,"H3",{class:!0});var Xt=n(R);ae=i(Xt,"A",{id:!0,class:!0,href:!0});var rr=n(ae);et=i(rr,"SPAN",{});var sr=n(et);x(ye.$$.fragment,sr),sr.forEach(a),rr.forEach(a),Ba=m(Xt),tt=i(Xt,"SPAN",{});var ir=n(tt);Ra=r(ir,"Fused ADAM"),ir.forEach(a),Xt.forEach(a),It=m(e),S=i(e,"P",{});var He=n(S);Wa=r(He,"Habana provides a "),$e=i(He,"A",{href:!0,rel:!0});var nr=n($e);Ja=r(nr,"custom fused ADAM implementation"),nr.forEach(a),Ka=r(He,`.
It can be used by specifying `),at=i(He,"CODE",{});var lr=n(at);Qa=r(lr,'"use_fused_adam": true'),lr.forEach(a),Va=r(He," in the Gaudi configuration file."),He.forEach(a),jt=m(e),x(oe.$$.fragment,e),Gt=m(e),W=i(e,"H3",{class:!0});var Zt=n(W);re=i(Zt,"A",{id:!0,class:!0,href:!0});var pr=n(re);ot=i(pr,"SPAN",{});var hr=n(ot);x(Ee.$$.fragment,hr),hr.forEach(a),pr.forEach(a),Xa=m(Zt),rt=i(Zt,"SPAN",{});var ur=n(rt);Za=r(ur,"Fused Gradient Norm Clipping"),ur.forEach(a),Zt.forEach(a),Dt=m(e),L=i(e,"P",{});var Ie=n(L);eo=r(Ie,"Habana provides a "),we=i(Ie,"A",{href:!0,rel:!0});var fr=n(we);to=r(fr,"custom gradient norm clipping implementation"),fr.forEach(a),ao=r(Ie,`.
It can be used by specifying `),st=i(Ie,"CODE",{});var mr=n(st);oo=r(mr,'"use_fused_clip_norm": true'),mr.forEach(a),ro=r(Ie," in the Gaudi configuration file."),Ie.forEach(a),Nt=m(e),J=i(e,"H2",{class:!0});var ea=n(J);se=i(ea,"A",{id:!0,class:!0,href:!0});var cr=n(se);it=i(cr,"SPAN",{});var dr=n(it);x(be.$$.fragment,dr),dr.forEach(a),cr.forEach(a),so=m(ea),nt=i(ea,"SPAN",{});var _r=n(nt);io=r(_r,"Tracking Memory Usage"),_r.forEach(a),ea.forEach(a),St=m(e),ie=i(e,"P",{});var ta=n(ie);no=r(ta,"You can pass the argument "),lt=i(ta,"CODE",{});var gr=n(lt);lo=r(gr,"gaudi_memory_stats=True"),gr.forEach(a),po=r(ta," to display live memory statistics in the trainer\u2019s progress bar:"),ta.forEach(a),Lt=m(e),U=i(e,"UL",{});var je=n(U);ne=i(je,"LI",{});var vt=n(ne);pt=i(vt,"CODE",{});var vr=n(pt);ho=r(vr,"mem"),vr.forEach(a),uo=r(vt," refers to the "),ht=i(vt,"EM",{});var yr=n(ht);fo=r(yr,"current"),yr.forEach(a),mo=r(vt," memory consumption,"),vt.forEach(a),co=m(je),le=i(je,"LI",{});var yt=n(le);ut=i(yt,"CODE",{});var $r=n(ut);_o=r($r,"max"),$r.forEach(a),go=r(yt," refers to the "),ft=i(yt,"EM",{});var Er=n(ft);vo=r(Er,"maximum"),Er.forEach(a),yo=r(yt," memory consumption reached during the run,"),yt.forEach(a),$o=m(je),pe=i(je,"LI",{});var $t=n(pe);mt=i($t,"CODE",{});var wr=n(mt);Eo=r(wr,"total"),wr.forEach(a),wo=r($t," refers to the "),ct=i($t,"EM",{});var br=n(ct);bo=r(br,"total"),br.forEach(a),Po=r($t," memory on the device."),$t.forEach(a),je.forEach(a),Ut=m(e),Ce=i(e,"P",{});var Pr=n(Ce);To=r(Pr,"These metrics can help you to adjust the batch size of your runs."),Pr.forEach(a),Ft=m(e),x(he.$$.fragment,e),Yt=m(e),ue=i(e,"P",{});var aa=n(ue);Ao=r(aa,"You can take a look at "),Pe=i(aa,"A",{href:!0,rel:!0});var Tr=n(Pe);ko=r(Tr,"Habana Gaudi\u2019s official documentation"),Tr.forEach(a),xo=r(aa," for more information about the memory stats API."),aa.forEach(a),this.h()},h(){u(h,"name","hf:doc:metadata"),u(h,"content",JSON.stringify(Gr)),u(d,"id","accelerating-training"),u(d,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(d,"href","#accelerating-training"),u(c,"class","relative group"),u(G,"href","distributed"),u(I,"id","lazy-mode"),u(I,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(I,"href","#lazy-mode"),u(H,"class","relative group"),u(X,"id","mixedprecision-training"),u(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(X,"href","#mixedprecision-training"),u(Y,"class","relative group"),u(de,"href","https://huggingface.co/Habana/bert-large-uncased-whole-word-masking/blob/main/gaudi_config.json"),u(de,"rel","nofollow"),u(ee,"id","custom-operators"),u(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ee,"href","#custom-operators"),u(B,"class","relative group"),u(ve,"href","https://docs.habana.ai/en/latest/PyTorch/PyTorch_CustomOp_API/page_index.html"),u(ve,"rel","nofollow"),u(ae,"id","fused-adam"),u(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(ae,"href","#fused-adam"),u(R,"class","relative group"),u($e,"href","https://docs.habana.ai/en/latest/PyTorch/Model_Optimization_PyTorch/Custom_Ops_PyTorch.html#custom-optimizers"),u($e,"rel","nofollow"),u(re,"id","fused-gradient-norm-clipping"),u(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(re,"href","#fused-gradient-norm-clipping"),u(W,"class","relative group"),u(we,"href","https://docs.habana.ai/en/latest/PyTorch/Model_Optimization_PyTorch/Custom_Ops_PyTorch.html#other-custom-ops"),u(we,"rel","nofollow"),u(se,"id","tracking-memory-usage"),u(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(se,"href","#tracking-memory-usage"),u(J,"class","relative group"),u(Pe,"href","https://docs.habana.ai/en/latest/PyTorch/PyTorch_User_Guide/Python_Packages.html#memory-stats-apis"),u(Pe,"rel","nofollow")},m(e,l){t(document.head,h),p(e,v,l),p(e,c,l),t(c,d),t(d,E),M(_,E,null),t(c,$),t(c,P),t(P,T),p(e,w,l),p(e,A,l),t(A,O),t(A,G),t(G,fe),t(A,F),p(e,b,l),p(e,H,l),t(H,I),t(I,K),M(D,K,null),t(H,ra),t(H,Ge),t(Ge,sa),p(e,Et,l),p(e,ke,l),t(ke,ia),p(e,wt,l),p(e,Q,l),t(Q,xe),t(xe,De),t(De,na),t(xe,la),t(Q,pa),t(Q,Me),t(Me,Ne),t(Ne,ha),t(Me,ua),p(e,bt,l),p(e,qe,l),t(qe,fa),p(e,Pt,l),p(e,ze,l),t(ze,ma),p(e,Tt,l),M(me,e,l),p(e,At,l),M(V,e,l),p(e,kt,l),p(e,Y,l),t(Y,X),t(X,Se),M(ce,Se,null),t(Y,ca),t(Y,Le),t(Le,da),p(e,xt,l),p(e,N,l),t(N,_a),t(N,Ue),t(Ue,ga),t(N,va),t(N,Fe),t(Fe,ya),t(N,$a),p(e,Mt,l),M(Z,e,l),p(e,qt,l),p(e,g,l),t(g,Ea),t(g,Ye),t(Ye,wa),t(g,ba),t(g,Be),t(Be,Pa),t(g,Ta),t(g,Re),t(Re,Aa),t(g,ka),t(g,We),t(We,xa),t(g,Ma),t(g,Je),t(Je,qa),t(g,za),t(g,Ke),t(Ke,Ca),t(g,Oa),t(g,Qe),t(Qe,Ha),t(g,Ia),t(g,Ve),t(Ve,ja),t(g,Ga),t(g,de),t(de,Da),t(g,Na),p(e,zt,l),M(_e,e,l),p(e,Ct,l),p(e,B,l),t(B,ee),t(ee,Xe),M(ge,Xe,null),t(B,Sa),t(B,Ze),t(Ze,La),p(e,Ot,l),p(e,te,l),t(te,Ua),t(te,ve),t(ve,Fa),t(te,Ya),p(e,Ht,l),p(e,R,l),t(R,ae),t(ae,et),M(ye,et,null),t(R,Ba),t(R,tt),t(tt,Ra),p(e,It,l),p(e,S,l),t(S,Wa),t(S,$e),t($e,Ja),t(S,Ka),t(S,at),t(at,Qa),t(S,Va),p(e,jt,l),M(oe,e,l),p(e,Gt,l),p(e,W,l),t(W,re),t(re,ot),M(Ee,ot,null),t(W,Xa),t(W,rt),t(rt,Za),p(e,Dt,l),p(e,L,l),t(L,eo),t(L,we),t(we,to),t(L,ao),t(L,st),t(st,oo),t(L,ro),p(e,Nt,l),p(e,J,l),t(J,se),t(se,it),M(be,it,null),t(J,so),t(J,nt),t(nt,io),p(e,St,l),p(e,ie,l),t(ie,no),t(ie,lt),t(lt,lo),t(ie,po),p(e,Lt,l),p(e,U,l),t(U,ne),t(ne,pt),t(pt,ho),t(ne,uo),t(ne,ht),t(ht,fo),t(ne,mo),t(U,co),t(U,le),t(le,ut),t(ut,_o),t(le,go),t(le,ft),t(ft,vo),t(le,yo),t(U,$o),t(U,pe),t(pe,mt),t(mt,Eo),t(pe,wo),t(pe,ct),t(ct,bo),t(pe,Po),p(e,Ut,l),p(e,Ce,l),t(Ce,To),p(e,Ft,l),M(he,e,l),p(e,Yt,l),p(e,ue,l),t(ue,Ao),t(ue,Pe),t(Pe,ko),t(ue,xo),Bt=!0},p(e,[l]){const Te={};l&2&&(Te.$$scope={dirty:l,ctx:e}),V.$set(Te);const dt={};l&2&&(dt.$$scope={dirty:l,ctx:e}),Z.$set(dt);const _t={};l&2&&(_t.$$scope={dirty:l,ctx:e}),oe.$set(_t);const gt={};l&2&&(gt.$$scope={dirty:l,ctx:e}),he.$set(gt)},i(e){Bt||(q(_.$$.fragment,e),q(D.$$.fragment,e),q(me.$$.fragment,e),q(V.$$.fragment,e),q(ce.$$.fragment,e),q(Z.$$.fragment,e),q(_e.$$.fragment,e),q(ge.$$.fragment,e),q(ye.$$.fragment,e),q(oe.$$.fragment,e),q(Ee.$$.fragment,e),q(be.$$.fragment,e),q(he.$$.fragment,e),Bt=!0)},o(e){z(_.$$.fragment,e),z(D.$$.fragment,e),z(me.$$.fragment,e),z(V.$$.fragment,e),z(ce.$$.fragment,e),z(Z.$$.fragment,e),z(_e.$$.fragment,e),z(ge.$$.fragment,e),z(ye.$$.fragment,e),z(oe.$$.fragment,e),z(Ee.$$.fragment,e),z(be.$$.fragment,e),z(he.$$.fragment,e),Bt=!1},d(e){a(h),e&&a(v),e&&a(c),C(_),e&&a(w),e&&a(A),e&&a(b),e&&a(H),C(D),e&&a(Et),e&&a(ke),e&&a(wt),e&&a(Q),e&&a(bt),e&&a(qe),e&&a(Pt),e&&a(ze),e&&a(Tt),C(me,e),e&&a(At),C(V,e),e&&a(kt),e&&a(Y),C(ce),e&&a(xt),e&&a(N),e&&a(Mt),C(Z,e),e&&a(qt),e&&a(g),e&&a(zt),C(_e,e),e&&a(Ct),e&&a(B),C(ge),e&&a(Ot),e&&a(te),e&&a(Ht),e&&a(R),C(ye),e&&a(It),e&&a(S),e&&a(jt),C(oe,e),e&&a(Gt),e&&a(W),C(Ee),e&&a(Dt),e&&a(L),e&&a(Nt),e&&a(J),C(be),e&&a(St),e&&a(ie),e&&a(Lt),e&&a(U),e&&a(Ut),e&&a(Ce),e&&a(Ft),C(he,e),e&&a(Yt),e&&a(ue)}}}const Gr={local:"accelerating-training",sections:[{local:"lazy-mode",title:"Lazy Mode"},{local:"mixedprecision-training",title:"Mixed-Precision Training"},{local:"custom-operators",sections:[{local:"fused-adam",title:"Fused ADAM"},{local:"fused-gradient-norm-clipping",title:"Fused Gradient Norm Clipping"}],title:"Custom Operators"},{local:"tracking-memory-usage",title:"Tracking Memory Usage"}],title:"Accelerating Training"};function Dr(j){return zr(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Fr extends kr{constructor(h){super();xr(this,h,Dr,jr,Mr,{})}}export{Fr as default,Gr as metadata};
