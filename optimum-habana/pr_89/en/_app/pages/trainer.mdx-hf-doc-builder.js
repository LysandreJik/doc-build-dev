import{S as bn,i as _n,s as vn,e as o,k as d,w as b,t as n,M as yn,c as i,d as a,m as p,a as s,x as _,h as r,b as l,G as e,g as u,y as v,q as y,o as T,B as $,v as Tn}from"../chunks/vendor-hf-doc-builder.js";import{T as fn}from"../chunks/Tip-hf-doc-builder.js";import{D as A}from"../chunks/Docstring-hf-doc-builder.js";import{C as $n}from"../chunks/CodeBlock-hf-doc-builder.js";import{I as Ma}from"../chunks/IconCopyLink-hf-doc-builder.js";function wn(Te){let c,w,g,x,P;return{c(){c=o("p"),w=n("The "),g=o("a"),x=n("GaudiTrainer"),P=n(" class is optimized for \u{1F917} Transformers models running on Habana Gaudi."),this.h()},l(k){c=i(k,"P",{});var D=s(c);w=r(D,"The "),g=i(D,"A",{href:!0});var z=s(g);x=r(z,"GaudiTrainer"),z.forEach(a),P=r(D," class is optimized for \u{1F917} Transformers models running on Habana Gaudi."),D.forEach(a),this.h()},h(){l(g,"href","/docs/optimum.habana/pr_89/en/trainer#optimum.habana.GaudiTrainer")},m(k,D){u(k,c,D),e(c,w),e(c,g),e(g,x),e(c,P)},d(k){k&&a(c)}}}function kn(Te){let c;return{c(){c=n(`If your predictions or labels have different sequence lengths (for instance because you're doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`)},l(w){c=r(w,`If your predictions or labels have different sequence lengths (for instance because you're doing dynamic
padding in a token classification task) the predictions will be padded (on the right) to allow for
concatenation into one array. The padding index is -100.`)},m(w,g){u(w,c,g)},d(w){w&&a(c)}}}function xn(Te){let c,w,g,x,P,k,D,z,Tt,Ke,G,$t,$e,wt,kt,Z,xt,Gt,ee,Et,qt,Qe,S,Dt,we,St,Nt,Ae,At,Pt,Xe,M,Ze,W,Ot,ke,Ct,Lt,et,te,tt,N,jt,xe,It,zt,ae,Mt,Wt,at,O,H,Pe,ne,Ht,Oe,Rt,nt,h,re,Vt,Ce,Ut,Bt,R,oe,Ft,ie,Yt,Le,Jt,Kt,Qt,V,se,Xt,C,Zt,je,ea,ta,Ie,aa,na,ra,U,le,oa,L,ia,ze,sa,la,Me,da,pa,ma,B,de,ca,j,ua,We,ha,ga,He,fa,ba,_a,F,pe,va,me,ya,Re,Ta,$a,wa,Y,ce,ka,Ve,xa,rt,I,J,Ue,ue,Ga,Be,Ea,ot,E,he,qa,K,ge,Da,fe,Sa,Fe,Na,Aa,Pa,q,be,Oa,_e,Ca,Ye,La,ja,Ia,Q,za,it;return k=new Ma({}),M=new fn({props:{warning:!0,$$slots:{default:[wn]},$$scope:{ctx:Te}}}),te=new $n({props:{code:`from torch import nn
from optimum.habana import GaudiTrainer


class CustomGaudiTrainer(GaudiTrainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.get("labels")
        # forward pass
        outputs = model(**inputs)
        logits = outputs.get("logits")
        # compute custom loss (suppose one has 3 labels with different weights)
        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 2.0, 3.0]))
        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))
        return (loss, outputs) if return_outputs else loss`,highlighted:`<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">from</span> optimum.habana <span class="hljs-keyword">import</span> GaudiTrainer


<span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomGaudiTrainer</span>(<span class="hljs-title class_ inherited__">GaudiTrainer</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_loss</span>(<span class="hljs-params">self, model, inputs, return_outputs=<span class="hljs-literal">False</span></span>):
        labels = inputs.get(<span class="hljs-string">&quot;labels&quot;</span>)
        <span class="hljs-comment"># forward pass</span>
        outputs = model(**inputs)
        logits = outputs.get(<span class="hljs-string">&quot;logits&quot;</span>)
        <span class="hljs-comment"># compute custom loss (suppose one has 3 labels with different weights)</span>
        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]))
        loss = loss_fct(logits.view(-<span class="hljs-number">1</span>, self.model.config.num_labels), labels.view(-<span class="hljs-number">1</span>))
        <span class="hljs-keyword">return</span> (loss, outputs) <span class="hljs-keyword">if</span> return_outputs <span class="hljs-keyword">else</span> loss`}}),ne=new Ma({}),re=new A({props:{name:"class optimum.habana.GaudiTrainer",anchor:"optimum.habana.GaudiTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"gaudi_config",val:": GaudiConfig = None"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"preprocess_logits_for_metrics",val:": typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer.py#L109"}}),oe=new A({props:{name:"create_optimizer",anchor:"optimum.habana.GaudiTrainer.create_optimizer",parameters:[],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer.py#L229"}}),se=new A({props:{name:"evaluation_loop",anchor:"optimum.habana.GaudiTrainer.evaluation_loop",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer.py#L877"}}),le=new A({props:{name:"prediction_loop",anchor:"optimum.habana.GaudiTrainer.prediction_loop",parameters:[{name:"dataloader",val:": DataLoader"},{name:"description",val:": str"},{name:"prediction_loss_only",val:": typing.Optional[bool] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer.py#L1154"}}),de=new A({props:{name:"prediction_step",anchor:"optimum.habana.GaudiTrainer.prediction_step",parameters:[{name:"model",val:": Module"},{name:"inputs",val:": typing.Dict[str, typing.Union[torch.Tensor, typing.Any]]"},{name:"prediction_loss_only",val:": bool"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"}],parametersDescription:[{anchor:"optimum.habana.GaudiTrainer.prediction_step.model",description:`<strong>model</strong> (<code>nn.Module</code>) &#x2014;
The model to evaluate.`,name:"model"},{anchor:"optimum.habana.GaudiTrainer.prediction_step.inputs",description:`<strong>inputs</strong> (<code>Dict[str, Union[torch.Tensor, Any]]</code>) &#x2014;
The inputs and targets of the model.
The dictionary will be unpacked before being fed to the model. Most models expect the targets under the
argument <code>labels</code>. Check your model&#x2019;s documentation for all accepted arguments.`,name:"inputs"},{anchor:"optimum.habana.GaudiTrainer.prediction_step.prediction_loss_only",description:`<strong>prediction_loss_only</strong> (<code>bool</code>) &#x2014;
Whether or not to return the loss only.`,name:"prediction_loss_only"},{anchor:"optimum.habana.GaudiTrainer.prediction_step.ignore_keys",description:`<strong>ignore_keys</strong> (<code>Lst[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer.py#L1078",returnDescription:`
<p>A tuple with the loss,
logits and labels (each being optional).</p>
`,returnType:`
<p>Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]</p>
`}}),pe=new A({props:{name:"save_model",anchor:"optimum.habana.GaudiTrainer.save_model",parameters:[{name:"output_dir",val:": typing.Optional[str] = None"},{name:"_internal_call",val:": bool = False"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer.py#L1279"}}),ce=new A({props:{name:"train",anchor:"optimum.habana.GaudiTrainer.train",parameters:[{name:"resume_from_checkpoint",val:": typing.Union[bool, str, NoneType] = None"},{name:"trial",val:": typing.Union[ForwardRef('optuna.Trial'), typing.Dict[str, typing.Any]] = None"},{name:"ignore_keys_for_eval",val:": typing.Optional[typing.List[str]] = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"optimum.habana.GaudiTrainer.train.resume_from_checkpoint",description:`<strong>resume_from_checkpoint</strong> (<code>str</code> or <code>bool</code>, <em>optional</em>) &#x2014;
If a <code>str</code>, local path to a saved checkpoint as saved by a previous instance of <code>Trainer</code>. If a
<code>bool</code> and equals <code>True</code>, load the last checkpoint in <em>args.output_dir</em> as saved by a previous instance
of <code>Trainer</code>. If present, training will resume from the model/optimizer/scheduler states loaded here.`,name:"resume_from_checkpoint"},{anchor:"optimum.habana.GaudiTrainer.train.trial",description:`<strong>trial</strong> (<code>optuna.Trial</code> or <code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The trial run or the hyperparameter dictionary for hyperparameter search.`,name:"trial"},{anchor:"optimum.habana.GaudiTrainer.train.ignore_keys_for_eval",description:`<strong>ignore_keys_for_eval</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions for evaluation during the training.
kwargs &#x2014;
Additional keyword arguments used to hide deprecated arguments`,name:"ignore_keys_for_eval"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer.py#L323"}}),ue=new Ma({}),he=new A({props:{name:"class optimum.habana.GaudiSeq2SeqTrainer",anchor:"optimum.habana.GaudiSeq2SeqTrainer",parameters:[{name:"model",val:": typing.Union[transformers.modeling_utils.PreTrainedModel, torch.nn.modules.module.Module] = None"},{name:"gaudi_config",val:": GaudiConfig = None"},{name:"args",val:": TrainingArguments = None"},{name:"data_collator",val:": typing.Optional[DataCollator] = None"},{name:"train_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"tokenizer",val:": typing.Optional[transformers.tokenization_utils_base.PreTrainedTokenizerBase] = None"},{name:"model_init",val:": typing.Callable[[], transformers.modeling_utils.PreTrainedModel] = None"},{name:"compute_metrics",val:": typing.Union[typing.Callable[[transformers.trainer_utils.EvalPrediction], typing.Dict], NoneType] = None"},{name:"callbacks",val:": typing.Optional[typing.List[transformers.trainer_callback.TrainerCallback]] = None"},{name:"optimizers",val:": typing.Tuple[torch.optim.optimizer.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None)"},{name:"preprocess_logits_for_metrics",val:": typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer_seq2seq.py#L30"}}),ge=new A({props:{name:"evaluate",anchor:"optimum.habana.GaudiSeq2SeqTrainer.evaluate",parameters:[{name:"eval_dataset",val:": typing.Optional[torch.utils.data.dataset.Dataset] = None"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'eval'"},{name:"**gen_kwargs",val:""}],parametersDescription:[{anchor:"optimum.habana.GaudiSeq2SeqTrainer.evaluate.eval_dataset",description:`<strong>eval_dataset</strong> (<code>Dataset</code>, <em>optional</em>) &#x2014;
Pass a dataset if you wish to override <code>self.eval_dataset</code>. If it is an <a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset" rel="nofollow">Dataset</a>, columns
not accepted by the <code>model.forward()</code> method are automatically removed. It must implement the <code>__len__</code>
method.`,name:"eval_dataset"},{anchor:"optimum.habana.GaudiSeq2SeqTrainer.evaluate.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.habana.GaudiSeq2SeqTrainer.evaluate.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.habana.GaudiSeq2SeqTrainer.evaluate.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.habana.GaudiSeq2SeqTrainer.evaluate.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.
gen_kwargs &#x2014;
Additional <code>generate</code> specific kwargs.`,name:"num_beams"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer_seq2seq.py#L31",returnDescription:`
<p>A dictionary containing the evaluation loss and the potential metrics computed from the predictions. The
dictionary also contains the epoch number which comes from the training state.</p>
`}}),be=new A({props:{name:"predict",anchor:"optimum.habana.GaudiSeq2SeqTrainer.predict",parameters:[{name:"test_dataset",val:": Dataset"},{name:"ignore_keys",val:": typing.Optional[typing.List[str]] = None"},{name:"metric_key_prefix",val:": str = 'test'"},{name:"**gen_kwargs",val:""}],parametersDescription:[{anchor:"optimum.habana.GaudiSeq2SeqTrainer.predict.test_dataset",description:`<strong>test_dataset</strong> (<code>Dataset</code>) &#x2014;
Dataset to run the predictions on. If it is a <a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset" rel="nofollow">Dataset</a>, columns not accepted by the
<code>model.forward()</code> method are automatically removed. Has to implement the method <code>__len__</code>`,name:"test_dataset"},{anchor:"optimum.habana.GaudiSeq2SeqTrainer.predict.ignore_keys",description:`<strong>ignore_keys</strong> (<code>List[str]</code>, <em>optional</em>) &#x2014;
A list of keys in the output of your model (if it is a dictionary) that should be ignored when
gathering predictions.`,name:"ignore_keys"},{anchor:"optimum.habana.GaudiSeq2SeqTrainer.predict.metric_key_prefix",description:`<strong>metric_key_prefix</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;eval&quot;</code>) &#x2014;
An optional prefix to be used as the metrics key prefix. For example the metrics &#x201C;bleu&#x201D; will be named
&#x201C;eval_bleu&#x201D; if the prefix is <code>&quot;eval&quot;</code> (default)`,name:"metric_key_prefix"},{anchor:"optimum.habana.GaudiSeq2SeqTrainer.predict.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The maximum target length to use when predicting with the generate method.`,name:"max_length"},{anchor:"optimum.habana.GaudiSeq2SeqTrainer.predict.num_beams",description:`<strong>num_beams</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Number of beams for beam search that will be used when predicting with the generate method. 1 means no
beam search.
gen_kwargs &#x2014;
Additional <code>generate</code> specific kwargs.`,name:"num_beams"}],source:"https://github.com/huggingface/optimum.habana/blob/vr_89/src/optimum/habana/trainer_seq2seq.py#L77"}}),Q=new fn({props:{$$slots:{default:[kn]},$$scope:{ctx:Te}}}),{c(){c=o("meta"),w=d(),g=o("h1"),x=o("a"),P=o("span"),b(k.$$.fragment),D=d(),z=o("span"),Tt=n("GaudiTrainer"),Ke=d(),G=o("p"),$t=n("The "),$e=o("a"),wt=n("GaudiTrainer"),kt=n(" class provides an extended API for the feature-complete "),Z=o("a"),xt=n("Transformers Trainer"),Gt=n(". It is used in all the "),ee=o("a"),Et=n("example scripts"),qt=n("."),Qe=d(),S=o("p"),Dt=n("Before instantiating your "),we=o("a"),St=n("GaudiTrainer"),Nt=n(", create a "),Ae=o("code"),At=n("GaudiTrainingArguments"),Pt=n(" object to access all the points of customization during training."),Xe=d(),b(M.$$.fragment),Ze=d(),W=o("p"),Ot=n("Here is an example of how to customize "),ke=o("a"),Ct=n("GaudiTrainer"),Lt=n(" to use a weighted loss (useful when you have an unbalanced training set):"),et=d(),b(te.$$.fragment),tt=d(),N=o("p"),jt=n("Another way to customize the training loop behavior for the PyTorch "),xe=o("a"),It=n("GaudiTrainer"),zt=n(" is to use "),ae=o("a"),Mt=n("callbacks"),Wt=n(" that can inspect the training loop state (for progress reporting, logging on TensorBoard or other ML platforms\u2026) and take decisions (like early stopping)."),at=d(),O=o("h2"),H=o("a"),Pe=o("span"),b(ne.$$.fragment),Ht=d(),Oe=o("span"),Rt=n("GaudiTrainer"),nt=d(),h=o("div"),b(re.$$.fragment),Vt=d(),Ce=o("p"),Ut=n(`GaudiTrainer is built on top of the tranformers\u2019 Trainer to enable
deployment on Habana\u2019s Gaudi.`),Bt=d(),R=o("div"),b(oe.$$.fragment),Ft=d(),ie=o("p"),Yt=n(`Setup the optimizer.
We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
Trainer\u2019s init through `),Le=o("code"),Jt=n("optimizers"),Kt=n(", or subclass and override this method in a subclass."),Qt=d(),V=o("div"),b(se.$$.fragment),Xt=d(),C=o("p"),Zt=n("Prediction/evaluation loop, shared by "),je=o("code"),ea=n("Trainer.evaluate()"),ta=n(" and "),Ie=o("code"),aa=n("Trainer.predict()"),na=n(`.
Works both with or without labels.`),ra=d(),U=o("div"),b(le.$$.fragment),oa=d(),L=o("p"),ia=n("Prediction/evaluation loop, shared by "),ze=o("code"),sa=n("Trainer.evaluate()"),la=n(" and "),Me=o("code"),da=n("Trainer.predict()"),pa=n(`.
Works both with or without labels.`),ma=d(),B=o("div"),b(de.$$.fragment),ca=d(),j=o("p"),ua=n("Perform an evaluation step on "),We=o("code"),ha=n("model"),ga=n(" using "),He=o("code"),fa=n("inputs"),ba=n(`.
Subclass and override to inject custom behavior.`),_a=d(),F=o("div"),b(pe.$$.fragment),va=d(),me=o("p"),ya=n("Will save the model, so you can reload it using "),Re=o("code"),Ta=n("from_pretrained()"),$a=n(`.
Will only save from the main process.`),wa=d(),Y=o("div"),b(ce.$$.fragment),ka=d(),Ve=o("p"),xa=n("Main training entry point."),rt=d(),I=o("h2"),J=o("a"),Ue=o("span"),b(ue.$$.fragment),Ga=d(),Be=o("span"),Ea=n("GaudiSeq2SeqTrainer"),ot=d(),E=o("div"),b(he.$$.fragment),qa=d(),K=o("div"),b(ge.$$.fragment),Da=d(),fe=o("p"),Sa=n(`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Fe=o("code"),Na=n("compute_metrics"),Aa=n(` argument).
You can also subclass and override this method to inject custom behavior.`),Pa=d(),q=o("div"),b(be.$$.fragment),Oa=d(),_e=o("p"),Ca=n(`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Ye=o("code"),La=n("evaluate()"),ja=n("."),Ia=d(),b(Q.$$.fragment),za=n("\nReturns: *NamedTuple* A namedtuple with the following keys:\n- predictions (`np.ndarray`): The predictions on `test_dataset`.\n- label_ids (`np.ndarray`, *optional*): The labels (if the dataset contained some).\n- metrics (`Dict[str, float]`, *optional*): The potential dictionary of metrics (if the dataset contained\n  labels)."),this.h()},l(t){const m=yn('[data-svelte="svelte-1phssyn"]',document.head);c=i(m,"META",{name:!0,content:!0}),m.forEach(a),w=p(t),g=i(t,"H1",{class:!0});var ve=s(g);x=i(ve,"A",{id:!0,class:!0,href:!0});var Je=s(x);P=i(Je,"SPAN",{});var Wa=s(P);_(k.$$.fragment,Wa),Wa.forEach(a),Je.forEach(a),D=p(ve),z=i(ve,"SPAN",{});var Ha=s(z);Tt=r(Ha,"GaudiTrainer"),Ha.forEach(a),ve.forEach(a),Ke=p(t),G=i(t,"P",{});var X=s(G);$t=r(X,"The "),$e=i(X,"A",{href:!0});var Ra=s($e);wt=r(Ra,"GaudiTrainer"),Ra.forEach(a),kt=r(X," class provides an extended API for the feature-complete "),Z=i(X,"A",{href:!0,rel:!0});var Va=s(Z);xt=r(Va,"Transformers Trainer"),Va.forEach(a),Gt=r(X,". It is used in all the "),ee=i(X,"A",{href:!0,rel:!0});var Ua=s(ee);Et=r(Ua,"example scripts"),Ua.forEach(a),qt=r(X,"."),X.forEach(a),Qe=p(t),S=i(t,"P",{});var Ge=s(S);Dt=r(Ge,"Before instantiating your "),we=i(Ge,"A",{href:!0});var Ba=s(we);St=r(Ba,"GaudiTrainer"),Ba.forEach(a),Nt=r(Ge,", create a "),Ae=i(Ge,"CODE",{});var Fa=s(Ae);At=r(Fa,"GaudiTrainingArguments"),Fa.forEach(a),Pt=r(Ge," object to access all the points of customization during training."),Ge.forEach(a),Xe=p(t),_(M.$$.fragment,t),Ze=p(t),W=i(t,"P",{});var st=s(W);Ot=r(st,"Here is an example of how to customize "),ke=i(st,"A",{href:!0});var Ya=s(ke);Ct=r(Ya,"GaudiTrainer"),Ya.forEach(a),Lt=r(st," to use a weighted loss (useful when you have an unbalanced training set):"),st.forEach(a),et=p(t),_(te.$$.fragment,t),tt=p(t),N=i(t,"P",{});var Ee=s(N);jt=r(Ee,"Another way to customize the training loop behavior for the PyTorch "),xe=i(Ee,"A",{href:!0});var Ja=s(xe);It=r(Ja,"GaudiTrainer"),Ja.forEach(a),zt=r(Ee," is to use "),ae=i(Ee,"A",{href:!0,rel:!0});var Ka=s(ae);Mt=r(Ka,"callbacks"),Ka.forEach(a),Wt=r(Ee," that can inspect the training loop state (for progress reporting, logging on TensorBoard or other ML platforms\u2026) and take decisions (like early stopping)."),Ee.forEach(a),at=p(t),O=i(t,"H2",{class:!0});var lt=s(O);H=i(lt,"A",{id:!0,class:!0,href:!0});var Qa=s(H);Pe=i(Qa,"SPAN",{});var Xa=s(Pe);_(ne.$$.fragment,Xa),Xa.forEach(a),Qa.forEach(a),Ht=p(lt),Oe=i(lt,"SPAN",{});var Za=s(Oe);Rt=r(Za,"GaudiTrainer"),Za.forEach(a),lt.forEach(a),nt=p(t),h=i(t,"DIV",{class:!0});var f=s(h);_(re.$$.fragment,f),Vt=p(f),Ce=i(f,"P",{});var en=s(Ce);Ut=r(en,`GaudiTrainer is built on top of the tranformers\u2019 Trainer to enable
deployment on Habana\u2019s Gaudi.`),en.forEach(a),Bt=p(f),R=i(f,"DIV",{class:!0});var dt=s(R);_(oe.$$.fragment,dt),Ft=p(dt),ie=i(dt,"P",{});var pt=s(ie);Yt=r(pt,`Setup the optimizer.
We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the
Trainer\u2019s init through `),Le=i(pt,"CODE",{});var tn=s(Le);Jt=r(tn,"optimizers"),tn.forEach(a),Kt=r(pt,", or subclass and override this method in a subclass."),pt.forEach(a),dt.forEach(a),Qt=p(f),V=i(f,"DIV",{class:!0});var mt=s(V);_(se.$$.fragment,mt),Xt=p(mt),C=i(mt,"P",{});var qe=s(C);Zt=r(qe,"Prediction/evaluation loop, shared by "),je=i(qe,"CODE",{});var an=s(je);ea=r(an,"Trainer.evaluate()"),an.forEach(a),ta=r(qe," and "),Ie=i(qe,"CODE",{});var nn=s(Ie);aa=r(nn,"Trainer.predict()"),nn.forEach(a),na=r(qe,`.
Works both with or without labels.`),qe.forEach(a),mt.forEach(a),ra=p(f),U=i(f,"DIV",{class:!0});var ct=s(U);_(le.$$.fragment,ct),oa=p(ct),L=i(ct,"P",{});var De=s(L);ia=r(De,"Prediction/evaluation loop, shared by "),ze=i(De,"CODE",{});var rn=s(ze);sa=r(rn,"Trainer.evaluate()"),rn.forEach(a),la=r(De," and "),Me=i(De,"CODE",{});var on=s(Me);da=r(on,"Trainer.predict()"),on.forEach(a),pa=r(De,`.
Works both with or without labels.`),De.forEach(a),ct.forEach(a),ma=p(f),B=i(f,"DIV",{class:!0});var ut=s(B);_(de.$$.fragment,ut),ca=p(ut),j=i(ut,"P",{});var Se=s(j);ua=r(Se,"Perform an evaluation step on "),We=i(Se,"CODE",{});var sn=s(We);ha=r(sn,"model"),sn.forEach(a),ga=r(Se," using "),He=i(Se,"CODE",{});var ln=s(He);fa=r(ln,"inputs"),ln.forEach(a),ba=r(Se,`.
Subclass and override to inject custom behavior.`),Se.forEach(a),ut.forEach(a),_a=p(f),F=i(f,"DIV",{class:!0});var ht=s(F);_(pe.$$.fragment,ht),va=p(ht),me=i(ht,"P",{});var gt=s(me);ya=r(gt,"Will save the model, so you can reload it using "),Re=i(gt,"CODE",{});var dn=s(Re);Ta=r(dn,"from_pretrained()"),dn.forEach(a),$a=r(gt,`.
Will only save from the main process.`),gt.forEach(a),ht.forEach(a),wa=p(f),Y=i(f,"DIV",{class:!0});var ft=s(Y);_(ce.$$.fragment,ft),ka=p(ft),Ve=i(ft,"P",{});var pn=s(Ve);xa=r(pn,"Main training entry point."),pn.forEach(a),ft.forEach(a),f.forEach(a),rt=p(t),I=i(t,"H2",{class:!0});var bt=s(I);J=i(bt,"A",{id:!0,class:!0,href:!0});var mn=s(J);Ue=i(mn,"SPAN",{});var cn=s(Ue);_(ue.$$.fragment,cn),cn.forEach(a),mn.forEach(a),Ga=p(bt),Be=i(bt,"SPAN",{});var un=s(Be);Ea=r(un,"GaudiSeq2SeqTrainer"),un.forEach(a),bt.forEach(a),ot=p(t),E=i(t,"DIV",{class:!0});var Ne=s(E);_(he.$$.fragment,Ne),qa=p(Ne),K=i(Ne,"DIV",{class:!0});var _t=s(K);_(ge.$$.fragment,_t),Da=p(_t),fe=i(_t,"P",{});var vt=s(fe);Sa=r(vt,`Run evaluation and returns metrics.
The calling script will be responsible for providing a method to compute metrics, as they are task-dependent
(pass it to the init `),Fe=i(vt,"CODE",{});var hn=s(Fe);Na=r(hn,"compute_metrics"),hn.forEach(a),Aa=r(vt,` argument).
You can also subclass and override this method to inject custom behavior.`),vt.forEach(a),_t.forEach(a),Pa=p(Ne),q=i(Ne,"DIV",{class:!0});var ye=s(q);_(be.$$.fragment,ye),Oa=p(ye),_e=i(ye,"P",{});var yt=s(_e);Ca=r(yt,`Run prediction and returns predictions and potential metrics.
Depending on the dataset and your use case, your test dataset may contain labels. In that case, this method
will also return metrics, like in `),Ye=i(yt,"CODE",{});var gn=s(Ye);La=r(gn,"evaluate()"),gn.forEach(a),ja=r(yt,"."),yt.forEach(a),Ia=p(ye),_(Q.$$.fragment,ye),za=r(ye,"\nReturns: *NamedTuple* A namedtuple with the following keys:\n- predictions (`np.ndarray`): The predictions on `test_dataset`.\n- label_ids (`np.ndarray`, *optional*): The labels (if the dataset contained some).\n- metrics (`Dict[str, float]`, *optional*): The potential dictionary of metrics (if the dataset contained\n  labels)."),ye.forEach(a),Ne.forEach(a),this.h()},h(){l(c,"name","hf:doc:metadata"),l(c,"content",JSON.stringify(Gn)),l(x,"id","gauditrainer"),l(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(x,"href","#gauditrainer"),l(g,"class","relative group"),l($e,"href","/docs/optimum.habana/pr_89/en/trainer#optimum.habana.GaudiTrainer"),l(Z,"href","https://huggingface.co/docs/transformers/main_classes/trainer"),l(Z,"rel","nofollow"),l(ee,"href","https://github.com/huggingface/optimum-habana/tree/main/examples"),l(ee,"rel","nofollow"),l(we,"href","/docs/optimum.habana/pr_89/en/trainer#optimum.habana.GaudiTrainer"),l(ke,"href","/docs/optimum.habana/pr_89/en/trainer#optimum.habana.GaudiTrainer"),l(xe,"href","/docs/optimum.habana/pr_89/en/trainer#optimum.habana.GaudiTrainer"),l(ae,"href","https://huggingface.co/docs/transformers/main_classes/callback"),l(ae,"rel","nofollow"),l(H,"id","optimum.habana.GaudiTrainer"),l(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(H,"href","#optimum.habana.GaudiTrainer"),l(O,"class","relative group"),l(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(h,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(J,"id","optimum.habana.GaudiSeq2SeqTrainer"),l(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(J,"href","#optimum.habana.GaudiSeq2SeqTrainer"),l(I,"class","relative group"),l(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),l(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(t,m){e(document.head,c),u(t,w,m),u(t,g,m),e(g,x),e(x,P),v(k,P,null),e(g,D),e(g,z),e(z,Tt),u(t,Ke,m),u(t,G,m),e(G,$t),e(G,$e),e($e,wt),e(G,kt),e(G,Z),e(Z,xt),e(G,Gt),e(G,ee),e(ee,Et),e(G,qt),u(t,Qe,m),u(t,S,m),e(S,Dt),e(S,we),e(we,St),e(S,Nt),e(S,Ae),e(Ae,At),e(S,Pt),u(t,Xe,m),v(M,t,m),u(t,Ze,m),u(t,W,m),e(W,Ot),e(W,ke),e(ke,Ct),e(W,Lt),u(t,et,m),v(te,t,m),u(t,tt,m),u(t,N,m),e(N,jt),e(N,xe),e(xe,It),e(N,zt),e(N,ae),e(ae,Mt),e(N,Wt),u(t,at,m),u(t,O,m),e(O,H),e(H,Pe),v(ne,Pe,null),e(O,Ht),e(O,Oe),e(Oe,Rt),u(t,nt,m),u(t,h,m),v(re,h,null),e(h,Vt),e(h,Ce),e(Ce,Ut),e(h,Bt),e(h,R),v(oe,R,null),e(R,Ft),e(R,ie),e(ie,Yt),e(ie,Le),e(Le,Jt),e(ie,Kt),e(h,Qt),e(h,V),v(se,V,null),e(V,Xt),e(V,C),e(C,Zt),e(C,je),e(je,ea),e(C,ta),e(C,Ie),e(Ie,aa),e(C,na),e(h,ra),e(h,U),v(le,U,null),e(U,oa),e(U,L),e(L,ia),e(L,ze),e(ze,sa),e(L,la),e(L,Me),e(Me,da),e(L,pa),e(h,ma),e(h,B),v(de,B,null),e(B,ca),e(B,j),e(j,ua),e(j,We),e(We,ha),e(j,ga),e(j,He),e(He,fa),e(j,ba),e(h,_a),e(h,F),v(pe,F,null),e(F,va),e(F,me),e(me,ya),e(me,Re),e(Re,Ta),e(me,$a),e(h,wa),e(h,Y),v(ce,Y,null),e(Y,ka),e(Y,Ve),e(Ve,xa),u(t,rt,m),u(t,I,m),e(I,J),e(J,Ue),v(ue,Ue,null),e(I,Ga),e(I,Be),e(Be,Ea),u(t,ot,m),u(t,E,m),v(he,E,null),e(E,qa),e(E,K),v(ge,K,null),e(K,Da),e(K,fe),e(fe,Sa),e(fe,Fe),e(Fe,Na),e(fe,Aa),e(E,Pa),e(E,q),v(be,q,null),e(q,Oa),e(q,_e),e(_e,Ca),e(_e,Ye),e(Ye,La),e(_e,ja),e(q,Ia),v(Q,q,null),e(q,za),it=!0},p(t,[m]){const ve={};m&2&&(ve.$$scope={dirty:m,ctx:t}),M.$set(ve);const Je={};m&2&&(Je.$$scope={dirty:m,ctx:t}),Q.$set(Je)},i(t){it||(y(k.$$.fragment,t),y(M.$$.fragment,t),y(te.$$.fragment,t),y(ne.$$.fragment,t),y(re.$$.fragment,t),y(oe.$$.fragment,t),y(se.$$.fragment,t),y(le.$$.fragment,t),y(de.$$.fragment,t),y(pe.$$.fragment,t),y(ce.$$.fragment,t),y(ue.$$.fragment,t),y(he.$$.fragment,t),y(ge.$$.fragment,t),y(be.$$.fragment,t),y(Q.$$.fragment,t),it=!0)},o(t){T(k.$$.fragment,t),T(M.$$.fragment,t),T(te.$$.fragment,t),T(ne.$$.fragment,t),T(re.$$.fragment,t),T(oe.$$.fragment,t),T(se.$$.fragment,t),T(le.$$.fragment,t),T(de.$$.fragment,t),T(pe.$$.fragment,t),T(ce.$$.fragment,t),T(ue.$$.fragment,t),T(he.$$.fragment,t),T(ge.$$.fragment,t),T(be.$$.fragment,t),T(Q.$$.fragment,t),it=!1},d(t){a(c),t&&a(w),t&&a(g),$(k),t&&a(Ke),t&&a(G),t&&a(Qe),t&&a(S),t&&a(Xe),$(M,t),t&&a(Ze),t&&a(W),t&&a(et),$(te,t),t&&a(tt),t&&a(N),t&&a(at),t&&a(O),$(ne),t&&a(nt),t&&a(h),$(re),$(oe),$(se),$(le),$(de),$(pe),$(ce),t&&a(rt),t&&a(I),$(ue),t&&a(ot),t&&a(E),$(he),$(ge),$(be),$(Q)}}}const Gn={local:"gauditrainer",sections:[{local:"optimum.habana.GaudiTrainer",title:"GaudiTrainer"},{local:"optimum.habana.GaudiSeq2SeqTrainer",title:"GaudiSeq2SeqTrainer"}],title:"GaudiTrainer"};function En(Te){return Tn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Pn extends bn{constructor(c){super();_n(this,c,En,xn,vn,{})}}export{Pn as default,Gn as metadata};
