import{S as Fs,i as qs,s as Ms,e as t,k as d,w as P,t as l,M as Hs,c as n,d as a,m as h,a as s,x as R,h as r,b as p,G as e,g as c,y as L,q as S,o as F,B as q,v as Us,L as Bs}from"../../chunks/vendor-hf-doc-builder.js";import{T as Cn}from"../../chunks/Tip-hf-doc-builder.js";import{D as An}from"../../chunks/Docstring-hf-doc-builder.js";import{C as Oo}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as Io}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as zs}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function Vs(ve){let b,C,_,f,g,u,v,M,H,y,w,T,V,k,m,E,U,J,B,j,x,W,pe,Q,N,$,I,oe,we,X,Ee,ue,te,ae,Y,ne,ye,Qe,G,me,O,be,Xe,se,$e,Ye,Ce;return{c(){b=t("p"),C=l("Raises the following errors:"),_=d(),f=t("ul"),g=t("li"),u=t("a"),v=t("code"),M=l("EnvironmentError"),H=l(`
if `),y=t("code"),w=l("use_auth_token=True"),T=l(" and the token cannot be found."),V=d(),k=t("li"),m=t("a"),E=t("code"),U=l("OSError"),J=l(`
if ETag cannot be determined.`),B=d(),j=t("li"),x=t("a"),W=t("code"),pe=l("ValueError"),Q=l(`
if some parameter value is invalid`),N=d(),$=t("li"),I=t("a"),oe=l("RepositoryNotFoundError"),we=l(`
If the repository to download from cannot be found. This may be because it doesn\u2019t exist,
or because it is set to `),X=t("code"),Ee=l("private"),ue=l(" and you do not have access."),te=d(),ae=t("li"),Y=t("a"),ne=l("RevisionNotFoundError"),ye=l(`
If the revision to download from cannot be found.`),Qe=d(),G=t("li"),me=t("a"),O=l("EntryNotFoundError"),be=l(`
If the file to download cannot be found.`),Xe=d(),se=t("li"),$e=t("a"),Ye=l("LocalEntryNotFoundError"),Ce=l(`
If network is disabled or unavailable and file is not found in cache.`),this.h()},l(K){b=n(K,"P",{});var je=s(b);C=r(je,"Raises the following errors:"),je.forEach(a),_=h(K),f=n(K,"UL",{});var A=s(f);g=n(A,"LI",{});var Ae=s(g);u=n(Ae,"A",{href:!0,rel:!0});var po=s(u);v=n(po,"CODE",{});var ge=s(v);M=r(ge,"EnvironmentError"),ge.forEach(a),po.forEach(a),H=r(Ae,`
if `),y=n(Ae,"CODE",{});var Ze=s(y);w=r(Ze,"use_auth_token=True"),Ze.forEach(a),T=r(Ae," and the token cannot be found."),Ae.forEach(a),V=h(A),k=n(A,"LI",{});var D=s(k);m=n(D,"A",{href:!0,rel:!0});var ke=s(m);E=n(ke,"CODE",{});var uo=s(E);U=r(uo,"OSError"),uo.forEach(a),ke.forEach(a),J=r(D,`
if ETag cannot be determined.`),D.forEach(a),B=h(A),j=n(A,"LI",{});var Ne=s(j);x=n(Ne,"A",{href:!0,rel:!0});var mo=s(x);W=n(mo,"CODE",{});var bo=s(W);pe=r(bo,"ValueError"),bo.forEach(a),mo.forEach(a),Q=r(Ne,`
if some parameter value is invalid`),Ne.forEach(a),N=h(A),$=n(A,"LI",{});var _e=s($);I=n(_e,"A",{href:!0});var go=s(I);oe=r(go,"RepositoryNotFoundError"),go.forEach(a),we=r(_e,`
If the repository to download from cannot be found. This may be because it doesn\u2019t exist,
or because it is set to `),X=n(_e,"CODE",{});var _o=s(X);Ee=r(_o,"private"),_o.forEach(a),ue=r(_e," and you do not have access."),_e.forEach(a),te=h(A),ae=n(A,"LI",{});var le=s(ae);Y=n(le,"A",{href:!0});var vo=s(Y);ne=r(vo,"RevisionNotFoundError"),vo.forEach(a),ye=r(le,`
If the revision to download from cannot be found.`),le.forEach(a),Qe=h(A),G=n(A,"LI",{});var re=s(G);me=n(re,"A",{href:!0});var wo=s(me);O=r(wo,"EntryNotFoundError"),wo.forEach(a),be=r(re,`
If the file to download cannot be found.`),re.forEach(a),Xe=h(A),se=n(A,"LI",{});var Ie=s(se);$e=n(Ie,"A",{href:!0});var Eo=s($e);Ye=r(Eo,"LocalEntryNotFoundError"),Eo.forEach(a),Ce=r(Ie,`
If network is disabled or unavailable and file is not found in cache.`),Ie.forEach(a),A.forEach(a),this.h()},h(){p(u,"href","https://docs.python.org/3/library/exceptions.html#EnvironmentError"),p(u,"rel","nofollow"),p(m,"href","https://docs.python.org/3/library/exceptions.html#OSError"),p(m,"rel","nofollow"),p(x,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),p(x,"rel","nofollow"),p(I,"href","/docs/huggingface_hub/pr_991/en/package_reference/utilities#huggingface_hub.utils.RepositoryNotFoundError"),p(Y,"href","/docs/huggingface_hub/pr_991/en/package_reference/utilities#huggingface_hub.utils.RevisionNotFoundError"),p(me,"href","/docs/huggingface_hub/pr_991/en/package_reference/utilities#huggingface_hub.utils.EntryNotFoundError"),p($e,"href","/docs/huggingface_hub/pr_991/en/package_reference/utilities#huggingface_hub.utils.LocalEntryNotFoundError")},m(K,je){c(K,b,je),e(b,C),c(K,_,je),c(K,f,je),e(f,g),e(g,u),e(u,v),e(v,M),e(g,H),e(g,y),e(y,w),e(g,T),e(f,V),e(f,k),e(k,m),e(m,E),e(E,U),e(k,J),e(f,B),e(f,j),e(j,x),e(x,W),e(W,pe),e(j,Q),e(f,N),e(f,$),e($,I),e(I,oe),e($,we),e($,X),e(X,Ee),e($,ue),e(f,te),e(f,ae),e(ae,Y),e(Y,ne),e(ae,ye),e(f,Qe),e(f,G),e(G,me),e(me,O),e(G,be),e(f,Xe),e(f,se),e(se,$e),e($e,Ye),e(se,Ce)},d(K){K&&a(b),K&&a(_),K&&a(f)}}}function Ws(ve){let b,C,_,f,g,u,v,M,H,y,w,T,V,k,m,E,U,J,B,j,x,W,pe,Q;return{c(){b=t("p"),C=l("Raises the following errors:"),_=d(),f=t("ul"),g=t("li"),u=t("a"),v=t("code"),M=l("EnvironmentError"),H=l(`
if `),y=t("code"),w=l("use_auth_token=True"),T=l(" and the token cannot be found."),V=d(),k=t("li"),m=t("a"),E=t("code"),U=l("OSError"),J=l(` if
ETag cannot be determined.`),B=d(),j=t("li"),x=t("a"),W=t("code"),pe=l("ValueError"),Q=l(`
if some parameter value is invalid`),this.h()},l(N){b=n(N,"P",{});var $=s(b);C=r($,"Raises the following errors:"),$.forEach(a),_=h(N),f=n(N,"UL",{});var I=s(f);g=n(I,"LI",{});var oe=s(g);u=n(oe,"A",{href:!0,rel:!0});var we=s(u);v=n(we,"CODE",{});var X=s(v);M=r(X,"EnvironmentError"),X.forEach(a),we.forEach(a),H=r(oe,`
if `),y=n(oe,"CODE",{});var Ee=s(y);w=r(Ee,"use_auth_token=True"),Ee.forEach(a),T=r(oe," and the token cannot be found."),oe.forEach(a),V=h(I),k=n(I,"LI",{});var ue=s(k);m=n(ue,"A",{href:!0,rel:!0});var te=s(m);E=n(te,"CODE",{});var ae=s(E);U=r(ae,"OSError"),ae.forEach(a),te.forEach(a),J=r(ue,` if
ETag cannot be determined.`),ue.forEach(a),B=h(I),j=n(I,"LI",{});var Y=s(j);x=n(Y,"A",{href:!0,rel:!0});var ne=s(x);W=n(ne,"CODE",{});var ye=s(W);pe=r(ye,"ValueError"),ye.forEach(a),ne.forEach(a),Q=r(Y,`
if some parameter value is invalid`),Y.forEach(a),I.forEach(a),this.h()},h(){p(u,"href","https://docs.python.org/3/library/exceptions.html#EnvironmentError"),p(u,"rel","nofollow"),p(m,"href","https://docs.python.org/3/library/exceptions.html#OSError"),p(m,"rel","nofollow"),p(x,"href","https://docs.python.org/3/library/exceptions.html#ValueError"),p(x,"rel","nofollow")},m(N,$){c(N,b,$),e(b,C),c(N,_,$),c(N,f,$),e(f,g),e(g,u),e(u,v),e(v,M),e(g,H),e(g,y),e(y,w),e(g,T),e(f,V),e(f,k),e(k,m),e(m,E),e(E,U),e(k,J),e(f,B),e(f,j),e(j,x),e(x,W),e(W,pe),e(j,Q)},d(N){N&&a(b),N&&a(_),N&&a(f)}}}function Gs(ve){let b,C,_,f,g;return f=new Oo({props:{code:`from huggingface_hub import hf_hub_url

hf_hub_url(
    repo_id="julien-c/EsperBERTo-small", filename="pytorch_model.bin"
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> hf_hub_url

<span class="hljs-meta">&gt;&gt;&gt; </span>hf_hub_url(
<span class="hljs-meta">... </span>    repo_id=<span class="hljs-string">&quot;julien-c/EsperBERTo-small&quot;</span>, filename=<span class="hljs-string">&quot;pytorch_model.bin&quot;</span>
<span class="hljs-meta">... </span>)
<span class="hljs-string">&#x27;https://huggingface.co/julien-c/EsperBERTo-small/resolve/main/pytorch_model.bin&#x27;</span>`}}),{c(){b=t("p"),C=l("Example:"),_=d(),P(f.$$.fragment)},l(u){b=n(u,"P",{});var v=s(b);C=r(v,"Example:"),v.forEach(a),_=h(u),R(f.$$.fragment,u)},m(u,v){c(u,b,v),e(b,C),c(u,_,v),L(f,u,v),g=!0},p:Bs,i(u){g||(S(f.$$.fragment,u),g=!0)},o(u){F(f.$$.fragment,u),g=!1},d(u){u&&a(b),u&&a(_),q(f,u)}}}function Ks(ve){let b,C,_,f,g,u,v,M,H,y,w,T,V,k;return{c(){b=t("p"),C=l("Notes:"),_=d(),f=t("p"),g=l(`Cloudfront is replicated over the globe so downloads are way faster for
the end user (and it also lowers our bandwidth costs).`),u=d(),v=t("p"),M=l(`Cloudfront aggressively caches files by default (default TTL is 24
hours), however this is not an issue here because we implement a
git-based versioning system on huggingface.co, which means that we store
the files on S3/Cloudfront in a content-addressable way (i.e., the file
name is its hash). Using content-addressable filenames means cache can\u2019t
ever be stale.`),H=d(),y=t("p"),w=l(`In terms of client-side caching from this library, we base our caching
on the objects\u2019 entity tag (`),T=t("code"),V=l("ETag"),k=l(`), which is an identifier of a
specific version of a resource [1]_. An object\u2019s ETag is: its git-sha1
if stored in git, or its sha256 if stored in git-lfs.`)},l(m){b=n(m,"P",{});var E=s(b);C=r(E,"Notes:"),E.forEach(a),_=h(m),f=n(m,"P",{});var U=s(f);g=r(U,`Cloudfront is replicated over the globe so downloads are way faster for
the end user (and it also lowers our bandwidth costs).`),U.forEach(a),u=h(m),v=n(m,"P",{});var J=s(v);M=r(J,`Cloudfront aggressively caches files by default (default TTL is 24
hours), however this is not an issue here because we implement a
git-based versioning system on huggingface.co, which means that we store
the files on S3/Cloudfront in a content-addressable way (i.e., the file
name is its hash). Using content-addressable filenames means cache can\u2019t
ever be stale.`),J.forEach(a),H=h(m),y=n(m,"P",{});var B=s(y);w=r(B,`In terms of client-side caching from this library, we base our caching
on the objects\u2019 entity tag (`),T=n(B,"CODE",{});var j=s(T);V=r(j,"ETag"),j.forEach(a),k=r(B,`), which is an identifier of a
specific version of a resource [1]_. An object\u2019s ETag is: its git-sha1
if stored in git, or its sha256 if stored in git-lfs.`),B.forEach(a)},m(m,E){c(m,b,E),e(b,C),c(m,_,E),c(m,f,E),e(f,g),c(m,u,E),c(m,v,E),e(v,M),c(m,H,E),c(m,y,E),e(y,w),e(y,T),e(T,V),e(y,k)},d(m){m&&a(b),m&&a(_),m&&a(f),m&&a(u),m&&a(v),m&&a(H),m&&a(y)}}}function Js(ve){let b,C,_,f,g,u,v,M,H,y,w,T,V,k,m,E,U,J,B,j,x,W,pe,Q,N,$,I,oe,we,X,Ee,ue,te,ae,Y,ne,ye,Qe,G,me,O,be,Xe,se,$e,Ye,Ce,K,je,A,Ae,po,ge,Ze,D,ke,uo,Ne,mo,bo,_e,go,_o,le,vo,re,wo,Ie,Eo,at,Po,yo,tt,eo,nt,_a,Oe,Fe,Ro,oo,st,Lo,lt,va,$o,rt,wa,jo,it,Ea,ao,ya,ie,ct,So,dt,ht,Fo,ft,pt,qo,ut,mt,$a,ko,bt,ja,to,ka,Do,gt,Da,To,_t,Ta,no,xa,xo,vt,Ca,Pe,qe,Mo,so,wt,Ho,Et,Aa,Z,yt,Uo,$t,jt,Bo,kt,Dt,zo,Tt,xt,Vo,Ct,At,Na,ce,Nt,Wo,It,Ot,Go,Pt,Rt,Ko,Lt,St,Ia,de,Ft,Jo,qt,Mt,Qo,Ht,Ut,Xo,Bt,zt,Oa,Re,Me,Yo,lo,Vt,Zo,Wt,Pa,He,Gt,ea,Kt,Jt,Ra,Le,Ue,oa,ro,Qt,aa,Xt,La,Be,Yt,ta,Zt,en,Sa,z,on,na,an,tn,sa,nn,sn,la,ln,rn,ra,cn,dn,ia,hn,fn,Fa,De,pn,ca,un,mn,da,bn,gn,qa,io,Ma,ze,_n,ha,vn,wn,Ha,Ve,En,fa,yn,$n,Ua,Se,We,pa,co,jn,ua,kn,Ba,Co,Dn,za,ho,Va;return u=new Io({}),T=new An({props:{name:"huggingface_hub.hf_hub_download",anchor:"huggingface_hub.hf_hub_download",parameters:[{name:"repo_id",val:": str"},{name:"filename",val:": str"},{name:"subfolder",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"},{name:"library_name",val:": typing.Optional[str] = None"},{name:"library_version",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Union[str, pathlib.Path, NoneType] = None"},{name:"user_agent",val:": typing.Union[typing.Dict, str, NoneType] = None"},{name:"force_download",val:": typing.Optional[bool] = False"},{name:"force_filename",val:": typing.Optional[str] = None"},{name:"proxies",val:": typing.Optional[typing.Dict] = None"},{name:"etag_timeout",val:": typing.Optional[float] = 10"},{name:"resume_download",val:": typing.Optional[bool] = False"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"local_files_only",val:": typing.Optional[bool] = False"},{name:"legacy_cache_layout",val:": typing.Optional[bool] = False"}],parametersDescription:[{anchor:"huggingface_hub.hf_hub_download.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A user or an organization name and a repo name separated by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.hf_hub_download.filename",description:`<strong>filename</strong> (<code>str</code>) &#x2014;
The name of the file in the repo.`,name:"filename"},{anchor:"huggingface_hub.hf_hub_download.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional value corresponding to a folder inside the model repo.`,name:"subfolder"},{anchor:"huggingface_hub.hf_hub_download.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.hf_hub_download.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"},{anchor:"huggingface_hub.hf_hub_download.library_name",description:`<strong>library_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the library to which the object corresponds.`,name:"library_name"},{anchor:"huggingface_hub.hf_hub_download.library_version",description:`<strong>library_version</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The version of the library.`,name:"library_version"},{anchor:"huggingface_hub.hf_hub_download.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>, <code>Path</code>, <em>optional</em>) &#x2014;
Path to the folder where cached files are stored.`,name:"cache_dir"},{anchor:"huggingface_hub.hf_hub_download.user_agent",description:`<strong>user_agent</strong> (<code>dict</code>, <code>str</code>, <em>optional</em>) &#x2014;
The user-agent info in the form of a dictionary or a string.`,name:"user_agent"},{anchor:"huggingface_hub.hf_hub_download.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether the file should be downloaded even if it already exists in
the local cache.`,name:"force_download"},{anchor:"huggingface_hub.hf_hub_download.proxies",description:`<strong>proxies</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Dictionary mapping protocol to the URL of the proxy passed to
<code>requests.request</code>.`,name:"proxies"},{anchor:"huggingface_hub.hf_hub_download.etag_timeout",description:`<strong>etag_timeout</strong> (<code>float</code>, <em>optional</em>, defaults to <code>10</code>) &#x2014;
When fetching ETag, how many seconds to wait for the server to send
data before giving up which is passed to <code>requests.request</code>.`,name:"etag_timeout"},{anchor:"huggingface_hub.hf_hub_download.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, resume a previously interrupted download.`,name:"resume_download"},{anchor:"huggingface_hub.hf_hub_download.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code>, <code>bool</code>, <em>optional</em>) &#x2014;
A token to be used for the download.<ul>
<li>If <code>True</code>, the token is read from the HuggingFace config
folder.</li>
<li>If a string, it&#x2019;s used as the authentication token.</li>
</ul>`,name:"use_auth_token"},{anchor:"huggingface_hub.hf_hub_download.local_files_only",description:`<strong>local_files_only</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, avoid downloading the file and return the path to the
local cached file if it exists.`,name:"local_files_only"},{anchor:"huggingface_hub.hf_hub_download.legacy_cache_layout",description:`<strong>legacy_cache_layout</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, uses the legacy file cache layout i.e. just call <a href="/docs/huggingface_hub/pr_991/en/package_reference/file_download#huggingface_hub.hf_hub_url">hf_hub_url()</a>
then <code>cached_download</code>. This is deprecated as the new cache layout is
more powerful.`,name:"legacy_cache_layout"}],source:"https://github.com/huggingface/huggingface_hub/blob/vr_991/src/huggingface_hub/file_download.py#L876",returnDescription:`
<p>Local path (string) of file or if networking is off, last version of
file cached on disk.</p>
`}}),G=new Cn({props:{$$slots:{default:[Vs]},$$scope:{ctx:ve}}}),be=new An({props:{name:"huggingface_hub.snapshot_download",anchor:"huggingface_hub.snapshot_download",parameters:[{name:"repo_id",val:": str"},{name:"revision",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"cache_dir",val:": typing.Union[str, pathlib.Path, NoneType] = None"},{name:"library_name",val:": typing.Optional[str] = None"},{name:"library_version",val:": typing.Optional[str] = None"},{name:"user_agent",val:": typing.Union[typing.Dict, str, NoneType] = None"},{name:"proxies",val:": typing.Optional[typing.Dict] = None"},{name:"etag_timeout",val:": typing.Optional[float] = 10"},{name:"resume_download",val:": typing.Optional[bool] = False"},{name:"use_auth_token",val:": typing.Union[bool, str, NoneType] = None"},{name:"local_files_only",val:": typing.Optional[bool] = False"},{name:"allow_regex",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_regex",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"allow_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"},{name:"ignore_patterns",val:": typing.Union[typing.List[str], str, NoneType] = None"}],parametersDescription:[{anchor:"huggingface_hub.snapshot_download.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A user or an organization name and a repo name separated by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.snapshot_download.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"},{anchor:"huggingface_hub.snapshot_download.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.snapshot_download.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code>, <code>Path</code>, <em>optional</em>) &#x2014;
Path to the folder where cached files are stored.`,name:"cache_dir"},{anchor:"huggingface_hub.snapshot_download.library_name",description:`<strong>library_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of the library to which the object corresponds.`,name:"library_name"},{anchor:"huggingface_hub.snapshot_download.library_version",description:`<strong>library_version</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The version of the library.`,name:"library_version"},{anchor:"huggingface_hub.snapshot_download.user_agent",description:`<strong>user_agent</strong> (<code>str</code>, <code>dict</code>, <em>optional</em>) &#x2014;
The user-agent info in the form of a dictionary or a string.`,name:"user_agent"},{anchor:"huggingface_hub.snapshot_download.proxies",description:`<strong>proxies</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Dictionary mapping protocol to the URL of the proxy passed to
<code>requests.request</code>.`,name:"proxies"},{anchor:"huggingface_hub.snapshot_download.etag_timeout",description:`<strong>etag_timeout</strong> (<code>float</code>, <em>optional</em>, defaults to <code>10</code>) &#x2014;
When fetching ETag, how many seconds to wait for the server to send
data before giving up which is passed to <code>requests.request</code>.`,name:"etag_timeout"},{anchor:"huggingface_hub.snapshot_download.resume_download",description:"<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False) -- If </code>True`, resume a previously interrupted download.",name:"resume_download"},{anchor:"huggingface_hub.snapshot_download.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code>, <code>bool</code>, <em>optional</em>) &#x2014;
A token to be used for the download.<ul>
<li>If <code>True</code>, the token is read from the HuggingFace config
folder.</li>
<li>If a string, it&#x2019;s used as the authentication token.</li>
</ul>`,name:"use_auth_token"},{anchor:"huggingface_hub.snapshot_download.local_files_only",description:`<strong>local_files_only</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>True</code>, avoid downloading the file and return the path to the
local cached file if it exists.`,name:"local_files_only"},{anchor:"huggingface_hub.snapshot_download.allow_patterns",description:`<strong>allow_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, only files matching at least one pattern are downloaded.`,name:"allow_patterns"},{anchor:"huggingface_hub.snapshot_download.ignore_patterns",description:`<strong>ignore_patterns</strong> (<code>List[str]</code> or <code>str</code>, <em>optional</em>) &#x2014;
If provided, files matching any of the patterns are not downloaded.`,name:"ignore_patterns"}],source:"https://github.com/huggingface/huggingface_hub/blob/vr_991/src/huggingface_hub/_snapshot_download.py#L15",returnDescription:`
<p>Local folder path (string) of repo snapshot</p>
`}}),ge=new Cn({props:{$$slots:{default:[Ws]},$$scope:{ctx:ve}}}),ke=new An({props:{name:"huggingface_hub.hf_hub_url",anchor:"huggingface_hub.hf_hub_url",parameters:[{name:"repo_id",val:": str"},{name:"filename",val:": str"},{name:"subfolder",val:": typing.Optional[str] = None"},{name:"repo_type",val:": typing.Optional[str] = None"},{name:"revision",val:": typing.Optional[str] = None"}],parametersDescription:[{anchor:"huggingface_hub.hf_hub_url.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
A namespace (user or an organization) name and a repo name separated
by a <code>/</code>.`,name:"repo_id"},{anchor:"huggingface_hub.hf_hub_url.filename",description:`<strong>filename</strong> (<code>str</code>) &#x2014;
The name of the file in the repo.`,name:"filename"},{anchor:"huggingface_hub.hf_hub_url.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional value corresponding to a folder inside the repo.`,name:"subfolder"},{anchor:"huggingface_hub.hf_hub_url.repo_type",description:`<strong>repo_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Set to <code>&quot;dataset&quot;</code> or <code>&quot;space&quot;</code> if uploading to a dataset or space,
<code>None</code> or <code>&quot;model&quot;</code> if uploading to a model. Default is <code>None</code>.`,name:"repo_type"},{anchor:"huggingface_hub.hf_hub_url.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>) &#x2014;
An optional Git revision id which can be a branch name, a tag, or a
commit hash.`,name:"revision"}],source:"https://github.com/huggingface/huggingface_hub/blob/vr_991/src/huggingface_hub/file_download.py#L157"}}),le=new zs({props:{anchor:"huggingface_hub.hf_hub_url.example",$$slots:{default:[Gs]},$$scope:{ctx:ve}}}),re=new Cn({props:{$$slots:{default:[Ks]},$$scope:{ctx:ve}}}),oo=new Io({}),ao=new Oo({props:{code:`<CACHE_DIR>
\u251C\u2500 <MODELS>
\u251C\u2500 <DATASETS>
\u251C\u2500 <SPACES>`,highlighted:`<span class="hljs-tag">&lt;<span class="hljs-name">CACHE_DIR</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">MODELS</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">DATASETS</span>&gt;</span>
\u251C\u2500 <span class="hljs-tag">&lt;<span class="hljs-name">SPACES</span>&gt;</span>`}}),to=new Oo({props:{code:`<CACHE_DIR>
\u251C\u2500 models--julien-c--EsperBERTo-small
\u251C\u2500 models--lysandrejik--arxiv-nlp
\u251C\u2500 models--bert-base-cased
\u251C\u2500 datasets--glue
\u251C\u2500 datasets--huggingface--DataMeasurementsFiles
\u251C\u2500 spaces--dalle-mini--dalle-mini`,highlighted:`&lt;<span class="hljs-comment">CACHE_DIR</span>&gt;
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">julien</span><span class="hljs-literal">-</span><span class="hljs-comment">c</span>--<span class="hljs-comment">EsperBERTo</span><span class="hljs-literal">-</span><span class="hljs-comment">small</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">lysandrejik</span>--<span class="hljs-comment">arxiv</span><span class="hljs-literal">-</span><span class="hljs-comment">nlp</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">models</span>--<span class="hljs-comment">bert</span><span class="hljs-literal">-</span><span class="hljs-comment">base</span><span class="hljs-literal">-</span><span class="hljs-comment">cased</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">datasets</span>--<span class="hljs-comment">glue</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">datasets</span>--<span class="hljs-comment">huggingface</span>--<span class="hljs-comment">DataMeasurementsFiles</span>
<span class="hljs-comment">\u251C\u2500</span> <span class="hljs-comment">spaces</span>--<span class="hljs-comment">dalle</span><span class="hljs-literal">-</span><span class="hljs-comment">mini</span>--<span class="hljs-comment">dalle</span><span class="hljs-literal">-</span><span class="hljs-comment">mini</span>`}}),no=new Oo({props:{code:`<CACHE_DIR>
\u251C\u2500 datasets--glue
\u2502  \u251C\u2500 refs
\u2502  \u251C\u2500 blobs
\u2502  \u251C\u2500 snapshots
...`,highlighted:`&lt;CACHE_DIR&gt;
\u251C\u2500 datasets<span class="hljs-params">--glue</span>
\u2502  \u251C\u2500 refs
\u2502  \u251C\u2500 blobs
\u2502  \u251C\u2500 snapshots
<span class="hljs-string">...</span>`}}),so=new Io({}),lo=new Io({}),ro=new Io({}),io=new Oo({props:{code:"<CACHE_DIR>/<REPO_NAME>/snapshots/aaaaaa/README.md",highlighted:'&lt;CACHE_DIR&gt;<span class="hljs-regexp">/&lt;REPO_NAME&gt;/</span>snapshots<span class="hljs-regexp">/aaaaaa/</span>README.md'}}),co=new Io({}),ho=new Oo({props:{code:`    [  96]  .
    \u2514\u2500\u2500 [ 160]  models--julien-c--EsperBERTo-small
        \u251C\u2500\u2500 [ 160]  blobs
        \u2502   \u251C\u2500\u2500 [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
        \u2502   \u251C\u2500\u2500 [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
        \u2502   \u2514\u2500\u2500 [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
        \u251C\u2500\u2500 [  96]  refs
        \u2502   \u2514\u2500\u2500 [  40]  main
        \u2514\u2500\u2500 [ 128]  snapshots
            \u251C\u2500\u2500 [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
            \u2502   \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
            \u2502   \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
            \u2514\u2500\u2500 [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
                \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
                \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`,highlighted:`    <span class="hljs-selector-attr">[  96]</span>  .
    \u2514\u2500\u2500 <span class="hljs-selector-attr">[ 160]</span>  models<span class="hljs-attr">--julien-c--EsperBERTo-small</span>
        \u251C\u2500\u2500 <span class="hljs-selector-attr">[ 160]</span>  blobs
        \u2502   \u251C\u2500\u2500 <span class="hljs-selector-attr">[321M]</span>  <span class="hljs-number">403450</span>e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
        \u2502   \u251C\u2500\u2500 <span class="hljs-selector-attr">[ 398]</span>  <span class="hljs-number">7</span>cb18dc9bafbfcf74629a4b760af1b160957a83e
        \u2502   \u2514\u2500\u2500 <span class="hljs-selector-attr">[1.4K]</span>  d7edf6bd2a681fb0175f7735299831ee1b22b812
        \u251C\u2500\u2500 <span class="hljs-selector-attr">[  96]</span>  refs
        \u2502   \u2514\u2500\u2500 <span class="hljs-selector-attr">[  40]</span>  <span class="hljs-selector-tag">main</span>
        \u2514\u2500\u2500 <span class="hljs-selector-attr">[ 128]</span>  snapshots
            \u251C\u2500\u2500 <span class="hljs-selector-attr">[ 128]</span>  <span class="hljs-number">2439</span>f60ef33a0d46d85da5001d52aeda5b00ce9f
            \u2502   \u251C\u2500\u2500 <span class="hljs-selector-attr">[  52]</span>  README<span class="hljs-selector-class">.md</span> -&gt; ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
            \u2502   \u2514\u2500\u2500 <span class="hljs-selector-attr">[  76]</span>  pytorch_model<span class="hljs-selector-class">.bin</span> -&gt; ../../blobs/<span class="hljs-number">403450</span>e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
            \u2514\u2500\u2500 <span class="hljs-selector-attr">[ 128]</span>  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
                \u251C\u2500\u2500 <span class="hljs-selector-attr">[  52]</span>  README<span class="hljs-selector-class">.md</span> -&gt; ../../blobs/<span class="hljs-number">7</span>cb18dc9bafbfcf74629a4b760af1b160957a83e
                \u2514\u2500\u2500 <span class="hljs-selector-attr">[  76]</span>  pytorch_model<span class="hljs-selector-class">.bin</span> -&gt; ../../blobs/<span class="hljs-number">403450</span>e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`}}),{c(){b=t("meta"),C=d(),_=t("h1"),f=t("a"),g=t("span"),P(u.$$.fragment),v=d(),M=t("span"),H=l("Downloading files"),y=d(),w=t("div"),P(T.$$.fragment),V=d(),k=t("p"),m=l("Download a given file if it\u2019s not already present in the local cache."),E=d(),U=t("p"),J=l("The new cache file layout looks like this:"),B=d(),j=t("ul"),x=t("li"),W=l("The cache directory contains one subfolder per repo_id (namespaced by repo type)"),pe=d(),Q=t("li"),N=l("inside each repo folder:"),$=t("ul"),I=t("li"),oe=l("refs is a list of the latest known revision => commit_hash pairs"),we=d(),X=t("li"),Ee=l(`blobs contains the actual file blobs (identified by their git-sha or sha256, depending on
whether they\u2019re LFS files or not)`),ue=d(),te=t("li"),ae=l(`snapshots contains one subfolder per commit, each \u201Ccommit\u201D contains the subset of the files
that have been resolved at that particular commit. Each filename is a symlink to the blob
at that particular commit.`),Y=d(),ne=t("p"),ye=l(`[  96]  .
\u2514\u2500\u2500 [ 160]  models\u2014julien-c\u2014EsperBERTo-small
\u251C\u2500\u2500 [ 160]  blobs
\u2502   \u251C\u2500\u2500 [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2502   \u251C\u2500\u2500 [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2502   \u2514\u2500\u2500 [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
\u251C\u2500\u2500 [  96]  refs
\u2502   \u2514\u2500\u2500 [  40]  main
\u2514\u2500\u2500 [ 128]  snapshots
\u251C\u2500\u2500 [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
\u2502   \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
\u2502   \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2514\u2500\u2500 [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
\u251C\u2500\u2500 [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`),Qe=d(),P(G.$$.fragment),me=d(),O=t("div"),P(be.$$.fragment),Xe=d(),se=t("p"),$e=l("Download all files of a repo."),Ye=d(),Ce=t("p"),K=l(`Downloads a whole snapshot of a repo\u2019s files at the specified revision. This
is useful when you want all files from a repo, because you don\u2019t know which
ones you will need a priori. All files are nested inside a folder in order
to keep their actual filename relative to that folder.`),je=d(),A=t("p"),Ae=l(`An alternative would be to just clone a repo but this would require that the
user always has git and git-lfs installed, and properly configured.`),po=d(),P(ge.$$.fragment),Ze=d(),D=t("div"),P(ke.$$.fragment),uo=d(),Ne=t("p"),mo=l("Construct the URL of a file from the given information."),bo=d(),_e=t("p"),go=l(`The resolved address can either be a huggingface.co-hosted url, or a link to
Cloudfront (a Content Delivery Network, or CDN) for large files which are
more than a few MBs.`),_o=d(),P(le.$$.fragment),vo=d(),P(re.$$.fragment),wo=d(),Ie=t("p"),Eo=l("References:"),at=d(),Po=t("ul"),yo=t("li"),tt=l("[1] "),eo=t("a"),nt=l("https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),_a=d(),Oe=t("h2"),Fe=t("a"),Ro=t("span"),P(oo.$$.fragment),st=d(),Lo=t("span"),lt=l("Caching"),va=d(),$o=t("p"),rt=l(`The methods displayed above are designed to work with a caching system that prevents re-downloading files.
The caching system was updated in v0.8.0 to allow directory structure and file sharing across
libraries that depend on the hub.`),wa=d(),jo=t("p"),it=l("The caching system is designed as follows:"),Ea=d(),P(ao.$$.fragment),ya=d(),ie=t("p"),ct=l("The "),So=t("code"),dt=l("<CACHE_DIR>"),ht=l(` is usually your user\u2019s home directory. However, it is customizable with the
`),Fo=t("code"),ft=l("cache_dir"),pt=l(" argument on all methods, or by specifying the "),qo=t("code"),ut=l("HF_HOME"),mt=l(" environment variable."),$a=d(),ko=t("p"),bt=l(`Models, datasets and spaces share a common root. Each of these repositories contains the namespace
(organization, username) if it exists, alongside the repository name:`),ja=d(),P(to.$$.fragment),ka=d(),Do=t("p"),gt=l(`It is within these folders that all files will now be downloaded from the hub. Caching ensures that
a file isn\u2019t downloaded twice if it already exists and wasn\u2019t updated; but if it was updated,
and you\u2019re asking for the latest file, then it will download the latest file (while keeping
the previous file intact in case you need it again).`),Da=d(),To=t("p"),_t=l("In order to achieve this, all folders contain the same skeleton:"),Ta=d(),P(no.$$.fragment),xa=d(),xo=t("p"),vt=l("Each folder is designed to contain the following:"),Ca=d(),Pe=t("h3"),qe=t("a"),Mo=t("span"),P(so.$$.fragment),wt=d(),Ho=t("span"),Et=l("Refs"),Aa=d(),Z=t("p"),yt=l("The "),Uo=t("code"),$t=l("refs"),jt=l(` folder contains files which indicates the latest revision of the given reference. For example,
if we have previously fetched a file from the `),Bo=t("code"),kt=l("main"),Dt=l(" branch of a repository, the "),zo=t("code"),Tt=l("refs"),xt=l(`
folder will contain a file named `),Vo=t("code"),Ct=l("main"),At=l(", which will itself contain the commit identifier of the current head."),Na=d(),ce=t("p"),Nt=l("If the latest commit of "),Wo=t("code"),It=l("main"),Ot=l(" has "),Go=t("code"),Pt=l("aaaaaa"),Rt=l(" as identifier, then it will contain "),Ko=t("code"),Lt=l("aaaaaa"),St=l("."),Ia=d(),de=t("p"),Ft=l("If that same branch gets updated with a new commit, that has "),Jo=t("code"),qt=l("bbbbbb"),Mt=l(` as an identifier, then
redownloading a file from that reference will update the `),Qo=t("code"),Ht=l("refs/main"),Ut=l(" file to contain "),Xo=t("code"),Bt=l("bbbbbb"),zt=l("."),Oa=d(),Re=t("h3"),Me=t("a"),Yo=t("span"),P(lo.$$.fragment),Vt=d(),Zo=t("span"),Wt=l("Blobs"),Pa=d(),He=t("p"),Gt=l("The "),ea=t("code"),Kt=l("blobs"),Jt=l(" folder contains the actual files that we have downloaded. The name of each file is their hash."),Ra=d(),Le=t("h3"),Ue=t("a"),oa=t("span"),P(ro.$$.fragment),Qt=d(),aa=t("span"),Xt=l("Snapshots"),La=d(),Be=t("p"),Yt=l("The "),ta=t("code"),Zt=l("snapshots"),en=l(` folder contains symlinks to the blobs mentioned above. It is itself made up of several folders:
one per known revision!`),Sa=d(),z=t("p"),on=l("In the explanation above, we had initially fetched a file from the "),na=t("code"),an=l("aaaaaa"),tn=l(` revision, before fetching a file from
the `),sa=t("code"),nn=l("bbbbbb"),sn=l(" revision. In this situation, we would now have two folders in the "),la=t("code"),ln=l("snapshots"),rn=l(" folder: "),ra=t("code"),cn=l("aaaaaa"),dn=l(`
and `),ia=t("code"),hn=l("bbbbbb"),fn=l("."),Fa=d(),De=t("p"),pn=l(`In each of these folders, live symlinks that have the names of the files that we have downloaded. For example,
if we had downloaded the `),ca=t("code"),un=l("READMD.md"),mn=l(" file at revision "),da=t("code"),bn=l("aaaaaa"),gn=l(", we would have the following path:"),qa=d(),P(io.$$.fragment),Ma=d(),ze=t("p"),_n=l("That "),ha=t("code"),vn=l("README.md"),wn=l(" file is actually a symlink linking to the blob that has the hash of the file."),Ha=d(),Ve=t("p"),En=l(`Creating the skeleton this way means opens up the mechanism to file sharing: if the same file was fetched in
revision `),fa=t("code"),yn=l("bbbbbb"),$n=l(", it would have the same hash and the file would not need to be redownloaded."),Ua=d(),Se=t("h3"),We=t("a"),pa=t("span"),P(co.$$.fragment),jn=d(),ua=t("span"),kn=l("In practice"),Ba=d(),Co=t("p"),Dn=l("In practice, it should look like the following tree in your cache:"),za=d(),P(ho.$$.fragment),this.h()},l(o){const i=Hs('[data-svelte="svelte-1phssyn"]',document.head);b=n(i,"META",{name:!0,content:!0}),i.forEach(a),C=h(o),_=n(o,"H1",{class:!0});var fo=s(_);f=n(fo,"A",{id:!0,class:!0,href:!0});var ma=s(f);g=n(ma,"SPAN",{});var ba=s(g);R(u.$$.fragment,ba),ba.forEach(a),ma.forEach(a),v=h(fo),M=n(fo,"SPAN",{});var ga=s(M);H=r(ga,"Downloading files"),ga.forEach(a),fo.forEach(a),y=h(o),w=n(o,"DIV",{class:!0});var he=s(w);R(T.$$.fragment,he),V=h(he),k=n(he,"P",{});var Nn=s(k);m=r(Nn,"Download a given file if it\u2019s not already present in the local cache."),Nn.forEach(a),E=h(he),U=n(he,"P",{});var In=s(U);J=r(In,"The new cache file layout looks like this:"),In.forEach(a),B=h(he),j=n(he,"UL",{});var Wa=s(j);x=n(Wa,"LI",{});var On=s(x);W=r(On,"The cache directory contains one subfolder per repo_id (namespaced by repo type)"),On.forEach(a),pe=h(Wa),Q=n(Wa,"LI",{});var Tn=s(Q);N=r(Tn,"inside each repo folder:"),$=n(Tn,"UL",{});var Ao=s($);I=n(Ao,"LI",{});var Pn=s(I);oe=r(Pn,"refs is a list of the latest known revision => commit_hash pairs"),Pn.forEach(a),we=h(Ao),X=n(Ao,"LI",{});var Rn=s(X);Ee=r(Rn,`blobs contains the actual file blobs (identified by their git-sha or sha256, depending on
whether they\u2019re LFS files or not)`),Rn.forEach(a),ue=h(Ao),te=n(Ao,"LI",{});var Ln=s(te);ae=r(Ln,`snapshots contains one subfolder per commit, each \u201Ccommit\u201D contains the subset of the files
that have been resolved at that particular commit. Each filename is a symlink to the blob
at that particular commit.`),Ln.forEach(a),Ao.forEach(a),Tn.forEach(a),Wa.forEach(a),Y=h(he),ne=n(he,"P",{});var Sn=s(ne);ye=r(Sn,`[  96]  .
\u2514\u2500\u2500 [ 160]  models\u2014julien-c\u2014EsperBERTo-small
\u251C\u2500\u2500 [ 160]  blobs
\u2502   \u251C\u2500\u2500 [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2502   \u251C\u2500\u2500 [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2502   \u2514\u2500\u2500 [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812
\u251C\u2500\u2500 [  96]  refs
\u2502   \u2514\u2500\u2500 [  40]  main
\u2514\u2500\u2500 [ 128]  snapshots
\u251C\u2500\u2500 [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f
\u2502   \u251C\u2500\u2500 [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812
\u2502   \u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd
\u2514\u2500\u2500 [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48
\u251C\u2500\u2500 [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e
\u2514\u2500\u2500 [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd`),Sn.forEach(a),Qe=h(he),R(G.$$.fragment,he),he.forEach(a),me=h(o),O=n(o,"DIV",{class:!0});var Te=s(O);R(be.$$.fragment,Te),Xe=h(Te),se=n(Te,"P",{});var Fn=s(se);$e=r(Fn,"Download all files of a repo."),Fn.forEach(a),Ye=h(Te),Ce=n(Te,"P",{});var qn=s(Ce);K=r(qn,`Downloads a whole snapshot of a repo\u2019s files at the specified revision. This
is useful when you want all files from a repo, because you don\u2019t know which
ones you will need a priori. All files are nested inside a folder in order
to keep their actual filename relative to that folder.`),qn.forEach(a),je=h(Te),A=n(Te,"P",{});var Mn=s(A);Ae=r(Mn,`An alternative would be to just clone a repo but this would require that the
user always has git and git-lfs installed, and properly configured.`),Mn.forEach(a),po=h(Te),R(ge.$$.fragment,Te),Te.forEach(a),Ze=h(o),D=n(o,"DIV",{class:!0});var ee=s(D);R(ke.$$.fragment,ee),uo=h(ee),Ne=n(ee,"P",{});var Hn=s(Ne);mo=r(Hn,"Construct the URL of a file from the given information."),Hn.forEach(a),bo=h(ee),_e=n(ee,"P",{});var Un=s(_e);go=r(Un,`The resolved address can either be a huggingface.co-hosted url, or a link to
Cloudfront (a Content Delivery Network, or CDN) for large files which are
more than a few MBs.`),Un.forEach(a),_o=h(ee),R(le.$$.fragment,ee),vo=h(ee),R(re.$$.fragment,ee),wo=h(ee),Ie=n(ee,"P",{});var Bn=s(Ie);Eo=r(Bn,"References:"),Bn.forEach(a),at=h(ee),Po=n(ee,"UL",{});var zn=s(Po);yo=n(zn,"LI",{});var xn=s(yo);tt=r(xn,"[1] "),eo=n(xn,"A",{href:!0,rel:!0});var Vn=s(eo);nt=r(Vn,"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),Vn.forEach(a),xn.forEach(a),zn.forEach(a),ee.forEach(a),_a=h(o),Oe=n(o,"H2",{class:!0});var Ga=s(Oe);Fe=n(Ga,"A",{id:!0,class:!0,href:!0});var Wn=s(Fe);Ro=n(Wn,"SPAN",{});var Gn=s(Ro);R(oo.$$.fragment,Gn),Gn.forEach(a),Wn.forEach(a),st=h(Ga),Lo=n(Ga,"SPAN",{});var Kn=s(Lo);lt=r(Kn,"Caching"),Kn.forEach(a),Ga.forEach(a),va=h(o),$o=n(o,"P",{});var Jn=s($o);rt=r(Jn,`The methods displayed above are designed to work with a caching system that prevents re-downloading files.
The caching system was updated in v0.8.0 to allow directory structure and file sharing across
libraries that depend on the hub.`),Jn.forEach(a),wa=h(o),jo=n(o,"P",{});var Qn=s(jo);it=r(Qn,"The caching system is designed as follows:"),Qn.forEach(a),Ea=h(o),R(ao.$$.fragment,o),ya=h(o),ie=n(o,"P",{});var Ge=s(ie);ct=r(Ge,"The "),So=n(Ge,"CODE",{});var Xn=s(So);dt=r(Xn,"<CACHE_DIR>"),Xn.forEach(a),ht=r(Ge,` is usually your user\u2019s home directory. However, it is customizable with the
`),Fo=n(Ge,"CODE",{});var Yn=s(Fo);ft=r(Yn,"cache_dir"),Yn.forEach(a),pt=r(Ge," argument on all methods, or by specifying the "),qo=n(Ge,"CODE",{});var Zn=s(qo);ut=r(Zn,"HF_HOME"),Zn.forEach(a),mt=r(Ge," environment variable."),Ge.forEach(a),$a=h(o),ko=n(o,"P",{});var es=s(ko);bt=r(es,`Models, datasets and spaces share a common root. Each of these repositories contains the namespace
(organization, username) if it exists, alongside the repository name:`),es.forEach(a),ja=h(o),R(to.$$.fragment,o),ka=h(o),Do=n(o,"P",{});var os=s(Do);gt=r(os,`It is within these folders that all files will now be downloaded from the hub. Caching ensures that
a file isn\u2019t downloaded twice if it already exists and wasn\u2019t updated; but if it was updated,
and you\u2019re asking for the latest file, then it will download the latest file (while keeping
the previous file intact in case you need it again).`),os.forEach(a),Da=h(o),To=n(o,"P",{});var as=s(To);_t=r(as,"In order to achieve this, all folders contain the same skeleton:"),as.forEach(a),Ta=h(o),R(no.$$.fragment,o),xa=h(o),xo=n(o,"P",{});var ts=s(xo);vt=r(ts,"Each folder is designed to contain the following:"),ts.forEach(a),Ca=h(o),Pe=n(o,"H3",{class:!0});var Ka=s(Pe);qe=n(Ka,"A",{id:!0,class:!0,href:!0});var ns=s(qe);Mo=n(ns,"SPAN",{});var ss=s(Mo);R(so.$$.fragment,ss),ss.forEach(a),ns.forEach(a),wt=h(Ka),Ho=n(Ka,"SPAN",{});var ls=s(Ho);Et=r(ls,"Refs"),ls.forEach(a),Ka.forEach(a),Aa=h(o),Z=n(o,"P",{});var xe=s(Z);yt=r(xe,"The "),Uo=n(xe,"CODE",{});var rs=s(Uo);$t=r(rs,"refs"),rs.forEach(a),jt=r(xe,` folder contains files which indicates the latest revision of the given reference. For example,
if we have previously fetched a file from the `),Bo=n(xe,"CODE",{});var is=s(Bo);kt=r(is,"main"),is.forEach(a),Dt=r(xe," branch of a repository, the "),zo=n(xe,"CODE",{});var cs=s(zo);Tt=r(cs,"refs"),cs.forEach(a),xt=r(xe,`
folder will contain a file named `),Vo=n(xe,"CODE",{});var ds=s(Vo);Ct=r(ds,"main"),ds.forEach(a),At=r(xe,", which will itself contain the commit identifier of the current head."),xe.forEach(a),Na=h(o),ce=n(o,"P",{});var Ke=s(ce);Nt=r(Ke,"If the latest commit of "),Wo=n(Ke,"CODE",{});var hs=s(Wo);It=r(hs,"main"),hs.forEach(a),Ot=r(Ke," has "),Go=n(Ke,"CODE",{});var fs=s(Go);Pt=r(fs,"aaaaaa"),fs.forEach(a),Rt=r(Ke," as identifier, then it will contain "),Ko=n(Ke,"CODE",{});var ps=s(Ko);Lt=r(ps,"aaaaaa"),ps.forEach(a),St=r(Ke,"."),Ke.forEach(a),Ia=h(o),de=n(o,"P",{});var Je=s(de);Ft=r(Je,"If that same branch gets updated with a new commit, that has "),Jo=n(Je,"CODE",{});var us=s(Jo);qt=r(us,"bbbbbb"),us.forEach(a),Mt=r(Je,` as an identifier, then
redownloading a file from that reference will update the `),Qo=n(Je,"CODE",{});var ms=s(Qo);Ht=r(ms,"refs/main"),ms.forEach(a),Ut=r(Je," file to contain "),Xo=n(Je,"CODE",{});var bs=s(Xo);Bt=r(bs,"bbbbbb"),bs.forEach(a),zt=r(Je,"."),Je.forEach(a),Oa=h(o),Re=n(o,"H3",{class:!0});var Ja=s(Re);Me=n(Ja,"A",{id:!0,class:!0,href:!0});var gs=s(Me);Yo=n(gs,"SPAN",{});var _s=s(Yo);R(lo.$$.fragment,_s),_s.forEach(a),gs.forEach(a),Vt=h(Ja),Zo=n(Ja,"SPAN",{});var vs=s(Zo);Wt=r(vs,"Blobs"),vs.forEach(a),Ja.forEach(a),Pa=h(o),He=n(o,"P",{});var Qa=s(He);Gt=r(Qa,"The "),ea=n(Qa,"CODE",{});var ws=s(ea);Kt=r(ws,"blobs"),ws.forEach(a),Jt=r(Qa," folder contains the actual files that we have downloaded. The name of each file is their hash."),Qa.forEach(a),Ra=h(o),Le=n(o,"H3",{class:!0});var Xa=s(Le);Ue=n(Xa,"A",{id:!0,class:!0,href:!0});var Es=s(Ue);oa=n(Es,"SPAN",{});var ys=s(oa);R(ro.$$.fragment,ys),ys.forEach(a),Es.forEach(a),Qt=h(Xa),aa=n(Xa,"SPAN",{});var $s=s(aa);Xt=r($s,"Snapshots"),$s.forEach(a),Xa.forEach(a),La=h(o),Be=n(o,"P",{});var Ya=s(Be);Yt=r(Ya,"The "),ta=n(Ya,"CODE",{});var js=s(ta);Zt=r(js,"snapshots"),js.forEach(a),en=r(Ya,` folder contains symlinks to the blobs mentioned above. It is itself made up of several folders:
one per known revision!`),Ya.forEach(a),Sa=h(o),z=n(o,"P",{});var fe=s(z);on=r(fe,"In the explanation above, we had initially fetched a file from the "),na=n(fe,"CODE",{});var ks=s(na);an=r(ks,"aaaaaa"),ks.forEach(a),tn=r(fe,` revision, before fetching a file from
the `),sa=n(fe,"CODE",{});var Ds=s(sa);nn=r(Ds,"bbbbbb"),Ds.forEach(a),sn=r(fe," revision. In this situation, we would now have two folders in the "),la=n(fe,"CODE",{});var Ts=s(la);ln=r(Ts,"snapshots"),Ts.forEach(a),rn=r(fe," folder: "),ra=n(fe,"CODE",{});var xs=s(ra);cn=r(xs,"aaaaaa"),xs.forEach(a),dn=r(fe,`
and `),ia=n(fe,"CODE",{});var Cs=s(ia);hn=r(Cs,"bbbbbb"),Cs.forEach(a),fn=r(fe,"."),fe.forEach(a),Fa=h(o),De=n(o,"P",{});var No=s(De);pn=r(No,`In each of these folders, live symlinks that have the names of the files that we have downloaded. For example,
if we had downloaded the `),ca=n(No,"CODE",{});var As=s(ca);un=r(As,"READMD.md"),As.forEach(a),mn=r(No," file at revision "),da=n(No,"CODE",{});var Ns=s(da);bn=r(Ns,"aaaaaa"),Ns.forEach(a),gn=r(No,", we would have the following path:"),No.forEach(a),qa=h(o),R(io.$$.fragment,o),Ma=h(o),ze=n(o,"P",{});var Za=s(ze);_n=r(Za,"That "),ha=n(Za,"CODE",{});var Is=s(ha);vn=r(Is,"README.md"),Is.forEach(a),wn=r(Za," file is actually a symlink linking to the blob that has the hash of the file."),Za.forEach(a),Ha=h(o),Ve=n(o,"P",{});var et=s(Ve);En=r(et,`Creating the skeleton this way means opens up the mechanism to file sharing: if the same file was fetched in
revision `),fa=n(et,"CODE",{});var Os=s(fa);yn=r(Os,"bbbbbb"),Os.forEach(a),$n=r(et,", it would have the same hash and the file would not need to be redownloaded."),et.forEach(a),Ua=h(o),Se=n(o,"H3",{class:!0});var ot=s(Se);We=n(ot,"A",{id:!0,class:!0,href:!0});var Ps=s(We);pa=n(Ps,"SPAN",{});var Rs=s(pa);R(co.$$.fragment,Rs),Rs.forEach(a),Ps.forEach(a),jn=h(ot),ua=n(ot,"SPAN",{});var Ls=s(ua);kn=r(Ls,"In practice"),Ls.forEach(a),ot.forEach(a),Ba=h(o),Co=n(o,"P",{});var Ss=s(Co);Dn=r(Ss,"In practice, it should look like the following tree in your cache:"),Ss.forEach(a),za=h(o),R(ho.$$.fragment,o),this.h()},h(){p(b,"name","hf:doc:metadata"),p(b,"content",JSON.stringify(Qs)),p(f,"id","huggingface_hub.hf_hub_download"),p(f,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(f,"href","#huggingface_hub.hf_hub_download"),p(_,"class","relative group"),p(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(eo,"href","https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag"),p(eo,"rel","nofollow"),p(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),p(Fe,"id","caching"),p(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Fe,"href","#caching"),p(Oe,"class","relative group"),p(qe,"id","refs"),p(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(qe,"href","#refs"),p(Pe,"class","relative group"),p(Me,"id","blobs"),p(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Me,"href","#blobs"),p(Re,"class","relative group"),p(Ue,"id","snapshots"),p(Ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Ue,"href","#snapshots"),p(Le,"class","relative group"),p(We,"id","in-practice"),p(We,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(We,"href","#in-practice"),p(Se,"class","relative group")},m(o,i){e(document.head,b),c(o,C,i),c(o,_,i),e(_,f),e(f,g),L(u,g,null),e(_,v),e(_,M),e(M,H),c(o,y,i),c(o,w,i),L(T,w,null),e(w,V),e(w,k),e(k,m),e(w,E),e(w,U),e(U,J),e(w,B),e(w,j),e(j,x),e(x,W),e(j,pe),e(j,Q),e(Q,N),e(Q,$),e($,I),e(I,oe),e($,we),e($,X),e(X,Ee),e($,ue),e($,te),e(te,ae),e(w,Y),e(w,ne),e(ne,ye),e(w,Qe),L(G,w,null),c(o,me,i),c(o,O,i),L(be,O,null),e(O,Xe),e(O,se),e(se,$e),e(O,Ye),e(O,Ce),e(Ce,K),e(O,je),e(O,A),e(A,Ae),e(O,po),L(ge,O,null),c(o,Ze,i),c(o,D,i),L(ke,D,null),e(D,uo),e(D,Ne),e(Ne,mo),e(D,bo),e(D,_e),e(_e,go),e(D,_o),L(le,D,null),e(D,vo),L(re,D,null),e(D,wo),e(D,Ie),e(Ie,Eo),e(D,at),e(D,Po),e(Po,yo),e(yo,tt),e(yo,eo),e(eo,nt),c(o,_a,i),c(o,Oe,i),e(Oe,Fe),e(Fe,Ro),L(oo,Ro,null),e(Oe,st),e(Oe,Lo),e(Lo,lt),c(o,va,i),c(o,$o,i),e($o,rt),c(o,wa,i),c(o,jo,i),e(jo,it),c(o,Ea,i),L(ao,o,i),c(o,ya,i),c(o,ie,i),e(ie,ct),e(ie,So),e(So,dt),e(ie,ht),e(ie,Fo),e(Fo,ft),e(ie,pt),e(ie,qo),e(qo,ut),e(ie,mt),c(o,$a,i),c(o,ko,i),e(ko,bt),c(o,ja,i),L(to,o,i),c(o,ka,i),c(o,Do,i),e(Do,gt),c(o,Da,i),c(o,To,i),e(To,_t),c(o,Ta,i),L(no,o,i),c(o,xa,i),c(o,xo,i),e(xo,vt),c(o,Ca,i),c(o,Pe,i),e(Pe,qe),e(qe,Mo),L(so,Mo,null),e(Pe,wt),e(Pe,Ho),e(Ho,Et),c(o,Aa,i),c(o,Z,i),e(Z,yt),e(Z,Uo),e(Uo,$t),e(Z,jt),e(Z,Bo),e(Bo,kt),e(Z,Dt),e(Z,zo),e(zo,Tt),e(Z,xt),e(Z,Vo),e(Vo,Ct),e(Z,At),c(o,Na,i),c(o,ce,i),e(ce,Nt),e(ce,Wo),e(Wo,It),e(ce,Ot),e(ce,Go),e(Go,Pt),e(ce,Rt),e(ce,Ko),e(Ko,Lt),e(ce,St),c(o,Ia,i),c(o,de,i),e(de,Ft),e(de,Jo),e(Jo,qt),e(de,Mt),e(de,Qo),e(Qo,Ht),e(de,Ut),e(de,Xo),e(Xo,Bt),e(de,zt),c(o,Oa,i),c(o,Re,i),e(Re,Me),e(Me,Yo),L(lo,Yo,null),e(Re,Vt),e(Re,Zo),e(Zo,Wt),c(o,Pa,i),c(o,He,i),e(He,Gt),e(He,ea),e(ea,Kt),e(He,Jt),c(o,Ra,i),c(o,Le,i),e(Le,Ue),e(Ue,oa),L(ro,oa,null),e(Le,Qt),e(Le,aa),e(aa,Xt),c(o,La,i),c(o,Be,i),e(Be,Yt),e(Be,ta),e(ta,Zt),e(Be,en),c(o,Sa,i),c(o,z,i),e(z,on),e(z,na),e(na,an),e(z,tn),e(z,sa),e(sa,nn),e(z,sn),e(z,la),e(la,ln),e(z,rn),e(z,ra),e(ra,cn),e(z,dn),e(z,ia),e(ia,hn),e(z,fn),c(o,Fa,i),c(o,De,i),e(De,pn),e(De,ca),e(ca,un),e(De,mn),e(De,da),e(da,bn),e(De,gn),c(o,qa,i),L(io,o,i),c(o,Ma,i),c(o,ze,i),e(ze,_n),e(ze,ha),e(ha,vn),e(ze,wn),c(o,Ha,i),c(o,Ve,i),e(Ve,En),e(Ve,fa),e(fa,yn),e(Ve,$n),c(o,Ua,i),c(o,Se,i),e(Se,We),e(We,pa),L(co,pa,null),e(Se,jn),e(Se,ua),e(ua,kn),c(o,Ba,i),c(o,Co,i),e(Co,Dn),c(o,za,i),L(ho,o,i),Va=!0},p(o,[i]){const fo={};i&2&&(fo.$$scope={dirty:i,ctx:o}),G.$set(fo);const ma={};i&2&&(ma.$$scope={dirty:i,ctx:o}),ge.$set(ma);const ba={};i&2&&(ba.$$scope={dirty:i,ctx:o}),le.$set(ba);const ga={};i&2&&(ga.$$scope={dirty:i,ctx:o}),re.$set(ga)},i(o){Va||(S(u.$$.fragment,o),S(T.$$.fragment,o),S(G.$$.fragment,o),S(be.$$.fragment,o),S(ge.$$.fragment,o),S(ke.$$.fragment,o),S(le.$$.fragment,o),S(re.$$.fragment,o),S(oo.$$.fragment,o),S(ao.$$.fragment,o),S(to.$$.fragment,o),S(no.$$.fragment,o),S(so.$$.fragment,o),S(lo.$$.fragment,o),S(ro.$$.fragment,o),S(io.$$.fragment,o),S(co.$$.fragment,o),S(ho.$$.fragment,o),Va=!0)},o(o){F(u.$$.fragment,o),F(T.$$.fragment,o),F(G.$$.fragment,o),F(be.$$.fragment,o),F(ge.$$.fragment,o),F(ke.$$.fragment,o),F(le.$$.fragment,o),F(re.$$.fragment,o),F(oo.$$.fragment,o),F(ao.$$.fragment,o),F(to.$$.fragment,o),F(no.$$.fragment,o),F(so.$$.fragment,o),F(lo.$$.fragment,o),F(ro.$$.fragment,o),F(io.$$.fragment,o),F(co.$$.fragment,o),F(ho.$$.fragment,o),Va=!1},d(o){a(b),o&&a(C),o&&a(_),q(u),o&&a(y),o&&a(w),q(T),q(G),o&&a(me),o&&a(O),q(be),q(ge),o&&a(Ze),o&&a(D),q(ke),q(le),q(re),o&&a(_a),o&&a(Oe),q(oo),o&&a(va),o&&a($o),o&&a(wa),o&&a(jo),o&&a(Ea),q(ao,o),o&&a(ya),o&&a(ie),o&&a($a),o&&a(ko),o&&a(ja),q(to,o),o&&a(ka),o&&a(Do),o&&a(Da),o&&a(To),o&&a(Ta),q(no,o),o&&a(xa),o&&a(xo),o&&a(Ca),o&&a(Pe),q(so),o&&a(Aa),o&&a(Z),o&&a(Na),o&&a(ce),o&&a(Ia),o&&a(de),o&&a(Oa),o&&a(Re),q(lo),o&&a(Pa),o&&a(He),o&&a(Ra),o&&a(Le),q(ro),o&&a(La),o&&a(Be),o&&a(Sa),o&&a(z),o&&a(Fa),o&&a(De),o&&a(qa),q(io,o),o&&a(Ma),o&&a(ze),o&&a(Ha),o&&a(Ve),o&&a(Ua),o&&a(Se),q(co),o&&a(Ba),o&&a(Co),o&&a(za),q(ho,o)}}}const Qs={local:"huggingface_hub.hf_hub_download",sections:[{local:"caching",sections:[{local:"refs",title:"Refs"},{local:"blobs",title:"Blobs"},{local:"snapshots",title:"Snapshots"},{local:"in-practice",title:"In practice"}],title:"Caching"}],title:"Downloading files"};function Xs(ve){return Us(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class nl extends Fs{constructor(b){super();qs(this,b,Xs,Js,Ms,{})}}export{nl as default,Qs as metadata};
