import{S as Ss,i as Us,s as zs,e as n,k as m,w as D,t as o,M as Fs,c as i,d as s,m as f,a as p,x as L,h as r,b as c,N as _s,G as e,g as l,y as B,L as Gs,q as T,o as N,B as O,v as Ys}from"../chunks/vendor-hf-doc-builder.js";import{I as Hs}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as W}from"../chunks/CodeBlock-hf-doc-builder.js";function Js(ys){let g,pa,u,y,X,w,Ta,Z,Na,ra,M,Oa,ma,h,Ma,aa,Ra,Sa,sa,Ua,za,fa,k,ca,v,Fa,x,Ga,Ya,ha,R,Ha,da,E,ga,S,Ja,ua,d,U,ea,Va,Ka,Qa,z,ta,Wa,Xa,Za,F,la,as,ss,_a,G,es,ya,I,na,vs,va,j,ts,ia,ls,ns,ja,C,$a,Y,is,ba,P,wa,$,os,H,ps,rs,ka,q,xa,b,ms,oa,fs,cs,Ea,A,Ia,_,J,js,hs,V,$s,Ca;return w=new Hs({}),k=new W({props:{code:"pip install -U albumentations opencv-python",highlighted:"pip install -U albumentations opencv-python"}}),E=new W({props:{code:`from datasets import load_dataset

dataset = load_dataset("beans")
dataset["train"][10]`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;beans&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">10</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x500 at <span class="hljs-number">0x7F8D2F4D7A10</span>&gt;,
 <span class="hljs-string">&#x27;image_file_path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/b0a21163f78769a2cf11f58dfc767fb458fc7cea5c05dccc0144a2c0f0bc1292/train/angular_leaf_spot/angular_leaf_spot_train.204.jpg&#x27;</span>,
 <span class="hljs-string">&#x27;labels&#x27;</span>: <span class="hljs-number">0</span>}`}}),C=new W({props:{code:`import cv2
import albumentations as A
import numpy as np

transform = A.Compose([
    A.RandomCrop(width=256, height=256),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
])`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> cv2
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> albumentations <span class="hljs-keyword">as</span> A
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-meta">&gt;&gt;&gt; </span>transform = A.Compose([
<span class="hljs-meta">... </span>    A.RandomCrop(width=<span class="hljs-number">256</span>, height=<span class="hljs-number">256</span>),
<span class="hljs-meta">... </span>    A.HorizontalFlip(p=<span class="hljs-number">0.5</span>),
<span class="hljs-meta">... </span>    A.RandomBrightnessContrast(p=<span class="hljs-number">0.2</span>),
<span class="hljs-meta">... </span>])`}}),P=new W({props:{code:`def transforms(examples):
    examples["pixel_values"] = [
        transform(image=np.array(image))["image"] for image in examples["image"]
    ]

    return examples`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [
<span class="hljs-meta">... </span>        transform(image=np.array(image))[<span class="hljs-string">&quot;image&quot;</span>] <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`}}),q=new W({props:{code:"dataset.set_transform(transforms)",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)'}}),A=new W({props:{code:`import numpy as np
import matplotlib.pyplot as plt

img = dataset["train"][0]["pixel_values"]
plt.imshow(img)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img)`}}),{c(){g=n("meta"),pa=m(),u=n("h1"),y=n("a"),X=n("span"),D(w.$$.fragment),Ta=m(),Z=n("span"),Na=o("Image classification"),ra=m(),M=n("p"),Oa=o("Image classification datasets are used to train a model to classify an entire image. There are a wide variety of applications enabled by these datasets such as identifying endangered wildlife species or screening for disease in medical images. This guide will show you how to apply transformations to an image classification dataset."),ma=m(),h=n("p"),Ma=o("Before you start, make sure you have up-to-date versions of "),aa=n("code"),Ra=o("albumentations"),Sa=o(" and "),sa=n("code"),Ua=o("cv2"),za=o(" installed:"),fa=m(),D(k.$$.fragment),ca=m(),v=n("p"),Fa=o("This guide uses the "),x=n("a"),Ga=o("Beans"),Ya=o(" dataset for identifying the type of bean plant disease based on an image of its leaf."),ha=m(),R=n("p"),Ha=o("Load the dataset and take a look at an example:"),da=m(),D(E.$$.fragment),ga=m(),S=n("p"),Ja=o("The dataset has three fields:"),ua=m(),d=n("ul"),U=n("li"),ea=n("code"),Va=o("image"),Ka=o(": a PIL image object."),Qa=m(),z=n("li"),ta=n("code"),Wa=o("image_file_path"),Xa=o(": the path to the image file."),Za=m(),F=n("li"),la=n("code"),as=o("labels"),ss=o(": the label or category of the image."),_a=m(),G=n("p"),es=o("Next, check out an image:"),ya=m(),I=n("div"),na=n("img"),va=m(),j=n("p"),ts=o("Now apply some augmentations with "),ia=n("code"),ls=o("albumentations"),ns=o(". You\u2019ll randomly crop the image, flip it horizontally, and adjust its brightness."),ja=m(),D(C.$$.fragment),$a=m(),Y=n("p"),is=o("Create a function to apply the transformation to the images:"),ba=m(),D(P.$$.fragment),wa=m(),$=n("p"),os=o("Use the "),H=n("a"),ps=o("set_transform()"),rs=o(" function to apply the transformation on-the-fly to batches of the dataset to consume less disk space:"),ka=m(),D(q.$$.fragment),xa=m(),b=n("p"),ms=o("You can verify the transformation worked by indexing into the "),oa=n("code"),fs=o("pixel_values"),cs=o(" of the first example:"),Ea=m(),D(A.$$.fragment),Ia=m(),_=n("div"),J=n("img"),hs=m(),V=n("img"),this.h()},l(a){const t=Fs('[data-svelte="svelte-1phssyn"]',document.head);g=i(t,"META",{name:!0,content:!0}),t.forEach(s),pa=f(a),u=i(a,"H1",{class:!0});var Pa=p(u);y=i(Pa,"A",{id:!0,class:!0,href:!0});var bs=p(y);X=i(bs,"SPAN",{});var ws=p(X);L(w.$$.fragment,ws),ws.forEach(s),bs.forEach(s),Ta=f(Pa),Z=i(Pa,"SPAN",{});var ks=p(Z);Na=r(ks,"Image classification"),ks.forEach(s),Pa.forEach(s),ra=f(a),M=i(a,"P",{});var xs=p(M);Oa=r(xs,"Image classification datasets are used to train a model to classify an entire image. There are a wide variety of applications enabled by these datasets such as identifying endangered wildlife species or screening for disease in medical images. This guide will show you how to apply transformations to an image classification dataset."),xs.forEach(s),ma=f(a),h=i(a,"P",{});var K=p(h);Ma=r(K,"Before you start, make sure you have up-to-date versions of "),aa=i(K,"CODE",{});var Es=p(aa);Ra=r(Es,"albumentations"),Es.forEach(s),Sa=r(K," and "),sa=i(K,"CODE",{});var Is=p(sa);Ua=r(Is,"cv2"),Is.forEach(s),za=r(K," installed:"),K.forEach(s),fa=f(a),L(k.$$.fragment,a),ca=f(a),v=i(a,"P",{});var qa=p(v);Fa=r(qa,"This guide uses the "),x=i(qa,"A",{href:!0,rel:!0});var Cs=p(x);Ga=r(Cs,"Beans"),Cs.forEach(s),Ya=r(qa," dataset for identifying the type of bean plant disease based on an image of its leaf."),qa.forEach(s),ha=f(a),R=i(a,"P",{});var Ps=p(R);Ha=r(Ps,"Load the dataset and take a look at an example:"),Ps.forEach(s),da=f(a),L(E.$$.fragment,a),ga=f(a),S=i(a,"P",{});var qs=p(S);Ja=r(qs,"The dataset has three fields:"),qs.forEach(s),ua=f(a),d=i(a,"UL",{});var Q=p(d);U=i(Q,"LI",{});var ds=p(U);ea=i(ds,"CODE",{});var As=p(ea);Va=r(As,"image"),As.forEach(s),Ka=r(ds,": a PIL image object."),ds.forEach(s),Qa=f(Q),z=i(Q,"LI",{});var gs=p(z);ta=i(gs,"CODE",{});var Ds=p(ta);Wa=r(Ds,"image_file_path"),Ds.forEach(s),Xa=r(gs,": the path to the image file."),gs.forEach(s),Za=f(Q),F=i(Q,"LI",{});var us=p(F);la=i(us,"CODE",{});var Ls=p(la);as=r(Ls,"labels"),Ls.forEach(s),ss=r(us,": the label or category of the image."),us.forEach(s),Q.forEach(s),_a=f(a),G=i(a,"P",{});var Bs=p(G);es=r(Bs,"Next, check out an image:"),Bs.forEach(s),ya=f(a),I=i(a,"DIV",{class:!0});var Ts=p(I);na=i(Ts,"IMG",{src:!0}),Ts.forEach(s),va=f(a),j=i(a,"P",{});var Aa=p(j);ts=r(Aa,"Now apply some augmentations with "),ia=i(Aa,"CODE",{});var Ns=p(ia);ls=r(Ns,"albumentations"),Ns.forEach(s),ns=r(Aa,". You\u2019ll randomly crop the image, flip it horizontally, and adjust its brightness."),Aa.forEach(s),ja=f(a),L(C.$$.fragment,a),$a=f(a),Y=i(a,"P",{});var Os=p(Y);is=r(Os,"Create a function to apply the transformation to the images:"),Os.forEach(s),ba=f(a),L(P.$$.fragment,a),wa=f(a),$=i(a,"P",{});var Da=p($);os=r(Da,"Use the "),H=i(Da,"A",{href:!0});var Ms=p(H);ps=r(Ms,"set_transform()"),Ms.forEach(s),rs=r(Da," function to apply the transformation on-the-fly to batches of the dataset to consume less disk space:"),Da.forEach(s),ka=f(a),L(q.$$.fragment,a),xa=f(a),b=i(a,"P",{});var La=p(b);ms=r(La,"You can verify the transformation worked by indexing into the "),oa=i(La,"CODE",{});var Rs=p(oa);fs=r(Rs,"pixel_values"),Rs.forEach(s),cs=r(La," of the first example:"),La.forEach(s),Ea=f(a),L(A.$$.fragment,a),Ia=f(a),_=i(a,"DIV",{class:!0});var Ba=p(_);J=i(Ba,"IMG",{class:!0,src:!0}),hs=f(Ba),V=i(Ba,"IMG",{class:!0,src:!0}),Ba.forEach(s),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(Vs)),c(y,"id","image-classification"),c(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y,"href","#image-classification"),c(u,"class","relative group"),c(x,"href","https://huggingface.co/datasets/beans"),c(x,"rel","nofollow"),_s(na.src,vs="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/img_clf.png")||c(na,"src",vs),c(I,"class","flex justify-center"),c(H,"href","/docs/datasets/pr_4698/en/package_reference/main_classes#datasets.Dataset.set_transform"),c(J,"class","block dark:hidden"),_s(J.src,js="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/img_clf_aug.png")||c(J,"src",js),c(V,"class","hidden dark:block"),_s(V.src,$s="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/datasets/img_clf_aug.png")||c(V,"src",$s),c(_,"class","flex justify-center")},m(a,t){e(document.head,g),l(a,pa,t),l(a,u,t),e(u,y),e(y,X),B(w,X,null),e(u,Ta),e(u,Z),e(Z,Na),l(a,ra,t),l(a,M,t),e(M,Oa),l(a,ma,t),l(a,h,t),e(h,Ma),e(h,aa),e(aa,Ra),e(h,Sa),e(h,sa),e(sa,Ua),e(h,za),l(a,fa,t),B(k,a,t),l(a,ca,t),l(a,v,t),e(v,Fa),e(v,x),e(x,Ga),e(v,Ya),l(a,ha,t),l(a,R,t),e(R,Ha),l(a,da,t),B(E,a,t),l(a,ga,t),l(a,S,t),e(S,Ja),l(a,ua,t),l(a,d,t),e(d,U),e(U,ea),e(ea,Va),e(U,Ka),e(d,Qa),e(d,z),e(z,ta),e(ta,Wa),e(z,Xa),e(d,Za),e(d,F),e(F,la),e(la,as),e(F,ss),l(a,_a,t),l(a,G,t),e(G,es),l(a,ya,t),l(a,I,t),e(I,na),l(a,va,t),l(a,j,t),e(j,ts),e(j,ia),e(ia,ls),e(j,ns),l(a,ja,t),B(C,a,t),l(a,$a,t),l(a,Y,t),e(Y,is),l(a,ba,t),B(P,a,t),l(a,wa,t),l(a,$,t),e($,os),e($,H),e(H,ps),e($,rs),l(a,ka,t),B(q,a,t),l(a,xa,t),l(a,b,t),e(b,ms),e(b,oa),e(oa,fs),e(b,cs),l(a,Ea,t),B(A,a,t),l(a,Ia,t),l(a,_,t),e(_,J),e(_,hs),e(_,V),Ca=!0},p:Gs,i(a){Ca||(T(w.$$.fragment,a),T(k.$$.fragment,a),T(E.$$.fragment,a),T(C.$$.fragment,a),T(P.$$.fragment,a),T(q.$$.fragment,a),T(A.$$.fragment,a),Ca=!0)},o(a){N(w.$$.fragment,a),N(k.$$.fragment,a),N(E.$$.fragment,a),N(C.$$.fragment,a),N(P.$$.fragment,a),N(q.$$.fragment,a),N(A.$$.fragment,a),Ca=!1},d(a){s(g),a&&s(pa),a&&s(u),O(w),a&&s(ra),a&&s(M),a&&s(ma),a&&s(h),a&&s(fa),O(k,a),a&&s(ca),a&&s(v),a&&s(ha),a&&s(R),a&&s(da),O(E,a),a&&s(ga),a&&s(S),a&&s(ua),a&&s(d),a&&s(_a),a&&s(G),a&&s(ya),a&&s(I),a&&s(va),a&&s(j),a&&s(ja),O(C,a),a&&s($a),a&&s(Y),a&&s(ba),O(P,a),a&&s(wa),a&&s($),a&&s(ka),O(q,a),a&&s(xa),a&&s(b),a&&s(Ea),O(A,a),a&&s(Ia),a&&s(_)}}}const Vs={local:"image-classification",title:"Image classification"};function Ks(ys){return Ys(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Zs extends Ss{constructor(g){super();Us(this,g,Ks,Js,zs,{})}}export{Zs as default,Vs as metadata};
